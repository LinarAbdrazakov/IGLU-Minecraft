{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bEtC0TWMtlhX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import VisualEncoder,VisualDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhGyiJ0cmD3j"
   },
   "outputs": [],
   "source": [
    "images = np.load('images.npy') # путь до картинок из иглу\n",
    "images = np.transpose(images,(0,3,1,2))\n",
    "images = torch.Tensor(images)\n",
    "train_dataset = images\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [100000, 13873])\n",
    "train_loader = data.DataLoader(train_set, batch_size=256, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(val_set, batch_size=256, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vj5eOljtwT-T",
    "outputId": "25df78c7-6243-45ae-c9a2-e1a08fa82262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): VisualEncoder(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder): VisualDecoder(\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (cnn): Sequential(\n",
       "      (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), output_padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): ConvTranspose2d(32, 3, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (5): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "  def __init__(self,\n",
    "               encoder_class : object = VisualEncoder,\n",
    "               decoder_class : object = VisualDecoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder_class()\n",
    "    self.decoder = decoder_class()\n",
    "  def forward(self, x):\n",
    "    encode = self.encoder(x)\n",
    "    decode = self.decoder(encode)\n",
    "    return decode\n",
    "model = Autoencoder()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "BSCdzJtc4O6c",
    "outputId": "73b26f0e-0082-4485-9edf-c24e6f368f92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "config_defaults = {\n",
    "    'epochs': 10,\n",
    "    'batch_size': 256,\n",
    "    'learning_rate': 1e-3,\n",
    "    'optimizer': 'adam',\n",
    "    'model': 'VisualEncoder'\n",
    "    }\n",
    "wandb.init(project='test_try', entity='neuro_ai',config=config_defaults)\n",
    "config = wandb.config\n",
    "config = config_defaults\n",
    "optimizer = optim.Adam(model.parameters(), config.learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "for epoch in range(config.epochs):\n",
    "  #train\n",
    "  model.train()\n",
    "  # train_loss = []\n",
    "  for data in train_loader:\n",
    "    data/=255\n",
    "    data = data.to('cuda')\n",
    "    predict = model(data)\n",
    "    loss = criterion(predict, data)\n",
    "    # train_loss.append(loss.item())\n",
    "    wandb.log({\"train_loss\":loss})\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  # train_loss = np.array(train_loss).mean()\n",
    "  #evaluate\n",
    "  model.eval()\n",
    "  val_loss = []\n",
    "  for data in val_loader:\n",
    "      data/=255\n",
    "      data = data.to('cuda')\n",
    "      predict = model(data)\n",
    "      loss = criterion(predict, data)\n",
    "      val_loss.append(loss.item())\n",
    "  val_loss = np.array(val_loss).mean()\n",
    "  wandb.log({'val_loss': val_loss})\n",
    "  print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d1rZFT-Bj_H"
   },
   "outputs": [],
   "source": [
    "torch.save(model.encoder,'encoder_model.pth')\n",
    "torch.save(model.state_dict(), 'autoencoder_weights.pth')\n",
    "torch.save(model,'autoencoder_model.pth')\n",
    "torch.save(model.encoder.state_dict(),'encoder_weigths.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IGLUVisualAutoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
