{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEtC0TWMtlhX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "collapsed": true,
    "id": "-X_4bXHF4UX4",
    "outputId": "8aed9e29-65f4-495b-ced9-2d18d6d46a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.12.1-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 41.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "\u001b[K     |████████████████████████████████| 170 kB 29.9 MB/s \n",
      "\u001b[?25hCollecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 5.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
      "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
      "Building wheels for collected packages: subprocess32, pathtools\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=f38ea3066a83ba109867edd9964f12550464f1521508deedae711865ec830501\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=11b4100c93285b72f6946ad3e75389c5913034f47deb123e041770c4ab18aac8\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "Successfully built subprocess32 pathtools\n",
      "Installing collected packages: smmap, gitdb, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
      "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.12.1\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter: ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhGyiJ0cmD3j"
   },
   "outputs": [],
   "source": [
    "images = np.load('images.npy') # путь до картинок из иглу\n",
    "images = np.transpose(images,(0,3,1,2))\n",
    "images = torch.Tensor(images)\n",
    "train_dataset = images\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [100000, 13873])\n",
    "train_loader = data.DataLoader(train_set, batch_size=256, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(val_set, batch_size=256, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIIaHdwGvPQg"
   },
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self, features_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4, padding=0),  # (3, 64, 64) -> (32, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0), #             -> (64, 5, 5)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0), #             -> (64, 3, 3)\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        n_flatten = 1024\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(self.cnn(x))\n",
    "\n",
    "class VisualDecoder(nn.Module):\n",
    "    def __init__(self, features_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        n_flatten = 1024\n",
    "        self.linear = nn.Sequential(nn.Linear(features_dim, n_flatten), nn.ReLU())\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3,stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=0,output_padding=1),\n",
    "            # nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=8,stride=4, padding=0),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x.reshape(x.shape[0], 64, 4, 4)\n",
    "        x = self.cnn(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vj5eOljtwT-T",
    "outputId": "25df78c7-6243-45ae-c9a2-e1a08fa82262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): VisualEncoder(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder): VisualDecoder(\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (cnn): Sequential(\n",
       "      (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), output_padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): ConvTranspose2d(32, 3, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (5): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "  def __init__(self,\n",
    "               encoder_class : object = VisualEncoder,\n",
    "               decoder_class : object = VisualDecoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder_class()\n",
    "    self.decoder = decoder_class()\n",
    "  def forward(self, x):\n",
    "    encode = self.encoder(x)\n",
    "    decode = self.decoder(encode)\n",
    "    return decode\n",
    "model = Autoencoder()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "BSCdzJtc4O6c",
    "outputId": "73b26f0e-0082-4485-9edf-c24e6f368f92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "config_defaults = {\n",
    "    'epochs': 10,\n",
    "    'batch_size': 256,\n",
    "    'learning_rate': 1e-3,\n",
    "    'optimizer': 'adam',\n",
    "    'model': 'VisualEncoder'\n",
    "    }\n",
    "wandb.init(project='test_try', entity='neuro_ai',config=config_defaults)\n",
    "config = wandb.config\n",
    "config = config_defaults\n",
    "optimizer = optim.Adam(model.parameters(), config.learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "for epoch in range(config.epochs):\n",
    "  #train\n",
    "  model.train()\n",
    "  # train_loss = []\n",
    "  for data in train_loader:\n",
    "    data/=255\n",
    "    data = data.to('cuda')\n",
    "    predict = model(data)\n",
    "    loss = criterion(predict, data)\n",
    "    # train_loss.append(loss.item())\n",
    "    wandb.log({\"train_loss\":loss})\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  # train_loss = np.array(train_loss).mean()\n",
    "  #evaluate\n",
    "  model.eval()\n",
    "  val_loss = []\n",
    "  for data in val_loader:\n",
    "      data/=255\n",
    "      data = data.to('cuda')\n",
    "      predict = model(data)\n",
    "      loss = criterion(predict, data)\n",
    "      val_loss.append(loss.item())\n",
    "  val_loss = np.array(val_loss).mean()\n",
    "  wandb.log({'val_loss': val_loss})\n",
    "  print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d1rZFT-Bj_H"
   },
   "outputs": [],
   "source": [
    "torch.save(model.encoder,'encoder_model.pth')\n",
    "torch.save(model.state_dict(), 'autoencoder_weights.pth')\n",
    "torch.save(model,'autoencoder_model.pth')\n",
    "torch.save(model.encoder.state_dict(),'encoder_weigths.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IGLUVisualAutoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
