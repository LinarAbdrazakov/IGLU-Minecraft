{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            #nn.ELU(),\n",
    "        )\n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        target_features = target_features.reshape(target_features.shape[0], -1)\n",
    "        features = torch.cat([visual_features, target_features], dim=1)\n",
    "        features = self.policy_network(features)\n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592760ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2362368"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_features_dim = 512\n",
    "target_features_dim = 9 * 11 * 11\n",
    "policy_hidden_dim = 256 \n",
    "\n",
    "policy_network = nn.Sequential(\n",
    "    nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(512, policy_hidden_dim),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "    nn.ELU(),\n",
    "    #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "    #nn.ELU(),\n",
    ")\n",
    "\n",
    "sum(p.numel() for p in policy_network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "            \n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=250)\n",
    "    env.update_taskset(TaskSet(preset=['C3',  'C17', 'C20',\n",
    "                                       'C22', 'C32', 'C40',\n",
    "                                       'C85', 'C87', 'C93']))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-11-06 22:05:49,744\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-11-06 22:05:49,759\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id ef0ef_00000 but id b3578_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=492355)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492355)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO MultiTask <=10 pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/b3578_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/b3578_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211106_220550-b3578_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492355)\u001b[0m 2021-11-06 22:05:53,151\tWARNING ppo.py:143 -- `train_batch_size` (5000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1666.\n",
      "\u001b[2m\u001b[36m(pid=492355)\u001b[0m 2021-11-06 22:05:53,151\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=492355)\u001b[0m 2021-11-06 22:05:53,151\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492355)\u001b[0m 2021-11-06 22:05:59,158\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 9996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-09-16\n",
      "  done: false\n",
      "  episode_len_mean: 100.96938775510205\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.020000000000007\n",
      "  episode_reward_mean: -0.8130612244897962\n",
      "  episode_reward_min: -1.2400000000000009\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 98\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.882957436080672\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0067987647023400955\n",
      "          policy_loss: -0.014011172058745327\n",
      "          total_loss: -0.003066996443602774\n",
      "          vf_explained_var: -0.24038957059383392\n",
      "          vf_loss: 0.03841399739100399\n",
      "    num_agent_steps_sampled: 9996\n",
      "    num_agent_steps_trained: 9996\n",
      "    num_steps_sampled: 9996\n",
      "    num_steps_trained: 9996\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.11985815602839\n",
      "    ram_util_percent: 44.649290780141854\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04665349126705186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 51.37910823523276\n",
      "    mean_inference_ms: 2.548770144775864\n",
      "    mean_raw_obs_processing_ms: 0.5788092663818671\n",
      "  time_since_restore: 197.5869014263153\n",
      "  time_this_iter_s: 197.5869014263153\n",
      "  time_total_s: 197.5869014263153\n",
      "  timers:\n",
      "    learn_throughput: 1045.575\n",
      "    learn_time_ms: 9560.286\n",
      "    load_throughput: 89123.466\n",
      "    load_time_ms: 112.159\n",
      "    sample_throughput: 53.203\n",
      "    sample_time_ms: 187882.744\n",
      "    update_time_ms: 14.107\n",
      "  timestamp: 1636236556\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9996\n",
      "  training_iteration: 1\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         197.587</td><td style=\"text-align: right;\">9996</td><td style=\"text-align: right;\">-0.813061</td><td style=\"text-align: right;\">                3.02</td><td style=\"text-align: right;\">               -1.24</td><td style=\"text-align: right;\">           100.969</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 19992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-11-11\n",
      "  done: false\n",
      "  episode_len_mean: 98.89108910891089\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.730000000000001\n",
      "  episode_reward_mean: -0.7006930693069311\n",
      "  episode_reward_min: -1.5600000000000007\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 199\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8704273527504034\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008737530106856474\n",
      "          policy_loss: -0.01511833194611419\n",
      "          total_loss: 0.023536202814589197\n",
      "          vf_explained_var: -0.021123560145497322\n",
      "          vf_loss: 0.06561130183991681\n",
      "    num_agent_steps_sampled: 19992\n",
      "    num_agent_steps_trained: 19992\n",
      "    num_steps_sampled: 19992\n",
      "    num_steps_trained: 19992\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.37439024390245\n",
      "    ram_util_percent: 51.813414634146326\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046332798569556244\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 39.362693640289926\n",
      "    mean_inference_ms: 2.549176996976307\n",
      "    mean_raw_obs_processing_ms: 0.5822906026062229\n",
      "  time_since_restore: 312.20627212524414\n",
      "  time_this_iter_s: 114.61937069892883\n",
      "  time_total_s: 312.20627212524414\n",
      "  timers:\n",
      "    learn_throughput: 1045.672\n",
      "    learn_time_ms: 9559.4\n",
      "    load_throughput: 88600.914\n",
      "    load_time_ms: 112.821\n",
      "    sample_throughput: 68.279\n",
      "    sample_time_ms: 146398.642\n",
      "    update_time_ms: 10.957\n",
      "  timestamp: 1636236671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19992\n",
      "  training_iteration: 2\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         312.206</td><td style=\"text-align: right;\">19992</td><td style=\"text-align: right;\">-0.700693</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           98.8911</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 29988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-13-07\n",
      "  done: false\n",
      "  episode_len_mean: 97.6116504854369\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.9000000000000017\n",
      "  episode_reward_mean: -0.36242718446601996\n",
      "  episode_reward_min: -1.780000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 302\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8429944474472957\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010043211217889005\n",
      "          policy_loss: -0.02009713626347291\n",
      "          total_loss: 0.11554151282001\n",
      "          vf_explained_var: -0.02040037140250206\n",
      "          vf_loss: 0.16205995082775623\n",
      "    num_agent_steps_sampled: 29988\n",
      "    num_agent_steps_trained: 29988\n",
      "    num_steps_sampled: 29988\n",
      "    num_steps_trained: 29988\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.44606060606061\n",
      "    ram_util_percent: 51.94666666666667\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04585474523087715\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.57766686761035\n",
      "    mean_inference_ms: 2.53985396361315\n",
      "    mean_raw_obs_processing_ms: 0.5918681130157659\n",
      "  time_since_restore: 427.81026816368103\n",
      "  time_this_iter_s: 115.60399603843689\n",
      "  time_total_s: 427.81026816368103\n",
      "  timers:\n",
      "    learn_throughput: 1050.143\n",
      "    learn_time_ms: 9518.707\n",
      "    load_throughput: 88905.625\n",
      "    load_time_ms: 112.434\n",
      "    sample_throughput: 75.193\n",
      "    sample_time_ms: 132937.892\n",
      "    update_time_ms: 10.467\n",
      "  timestamp: 1636236787\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29988\n",
      "  training_iteration: 3\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">          427.81</td><td style=\"text-align: right;\">29988</td><td style=\"text-align: right;\">-0.362427</td><td style=\"text-align: right;\">                 2.9</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           97.6117</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 39984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-15-45\n",
      "  done: false\n",
      "  episode_len_mean: 96.11764705882354\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.030000000000001\n",
      "  episode_reward_mean: 0.6533333333333339\n",
      "  episode_reward_min: -1.7000000000000008\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 404\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8128473255369397\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01222613251808544\n",
      "          policy_loss: -0.022945866004651427\n",
      "          total_loss: 0.28771926366811634\n",
      "          vf_explained_var: 0.29705411195755005\n",
      "          vf_loss: 0.3363483756812464\n",
      "    num_agent_steps_sampled: 39984\n",
      "    num_agent_steps_trained: 39984\n",
      "    num_steps_sampled: 39984\n",
      "    num_steps_trained: 39984\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.71233480176211\n",
      "    ram_util_percent: 51.598678414096916\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045574677006309364\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.21939478562802\n",
      "    mean_inference_ms: 2.5249725373469163\n",
      "    mean_raw_obs_processing_ms: 1.9274640012360391\n",
      "  time_since_restore: 586.7273848056793\n",
      "  time_this_iter_s: 158.9171166419983\n",
      "  time_total_s: 586.7273848056793\n",
      "  timers:\n",
      "    learn_throughput: 1050.865\n",
      "    learn_time_ms: 9512.161\n",
      "    load_throughput: 89610.828\n",
      "    load_time_ms: 111.549\n",
      "    sample_throughput: 72.95\n",
      "    sample_time_ms: 137025.221\n",
      "    update_time_ms: 11.695\n",
      "  timestamp: 1636236945\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39984\n",
      "  training_iteration: 4\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         586.727</td><td style=\"text-align: right;\">39984</td><td style=\"text-align: right;\">0.653333</td><td style=\"text-align: right;\">                5.03</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           96.1176</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 49980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-17-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.760000000000006\n",
      "  episode_reward_mean: 0.8541000000000016\n",
      "  episode_reward_min: -1.6700000000000008\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 504\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7911398015470588\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013859893252548699\n",
      "          policy_loss: -0.02394891201208035\n",
      "          total_loss: 0.3152843459174992\n",
      "          vf_explained_var: 0.3669101297855377\n",
      "          vf_loss: 0.36437267779539795\n",
      "    num_agent_steps_sampled: 49980\n",
      "    num_agent_steps_trained: 49980\n",
      "    num_steps_sampled: 49980\n",
      "    num_steps_trained: 49980\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95197740112994\n",
      "    ram_util_percent: 52.770621468926564\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0452779960849836\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.41658193662553\n",
      "    mean_inference_ms: 2.52003693178517\n",
      "    mean_raw_obs_processing_ms: 1.680516227583418\n",
      "  time_since_restore: 710.8437783718109\n",
      "  time_this_iter_s: 124.11639356613159\n",
      "  time_total_s: 710.8437783718109\n",
      "  timers:\n",
      "    learn_throughput: 1050.346\n",
      "    learn_time_ms: 9516.863\n",
      "    load_throughput: 89482.133\n",
      "    load_time_ms: 111.709\n",
      "    sample_throughput: 75.436\n",
      "    sample_time_ms: 132509.475\n",
      "    update_time_ms: 10.845\n",
      "  timestamp: 1636237070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 49980\n",
      "  training_iteration: 5\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         710.844</td><td style=\"text-align: right;\">49980</td><td style=\"text-align: right;\">  0.8541</td><td style=\"text-align: right;\">                4.76</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">             100.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 59976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-20-07\n",
      "  done: false\n",
      "  episode_len_mean: 101.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.930000000000001\n",
      "  episode_reward_mean: 0.9985000000000016\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 603\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7747156992936746\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017946328197573493\n",
      "          policy_loss: -0.026925969722433985\n",
      "          total_loss: 0.3421958462916251\n",
      "          vf_explained_var: 0.4086821675300598\n",
      "          vf_loss: 0.3932797075273135\n",
      "    num_agent_steps_sampled: 59976\n",
      "    num_agent_steps_trained: 59976\n",
      "    num_steps_sampled: 59976\n",
      "    num_steps_trained: 59976\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.68979591836734\n",
      "    ram_util_percent: 53.1061224489796\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044872165880920536\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.71122550666743\n",
      "    mean_inference_ms: 2.513077104767986\n",
      "    mean_raw_obs_processing_ms: 2.086902733930238\n",
      "  time_since_restore: 848.345941066742\n",
      "  time_this_iter_s: 137.50216269493103\n",
      "  time_total_s: 848.345941066742\n",
      "  timers:\n",
      "    learn_throughput: 1050.783\n",
      "    learn_time_ms: 9512.903\n",
      "    load_throughput: 89658.384\n",
      "    load_time_ms: 111.49\n",
      "    sample_throughput: 75.879\n",
      "    sample_time_ms: 131735.742\n",
      "    update_time_ms: 11.371\n",
      "  timestamp: 1636237207\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59976\n",
      "  training_iteration: 6\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         848.346</td><td style=\"text-align: right;\">59976</td><td style=\"text-align: right;\">  0.9985</td><td style=\"text-align: right;\">                4.93</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">            101.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 69972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-22-25\n",
      "  done: false\n",
      "  episode_len_mean: 102.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.1800000000000015\n",
      "  episode_reward_mean: 1.402000000000003\n",
      "  episode_reward_min: -1.7700000000000011\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 700\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.749470445029756\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01701558884952315\n",
      "          policy_loss: -0.024770759908148112\n",
      "          total_loss: 0.3153886606741665\n",
      "          vf_explained_var: 0.46201270818710327\n",
      "          vf_loss: 0.3642510064583049\n",
      "    num_agent_steps_sampled: 69972\n",
      "    num_agent_steps_trained: 69972\n",
      "    num_steps_sampled: 69972\n",
      "    num_steps_trained: 69972\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.64314720812185\n",
      "    ram_util_percent: 53.1984771573604\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04483189987575475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.26087631831072\n",
      "    mean_inference_ms: 2.512332999769949\n",
      "    mean_raw_obs_processing_ms: 2.1219232940326287\n",
      "  time_since_restore: 986.4011962413788\n",
      "  time_this_iter_s: 138.05525517463684\n",
      "  time_total_s: 986.4011962413788\n",
      "  timers:\n",
      "    learn_throughput: 1051.184\n",
      "    learn_time_ms: 9509.28\n",
      "    load_throughput: 89867.732\n",
      "    load_time_ms: 111.23\n",
      "    sample_throughput: 76.151\n",
      "    sample_time_ms: 131264.666\n",
      "    update_time_ms: 10.698\n",
      "  timestamp: 1636237345\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69972\n",
      "  training_iteration: 7\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         986.401</td><td style=\"text-align: right;\">69972</td><td style=\"text-align: right;\">   1.402</td><td style=\"text-align: right;\">                5.18</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">            102.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 79968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-25-04\n",
      "  done: false\n",
      "  episode_len_mean: 100.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.040000000000001\n",
      "  episode_reward_mean: 1.0834000000000026\n",
      "  episode_reward_min: -1.950000000000001\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 800\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.737551778809637\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015216405026077285\n",
      "          policy_loss: -0.030675791710233078\n",
      "          total_loss: 0.27992696514050674\n",
      "          vf_explained_var: 0.4941944479942322\n",
      "          vf_loss: 0.33493499320923775\n",
      "    num_agent_steps_sampled: 79968\n",
      "    num_agent_steps_trained: 79968\n",
      "    num_steps_sampled: 79968\n",
      "    num_steps_trained: 79968\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.82522123893806\n",
      "    ram_util_percent: 53.28982300884957\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044414739694268714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.62568777854387\n",
      "    mean_inference_ms: 2.5028626250769928\n",
      "    mean_raw_obs_processing_ms: 2.5476138937091837\n",
      "  time_since_restore: 1144.8867263793945\n",
      "  time_this_iter_s: 158.48553013801575\n",
      "  time_total_s: 1144.8867263793945\n",
      "  timers:\n",
      "    learn_throughput: 1051.575\n",
      "    learn_time_ms: 9505.74\n",
      "    load_throughput: 90308.597\n",
      "    load_time_ms: 110.687\n",
      "    sample_throughput: 74.895\n",
      "    sample_time_ms: 133466.5\n",
      "    update_time_ms: 10.021\n",
      "  timestamp: 1636237504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79968\n",
      "  training_iteration: 8\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         1144.89</td><td style=\"text-align: right;\">79968</td><td style=\"text-align: right;\">  1.0834</td><td style=\"text-align: right;\">                5.04</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">             100.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 89964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-27-45\n",
      "  done: false\n",
      "  episode_len_mean: 102.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.69\n",
      "  episode_reward_mean: 1.588600000000004\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 897\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7144894275909817\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01794989639724444\n",
      "          policy_loss: -0.028097341814611713\n",
      "          total_loss: 0.3276387840222854\n",
      "          vf_explained_var: 0.6041265726089478\n",
      "          vf_loss: 0.3792910394505558\n",
      "    num_agent_steps_sampled: 89964\n",
      "    num_agent_steps_trained: 89964\n",
      "    num_steps_sampled: 89964\n",
      "    num_steps_trained: 89964\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.43160173160175\n",
      "    ram_util_percent: 53.23636363636365\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04413276281369979\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.009760450887367\n",
      "    mean_inference_ms: 2.494409084583233\n",
      "    mean_raw_obs_processing_ms: 3.1217986719550397\n",
      "  time_since_restore: 1306.3656010627747\n",
      "  time_this_iter_s: 161.47887468338013\n",
      "  time_total_s: 1306.3656010627747\n",
      "  timers:\n",
      "    learn_throughput: 1052.373\n",
      "    learn_time_ms: 9498.53\n",
      "    load_throughput: 90435.117\n",
      "    load_time_ms: 110.532\n",
      "    sample_throughput: 73.763\n",
      "    sample_time_ms: 135515.741\n",
      "    update_time_ms: 9.809\n",
      "  timestamp: 1636237665\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89964\n",
      "  training_iteration: 9\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         1306.37</td><td style=\"text-align: right;\">89964</td><td style=\"text-align: right;\">  1.5886</td><td style=\"text-align: right;\">                5.69</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">             102.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 99960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-31-15\n",
      "  done: false\n",
      "  episode_len_mean: 100.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.720000000000001\n",
      "  episode_reward_mean: 1.8725000000000054\n",
      "  episode_reward_min: -2.1999999999999997\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 996\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.679502201284099\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01843892547095932\n",
      "          policy_loss: -0.030897222126587333\n",
      "          total_loss: 0.33880648418910736\n",
      "          vf_explained_var: 0.6360749006271362\n",
      "          vf_loss: 0.3928109419778881\n",
      "    num_agent_steps_sampled: 99960\n",
      "    num_agent_steps_trained: 99960\n",
      "    num_steps_sampled: 99960\n",
      "    num_steps_trained: 99960\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.03166666666667\n",
      "    ram_util_percent: 53.315999999999995\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043941584844242494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.495614675099915\n",
      "    mean_inference_ms: 2.485480289163285\n",
      "    mean_raw_obs_processing_ms: 4.548030961849907\n",
      "  time_since_restore: 1516.5655653476715\n",
      "  time_this_iter_s: 210.19996428489685\n",
      "  time_total_s: 1516.5655653476715\n",
      "  timers:\n",
      "    learn_throughput: 1052.493\n",
      "    learn_time_ms: 9497.453\n",
      "    load_throughput: 90547.303\n",
      "    load_time_ms: 110.395\n",
      "    sample_throughput: 70.383\n",
      "    sample_time_ms: 142022.513\n",
      "    update_time_ms: 9.702\n",
      "  timestamp: 1636237875\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99960\n",
      "  training_iteration: 10\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         1516.57</td><td style=\"text-align: right;\">99960</td><td style=\"text-align: right;\">  1.8725</td><td style=\"text-align: right;\">                5.72</td><td style=\"text-align: right;\">                -2.2</td><td style=\"text-align: right;\">             100.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 109956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-34-35\n",
      "  done: false\n",
      "  episode_len_mean: 97.49514563106796\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.430000000000007\n",
      "  episode_reward_mean: 2.019029126213598\n",
      "  episode_reward_min: -1.8200000000000007\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 1099\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6543958763790947\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019016498642828387\n",
      "          policy_loss: -0.029504858704013193\n",
      "          total_loss: 0.3336116527533557\n",
      "          vf_explained_var: 0.6999174356460571\n",
      "          vf_loss: 0.38585717069287584\n",
      "    num_agent_steps_sampled: 109956\n",
      "    num_agent_steps_trained: 109956\n",
      "    num_steps_sampled: 109956\n",
      "    num_steps_trained: 109956\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.54436619718311\n",
      "    ram_util_percent: 53.46338028169014\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04383589283427113\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.32134314744901\n",
      "    mean_inference_ms: 2.481254826887094\n",
      "    mean_raw_obs_processing_ms: 5.448244219302294\n",
      "  time_since_restore: 1716.0904269218445\n",
      "  time_this_iter_s: 199.52486157417297\n",
      "  time_total_s: 1716.0904269218445\n",
      "  timers:\n",
      "    learn_throughput: 1053.134\n",
      "    learn_time_ms: 9491.67\n",
      "    load_throughput: 90660.592\n",
      "    load_time_ms: 110.257\n",
      "    sample_throughput: 70.284\n",
      "    sample_time_ms: 142223.683\n",
      "    update_time_ms: 8.703\n",
      "  timestamp: 1636238075\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109956\n",
      "  training_iteration: 11\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         1716.09</td><td style=\"text-align: right;\">109956</td><td style=\"text-align: right;\"> 2.01903</td><td style=\"text-align: right;\">                9.43</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           97.4951</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 119952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-38-36\n",
      "  done: false\n",
      "  episode_len_mean: 96.75728155339806\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.510000000000012\n",
      "  episode_reward_mean: 2.352621359223307\n",
      "  episode_reward_min: -1.600000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 1202\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.626043531629774\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.020383396375117574\n",
      "          policy_loss: -0.035758528064013036\n",
      "          total_loss: 0.29308553997220266\n",
      "          vf_explained_var: 0.7461588382720947\n",
      "          vf_loss: 0.3510278247869932\n",
      "    num_agent_steps_sampled: 119952\n",
      "    num_agent_steps_trained: 119952\n",
      "    num_steps_sampled: 119952\n",
      "    num_steps_trained: 119952\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.30927536231883\n",
      "    ram_util_percent: 53.41101449275363\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04366204060058737\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.92023080009028\n",
      "    mean_inference_ms: 2.473618401264237\n",
      "    mean_raw_obs_processing_ms: 7.468259207654213\n",
      "  time_since_restore: 1957.4705951213837\n",
      "  time_this_iter_s: 241.38016819953918\n",
      "  time_total_s: 1957.4705951213837\n",
      "  timers:\n",
      "    learn_throughput: 1054.3\n",
      "    learn_time_ms: 9481.169\n",
      "    load_throughput: 90942.099\n",
      "    load_time_ms: 109.916\n",
      "    sample_throughput: 64.527\n",
      "    sample_time_ms: 154911.618\n",
      "    update_time_ms: 8.764\n",
      "  timestamp: 1636238316\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119952\n",
      "  training_iteration: 12\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         1957.47</td><td style=\"text-align: right;\">119952</td><td style=\"text-align: right;\"> 2.35262</td><td style=\"text-align: right;\">                6.51</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           96.7573</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 129948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-43-02\n",
      "  done: false\n",
      "  episode_len_mean: 90.9090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.95000000000001\n",
      "  episode_reward_mean: 2.8700000000000068\n",
      "  episode_reward_min: -1.5800000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 1312\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.57596069401146\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02080014275892654\n",
      "          policy_loss: -0.03537120167325195\n",
      "          total_loss: 0.31262989497114707\n",
      "          vf_explained_var: 0.7252334952354431\n",
      "          vf_loss: 0.36752065790450983\n",
      "    num_agent_steps_sampled: 129948\n",
      "    num_agent_steps_trained: 129948\n",
      "    num_steps_sampled: 129948\n",
      "    num_steps_trained: 129948\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.24459102902374\n",
      "    ram_util_percent: 53.46094986807388\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04351240818321895\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.65492141360455\n",
      "    mean_inference_ms: 2.466431466391678\n",
      "    mean_raw_obs_processing_ms: 9.78515950461998\n",
      "  time_since_restore: 2223.0758583545685\n",
      "  time_this_iter_s: 265.6052632331848\n",
      "  time_total_s: 2223.0758583545685\n",
      "  timers:\n",
      "    learn_throughput: 1053.687\n",
      "    learn_time_ms: 9486.689\n",
      "    load_throughput: 91076.554\n",
      "    load_time_ms: 109.754\n",
      "    sample_throughput: 58.832\n",
      "    sample_time_ms: 169908.197\n",
      "    update_time_ms: 8.787\n",
      "  timestamp: 1636238582\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129948\n",
      "  training_iteration: 13\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         2223.08</td><td style=\"text-align: right;\">129948</td><td style=\"text-align: right;\">    2.87</td><td style=\"text-align: right;\">                8.95</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           90.9091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 139944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-48-24\n",
      "  done: false\n",
      "  episode_len_mean: 92.05504587155963\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.130000000000016\n",
      "  episode_reward_mean: 3.1777064220183564\n",
      "  episode_reward_min: 0.159999999999999\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 1421\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.551375644431155\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019077878332017177\n",
      "          policy_loss: -0.03712439205593024\n",
      "          total_loss: 0.3298228888780388\n",
      "          vf_explained_var: 0.7895557284355164\n",
      "          vf_loss: 0.3838759921172745\n",
      "    num_agent_steps_sampled: 139944\n",
      "    num_agent_steps_trained: 139944\n",
      "    num_steps_sampled: 139944\n",
      "    num_steps_trained: 139944\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.56304347826087\n",
      "    ram_util_percent: 53.68239130434783\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04330729832407384\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.310961074090663\n",
      "    mean_inference_ms: 2.4591113479433195\n",
      "    mean_raw_obs_processing_ms: 11.791266379142408\n",
      "  time_since_restore: 2545.246042251587\n",
      "  time_this_iter_s: 322.17018389701843\n",
      "  time_total_s: 2545.246042251587\n",
      "  timers:\n",
      "    learn_throughput: 1054.132\n",
      "    learn_time_ms: 9482.681\n",
      "    load_throughput: 90881.245\n",
      "    load_time_ms: 109.99\n",
      "    sample_throughput: 53.673\n",
      "    sample_time_ms: 186238.455\n",
      "    update_time_ms: 7.708\n",
      "  timestamp: 1636238904\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 139944\n",
      "  training_iteration: 14\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         2545.25</td><td style=\"text-align: right;\">139944</td><td style=\"text-align: right;\"> 3.17771</td><td style=\"text-align: right;\">                7.13</td><td style=\"text-align: right;\">                0.16</td><td style=\"text-align: right;\">            92.055</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 149940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-54-50\n",
      "  done: false\n",
      "  episode_len_mean: 84.00840336134453\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.82\n",
      "  episode_reward_mean: 3.023949579831939\n",
      "  episode_reward_min: -1.4700000000000009\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 1540\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5483338394735613\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017781711699984052\n",
      "          policy_loss: -0.035487792405307805\n",
      "          total_loss: 0.3097625810517651\n",
      "          vf_explained_var: 0.8187939524650574\n",
      "          vf_loss: 0.3627319406845376\n",
      "    num_agent_steps_sampled: 149940\n",
      "    num_agent_steps_trained: 149940\n",
      "    num_steps_sampled: 149940\n",
      "    num_steps_trained: 149940\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.08181818181818\n",
      "    ram_util_percent: 53.593818181818186\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04310200323165829\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.033955022121162\n",
      "    mean_inference_ms: 2.450618852089073\n",
      "    mean_raw_obs_processing_ms: 14.966337016100292\n",
      "  time_since_restore: 2931.022573709488\n",
      "  time_this_iter_s: 385.776531457901\n",
      "  time_total_s: 2931.022573709488\n",
      "  timers:\n",
      "    learn_throughput: 1054.983\n",
      "    learn_time_ms: 9475.036\n",
      "    load_throughput: 91232.088\n",
      "    load_time_ms: 109.567\n",
      "    sample_throughput: 47.06\n",
      "    sample_time_ms: 212411.77\n",
      "    update_time_ms: 8.504\n",
      "  timestamp: 1636239290\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 149940\n",
      "  training_iteration: 15\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         2931.02</td><td style=\"text-align: right;\">149940</td><td style=\"text-align: right;\"> 3.02395</td><td style=\"text-align: right;\">                9.82</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           84.0084</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 159936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_22-58-34\n",
      "  done: false\n",
      "  episode_len_mean: 89.45045045045045\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.160000000000011\n",
      "  episode_reward_mean: 3.203783783783791\n",
      "  episode_reward_min: 0.0899999999999996\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 1651\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5235114162803716\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01848577281741722\n",
      "          policy_loss: -0.03941809037604775\n",
      "          total_loss: 0.26491224150467885\n",
      "          vf_explained_var: 0.839900553226471\n",
      "          vf_loss: 0.32124684788605085\n",
      "    num_agent_steps_sampled: 159936\n",
      "    num_agent_steps_trained: 159936\n",
      "    num_steps_sampled: 159936\n",
      "    num_steps_trained: 159936\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.420625\n",
      "    ram_util_percent: 53.6875\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04298376882980059\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.973030135530884\n",
      "    mean_inference_ms: 2.447614721179266\n",
      "    mean_raw_obs_processing_ms: 15.666724344981409\n",
      "  time_since_restore: 3155.1527416706085\n",
      "  time_this_iter_s: 224.1301679611206\n",
      "  time_total_s: 3155.1527416706085\n",
      "  timers:\n",
      "    learn_throughput: 1055.215\n",
      "    learn_time_ms: 9472.952\n",
      "    load_throughput: 90879.669\n",
      "    load_time_ms: 109.992\n",
      "    sample_throughput: 45.215\n",
      "    sample_time_ms: 221077.042\n",
      "    update_time_ms: 8.294\n",
      "  timestamp: 1636239514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159936\n",
      "  training_iteration: 16\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         3155.15</td><td style=\"text-align: right;\">159936</td><td style=\"text-align: right;\"> 3.20378</td><td style=\"text-align: right;\">                7.16</td><td style=\"text-align: right;\">                0.09</td><td style=\"text-align: right;\">           89.4505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 169932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_23-03-54\n",
      "  done: false\n",
      "  episode_len_mean: 84.13333333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.680000000000001\n",
      "  episode_reward_mean: 3.410083333333341\n",
      "  episode_reward_min: -1.630000000000001\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 1771\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4809008734857936\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.020637559266016972\n",
      "          policy_loss: -0.0401372610599312\n",
      "          total_loss: 0.29531532770548113\n",
      "          vf_explained_var: 0.8618206977844238\n",
      "          vf_loss: 0.3509746960658803\n",
      "    num_agent_steps_sampled: 169932\n",
      "    num_agent_steps_trained: 169932\n",
      "    num_steps_sampled: 169932\n",
      "    num_steps_trained: 169932\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.38377192982456\n",
      "    ram_util_percent: 53.68421052631579\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.042868633291589235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.8450645056379\n",
      "    mean_inference_ms: 2.443056489515871\n",
      "    mean_raw_obs_processing_ms: 17.73286797192419\n",
      "  time_since_restore: 3475.1338102817535\n",
      "  time_this_iter_s: 319.981068611145\n",
      "  time_total_s: 3475.1338102817535\n",
      "  timers:\n",
      "    learn_throughput: 1056.074\n",
      "    learn_time_ms: 9465.243\n",
      "    load_throughput: 90887.608\n",
      "    load_time_ms: 109.982\n",
      "    sample_throughput: 41.776\n",
      "    sample_time_ms: 239277.137\n",
      "    update_time_ms: 8.53\n",
      "  timestamp: 1636239834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169932\n",
      "  training_iteration: 17\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         3475.13</td><td style=\"text-align: right;\">169932</td><td style=\"text-align: right;\"> 3.41008</td><td style=\"text-align: right;\">                9.68</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           84.1333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 179928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_23-10-31\n",
      "  done: false\n",
      "  episode_len_mean: 78.078125\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.430000000000007\n",
      "  episode_reward_mean: 3.6878125000000064\n",
      "  episode_reward_min: -1.5200000000000005\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 1899\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4428030230041244\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01808975568574261\n",
      "          policy_loss: -0.03721424026303312\n",
      "          total_loss: 0.29554537732918296\n",
      "          vf_explained_var: 0.8480872511863708\n",
      "          vf_loss: 0.3449770635455592\n",
      "    num_agent_steps_sampled: 179928\n",
      "    num_agent_steps_trained: 179928\n",
      "    num_steps_sampled: 179928\n",
      "    num_steps_trained: 179928\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.42155477031802\n",
      "    ram_util_percent: 53.84151943462898\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04274604800234344\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.790347900573348\n",
      "    mean_inference_ms: 2.437909415084066\n",
      "    mean_raw_obs_processing_ms: 20.333512480183074\n",
      "  time_since_restore: 3871.4240498542786\n",
      "  time_this_iter_s: 396.290239572525\n",
      "  time_total_s: 3871.4240498542786\n",
      "  timers:\n",
      "    learn_throughput: 1056.605\n",
      "    learn_time_ms: 9460.493\n",
      "    load_throughput: 90631.019\n",
      "    load_time_ms: 110.293\n",
      "    sample_throughput: 37.999\n",
      "    sample_time_ms: 263062.174\n",
      "    update_time_ms: 8.416\n",
      "  timestamp: 1636240231\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179928\n",
      "  training_iteration: 18\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         3871.42</td><td style=\"text-align: right;\">179928</td><td style=\"text-align: right;\"> 3.68781</td><td style=\"text-align: right;\">                9.43</td><td style=\"text-align: right;\">               -1.52</td><td style=\"text-align: right;\">           78.0781</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 189924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_23-17-14\n",
      "  done: false\n",
      "  episode_len_mean: 79.624\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.870000000000013\n",
      "  episode_reward_mean: 3.826480000000007\n",
      "  episode_reward_min: -1.1200000000000008\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 2024\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.418796075307406\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018642236216753386\n",
      "          policy_loss: -0.040468431994892085\n",
      "          total_loss: 0.281378404980796\n",
      "          vf_explained_var: 0.8543462157249451\n",
      "          vf_loss: 0.33345128616206665\n",
      "    num_agent_steps_sampled: 189924\n",
      "    num_agent_steps_trained: 189924\n",
      "    num_steps_sampled: 189924\n",
      "    num_steps_trained: 189924\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.85791304347825\n",
      "    ram_util_percent: 53.797391304347826\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.042636187953394925\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.776994333214635\n",
      "    mean_inference_ms: 2.4339308040727166\n",
      "    mean_raw_obs_processing_ms: 22.720835742204176\n",
      "  time_since_restore: 4274.498636484146\n",
      "  time_this_iter_s: 403.07458662986755\n",
      "  time_total_s: 4274.498636484146\n",
      "  timers:\n",
      "    learn_throughput: 1056.27\n",
      "    learn_time_ms: 9463.487\n",
      "    load_throughput: 90550.139\n",
      "    load_time_ms: 110.392\n",
      "    sample_throughput: 34.803\n",
      "    sample_time_ms: 287218.313\n",
      "    update_time_ms: 8.461\n",
      "  timestamp: 1636240634\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189924\n",
      "  training_iteration: 19\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">          4274.5</td><td style=\"text-align: right;\">189924</td><td style=\"text-align: right;\"> 3.82648</td><td style=\"text-align: right;\">               10.87</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">            79.624</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 199920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_23-22-00\n",
      "  done: false\n",
      "  episode_len_mean: 85.17796610169492\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.73000000000001\n",
      "  episode_reward_mean: 3.441101694915263\n",
      "  episode_reward_min: 0.16999999999999915\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 2142\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.425335910381415\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018698607429357954\n",
      "          policy_loss: -0.042993195028577604\n",
      "          total_loss: 0.2942822369070262\n",
      "          vf_explained_var: 0.8412535190582275\n",
      "          vf_loss: 0.3489072308007978\n",
      "    num_agent_steps_sampled: 199920\n",
      "    num_agent_steps_trained: 199920\n",
      "    num_steps_sampled: 199920\n",
      "    num_steps_trained: 199920\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.55980392156862\n",
      "    ram_util_percent: 53.970588235294116\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0426120908601983\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.8224255152265\n",
      "    mean_inference_ms: 2.4333244596744668\n",
      "    mean_raw_obs_processing_ms: 23.470765450575573\n",
      "  time_since_restore: 4560.362314462662\n",
      "  time_this_iter_s: 285.8636779785156\n",
      "  time_total_s: 4560.362314462662\n",
      "  timers:\n",
      "    learn_throughput: 1056.25\n",
      "    learn_time_ms: 9463.668\n",
      "    load_throughput: 90317.196\n",
      "    load_time_ms: 110.677\n",
      "    sample_throughput: 33.91\n",
      "    sample_time_ms: 294783.909\n",
      "    update_time_ms: 8.832\n",
      "  timestamp: 1636240920\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199920\n",
      "  training_iteration: 20\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         4560.36</td><td style=\"text-align: right;\">199920</td><td style=\"text-align: right;\">  3.4411</td><td style=\"text-align: right;\">                8.73</td><td style=\"text-align: right;\">                0.17</td><td style=\"text-align: right;\">            85.178</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 209916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_23-29-24\n",
      "  done: false\n",
      "  episode_len_mean: 78.40625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.89\n",
      "  episode_reward_mean: 3.4210156250000066\n",
      "  episode_reward_min: -1.1900000000000008\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 2270\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4237866195858033\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017780377532087634\n",
      "          policy_loss: -0.046512353108224706\n",
      "          total_loss: 0.23710899967381843\n",
      "          vf_explained_var: 0.8547632694244385\n",
      "          vf_loss: 0.29585746350324055\n",
      "    num_agent_steps_sampled: 209916\n",
      "    num_agent_steps_trained: 209916\n",
      "    num_steps_sampled: 209916\n",
      "    num_steps_trained: 209916\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.55520504731861\n",
      "    ram_util_percent: 54.05283911671924\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0425327469742661\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.754946940282757\n",
      "    mean_inference_ms: 2.4299510356510567\n",
      "    mean_raw_obs_processing_ms: 26.064729763473167\n",
      "  time_since_restore: 5004.676823139191\n",
      "  time_this_iter_s: 444.31450867652893\n",
      "  time_total_s: 5004.676823139191\n",
      "  timers:\n",
      "    learn_throughput: 1057.052\n",
      "    learn_time_ms: 9456.491\n",
      "    load_throughput: 90307.974\n",
      "    load_time_ms: 110.688\n",
      "    sample_throughput: 31.309\n",
      "    sample_time_ms: 319269.87\n",
      "    update_time_ms: 8.799\n",
      "  timestamp: 1636241364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209916\n",
      "  training_iteration: 21\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         5004.68</td><td style=\"text-align: right;\">209916</td><td style=\"text-align: right;\"> 3.42102</td><td style=\"text-align: right;\">                9.89</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           78.4062</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 219912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_23-34-52\n",
      "  done: false\n",
      "  episode_len_mean: 86.72173913043478\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.730000000000004\n",
      "  episode_reward_mean: 3.7476521739130524\n",
      "  episode_reward_min: -1.569999999999995\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 2385\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4194643079725084\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02015789779634748\n",
      "          policy_loss: -0.04479248279498683\n",
      "          total_loss: 0.27843376113754564\n",
      "          vf_explained_var: 0.8601797819137573\n",
      "          vf_loss: 0.33381430635976994\n",
      "    num_agent_steps_sampled: 219912\n",
      "    num_agent_steps_trained: 219912\n",
      "    num_steps_sampled: 219912\n",
      "    num_steps_trained: 219912\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.08464818763325\n",
      "    ram_util_percent: 54.04413646055437\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04248545277959117\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.757754020328804\n",
      "    mean_inference_ms: 2.4289183762106163\n",
      "    mean_raw_obs_processing_ms: 26.85449394443415\n",
      "  time_since_restore: 5333.048065662384\n",
      "  time_this_iter_s: 328.37124252319336\n",
      "  time_total_s: 5333.048065662384\n",
      "  timers:\n",
      "    learn_throughput: 1057.45\n",
      "    learn_time_ms: 9452.929\n",
      "    load_throughput: 90334.846\n",
      "    load_time_ms: 110.655\n",
      "    sample_throughput: 30.478\n",
      "    sample_time_ms: 327972.467\n",
      "    update_time_ms: 9.191\n",
      "  timestamp: 1636241692\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219912\n",
      "  training_iteration: 22\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         5333.05</td><td style=\"text-align: right;\">219912</td><td style=\"text-align: right;\"> 3.74765</td><td style=\"text-align: right;\">                9.73</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           86.7217</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 229908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_23-41-29\n",
      "  done: false\n",
      "  episode_len_mean: 83.84615384615384\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.440000000000015\n",
      "  episode_reward_mean: 3.996495726495735\n",
      "  episode_reward_min: -0.07000000000000067\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 2502\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.41907168820373\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01666302551976726\n",
      "          policy_loss: -0.04908370156493834\n",
      "          total_loss: 0.2599359986077771\n",
      "          vf_explained_var: 0.850044846534729\n",
      "          vf_loss: 0.3163391024638445\n",
      "    num_agent_steps_sampled: 229908\n",
      "    num_agent_steps_trained: 229908\n",
      "    num_steps_sampled: 229908\n",
      "    num_steps_trained: 229908\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.62014134275618\n",
      "    ram_util_percent: 54.129858657243815\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04238609153722123\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.6658478681376\n",
      "    mean_inference_ms: 2.4258167399802555\n",
      "    mean_raw_obs_processing_ms: 28.03825425003795\n",
      "  time_since_restore: 5729.907423019409\n",
      "  time_this_iter_s: 396.85935735702515\n",
      "  time_total_s: 5729.907423019409\n",
      "  timers:\n",
      "    learn_throughput: 1057.528\n",
      "    learn_time_ms: 9452.229\n",
      "    load_throughput: 89935.396\n",
      "    load_time_ms: 111.146\n",
      "    sample_throughput: 29.305\n",
      "    sample_time_ms: 341097.695\n",
      "    update_time_ms: 9.057\n",
      "  timestamp: 1636242089\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229908\n",
      "  training_iteration: 23\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         5729.91</td><td style=\"text-align: right;\">229908</td><td style=\"text-align: right;\">  3.9965</td><td style=\"text-align: right;\">               10.44</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">           83.8462</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 239904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_23-48-03\n",
      "  done: false\n",
      "  episode_len_mean: 84.81666666666666\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.89\n",
      "  episode_reward_mean: 3.811666666666676\n",
      "  episode_reward_min: -1.860000000000001\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 2622\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.396184074776804\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01651395082867579\n",
      "          policy_loss: -0.044860115060264355\n",
      "          total_loss: 0.24147657083236\n",
      "          vf_explained_var: 0.8714379668235779\n",
      "          vf_loss: 0.29357815130462506\n",
      "    num_agent_steps_sampled: 239904\n",
      "    num_agent_steps_trained: 239904\n",
      "    num_steps_sampled: 239904\n",
      "    num_steps_trained: 239904\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.18879003558719\n",
      "    ram_util_percent: 54.06459074733096\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04232552851778416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.555522817176975\n",
      "    mean_inference_ms: 2.423502951319431\n",
      "    mean_raw_obs_processing_ms: 29.549029045772773\n",
      "  time_since_restore: 6124.046488046646\n",
      "  time_this_iter_s: 394.13906502723694\n",
      "  time_total_s: 6124.046488046646\n",
      "  timers:\n",
      "    learn_throughput: 1057.259\n",
      "    learn_time_ms: 9454.636\n",
      "    load_throughput: 88929.643\n",
      "    load_time_ms: 112.403\n",
      "    sample_throughput: 28.7\n",
      "    sample_time_ms: 348290.774\n",
      "    update_time_ms: 9.042\n",
      "  timestamp: 1636242483\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239904\n",
      "  training_iteration: 24\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         6124.05</td><td style=\"text-align: right;\">239904</td><td style=\"text-align: right;\"> 3.81167</td><td style=\"text-align: right;\">                9.89</td><td style=\"text-align: right;\">               -1.86</td><td style=\"text-align: right;\">           84.8167</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 249900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_23-54-17\n",
      "  done: false\n",
      "  episode_len_mean: 81.80327868852459\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.890000000000013\n",
      "  episode_reward_mean: 4.035163934426238\n",
      "  episode_reward_min: 0.019999999999999053\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 2744\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3832997169250096\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017087917827843548\n",
      "          policy_loss: -0.046394988188408634\n",
      "          total_loss: 0.25245897526709504\n",
      "          vf_explained_var: 0.878831148147583\n",
      "          vf_loss: 0.3053854423392023\n",
      "    num_agent_steps_sampled: 249900\n",
      "    num_agent_steps_trained: 249900\n",
      "    num_steps_sampled: 249900\n",
      "    num_steps_trained: 249900\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.10825515947468\n",
      "    ram_util_percent: 54.12720450281425\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.042270653134512934\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.47417870456364\n",
      "    mean_inference_ms: 2.420598797171939\n",
      "    mean_raw_obs_processing_ms: 30.872991730988613\n",
      "  time_since_restore: 6497.446809530258\n",
      "  time_this_iter_s: 373.40032148361206\n",
      "  time_total_s: 6497.446809530258\n",
      "  timers:\n",
      "    learn_throughput: 1057.092\n",
      "    learn_time_ms: 9456.128\n",
      "    load_throughput: 88740.813\n",
      "    load_time_ms: 112.643\n",
      "    sample_throughput: 28.803\n",
      "    sample_time_ms: 347052.538\n",
      "    update_time_ms: 8.021\n",
      "  timestamp: 1636242857\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249900\n",
      "  training_iteration: 25\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         6497.45</td><td style=\"text-align: right;\">249900</td><td style=\"text-align: right;\"> 4.03516</td><td style=\"text-align: right;\">               10.89</td><td style=\"text-align: right;\">                0.02</td><td style=\"text-align: right;\">           81.8033</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 259896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_00-01-21\n",
      "  done: false\n",
      "  episode_len_mean: 83.4201680672269\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.89\n",
      "  episode_reward_mean: 3.9489075630252186\n",
      "  episode_reward_min: -0.18000000000000083\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 2863\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.365568749517457\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01661658791001848\n",
      "          policy_loss: -0.04441583103731147\n",
      "          total_loss: 0.25259184654738404\n",
      "          vf_explained_var: 0.8834826350212097\n",
      "          vf_loss: 0.30383906855415077\n",
      "    num_agent_steps_sampled: 259896\n",
      "    num_agent_steps_trained: 259896\n",
      "    num_steps_sampled: 259896\n",
      "    num_steps_trained: 259896\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.95528052805281\n",
      "    ram_util_percent: 54.323267326732676\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04221683050933522\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.398548966797303\n",
      "    mean_inference_ms: 2.4188249622999756\n",
      "    mean_raw_obs_processing_ms: 32.04731144313333\n",
      "  time_since_restore: 6921.577965259552\n",
      "  time_this_iter_s: 424.1311557292938\n",
      "  time_total_s: 6921.577965259552\n",
      "  timers:\n",
      "    learn_throughput: 1057.35\n",
      "    learn_time_ms: 9453.822\n",
      "    load_throughput: 89056.053\n",
      "    load_time_ms: 112.244\n",
      "    sample_throughput: 27.233\n",
      "    sample_time_ms: 367056.039\n",
      "    update_time_ms: 7.383\n",
      "  timestamp: 1636243281\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259896\n",
      "  training_iteration: 26\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         6921.58</td><td style=\"text-align: right;\">259896</td><td style=\"text-align: right;\"> 3.94891</td><td style=\"text-align: right;\">                9.89</td><td style=\"text-align: right;\">               -0.18</td><td style=\"text-align: right;\">           83.4202</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 269892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_00-06-54\n",
      "  done: false\n",
      "  episode_len_mean: 86.18103448275862\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.88\n",
      "  episode_reward_mean: 3.9601724137931122\n",
      "  episode_reward_min: -1.6100000000000008\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 2979\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3712122273241354\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015999326070301686\n",
      "          policy_loss: -0.04892850153339215\n",
      "          total_loss: 0.18668069263171946\n",
      "          vf_explained_var: 0.8929296135902405\n",
      "          vf_loss: 0.24312199890040434\n",
      "    num_agent_steps_sampled: 269892\n",
      "    num_agent_steps_trained: 269892\n",
      "    num_steps_sampled: 269892\n",
      "    num_steps_trained: 269892\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.41726315789474\n",
      "    ram_util_percent: 54.30231578947368\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04217794468840878\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.350938868170314\n",
      "    mean_inference_ms: 2.417483599459816\n",
      "    mean_raw_obs_processing_ms: 32.91974083803495\n",
      "  time_since_restore: 7254.77502655983\n",
      "  time_this_iter_s: 333.1970613002777\n",
      "  time_total_s: 7254.77502655983\n",
      "  timers:\n",
      "    learn_throughput: 1057.339\n",
      "    learn_time_ms: 9453.924\n",
      "    load_throughput: 88930.436\n",
      "    load_time_ms: 112.402\n",
      "    sample_throughput: 27.135\n",
      "    sample_time_ms: 368377.714\n",
      "    update_time_ms: 7.183\n",
      "  timestamp: 1636243614\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269892\n",
      "  training_iteration: 27\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         7254.78</td><td style=\"text-align: right;\">269892</td><td style=\"text-align: right;\"> 3.96017</td><td style=\"text-align: right;\">                9.88</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">            86.181</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 279888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_00-13-37\n",
      "  done: false\n",
      "  episode_len_mean: 78.1015625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.89\n",
      "  episode_reward_mean: 4.3266406250000085\n",
      "  episode_reward_min: 0.21999999999999958\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 3107\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3172374552131716\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017695175014674703\n",
      "          policy_loss: -0.05151415873541791\n",
      "          total_loss: 0.22923505681797735\n",
      "          vf_explained_var: 0.8902043104171753\n",
      "          vf_loss: 0.28600522385448474\n",
      "    num_agent_steps_sampled: 279888\n",
      "    num_agent_steps_trained: 279888\n",
      "    num_steps_sampled: 279888\n",
      "    num_steps_trained: 279888\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.42839721254356\n",
      "    ram_util_percent: 54.308885017421595\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04213559330714005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.289975665675563\n",
      "    mean_inference_ms: 2.4154558100607053\n",
      "    mean_raw_obs_processing_ms: 34.44042278047566\n",
      "  time_since_restore: 7657.071808099747\n",
      "  time_this_iter_s: 402.296781539917\n",
      "  time_total_s: 7657.071808099747\n",
      "  timers:\n",
      "    learn_throughput: 1057.549\n",
      "    learn_time_ms: 9452.047\n",
      "    load_throughput: 88965.327\n",
      "    load_time_ms: 112.358\n",
      "    sample_throughput: 27.091\n",
      "    sample_time_ms: 368979.912\n",
      "    update_time_ms: 7.686\n",
      "  timestamp: 1636244017\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279888\n",
      "  training_iteration: 28\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         7657.07</td><td style=\"text-align: right;\">279888</td><td style=\"text-align: right;\"> 4.32664</td><td style=\"text-align: right;\">                9.89</td><td style=\"text-align: right;\">                0.22</td><td style=\"text-align: right;\">           78.1016</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 289884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_00-22-26\n",
      "  done: false\n",
      "  episode_len_mean: 75.93181818181819\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.300000000000017\n",
      "  episode_reward_mean: 4.492954545454554\n",
      "  episode_reward_min: 0.10000000000000009\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 3239\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.308614988714202\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016512230574337317\n",
      "          policy_loss: -0.051402418480979074\n",
      "          total_loss: 0.1891327839694981\n",
      "          vf_explained_var: 0.9079654812812805\n",
      "          vf_loss: 0.24690271742705605\n",
      "    num_agent_steps_sampled: 289884\n",
      "    num_agent_steps_trained: 289884\n",
      "    num_steps_sampled: 289884\n",
      "    num_steps_trained: 289884\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.92503311258278\n",
      "    ram_util_percent: 54.50172185430464\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04215563769286917\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.232135387582257\n",
      "    mean_inference_ms: 2.412562715720298\n",
      "    mean_raw_obs_processing_ms: 36.673945034557185\n",
      "  time_since_restore: 8186.007685422897\n",
      "  time_this_iter_s: 528.9358773231506\n",
      "  time_total_s: 8186.007685422897\n",
      "  timers:\n",
      "    learn_throughput: 1056.827\n",
      "    learn_time_ms: 9458.502\n",
      "    load_throughput: 89514.879\n",
      "    load_time_ms: 111.669\n",
      "    sample_throughput: 26.198\n",
      "    sample_time_ms: 381560.391\n",
      "    update_time_ms: 7.692\n",
      "  timestamp: 1636244546\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289884\n",
      "  training_iteration: 29\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         8186.01</td><td style=\"text-align: right;\">289884</td><td style=\"text-align: right;\"> 4.49295</td><td style=\"text-align: right;\">                10.3</td><td style=\"text-align: right;\">                 0.1</td><td style=\"text-align: right;\">           75.9318</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 299880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_00-29-08\n",
      "  done: false\n",
      "  episode_len_mean: 82.15573770491804\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000019\n",
      "  episode_reward_mean: 4.5969672131147625\n",
      "  episode_reward_min: 0.11999999999999834\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 3361\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3144637847558047\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017945152640642094\n",
      "          policy_loss: -0.046951614374406314\n",
      "          total_loss: 0.23649376154614565\n",
      "          vf_explained_var: 0.9028477072715759\n",
      "          vf_loss: 0.28842054448193977\n",
      "    num_agent_steps_sampled: 299880\n",
      "    num_agent_steps_trained: 299880\n",
      "    num_steps_sampled: 299880\n",
      "    num_steps_trained: 299880\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.59373913043478\n",
      "    ram_util_percent: 54.521043478260864\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04208920635513849\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.178836143061865\n",
      "    mean_inference_ms: 2.4114584429075427\n",
      "    mean_raw_obs_processing_ms: 37.46660163685569\n",
      "  time_since_restore: 8588.819801807404\n",
      "  time_this_iter_s: 402.8121163845062\n",
      "  time_total_s: 8588.819801807404\n",
      "  timers:\n",
      "    learn_throughput: 1057.211\n",
      "    learn_time_ms: 9455.066\n",
      "    load_throughput: 89622.838\n",
      "    load_time_ms: 111.534\n",
      "    sample_throughput: 25.418\n",
      "    sample_time_ms: 393259.45\n",
      "    update_time_ms: 6.821\n",
      "  timestamp: 1636244948\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299880\n",
      "  training_iteration: 30\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         8588.82</td><td style=\"text-align: right;\">299880</td><td style=\"text-align: right;\"> 4.59697</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">                0.12</td><td style=\"text-align: right;\">           82.1557</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 309876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_00-36-00\n",
      "  done: false\n",
      "  episode_len_mean: 85.00847457627118\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.040000000000022\n",
      "  episode_reward_mean: 4.342711864406791\n",
      "  episode_reward_min: -0.17000000000000112\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 3479\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3218603213628133\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01589041217897515\n",
      "          policy_loss: -0.05559979406161568\n",
      "          total_loss: 0.17534259206527827\n",
      "          vf_explained_var: 0.9093758463859558\n",
      "          vf_loss: 0.23807194797465434\n",
      "    num_agent_steps_sampled: 309876\n",
      "    num_agent_steps_trained: 309876\n",
      "    num_steps_sampled: 309876\n",
      "    num_steps_trained: 309876\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.47035775127767\n",
      "    ram_util_percent: 54.71686541737649\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04208477991404552\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.18098194763771\n",
      "    mean_inference_ms: 2.411167204838237\n",
      "    mean_raw_obs_processing_ms: 38.30002433080039\n",
      "  time_since_restore: 9000.470641613007\n",
      "  time_this_iter_s: 411.650839805603\n",
      "  time_total_s: 9000.470641613007\n",
      "  timers:\n",
      "    learn_throughput: 1057.417\n",
      "    learn_time_ms: 9453.227\n",
      "    load_throughput: 89819.081\n",
      "    load_time_ms: 111.29\n",
      "    sample_throughput: 25.631\n",
      "    sample_time_ms: 389995.062\n",
      "    update_time_ms: 7.502\n",
      "  timestamp: 1636245360\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309876\n",
      "  training_iteration: 31\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         9000.47</td><td style=\"text-align: right;\">309876</td><td style=\"text-align: right;\"> 4.34271</td><td style=\"text-align: right;\">               10.04</td><td style=\"text-align: right;\">               -0.17</td><td style=\"text-align: right;\">           85.0085</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 319872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_00-42-09\n",
      "  done: false\n",
      "  episode_len_mean: 83.36974789915966\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.780000000000015\n",
      "  episode_reward_mean: 4.928235294117658\n",
      "  episode_reward_min: 0.16999999999999926\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 3598\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2806643241491074\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0173362067063078\n",
      "          policy_loss: -0.05652891714285072\n",
      "          total_loss: 0.209269319065552\n",
      "          vf_explained_var: 0.9056582450866699\n",
      "          vf_loss: 0.2710519694428668\n",
      "    num_agent_steps_sampled: 319872\n",
      "    num_agent_steps_trained: 319872\n",
      "    num_steps_sampled: 319872\n",
      "    num_steps_trained: 319872\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.01100569259961\n",
      "    ram_util_percent: 54.757685009487666\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04206566968117735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.16691695060392\n",
      "    mean_inference_ms: 2.4102742983392544\n",
      "    mean_raw_obs_processing_ms: 39.17639644335721\n",
      "  time_since_restore: 9369.500179052353\n",
      "  time_this_iter_s: 369.0295374393463\n",
      "  time_total_s: 9369.500179052353\n",
      "  timers:\n",
      "    learn_throughput: 1057.012\n",
      "    learn_time_ms: 9456.846\n",
      "    load_throughput: 89727.064\n",
      "    load_time_ms: 111.405\n",
      "    sample_throughput: 25.367\n",
      "    sample_time_ms: 394057.216\n",
      "    update_time_ms: 7.206\n",
      "  timestamp: 1636245729\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319872\n",
      "  training_iteration: 32\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">          9369.5</td><td style=\"text-align: right;\">319872</td><td style=\"text-align: right;\"> 4.92824</td><td style=\"text-align: right;\">               10.78</td><td style=\"text-align: right;\">                0.17</td><td style=\"text-align: right;\">           83.3697</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 329868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_00-49-29\n",
      "  done: false\n",
      "  episode_len_mean: 78.0625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.46000000000002\n",
      "  episode_reward_mean: 4.827734375000009\n",
      "  episode_reward_min: 0.30000000000000904\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 3726\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2742595540152655\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017808138584914677\n",
      "          policy_loss: -0.053843111287738776\n",
      "          total_loss: 0.2533282441803469\n",
      "          vf_explained_var: 0.8950046896934509\n",
      "          vf_loss: 0.31188320906307454\n",
      "    num_agent_steps_sampled: 329868\n",
      "    num_agent_steps_trained: 329868\n",
      "    num_steps_sampled: 329868\n",
      "    num_steps_trained: 329868\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.88931419457737\n",
      "    ram_util_percent: 54.89856459330144\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04201758654382311\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.081786822283476\n",
      "    mean_inference_ms: 2.4080317542087686\n",
      "    mean_raw_obs_processing_ms: 40.21633572846166\n",
      "  time_since_restore: 9809.1791369915\n",
      "  time_this_iter_s: 439.67895793914795\n",
      "  time_total_s: 9809.1791369915\n",
      "  timers:\n",
      "    learn_throughput: 1057.359\n",
      "    learn_time_ms: 9453.742\n",
      "    load_throughput: 90080.725\n",
      "    load_time_ms: 110.967\n",
      "    sample_throughput: 25.094\n",
      "    sample_time_ms: 398343.146\n",
      "    update_time_ms: 6.979\n",
      "  timestamp: 1636246169\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329868\n",
      "  training_iteration: 33\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         9809.18</td><td style=\"text-align: right;\">329868</td><td style=\"text-align: right;\"> 4.82773</td><td style=\"text-align: right;\">               10.46</td><td style=\"text-align: right;\">                 0.3</td><td style=\"text-align: right;\">           78.0625</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 339864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_00-57-39\n",
      "  done: false\n",
      "  episode_len_mean: 78.11627906976744\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.320000000000023\n",
      "  episode_reward_mean: 4.780232558139544\n",
      "  episode_reward_min: 0.26999999999999913\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 3855\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2763678843139585\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016563441101781533\n",
      "          policy_loss: -0.05722061125322794\n",
      "          total_loss: 0.1898431322330402\n",
      "          vf_explained_var: 0.9277887344360352\n",
      "          vf_loss: 0.2530569352591649\n",
      "    num_agent_steps_sampled: 339864\n",
      "    num_agent_steps_trained: 339864\n",
      "    num_steps_sampled: 339864\n",
      "    num_steps_trained: 339864\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.0927142857143\n",
      "    ram_util_percent: 55.033428571428566\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041979845456983134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.009194483431955\n",
      "    mean_inference_ms: 2.4063333319906532\n",
      "    mean_raw_obs_processing_ms: 41.39374920283347\n",
      "  time_since_restore: 10299.276923418045\n",
      "  time_this_iter_s: 490.0977864265442\n",
      "  time_total_s: 10299.276923418045\n",
      "  timers:\n",
      "    learn_throughput: 1058.03\n",
      "    learn_time_ms: 9447.751\n",
      "    load_throughput: 91299.835\n",
      "    load_time_ms: 109.485\n",
      "    sample_throughput: 24.503\n",
      "    sample_time_ms: 407946.164\n",
      "    update_time_ms: 7.602\n",
      "  timestamp: 1636246659\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 339864\n",
      "  training_iteration: 34\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         10299.3</td><td style=\"text-align: right;\">339864</td><td style=\"text-align: right;\"> 4.78023</td><td style=\"text-align: right;\">               10.32</td><td style=\"text-align: right;\">                0.27</td><td style=\"text-align: right;\">           78.1163</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 349860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_01-04-28\n",
      "  done: false\n",
      "  episode_len_mean: 81.7603305785124\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.720000000000017\n",
      "  episode_reward_mean: 5.05413223140497\n",
      "  episode_reward_min: -1.0299999999999985\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 3976\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2576221572028268\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0180585897738117\n",
      "          policy_loss: -0.05428455516568616\n",
      "          total_loss: 0.1917799477545051\n",
      "          vf_explained_var: 0.9244428873062134\n",
      "          vf_loss: 0.25035640032818685\n",
      "    num_agent_steps_sampled: 349860\n",
      "    num_agent_steps_trained: 349860\n",
      "    num_steps_sampled: 349860\n",
      "    num_steps_trained: 349860\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.23447684391081\n",
      "    ram_util_percent: 55.02607204116639\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04194871002223968\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.932358581751178\n",
      "    mean_inference_ms: 2.404716959681744\n",
      "    mean_raw_obs_processing_ms: 42.34408349779664\n",
      "  time_since_restore: 10707.892981290817\n",
      "  time_this_iter_s: 408.6160578727722\n",
      "  time_total_s: 10707.892981290817\n",
      "  timers:\n",
      "    learn_throughput: 1058.826\n",
      "    learn_time_ms: 9440.645\n",
      "    load_throughput: 91234.848\n",
      "    load_time_ms: 109.563\n",
      "    sample_throughput: 24.293\n",
      "    sample_time_ms: 411473.77\n",
      "    update_time_ms: 8.486\n",
      "  timestamp: 1636247068\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 349860\n",
      "  training_iteration: 35\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         10707.9</td><td style=\"text-align: right;\">349860</td><td style=\"text-align: right;\"> 5.05413</td><td style=\"text-align: right;\">               10.72</td><td style=\"text-align: right;\">               -1.03</td><td style=\"text-align: right;\">           81.7603</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 359856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_01-11-05\n",
      "  done: false\n",
      "  episode_len_mean: 84.65546218487395\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.070000000000023\n",
      "  episode_reward_mean: 4.510084033613457\n",
      "  episode_reward_min: -1.530000000000001\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 4095\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2741868382845167\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01751549159504006\n",
      "          policy_loss: -0.05436535127874878\n",
      "          total_loss: 0.1805545209883115\n",
      "          vf_explained_var: 0.9137751460075378\n",
      "          vf_loss: 0.2399273043928238\n",
      "    num_agent_steps_sampled: 359856\n",
      "    num_agent_steps_trained: 359856\n",
      "    num_steps_sampled: 359856\n",
      "    num_steps_trained: 359856\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.88677248677249\n",
      "    ram_util_percent: 55.27495590828924\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04189811163593993\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.868770833934242\n",
      "    mean_inference_ms: 2.403347521754921\n",
      "    mean_raw_obs_processing_ms: 42.505040096032445\n",
      "  time_since_restore: 11105.389828443527\n",
      "  time_this_iter_s: 397.49684715270996\n",
      "  time_total_s: 11105.389828443527\n",
      "  timers:\n",
      "    learn_throughput: 1058.852\n",
      "    learn_time_ms: 9440.414\n",
      "    load_throughput: 91357.409\n",
      "    load_time_ms: 109.416\n",
      "    sample_throughput: 24.451\n",
      "    sample_time_ms: 408810.728\n",
      "    update_time_ms: 8.316\n",
      "  timestamp: 1636247465\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 359856\n",
      "  training_iteration: 36\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         11105.4</td><td style=\"text-align: right;\">359856</td><td style=\"text-align: right;\"> 4.51008</td><td style=\"text-align: right;\">               12.07</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">           84.6555</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 369852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_01-17-51\n",
      "  done: false\n",
      "  episode_len_mean: 82.24793388429752\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.860000000000012\n",
      "  episode_reward_mean: 4.7206611570248045\n",
      "  episode_reward_min: 0.12000000000000476\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 4216\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2612816981780224\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016862576518122393\n",
      "          policy_loss: -0.05547959861369469\n",
      "          total_loss: 0.16241388307629614\n",
      "          vf_explained_var: 0.9258328676223755\n",
      "          vf_loss: 0.22343293997880995\n",
      "    num_agent_steps_sampled: 369852\n",
      "    num_agent_steps_trained: 369852\n",
      "    num_steps_sampled: 369852\n",
      "    num_steps_trained: 369852\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.95146804835925\n",
      "    ram_util_percent: 55.33056994818652\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041874536254375594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.881345047583235\n",
      "    mean_inference_ms: 2.4026646967062417\n",
      "    mean_raw_obs_processing_ms: 43.02237608431349\n",
      "  time_since_restore: 11511.092204332352\n",
      "  time_this_iter_s: 405.70237588882446\n",
      "  time_total_s: 11511.092204332352\n",
      "  timers:\n",
      "    learn_throughput: 1057.993\n",
      "    learn_time_ms: 9448.079\n",
      "    load_throughput: 91376.643\n",
      "    load_time_ms: 109.393\n",
      "    sample_throughput: 24.026\n",
      "    sample_time_ms: 416053.644\n",
      "    update_time_ms: 8.069\n",
      "  timestamp: 1636247871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 369852\n",
      "  training_iteration: 37\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         11511.1</td><td style=\"text-align: right;\">369852</td><td style=\"text-align: right;\"> 4.72066</td><td style=\"text-align: right;\">               12.86</td><td style=\"text-align: right;\">                0.12</td><td style=\"text-align: right;\">           82.2479</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 379848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_01-24-38\n",
      "  done: false\n",
      "  episode_len_mean: 80.264\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.55000000000002\n",
      "  episode_reward_mean: 5.499760000000011\n",
      "  episode_reward_min: 0.5700000000000033\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 4341\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.223712661836901\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01855090029423235\n",
      "          policy_loss: -0.05586306244357783\n",
      "          total_loss: 0.21061393776828916\n",
      "          vf_explained_var: 0.9262011647224426\n",
      "          vf_loss: 0.2699313397813811\n",
      "    num_agent_steps_sampled: 379848\n",
      "    num_agent_steps_trained: 379848\n",
      "    num_steps_sampled: 379848\n",
      "    num_steps_trained: 379848\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.34956970740103\n",
      "    ram_util_percent: 55.278485370051634\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041843716006873755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.828235959961905\n",
      "    mean_inference_ms: 2.4015930880652294\n",
      "    mean_raw_obs_processing_ms: 43.74627933282113\n",
      "  time_since_restore: 11918.236621379852\n",
      "  time_this_iter_s: 407.1444170475006\n",
      "  time_total_s: 11918.236621379852\n",
      "  timers:\n",
      "    learn_throughput: 1056.656\n",
      "    learn_time_ms: 9460.029\n",
      "    load_throughput: 91401.743\n",
      "    load_time_ms: 109.363\n",
      "    sample_throughput: 23.999\n",
      "    sample_time_ms: 416525.912\n",
      "    update_time_ms: 8.397\n",
      "  timestamp: 1636248278\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 379848\n",
      "  training_iteration: 38\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         11918.2</td><td style=\"text-align: right;\">379848</td><td style=\"text-align: right;\"> 5.49976</td><td style=\"text-align: right;\">               12.55</td><td style=\"text-align: right;\">                0.57</td><td style=\"text-align: right;\">            80.264</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 389844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_01-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 78.1259842519685\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.010000000000021\n",
      "  episode_reward_mean: 5.283622047244105\n",
      "  episode_reward_min: 0.2699999999999989\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 4468\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.232018192812928\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01771654079742359\n",
      "          policy_loss: -0.06035850683274942\n",
      "          total_loss: 0.16173392571986486\n",
      "          vf_explained_var: 0.9261177182197571\n",
      "          vf_loss: 0.226474614517811\n",
      "    num_agent_steps_sampled: 389844\n",
      "    num_agent_steps_trained: 389844\n",
      "    num_steps_sampled: 389844\n",
      "    num_steps_trained: 389844\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.98596802841918\n",
      "    ram_util_percent: 55.20142095914743\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041814770794778855\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.83177961553639\n",
      "    mean_inference_ms: 2.400379459189329\n",
      "    mean_raw_obs_processing_ms: 44.47226817756777\n",
      "  time_since_restore: 12312.793919801712\n",
      "  time_this_iter_s: 394.55729842185974\n",
      "  time_total_s: 12312.793919801712\n",
      "  timers:\n",
      "    learn_throughput: 1057.34\n",
      "    learn_time_ms: 9453.91\n",
      "    load_throughput: 90845.011\n",
      "    load_time_ms: 110.034\n",
      "    sample_throughput: 24.798\n",
      "    sample_time_ms: 403093.268\n",
      "    update_time_ms: 8.573\n",
      "  timestamp: 1636248673\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 389844\n",
      "  training_iteration: 39\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         12312.8</td><td style=\"text-align: right;\">389844</td><td style=\"text-align: right;\"> 5.28362</td><td style=\"text-align: right;\">               12.01</td><td style=\"text-align: right;\">                0.27</td><td style=\"text-align: right;\">            78.126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 399840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_01-38-41\n",
      "  done: false\n",
      "  episode_len_mean: 81.0725806451613\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.64000000000002\n",
      "  episode_reward_mean: 4.866612903225817\n",
      "  episode_reward_min: 0.02999999999999889\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 4592\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.218476415088034\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017592417102627433\n",
      "          policy_loss: -0.0565326711592766\n",
      "          total_loss: 0.17512658311643153\n",
      "          vf_explained_var: 0.9150434732437134\n",
      "          vf_loss: 0.23603169456060624\n",
      "    num_agent_steps_sampled: 399840\n",
      "    num_agent_steps_trained: 399840\n",
      "    num_steps_sampled: 399840\n",
      "    num_steps_trained: 399840\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.3849765258216\n",
      "    ram_util_percent: 55.470579029733955\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041795309973948674\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.82974920053594\n",
      "    mean_inference_ms: 2.398559215298562\n",
      "    mean_raw_obs_processing_ms: 45.05188194635191\n",
      "  time_since_restore: 12760.825524568558\n",
      "  time_this_iter_s: 448.0316047668457\n",
      "  time_total_s: 12760.825524568558\n",
      "  timers:\n",
      "    learn_throughput: 1057.184\n",
      "    learn_time_ms: 9455.305\n",
      "    load_throughput: 90882.663\n",
      "    load_time_ms: 109.988\n",
      "    sample_throughput: 24.523\n",
      "    sample_time_ms: 407612.45\n",
      "    update_time_ms: 9.987\n",
      "  timestamp: 1636249121\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 399840\n",
      "  training_iteration: 40\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         12760.8</td><td style=\"text-align: right;\">399840</td><td style=\"text-align: right;\"> 4.86661</td><td style=\"text-align: right;\">               10.64</td><td style=\"text-align: right;\">                0.03</td><td style=\"text-align: right;\">           81.0726</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 409836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_01-45-08\n",
      "  done: false\n",
      "  episode_len_mean: 79.76984126984127\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.95000000000002\n",
      "  episode_reward_mean: 4.837142857142868\n",
      "  episode_reward_min: -0.2000000000000011\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 4718\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2359801929221192\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016918436235298342\n",
      "          policy_loss: -0.06032231456289689\n",
      "          total_loss: 0.16498443071658794\n",
      "          vf_explained_var: 0.9176260232925415\n",
      "          vf_loss: 0.2305366295365951\n",
      "    num_agent_steps_sampled: 409836\n",
      "    num_agent_steps_trained: 409836\n",
      "    num_steps_sampled: 409836\n",
      "    num_steps_trained: 409836\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.74376130198915\n",
      "    ram_util_percent: 55.3878842676311\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04176397758456378\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.8417391586328\n",
      "    mean_inference_ms: 2.398751298769788\n",
      "    mean_raw_obs_processing_ms: 45.40543734226893\n",
      "  time_since_restore: 13148.343115568161\n",
      "  time_this_iter_s: 387.51759099960327\n",
      "  time_total_s: 13148.343115568161\n",
      "  timers:\n",
      "    learn_throughput: 1056.875\n",
      "    learn_time_ms: 9458.07\n",
      "    load_throughput: 90841.193\n",
      "    load_time_ms: 110.038\n",
      "    sample_throughput: 24.67\n",
      "    sample_time_ms: 405196.215\n",
      "    update_time_ms: 9.852\n",
      "  timestamp: 1636249508\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 409836\n",
      "  training_iteration: 41\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         13148.3</td><td style=\"text-align: right;\">409836</td><td style=\"text-align: right;\"> 4.83714</td><td style=\"text-align: right;\">               11.95</td><td style=\"text-align: right;\">                -0.2</td><td style=\"text-align: right;\">           79.7698</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 419832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_01-52-28\n",
      "  done: false\n",
      "  episode_len_mean: 75.1590909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.120000000000013\n",
      "  episode_reward_mean: 5.256212121212131\n",
      "  episode_reward_min: 0.3599999999999989\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 4850\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.198389208214915\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018651370108059\n",
      "          policy_loss: -0.05625665997847533\n",
      "          total_loss: 0.1738084363997874\n",
      "          vf_explained_var: 0.929084062576294\n",
      "          vf_loss: 0.23316447551433855\n",
      "    num_agent_steps_sampled: 419832\n",
      "    num_agent_steps_trained: 419832\n",
      "    num_steps_sampled: 419832\n",
      "    num_steps_trained: 419832\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.35837320574163\n",
      "    ram_util_percent: 55.47862838915469\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041748982171480584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.897858377925218\n",
      "    mean_inference_ms: 2.3980017649062333\n",
      "    mean_raw_obs_processing_ms: 46.08558742621175\n",
      "  time_since_restore: 13587.775024175644\n",
      "  time_this_iter_s: 439.4319086074829\n",
      "  time_total_s: 13587.775024175644\n",
      "  timers:\n",
      "    learn_throughput: 1057.159\n",
      "    learn_time_ms: 9455.534\n",
      "    load_throughput: 90685.947\n",
      "    load_time_ms: 110.227\n",
      "    sample_throughput: 24.248\n",
      "    sample_time_ms: 412239.5\n",
      "    update_time_ms: 9.494\n",
      "  timestamp: 1636249948\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 419832\n",
      "  training_iteration: 42\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         13587.8</td><td style=\"text-align: right;\">419832</td><td style=\"text-align: right;\"> 5.25621</td><td style=\"text-align: right;\">               13.12</td><td style=\"text-align: right;\">                0.36</td><td style=\"text-align: right;\">           75.1591</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 429828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_02-01-02\n",
      "  done: false\n",
      "  episode_len_mean: 73.74264705882354\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.070000000000023\n",
      "  episode_reward_mean: 5.6569117647058915\n",
      "  episode_reward_min: 0.35000000000000064\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 4986\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1817500832753303\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019941017957862444\n",
      "          policy_loss: -0.05459857750206422\n",
      "          total_loss: 0.21031253687305074\n",
      "          vf_explained_var: 0.924432098865509\n",
      "          vf_loss: 0.26653833327512455\n",
      "    num_agent_steps_sampled: 429828\n",
      "    num_agent_steps_trained: 429828\n",
      "    num_steps_sampled: 429828\n",
      "    num_steps_trained: 429828\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.98079019073569\n",
      "    ram_util_percent: 55.50313351498638\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04173386724145495\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.891651384963726\n",
      "    mean_inference_ms: 2.3982547314456943\n",
      "    mean_raw_obs_processing_ms: 46.81975581158041\n",
      "  time_since_restore: 14101.905185699463\n",
      "  time_this_iter_s: 514.130161523819\n",
      "  time_total_s: 14101.905185699463\n",
      "  timers:\n",
      "    learn_throughput: 1056.796\n",
      "    learn_time_ms: 9458.775\n",
      "    load_throughput: 90894.721\n",
      "    load_time_ms: 109.973\n",
      "    sample_throughput: 23.818\n",
      "    sample_time_ms: 419681.421\n",
      "    update_time_ms: 9.867\n",
      "  timestamp: 1636250462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 429828\n",
      "  training_iteration: 43\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         14101.9</td><td style=\"text-align: right;\">429828</td><td style=\"text-align: right;\"> 5.65691</td><td style=\"text-align: right;\">               12.07</td><td style=\"text-align: right;\">                0.35</td><td style=\"text-align: right;\">           73.7426</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 439824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_02-08-07\n",
      "  done: false\n",
      "  episode_len_mean: 75.08208955223881\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.86000000000002\n",
      "  episode_reward_mean: 5.253432835820906\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 5120\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.188707156874176\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016769512826769153\n",
      "          policy_loss: -0.05890241562524158\n",
      "          total_loss: 0.14853591298222796\n",
      "          vf_explained_var: 0.9375755190849304\n",
      "          vf_loss: 0.2123462670060814\n",
      "    num_agent_steps_sampled: 439824\n",
      "    num_agent_steps_trained: 439824\n",
      "    num_steps_sampled: 439824\n",
      "    num_steps_trained: 439824\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.41848184818481\n",
      "    ram_util_percent: 55.53465346534654\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04172597827203625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.916093621039366\n",
      "    mean_inference_ms: 2.397497369173494\n",
      "    mean_raw_obs_processing_ms: 47.51169143170532\n",
      "  time_since_restore: 14526.691929101944\n",
      "  time_this_iter_s: 424.7867434024811\n",
      "  time_total_s: 14526.691929101944\n",
      "  timers:\n",
      "    learn_throughput: 1057.005\n",
      "    learn_time_ms: 9456.909\n",
      "    load_throughput: 90653.104\n",
      "    load_time_ms: 110.266\n",
      "    sample_throughput: 24.195\n",
      "    sample_time_ms: 413151.711\n",
      "    update_time_ms: 10.24\n",
      "  timestamp: 1636250887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 439824\n",
      "  training_iteration: 44\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         14526.7</td><td style=\"text-align: right;\">439824</td><td style=\"text-align: right;\"> 5.25343</td><td style=\"text-align: right;\">               11.86</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           75.0821</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 449820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_02-16-31\n",
      "  done: false\n",
      "  episode_len_mean: 75.91472868217055\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.910000000000021\n",
      "  episode_reward_mean: 5.163100775193809\n",
      "  episode_reward_min: 0.22999999999999896\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 5249\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1766435366410475\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018786932462139694\n",
      "          policy_loss: -0.05711398767944202\n",
      "          total_loss: 0.18857668915795336\n",
      "          vf_explained_var: 0.9247210025787354\n",
      "          vf_loss: 0.24843534149038485\n",
      "    num_agent_steps_sampled: 449820\n",
      "    num_agent_steps_trained: 449820\n",
      "    num_steps_sampled: 449820\n",
      "    num_steps_trained: 449820\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.75611111111111\n",
      "    ram_util_percent: 55.76208333333333\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041685017916954996\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.907014056628615\n",
      "    mean_inference_ms: 2.396391439179709\n",
      "    mean_raw_obs_processing_ms: 48.05896743884425\n",
      "  time_since_restore: 15031.183537483215\n",
      "  time_this_iter_s: 504.49160838127136\n",
      "  time_total_s: 15031.183537483215\n",
      "  timers:\n",
      "    learn_throughput: 1056.773\n",
      "    learn_time_ms: 9458.989\n",
      "    load_throughput: 90890.997\n",
      "    load_time_ms: 109.978\n",
      "    sample_throughput: 23.646\n",
      "    sample_time_ms: 422738.406\n",
      "    update_time_ms: 9.234\n",
      "  timestamp: 1636251391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 449820\n",
      "  training_iteration: 45\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         15031.2</td><td style=\"text-align: right;\">449820</td><td style=\"text-align: right;\">  5.1631</td><td style=\"text-align: right;\">               11.91</td><td style=\"text-align: right;\">                0.23</td><td style=\"text-align: right;\">           75.9147</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 459816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_02-25-34\n",
      "  done: false\n",
      "  episode_len_mean: 68.66666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.070000000000013\n",
      "  episode_reward_mean: 5.677891156462594\n",
      "  episode_reward_min: 0.3599999999999991\n",
      "  episodes_this_iter: 147\n",
      "  episodes_total: 5396\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1379926694764033\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017963978835499658\n",
      "          policy_loss: -0.05780736955089701\n",
      "          total_loss: 0.1855272352257664\n",
      "          vf_explained_var: 0.9402636885643005\n",
      "          vf_loss: 0.2465260014988673\n",
      "    num_agent_steps_sampled: 459816\n",
      "    num_agent_steps_trained: 459816\n",
      "    num_steps_sampled: 459816\n",
      "    num_steps_trained: 459816\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.54431524547803\n",
      "    ram_util_percent: 55.62299741602067\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04167309115261905\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.928641404280434\n",
      "    mean_inference_ms: 2.395645788639179\n",
      "    mean_raw_obs_processing_ms: 49.33083740046981\n",
      "  time_since_restore: 15573.649857759476\n",
      "  time_this_iter_s: 542.4663202762604\n",
      "  time_total_s: 15573.649857759476\n",
      "  timers:\n",
      "    learn_throughput: 1056.984\n",
      "    learn_time_ms: 9457.096\n",
      "    load_throughput: 90990.0\n",
      "    load_time_ms: 109.858\n",
      "    sample_throughput: 22.862\n",
      "    sample_time_ms: 437236.549\n",
      "    update_time_ms: 10.089\n",
      "  timestamp: 1636251934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 459816\n",
      "  training_iteration: 46\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         15573.6</td><td style=\"text-align: right;\">459816</td><td style=\"text-align: right;\"> 5.67789</td><td style=\"text-align: right;\">               13.07</td><td style=\"text-align: right;\">                0.36</td><td style=\"text-align: right;\">           68.6667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 469812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_02-32-53\n",
      "  done: false\n",
      "  episode_len_mean: 74.78358208955224\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.32000000000002\n",
      "  episode_reward_mean: 4.88768656716419\n",
      "  episode_reward_min: 0.6099999999999998\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 5530\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.206125971598503\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016196799383156296\n",
      "          policy_loss: -0.06281006268551971\n",
      "          total_loss: 0.12652334021006384\n",
      "          vf_explained_var: 0.938781201839447\n",
      "          vf_loss: 0.1949954021562878\n",
      "    num_agent_steps_sampled: 469812\n",
      "    num_agent_steps_trained: 469812\n",
      "    num_steps_sampled: 469812\n",
      "    num_steps_trained: 469812\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.79968102073366\n",
      "    ram_util_percent: 55.91626794258373\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041638580547442\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.931522770352473\n",
      "    mean_inference_ms: 2.394072974408275\n",
      "    mean_raw_obs_processing_ms: 50.03288455536688\n",
      "  time_since_restore: 16013.01853609085\n",
      "  time_this_iter_s: 439.3686783313751\n",
      "  time_total_s: 16013.01853609085\n",
      "  timers:\n",
      "    learn_throughput: 1057.403\n",
      "    learn_time_ms: 9453.346\n",
      "    load_throughput: 91098.283\n",
      "    load_time_ms: 109.728\n",
      "    sample_throughput: 22.687\n",
      "    sample_time_ms: 440605.936\n",
      "    update_time_ms: 11.334\n",
      "  timestamp: 1636252373\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 469812\n",
      "  training_iteration: 47\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">           16013</td><td style=\"text-align: right;\">469812</td><td style=\"text-align: right;\"> 4.88769</td><td style=\"text-align: right;\">               12.32</td><td style=\"text-align: right;\">                0.61</td><td style=\"text-align: right;\">           74.7836</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 479808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_02-42-06\n",
      "  done: false\n",
      "  episode_len_mean: 71.00714285714285\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.020000000000012\n",
      "  episode_reward_mean: 5.862785714285724\n",
      "  episode_reward_min: 0.34000000000000186\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 5670\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1313935042446497\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018530758908821852\n",
      "          policy_loss: -0.05709982999942751\n",
      "          total_loss: 0.20476613521066486\n",
      "          vf_explained_var: 0.9411544799804688\n",
      "          vf_loss: 0.2644175054553228\n",
      "    num_agent_steps_sampled: 479808\n",
      "    num_agent_steps_trained: 479808\n",
      "    num_steps_sampled: 479808\n",
      "    num_steps_trained: 479808\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.59962025316456\n",
      "    ram_util_percent: 55.96354430379748\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0415983733991977\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.92174886252135\n",
      "    mean_inference_ms: 2.3931397381870254\n",
      "    mean_raw_obs_processing_ms: 50.926768101687045\n",
      "  time_since_restore: 16566.30420923233\n",
      "  time_this_iter_s: 553.2856731414795\n",
      "  time_total_s: 16566.30420923233\n",
      "  timers:\n",
      "    learn_throughput: 1058.848\n",
      "    learn_time_ms: 9440.449\n",
      "    load_throughput: 90967.612\n",
      "    load_time_ms: 109.885\n",
      "    sample_throughput: 21.958\n",
      "    sample_time_ms: 455233.803\n",
      "    update_time_ms: 10.519\n",
      "  timestamp: 1636252926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 479808\n",
      "  training_iteration: 48\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         16566.3</td><td style=\"text-align: right;\">479808</td><td style=\"text-align: right;\"> 5.86279</td><td style=\"text-align: right;\">               13.02</td><td style=\"text-align: right;\">                0.34</td><td style=\"text-align: right;\">           71.0071</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 489804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_02-49-44\n",
      "  done: false\n",
      "  episode_len_mean: 73.28467153284672\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.060000000000015\n",
      "  episode_reward_mean: 5.442627737226286\n",
      "  episode_reward_min: 0.520000000000001\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 5807\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1557112091626878\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018542158807555446\n",
      "          policy_loss: -0.05727011611064275\n",
      "          total_loss: 0.20070196683239988\n",
      "          vf_explained_var: 0.9295142889022827\n",
      "          vf_loss: 0.26075525741355543\n",
      "    num_agent_steps_sampled: 489804\n",
      "    num_agent_steps_trained: 489804\n",
      "    num_steps_sampled: 489804\n",
      "    num_steps_trained: 489804\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.9446319018405\n",
      "    ram_util_percent: 56.115490797546016\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04160674392970118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.92878141075692\n",
      "    mean_inference_ms: 2.39286326790965\n",
      "    mean_raw_obs_processing_ms: 51.55577549299457\n",
      "  time_since_restore: 17023.641102313995\n",
      "  time_this_iter_s: 457.33689308166504\n",
      "  time_total_s: 17023.641102313995\n",
      "  timers:\n",
      "    learn_throughput: 1058.7\n",
      "    learn_time_ms: 9441.772\n",
      "    load_throughput: 90937.562\n",
      "    load_time_ms: 109.922\n",
      "    sample_throughput: 21.659\n",
      "    sample_time_ms: 461510.794\n",
      "    update_time_ms: 10.009\n",
      "  timestamp: 1636253384\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 489804\n",
      "  training_iteration: 49\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         17023.6</td><td style=\"text-align: right;\">489804</td><td style=\"text-align: right;\"> 5.44263</td><td style=\"text-align: right;\">               13.06</td><td style=\"text-align: right;\">                0.52</td><td style=\"text-align: right;\">           73.2847</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 499800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_02-57-56\n",
      "  done: false\n",
      "  episode_len_mean: 72.6231884057971\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.090000000000012\n",
      "  episode_reward_mean: 5.495217391304357\n",
      "  episode_reward_min: 0.4499999999999993\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 5945\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.123642136398544\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02002683255329158\n",
      "          policy_loss: -0.05435470100173838\n",
      "          total_loss: 0.2584059531084047\n",
      "          vf_explained_var: 0.9274259805679321\n",
      "          vf_loss: 0.313719906578334\n",
      "    num_agent_steps_sampled: 499800\n",
      "    num_agent_steps_trained: 499800\n",
      "    num_steps_sampled: 499800\n",
      "    num_steps_trained: 499800\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.58378378378379\n",
      "    ram_util_percent: 56.38122332859175\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04158668920723714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.96197876047785\n",
      "    mean_inference_ms: 2.3919953041396815\n",
      "    mean_raw_obs_processing_ms: 52.133184624003825\n",
      "  time_since_restore: 17516.22681927681\n",
      "  time_this_iter_s: 492.58571696281433\n",
      "  time_total_s: 17516.22681927681\n",
      "  timers:\n",
      "    learn_throughput: 1058.745\n",
      "    learn_time_ms: 9441.366\n",
      "    load_throughput: 91495.192\n",
      "    load_time_ms: 109.252\n",
      "    sample_throughput: 21.452\n",
      "    sample_time_ms: 465968.411\n",
      "    update_time_ms: 8.724\n",
      "  timestamp: 1636253876\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 499800\n",
      "  training_iteration: 50\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         17516.2</td><td style=\"text-align: right;\">499800</td><td style=\"text-align: right;\"> 5.49522</td><td style=\"text-align: right;\">               13.09</td><td style=\"text-align: right;\">                0.45</td><td style=\"text-align: right;\">           72.6232</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 509796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_03-05-24\n",
      "  done: false\n",
      "  episode_len_mean: 75.59398496240601\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.98000000000002\n",
      "  episode_reward_mean: 5.302556390977452\n",
      "  episode_reward_min: 9.246076126956382e-16\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 6078\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.184232100360414\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013720731648978043\n",
      "          policy_loss: -0.05756957553223603\n",
      "          total_loss: 0.17248690475064973\n",
      "          vf_explained_var: 0.9402358531951904\n",
      "          vf_loss: 0.23106044084470495\n",
      "    num_agent_steps_sampled: 509796\n",
      "    num_agent_steps_trained: 509796\n",
      "    num_steps_sampled: 509796\n",
      "    num_steps_trained: 509796\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.10438184663536\n",
      "    ram_util_percent: 56.49906103286384\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04157007757157422\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.969954500231797\n",
      "    mean_inference_ms: 2.3915005923893045\n",
      "    mean_raw_obs_processing_ms: 52.68699045940298\n",
      "  time_since_restore: 17963.8025329113\n",
      "  time_this_iter_s: 447.57571363449097\n",
      "  time_total_s: 17963.8025329113\n",
      "  timers:\n",
      "    learn_throughput: 1058.541\n",
      "    learn_time_ms: 9443.187\n",
      "    load_throughput: 91285.92\n",
      "    load_time_ms: 109.502\n",
      "    sample_throughput: 21.179\n",
      "    sample_time_ms: 471972.157\n",
      "    update_time_ms: 8.557\n",
      "  timestamp: 1636254324\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 509796\n",
      "  training_iteration: 51\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         17963.8</td><td style=\"text-align: right;\">509796</td><td style=\"text-align: right;\"> 5.30256</td><td style=\"text-align: right;\">               11.98</td><td style=\"text-align: right;\">         9.24608e-16</td><td style=\"text-align: right;\">            75.594</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 519792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_03-12-57\n",
      "  done: false\n",
      "  episode_len_mean: 74.62406015037594\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.990000000000013\n",
      "  episode_reward_mean: 5.658195488721813\n",
      "  episode_reward_min: 0.29999999999999905\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 6211\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.147796976770091\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015107283735260758\n",
      "          policy_loss: -0.060471870410295885\n",
      "          total_loss: 0.1546619632615684\n",
      "          vf_explained_var: 0.9434837698936462\n",
      "          vf_loss: 0.21366761673210014\n",
      "    num_agent_steps_sampled: 519792\n",
      "    num_agent_steps_trained: 519792\n",
      "    num_steps_sampled: 519792\n",
      "    num_steps_trained: 519792\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.3577399380805\n",
      "    ram_util_percent: 56.48606811145511\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04155421185325589\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.990332374089544\n",
      "    mean_inference_ms: 2.391259332258545\n",
      "    mean_raw_obs_processing_ms: 52.900674501570876\n",
      "  time_since_restore: 18416.320941209793\n",
      "  time_this_iter_s: 452.51840829849243\n",
      "  time_total_s: 18416.320941209793\n",
      "  timers:\n",
      "    learn_throughput: 1058.182\n",
      "    learn_time_ms: 9446.389\n",
      "    load_throughput: 91527.95\n",
      "    load_time_ms: 109.213\n",
      "    sample_throughput: 21.121\n",
      "    sample_time_ms: 473277.63\n",
      "    update_time_ms: 8.738\n",
      "  timestamp: 1636254777\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 519792\n",
      "  training_iteration: 52\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         18416.3</td><td style=\"text-align: right;\">519792</td><td style=\"text-align: right;\">  5.6582</td><td style=\"text-align: right;\">               12.99</td><td style=\"text-align: right;\">                 0.3</td><td style=\"text-align: right;\">           74.6241</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 529788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_03-20-24\n",
      "  done: false\n",
      "  episode_len_mean: 73.55474452554745\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.880000000000015\n",
      "  episode_reward_mean: 5.5215328467153375\n",
      "  episode_reward_min: -0.1300000000000011\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 6348\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1543233970291595\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01495507324912447\n",
      "          policy_loss: -0.05854102731960961\n",
      "          total_loss: 0.184578550245581\n",
      "          vf_explained_var: 0.9299817085266113\n",
      "          vf_loss: 0.24194979367729946\n",
      "    num_agent_steps_sampled: 529788\n",
      "    num_agent_steps_trained: 529788\n",
      "    num_steps_sampled: 529788\n",
      "    num_steps_trained: 529788\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.70454545454545\n",
      "    ram_util_percent: 56.47100313479624\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04155066120609809\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.071541185267947\n",
      "    mean_inference_ms: 2.390925078056746\n",
      "    mean_raw_obs_processing_ms: 53.39516083178618\n",
      "  time_since_restore: 18863.786553621292\n",
      "  time_this_iter_s: 447.465612411499\n",
      "  time_total_s: 18863.786553621292\n",
      "  timers:\n",
      "    learn_throughput: 1058.531\n",
      "    learn_time_ms: 9443.276\n",
      "    load_throughput: 91225.339\n",
      "    load_time_ms: 109.575\n",
      "    sample_throughput: 21.422\n",
      "    sample_time_ms: 466614.125\n",
      "    update_time_ms: 8.694\n",
      "  timestamp: 1636255224\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 529788\n",
      "  training_iteration: 53\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         18863.8</td><td style=\"text-align: right;\">529788</td><td style=\"text-align: right;\"> 5.52153</td><td style=\"text-align: right;\">               12.88</td><td style=\"text-align: right;\">               -0.13</td><td style=\"text-align: right;\">           73.5547</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 539784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_03-29-16\n",
      "  done: false\n",
      "  episode_len_mean: 70.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.920000000000014\n",
      "  episode_reward_mean: 5.888156028368804\n",
      "  episode_reward_min: 0.41999999999999915\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 6489\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1293531532980436\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014746773751911083\n",
      "          policy_loss: -0.05581888242935141\n",
      "          total_loss: 0.19435993493335624\n",
      "          vf_explained_var: 0.9347234964370728\n",
      "          vf_loss: 0.24907568621520812\n",
      "    num_agent_steps_sampled: 539784\n",
      "    num_agent_steps_trained: 539784\n",
      "    num_steps_sampled: 539784\n",
      "    num_steps_trained: 539784\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.60645586297761\n",
      "    ram_util_percent: 56.5862977602108\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04152594492194693\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.075314371196193\n",
      "    mean_inference_ms: 2.38992438773789\n",
      "    mean_raw_obs_processing_ms: 54.23934445219801\n",
      "  time_since_restore: 19395.255910634995\n",
      "  time_this_iter_s: 531.4693570137024\n",
      "  time_total_s: 19395.255910634995\n",
      "  timers:\n",
      "    learn_throughput: 1057.752\n",
      "    learn_time_ms: 9450.228\n",
      "    load_throughput: 91331.378\n",
      "    load_time_ms: 109.448\n",
      "    sample_throughput: 20.944\n",
      "    sample_time_ms: 477276.409\n",
      "    update_time_ms: 7.629\n",
      "  timestamp: 1636255756\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 539784\n",
      "  training_iteration: 54\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         19395.3</td><td style=\"text-align: right;\">539784</td><td style=\"text-align: right;\"> 5.88816</td><td style=\"text-align: right;\">               12.92</td><td style=\"text-align: right;\">                0.42</td><td style=\"text-align: right;\">                70</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 549780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_03-37-18\n",
      "  done: false\n",
      "  episode_len_mean: 74.15441176470588\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.030000000000014\n",
      "  episode_reward_mean: 5.426838235294127\n",
      "  episode_reward_min: -1.0799999999999996\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 6625\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1824990317352815\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015149984567977462\n",
      "          policy_loss: -0.05730666191452462\n",
      "          total_loss: 0.20101420485900126\n",
      "          vf_explained_var: 0.9329208135604858\n",
      "          vf_loss: 0.25713681807248\n",
      "    num_agent_steps_sampled: 549780\n",
      "    num_agent_steps_trained: 549780\n",
      "    num_steps_sampled: 549780\n",
      "    num_steps_trained: 549780\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.71146589259796\n",
      "    ram_util_percent: 56.74804063860668\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04149874296684615\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.085913188627064\n",
      "    mean_inference_ms: 2.390174495685024\n",
      "    mean_raw_obs_processing_ms: 54.26322449811543\n",
      "  time_since_restore: 19878.068474531174\n",
      "  time_this_iter_s: 482.8125638961792\n",
      "  time_total_s: 19878.068474531174\n",
      "  timers:\n",
      "    learn_throughput: 1057.702\n",
      "    learn_time_ms: 9450.677\n",
      "    load_throughput: 91249.602\n",
      "    load_time_ms: 109.546\n",
      "    sample_throughput: 21.039\n",
      "    sample_time_ms: 475108.269\n",
      "    update_time_ms: 7.754\n",
      "  timestamp: 1636256238\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 549780\n",
      "  training_iteration: 55\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         19878.1</td><td style=\"text-align: right;\">549780</td><td style=\"text-align: right;\"> 5.42684</td><td style=\"text-align: right;\">               13.03</td><td style=\"text-align: right;\">               -1.08</td><td style=\"text-align: right;\">           74.1544</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 559776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_03-47-59\n",
      "  done: false\n",
      "  episode_len_mean: 64.89542483660131\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.070000000000013\n",
      "  episode_reward_mean: 5.716993464052296\n",
      "  episode_reward_min: 0.39999999999999913\n",
      "  episodes_this_iter: 153\n",
      "  episodes_total: 6778\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1170341002635467\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012630008153233814\n",
      "          policy_loss: -0.05912718756410938\n",
      "          total_loss: 0.10910919333020082\n",
      "          vf_explained_var: 0.9582887887954712\n",
      "          vf_loss: 0.17022489583931671\n",
      "    num_agent_steps_sampled: 559776\n",
      "    num_agent_steps_trained: 559776\n",
      "    num_steps_sampled: 559776\n",
      "    num_steps_trained: 559776\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.02800875273523\n",
      "    ram_util_percent: 56.782056892778996\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041474139368838356\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.114802983027683\n",
      "    mean_inference_ms: 2.38984384742906\n",
      "    mean_raw_obs_processing_ms: 55.3724571592418\n",
      "  time_since_restore: 20518.60205388069\n",
      "  time_this_iter_s: 640.5335793495178\n",
      "  time_total_s: 20518.60205388069\n",
      "  timers:\n",
      "    learn_throughput: 1057.225\n",
      "    learn_time_ms: 9454.942\n",
      "    load_throughput: 91143.356\n",
      "    load_time_ms: 109.673\n",
      "    sample_throughput: 20.614\n",
      "    sample_time_ms: 484911.206\n",
      "    update_time_ms: 7.069\n",
      "  timestamp: 1636256879\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 559776\n",
      "  training_iteration: 56\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         20518.6</td><td style=\"text-align: right;\">559776</td><td style=\"text-align: right;\"> 5.71699</td><td style=\"text-align: right;\">               13.07</td><td style=\"text-align: right;\">                 0.4</td><td style=\"text-align: right;\">           64.8954</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 569772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_03-56-20\n",
      "  done: false\n",
      "  episode_len_mean: 72.35507246376811\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.74000000000002\n",
      "  episode_reward_mean: 5.955797101449284\n",
      "  episode_reward_min: 0.5600000000000022\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 6916\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0832734926134093\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01619218702371733\n",
      "          policy_loss: -0.06048015007255678\n",
      "          total_loss: 0.19880340004132854\n",
      "          vf_explained_var: 0.943726658821106\n",
      "          vf_loss: 0.2555244015545672\n",
      "    num_agent_steps_sampled: 569772\n",
      "    num_agent_steps_trained: 569772\n",
      "    num_steps_sampled: 569772\n",
      "    num_steps_trained: 569772\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.15406162464986\n",
      "    ram_util_percent: 56.968347338935565\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04145593066082277\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.13733902977946\n",
      "    mean_inference_ms: 2.389893192432635\n",
      "    mean_raw_obs_processing_ms: 55.61903206216001\n",
      "  time_since_restore: 21019.072385549545\n",
      "  time_this_iter_s: 500.47033166885376\n",
      "  time_total_s: 21019.072385549545\n",
      "  timers:\n",
      "    learn_throughput: 1057.584\n",
      "    learn_time_ms: 9451.731\n",
      "    load_throughput: 91026.013\n",
      "    load_time_ms: 109.815\n",
      "    sample_throughput: 20.357\n",
      "    sample_time_ms: 491024.957\n",
      "    update_time_ms: 6.4\n",
      "  timestamp: 1636257380\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 569772\n",
      "  training_iteration: 57\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         21019.1</td><td style=\"text-align: right;\">569772</td><td style=\"text-align: right;\">  5.9558</td><td style=\"text-align: right;\">               13.74</td><td style=\"text-align: right;\">                0.56</td><td style=\"text-align: right;\">           72.3551</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 579768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_04-03-21\n",
      "  done: false\n",
      "  episode_len_mean: 74.57777777777778\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.020000000000014\n",
      "  episode_reward_mean: 5.8519259259259355\n",
      "  episode_reward_min: 0.4000000000000037\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 7051\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.086603338901813\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015606230455600011\n",
      "          policy_loss: -0.05773399359602322\n",
      "          total_loss: 0.1781271454718951\n",
      "          vf_explained_var: 0.9526033401489258\n",
      "          vf_loss: 0.2330252098858866\n",
      "    num_agent_steps_sampled: 579768\n",
      "    num_agent_steps_trained: 579768\n",
      "    num_steps_sampled: 579768\n",
      "    num_steps_trained: 579768\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.23078202995008\n",
      "    ram_util_percent: 56.82545757071547\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041455713619249754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.15640260400312\n",
      "    mean_inference_ms: 2.389275672055561\n",
      "    mean_raw_obs_processing_ms: 56.07017330105717\n",
      "  time_since_restore: 21440.434536218643\n",
      "  time_this_iter_s: 421.3621506690979\n",
      "  time_total_s: 21440.434536218643\n",
      "  timers:\n",
      "    learn_throughput: 1057.273\n",
      "    learn_time_ms: 9454.513\n",
      "    load_throughput: 91241.777\n",
      "    load_time_ms: 109.555\n",
      "    sample_throughput: 20.92\n",
      "    sample_time_ms: 477828.914\n",
      "    update_time_ms: 7.518\n",
      "  timestamp: 1636257801\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 579768\n",
      "  training_iteration: 58\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         21440.4</td><td style=\"text-align: right;\">579768</td><td style=\"text-align: right;\"> 5.85193</td><td style=\"text-align: right;\">               13.02</td><td style=\"text-align: right;\">                 0.4</td><td style=\"text-align: right;\">           74.5778</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 589764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_04-10-22\n",
      "  done: false\n",
      "  episode_len_mean: 80.31451612903226\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.570000000000027\n",
      "  episode_reward_mean: 6.010322580645172\n",
      "  episode_reward_min: 0.3800000000000061\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 7175\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0773479437216733\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015073753350121018\n",
      "          policy_loss: -0.05926216471876599\n",
      "          total_loss: 0.21770645023251955\n",
      "          vf_explained_var: 0.9392252564430237\n",
      "          vf_loss: 0.27484883235560525\n",
      "    num_agent_steps_sampled: 589764\n",
      "    num_agent_steps_trained: 589764\n",
      "    num_steps_sampled: 589764\n",
      "    num_steps_trained: 589764\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.98036605657238\n",
      "    ram_util_percent: 57.10881863560732\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0414426052152829\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.151295804091955\n",
      "    mean_inference_ms: 2.3889599400903014\n",
      "    mean_raw_obs_processing_ms: 56.13983021348447\n",
      "  time_since_restore: 21861.847660779953\n",
      "  time_this_iter_s: 421.4131245613098\n",
      "  time_total_s: 21861.847660779953\n",
      "  timers:\n",
      "    learn_throughput: 1057.361\n",
      "    learn_time_ms: 9453.722\n",
      "    load_throughput: 91286.337\n",
      "    load_time_ms: 109.502\n",
      "    sample_throughput: 21.078\n",
      "    sample_time_ms: 474237.788\n",
      "    update_time_ms: 7.453\n",
      "  timestamp: 1636258222\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 589764\n",
      "  training_iteration: 59\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         21861.8</td><td style=\"text-align: right;\">589764</td><td style=\"text-align: right;\"> 6.01032</td><td style=\"text-align: right;\">               13.57</td><td style=\"text-align: right;\">                0.38</td><td style=\"text-align: right;\">           80.3145</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 599760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_04-18-42\n",
      "  done: false\n",
      "  episode_len_mean: 71.07801418439716\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.970000000000024\n",
      "  episode_reward_mean: 5.74304964539008\n",
      "  episode_reward_min: 0.4200000000000065\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 7316\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.065147665117541\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01415158046828657\n",
      "          policy_loss: -0.0639263820508097\n",
      "          total_loss: 0.14867187658340758\n",
      "          vf_explained_var: 0.950508713722229\n",
      "          vf_loss: 0.21175702313900505\n",
      "    num_agent_steps_sampled: 599760\n",
      "    num_agent_steps_trained: 599760\n",
      "    num_steps_sampled: 599760\n",
      "    num_steps_trained: 599760\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.15694249649368\n",
      "    ram_util_percent: 57.070266479663395\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04141098727497443\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.144781106705985\n",
      "    mean_inference_ms: 2.388152182222211\n",
      "    mean_raw_obs_processing_ms: 56.752666791804124\n",
      "  time_since_restore: 22361.396885871887\n",
      "  time_this_iter_s: 499.5492250919342\n",
      "  time_total_s: 22361.396885871887\n",
      "  timers:\n",
      "    learn_throughput: 1057.591\n",
      "    learn_time_ms: 9451.669\n",
      "    load_throughput: 90858.044\n",
      "    load_time_ms: 110.018\n",
      "    sample_throughput: 21.047\n",
      "    sample_time_ms: 474935.841\n",
      "    update_time_ms: 7.494\n",
      "  timestamp: 1636258722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 599760\n",
      "  training_iteration: 60\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         22361.4</td><td style=\"text-align: right;\">599760</td><td style=\"text-align: right;\"> 5.74305</td><td style=\"text-align: right;\">               13.97</td><td style=\"text-align: right;\">                0.42</td><td style=\"text-align: right;\">            71.078</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 609756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_04-26-15\n",
      "  done: false\n",
      "  episode_len_mean: 70.91489361702128\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.190000000000012\n",
      "  episode_reward_mean: 5.713546099290789\n",
      "  episode_reward_min: -1.3800000000000008\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 7457\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.07827275329166\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014631924886278371\n",
      "          policy_loss: -0.05595487758326225\n",
      "          total_loss: 0.15684442416422514\n",
      "          vf_explained_var: 0.9471813440322876\n",
      "          vf_loss: 0.21135979357820292\n",
      "    num_agent_steps_sampled: 609756\n",
      "    num_agent_steps_trained: 609756\n",
      "    num_steps_sampled: 609756\n",
      "    num_steps_trained: 609756\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.97697063369397\n",
      "    ram_util_percent: 57.300927357032464\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04139951438507361\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.190501944726247\n",
      "    mean_inference_ms: 2.387657213996275\n",
      "    mean_raw_obs_processing_ms: 57.22607551064173\n",
      "  time_since_restore: 22814.536506414413\n",
      "  time_this_iter_s: 453.13962054252625\n",
      "  time_total_s: 22814.536506414413\n",
      "  timers:\n",
      "    learn_throughput: 1058.144\n",
      "    learn_time_ms: 9446.73\n",
      "    load_throughput: 91081.975\n",
      "    load_time_ms: 109.747\n",
      "    sample_throughput: 21.022\n",
      "    sample_time_ms: 475495.934\n",
      "    update_time_ms: 8.919\n",
      "  timestamp: 1636259175\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 609756\n",
      "  training_iteration: 61\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         22814.5</td><td style=\"text-align: right;\">609756</td><td style=\"text-align: right;\"> 5.71355</td><td style=\"text-align: right;\">               13.19</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           70.9149</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 619752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_04-36-56\n",
      "  done: false\n",
      "  episode_len_mean: 67.02684563758389\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.080000000000013\n",
      "  episode_reward_mean: 6.310469798657726\n",
      "  episode_reward_min: 0.5600000000000007\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 7606\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0148856381065827\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014510917330608048\n",
      "          policy_loss: -0.059543824448990514\n",
      "          total_loss: 0.14756621196468034\n",
      "          vf_explained_var: 0.9598572254180908\n",
      "          vf_loss: 0.20522043791910013\n",
      "    num_agent_steps_sampled: 619752\n",
      "    num_agent_steps_trained: 619752\n",
      "    num_steps_sampled: 619752\n",
      "    num_steps_trained: 619752\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.49409836065574\n",
      "    ram_util_percent: 57.49846994535519\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04138749345728683\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.212783010593423\n",
      "    mean_inference_ms: 2.387508064652986\n",
      "    mean_raw_obs_processing_ms: 58.01712058694503\n",
      "  time_since_restore: 23455.900283813477\n",
      "  time_this_iter_s: 641.3637773990631\n",
      "  time_total_s: 23455.900283813477\n",
      "  timers:\n",
      "    learn_throughput: 1058.26\n",
      "    learn_time_ms: 9445.695\n",
      "    load_throughput: 91056.971\n",
      "    load_time_ms: 109.777\n",
      "    sample_throughput: 20.219\n",
      "    sample_time_ms: 494381.248\n",
      "    update_time_ms: 9.11\n",
      "  timestamp: 1636259816\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 619752\n",
      "  training_iteration: 62\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         23455.9</td><td style=\"text-align: right;\">619752</td><td style=\"text-align: right;\"> 6.31047</td><td style=\"text-align: right;\">               13.08</td><td style=\"text-align: right;\">                0.56</td><td style=\"text-align: right;\">           67.0268</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 629748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_04-44-39\n",
      "  done: false\n",
      "  episode_len_mean: 73.19117647058823\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.310000000000008\n",
      "  episode_reward_mean: 5.805588235294128\n",
      "  episode_reward_min: 0.5299999999999989\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 7742\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0679812247936544\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014257522653780675\n",
      "          policy_loss: -0.05835134333524949\n",
      "          total_loss: 0.1583787517454953\n",
      "          vf_explained_var: 0.9553336501121521\n",
      "          vf_loss: 0.21575629451654404\n",
      "    num_agent_steps_sampled: 629748\n",
      "    num_agent_steps_trained: 629748\n",
      "    num_steps_sampled: 629748\n",
      "    num_steps_trained: 629748\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.99121212121211\n",
      "    ram_util_percent: 57.60393939393939\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04139685904493503\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.256827964305103\n",
      "    mean_inference_ms: 2.387186213300207\n",
      "    mean_raw_obs_processing_ms: 58.25849141797153\n",
      "  time_since_restore: 23918.12907767296\n",
      "  time_this_iter_s: 462.2287938594818\n",
      "  time_total_s: 23918.12907767296\n",
      "  timers:\n",
      "    learn_throughput: 1058.683\n",
      "    learn_time_ms: 9441.92\n",
      "    load_throughput: 91247.755\n",
      "    load_time_ms: 109.548\n",
      "    sample_throughput: 20.159\n",
      "    sample_time_ms: 495861.421\n",
      "    update_time_ms: 8.868\n",
      "  timestamp: 1636260279\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 629748\n",
      "  training_iteration: 63\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         23918.1</td><td style=\"text-align: right;\">629748</td><td style=\"text-align: right;\"> 5.80559</td><td style=\"text-align: right;\">               13.31</td><td style=\"text-align: right;\">                0.53</td><td style=\"text-align: right;\">           73.1912</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 639744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_04-52-53\n",
      "  done: false\n",
      "  episode_len_mean: 71.23404255319149\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.710000000000024\n",
      "  episode_reward_mean: 6.054468085106393\n",
      "  episode_reward_min: 0.5100000000000005\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 7883\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0455455791237007\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014829667197812058\n",
      "          policy_loss: -0.06470662058195752\n",
      "          total_loss: 0.13791461448368225\n",
      "          vf_explained_var: 0.9575884938240051\n",
      "          vf_loss: 0.2005541337096793\n",
      "    num_agent_steps_sampled: 639744\n",
      "    num_agent_steps_trained: 639744\n",
      "    num_steps_sampled: 639744\n",
      "    num_steps_trained: 639744\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.25758865248228\n",
      "    ram_util_percent: 57.689645390070915\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04139154797912054\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.297979766620163\n",
      "    mean_inference_ms: 2.387299463713835\n",
      "    mean_raw_obs_processing_ms: 58.48426575242444\n",
      "  time_since_restore: 24412.62096476555\n",
      "  time_this_iter_s: 494.49188709259033\n",
      "  time_total_s: 24412.62096476555\n",
      "  timers:\n",
      "    learn_throughput: 1059.242\n",
      "    learn_time_ms: 9436.934\n",
      "    load_throughput: 91686.916\n",
      "    load_time_ms: 109.023\n",
      "    sample_throughput: 20.31\n",
      "    sample_time_ms: 492168.408\n",
      "    update_time_ms: 9.701\n",
      "  timestamp: 1636260773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 639744\n",
      "  training_iteration: 64\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         24412.6</td><td style=\"text-align: right;\">639744</td><td style=\"text-align: right;\"> 6.05447</td><td style=\"text-align: right;\">               13.71</td><td style=\"text-align: right;\">                0.51</td><td style=\"text-align: right;\">            71.234</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 649740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_04-59-22\n",
      "  done: false\n",
      "  episode_len_mean: 76.9076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.21000000000001\n",
      "  episode_reward_mean: 5.941307692307704\n",
      "  episode_reward_min: 0.8900000000000031\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 8013\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0650990329237064\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01635077545418801\n",
      "          policy_loss: -0.059298238640603344\n",
      "          total_loss: 0.167563269718781\n",
      "          vf_explained_var: 0.9450250864028931\n",
      "          vf_loss: 0.2226797594808233\n",
      "    num_agent_steps_sampled: 649740\n",
      "    num_agent_steps_trained: 649740\n",
      "    num_steps_sampled: 649740\n",
      "    num_steps_trained: 649740\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.12810810810812\n",
      "    ram_util_percent: 57.6790990990991\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04137130586715388\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.30144651217466\n",
      "    mean_inference_ms: 2.3868757119070945\n",
      "    mean_raw_obs_processing_ms: 58.60355044557657\n",
      "  time_since_restore: 24801.573942661285\n",
      "  time_this_iter_s: 388.9529778957367\n",
      "  time_total_s: 24801.573942661285\n",
      "  timers:\n",
      "    learn_throughput: 1058.141\n",
      "    learn_time_ms: 9446.754\n",
      "    load_throughput: 91684.349\n",
      "    load_time_ms: 109.026\n",
      "    sample_throughput: 20.705\n",
      "    sample_time_ms: 482771.909\n",
      "    update_time_ms: 10.34\n",
      "  timestamp: 1636261162\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 649740\n",
      "  training_iteration: 65\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         24801.6</td><td style=\"text-align: right;\">649740</td><td style=\"text-align: right;\"> 5.94131</td><td style=\"text-align: right;\">               13.21</td><td style=\"text-align: right;\">                0.89</td><td style=\"text-align: right;\">           76.9077</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 659736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_05-09-11\n",
      "  done: false\n",
      "  episode_len_mean: 67.33561643835617\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.060000000000013\n",
      "  episode_reward_mean: 5.886301369863022\n",
      "  episode_reward_min: 0.500000000000001\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 8159\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0626715789493333\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016470627530574725\n",
      "          policy_loss: -0.0585150111761167\n",
      "          total_loss: 0.19835696270466488\n",
      "          vf_explained_var: 0.9453590512275696\n",
      "          vf_loss: 0.2524839243636681\n",
      "    num_agent_steps_sampled: 659736\n",
      "    num_agent_steps_trained: 659736\n",
      "    num_steps_sampled: 659736\n",
      "    num_steps_trained: 659736\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.51010701545779\n",
      "    ram_util_percent: 57.85683709869204\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04137432570490473\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.332295208013992\n",
      "    mean_inference_ms: 2.3866769881217302\n",
      "    mean_raw_obs_processing_ms: 59.24137790024956\n",
      "  time_since_restore: 25390.33235311508\n",
      "  time_this_iter_s: 588.7584104537964\n",
      "  time_total_s: 25390.33235311508\n",
      "  timers:\n",
      "    learn_throughput: 1058.684\n",
      "    learn_time_ms: 9441.907\n",
      "    load_throughput: 91662.641\n",
      "    load_time_ms: 109.052\n",
      "    sample_throughput: 20.93\n",
      "    sample_time_ms: 477599.047\n",
      "    update_time_ms: 10.642\n",
      "  timestamp: 1636261751\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 659736\n",
      "  training_iteration: 66\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         25390.3</td><td style=\"text-align: right;\">659736</td><td style=\"text-align: right;\">  5.8863</td><td style=\"text-align: right;\">               13.06</td><td style=\"text-align: right;\">                 0.5</td><td style=\"text-align: right;\">           67.3356</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 669732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_05-16-44\n",
      "  done: false\n",
      "  episode_len_mean: 76.47368421052632\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.200000000000012\n",
      "  episode_reward_mean: 6.063007518797003\n",
      "  episode_reward_min: 0.3099999999999987\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 8292\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0595217612054615\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014961483305963556\n",
      "          policy_loss: -0.05930158668794693\n",
      "          total_loss: 0.1801415704127051\n",
      "          vf_explained_var: 0.9449120759963989\n",
      "          vf_loss: 0.23731562206760431\n",
      "    num_agent_steps_sampled: 669732\n",
      "    num_agent_steps_trained: 669732\n",
      "    num_steps_sampled: 669732\n",
      "    num_steps_trained: 669732\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.82658423493045\n",
      "    ram_util_percent: 57.893353941267385\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04137391344943227\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.384476722608195\n",
      "    mean_inference_ms: 2.386946082385478\n",
      "    mean_raw_obs_processing_ms: 59.38019336186725\n",
      "  time_since_restore: 25843.69848704338\n",
      "  time_this_iter_s: 453.36613392829895\n",
      "  time_total_s: 25843.69848704338\n",
      "  timers:\n",
      "    learn_throughput: 1058.707\n",
      "    learn_time_ms: 9441.703\n",
      "    load_throughput: 91696.22\n",
      "    load_time_ms: 109.012\n",
      "    sample_throughput: 21.138\n",
      "    sample_time_ms: 472888.997\n",
      "    update_time_ms: 10.49\n",
      "  timestamp: 1636262204\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 669732\n",
      "  training_iteration: 67\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         25843.7</td><td style=\"text-align: right;\">669732</td><td style=\"text-align: right;\"> 6.06301</td><td style=\"text-align: right;\">                13.2</td><td style=\"text-align: right;\">                0.31</td><td style=\"text-align: right;\">           76.4737</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 679728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_05-24-12\n",
      "  done: false\n",
      "  episode_len_mean: 72.13868613138686\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.110000000000012\n",
      "  episode_reward_mean: 6.051386861313878\n",
      "  episode_reward_min: 0.35000000000000797\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 8429\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0519357175908537\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016708622636138846\n",
      "          policy_loss: -0.05805128393296757\n",
      "          total_loss: 0.21319802137505678\n",
      "          vf_explained_var: 0.9436988830566406\n",
      "          vf_loss: 0.26639244213827656\n",
      "    num_agent_steps_sampled: 679728\n",
      "    num_agent_steps_trained: 679728\n",
      "    num_steps_sampled: 679728\n",
      "    num_steps_trained: 679728\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.01768388106417\n",
      "    ram_util_percent: 57.98247261345853\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04137642401994111\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.422070468046297\n",
      "    mean_inference_ms: 2.3867247742162423\n",
      "    mean_raw_obs_processing_ms: 59.7222587876555\n",
      "  time_since_restore: 26291.52950310707\n",
      "  time_this_iter_s: 447.8310160636902\n",
      "  time_total_s: 26291.52950310707\n",
      "  timers:\n",
      "    learn_throughput: 1058.127\n",
      "    learn_time_ms: 9446.882\n",
      "    load_throughput: 91546.756\n",
      "    load_time_ms: 109.19\n",
      "    sample_throughput: 21.021\n",
      "    sample_time_ms: 475530.391\n",
      "    update_time_ms: 10.493\n",
      "  timestamp: 1636262652\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 679728\n",
      "  training_iteration: 68\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         26291.5</td><td style=\"text-align: right;\">679728</td><td style=\"text-align: right;\"> 6.05139</td><td style=\"text-align: right;\">               13.11</td><td style=\"text-align: right;\">                0.35</td><td style=\"text-align: right;\">           72.1387</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 689724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_05-30-56\n",
      "  done: false\n",
      "  episode_len_mean: 75.21641791044776\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.15000000000001\n",
      "  episode_reward_mean: 6.491194029850756\n",
      "  episode_reward_min: 0.6999999999999988\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 8563\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.017735736696129\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015039710078622417\n",
      "          policy_loss: -0.06184021901562173\n",
      "          total_loss: 0.18445522214134788\n",
      "          vf_explained_var: 0.9520906209945679\n",
      "          vf_loss: 0.2436312386368075\n",
      "    num_agent_steps_sampled: 689724\n",
      "    num_agent_steps_trained: 689724\n",
      "    num_steps_sampled: 689724\n",
      "    num_steps_trained: 689724\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.18333333333334\n",
      "    ram_util_percent: 58.06805555555555\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04135201227077285\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.447171433645515\n",
      "    mean_inference_ms: 2.386425878954164\n",
      "    mean_raw_obs_processing_ms: 59.84990971375713\n",
      "  time_since_restore: 26695.373972654343\n",
      "  time_this_iter_s: 403.84446954727173\n",
      "  time_total_s: 26695.373972654343\n",
      "  timers:\n",
      "    learn_throughput: 1057.987\n",
      "    learn_time_ms: 9448.132\n",
      "    load_throughput: 91612.568\n",
      "    load_time_ms: 109.112\n",
      "    sample_throughput: 21.099\n",
      "    sample_time_ms: 473771.911\n",
      "    update_time_ms: 10.728\n",
      "  timestamp: 1636263056\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 689724\n",
      "  training_iteration: 69\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         26695.4</td><td style=\"text-align: right;\">689724</td><td style=\"text-align: right;\"> 6.49119</td><td style=\"text-align: right;\">               15.15</td><td style=\"text-align: right;\">                 0.7</td><td style=\"text-align: right;\">           75.2164</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 699720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_05-43-30\n",
      "  done: false\n",
      "  episode_len_mean: 65.375\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.100000000000023\n",
      "  episode_reward_mean: 6.317565789473693\n",
      "  episode_reward_min: 0.8000000000000095\n",
      "  episodes_this_iter: 152\n",
      "  episodes_total: 8715\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.027845080082233\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014837833754057108\n",
      "          policy_loss: -0.06341650301956722\n",
      "          total_loss: 0.1444003950438311\n",
      "          vf_explained_var: 0.9567330479621887\n",
      "          vf_loss: 0.2055603910333071\n",
      "    num_agent_steps_sampled: 699720\n",
      "    num_agent_steps_trained: 699720\n",
      "    num_steps_sampled: 699720\n",
      "    num_steps_trained: 699720\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.09507434944238\n",
      "    ram_util_percent: 58.27834572490706\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04135659333975149\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.470186656674922\n",
      "    mean_inference_ms: 2.3846426421034614\n",
      "    mean_raw_obs_processing_ms: 60.95243902145383\n",
      "  time_since_restore: 27449.242034196854\n",
      "  time_this_iter_s: 753.868061542511\n",
      "  time_total_s: 27449.242034196854\n",
      "  timers:\n",
      "    learn_throughput: 1057.817\n",
      "    learn_time_ms: 9449.653\n",
      "    load_throughput: 91716.881\n",
      "    load_time_ms: 108.988\n",
      "    sample_throughput: 20.024\n",
      "    sample_time_ms: 499202.12\n",
      "    update_time_ms: 10.885\n",
      "  timestamp: 1636263810\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 699720\n",
      "  training_iteration: 70\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         27449.2</td><td style=\"text-align: right;\">699720</td><td style=\"text-align: right;\"> 6.31757</td><td style=\"text-align: right;\">                14.1</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            65.375</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 709716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_05-50-24\n",
      "  done: false\n",
      "  episode_len_mean: 75.56390977443608\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.95000000000002\n",
      "  episode_reward_mean: 6.371578947368432\n",
      "  episode_reward_min: 0.6100000000000093\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 8848\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0326666622080354\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018349509949399854\n",
      "          policy_loss: -0.05661863929982114\n",
      "          total_loss: 0.21147908860674272\n",
      "          vf_explained_var: 0.9494695663452148\n",
      "          vf_loss: 0.26055607710702294\n",
      "    num_agent_steps_sampled: 709716\n",
      "    num_agent_steps_trained: 709716\n",
      "    num_steps_sampled: 709716\n",
      "    num_steps_trained: 709716\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.39254237288135\n",
      "    ram_util_percent: 58.264406779661016\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04135012075831493\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.476642641828303\n",
      "    mean_inference_ms: 2.385804430859562\n",
      "    mean_raw_obs_processing_ms: 60.89071720576095\n",
      "  time_since_restore: 27862.898231983185\n",
      "  time_this_iter_s: 413.6561977863312\n",
      "  time_total_s: 27862.898231983185\n",
      "  timers:\n",
      "    learn_throughput: 1057.826\n",
      "    learn_time_ms: 9449.569\n",
      "    load_throughput: 91674.326\n",
      "    load_time_ms: 109.038\n",
      "    sample_throughput: 20.184\n",
      "    sample_time_ms: 495255.035\n",
      "    update_time_ms: 9.532\n",
      "  timestamp: 1636264224\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 709716\n",
      "  training_iteration: 71\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         27862.9</td><td style=\"text-align: right;\">709716</td><td style=\"text-align: right;\"> 6.37158</td><td style=\"text-align: right;\">               13.95</td><td style=\"text-align: right;\">                0.61</td><td style=\"text-align: right;\">           75.5639</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 719712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_05-59-54\n",
      "  done: false\n",
      "  episode_len_mean: 70.47183098591549\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.070000000000014\n",
      "  episode_reward_mean: 6.035985915492967\n",
      "  episode_reward_min: 0.559999999999999\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 8990\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0442884862932384\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013847421799084403\n",
      "          policy_loss: -0.057346197774904406\n",
      "          total_loss: 0.14290183069916745\n",
      "          vf_explained_var: 0.9514022469520569\n",
      "          vf_loss: 0.19966014173104724\n",
      "    num_agent_steps_sampled: 719712\n",
      "    num_agent_steps_trained: 719712\n",
      "    num_steps_sampled: 719712\n",
      "    num_steps_trained: 719712\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.92976629766297\n",
      "    ram_util_percent: 58.572816728167275\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04130798638305244\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.494227488989456\n",
      "    mean_inference_ms: 2.3843221789443665\n",
      "    mean_raw_obs_processing_ms: 61.2675657253935\n",
      "  time_since_restore: 28432.91312146187\n",
      "  time_this_iter_s: 570.0148894786835\n",
      "  time_total_s: 28432.91312146187\n",
      "  timers:\n",
      "    learn_throughput: 1058.21\n",
      "    learn_time_ms: 9446.14\n",
      "    load_throughput: 91462.338\n",
      "    load_time_ms: 109.291\n",
      "    sample_throughput: 20.478\n",
      "    sample_time_ms: 488123.296\n",
      "    update_time_ms: 9.388\n",
      "  timestamp: 1636264794\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 719712\n",
      "  training_iteration: 72\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         28432.9</td><td style=\"text-align: right;\">719712</td><td style=\"text-align: right;\"> 6.03599</td><td style=\"text-align: right;\">               13.07</td><td style=\"text-align: right;\">                0.56</td><td style=\"text-align: right;\">           70.4718</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 729708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_06-07-20\n",
      "  done: false\n",
      "  episode_len_mean: 72.39855072463769\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.100000000000012\n",
      "  episode_reward_mean: 6.306739130434793\n",
      "  episode_reward_min: 0.6800000000000029\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 9128\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0221513775678783\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015045133979372174\n",
      "          policy_loss: -0.06485373360924741\n",
      "          total_loss: 0.13336940954407503\n",
      "          vf_explained_var: 0.9604810476303101\n",
      "          vf_loss: 0.1955948592028302\n",
      "    num_agent_steps_sampled: 729708\n",
      "    num_agent_steps_trained: 729708\n",
      "    num_steps_sampled: 729708\n",
      "    num_steps_trained: 729708\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.77601880877742\n",
      "    ram_util_percent: 58.37319749216301\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04132146529870832\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.5363780284476\n",
      "    mean_inference_ms: 2.38477385766918\n",
      "    mean_raw_obs_processing_ms: 61.51363372036141\n",
      "  time_since_restore: 28879.497581481934\n",
      "  time_this_iter_s: 446.5844600200653\n",
      "  time_total_s: 28879.497581481934\n",
      "  timers:\n",
      "    learn_throughput: 1058.124\n",
      "    learn_time_ms: 9446.905\n",
      "    load_throughput: 91358.285\n",
      "    load_time_ms: 109.415\n",
      "    sample_throughput: 20.544\n",
      "    sample_time_ms: 486558.721\n",
      "    update_time_ms: 9.064\n",
      "  timestamp: 1636265240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 729708\n",
      "  training_iteration: 73\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         28879.5</td><td style=\"text-align: right;\">729708</td><td style=\"text-align: right;\"> 6.30674</td><td style=\"text-align: right;\">                13.1</td><td style=\"text-align: right;\">                0.68</td><td style=\"text-align: right;\">           72.3986</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 739704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_06-15-49\n",
      "  done: false\n",
      "  episode_len_mean: 73.28676470588235\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.32000000000001\n",
      "  episode_reward_mean: 6.845441176470598\n",
      "  episode_reward_min: 0.7200000000000035\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 9264\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9848543194624093\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01571277837139209\n",
      "          policy_loss: -0.06422443947094118\n",
      "          total_loss: 0.14874132757719893\n",
      "          vf_explained_var: 0.9611971974372864\n",
      "          vf_loss: 0.20895052884315324\n",
      "    num_agent_steps_sampled: 739704\n",
      "    num_agent_steps_trained: 739704\n",
      "    num_steps_sampled: 739704\n",
      "    num_steps_trained: 739704\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.44593103448277\n",
      "    ram_util_percent: 58.57696551724138\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041339169851745544\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.548204112506294\n",
      "    mean_inference_ms: 2.385262641760916\n",
      "    mean_raw_obs_processing_ms: 61.70866268437521\n",
      "  time_since_restore: 29388.17174267769\n",
      "  time_this_iter_s: 508.674161195755\n",
      "  time_total_s: 29388.17174267769\n",
      "  timers:\n",
      "    learn_throughput: 1057.76\n",
      "    learn_time_ms: 9450.156\n",
      "    load_throughput: 91109.507\n",
      "    load_time_ms: 109.714\n",
      "    sample_throughput: 20.485\n",
      "    sample_time_ms: 487974.205\n",
      "    update_time_ms: 8.265\n",
      "  timestamp: 1636265749\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 739704\n",
      "  training_iteration: 74\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         29388.2</td><td style=\"text-align: right;\">739704</td><td style=\"text-align: right;\"> 6.84544</td><td style=\"text-align: right;\">               13.32</td><td style=\"text-align: right;\">                0.72</td><td style=\"text-align: right;\">           73.2868</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 749700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_06-24-54\n",
      "  done: false\n",
      "  episode_len_mean: 70.37588652482269\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000024\n",
      "  episode_reward_mean: 6.0092198581560385\n",
      "  episode_reward_min: 0.4200000000000055\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 9405\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0351844447290794\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015437402887187212\n",
      "          policy_loss: -0.06377475223798527\n",
      "          total_loss: 0.14158018480460996\n",
      "          vf_explained_var: 0.9570084810256958\n",
      "          vf_loss: 0.20226122636156968\n",
      "    num_agent_steps_sampled: 749700\n",
      "    num_agent_steps_trained: 749700\n",
      "    num_steps_sampled: 749700\n",
      "    num_steps_trained: 749700\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.77609254498715\n",
      "    ram_util_percent: 58.62853470437018\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04130251397171142\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.56974066794235\n",
      "    mean_inference_ms: 2.3838507310705874\n",
      "    mean_raw_obs_processing_ms: 62.24233276957917\n",
      "  time_since_restore: 29933.367563962936\n",
      "  time_this_iter_s: 545.1958212852478\n",
      "  time_total_s: 29933.367563962936\n",
      "  timers:\n",
      "    learn_throughput: 1057.807\n",
      "    learn_time_ms: 9449.741\n",
      "    load_throughput: 91187.066\n",
      "    load_time_ms: 109.621\n",
      "    sample_throughput: 19.849\n",
      "    sample_time_ms: 503599.349\n",
      "    update_time_ms: 7.748\n",
      "  timestamp: 1636266294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 749700\n",
      "  training_iteration: 75\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         29933.4</td><td style=\"text-align: right;\">749700</td><td style=\"text-align: right;\"> 6.00922</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                0.42</td><td style=\"text-align: right;\">           70.3759</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 759696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_06-36-54\n",
      "  done: false\n",
      "  episode_len_mean: 67.70270270270271\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.140000000000013\n",
      "  episode_reward_mean: 6.3937837837837925\n",
      "  episode_reward_min: 0.5999999999999989\n",
      "  episodes_this_iter: 148\n",
      "  episodes_total: 9553\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0181184688185017\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016714106079691152\n",
      "          policy_loss: -0.061238409956105244\n",
      "          total_loss: 0.16378510009783964\n",
      "          vf_explained_var: 0.9603580236434937\n",
      "          vf_loss: 0.2198201487175165\n",
      "    num_agent_steps_sampled: 759696\n",
      "    num_agent_steps_trained: 759696\n",
      "    num_steps_sampled: 759696\n",
      "    num_steps_trained: 759696\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.2511673151751\n",
      "    ram_util_percent: 58.94474708171206\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041274691892698466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.569645671809795\n",
      "    mean_inference_ms: 2.383395231649086\n",
      "    mean_raw_obs_processing_ms: 62.88500898123284\n",
      "  time_since_restore: 30653.34426522255\n",
      "  time_this_iter_s: 719.976701259613\n",
      "  time_total_s: 30653.34426522255\n",
      "  timers:\n",
      "    learn_throughput: 1057.36\n",
      "    learn_time_ms: 9453.734\n",
      "    load_throughput: 91100.341\n",
      "    load_time_ms: 109.725\n",
      "    sample_throughput: 19.345\n",
      "    sample_time_ms: 516717.237\n",
      "    update_time_ms: 7.364\n",
      "  timestamp: 1636267014\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 759696\n",
      "  training_iteration: 76\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         30653.3</td><td style=\"text-align: right;\">759696</td><td style=\"text-align: right;\"> 6.39378</td><td style=\"text-align: right;\">               13.14</td><td style=\"text-align: right;\">                 0.6</td><td style=\"text-align: right;\">           67.7027</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 769692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_06-46-31\n",
      "  done: false\n",
      "  episode_len_mean: 70.20138888888889\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.080000000000013\n",
      "  episode_reward_mean: 6.46861111111112\n",
      "  episode_reward_min: 0.670000000000014\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 9697\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9864911590885912\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01571242278040411\n",
      "          policy_loss: -0.064329983594899\n",
      "          total_loss: 0.15412023746782644\n",
      "          vf_explained_var: 0.958391547203064\n",
      "          vf_loss: 0.2144518914226538\n",
      "    num_agent_steps_sampled: 769692\n",
      "    num_agent_steps_trained: 769692\n",
      "    num_steps_sampled: 769692\n",
      "    num_steps_trained: 769692\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.73912515188336\n",
      "    ram_util_percent: 58.9037667071689\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04128345792722258\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.57118531833034\n",
      "    mean_inference_ms: 2.384066726214908\n",
      "    mean_raw_obs_processing_ms: 63.20826914715659\n",
      "  time_since_restore: 31229.846263170242\n",
      "  time_this_iter_s: 576.5019979476929\n",
      "  time_total_s: 31229.846263170242\n",
      "  timers:\n",
      "    learn_throughput: 1056.445\n",
      "    learn_time_ms: 9461.923\n",
      "    load_throughput: 91051.731\n",
      "    load_time_ms: 109.784\n",
      "    sample_throughput: 18.895\n",
      "    sample_time_ms: 529023.166\n",
      "    update_time_ms: 6.947\n",
      "  timestamp: 1636267591\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 769692\n",
      "  training_iteration: 77\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         31229.8</td><td style=\"text-align: right;\">769692</td><td style=\"text-align: right;\"> 6.46861</td><td style=\"text-align: right;\">               13.08</td><td style=\"text-align: right;\">                0.67</td><td style=\"text-align: right;\">           70.2014</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 779688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_06-55-52\n",
      "  done: false\n",
      "  episode_len_mean: 69.34027777777777\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.130000000000013\n",
      "  episode_reward_mean: 6.236875000000008\n",
      "  episode_reward_min: 0.869999999999999\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 9841\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.997704538422772\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017053657565771513\n",
      "          policy_loss: -0.06176203147818645\n",
      "          total_loss: 0.1799248424099965\n",
      "          vf_explained_var: 0.9562793970108032\n",
      "          vf_loss: 0.23576367799606587\n",
      "    num_agent_steps_sampled: 779688\n",
      "    num_agent_steps_trained: 779688\n",
      "    num_steps_sampled: 779688\n",
      "    num_steps_trained: 779688\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.47775\n",
      "    ram_util_percent: 59.02174999999999\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041309950013946946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.614929877569182\n",
      "    mean_inference_ms: 2.3844432392552974\n",
      "    mean_raw_obs_processing_ms: 63.41041225462852\n",
      "  time_since_restore: 31790.653977632523\n",
      "  time_this_iter_s: 560.8077144622803\n",
      "  time_total_s: 31790.653977632523\n",
      "  timers:\n",
      "    learn_throughput: 1056.265\n",
      "    learn_time_ms: 9463.531\n",
      "    load_throughput: 91240.705\n",
      "    load_time_ms: 109.556\n",
      "    sample_throughput: 18.5\n",
      "    sample_time_ms: 540319.918\n",
      "    update_time_ms: 6.616\n",
      "  timestamp: 1636268152\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 779688\n",
      "  training_iteration: 78\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         31790.7</td><td style=\"text-align: right;\">779688</td><td style=\"text-align: right;\"> 6.23688</td><td style=\"text-align: right;\">               13.13</td><td style=\"text-align: right;\">                0.87</td><td style=\"text-align: right;\">           69.3403</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 789684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_07-05-13\n",
      "  done: false\n",
      "  episode_len_mean: 68.54482758620689\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.160000000000013\n",
      "  episode_reward_mean: 6.384344827586216\n",
      "  episode_reward_min: 0.5500000000000067\n",
      "  episodes_this_iter: 145\n",
      "  episodes_total: 9986\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9944460865778801\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017287281596030653\n",
      "          policy_loss: -0.06078482551468361\n",
      "          total_loss: 0.16440952511456533\n",
      "          vf_explained_var: 0.9617472290992737\n",
      "          vf_loss: 0.21888375219562625\n",
      "    num_agent_steps_sampled: 789684\n",
      "    num_agent_steps_trained: 789684\n",
      "    num_steps_sampled: 789684\n",
      "    num_steps_trained: 789684\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.52172284644195\n",
      "    ram_util_percent: 58.978901373283406\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04127307492663385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.624922361537028\n",
      "    mean_inference_ms: 2.3832906505759137\n",
      "    mean_raw_obs_processing_ms: 64.01587587439403\n",
      "  time_since_restore: 32351.99709224701\n",
      "  time_this_iter_s: 561.3431146144867\n",
      "  time_total_s: 32351.99709224701\n",
      "  timers:\n",
      "    learn_throughput: 1057.061\n",
      "    learn_time_ms: 9456.409\n",
      "    load_throughput: 91059.048\n",
      "    load_time_ms: 109.775\n",
      "    sample_throughput: 17.976\n",
      "    sample_time_ms: 556076.188\n",
      "    update_time_ms: 7.023\n",
      "  timestamp: 1636268713\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 789684\n",
      "  training_iteration: 79\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">           32352</td><td style=\"text-align: right;\">789684</td><td style=\"text-align: right;\"> 6.38434</td><td style=\"text-align: right;\">               13.16</td><td style=\"text-align: right;\">                0.55</td><td style=\"text-align: right;\">           68.5448</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 799680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_07-14-18\n",
      "  done: false\n",
      "  episode_len_mean: 70.60714285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.15000000000001\n",
      "  episode_reward_mean: 5.831142857142866\n",
      "  episode_reward_min: 0.6900000000000023\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 10126\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.009293565281436\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014907546337934575\n",
      "          policy_loss: -0.06759799011370056\n",
      "          total_loss: 0.12113507744402457\n",
      "          vf_explained_var: 0.9606860280036926\n",
      "          vf_loss: 0.1861851683411843\n",
      "    num_agent_steps_sampled: 799680\n",
      "    num_agent_steps_trained: 799680\n",
      "    num_steps_sampled: 799680\n",
      "    num_steps_trained: 799680\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.44023136246787\n",
      "    ram_util_percent: 59.0496143958869\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04125991215568716\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.63544540372225\n",
      "    mean_inference_ms: 2.3831169398056673\n",
      "    mean_raw_obs_processing_ms: 64.34089683530797\n",
      "  time_since_restore: 32897.29880738258\n",
      "  time_this_iter_s: 545.3017151355743\n",
      "  time_total_s: 32897.29880738258\n",
      "  timers:\n",
      "    learn_throughput: 1057.119\n",
      "    learn_time_ms: 9455.89\n",
      "    load_throughput: 90925.157\n",
      "    load_time_ms: 109.937\n",
      "    sample_throughput: 18.676\n",
      "    sample_time_ms: 535219.91\n",
      "    update_time_ms: 6.856\n",
      "  timestamp: 1636269258\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 799680\n",
      "  training_iteration: 80\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         32897.3</td><td style=\"text-align: right;\">799680</td><td style=\"text-align: right;\"> 5.83114</td><td style=\"text-align: right;\">               13.15</td><td style=\"text-align: right;\">                0.69</td><td style=\"text-align: right;\">           70.6071</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 809676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_07-23-07\n",
      "  done: false\n",
      "  episode_len_mean: 72.19858156028369\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.190000000000012\n",
      "  episode_reward_mean: 6.286950354609939\n",
      "  episode_reward_min: 0.5200000000000002\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 10267\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9811907990365967\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016709491011088106\n",
      "          policy_loss: -0.06133965336454984\n",
      "          total_loss: 0.1564413134382767\n",
      "          vf_explained_var: 0.9529363512992859\n",
      "          vf_loss: 0.21221533631348713\n",
      "    num_agent_steps_sampled: 809676\n",
      "    num_agent_steps_trained: 809676\n",
      "    num_steps_sampled: 809676\n",
      "    num_steps_trained: 809676\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.53403973509933\n",
      "    ram_util_percent: 59.16953642384106\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041303670754951914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.713358946372807\n",
      "    mean_inference_ms: 2.383822838381151\n",
      "    mean_raw_obs_processing_ms: 64.35405533955637\n",
      "  time_since_restore: 33426.287982702255\n",
      "  time_this_iter_s: 528.9891753196716\n",
      "  time_total_s: 33426.287982702255\n",
      "  timers:\n",
      "    learn_throughput: 1056.477\n",
      "    learn_time_ms: 9461.634\n",
      "    load_throughput: 91057.98\n",
      "    load_time_ms: 109.776\n",
      "    sample_throughput: 18.283\n",
      "    sample_time_ms: 546746.914\n",
      "    update_time_ms: 7.819\n",
      "  timestamp: 1636269787\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 809676\n",
      "  training_iteration: 81\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         33426.3</td><td style=\"text-align: right;\">809676</td><td style=\"text-align: right;\"> 6.28695</td><td style=\"text-align: right;\">               13.19</td><td style=\"text-align: right;\">                0.52</td><td style=\"text-align: right;\">           72.1986</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 819672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_07-29-45\n",
      "  done: false\n",
      "  episode_len_mean: 75.28787878787878\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.800000000000022\n",
      "  episode_reward_mean: 6.636212121212132\n",
      "  episode_reward_min: 0.7900000000000006\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 10399\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9749023978526776\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01632130648277102\n",
      "          policy_loss: -0.05893709902993889\n",
      "          total_loss: 0.1581075451336801\n",
      "          vf_explained_var: 0.9612787961959839\n",
      "          vf_loss: 0.21200568498645583\n",
      "    num_agent_steps_sampled: 819672\n",
      "    num_agent_steps_trained: 819672\n",
      "    num_steps_sampled: 819672\n",
      "    num_steps_trained: 819672\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.50971731448763\n",
      "    ram_util_percent: 59.40742049469966\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041284765136178216\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.75871877717594\n",
      "    mean_inference_ms: 2.3837255892743565\n",
      "    mean_raw_obs_processing_ms: 64.4671658536283\n",
      "  time_since_restore: 33823.31555247307\n",
      "  time_this_iter_s: 397.027569770813\n",
      "  time_total_s: 33823.31555247307\n",
      "  timers:\n",
      "    learn_throughput: 1055.326\n",
      "    learn_time_ms: 9471.953\n",
      "    load_throughput: 91323.5\n",
      "    load_time_ms: 109.457\n",
      "    sample_throughput: 18.88\n",
      "    sample_time_ms: 529436.303\n",
      "    update_time_ms: 8.055\n",
      "  timestamp: 1636270185\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 819672\n",
      "  training_iteration: 82\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         33823.3</td><td style=\"text-align: right;\">819672</td><td style=\"text-align: right;\"> 6.63621</td><td style=\"text-align: right;\">                13.8</td><td style=\"text-align: right;\">                0.79</td><td style=\"text-align: right;\">           75.2879</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 829668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_07-36-39\n",
      "  done: false\n",
      "  episode_len_mean: 78.85826771653544\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.200000000000012\n",
      "  episode_reward_mean: 6.640551181102375\n",
      "  episode_reward_min: 0.579999999999999\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 10526\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0066117818538958\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016956250926716026\n",
      "          policy_loss: -0.06461293478138172\n",
      "          total_loss: 0.15911679512056975\n",
      "          vf_explained_var: 0.9582443237304688\n",
      "          vf_loss: 0.21804354205791257\n",
      "    num_agent_steps_sampled: 829668\n",
      "    num_agent_steps_trained: 829668\n",
      "    num_steps_sampled: 829668\n",
      "    num_steps_trained: 829668\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.01655405405405\n",
      "    ram_util_percent: 59.66554054054054\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04129022844324548\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.796389225600528\n",
      "    mean_inference_ms: 2.3833132065674683\n",
      "    mean_raw_obs_processing_ms: 64.34526990390562\n",
      "  time_since_restore: 34237.565902233124\n",
      "  time_this_iter_s: 414.25034976005554\n",
      "  time_total_s: 34237.565902233124\n",
      "  timers:\n",
      "    learn_throughput: 1055.154\n",
      "    learn_time_ms: 9473.499\n",
      "    load_throughput: 91302.936\n",
      "    load_time_ms: 109.482\n",
      "    sample_throughput: 18.997\n",
      "    sample_time_ms: 526200.769\n",
      "    update_time_ms: 8.192\n",
      "  timestamp: 1636270599\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 829668\n",
      "  training_iteration: 83\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         34237.6</td><td style=\"text-align: right;\">829668</td><td style=\"text-align: right;\"> 6.64055</td><td style=\"text-align: right;\">                13.2</td><td style=\"text-align: right;\">                0.58</td><td style=\"text-align: right;\">           78.8583</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 839664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_07-43-59\n",
      "  done: false\n",
      "  episode_len_mean: 71.35460992907801\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.04000000000002\n",
      "  episode_reward_mean: 6.558865248226961\n",
      "  episode_reward_min: 0.16000000000000555\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 10667\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9579111519022885\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01695582814538251\n",
      "          policy_loss: -0.06111923364174162\n",
      "          total_loss: 0.1828127825521251\n",
      "          vf_explained_var: 0.9537572860717773\n",
      "          vf_loss: 0.23775946395392092\n",
      "    num_agent_steps_sampled: 839664\n",
      "    num_agent_steps_trained: 839664\n",
      "    num_steps_sampled: 839664\n",
      "    num_steps_trained: 839664\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.15939490445861\n",
      "    ram_util_percent: 59.70414012738854\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04129855036422849\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.820082842670097\n",
      "    mean_inference_ms: 2.383746888924088\n",
      "    mean_raw_obs_processing_ms: 64.54659058969486\n",
      "  time_since_restore: 34678.22316646576\n",
      "  time_this_iter_s: 440.6572642326355\n",
      "  time_total_s: 34678.22316646576\n",
      "  timers:\n",
      "    learn_throughput: 1055.128\n",
      "    learn_time_ms: 9473.733\n",
      "    load_throughput: 91291.207\n",
      "    load_time_ms: 109.496\n",
      "    sample_throughput: 19.245\n",
      "    sample_time_ms: 519398.386\n",
      "    update_time_ms: 8.405\n",
      "  timestamp: 1636271039\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 839664\n",
      "  training_iteration: 84\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         34678.2</td><td style=\"text-align: right;\">839664</td><td style=\"text-align: right;\"> 6.55887</td><td style=\"text-align: right;\">               14.04</td><td style=\"text-align: right;\">                0.16</td><td style=\"text-align: right;\">           71.3546</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 849660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_07-53-19\n",
      "  done: false\n",
      "  episode_len_mean: 68.8041958041958\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.00000000000002\n",
      "  episode_reward_mean: 6.306083916083925\n",
      "  episode_reward_min: 0.6300000000000052\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 10810\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.96047997321838\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014177995822908095\n",
      "          policy_loss: -0.06718892644231136\n",
      "          total_loss: 0.09107257793617682\n",
      "          vf_explained_var: 0.9667494893074036\n",
      "          vf_loss: 0.15633347346328008\n",
      "    num_agent_steps_sampled: 849660\n",
      "    num_agent_steps_trained: 849660\n",
      "    num_steps_sampled: 849660\n",
      "    num_steps_trained: 849660\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.30501253132832\n",
      "    ram_util_percent: 59.7670426065163\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04129215759882128\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.853001571521514\n",
      "    mean_inference_ms: 2.384273010927402\n",
      "    mean_raw_obs_processing_ms: 64.87209473790224\n",
      "  time_since_restore: 35237.37403821945\n",
      "  time_this_iter_s: 559.1508717536926\n",
      "  time_total_s: 35237.37403821945\n",
      "  timers:\n",
      "    learn_throughput: 1055.727\n",
      "    learn_time_ms: 9468.355\n",
      "    load_throughput: 91042.122\n",
      "    load_time_ms: 109.795\n",
      "    sample_throughput: 19.194\n",
      "    sample_time_ms: 520798.959\n",
      "    update_time_ms: 8.305\n",
      "  timestamp: 1636271599\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 849660\n",
      "  training_iteration: 85\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         35237.4</td><td style=\"text-align: right;\">849660</td><td style=\"text-align: right;\"> 6.30608</td><td style=\"text-align: right;\">                  14</td><td style=\"text-align: right;\">                0.63</td><td style=\"text-align: right;\">           68.8042</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 859656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_08-01-42\n",
      "  done: false\n",
      "  episode_len_mean: 76.74809160305344\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.230000000000011\n",
      "  episode_reward_mean: 6.494198473282454\n",
      "  episode_reward_min: 1.0200000000000014\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 10941\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9757847873573628\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015107521423125398\n",
      "          policy_loss: -0.06448835027523529\n",
      "          total_loss: 0.11107624743897945\n",
      "          vf_explained_var: 0.9666306972503662\n",
      "          vf_loss: 0.17237789776717496\n",
      "    num_agent_steps_sampled: 859656\n",
      "    num_agent_steps_trained: 859656\n",
      "    num_steps_sampled: 859656\n",
      "    num_steps_trained: 859656\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.81502086230876\n",
      "    ram_util_percent: 59.86230876216969\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041293884949598514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.890204798346502\n",
      "    mean_inference_ms: 2.3830108495297675\n",
      "    mean_raw_obs_processing_ms: 65.04886280388665\n",
      "  time_since_restore: 35740.80299258232\n",
      "  time_this_iter_s: 503.42895436286926\n",
      "  time_total_s: 35740.80299258232\n",
      "  timers:\n",
      "    learn_throughput: 1055.344\n",
      "    learn_time_ms: 9471.796\n",
      "    load_throughput: 91155.166\n",
      "    load_time_ms: 109.659\n",
      "    sample_throughput: 20.026\n",
      "    sample_time_ms: 499140.85\n",
      "    update_time_ms: 8.44\n",
      "  timestamp: 1636272102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 859656\n",
      "  training_iteration: 86\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         35740.8</td><td style=\"text-align: right;\">859656</td><td style=\"text-align: right;\">  6.4942</td><td style=\"text-align: right;\">               13.23</td><td style=\"text-align: right;\">                1.02</td><td style=\"text-align: right;\">           76.7481</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 869652\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_08-09-25\n",
      "  done: false\n",
      "  episode_len_mean: 74.23703703703704\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.180000000000012\n",
      "  episode_reward_mean: 6.590296296296307\n",
      "  episode_reward_min: 0.5000000000000036\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 11076\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9692386649612688\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018029406041482083\n",
      "          policy_loss: -0.06446195144174445\n",
      "          total_loss: 0.16942761579098609\n",
      "          vf_explained_var: 0.9513214826583862\n",
      "          vf_loss: 0.22619979348129188\n",
      "    num_agent_steps_sampled: 869652\n",
      "    num_agent_steps_trained: 869652\n",
      "    num_steps_sampled: 869652\n",
      "    num_steps_trained: 869652\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.61681818181818\n",
      "    ram_util_percent: 59.8280303030303\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041277397927684124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.917904130252282\n",
      "    mean_inference_ms: 2.3835624472421504\n",
      "    mean_raw_obs_processing_ms: 65.1760736378935\n",
      "  time_since_restore: 36203.786709308624\n",
      "  time_this_iter_s: 462.9837167263031\n",
      "  time_total_s: 36203.786709308624\n",
      "  timers:\n",
      "    learn_throughput: 1055.952\n",
      "    learn_time_ms: 9466.337\n",
      "    load_throughput: 91281.428\n",
      "    load_time_ms: 109.507\n",
      "    sample_throughput: 20.492\n",
      "    sample_time_ms: 487794.878\n",
      "    update_time_ms: 8.381\n",
      "  timestamp: 1636272565\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 869652\n",
      "  training_iteration: 87\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         36203.8</td><td style=\"text-align: right;\">869652</td><td style=\"text-align: right;\">  6.5903</td><td style=\"text-align: right;\">               13.18</td><td style=\"text-align: right;\">                 0.5</td><td style=\"text-align: right;\">            74.237</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 879648\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_08-19-44\n",
      "  done: false\n",
      "  episode_len_mean: 66.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.160000000000013\n",
      "  episode_reward_mean: 6.598133333333343\n",
      "  episode_reward_min: 0.5200000000000062\n",
      "  episodes_this_iter: 150\n",
      "  episodes_total: 11226\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9680988418750274\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015397815933490022\n",
      "          policy_loss: -0.06448147247712581\n",
      "          total_loss: 0.1504499674615506\n",
      "          vf_explained_var: 0.9608657360076904\n",
      "          vf_loss: 0.21122699549310228\n",
      "    num_agent_steps_sampled: 879648\n",
      "    num_agent_steps_trained: 879648\n",
      "    num_steps_sampled: 879648\n",
      "    num_steps_trained: 879648\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.74133635334088\n",
      "    ram_util_percent: 60.042582106455264\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041276295597112475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.94349557871403\n",
      "    mean_inference_ms: 2.3832709280719957\n",
      "    mean_raw_obs_processing_ms: 65.60552092074485\n",
      "  time_since_restore: 36822.27109980583\n",
      "  time_this_iter_s: 618.4843904972076\n",
      "  time_total_s: 36822.27109980583\n",
      "  timers:\n",
      "    learn_throughput: 1056.106\n",
      "    learn_time_ms: 9464.957\n",
      "    load_throughput: 91134.104\n",
      "    load_time_ms: 109.685\n",
      "    sample_throughput: 20.253\n",
      "    sample_time_ms: 493564.248\n",
      "    update_time_ms: 7.679\n",
      "  timestamp: 1636273184\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 879648\n",
      "  training_iteration: 88\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         36822.3</td><td style=\"text-align: right;\">879648</td><td style=\"text-align: right;\"> 6.59813</td><td style=\"text-align: right;\">               13.16</td><td style=\"text-align: right;\">                0.52</td><td style=\"text-align: right;\">             66.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 889644\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_08-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 65.57236842105263\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.150000000000013\n",
      "  episode_reward_mean: 6.673289473684219\n",
      "  episode_reward_min: 0.7799999999999992\n",
      "  episodes_this_iter: 152\n",
      "  episodes_total: 11378\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.916105506562779\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01672490643127442\n",
      "          policy_loss: -0.06187501373565477\n",
      "          total_loss: 0.1716296785367796\n",
      "          vf_explained_var: 0.9582705497741699\n",
      "          vf_loss: 0.22726479680237607\n",
      "    num_agent_steps_sampled: 889644\n",
      "    num_agent_steps_trained: 889644\n",
      "    num_steps_sampled: 889644\n",
      "    num_steps_trained: 889644\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.88766467065868\n",
      "    ram_util_percent: 59.98694610778442\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04126891114338665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.968471381034718\n",
      "    mean_inference_ms: 2.382497226510358\n",
      "    mean_raw_obs_processing_ms: 66.2331816093714\n",
      "  time_since_restore: 37407.332080841064\n",
      "  time_this_iter_s: 585.0609810352325\n",
      "  time_total_s: 37407.332080841064\n",
      "  timers:\n",
      "    learn_throughput: 1055.419\n",
      "    learn_time_ms: 9471.119\n",
      "    load_throughput: 91293.95\n",
      "    load_time_ms: 109.492\n",
      "    sample_throughput: 20.156\n",
      "    sample_time_ms: 495930.865\n",
      "    update_time_ms: 7.02\n",
      "  timestamp: 1636273769\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 889644\n",
      "  training_iteration: 89\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         37407.3</td><td style=\"text-align: right;\">889644</td><td style=\"text-align: right;\"> 6.67329</td><td style=\"text-align: right;\">               13.15</td><td style=\"text-align: right;\">                0.78</td><td style=\"text-align: right;\">           65.5724</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 899640\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_08-37-01\n",
      "  done: false\n",
      "  episode_len_mean: 72.06474820143885\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.060000000000013\n",
      "  episode_reward_mean: 6.509352517985621\n",
      "  episode_reward_min: 0.6900000000000038\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 11517\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9607391949392792\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015235866916613999\n",
      "          policy_loss: -0.06291615349742083\n",
      "          total_loss: 0.1185712705931475\n",
      "          vf_explained_var: 0.9592134952545166\n",
      "          vf_loss: 0.17795534312215625\n",
      "    num_agent_steps_sampled: 899640\n",
      "    num_agent_steps_trained: 899640\n",
      "    num_steps_sampled: 899640\n",
      "    num_steps_trained: 899640\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.8276397515528\n",
      "    ram_util_percent: 60.093788819875776\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04126459522707026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.99769534640026\n",
      "    mean_inference_ms: 2.3834246424007457\n",
      "    mean_raw_obs_processing_ms: 66.30944381613396\n",
      "  time_since_restore: 37859.1180999279\n",
      "  time_this_iter_s: 451.78601908683777\n",
      "  time_total_s: 37859.1180999279\n",
      "  timers:\n",
      "    learn_throughput: 1055.675\n",
      "    learn_time_ms: 9468.825\n",
      "    load_throughput: 91242.433\n",
      "    load_time_ms: 109.554\n",
      "    sample_throughput: 20.543\n",
      "    sample_time_ms: 486581.228\n",
      "    update_time_ms: 7.586\n",
      "  timestamp: 1636274221\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 899640\n",
      "  training_iteration: 90\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         37859.1</td><td style=\"text-align: right;\">899640</td><td style=\"text-align: right;\"> 6.50935</td><td style=\"text-align: right;\">               13.06</td><td style=\"text-align: right;\">                0.69</td><td style=\"text-align: right;\">           72.0647</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 909636\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_08-44-49\n",
      "  done: false\n",
      "  episode_len_mean: 72.32608695652173\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.740000000000023\n",
      "  episode_reward_mean: 6.0213043478260975\n",
      "  episode_reward_min: 0.1700000000000039\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 11655\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.992036510227073\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01712160928025029\n",
      "          policy_loss: -0.06499715113741719\n",
      "          total_loss: 0.14995474404173817\n",
      "          vf_explained_var: 0.9604886770248413\n",
      "          vf_loss: 0.20886881726228784\n",
      "    num_agent_steps_sampled: 909636\n",
      "    num_agent_steps_trained: 909636\n",
      "    num_steps_sampled: 909636\n",
      "    num_steps_trained: 909636\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.64880239520959\n",
      "    ram_util_percent: 60.23997005988024\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04126829273926675\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.033481990212366\n",
      "    mean_inference_ms: 2.38346298642107\n",
      "    mean_raw_obs_processing_ms: 66.54598753999201\n",
      "  time_since_restore: 38327.080614089966\n",
      "  time_this_iter_s: 467.9625141620636\n",
      "  time_total_s: 38327.080614089966\n",
      "  timers:\n",
      "    learn_throughput: 1055.585\n",
      "    learn_time_ms: 9469.631\n",
      "    load_throughput: 90990.868\n",
      "    load_time_ms: 109.857\n",
      "    sample_throughput: 20.804\n",
      "    sample_time_ms: 480477.872\n",
      "    update_time_ms: 7.138\n",
      "  timestamp: 1636274689\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 909636\n",
      "  training_iteration: 91\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         38327.1</td><td style=\"text-align: right;\">909636</td><td style=\"text-align: right;\">  6.0213</td><td style=\"text-align: right;\">               13.74</td><td style=\"text-align: right;\">                0.17</td><td style=\"text-align: right;\">           72.3261</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 919632\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_08-52-58\n",
      "  done: false\n",
      "  episode_len_mean: 75.78625954198473\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.140000000000013\n",
      "  episode_reward_mean: 6.641908396946576\n",
      "  episode_reward_min: 0.689999999999999\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 11786\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9598894487079392\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016135574731944415\n",
      "          policy_loss: -0.06538624002988268\n",
      "          total_loss: 0.11861908761227233\n",
      "          vf_explained_var: 0.9609853029251099\n",
      "          vf_loss: 0.17909831866526452\n",
      "    num_agent_steps_sampled: 919632\n",
      "    num_agent_steps_trained: 919632\n",
      "    num_steps_sampled: 919632\n",
      "    num_steps_trained: 919632\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.83008595988538\n",
      "    ram_util_percent: 60.35085959885386\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04127901692921699\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.054412881440097\n",
      "    mean_inference_ms: 2.3829838115735478\n",
      "    mean_raw_obs_processing_ms: 66.71314986749265\n",
      "  time_since_restore: 38816.09965181351\n",
      "  time_this_iter_s: 489.01903772354126\n",
      "  time_total_s: 38816.09965181351\n",
      "  timers:\n",
      "    learn_throughput: 1056.425\n",
      "    learn_time_ms: 9462.097\n",
      "    load_throughput: 90867.555\n",
      "    load_time_ms: 110.006\n",
      "    sample_throughput: 20.413\n",
      "    sample_time_ms: 489685.858\n",
      "    update_time_ms: 6.987\n",
      "  timestamp: 1636275178\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 919632\n",
      "  training_iteration: 92\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         38816.1</td><td style=\"text-align: right;\">919632</td><td style=\"text-align: right;\"> 6.64191</td><td style=\"text-align: right;\">               13.14</td><td style=\"text-align: right;\">                0.69</td><td style=\"text-align: right;\">           75.7863</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 929628\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_09-01-03\n",
      "  done: false\n",
      "  episode_len_mean: 77.55038759689923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.140000000000015\n",
      "  episode_reward_mean: 6.809069767441872\n",
      "  episode_reward_min: 0.45000000000000207\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 11915\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9597204053503836\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018634866710390566\n",
      "          policy_loss: -0.06305280226863857\n",
      "          total_loss: 0.15792404336488655\n",
      "          vf_explained_var: 0.95921391248703\n",
      "          vf_loss: 0.21227234629675365\n",
      "    num_agent_steps_sampled: 929628\n",
      "    num_agent_steps_trained: 929628\n",
      "    num_steps_sampled: 929628\n",
      "    num_steps_trained: 929628\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.04646464646464\n",
      "    ram_util_percent: 60.64646464646464\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04126199833624309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.060953239023323\n",
      "    mean_inference_ms: 2.3837147646274213\n",
      "    mean_raw_obs_processing_ms: 66.5696518858687\n",
      "  time_since_restore: 39301.644936561584\n",
      "  time_this_iter_s: 485.5452847480774\n",
      "  time_total_s: 39301.644936561584\n",
      "  timers:\n",
      "    learn_throughput: 1056.11\n",
      "    learn_time_ms: 9464.921\n",
      "    load_throughput: 89672.37\n",
      "    load_time_ms: 111.472\n",
      "    sample_throughput: 20.12\n",
      "    sample_time_ms: 496811.006\n",
      "    update_time_ms: 7.142\n",
      "  timestamp: 1636275663\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 929628\n",
      "  training_iteration: 93\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         39301.6</td><td style=\"text-align: right;\">929628</td><td style=\"text-align: right;\"> 6.80907</td><td style=\"text-align: right;\">               13.14</td><td style=\"text-align: right;\">                0.45</td><td style=\"text-align: right;\">           77.5504</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 939624\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_09-09-15\n",
      "  done: false\n",
      "  episode_len_mean: 72.83333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.150000000000013\n",
      "  episode_reward_mean: 6.534275362318851\n",
      "  episode_reward_min: 0.8499999999999991\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 12053\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9717351880847898\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015672205934206127\n",
      "          policy_loss: -0.06620374041744786\n",
      "          total_loss: 0.10661401526572613\n",
      "          vf_explained_var: 0.9659060835838318\n",
      "          vf_loss: 0.16873294503834002\n",
      "    num_agent_steps_sampled: 939624\n",
      "    num_agent_steps_trained: 939624\n",
      "    num_steps_sampled: 939624\n",
      "    num_steps_trained: 939624\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.52849002849003\n",
      "    ram_util_percent: 60.71253561253561\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04127889606705022\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.111042858193517\n",
      "    mean_inference_ms: 2.383139663468915\n",
      "    mean_raw_obs_processing_ms: 66.90507660085976\n",
      "  time_since_restore: 39793.643293619156\n",
      "  time_this_iter_s: 491.9983570575714\n",
      "  time_total_s: 39793.643293619156\n",
      "  timers:\n",
      "    learn_throughput: 1055.729\n",
      "    learn_time_ms: 9468.341\n",
      "    load_throughput: 89488.493\n",
      "    load_time_ms: 111.702\n",
      "    sample_throughput: 19.915\n",
      "    sample_time_ms: 501941.662\n",
      "    update_time_ms: 7.018\n",
      "  timestamp: 1636276155\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 939624\n",
      "  training_iteration: 94\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         39793.6</td><td style=\"text-align: right;\">939624</td><td style=\"text-align: right;\"> 6.53428</td><td style=\"text-align: right;\">               13.15</td><td style=\"text-align: right;\">                0.85</td><td style=\"text-align: right;\">           72.8333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 949620\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_09-17-54\n",
      "  done: false\n",
      "  episode_len_mean: 74.06716417910448\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.740000000000023\n",
      "  episode_reward_mean: 6.8712686567164285\n",
      "  episode_reward_min: 0.6099999999999989\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 12187\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9580311856718144\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017295603615489315\n",
      "          policy_loss: -0.06694112633808683\n",
      "          total_loss: 0.12594817188751495\n",
      "          vf_explained_var: 0.9623190760612488\n",
      "          vf_loss: 0.18620191252129709\n",
      "    num_agent_steps_sampled: 949620\n",
      "    num_agent_steps_trained: 949620\n",
      "    num_steps_sampled: 949620\n",
      "    num_steps_trained: 949620\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.44445945945947\n",
      "    ram_util_percent: 60.91918918918918\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041237284937945415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.09778026026578\n",
      "    mean_inference_ms: 2.383015437076005\n",
      "    mean_raw_obs_processing_ms: 67.10263465001258\n",
      "  time_since_restore: 40311.97742509842\n",
      "  time_this_iter_s: 518.3341314792633\n",
      "  time_total_s: 40311.97742509842\n",
      "  timers:\n",
      "    learn_throughput: 1056.031\n",
      "    learn_time_ms: 9465.633\n",
      "    load_throughput: 89515.433\n",
      "    load_time_ms: 111.668\n",
      "    sample_throughput: 20.078\n",
      "    sample_time_ms: 497862.942\n",
      "    update_time_ms: 6.921\n",
      "  timestamp: 1636276674\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 949620\n",
      "  training_iteration: 95\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">           40312</td><td style=\"text-align: right;\">949620</td><td style=\"text-align: right;\"> 6.87127</td><td style=\"text-align: right;\">               13.74</td><td style=\"text-align: right;\">                0.61</td><td style=\"text-align: right;\">           74.0672</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 959616\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_09-24-59\n",
      "  done: false\n",
      "  episode_len_mean: 76.11363636363636\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.16000000000001\n",
      "  episode_reward_mean: 6.6692424242424355\n",
      "  episode_reward_min: 0.6300000000000137\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 12319\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.96193465442739\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01739579340319158\n",
      "          policy_loss: -0.0638120859893214\n",
      "          total_loss: 0.1659320669583021\n",
      "          vf_explained_var: 0.9567668437957764\n",
      "          vf_loss: 0.22294363842751735\n",
      "    num_agent_steps_sampled: 959616\n",
      "    num_agent_steps_trained: 959616\n",
      "    num_steps_sampled: 959616\n",
      "    num_steps_trained: 959616\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.4980198019802\n",
      "    ram_util_percent: 60.82343234323432\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04128064692707627\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.13350219731705\n",
      "    mean_inference_ms: 2.383741566776566\n",
      "    mean_raw_obs_processing_ms: 66.99824812231545\n",
      "  time_since_restore: 40736.86441540718\n",
      "  time_this_iter_s: 424.8869903087616\n",
      "  time_total_s: 40736.86441540718\n",
      "  timers:\n",
      "    learn_throughput: 1056.791\n",
      "    learn_time_ms: 9458.827\n",
      "    load_throughput: 89486.449\n",
      "    load_time_ms: 111.704\n",
      "    sample_throughput: 20.399\n",
      "    sample_time_ms: 490014.609\n",
      "    update_time_ms: 7.908\n",
      "  timestamp: 1636277099\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 959616\n",
      "  training_iteration: 96\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         40736.9</td><td style=\"text-align: right;\">959616</td><td style=\"text-align: right;\"> 6.66924</td><td style=\"text-align: right;\">               13.16</td><td style=\"text-align: right;\">                0.63</td><td style=\"text-align: right;\">           76.1136</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 969612\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_09-34-19\n",
      "  done: false\n",
      "  episode_len_mean: 73.4014598540146\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.060000000000013\n",
      "  episode_reward_mean: 6.3988321167883315\n",
      "  episode_reward_min: -1.270000000000001\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 12456\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9678082560881591\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015743040149504357\n",
      "          policy_loss: -0.06603572685271501\n",
      "          total_loss: 0.14000381818996407\n",
      "          vf_explained_var: 0.9609586000442505\n",
      "          vf_loss: 0.20180788488787973\n",
      "    num_agent_steps_sampled: 969612\n",
      "    num_agent_steps_trained: 969612\n",
      "    num_steps_sampled: 969612\n",
      "    num_steps_trained: 969612\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.897375\n",
      "    ram_util_percent: 60.985375000000005\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04125053155067695\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.14407296131806\n",
      "    mean_inference_ms: 2.382995421370697\n",
      "    mean_raw_obs_processing_ms: 67.37970682203321\n",
      "  time_since_restore: 41297.685190200806\n",
      "  time_this_iter_s: 560.8207747936249\n",
      "  time_total_s: 41297.685190200806\n",
      "  timers:\n",
      "    learn_throughput: 1056.433\n",
      "    learn_time_ms: 9462.028\n",
      "    load_throughput: 89485.819\n",
      "    load_time_ms: 111.705\n",
      "    sample_throughput: 20.0\n",
      "    sample_time_ms: 499794.327\n",
      "    update_time_ms: 8.565\n",
      "  timestamp: 1636277659\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 969612\n",
      "  training_iteration: 97\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         41297.7</td><td style=\"text-align: right;\">969612</td><td style=\"text-align: right;\"> 6.39883</td><td style=\"text-align: right;\">               13.06</td><td style=\"text-align: right;\">               -1.27</td><td style=\"text-align: right;\">           73.4015</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 979608\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_09-43-54\n",
      "  done: false\n",
      "  episode_len_mean: 72.2043795620438\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.120000000000013\n",
      "  episode_reward_mean: 6.732919708029208\n",
      "  episode_reward_min: 0.540000000000007\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 12593\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9659313230433015\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016843675070435958\n",
      "          policy_loss: -0.06284683041720308\n",
      "          total_loss: 0.1498360829332318\n",
      "          vf_explained_var: 0.96296626329422\n",
      "          vf_loss: 0.20676089494019492\n",
      "    num_agent_steps_sampled: 979608\n",
      "    num_agent_steps_trained: 979608\n",
      "    num_steps_sampled: 979608\n",
      "    num_steps_trained: 979608\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.08853658536586\n",
      "    ram_util_percent: 61.03987804878049\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041300407644709845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.182068051566795\n",
      "    mean_inference_ms: 2.3827073949549673\n",
      "    mean_raw_obs_processing_ms: 67.55906539206387\n",
      "  time_since_restore: 41871.837389945984\n",
      "  time_this_iter_s: 574.1521997451782\n",
      "  time_total_s: 41871.837389945984\n",
      "  timers:\n",
      "    learn_throughput: 1056.873\n",
      "    learn_time_ms: 9458.086\n",
      "    load_throughput: 89372.473\n",
      "    load_time_ms: 111.847\n",
      "    sample_throughput: 20.179\n",
      "    sample_time_ms: 495365.408\n",
      "    update_time_ms: 8.533\n",
      "  timestamp: 1636278234\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 979608\n",
      "  training_iteration: 98\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         41871.8</td><td style=\"text-align: right;\">979608</td><td style=\"text-align: right;\"> 6.73292</td><td style=\"text-align: right;\">               13.12</td><td style=\"text-align: right;\">                0.54</td><td style=\"text-align: right;\">           72.2044</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 989604\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_09-51-29\n",
      "  done: false\n",
      "  episode_len_mean: 71.96428571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.200000000000012\n",
      "  episode_reward_mean: 6.723357142857154\n",
      "  episode_reward_min: 0.4900000000000093\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 12733\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9588560407997198\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01632236647459309\n",
      "          policy_loss: -0.061292891578478184\n",
      "          total_loss: 0.15773566887101048\n",
      "          vf_explained_var: 0.9673821926116943\n",
      "          vf_loss: 0.21382752723323228\n",
      "    num_agent_steps_sampled: 989604\n",
      "    num_agent_steps_trained: 989604\n",
      "    num_steps_sampled: 989604\n",
      "    num_steps_trained: 989604\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.52650231124807\n",
      "    ram_util_percent: 60.95654853620956\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041291157697853215\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.216655331537822\n",
      "    mean_inference_ms: 2.384025849081743\n",
      "    mean_raw_obs_processing_ms: 67.60103062261994\n",
      "  time_since_restore: 42326.95874214172\n",
      "  time_this_iter_s: 455.12135219573975\n",
      "  time_total_s: 42326.95874214172\n",
      "  timers:\n",
      "    learn_throughput: 1056.425\n",
      "    learn_time_ms: 9462.096\n",
      "    load_throughput: 89313.454\n",
      "    load_time_ms: 111.92\n",
      "    sample_throughput: 20.723\n",
      "    sample_time_ms: 482366.125\n",
      "    update_time_ms: 9.5\n",
      "  timestamp: 1636278689\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 989604\n",
      "  training_iteration: 99\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">           42327</td><td style=\"text-align: right;\">989604</td><td style=\"text-align: right;\"> 6.72336</td><td style=\"text-align: right;\">                13.2</td><td style=\"text-align: right;\">                0.49</td><td style=\"text-align: right;\">           71.9643</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 999600\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_09-59-27\n",
      "  done: false\n",
      "  episode_len_mean: 76.07692307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.930000000000023\n",
      "  episode_reward_mean: 7.1128461538461645\n",
      "  episode_reward_min: 0.28999999999999926\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 12863\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9588598445949392\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019368911758238197\n",
      "          policy_loss: -0.06133038869453992\n",
      "          total_loss: 0.20236434711095613\n",
      "          vf_explained_var: 0.9537079930305481\n",
      "          vf_loss: 0.25386680093649616\n",
      "    num_agent_steps_sampled: 999600\n",
      "    num_agent_steps_trained: 999600\n",
      "    num_steps_sampled: 999600\n",
      "    num_steps_trained: 999600\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.76319648093842\n",
      "    ram_util_percent: 61.19897360703812\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04127193227153558\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.2238112139559\n",
      "    mean_inference_ms: 2.3833782603051445\n",
      "    mean_raw_obs_processing_ms: 67.78030288526355\n",
      "  time_since_restore: 42805.09620857239\n",
      "  time_this_iter_s: 478.13746643066406\n",
      "  time_total_s: 42805.09620857239\n",
      "  timers:\n",
      "    learn_throughput: 1055.54\n",
      "    learn_time_ms: 9470.031\n",
      "    load_throughput: 89167.971\n",
      "    load_time_ms: 112.103\n",
      "    sample_throughput: 20.611\n",
      "    sample_time_ms: 484993.341\n",
      "    update_time_ms: 9.218\n",
      "  timestamp: 1636279167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 999600\n",
      "  training_iteration: 100\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         42805.1</td><td style=\"text-align: right;\">999600</td><td style=\"text-align: right;\"> 7.11285</td><td style=\"text-align: right;\">               13.93</td><td style=\"text-align: right;\">                0.29</td><td style=\"text-align: right;\">           76.0769</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1009596\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_10-06-33\n",
      "  done: false\n",
      "  episode_len_mean: 75.78030303030303\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.090000000000012\n",
      "  episode_reward_mean: 6.453181818181829\n",
      "  episode_reward_min: 0.19999999999999896\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 12995\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.989652015408899\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01557601890590079\n",
      "          policy_loss: -0.06704330015648953\n",
      "          total_loss: 0.13293330783868193\n",
      "          vf_explained_var: 0.9581604599952698\n",
      "          vf_loss: 0.19621704941949783\n",
      "    num_agent_steps_sampled: 1009596\n",
      "    num_agent_steps_trained: 1009596\n",
      "    num_steps_sampled: 1009596\n",
      "    num_steps_trained: 1009596\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.5814144736842\n",
      "    ram_util_percent: 61.199506578947364\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04129350553946674\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.261188382542656\n",
      "    mean_inference_ms: 2.3834355660010798\n",
      "    mean_raw_obs_processing_ms: 67.80624629990815\n",
      "  time_since_restore: 43230.849783182144\n",
      "  time_this_iter_s: 425.75357460975647\n",
      "  time_total_s: 43230.849783182144\n",
      "  timers:\n",
      "    learn_throughput: 1055.254\n",
      "    learn_time_ms: 9472.602\n",
      "    load_throughput: 89255.709\n",
      "    load_time_ms: 111.993\n",
      "    sample_throughput: 20.792\n",
      "    sample_time_ms: 480770.665\n",
      "    update_time_ms: 8.624\n",
      "  timestamp: 1636279593\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1009596\n",
      "  training_iteration: 101\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         43230.8</td><td style=\"text-align: right;\">1009596</td><td style=\"text-align: right;\"> 6.45318</td><td style=\"text-align: right;\">               13.09</td><td style=\"text-align: right;\">                 0.2</td><td style=\"text-align: right;\">           75.7803</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1019592\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_10-12-49\n",
      "  done: false\n",
      "  episode_len_mean: 83.24793388429752\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000022\n",
      "  episode_reward_mean: 6.417933884297533\n",
      "  episode_reward_min: 0.20999999999999908\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 13116\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.000498284132053\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019115124078971164\n",
      "          policy_loss: -0.06361597511344232\n",
      "          total_loss: 0.19341323748708536\n",
      "          vf_explained_var: 0.951671838760376\n",
      "          vf_loss: 0.24800310086809163\n",
      "    num_agent_steps_sampled: 1019592\n",
      "    num_agent_steps_trained: 1019592\n",
      "    num_steps_sampled: 1019592\n",
      "    num_steps_trained: 1019592\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.53258845437617\n",
      "    ram_util_percent: 61.41024208566108\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041284864746255576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.291337901023184\n",
      "    mean_inference_ms: 2.3838445026953776\n",
      "    mean_raw_obs_processing_ms: 67.68471065873895\n",
      "  time_since_restore: 43607.15731072426\n",
      "  time_this_iter_s: 376.30752754211426\n",
      "  time_total_s: 43607.15731072426\n",
      "  timers:\n",
      "    learn_throughput: 1055.079\n",
      "    learn_time_ms: 9474.176\n",
      "    load_throughput: 89294.47\n",
      "    load_time_ms: 111.944\n",
      "    sample_throughput: 21.291\n",
      "    sample_time_ms: 469498.135\n",
      "    update_time_ms: 8.984\n",
      "  timestamp: 1636279969\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1019592\n",
      "  training_iteration: 102\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         43607.2</td><td style=\"text-align: right;\">1019592</td><td style=\"text-align: right;\"> 6.41793</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                0.21</td><td style=\"text-align: right;\">           83.2479</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1029588\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_10-21-51\n",
      "  done: false\n",
      "  episode_len_mean: 73.37956204379562\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.23000000000001\n",
      "  episode_reward_mean: 6.972116788321178\n",
      "  episode_reward_min: 0.47000000000001063\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 13253\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9503994783784588\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017270510777481683\n",
      "          policy_loss: -0.05977771165820523\n",
      "          total_loss: 0.19015953180292605\n",
      "          vf_explained_var: 0.9600978493690491\n",
      "          vf_loss: 0.2432116504296915\n",
      "    num_agent_steps_sampled: 1029588\n",
      "    num_agent_steps_trained: 1029588\n",
      "    num_steps_sampled: 1029588\n",
      "    num_steps_trained: 1029588\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.6593023255814\n",
      "    ram_util_percent: 61.421834625322994\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04127472820012994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.315863223634803\n",
      "    mean_inference_ms: 2.3837215592754872\n",
      "    mean_raw_obs_processing_ms: 67.98421117431744\n",
      "  time_since_restore: 44149.5949318409\n",
      "  time_this_iter_s: 542.4376211166382\n",
      "  time_total_s: 44149.5949318409\n",
      "  timers:\n",
      "    learn_throughput: 1055.505\n",
      "    learn_time_ms: 9470.35\n",
      "    load_throughput: 90683.103\n",
      "    load_time_ms: 110.23\n",
      "    sample_throughput: 21.036\n",
      "    sample_time_ms: 475193.16\n",
      "    update_time_ms: 8.914\n",
      "  timestamp: 1636280511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1029588\n",
      "  training_iteration: 103\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         44149.6</td><td style=\"text-align: right;\">1029588</td><td style=\"text-align: right;\"> 6.97212</td><td style=\"text-align: right;\">               13.23</td><td style=\"text-align: right;\">                0.47</td><td style=\"text-align: right;\">           73.3796</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1039584\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_10-29-49\n",
      "  done: false\n",
      "  episode_len_mean: 75.02255639097744\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.300000000000011\n",
      "  episode_reward_mean: 6.8440601503759515\n",
      "  episode_reward_min: 0.37000000000000755\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 13386\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9398967401594178\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019581972094898873\n",
      "          policy_loss: -0.061906063634679355\n",
      "          total_loss: 0.2302894369714981\n",
      "          vf_explained_var: 0.9501460790634155\n",
      "          vf_loss: 0.2818543490754743\n",
      "    num_agent_steps_sampled: 1039584\n",
      "    num_agent_steps_trained: 1039584\n",
      "    num_steps_sampled: 1039584\n",
      "    num_steps_trained: 1039584\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.15447870778267\n",
      "    ram_util_percent: 61.39251101321587\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041302782691303525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.33059911244759\n",
      "    mean_inference_ms: 2.3839772733907205\n",
      "    mean_raw_obs_processing_ms: 67.91379184722847\n",
      "  time_since_restore: 44627.13227915764\n",
      "  time_this_iter_s: 477.53734731674194\n",
      "  time_total_s: 44627.13227915764\n",
      "  timers:\n",
      "    learn_throughput: 1055.649\n",
      "    learn_time_ms: 9469.052\n",
      "    load_throughput: 90943.144\n",
      "    load_time_ms: 109.915\n",
      "    sample_throughput: 21.1\n",
      "    sample_time_ms: 473747.992\n",
      "    update_time_ms: 9.519\n",
      "  timestamp: 1636280989\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1039584\n",
      "  training_iteration: 104\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         44627.1</td><td style=\"text-align: right;\">1039584</td><td style=\"text-align: right;\"> 6.84406</td><td style=\"text-align: right;\">                13.3</td><td style=\"text-align: right;\">                0.37</td><td style=\"text-align: right;\">           75.0226</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1049580\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_10-38-08\n",
      "  done: false\n",
      "  episode_len_mean: 72.44927536231884\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.120000000000013\n",
      "  episode_reward_mean: 6.534637681159431\n",
      "  episode_reward_min: 0.870000000000006\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 13524\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9866827788515988\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015754199450227113\n",
      "          policy_loss: -0.06640081176590015\n",
      "          total_loss: 0.1301200934490746\n",
      "          vf_explained_var: 0.963744580745697\n",
      "          vf_loss: 0.1924610428384736\n",
      "    num_agent_steps_sampled: 1049580\n",
      "    num_agent_steps_trained: 1049580\n",
      "    num_steps_sampled: 1049580\n",
      "    num_steps_trained: 1049580\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.76535764375876\n",
      "    ram_util_percent: 61.493267882187936\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04129908443036269\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.338551838589773\n",
      "    mean_inference_ms: 2.3845188951489322\n",
      "    mean_raw_obs_processing_ms: 68.04502390309001\n",
      "  time_since_restore: 45126.503834724426\n",
      "  time_this_iter_s: 499.3715555667877\n",
      "  time_total_s: 45126.503834724426\n",
      "  timers:\n",
      "    learn_throughput: 1055.704\n",
      "    learn_time_ms: 9468.563\n",
      "    load_throughput: 91093.532\n",
      "    load_time_ms: 109.733\n",
      "    sample_throughput: 21.185\n",
      "    sample_time_ms: 471852.468\n",
      "    update_time_ms: 9.697\n",
      "  timestamp: 1636281488\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1049580\n",
      "  training_iteration: 105\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         45126.5</td><td style=\"text-align: right;\">1049580</td><td style=\"text-align: right;\"> 6.53464</td><td style=\"text-align: right;\">               13.12</td><td style=\"text-align: right;\">                0.87</td><td style=\"text-align: right;\">           72.4493</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1059576\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_10-46-27\n",
      "  done: false\n",
      "  episode_len_mean: 75.68702290076335\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.18000000000001\n",
      "  episode_reward_mean: 6.5445801526717675\n",
      "  episode_reward_min: 0.9800000000000046\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 13655\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9880942145983378\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018279342094082295\n",
      "          policy_loss: -0.060896016058758794\n",
      "          total_loss: 0.16804654910786349\n",
      "          vf_explained_var: 0.9545044898986816\n",
      "          vf_loss: 0.22106175719418078\n",
      "    num_agent_steps_sampled: 1059576\n",
      "    num_agent_steps_trained: 1059576\n",
      "    num_steps_sampled: 1059576\n",
      "    num_steps_trained: 1059576\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.50014064697609\n",
      "    ram_util_percent: 61.67201125175809\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041277706704784006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.357071656870826\n",
      "    mean_inference_ms: 2.383845057018396\n",
      "    mean_raw_obs_processing_ms: 68.32665109764707\n",
      "  time_since_restore: 45624.7374997139\n",
      "  time_this_iter_s: 498.23366498947144\n",
      "  time_total_s: 45624.7374997139\n",
      "  timers:\n",
      "    learn_throughput: 1054.376\n",
      "    learn_time_ms: 9480.492\n",
      "    load_throughput: 91038.425\n",
      "    load_time_ms: 109.8\n",
      "    sample_throughput: 20.861\n",
      "    sample_time_ms: 479175.477\n",
      "    update_time_ms: 9.294\n",
      "  timestamp: 1636281987\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1059576\n",
      "  training_iteration: 106\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         45624.7</td><td style=\"text-align: right;\">1059576</td><td style=\"text-align: right;\"> 6.54458</td><td style=\"text-align: right;\">               13.18</td><td style=\"text-align: right;\">                0.98</td><td style=\"text-align: right;\">            75.687</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1069572\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_10-53-55\n",
      "  done: false\n",
      "  episode_len_mean: 76.07575757575758\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.080000000000013\n",
      "  episode_reward_mean: 7.048030303030314\n",
      "  episode_reward_min: 0.610000000000008\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 13787\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9486252482120807\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018821525360842504\n",
      "          policy_loss: -0.06464985737688521\n",
      "          total_loss: 0.21941518550818292\n",
      "          vf_explained_var: 0.9493147134780884\n",
      "          vf_loss: 0.27496610373640673\n",
      "    num_agent_steps_sampled: 1069572\n",
      "    num_agent_steps_trained: 1069572\n",
      "    num_steps_sampled: 1069572\n",
      "    num_steps_trained: 1069572\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.34413145539905\n",
      "    ram_util_percent: 61.698904538341154\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041299315034674815\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.388532797357723\n",
      "    mean_inference_ms: 2.3846914082452675\n",
      "    mean_raw_obs_processing_ms: 68.2014995836965\n",
      "  time_since_restore: 46072.80375242233\n",
      "  time_this_iter_s: 448.06625270843506\n",
      "  time_total_s: 46072.80375242233\n",
      "  timers:\n",
      "    learn_throughput: 1054.775\n",
      "    learn_time_ms: 9476.905\n",
      "    load_throughput: 91014.611\n",
      "    load_time_ms: 109.829\n",
      "    sample_throughput: 21.363\n",
      "    sample_time_ms: 467903.097\n",
      "    update_time_ms: 9.666\n",
      "  timestamp: 1636282435\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1069572\n",
      "  training_iteration: 107\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         46072.8</td><td style=\"text-align: right;\">1069572</td><td style=\"text-align: right;\"> 7.04803</td><td style=\"text-align: right;\">               13.08</td><td style=\"text-align: right;\">                0.61</td><td style=\"text-align: right;\">           76.0758</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1079568\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_11-02-53\n",
      "  done: false\n",
      "  episode_len_mean: 71.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.120000000000013\n",
      "  episode_reward_mean: 6.688785714285724\n",
      "  episode_reward_min: 0.3899999999999989\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 13927\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.957770554530315\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0167547683698453\n",
      "          policy_loss: -0.06370890694391779\n",
      "          total_loss: 0.15719610650140123\n",
      "          vf_explained_var: 0.9619985818862915\n",
      "          vf_loss: 0.21503641551567448\n",
      "    num_agent_steps_sampled: 1079568\n",
      "    num_agent_steps_trained: 1079568\n",
      "    num_steps_sampled: 1079568\n",
      "    num_steps_trained: 1079568\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.88400520156046\n",
      "    ram_util_percent: 61.78413524057217\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041314068611367945\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.417037846768505\n",
      "    mean_inference_ms: 2.3842661052941674\n",
      "    mean_raw_obs_processing_ms: 68.47345048069123\n",
      "  time_since_restore: 46611.24425697327\n",
      "  time_this_iter_s: 538.4405045509338\n",
      "  time_total_s: 46611.24425697327\n",
      "  timers:\n",
      "    learn_throughput: 1053.727\n",
      "    learn_time_ms: 9486.325\n",
      "    load_throughput: 91039.651\n",
      "    load_time_ms: 109.798\n",
      "    sample_throughput: 21.528\n",
      "    sample_time_ms: 464321.746\n",
      "    update_time_ms: 9.954\n",
      "  timestamp: 1636282973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1079568\n",
      "  training_iteration: 108\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         46611.2</td><td style=\"text-align: right;\">1079568</td><td style=\"text-align: right;\"> 6.68879</td><td style=\"text-align: right;\">               13.12</td><td style=\"text-align: right;\">                0.39</td><td style=\"text-align: right;\">             71.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1089564\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_11-10-03\n",
      "  done: false\n",
      "  episode_len_mean: 74.16911764705883\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.190000000000012\n",
      "  episode_reward_mean: 7.14389705882354\n",
      "  episode_reward_min: 0.5700000000000017\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 14063\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9331447803057158\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015617774330536046\n",
      "          policy_loss: -0.06644396259743943\n",
      "          total_loss: 0.10359196055791954\n",
      "          vf_explained_var: 0.9740480780601501\n",
      "          vf_loss: 0.16564787741846\n",
      "    num_agent_steps_sampled: 1089564\n",
      "    num_agent_steps_trained: 1089564\n",
      "    num_steps_sampled: 1089564\n",
      "    num_steps_trained: 1089564\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.42006525285481\n",
      "    ram_util_percent: 61.7463295269168\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04130398375910406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.4295551849883\n",
      "    mean_inference_ms: 2.385109218924986\n",
      "    mean_raw_obs_processing_ms: 68.50373008074745\n",
      "  time_since_restore: 47041.378925323486\n",
      "  time_this_iter_s: 430.1346683502197\n",
      "  time_total_s: 47041.378925323486\n",
      "  timers:\n",
      "    learn_throughput: 1054.328\n",
      "    learn_time_ms: 9480.924\n",
      "    load_throughput: 91009.889\n",
      "    load_time_ms: 109.834\n",
      "    sample_throughput: 21.644\n",
      "    sample_time_ms: 461829.885\n",
      "    update_time_ms: 8.994\n",
      "  timestamp: 1636283403\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1089564\n",
      "  training_iteration: 109\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         47041.4</td><td style=\"text-align: right;\">1089564</td><td style=\"text-align: right;\">  7.1439</td><td style=\"text-align: right;\">               13.19</td><td style=\"text-align: right;\">                0.57</td><td style=\"text-align: right;\">           74.1691</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1099560\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_11-17-13\n",
      "  done: false\n",
      "  episode_len_mean: 81.1639344262295\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.110000000000012\n",
      "  episode_reward_mean: 6.7513934426229625\n",
      "  episode_reward_min: 0.5799999999999987\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 14185\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9658964401636367\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017279322994223002\n",
      "          policy_loss: -0.0678972048816295\n",
      "          total_loss: 0.13049507704046037\n",
      "          vf_explained_var: 0.962393045425415\n",
      "          vf_loss: 0.19180827589753346\n",
      "    num_agent_steps_sampled: 1099560\n",
      "    num_agent_steps_trained: 1099560\n",
      "    num_steps_sampled: 1099560\n",
      "    num_steps_trained: 1099560\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.10504885993485\n",
      "    ram_util_percent: 62.102605863192196\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041271424920261805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.455451875801874\n",
      "    mean_inference_ms: 2.3849696372978073\n",
      "    mean_raw_obs_processing_ms: 68.56487442554806\n",
      "  time_since_restore: 47471.05664753914\n",
      "  time_this_iter_s: 429.67772221565247\n",
      "  time_total_s: 47471.05664753914\n",
      "  timers:\n",
      "    learn_throughput: 1054.959\n",
      "    learn_time_ms: 9475.248\n",
      "    load_throughput: 91098.184\n",
      "    load_time_ms: 109.728\n",
      "    sample_throughput: 21.874\n",
      "    sample_time_ms: 456989.635\n",
      "    update_time_ms: 9.004\n",
      "  timestamp: 1636283833\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1099560\n",
      "  training_iteration: 110\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         47471.1</td><td style=\"text-align: right;\">1099560</td><td style=\"text-align: right;\"> 6.75139</td><td style=\"text-align: right;\">               13.11</td><td style=\"text-align: right;\">                0.58</td><td style=\"text-align: right;\">           81.1639</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1109556\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_11-23-59\n",
      "  done: false\n",
      "  episode_len_mean: 75.90151515151516\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.080000000000021\n",
      "  episode_reward_mean: 6.404469696969708\n",
      "  episode_reward_min: 0.5099999999999993\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 14317\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9881009569534889\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015739135069049757\n",
      "          policy_loss: -0.06517239350777788\n",
      "          total_loss: 0.14506495464911573\n",
      "          vf_explained_var: 0.9581125378608704\n",
      "          vf_loss: 0.20621454734832811\n",
      "    num_agent_steps_sampled: 1109556\n",
      "    num_agent_steps_trained: 1109556\n",
      "    num_steps_sampled: 1109556\n",
      "    num_steps_trained: 1109556\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.82923875432526\n",
      "    ram_util_percent: 62.03269896193772\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04130645373527273\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.477757430223903\n",
      "    mean_inference_ms: 2.3851985916510983\n",
      "    mean_raw_obs_processing_ms: 68.42868951703235\n",
      "  time_since_restore: 47876.65699982643\n",
      "  time_this_iter_s: 405.6003522872925\n",
      "  time_total_s: 47876.65699982643\n",
      "  timers:\n",
      "    learn_throughput: 1055.702\n",
      "    learn_time_ms: 9468.585\n",
      "    load_throughput: 91002.126\n",
      "    load_time_ms: 109.844\n",
      "    sample_throughput: 21.97\n",
      "    sample_time_ms: 454980.532\n",
      "    update_time_ms: 9.31\n",
      "  timestamp: 1636284239\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1109556\n",
      "  training_iteration: 111\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         47876.7</td><td style=\"text-align: right;\">1109556</td><td style=\"text-align: right;\"> 6.40447</td><td style=\"text-align: right;\">               14.08</td><td style=\"text-align: right;\">                0.51</td><td style=\"text-align: right;\">           75.9015</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1119552\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_11-32-19\n",
      "  done: false\n",
      "  episode_len_mean: 71.95652173913044\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.080000000000014\n",
      "  episode_reward_mean: 6.505869565217402\n",
      "  episode_reward_min: 0.1499999999999991\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 14455\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9695377122642648\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01829005864330086\n",
      "          policy_loss: -0.06133826453334246\n",
      "          total_loss: 0.17706851073676066\n",
      "          vf_explained_var: 0.962715744972229\n",
      "          vf_loss: 0.23032412678321712\n",
      "    num_agent_steps_sampled: 1119552\n",
      "    num_agent_steps_trained: 1119552\n",
      "    num_steps_sampled: 1119552\n",
      "    num_steps_trained: 1119552\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.1298319327731\n",
      "    ram_util_percent: 62.04285714285715\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04129630889410456\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.503582046727903\n",
      "    mean_inference_ms: 2.3848239193469896\n",
      "    mean_raw_obs_processing_ms: 68.72341485019834\n",
      "  time_since_restore: 48376.58418345451\n",
      "  time_this_iter_s: 499.9271836280823\n",
      "  time_total_s: 48376.58418345451\n",
      "  timers:\n",
      "    learn_throughput: 1055.038\n",
      "    learn_time_ms: 9474.541\n",
      "    load_throughput: 91042.399\n",
      "    load_time_ms: 109.795\n",
      "    sample_throughput: 21.389\n",
      "    sample_time_ms: 467335.971\n",
      "    update_time_ms: 9.928\n",
      "  timestamp: 1636284739\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1119552\n",
      "  training_iteration: 112\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         48376.6</td><td style=\"text-align: right;\">1119552</td><td style=\"text-align: right;\"> 6.50587</td><td style=\"text-align: right;\">               13.08</td><td style=\"text-align: right;\">                0.15</td><td style=\"text-align: right;\">           71.9565</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1129548\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_11-41-57\n",
      "  done: false\n",
      "  episode_len_mean: 74.34558823529412\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.210000000000013\n",
      "  episode_reward_mean: 7.326838235294128\n",
      "  episode_reward_min: 0.6900000000000016\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 14591\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.936995648828327\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016131521573817285\n",
      "          policy_loss: -0.06120770022464104\n",
      "          total_loss: 0.14329509602951157\n",
      "          vf_explained_var: 0.9682201147079468\n",
      "          vf_loss: 0.19937300519842624\n",
      "    num_agent_steps_sampled: 1129548\n",
      "    num_agent_steps_trained: 1129548\n",
      "    num_steps_sampled: 1129548\n",
      "    num_steps_trained: 1129548\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.74424242424243\n",
      "    ram_util_percent: 62.44036363636364\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04131237023905824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.5382450626842\n",
      "    mean_inference_ms: 2.384792095885677\n",
      "    mean_raw_obs_processing_ms: 68.7974196033293\n",
      "  time_since_restore: 48954.88369345665\n",
      "  time_this_iter_s: 578.2995100021362\n",
      "  time_total_s: 48954.88369345665\n",
      "  timers:\n",
      "    learn_throughput: 1055.405\n",
      "    learn_time_ms: 9471.246\n",
      "    load_throughput: 90789.929\n",
      "    load_time_ms: 110.1\n",
      "    sample_throughput: 21.226\n",
      "    sample_time_ms: 470923.804\n",
      "    update_time_ms: 11.221\n",
      "  timestamp: 1636285317\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1129548\n",
      "  training_iteration: 113\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         48954.9</td><td style=\"text-align: right;\">1129548</td><td style=\"text-align: right;\"> 7.32684</td><td style=\"text-align: right;\">               13.21</td><td style=\"text-align: right;\">                0.69</td><td style=\"text-align: right;\">           74.3456</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1139544\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_11-49-49\n",
      "  done: false\n",
      "  episode_len_mean: 72.97777777777777\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.12000000000001\n",
      "  episode_reward_mean: 6.583407407407417\n",
      "  episode_reward_min: 0.49000000000000143\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 14726\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9701714229379963\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01585199231720779\n",
      "          policy_loss: -0.06275592167328438\n",
      "          total_loss: 0.12993844379034117\n",
      "          vf_explained_var: 0.9675049781799316\n",
      "          vf_loss: 0.18832086626217406\n",
      "    num_agent_steps_sampled: 1139544\n",
      "    num_agent_steps_trained: 1139544\n",
      "    num_steps_sampled: 1139544\n",
      "    num_steps_trained: 1139544\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.96671619613669\n",
      "    ram_util_percent: 62.26909361069838\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041291528153765196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.558827929821454\n",
      "    mean_inference_ms: 2.385668776112185\n",
      "    mean_raw_obs_processing_ms: 68.8848906149466\n",
      "  time_since_restore: 49426.40119290352\n",
      "  time_this_iter_s: 471.5174994468689\n",
      "  time_total_s: 49426.40119290352\n",
      "  timers:\n",
      "    learn_throughput: 1055.838\n",
      "    learn_time_ms: 9467.365\n",
      "    load_throughput: 90706.607\n",
      "    load_time_ms: 110.201\n",
      "    sample_throughput: 21.253\n",
      "    sample_time_ms: 470325.789\n",
      "    update_time_ms: 11.05\n",
      "  timestamp: 1636285789\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1139544\n",
      "  training_iteration: 114\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         49426.4</td><td style=\"text-align: right;\">1139544</td><td style=\"text-align: right;\"> 6.58341</td><td style=\"text-align: right;\">               15.12</td><td style=\"text-align: right;\">                0.49</td><td style=\"text-align: right;\">           72.9778</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1149540\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_11-58-34\n",
      "  done: false\n",
      "  episode_len_mean: 67.84353741496598\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.740000000000023\n",
      "  episode_reward_mean: 6.4917006802721176\n",
      "  episode_reward_min: 0.38999999999999957\n",
      "  episodes_this_iter: 147\n",
      "  episodes_total: 14873\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9518594371966826\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016423984274897004\n",
      "          policy_loss: -0.06575353018557414\n",
      "          total_loss: 0.12775462025569545\n",
      "          vf_explained_var: 0.9670725464820862\n",
      "          vf_loss: 0.18808281908496322\n",
      "    num_agent_steps_sampled: 1149540\n",
      "    num_agent_steps_trained: 1149540\n",
      "    num_steps_sampled: 1149540\n",
      "    num_steps_trained: 1149540\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.1176\n",
      "    ram_util_percent: 62.25346666666667\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04132000025513178\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.592573819527946\n",
      "    mean_inference_ms: 2.386141224945418\n",
      "    mean_raw_obs_processing_ms: 69.03499510392935\n",
      "  time_since_restore: 49952.150594711304\n",
      "  time_this_iter_s: 525.749401807785\n",
      "  time_total_s: 49952.150594711304\n",
      "  timers:\n",
      "    learn_throughput: 1055.513\n",
      "    learn_time_ms: 9470.276\n",
      "    load_throughput: 90695.442\n",
      "    load_time_ms: 110.215\n",
      "    sample_throughput: 21.135\n",
      "    sample_time_ms: 472960.639\n",
      "    update_time_ms: 10.817\n",
      "  timestamp: 1636286314\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1149540\n",
      "  training_iteration: 115\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         49952.2</td><td style=\"text-align: right;\">1149540</td><td style=\"text-align: right;\">  6.4917</td><td style=\"text-align: right;\">               13.74</td><td style=\"text-align: right;\">                0.39</td><td style=\"text-align: right;\">           67.8435</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492348)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_b3578_00000:\n",
      "  agent_timesteps_total: 1159536\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-06-01\n",
      "  done: false\n",
      "  episode_len_mean: 72.9136690647482\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.11000000000002\n",
      "  episode_reward_mean: 6.785971223021594\n",
      "  episode_reward_min: 0.7300000000000036\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 15012\n",
      "  experiment_id: 5f28cb8af40d4f61a6ef0db2576d618a\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9446334323312482\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016493640813618225\n",
      "          policy_loss: -0.06176512789649841\n",
      "          total_loss: 0.1456288130619587\n",
      "          vf_explained_var: 0.9668768048286438\n",
      "          vf_loss: 0.20179056025102224\n",
      "    num_agent_steps_sampled: 1159536\n",
      "    num_agent_steps_trained: 1159536\n",
      "    num_steps_sampled: 1159536\n",
      "    num_steps_trained: 1159536\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.51598746081505\n",
      "    ram_util_percent: 62.432758620689654\n",
      "  pid: 492355\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04131011105063305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.626563485019027\n",
      "    mean_inference_ms: 2.386118822572305\n",
      "    mean_raw_obs_processing_ms: 69.26446608657118\n",
      "  time_since_restore: 50399.19483470917\n",
      "  time_this_iter_s: 447.04423999786377\n",
      "  time_total_s: 50399.19483470917\n",
      "  timers:\n",
      "    learn_throughput: 1052.306\n",
      "    learn_time_ms: 9499.141\n",
      "    load_throughput: 90440.306\n",
      "    load_time_ms: 110.526\n",
      "    sample_throughput: 21.368\n",
      "    sample_time_ms: 467812.225\n",
      "    update_time_ms: 11.176\n",
      "  timestamp: 1636286761\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1159536\n",
      "  training_iteration: 116\n",
      "  trial_id: b3578_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.74 GiB heap, 0.0/10.87 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_22-05-49<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_b3578_00000</td><td>RUNNING </td><td>192.168.3.5:492355</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         50399.2</td><td style=\"text-align: right;\">1159536</td><td style=\"text-align: right;\"> 6.78597</td><td style=\"text-align: right;\">               14.11</td><td style=\"text-align: right;\">                0.73</td><td style=\"text-align: right;\">           72.9137</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=492352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2021-11-07 12:06:12,739\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2021-11-07 12:06:12,739\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "Process _WandbLoggingProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/integration/wandb.py\", line 200, in run\n",
      "    result = self.queue.get()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "2021-11-07 12:06:13,072\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/util.py\", line 322, in _exit_function\n",
      "    p.join()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n",
      "Process wandb_internal:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/wandb/sdk/internal/internal.py\", line 152, in wandb_internal\n",
      "    thread.join()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_492241/2977992906.py\", line 34, in <module>\n",
      "    checkpoint_at_end=True)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\", line 532, in run\n",
      "    runner.step()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 554, in step\n",
      "    self._process_events(timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 675, in _process_events\n",
      "    timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 718, in get_next_available_trial\n",
      "    ready, _ = ray.wait(shuffled_results, timeout=timeout)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\", line 1793, in wait\n",
      "    fetch_local,\n",
      "  File \"python/ray/_raylet.pyx\", line 1222, in ray._raylet.CoreWorker.wait\n",
      "  File \"python/ray/_raylet.pyx\", line 155, in ray._raylet.check_status\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 396, in realpath\n",
      "    return abspath(path)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 353, in normpath\n",
      "    initial_slashes = path.startswith(sep)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_492241/2977992906.py\", line 34, in <module>\n",
      "    checkpoint_at_end=True)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\", line 532, in run\n",
      "    runner.step()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 554, in step\n",
      "    self._process_events(timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 675, in _process_events\n",
      "    timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 718, in get_next_available_trial\n",
      "    ready, _ = ray.wait(shuffled_results, timeout=timeout)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\", line 1793, in wait\n",
      "    fetch_local,\n",
      "  File \"python/ray/_raylet.pyx\", line 1222, in ray._raylet.CoreWorker.wait\n",
      "  File \"python/ray/_raylet.pyx\", line 155, in ray._raylet.check_status\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 170, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_492241/2977992906.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcheckpoint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         checkpoint_at_end=True)\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    674\u001b[0m             trial = self.trial_executor.get_next_available_trial(\n\u001b[0;32m--> 675\u001b[0;31m                 timeout=timeout)  # blocking\n\u001b[0m\u001b[1;32m    676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mfetch_local\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         )\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3360\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0;32m-> 3170\u001b[0;31m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3379\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3380\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0;32m-> 1143\u001b[0;31m                                                                      chained_exceptions_tb_offset)\n\u001b[0m\u001b[1;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 256,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 5_000,\n",
    "             \"lr\": 1e-4,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO MultiTask <=10 pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/10_blocks_max\",\n",
    "        keep_checkpoints_num=50,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
