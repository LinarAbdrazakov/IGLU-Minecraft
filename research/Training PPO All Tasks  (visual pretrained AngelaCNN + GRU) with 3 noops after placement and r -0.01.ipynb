{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "from ray.rllib.policy.rnn_sequencing import add_time_dimension\n",
    "\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        self.policy_hidden_dim = 256 \n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, self.policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.policy_hidden_dim, self.policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            #nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        self.time_major = self.model_config.get(\"_time_major\", False)\n",
    "        self.gru = nn.GRU(self.policy_hidden_dim, self.policy_hidden_dim, batch_first=not self.time_major)\n",
    "        \n",
    "        self.action_head = nn.Linear(self.policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(self.policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.gru.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        target_features = target_features.reshape(target_features.shape[0], -1)\n",
    "        features = torch.cat([visual_features, target_features], dim=1)\n",
    "        features = self.policy_network(features)\n",
    "        \n",
    "        if isinstance(seq_lens, np.ndarray):\n",
    "            seq_lens = torch.Tensor(seq_lens).int()\n",
    "        max_seq_len = features.shape[0] // seq_lens.shape[0]    \n",
    "        inputs = add_time_dimension(\n",
    "            features,\n",
    "            max_seq_len=max_seq_len,\n",
    "            framework=\"torch\",\n",
    "            time_major=self.time_major,\n",
    "        )\n",
    "        \n",
    "        h = state[0].permute(1, 0, 2)\n",
    "        output, new_h = self.gru(inputs, h)\n",
    "        new_state = [new_h.permute(1, 0, 2)]\n",
    "        \n",
    "        gru_output = output.reshape(-1, self.policy_hidden_dim)\n",
    "        \n",
    "        action = self.action_head(gru_output)\n",
    "        self.last_value = self.value_head(gru_output).squeeze(1)\n",
    "        return action, new_state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def get_initial_state(self):\n",
    "        return [torch.zeros(1, self.policy_hidden_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592760ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2362368"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_features_dim = 512\n",
    "target_features_dim = 9 * 11 * 11\n",
    "policy_hidden_dim = 256 \n",
    "\n",
    "policy_network = nn.Sequential(\n",
    "    nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(512, policy_hidden_dim),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "    nn.ELU(),\n",
    "    #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "    #nn.ELU(),\n",
    ")\n",
    "\n",
    "sum(p.numel() for p in policy_network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "tasks = []\n",
    "for i in range(1,156):\n",
    "    if ('C'+str(i)) == 'C38': continue\n",
    "    tasks.append('C'+str(i))\n",
    "    \n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "            \n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=250)\n",
    "    env.update_taskset(TaskSet(preset=tasks))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-11-07 12:37:45,307\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-11-07 12:37:45,327\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id 960ce_00000 but id 81db5_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=552473)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552473)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO All Tasks pretrained (AngelaCNN+GRU) (3 noops after placement) r: -0.01 div10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/81db5_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/81db5_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211107_123746-81db5_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552473)\u001b[0m 2021-11-07 12:37:48,754\tWARNING ppo.py:143 -- `train_batch_size` (5000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1666.\n",
      "\u001b[2m\u001b[36m(pid=552473)\u001b[0m 2021-11-07 12:37:48,754\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=552473)\u001b[0m 2021-11-07 12:37:48,754\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552473)\u001b[0m 2021-11-07 12:37:56,909\tINFO trainable.py:109 -- Trainable.setup took 10.587 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=552473)\u001b[0m 2021-11-07 12:37:56,910\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 9996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-41-32\n",
      "  done: false\n",
      "  episode_len_mean: 100.77319587628865\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.580000000000002\n",
      "  episode_reward_mean: -0.8639175257731962\n",
      "  episode_reward_min: -1.8000000000000012\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 97\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.884062057478815\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.005448134565703074\n",
      "          policy_loss: -0.012407635053237661\n",
      "          total_loss: -0.008587556214541452\n",
      "          vf_explained_var: 0.203287735581398\n",
      "          vf_loss: 0.03157107095218176\n",
      "    num_agent_steps_sampled: 9996\n",
      "    num_agent_steps_trained: 9996\n",
      "    num_steps_sampled: 9996\n",
      "    num_steps_trained: 9996\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.02564935064935\n",
      "    ram_util_percent: 46.650000000000006\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05498852728425705\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 55.96678062249896\n",
      "    mean_inference_ms: 2.882932108625055\n",
      "    mean_raw_obs_processing_ms: 0.6558890774873317\n",
      "  time_since_restore: 215.4554467201233\n",
      "  time_this_iter_s: 215.4554467201233\n",
      "  time_total_s: 215.4554467201233\n",
      "  timers:\n",
      "    learn_throughput: 805.698\n",
      "    learn_time_ms: 12406.63\n",
      "    load_throughput: 14477.711\n",
      "    load_time_ms: 690.441\n",
      "    sample_throughput: 49.405\n",
      "    sample_time_ms: 202329.081\n",
      "    update_time_ms: 12.645\n",
      "  timestamp: 1636288892\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9996\n",
      "  training_iteration: 1\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         215.455</td><td style=\"text-align: right;\">9996</td><td style=\"text-align: right;\">-0.863918</td><td style=\"text-align: right;\">                2.58</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           100.773</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 19992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-43-30\n",
      "  done: false\n",
      "  episode_len_mean: 98.43137254901961\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.460000000000004\n",
      "  episode_reward_mean: -0.5802941176470592\n",
      "  episode_reward_min: -1.600000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 199\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.869527016541897\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00825794731229035\n",
      "          policy_loss: -0.015938285919768005\n",
      "          total_loss: 0.08055777117579133\n",
      "          vf_explained_var: -0.18294155597686768\n",
      "          vf_loss: 0.12353973829497894\n",
      "    num_agent_steps_sampled: 19992\n",
      "    num_agent_steps_trained: 19992\n",
      "    num_steps_sampled: 19992\n",
      "    num_steps_trained: 19992\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.05029585798816\n",
      "    ram_util_percent: 52.064497041420125\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051960464595824235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.75855300819376\n",
      "    mean_inference_ms: 2.9122963462003497\n",
      "    mean_raw_obs_processing_ms: 0.6274123643749684\n",
      "  time_since_restore: 333.9032349586487\n",
      "  time_this_iter_s: 118.44778823852539\n",
      "  time_total_s: 333.9032349586487\n",
      "  timers:\n",
      "    learn_throughput: 805.295\n",
      "    learn_time_ms: 12412.848\n",
      "    load_throughput: 16641.976\n",
      "    load_time_ms: 600.65\n",
      "    sample_throughput: 64.947\n",
      "    sample_time_ms: 153909.523\n",
      "    update_time_ms: 13.608\n",
      "  timestamp: 1636289010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19992\n",
      "  training_iteration: 2\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         333.903</td><td style=\"text-align: right;\">19992</td><td style=\"text-align: right;\">-0.580294</td><td style=\"text-align: right;\">                4.46</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           98.4314</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 29988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-45-31\n",
      "  done: false\n",
      "  episode_len_mean: 96.24038461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.9000000000000035\n",
      "  episode_reward_mean: -0.39307692307692343\n",
      "  episode_reward_min: -1.810000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 303\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8557294466556646\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010938297962752872\n",
      "          policy_loss: -0.02790377158962034\n",
      "          total_loss: 0.07786307880877812\n",
      "          vf_explained_var: 0.15343286097049713\n",
      "          vf_loss: 0.13213648553539672\n",
      "    num_agent_steps_sampled: 29988\n",
      "    num_agent_steps_trained: 29988\n",
      "    num_steps_sampled: 29988\n",
      "    num_steps_trained: 29988\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.2220930232558\n",
      "    ram_util_percent: 51.94186046511628\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05121134917130895\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 37.297657201242096\n",
      "    mean_inference_ms: 2.9185965760771015\n",
      "    mean_raw_obs_processing_ms: 0.623153572816849\n",
      "  time_since_restore: 454.47997188568115\n",
      "  time_this_iter_s: 120.57673692703247\n",
      "  time_total_s: 454.47997188568115\n",
      "  timers:\n",
      "    learn_throughput: 804.899\n",
      "    learn_time_ms: 12418.95\n",
      "    load_throughput: 17631.261\n",
      "    load_time_ms: 566.948\n",
      "    sample_throughput: 72.184\n",
      "    sample_time_ms: 138479.077\n",
      "    update_time_ms: 11.412\n",
      "  timestamp: 1636289131\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29988\n",
      "  training_iteration: 3\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">          454.48</td><td style=\"text-align: right;\">29988</td><td style=\"text-align: right;\">-0.393077</td><td style=\"text-align: right;\">                 2.9</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           96.2404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 39984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-47-58\n",
      "  done: false\n",
      "  episode_len_mean: 93.66037735849056\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.710000000000006\n",
      "  episode_reward_mean: 0.1292452830188682\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 409\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.822630866164835\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01252816994067562\n",
      "          policy_loss: -0.03149683301243595\n",
      "          total_loss: 0.14709871391600104\n",
      "          vf_explained_var: 0.3094733655452728\n",
      "          vf_loss: 0.20431622123807414\n",
      "    num_agent_steps_sampled: 39984\n",
      "    num_agent_steps_trained: 39984\n",
      "    num_steps_sampled: 39984\n",
      "    num_steps_trained: 39984\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.08761904761906\n",
      "    ram_util_percent: 52.321904761904776\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05107105970404627\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.61028119129909\n",
      "    mean_inference_ms: 2.9206383860547263\n",
      "    mean_raw_obs_processing_ms: 2.004330664309972\n",
      "  time_since_restore: 601.9529285430908\n",
      "  time_this_iter_s: 147.47295665740967\n",
      "  time_total_s: 601.9529285430908\n",
      "  timers:\n",
      "    learn_throughput: 803.08\n",
      "    learn_time_ms: 12447.073\n",
      "    load_throughput: 17545.5\n",
      "    load_time_ms: 569.719\n",
      "    sample_throughput: 72.727\n",
      "    sample_time_ms: 137444.766\n",
      "    update_time_ms: 10.368\n",
      "  timestamp: 1636289278\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39984\n",
      "  training_iteration: 4\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         601.953</td><td style=\"text-align: right;\">39984</td><td style=\"text-align: right;\">0.129245</td><td style=\"text-align: right;\">                8.71</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           93.6604</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 49980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-50-06\n",
      "  done: false\n",
      "  episode_len_mean: 96.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0000000000000036\n",
      "  episode_reward_mean: 0.6787619047619061\n",
      "  episode_reward_min: -2.0300000000000002\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 514\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8020932246477175\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016654536320332553\n",
      "          policy_loss: -0.03329561155351102\n",
      "          total_loss: 0.31227522916379424\n",
      "          vf_explained_var: 0.3225064277648926\n",
      "          vf_loss: 0.3702608666804611\n",
      "    num_agent_steps_sampled: 49980\n",
      "    num_agent_steps_trained: 49980\n",
      "    num_steps_sampled: 49980\n",
      "    num_steps_trained: 49980\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.80491803278686\n",
      "    ram_util_percent: 53.850273224043725\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050754436537065524\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.55975393048955\n",
      "    mean_inference_ms: 2.9142978155048826\n",
      "    mean_raw_obs_processing_ms: 1.741048167194456\n",
      "  time_since_restore: 729.963593006134\n",
      "  time_this_iter_s: 128.0106644630432\n",
      "  time_total_s: 729.963593006134\n",
      "  timers:\n",
      "    learn_throughput: 802.224\n",
      "    learn_time_ms: 12460.366\n",
      "    load_throughput: 17946.359\n",
      "    load_time_ms: 556.993\n",
      "    sample_throughput: 75.187\n",
      "    sample_time_ms: 132948.734\n",
      "    update_time_ms: 9.865\n",
      "  timestamp: 1636289406\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 49980\n",
      "  training_iteration: 5\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         729.964</td><td style=\"text-align: right;\">49980</td><td style=\"text-align: right;\">0.678762</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">              96.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 59976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-52-16\n",
      "  done: false\n",
      "  episode_len_mean: 97.06862745098039\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.750000000000002\n",
      "  episode_reward_mean: 0.6676470588235304\n",
      "  episode_reward_min: -1.6700000000000008\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 616\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7822406593550983\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.024434898960707628\n",
      "          policy_loss: -0.03113511052129575\n",
      "          total_loss: 0.2316218328905246\n",
      "          vf_explained_var: 0.4430922865867615\n",
      "          vf_loss: 0.2856923694093513\n",
      "    num_agent_steps_sampled: 59976\n",
      "    num_agent_steps_trained: 59976\n",
      "    num_steps_sampled: 59976\n",
      "    num_steps_trained: 59976\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.82810810810811\n",
      "    ram_util_percent: 54.55567567567567\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05032997363171652\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.93801030473552\n",
      "    mean_inference_ms: 2.910723176646929\n",
      "    mean_raw_obs_processing_ms: 1.560510008113701\n",
      "  time_since_restore: 859.7278821468353\n",
      "  time_this_iter_s: 129.7642891407013\n",
      "  time_total_s: 859.7278821468353\n",
      "  timers:\n",
      "    learn_throughput: 802.075\n",
      "    learn_time_ms: 12462.669\n",
      "    load_throughput: 18262.535\n",
      "    load_time_ms: 547.35\n",
      "    sample_throughput: 76.743\n",
      "    sample_time_ms: 130252.528\n",
      "    update_time_ms: 9.342\n",
      "  timestamp: 1636289536\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59976\n",
      "  training_iteration: 6\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         859.728</td><td style=\"text-align: right;\">59976</td><td style=\"text-align: right;\">0.667647</td><td style=\"text-align: right;\">                4.75</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           97.0686</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 69972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-54-43\n",
      "  done: false\n",
      "  episode_len_mean: 95.24528301886792\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.920000000000009\n",
      "  episode_reward_mean: 1.1926415094339642\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 722\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7595538860712296\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.021193696005868148\n",
      "          policy_loss: -0.03799824479517863\n",
      "          total_loss: 0.2749890881298512\n",
      "          vf_explained_var: 0.5662446618080139\n",
      "          vf_loss: 0.33422476245552046\n",
      "    num_agent_steps_sampled: 69972\n",
      "    num_agent_steps_trained: 69972\n",
      "    num_steps_sampled: 69972\n",
      "    num_steps_trained: 69972\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.54476190476191\n",
      "    ram_util_percent: 54.69714285714284\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04990732776626649\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.48205734541758\n",
      "    mean_inference_ms: 2.907054612276351\n",
      "    mean_raw_obs_processing_ms: 2.1486712572449207\n",
      "  time_since_restore: 1006.4045283794403\n",
      "  time_this_iter_s: 146.67664623260498\n",
      "  time_total_s: 1006.4045283794403\n",
      "  timers:\n",
      "    learn_throughput: 801.322\n",
      "    learn_time_ms: 12474.384\n",
      "    load_throughput: 18477.724\n",
      "    load_time_ms: 540.976\n",
      "    sample_throughput: 76.462\n",
      "    sample_time_ms: 130731.416\n",
      "    update_time_ms: 9.584\n",
      "  timestamp: 1636289683\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69972\n",
      "  training_iteration: 7\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">          1006.4</td><td style=\"text-align: right;\">69972</td><td style=\"text-align: right;\"> 1.19264</td><td style=\"text-align: right;\">               10.92</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           95.2453</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 79968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-56-56\n",
      "  done: false\n",
      "  episode_len_mean: 96.20192307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.87000000000001\n",
      "  episode_reward_mean: 0.737019230769232\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 826\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7454164447947447\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017158678038308908\n",
      "          policy_loss: -0.050093303976827264\n",
      "          total_loss: 0.17008151742371627\n",
      "          vf_explained_var: 0.5696343779563904\n",
      "          vf_loss: 0.23990758145148428\n",
      "    num_agent_steps_sampled: 79968\n",
      "    num_agent_steps_trained: 79968\n",
      "    num_steps_sampled: 79968\n",
      "    num_steps_trained: 79968\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.71693121693121\n",
      "    ram_util_percent: 54.496296296296315\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049668479748216324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.21727856898947\n",
      "    mean_inference_ms: 2.906305928403123\n",
      "    mean_raw_obs_processing_ms: 1.9653517017580089\n",
      "  time_since_restore: 1139.2362599372864\n",
      "  time_this_iter_s: 132.83173155784607\n",
      "  time_total_s: 1139.2362599372864\n",
      "  timers:\n",
      "    learn_throughput: 800.927\n",
      "    learn_time_ms: 12480.536\n",
      "    load_throughput: 18666.235\n",
      "    load_time_ms: 535.512\n",
      "    sample_throughput: 77.271\n",
      "    sample_time_ms: 129363.495\n",
      "    update_time_ms: 9.572\n",
      "  timestamp: 1636289816\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79968\n",
      "  training_iteration: 8\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         1139.24</td><td style=\"text-align: right;\">79968</td><td style=\"text-align: right;\">0.737019</td><td style=\"text-align: right;\">                4.87</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           96.2019</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 89964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_12-59-06\n",
      "  done: false\n",
      "  episode_len_mean: 96.36893203883496\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.680000000000012\n",
      "  episode_reward_mean: 1.035242718446604\n",
      "  episode_reward_min: -2.0999999999999988\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 929\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7407099888874935\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.021436836153406247\n",
      "          policy_loss: -0.048860654188083726\n",
      "          total_loss: 0.16117291721574062\n",
      "          vf_explained_var: 0.577031672000885\n",
      "          vf_loss: 0.22779409277897614\n",
      "    num_agent_steps_sampled: 89964\n",
      "    num_agent_steps_trained: 89964\n",
      "    num_steps_sampled: 89964\n",
      "    num_steps_trained: 89964\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.78279569892474\n",
      "    ram_util_percent: 54.844086021505376\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049587257464621295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98207902099242\n",
      "    mean_inference_ms: 2.905763622721572\n",
      "    mean_raw_obs_processing_ms: 1.8232206278558238\n",
      "  time_since_restore: 1269.7285914421082\n",
      "  time_this_iter_s: 130.49233150482178\n",
      "  time_total_s: 1269.7285914421082\n",
      "  timers:\n",
      "    learn_throughput: 801.045\n",
      "    learn_time_ms: 12478.694\n",
      "    load_throughput: 18820.524\n",
      "    load_time_ms: 531.122\n",
      "    sample_throughput: 78.066\n",
      "    sample_time_ms: 128045.94\n",
      "    update_time_ms: 9.962\n",
      "  timestamp: 1636289946\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89964\n",
      "  training_iteration: 9\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         1269.73</td><td style=\"text-align: right;\">89964</td><td style=\"text-align: right;\"> 1.03524</td><td style=\"text-align: right;\">                8.68</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">           96.3689</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 99960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-01-18\n",
      "  done: false\n",
      "  episode_len_mean: 95.29523809523809\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.84000000000001\n",
      "  episode_reward_mean: 0.9066666666666683\n",
      "  episode_reward_min: -1.7300000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 1034\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7319690694156873\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02141083725505932\n",
      "          policy_loss: -0.05107570455767041\n",
      "          total_loss: 0.1447404513026102\n",
      "          vf_explained_var: 0.66274493932724\n",
      "          vf_loss: 0.2086835321643923\n",
      "    num_agent_steps_sampled: 99960\n",
      "    num_agent_steps_trained: 99960\n",
      "    num_steps_sampled: 99960\n",
      "    num_steps_trained: 99960\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85775401069519\n",
      "    ram_util_percent: 55.017112299465246\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04954287224075031\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.81640347638911\n",
      "    mean_inference_ms: 2.9052790618316955\n",
      "    mean_raw_obs_processing_ms: 1.7122351662823068\n",
      "  time_since_restore: 1400.8399391174316\n",
      "  time_this_iter_s: 131.1113476753235\n",
      "  time_total_s: 1400.8399391174316\n",
      "  timers:\n",
      "    learn_throughput: 800.99\n",
      "    learn_time_ms: 12479.564\n",
      "    load_throughput: 18939.686\n",
      "    load_time_ms: 527.781\n",
      "    sample_throughput: 78.677\n",
      "    sample_time_ms: 127051.697\n",
      "    update_time_ms: 9.611\n",
      "  timestamp: 1636290078\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99960\n",
      "  training_iteration: 10\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         1400.84</td><td style=\"text-align: right;\">99960</td><td style=\"text-align: right;\">0.906667</td><td style=\"text-align: right;\">                4.84</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           95.2952</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 109956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-03-47\n",
      "  done: false\n",
      "  episode_len_mean: 94.85849056603773\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.040000000000006\n",
      "  episode_reward_mean: 0.9728301886792473\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 1140\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.731305471240965\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019618779847453045\n",
      "          policy_loss: -0.052315612175967294\n",
      "          total_loss: 0.13186002302495464\n",
      "          vf_explained_var: 0.6459531188011169\n",
      "          vf_loss: 0.19162467405613925\n",
      "    num_agent_steps_sampled: 109956\n",
      "    num_agent_steps_trained: 109956\n",
      "    num_steps_sampled: 109956\n",
      "    num_steps_trained: 109956\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.4300469483568\n",
      "    ram_util_percent: 54.975586854460104\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049513123318717676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.64957587496326\n",
      "    mean_inference_ms: 2.9041617030019546\n",
      "    mean_raw_obs_processing_ms: 2.090266702494253\n",
      "  time_since_restore: 1549.9256954193115\n",
      "  time_this_iter_s: 149.08575630187988\n",
      "  time_total_s: 1549.9256954193115\n",
      "  timers:\n",
      "    learn_throughput: 800.194\n",
      "    learn_time_ms: 12491.967\n",
      "    load_throughput: 19675.995\n",
      "    load_time_ms: 508.03\n",
      "    sample_throughput: 83.008\n",
      "    sample_time_ms: 120422.263\n",
      "    update_time_ms: 9.478\n",
      "  timestamp: 1636290227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109956\n",
      "  training_iteration: 11\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         1549.93</td><td style=\"text-align: right;\">109956</td><td style=\"text-align: right;\"> 0.97283</td><td style=\"text-align: right;\">                5.04</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           94.8585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 119952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-06-03\n",
      "  done: false\n",
      "  episode_len_mean: 97.37623762376238\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.27000000000001\n",
      "  episode_reward_mean: 0.8184158415841599\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 1241\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7289472606447007\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.020563775863684797\n",
      "          policy_loss: -0.05436774108427802\n",
      "          total_loss: 0.09429352682466424\n",
      "          vf_explained_var: 0.6483254432678223\n",
      "          vf_loss: 0.15512991710287383\n",
      "    num_agent_steps_sampled: 119952\n",
      "    num_agent_steps_trained: 119952\n",
      "    num_steps_sampled: 119952\n",
      "    num_steps_trained: 119952\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.35360824742267\n",
      "    ram_util_percent: 55.077835051546394\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04936982648041811\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.5731544178594\n",
      "    mean_inference_ms: 2.9025772033427635\n",
      "    mean_raw_obs_processing_ms: 1.9740619724505826\n",
      "  time_since_restore: 1685.7241656780243\n",
      "  time_this_iter_s: 135.79847025871277\n",
      "  time_total_s: 1685.7241656780243\n",
      "  timers:\n",
      "    learn_throughput: 799.701\n",
      "    learn_time_ms: 12499.664\n",
      "    load_throughput: 19740.09\n",
      "    load_time_ms: 506.381\n",
      "    sample_throughput: 81.832\n",
      "    sample_time_ms: 122152.273\n",
      "    update_time_ms: 8.689\n",
      "  timestamp: 1636290363\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119952\n",
      "  training_iteration: 12\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         1685.72</td><td style=\"text-align: right;\">119952</td><td style=\"text-align: right;\">0.818416</td><td style=\"text-align: right;\">                6.27</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           97.3762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 129948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-08-17\n",
      "  done: false\n",
      "  episode_len_mean: 97.7378640776699\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.110000000000012\n",
      "  episode_reward_mean: 1.0252427184466038\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 1344\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7243337504884115\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017992767751852\n",
      "          policy_loss: -0.060302324225967124\n",
      "          total_loss: 0.0958034462014633\n",
      "          vf_explained_var: 0.5844916701316833\n",
      "          vf_loss: 0.156022593495237\n",
      "    num_agent_steps_sampled: 129948\n",
      "    num_agent_steps_trained: 129948\n",
      "    num_steps_sampled: 129948\n",
      "    num_steps_trained: 129948\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.67864583333333\n",
      "    ram_util_percent: 55.3765625\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04926347938138608\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.498431577710534\n",
      "    mean_inference_ms: 2.9023405973002414\n",
      "    mean_raw_obs_processing_ms: 1.8764975358311904\n",
      "  time_since_restore: 1820.2735669612885\n",
      "  time_this_iter_s: 134.54940128326416\n",
      "  time_total_s: 1820.2735669612885\n",
      "  timers:\n",
      "    learn_throughput: 799.164\n",
      "    learn_time_ms: 12508.065\n",
      "    load_throughput: 19762.568\n",
      "    load_time_ms: 505.805\n",
      "    sample_throughput: 80.911\n",
      "    sample_time_ms: 123542.755\n",
      "    update_time_ms: 8.611\n",
      "  timestamp: 1636290497\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129948\n",
      "  training_iteration: 13\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         1820.27</td><td style=\"text-align: right;\">129948</td><td style=\"text-align: right;\"> 1.02524</td><td style=\"text-align: right;\">                7.11</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           97.7379</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 139944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-10-49\n",
      "  done: false\n",
      "  episode_len_mean: 96.57692307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.9700000000000095\n",
      "  episode_reward_mean: 0.8920192307692321\n",
      "  episode_reward_min: -2.0100000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1448\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7175154745069325\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01688571123425493\n",
      "          policy_loss: -0.057515333496799305\n",
      "          total_loss: 0.10269569298299726\n",
      "          vf_explained_var: 0.7024216651916504\n",
      "          vf_loss: 0.16174100869390953\n",
      "    num_agent_steps_sampled: 139944\n",
      "    num_agent_steps_trained: 139944\n",
      "    num_steps_sampled: 139944\n",
      "    num_steps_trained: 139944\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.53732718894008\n",
      "    ram_util_percent: 55.10276497695853\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049211403672200976\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.434740252714626\n",
      "    mean_inference_ms: 2.8992322923053453\n",
      "    mean_raw_obs_processing_ms: 2.152188742232566\n",
      "  time_since_restore: 1972.3016984462738\n",
      "  time_this_iter_s: 152.02813148498535\n",
      "  time_total_s: 1972.3016984462738\n",
      "  timers:\n",
      "    learn_throughput: 799.678\n",
      "    learn_time_ms: 12500.033\n",
      "    load_throughput: 20081.269\n",
      "    load_time_ms: 497.777\n",
      "    sample_throughput: 80.603\n",
      "    sample_time_ms: 124014.632\n",
      "    update_time_ms: 8.591\n",
      "  timestamp: 1636290649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 139944\n",
      "  training_iteration: 14\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">          1972.3</td><td style=\"text-align: right;\">139944</td><td style=\"text-align: right;\">0.892019</td><td style=\"text-align: right;\">                6.97</td><td style=\"text-align: right;\">               -2.01</td><td style=\"text-align: right;\">           96.5769</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 149940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-12-58\n",
      "  done: false\n",
      "  episode_len_mean: 96.92233009708738\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.030000000000013\n",
      "  episode_reward_mean: 0.9675728155339824\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 1551\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7206488605238435\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018552981338901573\n",
      "          policy_loss: -0.06165777401567741\n",
      "          total_loss: 0.10138632404295304\n",
      "          vf_explained_var: 0.7040499448776245\n",
      "          vf_loss: 0.16207324609033064\n",
      "    num_agent_steps_sampled: 149940\n",
      "    num_agent_steps_trained: 149940\n",
      "    num_steps_sampled: 149940\n",
      "    num_steps_trained: 149940\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0820652173913\n",
      "    ram_util_percent: 54.748913043478254\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04921797440271938\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.33200237978788\n",
      "    mean_inference_ms: 2.8988239474970086\n",
      "    mean_raw_obs_processing_ms: 2.0545557136420944\n",
      "  time_since_restore: 2101.2645750045776\n",
      "  time_this_iter_s: 128.96287655830383\n",
      "  time_total_s: 2101.2645750045776\n",
      "  timers:\n",
      "    learn_throughput: 800.109\n",
      "    learn_time_ms: 12493.291\n",
      "    load_throughput: 20146.517\n",
      "    load_time_ms: 496.165\n",
      "    sample_throughput: 80.536\n",
      "    sample_time_ms: 124118.972\n",
      "    update_time_ms: 8.445\n",
      "  timestamp: 1636290778\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 149940\n",
      "  training_iteration: 15\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         2101.26</td><td style=\"text-align: right;\">149940</td><td style=\"text-align: right;\">0.967573</td><td style=\"text-align: right;\">                5.03</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           96.9223</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 159936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-15-08\n",
      "  done: false\n",
      "  episode_len_mean: 97.91176470588235\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.94000000000001\n",
      "  episode_reward_mean: 0.7946078431372565\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 1653\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7162166035073434\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01788260955443526\n",
      "          policy_loss: -0.059286390386350675\n",
      "          total_loss: 0.08364793523109039\n",
      "          vf_explained_var: 0.7393493056297302\n",
      "          vf_loss: 0.14293727800409253\n",
      "    num_agent_steps_sampled: 159936\n",
      "    num_agent_steps_trained: 159936\n",
      "    num_steps_sampled: 159936\n",
      "    num_steps_trained: 159936\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77391304347827\n",
      "    ram_util_percent: 55.33858695652174\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049219348871145714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.22407475487005\n",
      "    mean_inference_ms: 2.8993587274944774\n",
      "    mean_raw_obs_processing_ms: 1.9688676667233267\n",
      "  time_since_restore: 2230.587459087372\n",
      "  time_this_iter_s: 129.3228840827942\n",
      "  time_total_s: 2230.587459087372\n",
      "  timers:\n",
      "    learn_throughput: 800.086\n",
      "    learn_time_ms: 12493.657\n",
      "    load_throughput: 20155.82\n",
      "    load_time_ms: 495.936\n",
      "    sample_throughput: 80.565\n",
      "    sample_time_ms: 124073.488\n",
      "    update_time_ms: 9.5\n",
      "  timestamp: 1636290908\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159936\n",
      "  training_iteration: 16\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         2230.59</td><td style=\"text-align: right;\">159936</td><td style=\"text-align: right;\">0.794608</td><td style=\"text-align: right;\">                4.94</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           97.9118</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 169932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-17-20\n",
      "  done: false\n",
      "  episode_len_mean: 95.46666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.6400000000000095\n",
      "  episode_reward_mean: 0.9340952380952401\n",
      "  episode_reward_min: -1.860000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 1758\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7122392255016883\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02113112106516222\n",
      "          policy_loss: -0.05204400480539863\n",
      "          total_loss: 0.12250012070227626\n",
      "          vf_explained_var: 0.6810734868049622\n",
      "          vf_loss: 0.16957362833727374\n",
      "    num_agent_steps_sampled: 169932\n",
      "    num_agent_steps_trained: 169932\n",
      "    num_steps_sampled: 169932\n",
      "    num_steps_trained: 169932\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69629629629628\n",
      "    ram_util_percent: 55.526455026455025\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04916537838165691\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.17470789846191\n",
      "    mean_inference_ms: 2.8994941073662672\n",
      "    mean_raw_obs_processing_ms: 1.8950521882968756\n",
      "  time_since_restore: 2362.833675146103\n",
      "  time_this_iter_s: 132.24621605873108\n",
      "  time_total_s: 2362.833675146103\n",
      "  timers:\n",
      "    learn_throughput: 800.266\n",
      "    learn_time_ms: 12490.842\n",
      "    load_throughput: 20180.876\n",
      "    load_time_ms: 495.32\n",
      "    sample_throughput: 81.511\n",
      "    sample_time_ms: 122634.028\n",
      "    update_time_ms: 9.483\n",
      "  timestamp: 1636291040\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169932\n",
      "  training_iteration: 17\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         2362.83</td><td style=\"text-align: right;\">169932</td><td style=\"text-align: right;\">0.934095</td><td style=\"text-align: right;\">                6.64</td><td style=\"text-align: right;\">               -1.86</td><td style=\"text-align: right;\">           95.4667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 179928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-19-46\n",
      "  done: false\n",
      "  episode_len_mean: 93.34579439252336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.060000000000012\n",
      "  episode_reward_mean: 0.9314953271028059\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 1865\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7130565820596155\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015504323764823977\n",
      "          policy_loss: -0.05911546085503959\n",
      "          total_loss: 0.10715785208645746\n",
      "          vf_explained_var: 0.7006322741508484\n",
      "          vf_loss: 0.15808309013039892\n",
      "    num_agent_steps_sampled: 179928\n",
      "    num_agent_steps_trained: 179928\n",
      "    num_steps_sampled: 179928\n",
      "    num_steps_trained: 179928\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.13205741626794\n",
      "    ram_util_percent: 54.95502392344497\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04915254686263334\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08096698803345\n",
      "    mean_inference_ms: 2.8989043805470724\n",
      "    mean_raw_obs_processing_ms: 2.123267280669653\n",
      "  time_since_restore: 2509.498438835144\n",
      "  time_this_iter_s: 146.66476368904114\n",
      "  time_total_s: 2509.498438835144\n",
      "  timers:\n",
      "    learn_throughput: 800.309\n",
      "    learn_time_ms: 12490.18\n",
      "    load_throughput: 20152.999\n",
      "    load_time_ms: 496.006\n",
      "    sample_throughput: 80.602\n",
      "    sample_time_ms: 124017.42\n",
      "    update_time_ms: 9.666\n",
      "  timestamp: 1636291186\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179928\n",
      "  training_iteration: 18\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">          2509.5</td><td style=\"text-align: right;\">179928</td><td style=\"text-align: right;\">0.931495</td><td style=\"text-align: right;\">                5.06</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           93.3458</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 189924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-21-59\n",
      "  done: false\n",
      "  episode_len_mean: 95.07619047619048\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.6400000000000095\n",
      "  episode_reward_mean: 1.1096190476190495\n",
      "  episode_reward_min: -1.9900000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 1970\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7099881056027533\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016072543428741575\n",
      "          policy_loss: -0.052196202120022565\n",
      "          total_loss: 0.1169102566274685\n",
      "          vf_explained_var: 0.7402122616767883\n",
      "          vf_loss: 0.1595910735667134\n",
      "    num_agent_steps_sampled: 189924\n",
      "    num_agent_steps_trained: 189924\n",
      "    num_steps_sampled: 189924\n",
      "    num_steps_trained: 189924\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77157894736841\n",
      "    ram_util_percent: 55.10368421052632\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049096554943141496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.0621517081192\n",
      "    mean_inference_ms: 2.8989536144483536\n",
      "    mean_raw_obs_processing_ms: 2.047852571493623\n",
      "  time_since_restore: 2642.0201864242554\n",
      "  time_this_iter_s: 132.52174758911133\n",
      "  time_total_s: 2642.0201864242554\n",
      "  timers:\n",
      "    learn_throughput: 800.256\n",
      "    learn_time_ms: 12491.004\n",
      "    load_throughput: 20159.578\n",
      "    load_time_ms: 495.844\n",
      "    sample_throughput: 80.47\n",
      "    sample_time_ms: 124220.667\n",
      "    update_time_ms: 8.958\n",
      "  timestamp: 1636291319\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189924\n",
      "  training_iteration: 19\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         2642.02</td><td style=\"text-align: right;\">189924</td><td style=\"text-align: right;\"> 1.10962</td><td style=\"text-align: right;\">                6.64</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           95.0762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 199920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-24-11\n",
      "  done: false\n",
      "  episode_len_mean: 95.44761904761904\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.990000000000008\n",
      "  episode_reward_mean: 1.0897142857142892\n",
      "  episode_reward_min: -1.8000000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 2075\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.700362457169427\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016706487531398827\n",
      "          policy_loss: -0.056920925291093674\n",
      "          total_loss: 0.11833684539649253\n",
      "          vf_explained_var: 0.7622712254524231\n",
      "          vf_loss: 0.16420192731878697\n",
      "    num_agent_steps_sampled: 199920\n",
      "    num_agent_steps_trained: 199920\n",
      "    num_steps_sampled: 199920\n",
      "    num_steps_trained: 199920\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.71010638297874\n",
      "    ram_util_percent: 55.376063829787235\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04907358750691038\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.03629381365437\n",
      "    mean_inference_ms: 2.8992882743159183\n",
      "    mean_raw_obs_processing_ms: 1.9801906480309919\n",
      "  time_since_restore: 2773.957239151001\n",
      "  time_this_iter_s: 131.9370527267456\n",
      "  time_total_s: 2773.957239151001\n",
      "  timers:\n",
      "    learn_throughput: 800.463\n",
      "    learn_time_ms: 12487.767\n",
      "    load_throughput: 20173.199\n",
      "    load_time_ms: 495.509\n",
      "    sample_throughput: 80.414\n",
      "    sample_time_ms: 124307.067\n",
      "    update_time_ms: 9.181\n",
      "  timestamp: 1636291451\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199920\n",
      "  training_iteration: 20\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         2773.96</td><td style=\"text-align: right;\">199920</td><td style=\"text-align: right;\"> 1.08971</td><td style=\"text-align: right;\">                4.99</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           95.4476</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 209916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-26-49\n",
      "  done: false\n",
      "  episode_len_mean: 94.8952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.93000000000001\n",
      "  episode_reward_mean: 0.8868571428571451\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 2180\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7029424543054694\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015577950840711561\n",
      "          policy_loss: -0.060171757663628006\n",
      "          total_loss: 0.09002083634672105\n",
      "          vf_explained_var: 0.7640243172645569\n",
      "          vf_loss: 0.14173349899550278\n",
      "    num_agent_steps_sampled: 209916\n",
      "    num_agent_steps_trained: 209916\n",
      "    num_steps_sampled: 209916\n",
      "    num_steps_trained: 209916\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.52699115044247\n",
      "    ram_util_percent: 55.47787610619469\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048909332821326076\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.9359826210798\n",
      "    mean_inference_ms: 2.8970041900298558\n",
      "    mean_raw_obs_processing_ms: 2.1556810088219347\n",
      "  time_since_restore: 2932.3382484912872\n",
      "  time_this_iter_s: 158.38100934028625\n",
      "  time_total_s: 2932.3382484912872\n",
      "  timers:\n",
      "    learn_throughput: 800.74\n",
      "    learn_time_ms: 12483.459\n",
      "    load_throughput: 20179.094\n",
      "    load_time_ms: 495.364\n",
      "    sample_throughput: 79.814\n",
      "    sample_time_ms: 125240.956\n",
      "    update_time_ms: 9.067\n",
      "  timestamp: 1636291609\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209916\n",
      "  training_iteration: 21\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         2932.34</td><td style=\"text-align: right;\">209916</td><td style=\"text-align: right;\">0.886857</td><td style=\"text-align: right;\">                4.93</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           94.8952</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 219912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-29-10\n",
      "  done: false\n",
      "  episode_len_mean: 97.49019607843137\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.540000000000013\n",
      "  episode_reward_mean: 1.360588235294121\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 2282\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.700569127359961\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01948220990775801\n",
      "          policy_loss: -0.052184801796800025\n",
      "          total_loss: 0.14508064652312522\n",
      "          vf_explained_var: 0.7345572113990784\n",
      "          vf_loss: 0.17988822873777305\n",
      "    num_agent_steps_sampled: 219912\n",
      "    num_agent_steps_trained: 219912\n",
      "    num_steps_sampled: 219912\n",
      "    num_steps_trained: 219912\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.37\n",
      "    ram_util_percent: 55.287\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048811471530279524\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.83805351733478\n",
      "    mean_inference_ms: 2.896175476022874\n",
      "    mean_raw_obs_processing_ms: 2.1619732018949023\n",
      "  time_since_restore: 3072.4028038978577\n",
      "  time_this_iter_s: 140.06455540657043\n",
      "  time_total_s: 3072.4028038978577\n",
      "  timers:\n",
      "    learn_throughput: 800.77\n",
      "    learn_time_ms: 12482.98\n",
      "    load_throughput: 20203.473\n",
      "    load_time_ms: 494.766\n",
      "    sample_throughput: 79.543\n",
      "    sample_time_ms: 125668.067\n",
      "    update_time_ms: 9.631\n",
      "  timestamp: 1636291750\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219912\n",
      "  training_iteration: 22\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">          3072.4</td><td style=\"text-align: right;\">219912</td><td style=\"text-align: right;\"> 1.36059</td><td style=\"text-align: right;\">                8.54</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           97.4902</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 229908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-31-18\n",
      "  done: false\n",
      "  episode_len_mean: 97.4423076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.070000000000011\n",
      "  episode_reward_mean: 0.9260576923076942\n",
      "  episode_reward_min: -1.9000000000000008\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 2386\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.705834284806863\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015849795060138186\n",
      "          policy_loss: -0.05672982235733083\n",
      "          total_loss: 0.10344135139401679\n",
      "          vf_explained_var: 0.772047758102417\n",
      "          vf_loss: 0.1511217026453879\n",
      "    num_agent_steps_sampled: 229908\n",
      "    num_agent_steps_trained: 229908\n",
      "    num_steps_sampled: 229908\n",
      "    num_steps_trained: 229908\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7983606557377\n",
      "    ram_util_percent: 55.61366120218579\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048769640068047265\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.78941731904369\n",
      "    mean_inference_ms: 2.896356606075893\n",
      "    mean_raw_obs_processing_ms: 2.0968052586948684\n",
      "  time_since_restore: 3201.2012734413147\n",
      "  time_this_iter_s: 128.79846954345703\n",
      "  time_total_s: 3201.2012734413147\n",
      "  timers:\n",
      "    learn_throughput: 801.435\n",
      "    learn_time_ms: 12472.627\n",
      "    load_throughput: 20159.156\n",
      "    load_time_ms: 495.854\n",
      "    sample_throughput: 79.903\n",
      "    sample_time_ms: 125101.369\n",
      "    update_time_ms: 10.255\n",
      "  timestamp: 1636291878\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229908\n",
      "  training_iteration: 23\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">          3201.2</td><td style=\"text-align: right;\">229908</td><td style=\"text-align: right;\">0.926058</td><td style=\"text-align: right;\">                7.07</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           97.4423</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 239904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-33-43\n",
      "  done: false\n",
      "  episode_len_mean: 95.50961538461539\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.800000000000006\n",
      "  episode_reward_mean: 0.6714423076923093\n",
      "  episode_reward_min: -1.9300000000000013\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 2490\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.705974098759839\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013654281641177511\n",
      "          policy_loss: -0.06573103746533858\n",
      "          total_loss: 0.04941376058866606\n",
      "          vf_explained_var: 0.8229418396949768\n",
      "          vf_loss: 0.11109837763823378\n",
      "    num_agent_steps_sampled: 239904\n",
      "    num_agent_steps_trained: 239904\n",
      "    num_steps_sampled: 239904\n",
      "    num_steps_trained: 239904\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.54126213592232\n",
      "    ram_util_percent: 55.70194174757281\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048695744060759605\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.72857240690032\n",
      "    mean_inference_ms: 2.8952868355929247\n",
      "    mean_raw_obs_processing_ms: 2.173056453237795\n",
      "  time_since_restore: 3345.484890937805\n",
      "  time_this_iter_s: 144.28361749649048\n",
      "  time_total_s: 3345.484890937805\n",
      "  timers:\n",
      "    learn_throughput: 801.235\n",
      "    learn_time_ms: 12475.748\n",
      "    load_throughput: 20174.588\n",
      "    load_time_ms: 495.475\n",
      "    sample_throughput: 80.403\n",
      "    sample_time_ms: 124323.922\n",
      "    update_time_ms: 10.559\n",
      "  timestamp: 1636292023\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239904\n",
      "  training_iteration: 24\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         3345.48</td><td style=\"text-align: right;\">239904</td><td style=\"text-align: right;\">0.671442</td><td style=\"text-align: right;\">                 6.8</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">           95.5096</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 249900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-36-12\n",
      "  done: false\n",
      "  episode_len_mean: 95.5047619047619\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.910000000000005\n",
      "  episode_reward_mean: 0.8048571428571444\n",
      "  episode_reward_min: -1.7200000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 2595\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.707100103655432\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01598095140212039\n",
      "          policy_loss: -0.06017398072163993\n",
      "          total_loss: 0.07524562221976658\n",
      "          vf_explained_var: 0.7774372696876526\n",
      "          vf_loss: 0.12608399865273226\n",
      "    num_agent_steps_sampled: 249900\n",
      "    num_agent_steps_trained: 249900\n",
      "    num_steps_sampled: 249900\n",
      "    num_steps_trained: 249900\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.75887850467291\n",
      "    ram_util_percent: 55.34532710280373\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048658127874602726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.722664984775545\n",
      "    mean_inference_ms: 2.8953338356952423\n",
      "    mean_raw_obs_processing_ms: 2.183688824788581\n",
      "  time_since_restore: 3494.9455938339233\n",
      "  time_this_iter_s: 149.46070289611816\n",
      "  time_total_s: 3494.9455938339233\n",
      "  timers:\n",
      "    learn_throughput: 800.349\n",
      "    learn_time_ms: 12489.552\n",
      "    load_throughput: 20138.924\n",
      "    load_time_ms: 496.352\n",
      "    sample_throughput: 79.108\n",
      "    sample_time_ms: 126358.908\n",
      "    update_time_ms: 10.728\n",
      "  timestamp: 1636292172\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249900\n",
      "  training_iteration: 25\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         3494.95</td><td style=\"text-align: right;\">249900</td><td style=\"text-align: right;\">0.804857</td><td style=\"text-align: right;\">                4.91</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           95.5048</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 259896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-38-23\n",
      "  done: false\n",
      "  episode_len_mean: 96.46601941747574\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.590000000000014\n",
      "  episode_reward_mean: 1.0924271844660218\n",
      "  episode_reward_min: -2.0399999999999996\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 2698\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7021835814174424\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016764205971913936\n",
      "          policy_loss: -0.05916271383976603\n",
      "          total_loss: 0.0849987753404381\n",
      "          vf_explained_var: 0.7875007390975952\n",
      "          vf_loss: 0.1329923674559746\n",
      "    num_agent_steps_sampled: 259896\n",
      "    num_agent_steps_trained: 259896\n",
      "    num_steps_sampled: 259896\n",
      "    num_steps_trained: 259896\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69786096256685\n",
      "    ram_util_percent: 55.560427807486626\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048640235331677856\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.693089502964668\n",
      "    mean_inference_ms: 2.8955547703108935\n",
      "    mean_raw_obs_processing_ms: 2.1252734826343826\n",
      "  time_since_restore: 3625.941352367401\n",
      "  time_this_iter_s: 130.99575853347778\n",
      "  time_total_s: 3625.941352367401\n",
      "  timers:\n",
      "    learn_throughput: 800.153\n",
      "    learn_time_ms: 12492.614\n",
      "    load_throughput: 20103.447\n",
      "    load_time_ms: 497.228\n",
      "    sample_throughput: 79.005\n",
      "    sample_time_ms: 126523.571\n",
      "    update_time_ms: 9.71\n",
      "  timestamp: 1636292303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259896\n",
      "  training_iteration: 26\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         3625.94</td><td style=\"text-align: right;\">259896</td><td style=\"text-align: right;\"> 1.09243</td><td style=\"text-align: right;\">                6.59</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">            96.466</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 269892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-40-35\n",
      "  done: false\n",
      "  episode_len_mean: 95.10377358490567\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.4800000000000075\n",
      "  episode_reward_mean: 1.113490566037738\n",
      "  episode_reward_min: -1.9900000000000009\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2804\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.702842872163169\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017012666659806296\n",
      "          policy_loss: -0.05642311986218382\n",
      "          total_loss: 0.09115412494990553\n",
      "          vf_explained_var: 0.7988400459289551\n",
      "          vf_loss: 0.13584869124043064\n",
      "    num_agent_steps_sampled: 269892\n",
      "    num_agent_steps_trained: 269892\n",
      "    num_steps_sampled: 269892\n",
      "    num_steps_trained: 269892\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.875\n",
      "    ram_util_percent: 55.84893617021277\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0486213281234889\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.688022202955878\n",
      "    mean_inference_ms: 2.8963657378266356\n",
      "    mean_raw_obs_processing_ms: 2.0719052460136207\n",
      "  time_since_restore: 3758.0431213378906\n",
      "  time_this_iter_s: 132.1017689704895\n",
      "  time_total_s: 3758.0431213378906\n",
      "  timers:\n",
      "    learn_throughput: 800.262\n",
      "    learn_time_ms: 12490.917\n",
      "    load_throughput: 20091.518\n",
      "    load_time_ms: 497.523\n",
      "    sample_throughput: 79.013\n",
      "    sample_time_ms: 126510.748\n",
      "    update_time_ms: 9.366\n",
      "  timestamp: 1636292435\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269892\n",
      "  training_iteration: 27\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         3758.04</td><td style=\"text-align: right;\">269892</td><td style=\"text-align: right;\"> 1.11349</td><td style=\"text-align: right;\">                6.48</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           95.1038</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 279888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-43-02\n",
      "  done: false\n",
      "  episode_len_mean: 95.67961165048544\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.910000000000019\n",
      "  episode_reward_mean: 1.0958252427184494\n",
      "  episode_reward_min: -2.0300000000000007\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 2907\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.708665060997009\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016861953852492388\n",
      "          policy_loss: -0.05944416807376397\n",
      "          total_loss: 0.09076555278132327\n",
      "          vf_explained_var: 0.7898940443992615\n",
      "          vf_loss: 0.13888273092193737\n",
      "    num_agent_steps_sampled: 279888\n",
      "    num_agent_steps_trained: 279888\n",
      "    num_steps_sampled: 279888\n",
      "    num_steps_trained: 279888\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.87942583732055\n",
      "    ram_util_percent: 55.52488038277511\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04864833349424903\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.633939112216645\n",
      "    mean_inference_ms: 2.895473728450101\n",
      "    mean_raw_obs_processing_ms: 2.1409295876539476\n",
      "  time_since_restore: 3904.657910346985\n",
      "  time_this_iter_s: 146.61478900909424\n",
      "  time_total_s: 3904.657910346985\n",
      "  timers:\n",
      "    learn_throughput: 800.471\n",
      "    learn_time_ms: 12487.646\n",
      "    load_throughput: 20128.965\n",
      "    load_time_ms: 496.598\n",
      "    sample_throughput: 79.014\n",
      "    sample_time_ms: 126509.99\n",
      "    update_time_ms: 9.231\n",
      "  timestamp: 1636292582\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279888\n",
      "  training_iteration: 28\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         3904.66</td><td style=\"text-align: right;\">279888</td><td style=\"text-align: right;\"> 1.09583</td><td style=\"text-align: right;\">                6.91</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">           95.6796</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 289884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-45-37\n",
      "  done: false\n",
      "  episode_len_mean: 96.59615384615384\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.830000000000013\n",
      "  episode_reward_mean: 1.2093269230769261\n",
      "  episode_reward_min: -2.0100000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 3011\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.713868202918615\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01622758503200376\n",
      "          policy_loss: -0.056005145744005794\n",
      "          total_loss: 0.09591588506402456\n",
      "          vf_explained_var: 0.7645260691642761\n",
      "          vf_loss: 0.14209124455148847\n",
      "    num_agent_steps_sampled: 289884\n",
      "    num_agent_steps_trained: 289884\n",
      "    num_steps_sampled: 289884\n",
      "    num_steps_trained: 289884\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.98783783783784\n",
      "    ram_util_percent: 55.49819819819819\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04863046596392877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.5475145407813\n",
      "    mean_inference_ms: 2.8937293606489876\n",
      "    mean_raw_obs_processing_ms: 2.210504797560726\n",
      "  time_since_restore: 4060.1562654972076\n",
      "  time_this_iter_s: 155.49835515022278\n",
      "  time_total_s: 4060.1562654972076\n",
      "  timers:\n",
      "    learn_throughput: 799.679\n",
      "    learn_time_ms: 12500.012\n",
      "    load_throughput: 20102.571\n",
      "    load_time_ms: 497.25\n",
      "    sample_throughput: 77.612\n",
      "    sample_time_ms: 128793.715\n",
      "    update_time_ms: 9.813\n",
      "  timestamp: 1636292737\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289884\n",
      "  training_iteration: 29\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         4060.16</td><td style=\"text-align: right;\">289884</td><td style=\"text-align: right;\"> 1.20933</td><td style=\"text-align: right;\">                8.83</td><td style=\"text-align: right;\">               -2.01</td><td style=\"text-align: right;\">           96.5962</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 299880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-47-48\n",
      "  done: false\n",
      "  episode_len_mean: 96.93203883495146\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.480000000000012\n",
      "  episode_reward_mean: 0.8754368932038863\n",
      "  episode_reward_min: -1.94\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 3114\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7122195904071513\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017025060210008686\n",
      "          policy_loss: -0.06020125627198864\n",
      "          total_loss: 0.09091485077028315\n",
      "          vf_explained_var: 0.7639102339744568\n",
      "          vf_loss: 0.13945308590514793\n",
      "    num_agent_steps_sampled: 299880\n",
      "    num_agent_steps_trained: 299880\n",
      "    num_steps_sampled: 299880\n",
      "    num_steps_trained: 299880\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.64946236559142\n",
      "    ram_util_percent: 55.66612903225807\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048619057463710924\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.525523960329416\n",
      "    mean_inference_ms: 2.8941412274801883\n",
      "    mean_raw_obs_processing_ms: 2.1586235324378795\n",
      "  time_since_restore: 4190.217719078064\n",
      "  time_this_iter_s: 130.06145358085632\n",
      "  time_total_s: 4190.217719078064\n",
      "  timers:\n",
      "    learn_throughput: 798.705\n",
      "    learn_time_ms: 12515.251\n",
      "    load_throughput: 20094.419\n",
      "    load_time_ms: 497.452\n",
      "    sample_throughput: 77.735\n",
      "    sample_time_ms: 128590.87\n",
      "    update_time_ms: 9.695\n",
      "  timestamp: 1636292868\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299880\n",
      "  training_iteration: 30\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         4190.22</td><td style=\"text-align: right;\">299880</td><td style=\"text-align: right;\">0.875437</td><td style=\"text-align: right;\">                6.48</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">            96.932</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 309876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-50-13\n",
      "  done: false\n",
      "  episode_len_mean: 94.15094339622641\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.610000000000014\n",
      "  episode_reward_mean: 1.276792452830191\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 3220\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.709471003214518\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01819409205455538\n",
      "          policy_loss: -0.054841221122142784\n",
      "          total_loss: 0.11570147908298681\n",
      "          vf_explained_var: 0.7465397119522095\n",
      "          vf_loss: 0.156188993054068\n",
      "    num_agent_steps_sampled: 309876\n",
      "    num_agent_steps_trained: 309876\n",
      "    num_steps_sampled: 309876\n",
      "    num_steps_trained: 309876\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.99326923076923\n",
      "    ram_util_percent: 55.70192307692309\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04862967368156442\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.49649152600038\n",
      "    mean_inference_ms: 2.8932846582561025\n",
      "    mean_raw_obs_processing_ms: 2.2144498390350225\n",
      "  time_since_restore: 4335.822265863419\n",
      "  time_this_iter_s: 145.60454678535461\n",
      "  time_total_s: 4335.822265863419\n",
      "  timers:\n",
      "    learn_throughput: 798.495\n",
      "    learn_time_ms: 12518.546\n",
      "    load_throughput: 20079.481\n",
      "    load_time_ms: 497.822\n",
      "    sample_throughput: 78.517\n",
      "    sample_time_ms: 127310.341\n",
      "    update_time_ms: 9.574\n",
      "  timestamp: 1636293013\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309876\n",
      "  training_iteration: 31\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         4335.82</td><td style=\"text-align: right;\">309876</td><td style=\"text-align: right;\"> 1.27679</td><td style=\"text-align: right;\">                8.61</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           94.1509</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 319872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-52-38\n",
      "  done: false\n",
      "  episode_len_mean: 97.84313725490196\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.590000000000013\n",
      "  episode_reward_mean: 0.9889215686274534\n",
      "  episode_reward_min: -1.990000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 3322\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.712596161141355\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01599820323550902\n",
      "          policy_loss: -0.05543722986078495\n",
      "          total_loss: 0.08367633392693076\n",
      "          vf_explained_var: 0.7451394200325012\n",
      "          vf_loss: 0.12979361726623825\n",
      "    num_agent_steps_sampled: 319872\n",
      "    num_agent_steps_trained: 319872\n",
      "    num_steps_sampled: 319872\n",
      "    num_steps_trained: 319872\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.50485436893204\n",
      "    ram_util_percent: 55.407281553398064\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048563416682722745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.48421687865873\n",
      "    mean_inference_ms: 2.8927734501621667\n",
      "    mean_raw_obs_processing_ms: 2.2198106635837087\n",
      "  time_since_restore: 4480.681976556778\n",
      "  time_this_iter_s: 144.85971069335938\n",
      "  time_total_s: 4480.681976556778\n",
      "  timers:\n",
      "    learn_throughput: 798.336\n",
      "    learn_time_ms: 12521.045\n",
      "    load_throughput: 20056.539\n",
      "    load_time_ms: 498.391\n",
      "    sample_throughput: 78.224\n",
      "    sample_time_ms: 127786.724\n",
      "    update_time_ms: 9.583\n",
      "  timestamp: 1636293158\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319872\n",
      "  training_iteration: 32\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         4480.68</td><td style=\"text-align: right;\">319872</td><td style=\"text-align: right;\">0.988922</td><td style=\"text-align: right;\">                6.59</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           97.8431</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 329868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-54-51\n",
      "  done: false\n",
      "  episode_len_mean: 99.46078431372548\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.460000000000013\n",
      "  episode_reward_mean: 0.8931372549019624\n",
      "  episode_reward_min: -1.950000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 3424\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.711072022283179\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01409713317381184\n",
      "          policy_loss: -0.06184566554724852\n",
      "          total_loss: 0.05098609736966095\n",
      "          vf_explained_var: 0.7589762806892395\n",
      "          vf_loss: 0.1078274502347295\n",
      "    num_agent_steps_sampled: 329868\n",
      "    num_agent_steps_trained: 329868\n",
      "    num_steps_sampled: 329868\n",
      "    num_steps_trained: 329868\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.52631578947368\n",
      "    ram_util_percent: 55.5921052631579\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04854918991285877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.47479786967357\n",
      "    mean_inference_ms: 2.8926036200396807\n",
      "    mean_raw_obs_processing_ms: 2.171617488923011\n",
      "  time_since_restore: 4613.52497959137\n",
      "  time_this_iter_s: 132.84300303459167\n",
      "  time_total_s: 4613.52497959137\n",
      "  timers:\n",
      "    learn_throughput: 798.121\n",
      "    learn_time_ms: 12524.424\n",
      "    load_throughput: 20044.542\n",
      "    load_time_ms: 498.689\n",
      "    sample_throughput: 77.979\n",
      "    sample_time_ms: 128188.224\n",
      "    update_time_ms: 9.253\n",
      "  timestamp: 1636293291\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329868\n",
      "  training_iteration: 33\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         4613.52</td><td style=\"text-align: right;\">329868</td><td style=\"text-align: right;\">0.893137</td><td style=\"text-align: right;\">                4.46</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           99.4608</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 339864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-57-20\n",
      "  done: false\n",
      "  episode_len_mean: 97.09708737864078\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.80000000000001\n",
      "  episode_reward_mean: 1.0263106796116532\n",
      "  episode_reward_min: -1.810000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 3527\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7088166094233848\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01676516191609502\n",
      "          policy_loss: -0.05642231985152143\n",
      "          total_loss: 0.08512800530616083\n",
      "          vf_explained_var: 0.8004439473152161\n",
      "          vf_loss: 0.13044535623640457\n",
      "    num_agent_steps_sampled: 339864\n",
      "    num_agent_steps_trained: 339864\n",
      "    num_steps_sampled: 339864\n",
      "    num_steps_trained: 339864\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.68679245283018\n",
      "    ram_util_percent: 55.862264150943375\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048504146408397765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.459983051251907\n",
      "    mean_inference_ms: 2.8917939168612845\n",
      "    mean_raw_obs_processing_ms: 2.180682559601817\n",
      "  time_since_restore: 4762.288535833359\n",
      "  time_this_iter_s: 148.76355624198914\n",
      "  time_total_s: 4762.288535833359\n",
      "  timers:\n",
      "    learn_throughput: 798.82\n",
      "    learn_time_ms: 12513.464\n",
      "    load_throughput: 20045.059\n",
      "    load_time_ms: 498.677\n",
      "    sample_throughput: 77.701\n",
      "    sample_time_ms: 128647.238\n",
      "    update_time_ms: 9.112\n",
      "  timestamp: 1636293440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 339864\n",
      "  training_iteration: 34\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         4762.29</td><td style=\"text-align: right;\">339864</td><td style=\"text-align: right;\"> 1.02631</td><td style=\"text-align: right;\">                 8.8</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           97.0971</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 349860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_13-59-45\n",
      "  done: false\n",
      "  episode_len_mean: 96.33009708737865\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.590000000000014\n",
      "  episode_reward_mean: 1.2452427184466042\n",
      "  episode_reward_min: -2.05\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 3630\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7061106787787543\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018915783407043214\n",
      "          policy_loss: -0.054425117682315345\n",
      "          total_loss: 0.11094976774769841\n",
      "          vf_explained_var: 0.7687221169471741\n",
      "          vf_loss: 0.14934347298426123\n",
      "    num_agent_steps_sampled: 349860\n",
      "    num_agent_steps_trained: 349860\n",
      "    num_steps_sampled: 349860\n",
      "    num_steps_trained: 349860\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.80917874396135\n",
      "    ram_util_percent: 55.513043478260876\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048483522485372646\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.419375169154215\n",
      "    mean_inference_ms: 2.89117438703029\n",
      "    mean_raw_obs_processing_ms: 2.2317647542529127\n",
      "  time_since_restore: 4907.509294271469\n",
      "  time_this_iter_s: 145.22075843811035\n",
      "  time_total_s: 4907.509294271469\n",
      "  timers:\n",
      "    learn_throughput: 799.768\n",
      "    learn_time_ms: 12498.624\n",
      "    load_throughput: 20053.69\n",
      "    load_time_ms: 498.462\n",
      "    sample_throughput: 77.949\n",
      "    sample_time_ms: 128237.371\n",
      "    update_time_ms: 9.688\n",
      "  timestamp: 1636293585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 349860\n",
      "  training_iteration: 35\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         4907.51</td><td style=\"text-align: right;\">349860</td><td style=\"text-align: right;\"> 1.24524</td><td style=\"text-align: right;\">                8.59</td><td style=\"text-align: right;\">               -2.05</td><td style=\"text-align: right;\">           96.3301</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 359856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-01-54\n",
      "  done: false\n",
      "  episode_len_mean: 97.32038834951456\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.480000000000011\n",
      "  episode_reward_mean: 1.0744660194174787\n",
      "  episode_reward_min: -1.9700000000000006\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 3733\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.708618607887855\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016554946444030175\n",
      "          policy_loss: -0.05340847213425834\n",
      "          total_loss: 0.09604238723839398\n",
      "          vf_explained_var: 0.8036810755729675\n",
      "          vf_loss: 0.138822806513526\n",
      "    num_agent_steps_sampled: 359856\n",
      "    num_agent_steps_trained: 359856\n",
      "    num_steps_sampled: 359856\n",
      "    num_steps_trained: 359856\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7372972972973\n",
      "    ram_util_percent: 55.598918918918926\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04849140487488625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.396268348324618\n",
      "    mean_inference_ms: 2.8917686764762385\n",
      "    mean_raw_obs_processing_ms: 2.1871229358763777\n",
      "  time_since_restore: 5036.655822277069\n",
      "  time_this_iter_s: 129.14652800559998\n",
      "  time_total_s: 5036.655822277069\n",
      "  timers:\n",
      "    learn_throughput: 800.01\n",
      "    learn_time_ms: 12494.848\n",
      "    load_throughput: 20062.193\n",
      "    load_time_ms: 498.251\n",
      "    sample_throughput: 78.059\n",
      "    sample_time_ms: 128056.182\n",
      "    update_time_ms: 9.874\n",
      "  timestamp: 1636293714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 359856\n",
      "  training_iteration: 36\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         5036.66</td><td style=\"text-align: right;\">359856</td><td style=\"text-align: right;\"> 1.07447</td><td style=\"text-align: right;\">                6.48</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           97.3204</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 369852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-04-21\n",
      "  done: false\n",
      "  episode_len_mean: 95.88461538461539\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.9700000000000095\n",
      "  episode_reward_mean: 1.337019230769234\n",
      "  episode_reward_min: -2.1899999999999986\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 3837\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.698765781394437\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018428331711593263\n",
      "          policy_loss: -0.04798429309330536\n",
      "          total_loss: 0.1424753571843826\n",
      "          vf_explained_var: 0.7764484882354736\n",
      "          vf_loss: 0.1754652638720651\n",
      "    num_agent_steps_sampled: 369852\n",
      "    num_agent_steps_trained: 369852\n",
      "    num_steps_sampled: 369852\n",
      "    num_steps_trained: 369852\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.8377990430622\n",
      "    ram_util_percent: 55.94114832535885\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048443171423129025\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.36723067236452\n",
      "    mean_inference_ms: 2.891202664896784\n",
      "    mean_raw_obs_processing_ms: 2.1974845408677774\n",
      "  time_since_restore: 5183.137670040131\n",
      "  time_this_iter_s: 146.48184776306152\n",
      "  time_total_s: 5183.137670040131\n",
      "  timers:\n",
      "    learn_throughput: 799.759\n",
      "    learn_time_ms: 12498.761\n",
      "    load_throughput: 20069.602\n",
      "    load_time_ms: 498.067\n",
      "    sample_throughput: 77.195\n",
      "    sample_time_ms: 129490.639\n",
      "    update_time_ms: 9.7\n",
      "  timestamp: 1636293861\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 369852\n",
      "  training_iteration: 37\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         5183.14</td><td style=\"text-align: right;\">369852</td><td style=\"text-align: right;\"> 1.33702</td><td style=\"text-align: right;\">                6.97</td><td style=\"text-align: right;\">               -2.19</td><td style=\"text-align: right;\">           95.8846</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552471)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552469)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 379848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-06-45\n",
      "  done: false\n",
      "  episode_len_mean: 94.84761904761905\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.9500000000000135\n",
      "  episode_reward_mean: 1.451809523809527\n",
      "  episode_reward_min: -1.8400000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3942\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7010525489464783\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015702452981060527\n",
      "          policy_loss: -0.05412472604818745\n",
      "          total_loss: 0.11406689591304191\n",
      "          vf_explained_var: 0.7943245768547058\n",
      "          vf_loss: 0.1594299938163569\n",
      "    num_agent_steps_sampled: 379848\n",
      "    num_agent_steps_trained: 379848\n",
      "    num_steps_sampled: 379848\n",
      "    num_steps_trained: 379848\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.48097560975609\n",
      "    ram_util_percent: 55.81463414634146\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04845470806962906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33361267406628\n",
      "    mean_inference_ms: 2.8907719873754303\n",
      "    mean_raw_obs_processing_ms: 2.2412267845452662\n",
      "  time_since_restore: 5327.212578058243\n",
      "  time_this_iter_s: 144.07490801811218\n",
      "  time_total_s: 5327.212578058243\n",
      "  timers:\n",
      "    learn_throughput: 799.608\n",
      "    learn_time_ms: 12501.128\n",
      "    load_throughput: 20026.966\n",
      "    load_time_ms: 499.127\n",
      "    sample_throughput: 77.348\n",
      "    sample_time_ms: 129233.442\n",
      "    update_time_ms: 9.69\n",
      "  timestamp: 1636294005\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 379848\n",
      "  training_iteration: 38\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         5327.21</td><td style=\"text-align: right;\">379848</td><td style=\"text-align: right;\"> 1.45181</td><td style=\"text-align: right;\">                6.95</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           94.8476</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 389844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-08-57\n",
      "  done: false\n",
      "  episode_len_mean: 96.34615384615384\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.510000000000012\n",
      "  episode_reward_mean: 1.1890384615384642\n",
      "  episode_reward_min: -2.17\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 4046\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.698417137830685\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017353736332599973\n",
      "          policy_loss: -0.05533135909447596\n",
      "          total_loss: 0.10735864956205528\n",
      "          vf_explained_var: 0.7998394966125488\n",
      "          vf_loss: 0.1501401976101164\n",
      "    num_agent_steps_sampled: 389844\n",
      "    num_agent_steps_trained: 389844\n",
      "    num_steps_sampled: 389844\n",
      "    num_steps_trained: 389844\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89788359788358\n",
      "    ram_util_percent: 55.64391534391536\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04848167952648531\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.336307512932933\n",
      "    mean_inference_ms: 2.8911696213696745\n",
      "    mean_raw_obs_processing_ms: 2.2006330758914086\n",
      "  time_since_restore: 5459.362672328949\n",
      "  time_this_iter_s: 132.15009427070618\n",
      "  time_total_s: 5459.362672328949\n",
      "  timers:\n",
      "    learn_throughput: 799.669\n",
      "    learn_time_ms: 12500.17\n",
      "    load_throughput: 20050.8\n",
      "    load_time_ms: 498.534\n",
      "    sample_throughput: 78.771\n",
      "    sample_time_ms: 126899.78\n",
      "    update_time_ms: 10.171\n",
      "  timestamp: 1636294137\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 389844\n",
      "  training_iteration: 39\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         5459.36</td><td style=\"text-align: right;\">389844</td><td style=\"text-align: right;\"> 1.18904</td><td style=\"text-align: right;\">                8.51</td><td style=\"text-align: right;\">               -2.17</td><td style=\"text-align: right;\">           96.3462</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_81db5_00000:\n",
      "  agent_timesteps_total: 399840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-11-08\n",
      "  done: false\n",
      "  episode_len_mean: 97.2621359223301\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.610000000000017\n",
      "  episode_reward_mean: 1.1024271844660216\n",
      "  episode_reward_min: -1.7900000000000007\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4149\n",
      "  experiment_id: fa07df177b244fd6a682580aebaab5aa\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7054897664958597\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014789822021000239\n",
      "          policy_loss: -0.05670293285394521\n",
      "          total_loss: 0.08354698522369632\n",
      "          vf_explained_var: 0.7896628379821777\n",
      "          vf_loss: 0.13361175131434813\n",
      "    num_agent_steps_sampled: 399840\n",
      "    num_agent_steps_trained: 399840\n",
      "    num_steps_sampled: 399840\n",
      "    num_steps_trained: 399840\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.41069518716576\n",
      "    ram_util_percent: 55.83422459893048\n",
      "  pid: 552473\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04843250618700141\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.325584132915573\n",
      "    mean_inference_ms: 2.8914477054543526\n",
      "    mean_raw_obs_processing_ms: 2.1628426882062812\n",
      "  time_since_restore: 5590.254289627075\n",
      "  time_this_iter_s: 130.89161729812622\n",
      "  time_total_s: 5590.254289627075\n",
      "  timers:\n",
      "    learn_throughput: 800.359\n",
      "    learn_time_ms: 12489.396\n",
      "    load_throughput: 20059.568\n",
      "    load_time_ms: 498.316\n",
      "    sample_throughput: 78.713\n",
      "    sample_time_ms: 126993.604\n",
      "    update_time_ms: 10.081\n",
      "  timestamp: 1636294268\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 399840\n",
      "  training_iteration: 40\n",
      "  trial_id: 81db5_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.37 GiB heap, 0.0/10.69 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_12-37-45<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_81db5_00000</td><td>RUNNING </td><td>192.168.3.5:552473</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         5590.25</td><td style=\"text-align: right;\">399840</td><td style=\"text-align: right;\"> 1.10243</td><td style=\"text-align: right;\">                6.61</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           97.2621</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=552472)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2021-11-07 14:11:55,767\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2021-11-07 14:11:55,765\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "Process _WandbLoggingProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/integration/wandb.py\", line 200, in run\n",
      "    result = self.queue.get()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/util.py\", line 322, in _exit_function\n",
      "    p.join()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n",
      "Process wandb_internal:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/wandb/sdk/internal/internal.py\", line 152, in wandb_internal\n",
      "    thread.join()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "2021-11-07 14:11:56,512\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_552359/2342650933.py\", line 34, in <module>\n",
      "    checkpoint_at_end=True)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\", line 532, in run\n",
      "    runner.step()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 554, in step\n",
      "    self._process_events(timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 675, in _process_events\n",
      "    timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 718, in get_next_available_trial\n",
      "    ready, _ = ray.wait(shuffled_results, timeout=timeout)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\", line 1793, in wait\n",
      "    fetch_local,\n",
      "  File \"python/ray/_raylet.pyx\", line 1222, in ray._raylet.CoreWorker.wait\n",
      "  File \"python/ray/_raylet.pyx\", line 155, in ray._raylet.check_status\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_552359/2342650933.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcheckpoint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         checkpoint_at_end=True)\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    674\u001b[0m             trial = self.trial_executor.get_next_available_trial(\n\u001b[0;32m--> 675\u001b[0;31m                 timeout=timeout)  # blocking\n\u001b[0m\u001b[1;32m    676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mfetch_local\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         )\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 256,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 5_000,\n",
    "             \"lr\": 1e-4,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO All Tasks pretrained (AngelaCNN+GRU) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/all_tasks\",\n",
    "        keep_checkpoints_num=50,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
