{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4, padding=0),  \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(64, 512, kernel_size=2, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        features_dim = 512\n",
    "        self.encoder = VisualEncoder()\n",
    "        self.encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AnnaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.qvalue_head = nn.Linear(features_dim, num_outputs)\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.encoder.cuda()\n",
    "            self.qvalue_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        if self.use_cuda:\n",
    "            obs.cuda()\n",
    "            \n",
    "        features = self.encoder(obs)\n",
    "        qvalues = self.qvalue_head(features)\n",
    "        return qvalues, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=1000)\n",
    "    env.update_taskset(TaskSet(preset=['C17']))\n",
    "    env = PovOnlyWrapper(env)\n",
    "    env = IgluActionWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.dqn import DQNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 21:43:34,141\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-09-18 21:43:34,159\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id e5f53_00000 but id 79012_00000 is set.\n",
      "\u001b[2m\u001b[36m(pid=192079)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192079)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">DQN C17 pretrained (AnnaCNN)</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/79012_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/79012_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20210918_214334-79012_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192079)\u001b[0m 2021-09-18 21:43:37,678\tINFO dqn.py:188 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=192079)\u001b[0m 2021-09-18 21:43:37,678\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=192079)\u001b[0m 2021-09-18 21:43:45,536\tINFO trainable.py:109 -- Trainable.setup took 10.375 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=192079)\u001b[0m 2021-09-18 21:43:45,537\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 1000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-44-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: 0.0\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 1\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4.673000812530518\n",
      "          mean_q: -0.2864062786102295\n",
      "          min_q: -6.367076873779297\n",
      "        mean_td_error: 2.974947452545166\n",
      "        td_error: \"[10.027929    2.64336    -0.36019802  7.262098   -4.910972    8.456795\\n\\\n",
      "          \\ -6.7695312  -1.2066615   7.0700674   7.518149    6.6573467  -1.8900771\\n\\\n",
      "          \\ -0.9292927  -1.1667905   2.3895497  -0.4885858   0.4589427   1.8361897\\n\\\n",
      "          \\  7.0835295   4.2463355   8.84908     3.988898    8.994044   -0.9691594\\n\\\n",
      "          \\  5.186923    3.4442801  -5.8289447   2.9866636   6.060691    8.172208\\n\\\n",
      "          \\  6.1549497   0.23050332]\"\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.82058823529412\n",
      "    ram_util_percent: 68.62941176470588\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0437189649035047\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 68.21707769350095\n",
      "    mean_inference_ms: 1.7402791357659675\n",
      "    mean_raw_obs_processing_ms: 0.17104186973609886\n",
      "  time_since_restore: 70.84139800071716\n",
      "  time_this_iter_s: 70.84139800071716\n",
      "  time_total_s: 70.84139800071716\n",
      "  timers:\n",
      "    learn_throughput: 2921.206\n",
      "    learn_time_ms: 10.954\n",
      "    load_throughput: 2523.601\n",
      "    load_time_ms: 12.68\n",
      "    update_time_ms: 2.806\n",
      "  timestamp: 1632001496\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         70.8414</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 2000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-45-10\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -3.5\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 2\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 1504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -7.14740514755249\n",
      "          mean_q: -10.505796432495117\n",
      "          min_q: -12.08890438079834\n",
      "        mean_td_error: -0.12799526751041412\n",
      "        td_error: \"[ 0.29074192 -0.20342827  0.00730419 -0.10215187 -0.29607582  0.02104473\\n\\\n",
      "          \\ -0.82810116  0.47841263 -0.21363926 -0.42518806  0.06174469 -0.09171391\\n\\\n",
      "          \\ -0.20644951 -0.39144278 -0.38611984 -0.46460342 -0.02211571 -0.4322958\\n\\\n",
      "          \\ -0.05741024 -0.13162708 -0.07798576 -0.10860348  0.73654652  0.43892097\\n\\\n",
      "          \\  0.00730419 -0.03979301 -0.1202383  -0.38152695 -0.32791805 -0.18364716\\n\\\n",
      "          \\ -0.52649879 -0.11929417]\"\n",
      "    num_agent_steps_sampled: 2000\n",
      "    num_agent_steps_trained: 8032\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 8032\n",
      "    num_target_updates: 2\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.230000000000004\n",
      "    ram_util_percent: 75.95500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04293069247128482\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 53.2023478863873\n",
      "    mean_inference_ms: 1.7059234033555368\n",
      "    mean_raw_obs_processing_ms: 0.17522386992243386\n",
      "  time_since_restore: 84.81094598770142\n",
      "  time_this_iter_s: 13.969547986984253\n",
      "  time_total_s: 84.81094598770142\n",
      "  timers:\n",
      "    learn_throughput: 3845.284\n",
      "    learn_time_ms: 8.322\n",
      "    load_throughput: 62482.067\n",
      "    load_time_ms: 0.512\n",
      "    update_time_ms: 1.642\n",
      "  timestamp: 1632001510\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 2\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         84.8109</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">    -3.5</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 3000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-45-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -2.3333333333333335\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 3\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 2512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -6.573307037353516\n",
      "          mean_q: -9.210827827453613\n",
      "          min_q: -11.30009651184082\n",
      "        mean_td_error: 0.029880955815315247\n",
      "        td_error: \"[ 0.3161106   0.08565617 -0.67919636 -0.11431885  0.33440018 -0.08747768\\n\\\n",
      "          \\ -0.21803665  0.11559486  0.00648785  0.396883   -0.12437057  0.39020538\\n\\\n",
      "          \\  0.31508255 -0.12793541  0.49068928  0.2161026  -0.19348621  0.25642204\\n\\\n",
      "          \\  0.27713013 -0.04341125  0.16273499 -0.20053768 -0.2981825  -0.05867529\\n\\\n",
      "          \\ -0.05711317  0.00917721 -0.55943394  0.33622074 -0.2117691  -0.05860996\\n\\\n",
      "          \\  0.14737034  0.13247728]\"\n",
      "    num_agent_steps_sampled: 3000\n",
      "    num_agent_steps_trained: 16032\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 16032\n",
      "    num_target_updates: 4\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.16666666666666\n",
      "    ram_util_percent: 76.2\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04246457554667706\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 44.78209990168824\n",
      "    mean_inference_ms: 1.684211417436076\n",
      "    mean_raw_obs_processing_ms: 0.174194867789259\n",
      "  time_since_restore: 98.029132604599\n",
      "  time_this_iter_s: 13.218186616897583\n",
      "  time_total_s: 98.029132604599\n",
      "  timers:\n",
      "    learn_throughput: 3889.771\n",
      "    learn_time_ms: 8.227\n",
      "    load_throughput: 68089.351\n",
      "    load_time_ms: 0.47\n",
      "    update_time_ms: 1.725\n",
      "  timestamp: 1632001523\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 3\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         98.0291</td><td style=\"text-align: right;\">3000</td><td style=\"text-align: right;\">-2.33333</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-45-36\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -1.75\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 4\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 3520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -6.433832168579102\n",
      "          mean_q: -9.383733749389648\n",
      "          min_q: -11.126391410827637\n",
      "        mean_td_error: -0.12079459428787231\n",
      "        td_error: \"[-0.15248966 -0.270442   -0.14918995 -0.3243003  -0.96040154 -0.02317715\\n\\\n",
      "          \\  0.3066864  -0.33085537  0.04563522 -0.13394451 -0.28259277  0.16179752\\n\\\n",
      "          \\ -0.1500678  -0.14478397  0.21493149  0.5198579   0.53211594 -1.1480222\\n\\\n",
      "          \\ -0.41984844 -0.23652554 -0.102561   -0.45788383  0.1594696  -0.0093956\\n\\\n",
      "          \\  0.15388298 -0.15271473  0.1359663  -0.14487267 -0.07469559 -0.1724472\\n\\\n",
      "          \\ -0.10704899 -0.14750957]\"\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 24032\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 24032\n",
      "    num_target_updates: 6\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.89473684210527\n",
      "    ram_util_percent: 76.88947368421054\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04209052376587995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 39.29181532415926\n",
      "    mean_inference_ms: 1.6682632221520801\n",
      "    mean_raw_obs_processing_ms: 0.17317289544039394\n",
      "  time_since_restore: 111.14311194419861\n",
      "  time_this_iter_s: 13.11397933959961\n",
      "  time_total_s: 111.14311194419861\n",
      "  timers:\n",
      "    learn_throughput: 3891.756\n",
      "    learn_time_ms: 8.223\n",
      "    load_throughput: 65757.546\n",
      "    load_time_ms: 0.487\n",
      "    update_time_ms: 1.763\n",
      "  timestamp: 1632001536\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 4\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         111.143</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">   -1.75</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 5000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-45-49\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -1.4\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 5\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 4528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -5.413679122924805\n",
      "          mean_q: -7.750463485717773\n",
      "          min_q: -10.229337692260742\n",
      "        mean_td_error: 0.0107831209897995\n",
      "        td_error: \"[-0.17898464 -0.24409008  0.2301073  -0.13301754 -0.61808443 -0.03471518\\n\\\n",
      "          \\ -0.4417715  -0.29574013  0.37897873  0.17284012  0.30318165  0.25849438\\n\\\n",
      "          \\  0.25861502  0.57318974  0.01592255 -0.4034214  -0.13021755  0.25861502\\n\\\n",
      "          \\  0.13047695 -0.1393094  -0.0794034  -0.10541344  0.13083315  0.0359745\\n\\\n",
      "          \\ -0.13350916  0.07345724  0.12512016  0.0140624   0.00102663 -0.03082132\\n\\\n",
      "          \\  0.34195375  0.01070976]\"\n",
      "    num_agent_steps_sampled: 5000\n",
      "    num_agent_steps_trained: 32032\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 32032\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.45263157894737\n",
      "    ram_util_percent: 76.94736842105264\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04181845864327882\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.380243086098574\n",
      "    mean_inference_ms: 1.656106394372543\n",
      "    mean_raw_obs_processing_ms: 0.172016184606179\n",
      "  time_since_restore: 124.19481778144836\n",
      "  time_this_iter_s: 13.051705837249756\n",
      "  time_total_s: 124.19481778144836\n",
      "  timers:\n",
      "    learn_throughput: 3878.744\n",
      "    learn_time_ms: 8.25\n",
      "    load_throughput: 67996.215\n",
      "    load_time_ms: 0.471\n",
      "    update_time_ms: 1.577\n",
      "  timestamp: 1632001549\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 5\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         124.195</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">    -1.4</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 6000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-46-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -1.1666666666666667\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 6\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 5536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -4.772940158843994\n",
      "          mean_q: -6.730877876281738\n",
      "          min_q: -9.288907051086426\n",
      "        mean_td_error: 0.14136357605457306\n",
      "        td_error: \"[-0.8442359   0.32061148  0.05851603 -0.04691744 -0.17842865 -0.2625451\\n\\\n",
      "          \\ -0.08731222  0.10332012  0.12262297  0.58897114  0.12217045  0.35471535\\n\\\n",
      "          \\  0.07521296  0.12040615  0.1518178   0.44877863  0.2328453   0.19709826\\n\\\n",
      "          \\  0.56737614  0.06032181 -0.22938967  0.32085514  0.21272326  0.29747105\\n\\\n",
      "          \\  0.02523661  0.24436474  0.3021927   0.259418    0.10324383  0.38634825\\n\\\n",
      "          \\  0.4649167   0.03090858]\"\n",
      "    num_agent_steps_sampled: 6000\n",
      "    num_agent_steps_trained: 40032\n",
      "    num_steps_sampled: 6000\n",
      "    num_steps_trained: 40032\n",
      "    num_target_updates: 10\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.327777777777776\n",
      "    ram_util_percent: 76.92222222222225\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.041603948340418175\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.4263520870988\n",
      "    mean_inference_ms: 1.6463107104636094\n",
      "    mean_raw_obs_processing_ms: 0.17087422069605637\n",
      "  time_since_restore: 137.0901231765747\n",
      "  time_this_iter_s: 12.895305395126343\n",
      "  time_total_s: 137.0901231765747\n",
      "  timers:\n",
      "    learn_throughput: 3843.346\n",
      "    learn_time_ms: 8.326\n",
      "    load_throughput: 66961.549\n",
      "    load_time_ms: 0.478\n",
      "    update_time_ms: 1.642\n",
      "  timestamp: 1632001562\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 6\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">          137.09</td><td style=\"text-align: right;\">6000</td><td style=\"text-align: right;\">-1.16667</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 7000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-46-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -1.0\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 7\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 6544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -4.406432151794434\n",
      "          mean_q: -6.601197242736816\n",
      "          min_q: -7.950804233551025\n",
      "        mean_td_error: -0.010906681418418884\n",
      "        td_error: \"[ 0.06951094 -0.14714003 -0.32307625  0.05283737  0.05142403 -0.13982725\\n\\\n",
      "          \\  0.15855026 -0.35784292  0.28948832 -0.29547548  0.24098969 -0.02340412\\n\\\n",
      "          \\ -0.0220871   0.14803505  0.18096972 -0.00313997  0.23047495 -0.24001884\\n\\\n",
      "          \\  0.12159729 -0.57361746  0.25786924 -0.14498997 -0.06684399  0.17405367\\n\\\n",
      "          \\ -0.0033536   0.06961775  0.12732124 -0.10526514 -0.08854103  0.05339575\\n\\\n",
      "          \\ -0.0922966   0.05177069]\"\n",
      "    num_agent_steps_sampled: 7000\n",
      "    num_agent_steps_trained: 48032\n",
      "    num_steps_sampled: 7000\n",
      "    num_steps_trained: 48032\n",
      "    num_target_updates: 12\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.72777777777778\n",
      "    ram_util_percent: 76.92222222222223\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04142193081880678\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.100499481345572\n",
      "    mean_inference_ms: 1.6381763138149403\n",
      "    mean_raw_obs_processing_ms: 0.1698609079720181\n",
      "  time_since_restore: 149.79002404212952\n",
      "  time_this_iter_s: 12.69990086555481\n",
      "  time_total_s: 149.79002404212952\n",
      "  timers:\n",
      "    learn_throughput: 3890.437\n",
      "    learn_time_ms: 8.225\n",
      "    load_throughput: 66974.914\n",
      "    load_time_ms: 0.478\n",
      "    update_time_ms: 1.615\n",
      "  timestamp: 1632001575\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7000\n",
      "  training_iteration: 7\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">          149.79</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\">      -1</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 8000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-46-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -1.125\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 8\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 7552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -4.675305366516113\n",
      "          mean_q: -6.468472480773926\n",
      "          min_q: -8.977333068847656\n",
      "        mean_td_error: 0.14369216561317444\n",
      "        td_error: \"[ 0.18534517  0.1889615   0.1939311   0.2377286   0.15791464  0.55710506\\n\\\n",
      "          \\  0.21185398 -0.15650415  0.13556862  0.1485753   0.32682514  0.24498177\\n\\\n",
      "          \\  0.14300251  0.13095427  0.38039398  0.06554127  0.00088739 -0.24320602\\n\\\n",
      "          \\  0.36315727  0.08326721  0.12816    -0.05262804  0.18762064  0.06112146\\n\\\n",
      "          \\ -0.03294611  0.24930668  0.20516062  0.3381896  -0.38844442  0.3394227\\n\\\n",
      "          \\  0.10522985  0.1016717 ]\"\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 56032\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 56032\n",
      "    num_target_updates: 14\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.63157894736842\n",
      "    ram_util_percent: 77.1578947368421\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04127066160127911\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.22194719761388\n",
      "    mean_inference_ms: 1.6315447263087512\n",
      "    mean_raw_obs_processing_ms: 0.16905544541995993\n",
      "  time_since_restore: 163.02953433990479\n",
      "  time_this_iter_s: 13.239510297775269\n",
      "  time_total_s: 163.02953433990479\n",
      "  timers:\n",
      "    learn_throughput: 3847.665\n",
      "    learn_time_ms: 8.317\n",
      "    load_throughput: 67246.72\n",
      "    load_time_ms: 0.476\n",
      "    update_time_ms: 1.721\n",
      "  timestamp: 1632001588\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 8\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">          163.03</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">  -1.125</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 9000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-46-41\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -1.0\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 9\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 8560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -4.0863494873046875\n",
      "          mean_q: -5.707295894622803\n",
      "          min_q: -8.220646858215332\n",
      "        mean_td_error: -0.0062334612011909485\n",
      "        td_error: \"[-0.8542261  -0.08016729  0.2263937   0.13351536  0.05650997  0.07928371\\n\\\n",
      "          \\  0.23581362  0.10833454  0.02002954  0.03563213 -0.15421486  0.06459045\\n\\\n",
      "          \\ -0.20442247  0.24645805  0.15228748  0.14521742  0.13991785  0.12201214\\n\\\n",
      "          \\ -0.76774573  0.12738371  0.29291487  0.05375957 -0.02375174 -0.27696323\\n\\\n",
      "          \\ -0.0591464   0.307127   -0.36243868  0.21717978 -0.5726247   0.35486412\\n\\\n",
      "          \\  0.09803867 -0.06103325]\"\n",
      "    num_agent_steps_sampled: 9000\n",
      "    num_agent_steps_trained: 64032\n",
      "    num_steps_sampled: 9000\n",
      "    num_steps_trained: 64032\n",
      "    num_target_updates: 16\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.6578947368421\n",
      "    ram_util_percent: 77.52105263157894\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04113858822998579\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 26.662094267503033\n",
      "    mean_inference_ms: 1.6258892143474\n",
      "    mean_raw_obs_processing_ms: 0.16831460094503523\n",
      "  time_since_restore: 175.76498579978943\n",
      "  time_this_iter_s: 12.735451459884644\n",
      "  time_total_s: 175.76498579978943\n",
      "  timers:\n",
      "    learn_throughput: 3904.561\n",
      "    learn_time_ms: 8.196\n",
      "    load_throughput: 68328.528\n",
      "    load_time_ms: 0.468\n",
      "    update_time_ms: 1.677\n",
      "  timestamp: 1632001601\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9000\n",
      "  training_iteration: 9\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         175.765</td><td style=\"text-align: right;\">9000</td><td style=\"text-align: right;\">      -1</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 10000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-46-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.9\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 10\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 9568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -4.6550984382629395\n",
      "          mean_q: -5.4053120613098145\n",
      "          min_q: -6.231599807739258\n",
      "        mean_td_error: 0.1416890174150467\n",
      "        td_error: \"[ 0.0088644   0.18019009  0.15563965  0.18419695 -0.0194211   0.01757574\\n\\\n",
      "          \\  0.11802053  0.05857515  0.26461029  0.18782902  0.04374361  0.09643221\\n\\\n",
      "          \\  0.06248713 -0.03332663  0.48423386  0.21053123  0.17274141  0.05463696\\n\\\n",
      "          \\ -0.06997442  0.29258633  0.23615026  0.26964235  0.3139348   0.5971837\\n\\\n",
      "          \\  0.07134676  0.29060841  0.15302849  0.08852243  0.02116394  0.11825895\\n\\\n",
      "          \\  0.11691236 -0.21287632]\"\n",
      "    num_agent_steps_sampled: 10000\n",
      "    num_agent_steps_trained: 72032\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 72032\n",
      "    num_target_updates: 18\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.45882352941176\n",
      "    ram_util_percent: 78.07058823529412\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04102498598609615\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 25.338006964752488\n",
      "    mean_inference_ms: 1.6208965923990746\n",
      "    mean_raw_obs_processing_ms: 0.16760342175151874\n",
      "  time_since_restore: 187.96657395362854\n",
      "  time_this_iter_s: 12.201588153839111\n",
      "  time_total_s: 187.96657395362854\n",
      "  timers:\n",
      "    learn_throughput: 3859.482\n",
      "    learn_time_ms: 8.291\n",
      "    load_throughput: 67415.605\n",
      "    load_time_ms: 0.475\n",
      "    update_time_ms: 1.798\n",
      "  timestamp: 1632001613\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 10\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.2/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         187.967</td><td style=\"text-align: right;\">10000</td><td style=\"text-align: right;\">    -0.9</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 11000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-47-06\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.8181818181818182\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 11\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 10576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -3.5936570167541504\n",
      "          mean_q: -5.1761155128479\n",
      "          min_q: -6.363637924194336\n",
      "        mean_td_error: 0.03569931536912918\n",
      "        td_error: \"[ 0.01689911 -0.05960655 -0.039289   -0.1695919  -0.03459072  0.05724669\\n\\\n",
      "          \\  0.04026175 -0.46940255  0.06694031 -0.00944757  0.16921902  0.27079678\\n\\\n",
      "          \\  0.21130705  0.02407837  0.11245966  0.29006767 -0.18366337  0.0867281\\n\\\n",
      "          \\  0.21390486  0.1793809   0.13699913 -0.18868113 -0.2681284   0.19368649\\n\\\n",
      "          \\  0.22707939 -0.05501604  0.12798643 -0.0052352  -0.05532455 -0.09172535\\n\\\n",
      "          \\  0.33959484  0.0074439 ]\"\n",
      "    num_agent_steps_sampled: 11000\n",
      "    num_agent_steps_trained: 80032\n",
      "    num_steps_sampled: 11000\n",
      "    num_steps_trained: 80032\n",
      "    num_target_updates: 20\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.21666666666667\n",
      "    ram_util_percent: 78.50555555555556\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04092746399355302\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 24.203064705693574\n",
      "    mean_inference_ms: 1.6165777601404179\n",
      "    mean_raw_obs_processing_ms: 0.16695699828484553\n",
      "  time_since_restore: 200.85830807685852\n",
      "  time_this_iter_s: 12.89173412322998\n",
      "  time_total_s: 200.85830807685852\n",
      "  timers:\n",
      "    learn_throughput: 3904.391\n",
      "    learn_time_ms: 8.196\n",
      "    load_throughput: 67169.316\n",
      "    load_time_ms: 0.476\n",
      "    update_time_ms: 1.621\n",
      "  timestamp: 1632001626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11000\n",
      "  training_iteration: 11\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.2/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         200.858</td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\">-0.818182</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-47-19\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.75\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 12\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 11584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -0.8071195483207703\n",
      "          mean_q: -4.73500919342041\n",
      "          min_q: -6.780863285064697\n",
      "        mean_td_error: -0.010409332811832428\n",
      "        td_error: \"[ 0.04439211  0.01861906 -0.23006058 -0.02191544 -0.06022215 -0.16700792\\n\\\n",
      "          \\ -0.0024147  -0.00640917 -0.04365301 -0.20374155  0.14576435 -0.12463284\\n\\\n",
      "          \\ -0.19677305  0.5121002  -0.13513851 -0.05861044 -0.3168068   0.94361925\\n\\\n",
      "          \\  0.03647232  0.03965425  0.26104808 -0.04792738 -0.28947783 -0.16002703\\n\\\n",
      "          \\ -0.13507366 -0.240098   -0.09815502 -0.04672289 -0.12298536  0.11366749\\n\\\n",
      "          \\  0.10708952  0.15232801]\"\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 88032\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 88032\n",
      "    num_target_updates: 22\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.58421052631579\n",
      "    ram_util_percent: 78.71052631578947\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040841864993060396\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 23.218556553252526\n",
      "    mean_inference_ms: 1.6128775551700325\n",
      "    mean_raw_obs_processing_ms: 0.16637795572920688\n",
      "  time_since_restore: 213.82239079475403\n",
      "  time_this_iter_s: 12.964082717895508\n",
      "  time_total_s: 213.82239079475403\n",
      "  timers:\n",
      "    learn_throughput: 3807.53\n",
      "    learn_time_ms: 8.404\n",
      "    load_throughput: 62765.492\n",
      "    load_time_ms: 0.51\n",
      "    update_time_ms: 1.735\n",
      "  timestamp: 1632001639\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 12\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         213.822</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">   -0.75</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 13000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-47-32\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.6923076923076923\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 13\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 12592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -3.3653604984283447\n",
      "          mean_q: -4.898338317871094\n",
      "          min_q: -5.955390930175781\n",
      "        mean_td_error: -0.004489690065383911\n",
      "        td_error: \"[-0.07734537 -0.07218075  0.03968048  0.17262793 -0.05542517  0.12333202\\n\\\n",
      "          \\ -0.22847176  0.07239199 -0.05118847  0.11100245 -0.03561497 -0.04243898\\n\\\n",
      "          \\  0.12097359 -0.03342819  0.01096392 -0.10510445  0.03534985  0.01533794\\n\\\n",
      "          \\ -0.11318541  0.1084547  -0.07538033  0.0973649  -0.17673826  0.32180977\\n\\\n",
      "          \\ -0.08022118 -0.07049656 -0.10620785  0.14506865 -0.14208746  0.03393507\\n\\\n",
      "          \\ -0.06683922 -0.01960897]\"\n",
      "    num_agent_steps_sampled: 13000\n",
      "    num_agent_steps_trained: 96032\n",
      "    num_steps_sampled: 13000\n",
      "    num_steps_trained: 96032\n",
      "    num_target_updates: 24\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.757894736842104\n",
      "    ram_util_percent: 79.0578947368421\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04077520902863241\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 22.35597730226545\n",
      "    mean_inference_ms: 1.6098566868994781\n",
      "    mean_raw_obs_processing_ms: 0.16587499291260213\n",
      "  time_since_restore: 227.0891079902649\n",
      "  time_this_iter_s: 13.266717195510864\n",
      "  time_total_s: 227.0891079902649\n",
      "  timers:\n",
      "    learn_throughput: 3709.517\n",
      "    learn_time_ms: 8.626\n",
      "    load_throughput: 51825.519\n",
      "    load_time_ms: 0.617\n",
      "    update_time_ms: 1.917\n",
      "  timestamp: 1632001652\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13000\n",
      "  training_iteration: 13\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         227.089</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">-0.692308</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 14000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-47-46\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.6428571428571429\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 14\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 13600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -0.7208537459373474\n",
      "          mean_q: -4.061777591705322\n",
      "          min_q: -4.965319633483887\n",
      "        mean_td_error: 0.008724430575966835\n",
      "        td_error: \"[ 0.06552029 -0.17942643 -0.00077438  0.10195923  0.20495749  0.07375073\\n\\\n",
      "          \\ -0.04080963 -0.1194427  -0.00096512 -0.1611824   0.7060518   0.02492619\\n\\\n",
      "          \\  0.13468313 -0.06404781  0.08069277 -0.01262045 -0.2217269   0.4685259\\n\\\n",
      "          \\  0.12366509  0.11917305  0.02915478 -0.6477811   0.00219655  0.0844903\\n\\\n",
      "          \\  0.02546859 -0.32959318 -0.21968603 -0.02749586 -0.05122185  0.07427549\\n\\\n",
      "          \\  0.01680756  0.01965666]\"\n",
      "    num_agent_steps_sampled: 14000\n",
      "    num_agent_steps_trained: 104032\n",
      "    num_steps_sampled: 14000\n",
      "    num_steps_trained: 104032\n",
      "    num_target_updates: 26\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.88421052631579\n",
      "    ram_util_percent: 79.66315789473684\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040721283162018285\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 21.59406977014898\n",
      "    mean_inference_ms: 1.6073350151698296\n",
      "    mean_raw_obs_processing_ms: 0.16542847802573632\n",
      "  time_since_restore: 240.5171616077423\n",
      "  time_this_iter_s: 13.428053617477417\n",
      "  time_total_s: 240.5171616077423\n",
      "  timers:\n",
      "    learn_throughput: 3234.396\n",
      "    learn_time_ms: 9.894\n",
      "    load_throughput: 47376.537\n",
      "    load_time_ms: 0.675\n",
      "    update_time_ms: 1.699\n",
      "  timestamp: 1632001666\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14000\n",
      "  training_iteration: 14\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         240.517</td><td style=\"text-align: right;\">14000</td><td style=\"text-align: right;\">-0.642857</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 15000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-47-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.6\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 15\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 14608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -2.6821138858795166\n",
      "          mean_q: -3.9165806770324707\n",
      "          min_q: -4.885868072509766\n",
      "        mean_td_error: -0.07819058746099472\n",
      "        td_error: \"[ 0.16801262 -0.02446651  0.01501942 -0.13588381  0.08439684  0.13318682\\n\\\n",
      "          \\ -0.0058794   0.03417587  0.03930569  0.00947571  0.10768747 -0.01856565\\n\\\n",
      "          \\  0.01314783 -0.06984067  0.11224008  0.2942214   0.08866429 -0.0160923\\n\\\n",
      "          \\  0.17728353  0.02767324  0.01417375  0.15486884 -4.068378    0.02449417\\n\\\n",
      "          \\  0.10831594  0.09333396 -0.05987835 -0.05799055  0.07595134  0.04945469\\n\\\n",
      "          \\ -0.00684834  0.13664126]\"\n",
      "    num_agent_steps_sampled: 15000\n",
      "    num_agent_steps_trained: 112032\n",
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 112032\n",
      "    num_target_updates: 28\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.768421052631574\n",
      "    ram_util_percent: 80.23684210526316\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040676257466384064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 20.91447438465392\n",
      "    mean_inference_ms: 1.605200865157943\n",
      "    mean_raw_obs_processing_ms: 0.16502151535561285\n",
      "  time_since_restore: 253.7182013988495\n",
      "  time_this_iter_s: 13.201039791107178\n",
      "  time_total_s: 253.7182013988495\n",
      "  timers:\n",
      "    learn_throughput: 3720.56\n",
      "    learn_time_ms: 8.601\n",
      "    load_throughput: 53708.575\n",
      "    load_time_ms: 0.596\n",
      "    update_time_ms: 1.847\n",
      "  timestamp: 1632001679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 15\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         253.718</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\">    -0.6</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 16000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-48-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.5625\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 16\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 15616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -0.04044203460216522\n",
      "          mean_q: -3.613748073577881\n",
      "          min_q: -4.671721935272217\n",
      "        mean_td_error: 0.0162645373493433\n",
      "        td_error: \"[-0.13008404  0.18465948 -0.36908174 -0.7493552   0.03384495  0.0060668\\n\\\n",
      "          \\ -0.00904274 -0.01329017  0.21031928  0.01980734  0.07377601  0.0507226\\n\\\n",
      "          \\  0.06360888 -0.00627947  1.16333389  0.09209347  0.03535622  0.06597877\\n\\\n",
      "          \\ -0.19569278 -0.05317879 -0.0702939  -0.04911971  0.00866222 -0.13070488\\n\\\n",
      "          \\  0.01666021  0.02634621  0.03470635  0.10053396  0.02036214  0.02763343\\n\\\n",
      "          \\  0.06804776 -0.00593138]\"\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 120032\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 120032\n",
      "    num_target_updates: 30\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.1\n",
      "    ram_util_percent: 81.01578947368421\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04063565989115839\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 20.304758106704394\n",
      "    mean_inference_ms: 1.6032984091525457\n",
      "    mean_raw_obs_processing_ms: 0.16464890476425886\n",
      "  time_since_restore: 267.01040863990784\n",
      "  time_this_iter_s: 13.29220724105835\n",
      "  time_total_s: 267.01040863990784\n",
      "  timers:\n",
      "    learn_throughput: 3853.0\n",
      "    learn_time_ms: 8.305\n",
      "    load_throughput: 65246.088\n",
      "    load_time_ms: 0.49\n",
      "    update_time_ms: 1.871\n",
      "  timestamp: 1632001692\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 16\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">          267.01</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\"> -0.5625</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 17000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-48-25\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.5294117647058824\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 17\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 16624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 0.9041779637336731\n",
      "          mean_q: -3.1267356872558594\n",
      "          min_q: -4.488862037658691\n",
      "        mean_td_error: -0.0103125786408782\n",
      "        td_error: \"[ 0.0849514   0.01489496 -0.26937258 -0.28746575  0.07664251  0.13031146\\n\\\n",
      "          \\  0.1010375   0.01777077  0.02613091 -0.1719675   0.03264809  0.16193104\\n\\\n",
      "          \\  0.01637077 -0.13923144  0.10874248 -0.16963482  0.31207657  0.03622007\\n\\\n",
      "          \\  0.23759604 -0.01320934 -0.09988523  0.05148745 -0.29667616  0.00425005\\n\\\n",
      "          \\ -0.28933525  0.08744955  0.10831237  0.10881209  0.11620569  0.12453198\\n\\\n",
      "          \\ -0.5850042   0.03340602]\"\n",
      "    num_agent_steps_sampled: 17000\n",
      "    num_agent_steps_trained: 128032\n",
      "    num_steps_sampled: 17000\n",
      "    num_steps_trained: 128032\n",
      "    num_target_updates: 32\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.55263157894736\n",
      "    ram_util_percent: 81.84736842105262\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040599920885089014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 19.753494158125317\n",
      "    mean_inference_ms: 1.6015979267567817\n",
      "    mean_raw_obs_processing_ms: 0.16431042630431383\n",
      "  time_since_restore: 280.0908725261688\n",
      "  time_this_iter_s: 13.080463886260986\n",
      "  time_total_s: 280.0908725261688\n",
      "  timers:\n",
      "    learn_throughput: 3585.661\n",
      "    learn_time_ms: 8.924\n",
      "    load_throughput: 65411.437\n",
      "    load_time_ms: 0.489\n",
      "    update_time_ms: 1.683\n",
      "  timestamp: 1632001705\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17000\n",
      "  training_iteration: 17\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         280.091</td><td style=\"text-align: right;\">17000</td><td style=\"text-align: right;\">-0.529412</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 18000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-48-38\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.5\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 18\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 17632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: -1.12437105178833\n",
      "          mean_q: -3.059640884399414\n",
      "          min_q: -4.16714334487915\n",
      "        mean_td_error: -0.2001599818468094\n",
      "        td_error: \"[ 0.03240347 -0.2414329  -0.10866451 -0.05738401 -0.35782146 -0.13006353\\n\\\n",
      "          \\ -0.2589848  -0.9383879  -0.30952942 -0.01128101 -1.0391557  -0.09251571\\n\\\n",
      "          \\ -0.58139014 -0.12728238 -0.25344563  0.40093732 -0.10031056 -0.22164655\\n\\\n",
      "          \\ -0.16816139 -0.41455412 -0.13259411  0.03076768 -0.24943423 -0.37368774\\n\\\n",
      "          \\ -0.07617879 -0.10558724 -0.04189217 -0.19159722 -0.14144874 -0.06082368\\n\\\n",
      "          \\ -0.0629549  -0.02101731]\"\n",
      "    num_agent_steps_sampled: 18000\n",
      "    num_agent_steps_trained: 136032\n",
      "    num_steps_sampled: 18000\n",
      "    num_steps_trained: 136032\n",
      "    num_target_updates: 34\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.51666666666667\n",
      "    ram_util_percent: 82.17222222222223\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04056833462220962\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 19.252058472718694\n",
      "    mean_inference_ms: 1.6000595080101672\n",
      "    mean_raw_obs_processing_ms: 0.163993832131144\n",
      "  time_since_restore: 293.04829263687134\n",
      "  time_this_iter_s: 12.957420110702515\n",
      "  time_total_s: 293.04829263687134\n",
      "  timers:\n",
      "    learn_throughput: 3828.961\n",
      "    learn_time_ms: 8.357\n",
      "    load_throughput: 64400.81\n",
      "    load_time_ms: 0.497\n",
      "    update_time_ms: 1.645\n",
      "  timestamp: 1632001718\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 18\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         293.048</td><td style=\"text-align: right;\">18000</td><td style=\"text-align: right;\">    -0.5</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 19000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-48-52\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.47368421052631576\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 19\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 18640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 0.11896076798439026\n",
      "          mean_q: -2.3305935859680176\n",
      "          min_q: -4.00677490234375\n",
      "        mean_td_error: -0.03542964905500412\n",
      "        td_error: \"[ 0.35148048  0.03276467 -0.01041651 -0.08589856  0.13319945  0.02575779\\n\\\n",
      "          \\ -0.24029028 -0.65016544 -0.06364465  0.32502878 -0.30365944  0.1905191\\n\\\n",
      "          \\  0.02222583  0.22464442  0.13504934  0.12073469  0.5413282   0.0963819\\n\\\n",
      "          \\ -0.09622645  0.12786102 -0.0128454   0.48438835 -0.04788807  0.10990715\\n\\\n",
      "          \\ -0.34900403 -2.9767444   0.0215497   0.21820709  0.225564   -0.02844644\\n\\\n",
      "          \\  0.24929619  0.09559274]\"\n",
      "    num_agent_steps_sampled: 19000\n",
      "    num_agent_steps_trained: 144032\n",
      "    num_steps_sampled: 19000\n",
      "    num_steps_trained: 144032\n",
      "    num_target_updates: 36\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.60526315789473\n",
      "    ram_util_percent: 82.45263157894736\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040541627340854126\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 18.79441340993605\n",
      "    mean_inference_ms: 1.5987096979446773\n",
      "    mean_raw_obs_processing_ms: 0.16370526469437144\n",
      "  time_since_restore: 306.37486577033997\n",
      "  time_this_iter_s: 13.326573133468628\n",
      "  time_total_s: 306.37486577033997\n",
      "  timers:\n",
      "    learn_throughput: 3785.452\n",
      "    learn_time_ms: 8.453\n",
      "    load_throughput: 63090.029\n",
      "    load_time_ms: 0.507\n",
      "    update_time_ms: 1.708\n",
      "  timestamp: 1632001732\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19000\n",
      "  training_iteration: 19\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         306.375</td><td style=\"text-align: right;\">19000</td><td style=\"text-align: right;\">-0.473684</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-49-06\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.65\n",
      "  episode_reward_min: -7.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 20\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 19648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2.9804117679595947\n",
      "          mean_q: -1.9481654167175293\n",
      "          min_q: -3.4114413261413574\n",
      "        mean_td_error: -0.016958018764853477\n",
      "        td_error: \"[-0.32975292 -0.62307286  0.33914304  0.14650464  0.94428563  0.09635568\\n\\\n",
      "          \\  0.24942684 -0.33457732 -0.14456987 -0.4641999  -0.07098413  0.14154363\\n\\\n",
      "          \\  0.03252292 -0.23930776  0.0326395   0.1905806  -0.3547809   0.06344008\\n\\\n",
      "          \\ -0.04014802  0.22255778  0.0519821   0.1007278  -0.13491154  0.09028506\\n\\\n",
      "          \\ -0.13825163 -0.06211919 -0.02782083 -0.16746199 -0.11246538 -0.08226633\\n\\\n",
      "          \\  0.07193589  0.01010275]\"\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 152032\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 152032\n",
      "    num_target_updates: 38\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.76190476190476\n",
      "    ram_util_percent: 82.8047619047619\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04052213983850295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 18.377707841774033\n",
      "    mean_inference_ms: 1.5976046079277315\n",
      "    mean_raw_obs_processing_ms: 0.1635061596354172\n",
      "  time_since_restore: 320.97953629493713\n",
      "  time_this_iter_s: 14.604670524597168\n",
      "  time_total_s: 320.97953629493713\n",
      "  timers:\n",
      "    learn_throughput: 3643.785\n",
      "    learn_time_ms: 8.782\n",
      "    load_throughput: 61328.64\n",
      "    load_time_ms: 0.522\n",
      "    update_time_ms: 1.697\n",
      "  timestamp: 1632001746\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 20\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">          320.98</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">   -0.65</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -7</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 21000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-49-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -1.0\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 21\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 20656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4.670742034912109\n",
      "          mean_q: -0.4201623201370239\n",
      "          min_q: -3.0458791255950928\n",
      "        mean_td_error: 0.030296457931399345\n",
      "        td_error: \"[-0.16014406  0.09400463  0.15867996 -0.15168166 -0.04224277  0.22299409\\n\\\n",
      "          \\  0.537169    0.34571934  0.15771508 -0.3307556  -0.02640605  0.08202147\\n\\\n",
      "          \\ -0.25559556  0.46921396 -0.03512436 -0.1463244  -0.00797701  0.34499264\\n\\\n",
      "          \\  0.04375982 -0.56421614 -0.04329062  0.40290356  1.0049205  -0.2527659\\n\\\n",
      "          \\ -0.4825971  -1.6380885  -0.09389889 -0.02195454  0.90763927  0.17219424\\n\\\n",
      "          \\  0.05039263  0.22822952]\"\n",
      "    num_agent_steps_sampled: 21000\n",
      "    num_agent_steps_trained: 160032\n",
      "    num_steps_sampled: 21000\n",
      "    num_steps_trained: 160032\n",
      "    num_target_updates: 40\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.834999999999994\n",
      "    ram_util_percent: 82.825\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040504294111737324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 17.996171634498637\n",
      "    mean_inference_ms: 1.596595549511929\n",
      "    mean_raw_obs_processing_ms: 0.16335939856791373\n",
      "  time_since_restore: 335.1745505332947\n",
      "  time_this_iter_s: 14.195014238357544\n",
      "  time_total_s: 335.1745505332947\n",
      "  timers:\n",
      "    learn_throughput: 3851.453\n",
      "    learn_time_ms: 8.309\n",
      "    load_throughput: 66612.6\n",
      "    load_time_ms: 0.48\n",
      "    update_time_ms: 1.583\n",
      "  timestamp: 1632001761\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21000\n",
      "  training_iteration: 21\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         335.175</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\">      -1</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 22000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-49-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.9090909090909091\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 22\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 21664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4.920619487762451\n",
      "          mean_q: -0.574966311454773\n",
      "          min_q: -2.6937613487243652\n",
      "        mean_td_error: -0.030316419899463654\n",
      "        td_error: \"[ 0.05520296  0.99234176 -0.04740715 -0.27958345  0.25410748 -0.07137179\\n\\\n",
      "          \\  0.00925517 -0.21721423 -0.0128516  -0.35453272 -0.06336021  0.03883123\\n\\\n",
      "          \\ -0.06889272 -0.21300709  0.03067064  0.25112212  0.18173695 -0.4724412\\n\\\n",
      "          \\ -0.18310308  0.12223983 -0.30667663  0.04361513  0.04233623 -0.19873857\\n\\\n",
      "          \\ -0.49997973 -0.00631261  0.30400658  0.05585241 -0.20007837 -0.279635\\n\\\n",
      "          \\  0.09618831  0.02755404]\"\n",
      "    num_agent_steps_sampled: 22000\n",
      "    num_agent_steps_trained: 168032\n",
      "    num_steps_sampled: 22000\n",
      "    num_steps_trained: 168032\n",
      "    num_target_updates: 42\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.4\n",
      "    ram_util_percent: 83.05263157894736\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04048622093841576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 17.643027464701845\n",
      "    mean_inference_ms: 1.5956355560108841\n",
      "    mean_raw_obs_processing_ms: 0.1632283690255983\n",
      "  time_since_restore: 348.165611743927\n",
      "  time_this_iter_s: 12.991061210632324\n",
      "  time_total_s: 348.165611743927\n",
      "  timers:\n",
      "    learn_throughput: 3924.139\n",
      "    learn_time_ms: 8.155\n",
      "    load_throughput: 67223.143\n",
      "    load_time_ms: 0.476\n",
      "    update_time_ms: 1.607\n",
      "  timestamp: 1632001774\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 22000\n",
      "  training_iteration: 22\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         348.166</td><td style=\"text-align: right;\">22000</td><td style=\"text-align: right;\">-0.909091</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 23000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-49-48\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.173913043478261\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 23\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 22672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4.804653167724609\n",
      "          mean_q: 0.278086394071579\n",
      "          min_q: -2.3544092178344727\n",
      "        mean_td_error: 0.13082291185855865\n",
      "        td_error: \"[ 0.49755388  0.8184024   0.2146945   0.21909165  0.04964781  0.1291964\\n\\\n",
      "          \\ -0.01227772  0.18370962 -0.27368927  0.26487446 -0.8572793   0.5776379\\n\\\n",
      "          \\ -0.09907913  0.01183271  0.09897482 -0.30049825  0.45727164  0.1164645\\n\\\n",
      "          \\  0.02959466  0.03350902 -0.15724897  0.2656213   0.4861977   1.3830326\\n\\\n",
      "          \\  0.1726929   0.02622867 -0.02497053 -0.44049215  0.3528824  -0.03010654\\n\\\n",
      "          \\  0.0047214  -0.01185775]\"\n",
      "    num_agent_steps_sampled: 23000\n",
      "    num_agent_steps_trained: 176032\n",
      "    num_steps_sampled: 23000\n",
      "    num_steps_trained: 176032\n",
      "    num_target_updates: 44\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.495\n",
      "    ram_util_percent: 83.51000000000002\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040467461621232104\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 17.31744484958409\n",
      "    mean_inference_ms: 1.5947222126719027\n",
      "    mean_raw_obs_processing_ms: 0.16312292821368762\n",
      "  time_since_restore: 362.4394519329071\n",
      "  time_this_iter_s: 14.273840188980103\n",
      "  time_total_s: 362.4394519329071\n",
      "  timers:\n",
      "    learn_throughput: 3902.484\n",
      "    learn_time_ms: 8.2\n",
      "    load_throughput: 65767.213\n",
      "    load_time_ms: 0.487\n",
      "    update_time_ms: 1.695\n",
      "  timestamp: 1632001788\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 23000\n",
      "  training_iteration: 23\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         362.439</td><td style=\"text-align: right;\">23000</td><td style=\"text-align: right;\">-1.17391</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 24000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-50-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.0833333333333333\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 24\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 23680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.325234889984131\n",
      "          mean_q: 2.2595126628875732\n",
      "          min_q: -2.052518606185913\n",
      "        mean_td_error: 0.007677383720874786\n",
      "        td_error: \"[-0.1172142  -0.34024227 -0.1812979   0.31968975  0.11247802  0.50948143\\n\\\n",
      "          \\ -0.04953671  0.70829904  0.00711811  0.24168348 -0.09676385 -0.00425053\\n\\\n",
      "          \\ -0.07914019 -0.3106351   0.03880405  0.06203628 -0.23071659  0.18531203\\n\\\n",
      "          \\  0.24835181  0.01470891  0.4427929   0.10929775 -0.35266972 -0.13902903\\n\\\n",
      "          \\ -0.34028864  0.05420804 -0.43629408 -0.21872652  0.00722772  0.24595356\\n\\\n",
      "          \\ -0.04962437 -0.11533689]\"\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 184032\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 184032\n",
      "    num_target_updates: 46\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.614999999999995\n",
      "    ram_util_percent: 83.905\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04044860879519175\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 17.015254467134245\n",
      "    mean_inference_ms: 1.5938606456806472\n",
      "    mean_raw_obs_processing_ms: 0.16304168310262998\n",
      "  time_since_restore: 376.16913771629333\n",
      "  time_this_iter_s: 13.72968578338623\n",
      "  time_total_s: 376.16913771629333\n",
      "  timers:\n",
      "    learn_throughput: 3848.89\n",
      "    learn_time_ms: 8.314\n",
      "    load_throughput: 66605.989\n",
      "    load_time_ms: 0.48\n",
      "    update_time_ms: 1.638\n",
      "  timestamp: 1632001802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 24\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         376.169</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-1.08333</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 25000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-50-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 25\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 24688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.249934673309326\n",
      "          mean_q: 1.9399158954620361\n",
      "          min_q: -1.9644219875335693\n",
      "        mean_td_error: -0.016407400369644165\n",
      "        td_error: \"[ 0.17968035 -0.88449836  0.40617275 -0.40291834 -0.1165185  -0.67176294\\n\\\n",
      "          \\ -0.06230021  0.17224455 -0.18879354  0.20868337 -0.03666115  0.05141592\\n\\\n",
      "          \\  0.25536442  0.04932046 -1.2304721   0.33872557  0.24314642 -1.1028666\\n\\\n",
      "          \\  0.56155443  0.7323973  -0.01204324  0.0915554   0.35382688  0.94846344\\n\\\n",
      "          \\  0.04883602 -0.20732594  0.29244888 -0.15823507 -0.16793704 -0.19447732\\n\\\n",
      "          \\ -0.02633429  0.00427169]\"\n",
      "    num_agent_steps_sampled: 25000\n",
      "    num_agent_steps_trained: 192032\n",
      "    num_steps_sampled: 25000\n",
      "    num_steps_trained: 192032\n",
      "    num_target_updates: 48\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.345\n",
      "    ram_util_percent: 84.16000000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04042969105849135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 16.73395153545831\n",
      "    mean_inference_ms: 1.5930535383101705\n",
      "    mean_raw_obs_processing_ms: 0.16297498943687824\n",
      "  time_since_restore: 389.8937232494354\n",
      "  time_this_iter_s: 13.72458553314209\n",
      "  time_total_s: 389.8937232494354\n",
      "  timers:\n",
      "    learn_throughput: 3850.546\n",
      "    learn_time_ms: 8.311\n",
      "    load_throughput: 65828.5\n",
      "    load_time_ms: 0.486\n",
      "    update_time_ms: 1.923\n",
      "  timestamp: 1632001815\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25000\n",
      "  training_iteration: 25\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.1/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         389.894</td><td style=\"text-align: right;\">25000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 26000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-50-29\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.1923076923076923\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 26\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 25696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5.595303058624268\n",
      "          mean_q: 2.782785415649414\n",
      "          min_q: -1.7268249988555908\n",
      "        mean_td_error: -0.05418107286095619\n",
      "        td_error: \"[-0.05554056 -0.07096815 -0.15088415  0.38097954 -0.046574    0.5435357\\n\\\n",
      "          \\  0.873106   -0.08249378 -0.93961287 -0.03905296  0.6185894  -0.5192647\\n\\\n",
      "          \\ -0.01383352 -0.12218142 -0.3351283  -0.14791346  0.14383936  0.0136168\\n\\\n",
      "          \\  0.81956434 -0.38496947 -0.31050634 -0.35360003 -0.01112509 -0.3746159\\n\\\n",
      "          \\  0.03755999 -0.12994051 -0.17732286 -0.6188539  -0.06077886  0.02600336\\n\\\n",
      "          \\  0.11071014 -0.35613808]\"\n",
      "    num_agent_steps_sampled: 26000\n",
      "    num_agent_steps_trained: 200032\n",
      "    num_steps_sampled: 26000\n",
      "    num_steps_trained: 200032\n",
      "    num_target_updates: 50\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.96842105263158\n",
      "    ram_util_percent: 84.90526315789472\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04041102093461846\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 16.4708913531424\n",
      "    mean_inference_ms: 1.5922809093916743\n",
      "    mean_raw_obs_processing_ms: 0.16292040339159847\n",
      "  time_since_restore: 403.3189194202423\n",
      "  time_this_iter_s: 13.425196170806885\n",
      "  time_total_s: 403.3189194202423\n",
      "  timers:\n",
      "    learn_throughput: 3827.269\n",
      "    learn_time_ms: 8.361\n",
      "    load_throughput: 64617.846\n",
      "    load_time_ms: 0.495\n",
      "    update_time_ms: 1.695\n",
      "  timestamp: 1632001829\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 26000\n",
      "  training_iteration: 26\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         403.319</td><td style=\"text-align: right;\">26000</td><td style=\"text-align: right;\">-1.19231</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 27000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-50-42\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.1851851851851851\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 27\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 26704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.786098957061768\n",
      "          mean_q: 3.1521639823913574\n",
      "          min_q: -1.3241621255874634\n",
      "        mean_td_error: -0.026292160153388977\n",
      "        td_error: \"[-0.40853262  0.44149327 -0.40235043 -0.20161009  0.25129175  0.8692498\\n\\\n",
      "          \\  0.199651    3.2159264   0.0548923  -0.06927752 -0.30846953 -0.21972692\\n\\\n",
      "          \\ -0.1647377   0.11238384 -0.22071433  0.11173415 -0.43616915 -0.08949518\\n\\\n",
      "          \\ -0.1137002  -0.44358873 -0.19646311 -0.16613293 -0.3770299  -1.49224\\n \\\n",
      "          \\ 0.16713679  0.18965572 -0.20237184  0.05086613  0.01265311  0.05318895\\n\\\n",
      "          \\ -1.5792775   0.5204153 ]\"\n",
      "    num_agent_steps_sampled: 27000\n",
      "    num_agent_steps_trained: 208032\n",
      "    num_steps_sampled: 27000\n",
      "    num_steps_trained: 208032\n",
      "    num_target_updates: 52\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.61578947368421\n",
      "    ram_util_percent: 85.66842105263159\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04039272637828075\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 16.224290243693847\n",
      "    mean_inference_ms: 1.5915376911767793\n",
      "    mean_raw_obs_processing_ms: 0.16286658844823182\n",
      "  time_since_restore: 416.71045446395874\n",
      "  time_this_iter_s: 13.39153504371643\n",
      "  time_total_s: 416.71045446395874\n",
      "  timers:\n",
      "    learn_throughput: 3882.806\n",
      "    learn_time_ms: 8.241\n",
      "    load_throughput: 66260.727\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.74\n",
      "  timestamp: 1632001842\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27000\n",
      "  training_iteration: 27\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">          416.71</td><td style=\"text-align: right;\">27000</td><td style=\"text-align: right;\">-1.18519</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-50-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.25\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 28\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 27712\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5.3626580238342285\n",
      "          mean_q: 2.974167585372925\n",
      "          min_q: -1.048985242843628\n",
      "        mean_td_error: -0.13915497064590454\n",
      "        td_error: \"[-0.14073467 -0.24968195 -0.02351415 -0.29998732 -0.1610341   0.0082221\\n\\\n",
      "          \\ -0.23799658 -0.25820637 -0.13702989 -0.22879267 -0.5215106   0.08419657\\n\\\n",
      "          \\ -0.02743912 -0.21642447 -0.13876271 -0.05899858  0.17265844 -0.18141484\\n\\\n",
      "          \\ -0.9491713  -0.1232062   0.05906177  0.10750556 -0.14914227  0.30519485\\n\\\n",
      "          \\ -0.03351736 -0.13165474 -0.04061645  0.02104741 -0.08819079 -0.08481246\\n\\\n",
      "          \\ -0.45364022 -0.27536583]\"\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 216032\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 216032\n",
      "    num_target_updates: 54\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.321052631578944\n",
      "    ram_util_percent: 86.0\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040374738920858536\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 15.992744426875118\n",
      "    mean_inference_ms: 1.5908142468711655\n",
      "    mean_raw_obs_processing_ms: 0.1628204236699853\n",
      "  time_since_restore: 430.19584035873413\n",
      "  time_this_iter_s: 13.48538589477539\n",
      "  time_total_s: 430.19584035873413\n",
      "  timers:\n",
      "    learn_throughput: 3860.648\n",
      "    learn_time_ms: 8.289\n",
      "    load_throughput: 66460.871\n",
      "    load_time_ms: 0.481\n",
      "    update_time_ms: 1.608\n",
      "  timestamp: 1632001856\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 28\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         430.196</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">   -1.25</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 29000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-51-10\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.2413793103448276\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 29\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 28720\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.426444053649902\n",
      "          mean_q: 4.054887771606445\n",
      "          min_q: -0.3760780394077301\n",
      "        mean_td_error: 0.02724640443921089\n",
      "        td_error: \"[ 0.08274221  0.06272554  0.5697465   0.10291362  0.23640919  0.22640038\\n\\\n",
      "          \\  0.10907626 -0.20638514 -0.13456774 -0.13862824 -0.15588665  0.01041365\\n\\\n",
      "          \\  0.08818388 -0.33664393 -0.06716299 -0.17720366 -0.04270983 -0.17771633\\n\\\n",
      "          \\ -1.8220315   0.06661701  0.29415035 -0.08015394  0.1791172   0.40955448\\n\\\n",
      "          \\  0.970736    0.5306511   0.16244268  0.24216127 -0.05116296 -0.15466642\\n\\\n",
      "          \\  0.1493187  -0.07655573]\"\n",
      "    num_agent_steps_sampled: 29000\n",
      "    num_agent_steps_trained: 224032\n",
      "    num_steps_sampled: 29000\n",
      "    num_steps_trained: 224032\n",
      "    num_target_updates: 56\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.67\n",
      "    ram_util_percent: 86.18\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04035727932138275\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 15.775065982352846\n",
      "    mean_inference_ms: 1.590116922210223\n",
      "    mean_raw_obs_processing_ms: 0.1627852539770795\n",
      "  time_since_restore: 443.84211587905884\n",
      "  time_this_iter_s: 13.646275520324707\n",
      "  time_total_s: 443.84211587905884\n",
      "  timers:\n",
      "    learn_throughput: 3875.093\n",
      "    learn_time_ms: 8.258\n",
      "    load_throughput: 66609.294\n",
      "    load_time_ms: 0.48\n",
      "    update_time_ms: 1.665\n",
      "  timestamp: 1632001870\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29000\n",
      "  training_iteration: 29\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         443.842</td><td style=\"text-align: right;\">29000</td><td style=\"text-align: right;\">-1.24138</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-51-40\n",
      "  done: false\n",
      "  episode_len_mean: 996.0333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 30\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 29728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.493242263793945\n",
      "          mean_q: 3.9835495948791504\n",
      "          min_q: 2.9460911750793457\n",
      "        mean_td_error: 0.05591576546430588\n",
      "        td_error: \"[ 0.1298294   0.159338    0.25297308  0.21429586  0.15224838  0.2450273\\n\\\n",
      "          \\  0.01664782 -0.08398724 -0.06143522  0.05312228  0.5149708  -0.02377272\\n\\\n",
      "          \\  0.02075577 -0.15571022  0.07788086 -0.12814045  0.01427698 -0.04353952\\n\\\n",
      "          \\ -0.00337768 -0.04997921  0.22471595 -0.0545857   0.03306127 -0.08019257\\n\\\n",
      "          \\  0.02203274  0.14094663  0.00355101  0.414546   -0.15294027  0.05271149\\n\\\n",
      "          \\ -0.10056973 -0.0153966 ]\"\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_agent_steps_trained: 232032\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 232032\n",
      "    num_target_updates: 58\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.46046511627907\n",
      "    ram_util_percent: 85.17441860465115\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040340097805327\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 15.569352331925945\n",
      "    mean_inference_ms: 1.5894428229155426\n",
      "    mean_raw_obs_processing_ms: 0.18171180967960607\n",
      "  time_since_restore: 474.07488465309143\n",
      "  time_this_iter_s: 30.232768774032593\n",
      "  time_total_s: 474.07488465309143\n",
      "  timers:\n",
      "    learn_throughput: 3837.424\n",
      "    learn_time_ms: 8.339\n",
      "    load_throughput: 67112.22\n",
      "    load_time_ms: 0.477\n",
      "    update_time_ms: 1.616\n",
      "  timestamp: 1632001900\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 30\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.4/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         474.075</td><td style=\"text-align: right;\">30000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           996.033</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 31000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-51-55\n",
      "  done: false\n",
      "  episode_len_mean: 996.1612903225806\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.1612903225806452\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 31\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 30736\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.513443946838379\n",
      "          mean_q: 3.922114133834839\n",
      "          min_q: 2.5331552028656006\n",
      "        mean_td_error: -0.026539891958236694\n",
      "        td_error: \"[-0.07684755 -0.20846653 -0.04975748  0.07547283  0.16661954  0.24202299\\n\\\n",
      "          \\  0.04708743 -0.05004549  0.11802197 -0.19533873 -0.10285854  0.14690542\\n\\\n",
      "          \\ -0.05238986 -0.16695833  0.13173652  0.21718788 -0.18855762  0.1411264\\n\\\n",
      "          \\ -0.12382412 -0.2518065   0.0172348   0.08488464 -0.239928   -0.01536798\\n\\\n",
      "          \\ -0.32520962 -0.11230683 -0.0594523   0.5907917   0.02122927  0.18822956\\n\\\n",
      "          \\ -0.15100455 -0.66770744]\"\n",
      "    num_agent_steps_sampled: 31000\n",
      "    num_agent_steps_trained: 240032\n",
      "    num_steps_sampled: 31000\n",
      "    num_steps_trained: 240032\n",
      "    num_target_updates: 60\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.00909090909091\n",
      "    ram_util_percent: 85.74090909090907\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04032442995781423\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 15.376687547572583\n",
      "    mean_inference_ms: 1.588823829433647\n",
      "    mean_raw_obs_processing_ms: 0.19881902271462717\n",
      "  time_since_restore: 489.2284183502197\n",
      "  time_this_iter_s: 15.153533697128296\n",
      "  time_total_s: 489.2284183502197\n",
      "  timers:\n",
      "    learn_throughput: 3871.863\n",
      "    learn_time_ms: 8.265\n",
      "    load_throughput: 67422.378\n",
      "    load_time_ms: 0.475\n",
      "    update_time_ms: 1.651\n",
      "  timestamp: 1632001915\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 31000\n",
      "  training_iteration: 31\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         489.228</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">-1.16129</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           996.161</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 32000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-52-09\n",
      "  done: false\n",
      "  episode_len_mean: 996.28125\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.125\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 32\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 31744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5.638655185699463\n",
      "          mean_q: 4.070370674133301\n",
      "          min_q: 2.8947534561157227\n",
      "        mean_td_error: 0.015905186533927917\n",
      "        td_error: \"[ 0.17333841  0.4629836   0.1397419  -0.03973937 -0.257051    0.00644016\\n\\\n",
      "          \\ -0.08359385  0.07263613  0.01198387 -0.0467658   0.13908911  0.36191702\\n\\\n",
      "          \\  0.8765669  -0.5620439  -0.04660654 -0.28724813 -0.10915732 -0.10966015\\n\\\n",
      "          \\ -0.1443901   0.03047824 -0.41532898  0.01029873 -0.1038866   0.2750311\\n\\\n",
      "          \\  0.00606322 -0.03125811 -0.10039926 -0.15406275 -0.05559182  0.33904982\\n\\\n",
      "          \\  0.01784897  0.1322825 ]\"\n",
      "    num_agent_steps_sampled: 32000\n",
      "    num_agent_steps_trained: 248032\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 248032\n",
      "    num_target_updates: 62\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.19500000000001\n",
      "    ram_util_percent: 86.885\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04031097590915761\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 15.19458515981684\n",
      "    mean_inference_ms: 1.5882730176352702\n",
      "    mean_raw_obs_processing_ms: 0.2143179042586073\n",
      "  time_since_restore: 503.2293350696564\n",
      "  time_this_iter_s: 14.000916719436646\n",
      "  time_total_s: 503.2293350696564\n",
      "  timers:\n",
      "    learn_throughput: 3787.716\n",
      "    learn_time_ms: 8.448\n",
      "    load_throughput: 65293.699\n",
      "    load_time_ms: 0.49\n",
      "    update_time_ms: 1.76\n",
      "  timestamp: 1632001929\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 32\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         503.229</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">  -1.125</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           996.281</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 33000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-52-23\n",
      "  done: false\n",
      "  episode_len_mean: 996.3939393939394\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.1515151515151516\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 33\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 32752\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 12.751267433166504\n",
      "          mean_q: 4.2530059814453125\n",
      "          min_q: 3.087002754211426\n",
      "        mean_td_error: 0.05582917481660843\n",
      "        td_error: \"[-0.14746332  0.19070435 -0.16343307 -0.88859367  0.03545213 -0.25103903\\n\\\n",
      "          \\  0.05007839  0.09844613  0.05416965  0.19019055 -0.06923151  0.16122079\\n\\\n",
      "          \\ -0.01498985  0.08501625  0.13075829  0.23436594  0.11104083  0.2594769\\n\\\n",
      "          \\  0.02465749  0.11717987  0.24209356  0.2323947   0.11770701  0.04222178\\n\\\n",
      "          \\ -0.08856964  0.18162847  0.02146792  0.0731802   0.29548216  0.12462759\\n\\\n",
      "          \\  0.20368767  0.13260508]\"\n",
      "    num_agent_steps_sampled: 33000\n",
      "    num_agent_steps_trained: 256032\n",
      "    num_steps_sampled: 33000\n",
      "    num_steps_trained: 256032\n",
      "    num_target_updates: 64\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.7\n",
      "    ram_util_percent: 86.88000000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040299536944632904\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 15.0222736694547\n",
      "    mean_inference_ms: 1.5877891026938271\n",
      "    mean_raw_obs_processing_ms: 0.2283930644584692\n",
      "  time_since_restore: 517.3392860889435\n",
      "  time_this_iter_s: 14.10995101928711\n",
      "  time_total_s: 517.3392860889435\n",
      "  timers:\n",
      "    learn_throughput: 3283.462\n",
      "    learn_time_ms: 9.746\n",
      "    load_throughput: 65680.317\n",
      "    load_time_ms: 0.487\n",
      "    update_time_ms: 1.845\n",
      "  timestamp: 1632001943\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 33000\n",
      "  training_iteration: 33\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         517.339</td><td style=\"text-align: right;\">33000</td><td style=\"text-align: right;\">-1.15152</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           996.394</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 34000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-52-36\n",
      "  done: false\n",
      "  episode_len_mean: 996.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.1470588235294117\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 34\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 33760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5.336895942687988\n",
      "          mean_q: 3.8260326385498047\n",
      "          min_q: 3.042269229888916\n",
      "        mean_td_error: -0.002340354025363922\n",
      "        td_error: \"[-0.3290851   0.03584456  0.08652234 -0.00407314  0.05958486  0.04317689\\n\\\n",
      "          \\  0.01980591  0.00293279 -0.0057919  -0.023633    0.04617333  0.00607395\\n\\\n",
      "          \\  0.03843379  0.0604465  -0.05077314 -0.1713264  -0.21912432  0.12429047\\n\\\n",
      "          \\  0.11302376  0.01975441  0.24520683  0.01984406  0.01733184 -0.27254248\\n\\\n",
      "          \\ -0.280226    0.05152559  0.5114839  -0.05263948  0.02613163 -0.3044877\\n\\\n",
      "          \\  0.94028234 -0.8290584 ]\"\n",
      "    num_agent_steps_sampled: 34000\n",
      "    num_agent_steps_trained: 264032\n",
      "    num_steps_sampled: 34000\n",
      "    num_steps_trained: 264032\n",
      "    num_target_updates: 66\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.57222222222222\n",
      "    ram_util_percent: 86.86666666666667\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040288405159061826\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 14.85832353080081\n",
      "    mean_inference_ms: 1.587313047808919\n",
      "    mean_raw_obs_processing_ms: 0.2411911530765399\n",
      "  time_since_restore: 530.49107670784\n",
      "  time_this_iter_s: 13.151790618896484\n",
      "  time_total_s: 530.49107670784\n",
      "  timers:\n",
      "    learn_throughput: 3836.513\n",
      "    learn_time_ms: 8.341\n",
      "    load_throughput: 67639.837\n",
      "    load_time_ms: 0.473\n",
      "    update_time_ms: 1.862\n",
      "  timestamp: 1632001956\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 34000\n",
      "  training_iteration: 34\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         530.491</td><td style=\"text-align: right;\">34000</td><td style=\"text-align: right;\">-1.14706</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">             996.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 35000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-52-50\n",
      "  done: false\n",
      "  episode_len_mean: 996.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.1142857142857143\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 35\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 34768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.569573402404785\n",
      "          mean_q: 4.164155960083008\n",
      "          min_q: 3.256683349609375\n",
      "        mean_td_error: 0.15297476947307587\n",
      "        td_error: \"[ 0.01790905 -0.00659966 -0.03540683  0.1121366   0.06969452  0.16613317\\n\\\n",
      "          \\  0.25321293  0.2779479   0.14990091  0.0038259   0.295053    0.8207507\\n\\\n",
      "          \\  0.40935993  0.05959058  0.20446801 -0.04822898  0.35561657  0.22125101\\n\\\n",
      "          \\  0.18774557  0.05494833  0.2069273  -0.00193119  0.00693274  0.01611757\\n\\\n",
      "          \\  0.04526067  0.17475557  0.35484695  0.21544313  0.05080867  0.12459993\\n\\\n",
      "          \\  0.16964817 -0.03752613]\"\n",
      "    num_agent_steps_sampled: 35000\n",
      "    num_agent_steps_trained: 272032\n",
      "    num_steps_sampled: 35000\n",
      "    num_steps_trained: 272032\n",
      "    num_target_updates: 68\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.710526315789465\n",
      "    ram_util_percent: 87.16842105263159\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0402775895082768\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 14.702225681614657\n",
      "    mean_inference_ms: 1.586846736000451\n",
      "    mean_raw_obs_processing_ms: 0.2528429125650267\n",
      "  time_since_restore: 543.7665588855743\n",
      "  time_this_iter_s: 13.275482177734375\n",
      "  time_total_s: 543.7665588855743\n",
      "  timers:\n",
      "    learn_throughput: 3831.782\n",
      "    learn_time_ms: 8.351\n",
      "    load_throughput: 67989.326\n",
      "    load_time_ms: 0.471\n",
      "    update_time_ms: 1.746\n",
      "  timestamp: 1632001970\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35000\n",
      "  training_iteration: 35\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         543.767</td><td style=\"text-align: right;\">35000</td><td style=\"text-align: right;\">-1.11429</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">             996.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-53-03\n",
      "  done: false\n",
      "  episode_len_mean: 996.6944444444445\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.0833333333333333\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 36\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 35776\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11.457172393798828\n",
      "          mean_q: 4.083991527557373\n",
      "          min_q: 3.2742693424224854\n",
      "        mean_td_error: -0.008006282150745392\n",
      "        td_error: \"[ 0.05117393  0.15752339 -0.09156179 -0.04687357  0.15120673 -0.01368618\\n\\\n",
      "          \\  0.03541946  0.06984043  0.06960535 -0.01525593  0.05611062 -0.15876794\\n\\\n",
      "          \\ -0.23704219  0.01220536  0.00039077 -0.2384758   0.05590582 -0.02629137\\n\\\n",
      "          \\  0.09583139 -0.07391167  0.09376025 -0.17560863  0.10588574 -0.0957036\\n\\\n",
      "          \\  0.19761205  0.26035953  0.0962925  -0.28350878 -0.24447036  0.02033257\\n\\\n",
      "          \\ -0.26585102  0.1813519 ]\"\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 280032\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 280032\n",
      "    num_target_updates: 70\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.431578947368415\n",
      "    ram_util_percent: 87.6842105263158\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040266819338517036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 14.553230090541197\n",
      "    mean_inference_ms: 1.586386275912051\n",
      "    mean_raw_obs_processing_ms: 0.2634632750615806\n",
      "  time_since_restore: 556.8149168491364\n",
      "  time_this_iter_s: 13.048357963562012\n",
      "  time_total_s: 556.8149168491364\n",
      "  timers:\n",
      "    learn_throughput: 3796.19\n",
      "    learn_time_ms: 8.43\n",
      "    load_throughput: 66861.477\n",
      "    load_time_ms: 0.479\n",
      "    update_time_ms: 1.679\n",
      "  timestamp: 1632001983\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 36\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         556.815</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-1.08333</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           996.694</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 37000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-53-16\n",
      "  done: false\n",
      "  episode_len_mean: 996.7837837837837\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.054054054054054\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 37\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 36784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.654851913452148\n",
      "          mean_q: 3.903390884399414\n",
      "          min_q: 3.439727306365967\n",
      "        mean_td_error: -0.050138503313064575\n",
      "        td_error: \"[ 0.00847054  0.04167557  0.11126661 -1.1266012   0.00945067 -0.03760171\\n\\\n",
      "          \\  0.02830935  0.1777265  -0.11950183 -0.00964499 -0.08178759  0.04250622\\n\\\n",
      "          \\  0.03649521  0.27110934  0.05815244  0.07207775  0.07290483 -0.04882193\\n\\\n",
      "          \\ -0.08501911 -0.23640537 -1.021126    0.08615708 -0.02879357  0.06873775\\n\\\n",
      "          \\  0.00268936 -0.06318378  0.05752587 -0.13581562 -0.08941007  0.06958294\\n\\\n",
      "          \\  0.30038834 -0.03594565]\"\n",
      "    num_agent_steps_sampled: 37000\n",
      "    num_agent_steps_trained: 288032\n",
      "    num_steps_sampled: 37000\n",
      "    num_steps_trained: 288032\n",
      "    num_target_updates: 72\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.5388888888889\n",
      "    ram_util_percent: 88.04444444444444\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04025637739135958\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 14.410710250115699\n",
      "    mean_inference_ms: 1.5859349331818258\n",
      "    mean_raw_obs_processing_ms: 0.2731558578109397\n",
      "  time_since_restore: 569.6731290817261\n",
      "  time_this_iter_s: 12.858212232589722\n",
      "  time_total_s: 569.6731290817261\n",
      "  timers:\n",
      "    learn_throughput: 3837.478\n",
      "    learn_time_ms: 8.339\n",
      "    load_throughput: 66510.272\n",
      "    load_time_ms: 0.481\n",
      "    update_time_ms: 1.691\n",
      "  timestamp: 1632001996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 37000\n",
      "  training_iteration: 37\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         569.673</td><td style=\"text-align: right;\">37000</td><td style=\"text-align: right;\">-1.05405</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           996.784</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 38000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-53-29\n",
      "  done: false\n",
      "  episode_len_mean: 996.8684210526316\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.0263157894736843\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 38\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 37792\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5.438684463500977\n",
      "          mean_q: 3.783616304397583\n",
      "          min_q: 2.6930558681488037\n",
      "        mean_td_error: -0.05359040945768356\n",
      "        td_error: \"[-0.7414942   0.21658802 -1.383908   -0.04783893  0.03647375  0.03008699\\n\\\n",
      "          \\  0.72086596 -0.03707409 -0.2822144  -0.0723207  -1.0463548  -0.07971835\\n\\\n",
      "          \\  0.03104544  0.07528043  0.08175945  0.19224095 -0.11475396 -0.07822061\\n\\\n",
      "          \\ -0.00417852  0.09413695  0.0550127   0.00285101  0.03471804  0.20489883\\n\\\n",
      "          \\  0.13055539  0.08940363 -0.0457058   0.00378275  0.03909445  0.07091761\\n\\\n",
      "          \\  0.0171442   0.09203267]\"\n",
      "    num_agent_steps_sampled: 38000\n",
      "    num_agent_steps_trained: 296032\n",
      "    num_steps_sampled: 38000\n",
      "    num_steps_trained: 296032\n",
      "    num_target_updates: 74\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.17894736842105\n",
      "    ram_util_percent: 88.64736842105265\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04024636947898077\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 14.274409132153682\n",
      "    mean_inference_ms: 1.585493909582958\n",
      "    mean_raw_obs_processing_ms: 0.28201237293103587\n",
      "  time_since_restore: 582.797999382019\n",
      "  time_this_iter_s: 13.124870300292969\n",
      "  time_total_s: 582.797999382019\n",
      "  timers:\n",
      "    learn_throughput: 3829.365\n",
      "    learn_time_ms: 8.356\n",
      "    load_throughput: 66480.622\n",
      "    load_time_ms: 0.481\n",
      "    update_time_ms: 1.765\n",
      "  timestamp: 1632002009\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 38000\n",
      "  training_iteration: 38\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         582.798</td><td style=\"text-align: right;\">38000</td><td style=\"text-align: right;\">-1.02632</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           996.868</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 39000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-53-42\n",
      "  done: false\n",
      "  episode_len_mean: 996.9487179487179\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.0\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 39\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 38800\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.218772888183594\n",
      "          mean_q: 4.073036193847656\n",
      "          min_q: 3.345045328140259\n",
      "        mean_td_error: 0.04742252081632614\n",
      "        td_error: \"[ 0.02787089 -0.04474783 -0.09358168 -0.06537986 -0.09816623  4.24576426\\n\\\n",
      "          \\ -0.08982134  0.02067733  0.09994149 -0.05717635  0.05205441 -0.11620879\\n\\\n",
      "          \\ -0.96957779  0.00676107 -0.00536561  0.14338517  0.03158879 -0.05865765\\n\\\n",
      "          \\  0.01023936  0.08621788 -0.46130943  0.06219602  0.18801498 -0.13096237\\n\\\n",
      "          \\  0.04575682 -0.02761769 -0.45359564 -0.05366898  0.09585595 -0.79345465\\n\\\n",
      "          \\ -0.12793827  0.04842639]\"\n",
      "    num_agent_steps_sampled: 39000\n",
      "    num_agent_steps_trained: 304032\n",
      "    num_steps_sampled: 39000\n",
      "    num_steps_trained: 304032\n",
      "    num_target_updates: 76\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.67368421052632\n",
      "    ram_util_percent: 89.05263157894737\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04023664180573045\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 14.144022518098271\n",
      "    mean_inference_ms: 1.5850952700718068\n",
      "    mean_raw_obs_processing_ms: 0.29011404199601937\n",
      "  time_since_restore: 596.203551530838\n",
      "  time_this_iter_s: 13.40555214881897\n",
      "  time_total_s: 596.203551530838\n",
      "  timers:\n",
      "    learn_throughput: 3892.682\n",
      "    learn_time_ms: 8.221\n",
      "    load_throughput: 65510.41\n",
      "    load_time_ms: 0.488\n",
      "    update_time_ms: 1.733\n",
      "  timestamp: 1632002022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39000\n",
      "  training_iteration: 39\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         596.204</td><td style=\"text-align: right;\">39000</td><td style=\"text-align: right;\">      -1</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           996.949</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 40000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-53-55\n",
      "  done: false\n",
      "  episode_len_mean: 997.025\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.05\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 40\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 39808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11.779074668884277\n",
      "          mean_q: 3.760218620300293\n",
      "          min_q: 1.8132611513137817\n",
      "        mean_td_error: -0.06895551830530167\n",
      "        td_error: \"[-0.3250277  -0.36839676 -0.2335198  -0.27784395 -0.37333274 -0.2166524\\n\\\n",
      "          \\ -0.24263382 -0.2954142  -0.17661214  2.5516396   0.91584325 -0.37955666\\n\\\n",
      "          \\ -0.25476384 -0.5362482  -0.3895352  -0.2605431  -0.23907208 -0.6464653\\n\\\n",
      "          \\ -0.18871093 -0.28175974 -0.76876545 -0.11100149 -0.0573287  -1.1316264\\n\\\n",
      "          \\ -0.10338378  1.8132612   1.7412679  -0.371938   -0.20470285 -0.3199463\\n\\\n",
      "          \\ -0.2807362  -0.19307089]\"\n",
      "    num_agent_steps_sampled: 40000\n",
      "    num_agent_steps_trained: 312032\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 312032\n",
      "    num_target_updates: 78\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.310526315789474\n",
      "    ram_util_percent: 89.21052631578948\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04022701454450682\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 14.019165253384745\n",
      "    mean_inference_ms: 1.584703459549986\n",
      "    mean_raw_obs_processing_ms: 0.29754606451021953\n",
      "  time_since_restore: 609.4951903820038\n",
      "  time_this_iter_s: 13.291638851165771\n",
      "  time_total_s: 609.4951903820038\n",
      "  timers:\n",
      "    learn_throughput: 3812.625\n",
      "    learn_time_ms: 8.393\n",
      "    load_throughput: 67243.351\n",
      "    load_time_ms: 0.476\n",
      "    update_time_ms: 1.682\n",
      "  timestamp: 1632002035\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 40\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         609.495</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">   -1.05</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.025</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 41000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-54-08\n",
      "  done: false\n",
      "  episode_len_mean: 997.0975609756098\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.024390243902439\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 41\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 40816\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4.7531914710998535\n",
      "          mean_q: 3.5390186309814453\n",
      "          min_q: 3.1195497512817383\n",
      "        mean_td_error: 0.03161554038524628\n",
      "        td_error: \"[-1.4235258e-02 -7.1887016e-02  3.9095879e-03  1.0161400e-03\\n -1.4477539e-01\\\n",
      "          \\ -7.8139544e-02 -2.4372578e-02 -2.0828485e-02\\n -5.3122044e-03 -3.0177927e-01\\\n",
      "          \\  2.9224396e-02 -9.1405392e-02\\n  5.8674097e-02 -4.1867971e-02 -7.6838970e-02\\\n",
      "          \\  3.5519300e+00\\n -3.4042859e-01 -1.2740874e-01 -1.8038416e-01 -1.4682770e-01\\n\\\n",
      "          \\  1.0227602e+00 -7.7589536e-01  2.3367405e-02 -6.8500519e-02\\n -1.1473203e-01\\\n",
      "          \\ -7.9559326e-02 -2.3552179e-02 -4.7039843e-01\\n -8.1491470e-02 -7.1789026e-02\\\n",
      "          \\ -1.3886690e-01 -1.8790793e-01]\"\n",
      "    num_agent_steps_sampled: 41000\n",
      "    num_agent_steps_trained: 320032\n",
      "    num_steps_sampled: 41000\n",
      "    num_steps_trained: 320032\n",
      "    num_target_updates: 80\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.36842105263158\n",
      "    ram_util_percent: 89.26842105263158\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0402175711903848\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.899212417181829\n",
      "    mean_inference_ms: 1.5843164022911924\n",
      "    mean_raw_obs_processing_ms: 0.3043559232361695\n",
      "  time_since_restore: 622.3932015895844\n",
      "  time_this_iter_s: 12.898011207580566\n",
      "  time_total_s: 622.3932015895844\n",
      "  timers:\n",
      "    learn_throughput: 3857.629\n",
      "    learn_time_ms: 8.295\n",
      "    load_throughput: 66824.858\n",
      "    load_time_ms: 0.479\n",
      "    update_time_ms: 1.747\n",
      "  timestamp: 1632002048\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 41000\n",
      "  training_iteration: 41\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         622.393</td><td style=\"text-align: right;\">41000</td><td style=\"text-align: right;\">-1.02439</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.098</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 42000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-54-22\n",
      "  done: false\n",
      "  episode_len_mean: 997.1666666666666\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.0952380952380953\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 42\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 41824\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.793811798095703\n",
      "          mean_q: 4.013845443725586\n",
      "          min_q: 3.2244651317596436\n",
      "        mean_td_error: 0.010188095271587372\n",
      "        td_error: \"[ 0.03319883 -0.05528212  0.21129799 -0.15708661  0.13996458  0.34306002\\n\\\n",
      "          \\ -0.01659107 -0.2764151   0.02100635 -0.15996647  0.01597285  0.03171086\\n\\\n",
      "          \\ -0.10265017  0.03175187 -0.03872108  0.02974582 -1.7318573   0.1615622\\n\\\n",
      "          \\  0.9223099  -1.0802274  -0.00500011  0.07366371 -0.44558406  0.10675216\\n\\\n",
      "          \\  1.9699295   0.0480814  -0.04220533  0.0082438   0.03757644 -0.06207657\\n\\\n",
      "          \\  0.29519033  0.01866388]\"\n",
      "    num_agent_steps_sampled: 42000\n",
      "    num_agent_steps_trained: 328032\n",
      "    num_steps_sampled: 42000\n",
      "    num_steps_trained: 328032\n",
      "    num_target_updates: 82\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.26842105263158\n",
      "    ram_util_percent: 89.3842105263158\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04020823944545859\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.784248908195796\n",
      "    mean_inference_ms: 1.5839394984842956\n",
      "    mean_raw_obs_processing_ms: 0.31061088309646734\n",
      "  time_since_restore: 635.936416387558\n",
      "  time_this_iter_s: 13.543214797973633\n",
      "  time_total_s: 635.936416387558\n",
      "  timers:\n",
      "    learn_throughput: 3823.159\n",
      "    learn_time_ms: 8.37\n",
      "    load_throughput: 67001.661\n",
      "    load_time_ms: 0.478\n",
      "    update_time_ms: 1.646\n",
      "  timestamp: 1632002062\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 42000\n",
      "  training_iteration: 42\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         635.936</td><td style=\"text-align: right;\">42000</td><td style=\"text-align: right;\">-1.09524</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.167</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 43000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-54-35\n",
      "  done: false\n",
      "  episode_len_mean: 997.2325581395348\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.069767441860465\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 43\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 42832\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.1923346519470215\n",
      "          mean_q: 3.695333242416382\n",
      "          min_q: 2.7869651317596436\n",
      "        mean_td_error: -0.08843761682510376\n",
      "        td_error: \"[ 1.13683224e-01 -3.32355499e-04  1.60971642e-01 -6.19049311e-01\\n\\\n",
      "          \\ -7.33551979e-01 -1.02005005e-01 -5.04438877e-02 -4.97825146e-02\\n -4.57662582e-01\\\n",
      "          \\  3.46744061e-02 -1.05553389e-01 -2.32918501e-01\\n  2.85271406e-01 -3.69660854e-02\\\n",
      "          \\  3.49348307e-01 -1.95154428e-01\\n -9.55192804e-01  2.89558649e-01  1.69024467e-01\\\n",
      "          \\  9.34736729e-02\\n  2.93765068e-02 -4.06563282e-02  4.38332558e-02  5.50234318e-02\\n\\\n",
      "          \\ -5.39231300e-03  1.32956505e-02  1.90896511e-01 -8.91521454e-01\\n -1.27501488e-02\\\n",
      "          \\ -4.35547829e-02 -6.48422241e-02 -6.11047745e-02]\"\n",
      "    num_agent_steps_sampled: 43000\n",
      "    num_agent_steps_trained: 336032\n",
      "    num_steps_sampled: 43000\n",
      "    num_steps_trained: 336032\n",
      "    num_target_updates: 84\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.48421052631579\n",
      "    ram_util_percent: 89.49473684210527\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040198975691568446\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.673799988054304\n",
      "    mean_inference_ms: 1.5835693374504543\n",
      "    mean_raw_obs_processing_ms: 0.31634990544952435\n",
      "  time_since_restore: 649.154153585434\n",
      "  time_this_iter_s: 13.217737197875977\n",
      "  time_total_s: 649.154153585434\n",
      "  timers:\n",
      "    learn_throughput: 3410.436\n",
      "    learn_time_ms: 9.383\n",
      "    load_throughput: 66450.999\n",
      "    load_time_ms: 0.482\n",
      "    update_time_ms: 1.665\n",
      "  timestamp: 1632002075\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 43000\n",
      "  training_iteration: 43\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         649.154</td><td style=\"text-align: right;\">43000</td><td style=\"text-align: right;\">-1.06977</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.233</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-54-48\n",
      "  done: false\n",
      "  episode_len_mean: 997.2954545454545\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.0454545454545454\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 44\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 43840\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.229907989501953\n",
      "          mean_q: 3.795703411102295\n",
      "          min_q: 2.7222914695739746\n",
      "        mean_td_error: 0.14368019253015518\n",
      "        td_error: \"[ 3.31998825e-01  8.58085155e-02  1.10628891e+00  2.94058800e-01\\n\\\n",
      "          \\  3.78215146e+00  2.01643705e-01 -1.82460308e-01  5.82270622e-02\\n -3.99780273e-03\\\n",
      "          \\ -7.36245155e-01  7.03847408e-02  7.24513531e-02\\n  1.38370991e-02 -8.54713917e-02\\\n",
      "          \\  4.42848206e-02  8.08529854e-02\\n -1.14985228e-01  4.72650528e-02 -2.29382515e-03\\\n",
      "          \\ -1.20823383e-02\\n  4.83517885e-01  5.71756363e-01  9.39049721e-02  1.34344101e-02\\n\\\n",
      "          \\ -1.21012926e-01  8.21375847e-02 -2.69062281e-01  6.61473274e-02\\n  9.00518894e-02\\\n",
      "          \\ -1.27000809e-01  6.51581287e-02 -1.40298367e+00]\"\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 344032\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 344032\n",
      "    num_target_updates: 86\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.61052631578948\n",
      "    ram_util_percent: 89.7578947368421\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04019002023731854\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.56750939732126\n",
      "    mean_inference_ms: 1.5832058018304715\n",
      "    mean_raw_obs_processing_ms: 0.3216190364731908\n",
      "  time_since_restore: 662.2031586170197\n",
      "  time_this_iter_s: 13.049005031585693\n",
      "  time_total_s: 662.2031586170197\n",
      "  timers:\n",
      "    learn_throughput: 3862.659\n",
      "    learn_time_ms: 8.284\n",
      "    load_throughput: 67636.428\n",
      "    load_time_ms: 0.473\n",
      "    update_time_ms: 1.765\n",
      "  timestamp: 1632002088\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 44\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         662.203</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-1.04545</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.295</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 45000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-55-02\n",
      "  done: false\n",
      "  episode_len_mean: 997.3555555555556\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.0222222222222221\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 45\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 44848\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.223722457885742\n",
      "          mean_q: 3.6356277465820312\n",
      "          min_q: 3.13944149017334\n",
      "        mean_td_error: 0.11375890672206879\n",
      "        td_error: \"[ 1.7813444e-02  3.3248663e-02  3.6597896e+00  2.0668793e-01\\n -1.1531856e+00\\\n",
      "          \\  3.4593582e-02 -1.6703606e-03 -6.8266392e-02\\n  1.1094713e-01 -5.9701443e-02\\\n",
      "          \\  8.0179214e-02  6.9821119e-02\\n -4.8055649e-03  1.0448599e-01 -4.3160200e-02\\\n",
      "          \\  1.2554669e-01\\n  8.5544586e-02  7.9699278e-02  3.3159900e-01 -2.0099068e-01\\n\\\n",
      "          \\  6.6988707e-02 -3.5205603e-02 -4.2422533e-02  9.3884468e-02\\n -1.4611244e-02\\\n",
      "          \\  2.3298550e-01  5.3856134e-02  7.4432611e-02\\n -3.3034468e-01  1.7417550e-01\\\n",
      "          \\ -6.0729980e-02  1.9100189e-02]\"\n",
      "    num_agent_steps_sampled: 45000\n",
      "    num_agent_steps_trained: 352032\n",
      "    num_steps_sampled: 45000\n",
      "    num_steps_trained: 352032\n",
      "    num_target_updates: 88\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.626315789473686\n",
      "    ram_util_percent: 90.00526315789473\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04018128490561955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.465279578069193\n",
      "    mean_inference_ms: 1.5828511934888332\n",
      "    mean_raw_obs_processing_ms: 0.32645872889139843\n",
      "  time_since_restore: 675.5709705352783\n",
      "  time_this_iter_s: 13.367811918258667\n",
      "  time_total_s: 675.5709705352783\n",
      "  timers:\n",
      "    learn_throughput: 3857.973\n",
      "    learn_time_ms: 8.295\n",
      "    load_throughput: 64126.96\n",
      "    load_time_ms: 0.499\n",
      "    update_time_ms: 1.746\n",
      "  timestamp: 1632002102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45000\n",
      "  training_iteration: 45\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         675.571</td><td style=\"text-align: right;\">45000</td><td style=\"text-align: right;\">-1.02222</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.356</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 46000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-55-15\n",
      "  done: false\n",
      "  episode_len_mean: 997.4130434782609\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.0\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 46\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 45856\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 10.180728912353516\n",
      "          mean_q: 4.017122745513916\n",
      "          min_q: 3.0317654609680176\n",
      "        mean_td_error: -0.2603501081466675\n",
      "        td_error: \"[-0.12718964  0.02130699 -0.02829194 -0.9205334  -3.8163958  -0.01702094\\n\\\n",
      "          \\  0.05037236 -0.76329184  0.12497854 -2.1286736   0.03926563 -0.05675554\\n\\\n",
      "          \\ -0.22173691 -0.05596113 -0.00540257 -1.9145327   0.0957427  -0.02924681\\n\\\n",
      "          \\  1.0536127  -0.08723521  0.4574709   1.3369067  -0.07658386 -0.05009651\\n\\\n",
      "          \\  0.05318642 -0.00468826  0.01137233 -0.06464481  0.08612561  0.5841272\\n\\\n",
      "          \\ -0.9791789  -0.8982115 ]\"\n",
      "    num_agent_steps_sampled: 46000\n",
      "    num_agent_steps_trained: 360032\n",
      "    num_steps_sampled: 46000\n",
      "    num_steps_trained: 360032\n",
      "    num_target_updates: 90\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.5\n",
      "    ram_util_percent: 90.47894736842106\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04017278228656197\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.366755083304524\n",
      "    mean_inference_ms: 1.582508563106942\n",
      "    mean_raw_obs_processing_ms: 0.3309054369412506\n",
      "  time_since_restore: 688.7227530479431\n",
      "  time_this_iter_s: 13.151782512664795\n",
      "  time_total_s: 688.7227530479431\n",
      "  timers:\n",
      "    learn_throughput: 3862.158\n",
      "    learn_time_ms: 8.286\n",
      "    load_throughput: 68349.406\n",
      "    load_time_ms: 0.468\n",
      "    update_time_ms: 1.805\n",
      "  timestamp: 1632002115\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 46000\n",
      "  training_iteration: 46\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         688.723</td><td style=\"text-align: right;\">46000</td><td style=\"text-align: right;\">      -1</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.413</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 47000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-55-28\n",
      "  done: false\n",
      "  episode_len_mean: 997.468085106383\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.9787234042553191\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 47\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 46864\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.559581279754639\n",
      "          mean_q: 3.7831931114196777\n",
      "          min_q: 2.9590842723846436\n",
      "        mean_td_error: 0.2085999697446823\n",
      "        td_error: \"[ 0.05040884  0.59797025  0.81972647 -0.01727962 -0.01410151  0.07589269\\n\\\n",
      "          \\ -0.00475144 -0.02267408  0.09872603  0.11193824  0.11038828  0.11017323\\n\\\n",
      "          \\  2.0368328   0.22693157  0.06370783  0.05253172 -0.0557797   0.11752796\\n\\\n",
      "          \\  0.21093059  0.04233837  0.2596426  -0.38275027 -0.22275591  0.15426159\\n\\\n",
      "          \\  0.10590768  0.2269671   0.09614229  1.3248372   0.03797698  0.16499734\\n\\\n",
      "          \\  0.24898338  0.04955077]\"\n",
      "    num_agent_steps_sampled: 47000\n",
      "    num_agent_steps_trained: 368032\n",
      "    num_steps_sampled: 47000\n",
      "    num_steps_trained: 368032\n",
      "    num_target_updates: 92\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.38947368421052\n",
      "    ram_util_percent: 90.98947368421052\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04016454747062887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.27182273840341\n",
      "    mean_inference_ms: 1.5821728236437633\n",
      "    mean_raw_obs_processing_ms: 0.33499079442834595\n",
      "  time_since_restore: 702.0341899394989\n",
      "  time_this_iter_s: 13.311436891555786\n",
      "  time_total_s: 702.0341899394989\n",
      "  timers:\n",
      "    learn_throughput: 3860.97\n",
      "    learn_time_ms: 8.288\n",
      "    load_throughput: 67476.612\n",
      "    load_time_ms: 0.474\n",
      "    update_time_ms: 1.78\n",
      "  timestamp: 1632002128\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 47000\n",
      "  training_iteration: 47\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         702.034</td><td style=\"text-align: right;\">47000</td><td style=\"text-align: right;\">-0.978723</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.468</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 48000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-55-41\n",
      "  done: false\n",
      "  episode_len_mean: 997.5208333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.9583333333333334\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 48\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 47872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.83552360534668\n",
      "          mean_q: 3.4573686122894287\n",
      "          min_q: 2.58418345451355\n",
      "        mean_td_error: 0.0026631951332092285\n",
      "        td_error: \"[-0.10056567 -0.21098018  0.06673288 -0.14536309 -0.21019173 -0.09114051\\n\\\n",
      "          \\ -0.22637892 -0.09015059  0.01382327 -0.02884579 -0.07720065 -0.09501505\\n\\\n",
      "          \\ -0.29350567  0.72805667 -0.25644064 -0.02039695 -0.13177443  0.34889412\\n\\\n",
      "          \\  0.01621747 -0.02948332 -0.06409526  0.9832635  -0.07842708  0.13840723\\n\\\n",
      "          \\ -0.01764297 -0.05303216  0.1520338   0.17821002 -0.10195255 -0.15404558\\n\\\n",
      "          \\ -0.08076954  0.0169816 ]\"\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 376032\n",
      "    num_steps_sampled: 48000\n",
      "    num_steps_trained: 376032\n",
      "    num_target_updates: 94\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.310526315789474\n",
      "    ram_util_percent: 91.06315789473683\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040156475253048725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.180231261856783\n",
      "    mean_inference_ms: 1.5818418813721198\n",
      "    mean_raw_obs_processing_ms: 0.3387451967417396\n",
      "  time_since_restore: 715.2231640815735\n",
      "  time_this_iter_s: 13.188974142074585\n",
      "  time_total_s: 715.2231640815735\n",
      "  timers:\n",
      "    learn_throughput: 3827.367\n",
      "    learn_time_ms: 8.361\n",
      "    load_throughput: 67899.898\n",
      "    load_time_ms: 0.471\n",
      "    update_time_ms: 1.703\n",
      "  timestamp: 1632002141\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 48\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         715.223</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">-0.958333</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.521</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 49000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-55-54\n",
      "  done: false\n",
      "  episode_len_mean: 997.5714285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.9387755102040817\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 49\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 48880\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11.264409065246582\n",
      "          mean_q: 3.8357090950012207\n",
      "          min_q: 2.189816951751709\n",
      "        mean_td_error: 0.2698223181068897\n",
      "        td_error: \"[-0.12546682  0.11968493  0.29503822 -0.04229999  1.57108259  0.18768311\\n\\\n",
      "          \\  0.03590059  0.04823875  0.08620214 -0.24995446  0.10041356 -0.09101725\\n\\\n",
      "          \\  0.0050981   0.21362925  0.05701256  0.28418779  0.06198955  0.27980113\\n\\\n",
      "          \\  0.02929521  1.65512991  0.13348341  0.00401449  0.03360987  0.03842354\\n\\\n",
      "          \\  0.58995748  0.73127854  0.07011867  0.01280355  0.05646753  2.18981695\\n\\\n",
      "          \\  0.19362259  0.05906868]\"\n",
      "    num_agent_steps_sampled: 49000\n",
      "    num_agent_steps_trained: 384032\n",
      "    num_steps_sampled: 49000\n",
      "    num_steps_trained: 384032\n",
      "    num_target_updates: 96\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.36666666666666\n",
      "    ram_util_percent: 91.1888888888889\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04014860281408942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.091714258300218\n",
      "    mean_inference_ms: 1.5815161509927944\n",
      "    mean_raw_obs_processing_ms: 0.3421949568716982\n",
      "  time_since_restore: 728.1912786960602\n",
      "  time_this_iter_s: 12.968114614486694\n",
      "  time_total_s: 728.1912786960602\n",
      "  timers:\n",
      "    learn_throughput: 3885.369\n",
      "    learn_time_ms: 8.236\n",
      "    load_throughput: 67992.77\n",
      "    load_time_ms: 0.471\n",
      "    update_time_ms: 1.732\n",
      "  timestamp: 1632002154\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 49000\n",
      "  training_iteration: 49\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         728.191</td><td style=\"text-align: right;\">49000</td><td style=\"text-align: right;\">-0.938776</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.571</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 50000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-56-08\n",
      "  done: false\n",
      "  episode_len_mean: 997.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.92\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 50\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 49888\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 25.794464111328125\n",
      "          mean_q: 4.013084411621094\n",
      "          min_q: 2.6485817432403564\n",
      "        mean_td_error: 0.171047180891037\n",
      "        td_error: \"[ 0.60890675  0.00344014  0.19428825  0.04748964  0.03615403 -0.10482454\\n\\\n",
      "          \\  0.1330781   0.03330064  0.06344724  0.3540516  -0.00548935  1.0388498\\n\\\n",
      "          \\  0.1719389   0.01742792  0.01405239  0.06276226  0.02442765  0.16506553\\n\\\n",
      "          \\  0.08879447 -0.00217938  0.03813171  0.02302623  0.9664602  -0.0056231\\n\\\n",
      "          \\  0.07209921 -0.02705193  1.1115074   0.35239768 -0.02697253  0.05537462\\n\\\n",
      "          \\ -0.04844832  0.01762676]\"\n",
      "    num_agent_steps_sampled: 50000\n",
      "    num_agent_steps_trained: 392032\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 392032\n",
      "    num_target_updates: 98\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.55263157894736\n",
      "    ram_util_percent: 91.3157894736842\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040140895022963\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 13.006220537833691\n",
      "    mean_inference_ms: 1.5812028834212277\n",
      "    mean_raw_obs_processing_ms: 0.34536472426696385\n",
      "  time_since_restore: 741.4680287837982\n",
      "  time_this_iter_s: 13.276750087738037\n",
      "  time_total_s: 741.4680287837982\n",
      "  timers:\n",
      "    learn_throughput: 3761.054\n",
      "    learn_time_ms: 8.508\n",
      "    load_throughput: 65957.899\n",
      "    load_time_ms: 0.485\n",
      "    update_time_ms: 1.615\n",
      "  timestamp: 1632002168\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 50\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         741.468</td><td style=\"text-align: right;\">50000</td><td style=\"text-align: right;\">   -0.92</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">            997.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 51000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-56-21\n",
      "  done: false\n",
      "  episode_len_mean: 997.6666666666666\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.9019607843137255\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 51\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 50896\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 14.3095064163208\n",
      "          mean_q: 4.060037612915039\n",
      "          min_q: 2.711822748184204\n",
      "        mean_td_error: -0.13592319190502167\n",
      "        td_error: \"[-1.26437902e-01 -4.64200974e-03 -1.50953150e+00 -1.36065006e-01\\n\\\n",
      "          \\ -7.02438354e-02 -1.50407791e-01 -8.58325243e-01 -7.39040375e-02\\n -1.29438162e-01\\\n",
      "          \\  6.27431870e-02 -4.95030880e-02 -1.12909555e-01\\n -4.21747923e-01 -2.06218243e-01\\\n",
      "          \\ -1.59387112e-01 -8.57300758e-02\\n -4.19251442e-01 -8.65911245e-01 -2.33597755e-02\\\n",
      "          \\ -1.00294113e-01\\n  1.10435486e-03  7.78465271e-01 -2.07090378e-02 -3.54182482e-01\\n\\\n",
      "          \\ -5.12034893e-02 -7.60874748e-02 -1.12219810e-01  5.57636261e-01\\n  3.41979027e-01\\\n",
      "          \\ -6.38079643e-02  8.81977081e-02  1.85036659e-03]\"\n",
      "    num_agent_steps_sampled: 51000\n",
      "    num_agent_steps_trained: 400032\n",
      "    num_steps_sampled: 51000\n",
      "    num_steps_trained: 400032\n",
      "    num_target_updates: 100\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.9\n",
      "    ram_util_percent: 91.32631578947367\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04013342313417199\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.923568167829051\n",
      "    mean_inference_ms: 1.5808962776807156\n",
      "    mean_raw_obs_processing_ms: 0.34827635325476125\n",
      "  time_since_restore: 754.6995029449463\n",
      "  time_this_iter_s: 13.231474161148071\n",
      "  time_total_s: 754.6995029449463\n",
      "  timers:\n",
      "    learn_throughput: 3766.733\n",
      "    learn_time_ms: 8.495\n",
      "    load_throughput: 63253.56\n",
      "    load_time_ms: 0.506\n",
      "    update_time_ms: 1.672\n",
      "  timestamp: 1632002181\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 51000\n",
      "  training_iteration: 51\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">           754.7</td><td style=\"text-align: right;\">51000</td><td style=\"text-align: right;\">-0.901961</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-56-34\n",
      "  done: false\n",
      "  episode_len_mean: 997.7115384615385\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.8846153846153846\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 52\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 51904\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 10.69658374786377\n",
      "          mean_q: 3.2426931858062744\n",
      "          min_q: 2.5154242515563965\n",
      "        mean_td_error: 0.21769477427005768\n",
      "        td_error: \"[-9.3438387e-02 -1.2249756e-01 -2.0236969e-02  3.5963042e+00\\n  2.5187731e-02\\\n",
      "          \\ -5.5969954e-02  3.1783581e-03  9.7171736e-01\\n -9.0291023e-02 -5.5103278e-01\\\n",
      "          \\ -3.2100201e-02  2.6963925e-01\\n  7.4539948e-01 -3.3807993e-02 -4.6246052e-03\\\n",
      "          \\ -2.7493715e-02\\n  3.3584833e-02  1.1097703e+00  2.2317886e-02  1.3082027e-02\\n\\\n",
      "          \\  1.0095596e-02  1.7113447e-02  1.9385576e-01  2.1509433e-01\\n -6.8283081e-04\\\n",
      "          \\  2.8420925e-02 -2.8106213e-02 -1.1183262e-02\\n  8.6493266e-01 -4.2842627e-02\\\n",
      "          \\ -7.0206404e-02  3.1053066e-02]\"\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 408032\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 408032\n",
      "    num_target_updates: 102\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.13333333333333\n",
      "    ram_util_percent: 91.44444444444446\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040126246137123636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.843394718285412\n",
      "    mean_inference_ms: 1.5805926288057768\n",
      "    mean_raw_obs_processing_ms: 0.3509493077104261\n",
      "  time_since_restore: 767.3243553638458\n",
      "  time_this_iter_s: 12.624852418899536\n",
      "  time_total_s: 767.3243553638458\n",
      "  timers:\n",
      "    learn_throughput: 3645.339\n",
      "    learn_time_ms: 8.778\n",
      "    load_throughput: 54438.34\n",
      "    load_time_ms: 0.588\n",
      "    update_time_ms: 1.755\n",
      "  timestamp: 1632002194\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 52\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         767.324</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-0.884615</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.712</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 53000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-56-47\n",
      "  done: false\n",
      "  episode_len_mean: 997.7547169811321\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.8679245283018868\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 53\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 52912\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 13.341720581054688\n",
      "          mean_q: 3.7996654510498047\n",
      "          min_q: 2.4219160079956055\n",
      "        mean_td_error: 0.10187974572181702\n",
      "        td_error: \"[ 9.25343037e-02  2.84918308e-01  4.74343300e-02  2.07720995e-01\\n\\\n",
      "          \\  6.01413250e-02  5.19521236e-02  8.62658024e-02  3.79220486e-01\\n  2.95000076e-01\\\n",
      "          \\  4.49039936e-02 -1.96528244e+00  6.43975258e-01\\n  7.58814812e-02  1.01984501e-01\\\n",
      "          \\  2.97229290e-02  9.53161716e-02\\n  1.22547150e-03  9.43729877e-02 -3.16378117e-01\\\n",
      "          \\  1.18477106e-01\\n  9.76712704e-02  6.40857220e-02  9.85555649e-02  1.14866734e-01\\n\\\n",
      "          \\  4.22213078e-02  1.29698610e+00  5.23565769e-01  2.98023224e-02\\n  5.54156303e-02\\\n",
      "          \\  6.75447702e-01  1.22454643e-01 -2.90307999e-01]\"\n",
      "    num_agent_steps_sampled: 53000\n",
      "    num_agent_steps_trained: 416032\n",
      "    num_steps_sampled: 53000\n",
      "    num_steps_trained: 416032\n",
      "    num_target_updates: 104\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.11052631578947\n",
      "    ram_util_percent: 91.71052631578947\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040119463340586956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.765762208647187\n",
      "    mean_inference_ms: 1.5803039686213833\n",
      "    mean_raw_obs_processing_ms: 0.35340520457814756\n",
      "  time_since_restore: 780.5567202568054\n",
      "  time_this_iter_s: 13.232364892959595\n",
      "  time_total_s: 780.5567202568054\n",
      "  timers:\n",
      "    learn_throughput: 3739.405\n",
      "    learn_time_ms: 8.558\n",
      "    load_throughput: 36399.015\n",
      "    load_time_ms: 0.879\n",
      "    update_time_ms: 1.647\n",
      "  timestamp: 1632002207\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 53000\n",
      "  training_iteration: 53\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         780.557</td><td style=\"text-align: right;\">53000</td><td style=\"text-align: right;\">-0.867925</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.755</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 54000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-57-00\n",
      "  done: false\n",
      "  episode_len_mean: 997.7962962962963\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.8518518518518519\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 54\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 53920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 12.079015731811523\n",
      "          mean_q: 3.4907941818237305\n",
      "          min_q: 2.2865967750549316\n",
      "        mean_td_error: -0.29890137910842896\n",
      "        td_error: \"[-0.11962223 -0.13745809 -0.10339189 -0.07732797 -0.08420992 -0.14130545\\n\\\n",
      "          \\  0.05701828 -0.13131332 -1.4153576  -0.09179783 -0.22212315 -0.09022975\\n\\\n",
      "          \\ -0.00887632 -0.392555   -3.7871351  -1.1067584   0.019068   -0.13802218\\n\\\n",
      "          \\ -0.1177125  -0.12409663 -0.17924714 -0.09416223 -0.13300991 -0.08568883\\n\\\n",
      "          \\  0.07767677 -0.09225464 -0.30239964 -0.14927673 -0.05763507 -0.08596873\\n\\\n",
      "          \\ -0.15423751 -0.09543347]\"\n",
      "    num_agent_steps_sampled: 54000\n",
      "    num_agent_steps_trained: 424032\n",
      "    num_steps_sampled: 54000\n",
      "    num_steps_trained: 424032\n",
      "    num_target_updates: 106\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.37894736842105\n",
      "    ram_util_percent: 91.68421052631578\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04011287535434322\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.690641433356415\n",
      "    mean_inference_ms: 1.5800238230550723\n",
      "    mean_raw_obs_processing_ms: 0.3556645811347366\n",
      "  time_since_restore: 794.008820772171\n",
      "  time_this_iter_s: 13.4521005153656\n",
      "  time_total_s: 794.008820772171\n",
      "  timers:\n",
      "    learn_throughput: 3817.374\n",
      "    learn_time_ms: 8.383\n",
      "    load_throughput: 62998.23\n",
      "    load_time_ms: 0.508\n",
      "    update_time_ms: 1.609\n",
      "  timestamp: 1632002220\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 54000\n",
      "  training_iteration: 54\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         794.009</td><td style=\"text-align: right;\">54000</td><td style=\"text-align: right;\">-0.851852</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.796</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 55000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-57-14\n",
      "  done: false\n",
      "  episode_len_mean: 997.8363636363637\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.8363636363636363\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 55\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 54928\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 9.976149559020996\n",
      "          mean_q: 3.333428382873535\n",
      "          min_q: 2.3574490547180176\n",
      "        mean_td_error: -0.028484299778938293\n",
      "        td_error: \"[-1.99116230e-01 -5.06769419e-01 -4.32123184e-01 -7.96439648e-02\\n\\\n",
      "          \\  2.25782824e+00 -6.53265953e-01 -1.44696712e-01 -8.90164375e-02\\n -1.16382360e-01\\\n",
      "          \\  1.58286095e-03 -1.64925814e-01 -9.53910351e-02\\n -1.23423338e-01 -1.07756376e-01\\\n",
      "          \\ -8.20138454e-02 -6.25889301e-02\\n  5.63576221e-02 -1.21592760e-01 -9.65690613e-02\\\n",
      "          \\ -8.19599628e-02\\n -7.82828331e-02  1.17788553e-01 -2.65440941e-02 -1.05166435e-01\\n\\\n",
      "          \\ -1.12031937e-01 -2.58340836e-02  6.74648762e-01 -1.27083063e-01\\n -1.26223803e-01\\\n",
      "          \\ -5.79373837e-02 -1.24628067e-01 -7.87365437e-02]\"\n",
      "    num_agent_steps_sampled: 55000\n",
      "    num_agent_steps_trained: 432032\n",
      "    num_steps_sampled: 55000\n",
      "    num_steps_trained: 432032\n",
      "    num_target_updates: 108\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.3\n",
      "    ram_util_percent: 91.91\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04010642304594113\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.617955939541405\n",
      "    mean_inference_ms: 1.5797523819071493\n",
      "    mean_raw_obs_processing_ms: 0.3577364617304513\n",
      "  time_since_restore: 807.628351688385\n",
      "  time_this_iter_s: 13.61953091621399\n",
      "  time_total_s: 807.628351688385\n",
      "  timers:\n",
      "    learn_throughput: 3812.083\n",
      "    learn_time_ms: 8.394\n",
      "    load_throughput: 64499.845\n",
      "    load_time_ms: 0.496\n",
      "    update_time_ms: 1.634\n",
      "  timestamp: 1632002234\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 55000\n",
      "  training_iteration: 55\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         807.628</td><td style=\"text-align: right;\">55000</td><td style=\"text-align: right;\">-0.836364</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.836</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 56000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-57-28\n",
      "  done: false\n",
      "  episode_len_mean: 997.875\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.8928571428571429\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 56\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 55936\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11.793689727783203\n",
      "          mean_q: 3.7184031009674072\n",
      "          min_q: 2.631232976913452\n",
      "        mean_td_error: -0.0947934240102768\n",
      "        td_error: \"[ 3.05664539e-01  2.15031147e-01 -5.21826744e-02 -5.56777954e+00\\n\\\n",
      "          \\ -7.14945793e-03  3.90398026e-01 -2.42242813e-02  2.13835239e-02\\n -7.80847788e-01\\\n",
      "          \\  1.74121857e-02 -3.79424095e-02  1.29681110e-01\\n -4.13892269e-02 -1.32369995e-02\\\n",
      "          \\  2.60944843e-01  3.28207016e-03\\n  5.93433380e-01  1.38020515e-01 -4.02789116e-02\\\n",
      "          \\  2.50179768e-02\\n -3.70948315e-02 -3.66086960e-02 -3.77712250e-02  4.48203087e-01\\n\\\n",
      "          \\ -2.59594917e-02 -9.59634781e-03  2.85184860e-01  2.66497135e-02\\n  1.25232935e-01\\\n",
      "          \\  2.21570015e-01  5.04724503e-01 -3.31621170e-02]\"\n",
      "    num_agent_steps_sampled: 56000\n",
      "    num_agent_steps_trained: 440032\n",
      "    num_steps_sampled: 56000\n",
      "    num_steps_trained: 440032\n",
      "    num_target_updates: 110\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.794736842105266\n",
      "    ram_util_percent: 91.88421052631578\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040100150002305004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.547683439296119\n",
      "    mean_inference_ms: 1.5794901316962167\n",
      "    mean_raw_obs_processing_ms: 0.3596376949212013\n",
      "  time_since_restore: 821.5325231552124\n",
      "  time_this_iter_s: 13.904171466827393\n",
      "  time_total_s: 821.5325231552124\n",
      "  timers:\n",
      "    learn_throughput: 3803.678\n",
      "    learn_time_ms: 8.413\n",
      "    load_throughput: 64262.055\n",
      "    load_time_ms: 0.498\n",
      "    update_time_ms: 1.632\n",
      "  timestamp: 1632002248\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 56000\n",
      "  training_iteration: 56\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         821.533</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">-0.892857</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.875</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 57000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-57-42\n",
      "  done: false\n",
      "  episode_len_mean: 997.9122807017544\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.0\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 57\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 56944\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5.008108615875244\n",
      "          mean_q: 2.9856362342834473\n",
      "          min_q: 2.5556607246398926\n",
      "        mean_td_error: -0.07018575072288513\n",
      "        td_error: \"[-5.8149576e-02 -7.0111513e-02 -2.1446466e-02 -1.1756277e-01\\n -1.5777111e-02\\\n",
      "          \\ -1.8664527e-01  3.2313657e-01 -9.0265274e-04\\n -3.4894943e-02  2.2928190e-01\\\n",
      "          \\  4.2001247e-02  3.1884146e-01\\n -9.5851040e-01 -6.9561243e-02 -3.9720798e-01\\\n",
      "          \\  1.7404079e-02\\n -3.4778357e-02 -4.0615082e-02 -4.4275284e-02 -7.9943657e-02\\n\\\n",
      "          \\ -2.7659416e-02 -5.8591366e-03 -6.3998938e-02 -3.6828041e-02\\n  7.3361397e-03\\\n",
      "          \\  7.3308945e-02 -6.6908932e-01 -9.7737551e-02\\n -5.5240154e-02 -5.3463221e-02\\\n",
      "          \\ -4.7807217e-02 -6.9189072e-02]\"\n",
      "    num_agent_steps_sampled: 57000\n",
      "    num_agent_steps_trained: 448032\n",
      "    num_steps_sampled: 57000\n",
      "    num_steps_trained: 448032\n",
      "    num_target_updates: 112\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.5\n",
      "    ram_util_percent: 91.98999999999998\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04009431426459634\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.479699046065528\n",
      "    mean_inference_ms: 1.5792419115505327\n",
      "    mean_raw_obs_processing_ms: 0.36138197549601964\n",
      "  time_since_restore: 835.5408363342285\n",
      "  time_this_iter_s: 14.008313179016113\n",
      "  time_total_s: 835.5408363342285\n",
      "  timers:\n",
      "    learn_throughput: 3757.537\n",
      "    learn_time_ms: 8.516\n",
      "    load_throughput: 62891.958\n",
      "    load_time_ms: 0.509\n",
      "    update_time_ms: 1.66\n",
      "  timestamp: 1632002262\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 57000\n",
      "  training_iteration: 57\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         835.541</td><td style=\"text-align: right;\">57000</td><td style=\"text-align: right;\">      -1</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.912</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 58000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-57-56\n",
      "  done: false\n",
      "  episode_len_mean: 997.948275862069\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.1206896551724137\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 58\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 57952\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5.899270057678223\n",
      "          mean_q: 3.2467761039733887\n",
      "          min_q: 2.5043585300445557\n",
      "        mean_td_error: 0.057370394468307495\n",
      "        td_error: \"[-0.09897804  0.06249666 -0.34538221  0.06470728 -0.22278404 -0.01353669\\n\\\n",
      "          \\ -0.0554626  -0.02763176 -0.79802752 -0.00297737  1.00860548 -0.07620907\\n\\\n",
      "          \\ -0.0362184  -0.00357723 -0.05969548  0.1127069   0.00584316 -0.0259397\\n\\\n",
      "          \\  0.11904097  0.0380373  -0.56780744 -0.0765481  -0.0411756   0.27916288\\n\\\n",
      "          \\  0.0701623   0.02411485  0.03026342  2.51078367  0.1127069  -0.19533753\\n\\\n",
      "          \\ -0.16221046  0.20672011]\"\n",
      "    num_agent_steps_sampled: 58000\n",
      "    num_agent_steps_trained: 456032\n",
      "    num_steps_sampled: 58000\n",
      "    num_steps_trained: 456032\n",
      "    num_target_updates: 114\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.87\n",
      "    ram_util_percent: 92.065\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04008880718490616\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.413845858281526\n",
      "    mean_inference_ms: 1.579005829313977\n",
      "    mean_raw_obs_processing_ms: 0.3629803505343546\n",
      "  time_since_restore: 849.3661394119263\n",
      "  time_this_iter_s: 13.825303077697754\n",
      "  time_total_s: 849.3661394119263\n",
      "  timers:\n",
      "    learn_throughput: 3803.182\n",
      "    learn_time_ms: 8.414\n",
      "    load_throughput: 63519.985\n",
      "    load_time_ms: 0.504\n",
      "    update_time_ms: 1.664\n",
      "  timestamp: 1632002276\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 58000\n",
      "  training_iteration: 58\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         849.366</td><td style=\"text-align: right;\">58000</td><td style=\"text-align: right;\">-1.12069</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.948</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 59000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-58-10\n",
      "  done: false\n",
      "  episode_len_mean: 997.9830508474577\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.1864406779661016\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 59\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 58960\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.048262596130371\n",
      "          mean_q: 3.2378668785095215\n",
      "          min_q: 2.3552772998809814\n",
      "        mean_td_error: 0.08284918963909149\n",
      "        td_error: \"[ 0.06879497  0.11271381  0.0715301   0.09088969  0.06721234  0.04113793\\n\\\n",
      "          \\  0.01448441  0.05159187  0.04821706  0.614218    0.07430077  0.08831978\\n\\\n",
      "          \\ -0.3272822  -0.07304263  0.1178968   0.11307335  0.19857788  0.02325082\\n\\\n",
      "          \\  0.04142976  0.32563496  0.15011835  0.1257317   0.0432682  -0.12793446\\n\\\n",
      "          \\  0.12157106  0.13316226  0.3387084   0.06449103  0.03765774  0.14470363\\n\\\n",
      "          \\  1.0731664  -1.2164197 ]\"\n",
      "    num_agent_steps_sampled: 59000\n",
      "    num_agent_steps_trained: 464032\n",
      "    num_steps_sampled: 59000\n",
      "    num_steps_trained: 464032\n",
      "    num_target_updates: 116\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.989999999999995\n",
      "    ram_util_percent: 92.015\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04008365903628145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.350041398105036\n",
      "    mean_inference_ms: 1.578783050734097\n",
      "    mean_raw_obs_processing_ms: 0.36444632929235615\n",
      "  time_since_restore: 863.2974064350128\n",
      "  time_this_iter_s: 13.931267023086548\n",
      "  time_total_s: 863.2974064350128\n",
      "  timers:\n",
      "    learn_throughput: 3794.484\n",
      "    learn_time_ms: 8.433\n",
      "    load_throughput: 65638.56\n",
      "    load_time_ms: 0.488\n",
      "    update_time_ms: 1.628\n",
      "  timestamp: 1632002290\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59000\n",
      "  training_iteration: 59\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         863.297</td><td style=\"text-align: right;\">59000</td><td style=\"text-align: right;\">-1.18644</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           997.983</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-59-06\n",
      "  done: false\n",
      "  episode_len_mean: 989.3666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.1833333333333333\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 60\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 59968\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 12.047928810119629\n",
      "          mean_q: 3.573458194732666\n",
      "          min_q: 2.3405001163482666\n",
      "        mean_td_error: 0.1616000533103943\n",
      "        td_error: \"[ 0.01175165 -0.01753163  2.2790203   0.9362149  -0.00917006 -0.0351851\\n\\\n",
      "          \\  0.85249424  0.14759207  1.4843752  -0.03241205  0.43223333 -0.00621724\\n\\\n",
      "          \\ -1.4054613   0.2503128   0.33397293  0.03922963  0.01280594 -0.45052123\\n\\\n",
      "          \\  0.48949528 -0.04249954  0.10723662 -0.00483727  0.04290724  0.03026032\\n\\\n",
      "          \\  0.04527712 -0.00481987  0.00290275 -0.03051281 -0.4527645  -0.00610709\\n\\\n",
      "          \\  0.18297195 -0.01181293]\"\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 472032\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 472032\n",
      "    num_target_updates: 118\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.265000000000004\n",
      "    ram_util_percent: 91.97125\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04007891602877616\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.288155816956978\n",
      "    mean_inference_ms: 1.5785722290571391\n",
      "    mean_raw_obs_processing_ms: 0.37750182763231344\n",
      "  time_since_restore: 919.236629486084\n",
      "  time_this_iter_s: 55.93922305107117\n",
      "  time_total_s: 919.236629486084\n",
      "  timers:\n",
      "    learn_throughput: 3712.184\n",
      "    learn_time_ms: 8.62\n",
      "    load_throughput: 56818.952\n",
      "    load_time_ms: 0.563\n",
      "    update_time_ms: 1.715\n",
      "  timestamp: 1632002346\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 60\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         919.237</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-1.18333</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">           989.367</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 61000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-59-21\n",
      "  done: false\n",
      "  episode_len_mean: 989.5409836065573\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.3770491803278688\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 61\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 60976\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.525135040283203\n",
      "          mean_q: 3.382500171661377\n",
      "          min_q: 2.4403202533721924\n",
      "        mean_td_error: 0.012789510190486908\n",
      "        td_error: \"[ 8.87647867e-01  3.33700180e-02  6.06126785e-02 -7.05605507e-01\\n\\\n",
      "          \\  1.33879185e-02  6.04248047e-02  1.02022886e-01  1.62189007e-01\\n  4.72080708e-02\\\n",
      "          \\  1.60956383e-02  7.91599751e-02  1.45115852e-02\\n  3.67045403e-02  5.23469448e-02\\\n",
      "          \\ -5.63740730e-03  6.24997616e-02\\n -1.15027189e-01  5.50637245e-02  4.48477268e-02\\\n",
      "          \\ -4.45442200e-01\\n  4.13866043e-02  7.62431622e-02 -3.37593317e-01  3.29494476e-04\\n\\\n",
      "          \\  5.78022003e-03 -1.83134556e-01  6.65462017e-02 -7.77077675e-02\\n -3.60007286e-02\\\n",
      "          \\  3.70371342e-01  1.52945518e-02  1.13682747e-02]\"\n",
      "    num_agent_steps_sampled: 61000\n",
      "    num_agent_steps_trained: 480032\n",
      "    num_steps_sampled: 61000\n",
      "    num_steps_trained: 480032\n",
      "    num_target_updates: 120\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.036363636363646\n",
      "    ram_util_percent: 91.85454545454546\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04007427801255326\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.228570134823487\n",
      "    mean_inference_ms: 1.578367715869568\n",
      "    mean_raw_obs_processing_ms: 0.38986501097539955\n",
      "  time_since_restore: 934.6419310569763\n",
      "  time_this_iter_s: 15.405301570892334\n",
      "  time_total_s: 934.6419310569763\n",
      "  timers:\n",
      "    learn_throughput: 3805.749\n",
      "    learn_time_ms: 8.408\n",
      "    load_throughput: 67564.927\n",
      "    load_time_ms: 0.474\n",
      "    update_time_ms: 1.664\n",
      "  timestamp: 1632002361\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 61000\n",
      "  training_iteration: 61\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         934.642</td><td style=\"text-align: right;\">61000</td><td style=\"text-align: right;\">-1.37705</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           989.541</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 62000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-59-34\n",
      "  done: false\n",
      "  episode_len_mean: 989.7096774193549\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.467741935483871\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 62\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 61984\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.144378662109375\n",
      "          mean_q: 3.613436698913574\n",
      "          min_q: 2.2812695503234863\n",
      "        mean_td_error: 0.021030083298683167\n",
      "        td_error: \"[ 0.05354524 -0.0213151  -0.2601285   0.02051377  0.03778124  0.02885699\\n\\\n",
      "          \\  0.04566765  0.01424122 -0.25289536  0.00592375  0.13250709  0.16179752\\n\\\n",
      "          \\  0.09531903  0.04153419 -0.04612255  0.13522196 -1.1427622   0.317863\\n\\\n",
      "          \\ -0.15199137  0.22063494  0.02286386  0.21978426  0.02347803  0.02970648\\n\\\n",
      "          \\  0.11666727  0.05074406 -0.1079843   1.1975446   0.01249051 -0.44515705\\n\\\n",
      "          \\  0.04802895  0.06860352]\"\n",
      "    num_agent_steps_sampled: 62000\n",
      "    num_agent_steps_trained: 488032\n",
      "    num_steps_sampled: 62000\n",
      "    num_steps_trained: 488032\n",
      "    num_target_updates: 122\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.78421052631579\n",
      "    ram_util_percent: 92.05789473684212\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04006976011743473\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.170596714262873\n",
      "    mean_inference_ms: 1.5781657442512762\n",
      "    mean_raw_obs_processing_ms: 0.40157764692221465\n",
      "  time_since_restore: 947.8086755275726\n",
      "  time_this_iter_s: 13.166744470596313\n",
      "  time_total_s: 947.8086755275726\n",
      "  timers:\n",
      "    learn_throughput: 3795.6\n",
      "    learn_time_ms: 8.431\n",
      "    load_throughput: 63749.277\n",
      "    load_time_ms: 0.502\n",
      "    update_time_ms: 1.614\n",
      "  timestamp: 1632002374\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 62000\n",
      "  training_iteration: 62\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         947.809</td><td style=\"text-align: right;\">62000</td><td style=\"text-align: right;\">-1.46774</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            989.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 63000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_21-59-47\n",
      "  done: false\n",
      "  episode_len_mean: 989.8730158730159\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.507936507936508\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 63\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 62992\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11.693254470825195\n",
      "          mean_q: 3.832918643951416\n",
      "          min_q: 2.2851970195770264\n",
      "        mean_td_error: -0.097346231341362\n",
      "        td_error: \"[-1.7125607e-03 -2.3250103e-01 -4.9318027e-01 -6.4897299e-02\\n  3.5716295e-02\\\n",
      "          \\ -4.6612978e-01  1.6238070e-01 -8.5017204e-02\\n -1.6070938e-01  4.8983097e-03\\\n",
      "          \\  1.6212463e-05 -9.1875172e-01\\n  6.8681240e-02 -3.9587760e-01 -4.2897749e-01\\\n",
      "          \\ -4.5949936e-02\\n -1.4850569e-01 -2.8203678e-01  1.2453365e-01 -1.0197639e-02\\n\\\n",
      "          \\  2.0164728e-02 -2.8565407e-01  7.6020718e-02  1.7870665e-02\\n -7.8349113e-03\\\n",
      "          \\  5.4533482e-03 -1.5792131e-02 -2.2456050e-01\\n -1.4022708e-01  8.1796265e-01\\\n",
      "          \\ -3.2809258e-02 -7.4555874e-03]\"\n",
      "    num_agent_steps_sampled: 63000\n",
      "    num_agent_steps_trained: 496032\n",
      "    num_steps_sampled: 63000\n",
      "    num_steps_trained: 496032\n",
      "    num_target_updates: 124\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.39444444444444\n",
      "    ram_util_percent: 92.13333333333331\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04006531777892249\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.11412546067667\n",
      "    mean_inference_ms: 1.577964757058365\n",
      "    mean_raw_obs_processing_ms: 0.41267870888326375\n",
      "  time_since_restore: 960.8278946876526\n",
      "  time_this_iter_s: 13.019219160079956\n",
      "  time_total_s: 960.8278946876526\n",
      "  timers:\n",
      "    learn_throughput: 3801.179\n",
      "    learn_time_ms: 8.418\n",
      "    load_throughput: 65828.5\n",
      "    load_time_ms: 0.486\n",
      "    update_time_ms: 1.634\n",
      "  timestamp: 1632002387\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 63000\n",
      "  training_iteration: 63\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         960.828</td><td style=\"text-align: right;\">63000</td><td style=\"text-align: right;\">-1.50794</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           989.873</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 64000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-00-01\n",
      "  done: false\n",
      "  episode_len_mean: 990.03125\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -1.515625\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 64\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 64000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 9.707539558410645\n",
      "          mean_q: 3.487926721572876\n",
      "          min_q: 2.2791714668273926\n",
      "        mean_td_error: -0.003007248044013977\n",
      "        td_error: \"[ 5.84423542e-02 -9.47623253e-02 -2.62629986e-02 -4.40988302e-01\\n\\\n",
      "          \\ -5.66236973e-02  2.72359848e-02 -6.59834862e-01  3.71967077e-01\\n  2.26001740e-02\\\n",
      "          \\  3.35033417e-01  4.05039787e-02  7.66654015e-02\\n -2.28209972e-01 -1.49502754e-02\\\n",
      "          \\ -2.22309589e-01  1.39575005e-02\\n -6.71863556e-04  3.90982628e-01 -1.31518769e+00\\\n",
      "          \\  4.34396267e-02\\n -1.37073755e-01  8.32030773e-02 -1.06672525e-01  2.30238676e-01\\n\\\n",
      "          \\  2.02512741e-02  4.35121059e-02 -9.56113338e-02  1.41692758e+00\\n -7.71498680e-03\\\n",
      "          \\  4.35121059e-02  6.70862198e-02  2.50830650e-02]\"\n",
      "    num_agent_steps_sampled: 64000\n",
      "    num_agent_steps_trained: 504032\n",
      "    num_steps_sampled: 64000\n",
      "    num_steps_trained: 504032\n",
      "    num_target_updates: 126\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.64\n",
      "    ram_util_percent: 92.1\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04006100728412129\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.059325919994489\n",
      "    mean_inference_ms: 1.577769671334896\n",
      "    mean_raw_obs_processing_ms: 0.4232036296204934\n",
      "  time_since_restore: 974.8061044216156\n",
      "  time_this_iter_s: 13.978209733963013\n",
      "  time_total_s: 974.8061044216156\n",
      "  timers:\n",
      "    learn_throughput: 3803.419\n",
      "    learn_time_ms: 8.413\n",
      "    load_throughput: 65876.965\n",
      "    load_time_ms: 0.486\n",
      "    update_time_ms: 1.659\n",
      "  timestamp: 1632002401\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 64000\n",
      "  training_iteration: 64\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         974.806</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-1.51562</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           990.031</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 65000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-00-16\n",
      "  done: false\n",
      "  episode_len_mean: 990.1846153846154\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -1.4615384615384615\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 65\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 64504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.329339027404785\n",
      "          mean_q: 4.293850898742676\n",
      "          min_q: 2.4180383682250977\n",
      "        mean_td_error: -0.14731339365243912\n",
      "        td_error: \"[-1.07239819  0.5168581   0.00917768 -1.07365274  0.01448035  2.53936672\\n\\\n",
      "          \\  0.16014528  0.03563118 -0.02455091  0.48967075 -0.5465889  -0.0724535\\n\\\n",
      "          \\ -0.99481058 -0.0872035   0.01330876 -0.98677301 -0.04337621 -0.11386156\\n\\\n",
      "          \\  0.38207793  0.22513008 -0.461339   -0.01283813 -1.15834951 -0.03435922\\n\\\n",
      "          \\ -0.05378985 -0.04080129 -1.2317524  -0.43464756 -0.09710169  0.0173955\\n\\\n",
      "          \\  0.62762332 -1.20424652]\"\n",
      "    num_agent_steps_sampled: 65000\n",
      "    num_agent_steps_trained: 512032\n",
      "    num_steps_sampled: 65000\n",
      "    num_steps_trained: 512032\n",
      "    num_target_updates: 127\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.41904761904762\n",
      "    ram_util_percent: 91.87619047619047\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04005677823645284\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 12.006179485655835\n",
      "    mean_inference_ms: 1.577578871042835\n",
      "    mean_raw_obs_processing_ms: 0.43318540590038795\n",
      "  time_since_restore: 989.020271062851\n",
      "  time_this_iter_s: 14.214166641235352\n",
      "  time_total_s: 989.020271062851\n",
      "  timers:\n",
      "    learn_throughput: 3792.05\n",
      "    learn_time_ms: 8.439\n",
      "    load_throughput: 66589.466\n",
      "    load_time_ms: 0.481\n",
      "    update_time_ms: 1.647\n",
      "  timestamp: 1632002416\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 65000\n",
      "  training_iteration: 65\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">          989.02</td><td style=\"text-align: right;\">65000</td><td style=\"text-align: right;\">-1.46154</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           990.185</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 66000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-00-29\n",
      "  done: false\n",
      "  episode_len_mean: 990.3333333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -1.4393939393939394\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 66\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 65512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 18.16692352294922\n",
      "          mean_q: 4.952970504760742\n",
      "          min_q: 2.4833438396453857\n",
      "        mean_td_error: 0.2152150273323059\n",
      "        td_error: \"[ 0.16017103  0.29136992 -0.1540122   0.16509151  0.10822153  0.09312963\\n\\\n",
      "          \\  0.0995698   0.7150042  -0.00863791  0.0243063   0.01051283  1.5032148\\n\\\n",
      "          \\  0.0567627   1.1845493  -0.2854247  -0.2845831   0.4155531   0.03628063\\n\\\n",
      "          \\  0.00615692  0.4778719   0.60755014  0.41078424  0.24824429 -1.2285995\\n\\\n",
      "          \\  1.3737953   0.28747654 -0.00605512  0.06075573  0.02707624 -0.22531796\\n\\\n",
      "          \\  0.5882325   0.12783003]\"\n",
      "    num_agent_steps_sampled: 66000\n",
      "    num_agent_steps_trained: 520032\n",
      "    num_steps_sampled: 66000\n",
      "    num_steps_trained: 520032\n",
      "    num_target_updates: 129\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.41578947368421\n",
      "    ram_util_percent: 91.75263157894737\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04005261379294371\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.95449017257309\n",
      "    mean_inference_ms: 1.577390387744667\n",
      "    mean_raw_obs_processing_ms: 0.4426555828811771\n",
      "  time_since_restore: 1002.6758420467377\n",
      "  time_this_iter_s: 13.655570983886719\n",
      "  time_total_s: 1002.6758420467377\n",
      "  timers:\n",
      "    learn_throughput: 3822.745\n",
      "    learn_time_ms: 8.371\n",
      "    load_throughput: 65116.305\n",
      "    load_time_ms: 0.491\n",
      "    update_time_ms: 1.659\n",
      "  timestamp: 1632002429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 66000\n",
      "  training_iteration: 66\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         1002.68</td><td style=\"text-align: right;\">66000</td><td style=\"text-align: right;\">-1.43939</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           990.333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 67000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-00-43\n",
      "  done: false\n",
      "  episode_len_mean: 990.4776119402985\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -1.4328358208955223\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 67\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 66520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.19794750213623\n",
      "          mean_q: 4.131077766418457\n",
      "          min_q: 2.447491407394409\n",
      "        mean_td_error: -0.004957854747772217\n",
      "        td_error: \"[-0.70179987 -0.12657857  0.00831604 -0.17697477 -0.24152136 -0.03021312\\n\\\n",
      "          \\ -0.0797348  -0.3473904   0.00752258  0.8787141  -0.13655329 -0.32021904\\n\\\n",
      "          \\ -0.0084424   0.02852106 -0.38126326 -0.05422831 -0.05110931  0.1997881\\n\\\n",
      "          \\ -0.01125431  1.076406   -0.01611471 -0.2252307  -0.4181862   0.63893175\\n\\\n",
      "          \\ -0.11619806  0.08503938  0.25990343 -0.05462956  0.13795543  0.06658602\\n\\\n",
      "          \\  0.14480782 -0.193501  ]\"\n",
      "    num_agent_steps_sampled: 67000\n",
      "    num_agent_steps_trained: 528032\n",
      "    num_steps_sampled: 67000\n",
      "    num_steps_trained: 528032\n",
      "    num_target_updates: 131\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.885\n",
      "    ram_util_percent: 91.73500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04004864230776428\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.904222126340688\n",
      "    mean_inference_ms: 1.5772064434384148\n",
      "    mean_raw_obs_processing_ms: 0.4516469504841209\n",
      "  time_since_restore: 1016.4918134212494\n",
      "  time_this_iter_s: 13.815971374511719\n",
      "  time_total_s: 1016.4918134212494\n",
      "  timers:\n",
      "    learn_throughput: 3849.288\n",
      "    learn_time_ms: 8.313\n",
      "    load_throughput: 66619.213\n",
      "    load_time_ms: 0.48\n",
      "    update_time_ms: 1.629\n",
      "  timestamp: 1632002443\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 67000\n",
      "  training_iteration: 67\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         1016.49</td><td style=\"text-align: right;\">67000</td><td style=\"text-align: right;\">-1.43284</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           990.478</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-01-44\n",
      "  done: false\n",
      "  episode_len_mean: 978.7246376811594\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.3333333333333333\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 69\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 67528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.205183982849121\n",
      "          mean_q: 4.9590654373168945\n",
      "          min_q: 2.48298978805542\n",
      "        mean_td_error: 0.1047329232096672\n",
      "        td_error: \"[-0.08673239  0.6913266   0.30007792  0.17911243 -0.68612576 -1.0760727\\n\\\n",
      "          \\  0.15078783 -0.18017817  0.13332987  0.03558779  0.12012148 -0.02492929\\n\\\n",
      "          \\ -0.11976004  0.04170299  0.04379535 -0.24695873 -0.3240013   0.23548603\\n\\\n",
      "          \\  0.10184288  0.73225355  0.06989813  0.81827736 -0.50031567  0.05816078\\n\\\n",
      "          \\ -0.8970356   0.35631657  1.9844685   0.01554942  1.1326535   0.11786699\\n\\\n",
      "          \\  0.11235213  0.06259537]\"\n",
      "    num_agent_steps_sampled: 68000\n",
      "    num_agent_steps_trained: 536032\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 536032\n",
      "    num_target_updates: 133\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.333720930232563\n",
      "    ram_util_percent: 91.76279069767442\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04004121594666058\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.80781179596519\n",
      "    mean_inference_ms: 1.576858382400179\n",
      "    mean_raw_obs_processing_ms: 0.48841483128349517\n",
      "  time_since_restore: 1077.0855283737183\n",
      "  time_this_iter_s: 60.59371495246887\n",
      "  time_total_s: 1077.0855283737183\n",
      "  timers:\n",
      "    learn_throughput: 3792.683\n",
      "    learn_time_ms: 8.437\n",
      "    load_throughput: 65125.784\n",
      "    load_time_ms: 0.491\n",
      "    update_time_ms: 1.676\n",
      "  timestamp: 1632002504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 68\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         1077.09</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-1.33333</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           978.725</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 69000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-01-58\n",
      "  done: false\n",
      "  episode_len_mean: 979.0285714285715\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.3714285714285714\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 70\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 68536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 19.449647903442383\n",
      "          mean_q: 6.038233757019043\n",
      "          min_q: 2.718777656555176\n",
      "        mean_td_error: 0.028082631528377533\n",
      "        td_error: \"[ 0.23510695 -0.02306795  0.16398191 -0.3264644  -0.06555843 -0.28949833\\n\\\n",
      "          \\  0.25608826  0.40603447  0.17667818 -0.7242222  -0.5612869   0.49290562\\n\\\n",
      "          \\  0.43706656  0.02569675  3.180894   -0.24836731  0.25179052 -0.11531377\\n\\\n",
      "          \\  0.27270365  0.17814898  0.30572224 -0.3159175   0.5764661  -0.36933136\\n\\\n",
      "          \\ -0.13153124  0.69564533  0.12290907 -0.24171066 -0.4879217   0.12765169\\n\\\n",
      "          \\ -3.6268787   0.5202246 ]\"\n",
      "    num_agent_steps_sampled: 69000\n",
      "    num_agent_steps_trained: 544032\n",
      "    num_steps_sampled: 69000\n",
      "    num_steps_trained: 544032\n",
      "    num_target_updates: 135\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.37619047619047\n",
      "    ram_util_percent: 91.9\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040037650373577316\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.761723767068503\n",
      "    mean_inference_ms: 1.5766894916017389\n",
      "    mean_raw_obs_processing_ms: 0.5056877547713997\n",
      "  time_since_restore: 1091.6544907093048\n",
      "  time_this_iter_s: 14.568962335586548\n",
      "  time_total_s: 1091.6544907093048\n",
      "  timers:\n",
      "    learn_throughput: 3786.082\n",
      "    learn_time_ms: 8.452\n",
      "    load_throughput: 59790.506\n",
      "    load_time_ms: 0.535\n",
      "    update_time_ms: 1.676\n",
      "  timestamp: 1632002518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69000\n",
      "  training_iteration: 69\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         1091.65</td><td style=\"text-align: right;\">69000</td><td style=\"text-align: right;\">-1.37143</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           979.029</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 70000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-02-12\n",
      "  done: false\n",
      "  episode_len_mean: 979.3239436619718\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.380281690140845\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 71\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 69544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.939074516296387\n",
      "          mean_q: 4.623848915100098\n",
      "          min_q: 2.5794551372528076\n",
      "        mean_td_error: -0.015597417950630188\n",
      "        td_error: \"[-3.7520790e-01  1.0073519e-01  1.1395073e+00 -1.7094660e-01\\n -1.5666676e-01\\\n",
      "          \\ -2.8897953e-01  3.5005689e-01  3.4293365e-01\\n -4.8599720e-02  1.0025148e+00\\\n",
      "          \\ -2.1834850e-02 -4.3557644e-02\\n -1.6716580e+00 -1.0881853e-01  4.3885374e-01\\\n",
      "          \\  2.7400041e-01\\n  3.4509039e-01 -2.1813583e-01 -2.8838634e-01 -1.6630745e-01\\n\\\n",
      "          \\ -2.8578210e-01  6.9404745e-01  1.7151117e-02 -8.2962513e-03\\n -8.3602428e-02\\\n",
      "          \\  8.7932110e-02 -2.3094654e-02  2.6391983e-02\\n -2.0438519e+00  7.3114300e-01\\\n",
      "          \\ -4.3934107e-02 -1.8148422e-03]\"\n",
      "    num_agent_steps_sampled: 70000\n",
      "    num_agent_steps_trained: 552032\n",
      "    num_steps_sampled: 70000\n",
      "    num_steps_trained: 552032\n",
      "    num_target_updates: 137\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.765\n",
      "    ram_util_percent: 91.96500000000002\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04003420235635585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.716785634853167\n",
      "    mean_inference_ms: 1.57652400695788\n",
      "    mean_raw_obs_processing_ms: 0.5221641745879808\n",
      "  time_since_restore: 1105.2457330226898\n",
      "  time_this_iter_s: 13.59124231338501\n",
      "  time_total_s: 1105.2457330226898\n",
      "  timers:\n",
      "    learn_throughput: 3826.254\n",
      "    learn_time_ms: 8.363\n",
      "    load_throughput: 66735.147\n",
      "    load_time_ms: 0.48\n",
      "    update_time_ms: 1.616\n",
      "  timestamp: 1632002532\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 70000\n",
      "  training_iteration: 70\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         1105.25</td><td style=\"text-align: right;\">70000</td><td style=\"text-align: right;\">-1.38028</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           979.324</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 71000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-02-25\n",
      "  done: false\n",
      "  episode_len_mean: 979.6111111111111\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.3611111111111112\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 72\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 70552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.493847846984863\n",
      "          mean_q: 4.715361595153809\n",
      "          min_q: 3.7028417587280273\n",
      "        mean_td_error: 0.1387886255979538\n",
      "        td_error: \"[ 0.00876975  0.0199728  -0.08423519 -0.30845642  0.02317429 -0.09072256\\n\\\n",
      "          \\  0.62185526  0.07110929 -0.16098452 -0.04862976 -0.25106    -0.31412077\\n\\\n",
      "          \\ -0.05299091 -0.07395649  1.8253608   0.5649195   0.17890787  0.19851494\\n\\\n",
      "          \\ -0.2589259   0.43614388 -0.14294004  0.8844366   0.5160661  -0.1207118\\n\\\n",
      "          \\  0.522037    0.84241366 -0.03381491  0.05311871 -0.16487217 -0.00367641\\n\\\n",
      "          \\ -0.08284402 -0.13262248]\"\n",
      "    num_agent_steps_sampled: 71000\n",
      "    num_agent_steps_trained: 560032\n",
      "    num_steps_sampled: 71000\n",
      "    num_steps_trained: 560032\n",
      "    num_target_updates: 139\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.38947368421053\n",
      "    ram_util_percent: 91.93684210526317\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040030838258527414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.672951025860009\n",
      "    mean_inference_ms: 1.57635955335423\n",
      "    mean_raw_obs_processing_ms: 0.5378850012756815\n",
      "  time_since_restore: 1118.7770295143127\n",
      "  time_this_iter_s: 13.531296491622925\n",
      "  time_total_s: 1118.7770295143127\n",
      "  timers:\n",
      "    learn_throughput: 3832.394\n",
      "    learn_time_ms: 8.35\n",
      "    load_throughput: 65990.328\n",
      "    load_time_ms: 0.485\n",
      "    update_time_ms: 1.617\n",
      "  timestamp: 1632002545\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 71000\n",
      "  training_iteration: 71\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         1118.78</td><td style=\"text-align: right;\">71000</td><td style=\"text-align: right;\">-1.36111</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           979.611</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 72000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-02-39\n",
      "  done: false\n",
      "  episode_len_mean: 979.8904109589041\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.3835616438356164\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 73\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 71560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.141707897186279\n",
      "          mean_q: 4.9756059646606445\n",
      "          min_q: 3.6586272716522217\n",
      "        mean_td_error: 0.05674386024475098\n",
      "        td_error: \"[-6.9659710e-02  8.5935116e-02  5.4047108e-02 -2.4660110e-02\\n -1.0445118e-02\\\n",
      "          \\ -1.1315842e+00 -4.2255497e-01 -1.8472672e-03\\n  1.3814459e+00  1.4962482e-01\\\n",
      "          \\ -5.0170755e-01 -1.2704563e-01\\n -2.2862101e-01 -2.1573544e-02 -2.4791670e-01\\\n",
      "          \\  5.0579119e-01\\n  2.2155235e+00  3.3455849e-02 -2.7238512e-01  1.9457269e-01\\n\\\n",
      "          \\  4.4321728e-01 -2.0658016e-01  7.9237461e-02  4.2076278e-01\\n -1.7106056e-02\\\n",
      "          \\  3.6420822e-03 -2.2610903e-02  2.3754835e-01\\n -9.7095537e-01  1.0565519e-01\\\n",
      "          \\  1.9517565e-01 -1.2578011e-02]\"\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 568032\n",
      "    num_steps_sampled: 72000\n",
      "    num_steps_trained: 568032\n",
      "    num_target_updates: 141\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.28947368421053\n",
      "    ram_util_percent: 91.93157894736841\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04002758090250388\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.63016373294546\n",
      "    mean_inference_ms: 1.576196935693618\n",
      "    mean_raw_obs_processing_ms: 0.5528917190219301\n",
      "  time_since_restore: 1132.2732124328613\n",
      "  time_this_iter_s: 13.496182918548584\n",
      "  time_total_s: 1132.2732124328613\n",
      "  timers:\n",
      "    learn_throughput: 3776.77\n",
      "    learn_time_ms: 8.473\n",
      "    load_throughput: 66589.466\n",
      "    load_time_ms: 0.481\n",
      "    update_time_ms: 1.638\n",
      "  timestamp: 1632002559\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 72000\n",
      "  training_iteration: 72\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         1132.27</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">-1.38356</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            979.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 73000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-02-52\n",
      "  done: false\n",
      "  episode_len_mean: 980.1621621621622\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.3783783783783783\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 74\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 72568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.384367942810059\n",
      "          mean_q: 4.678645610809326\n",
      "          min_q: 3.564659357070923\n",
      "        mean_td_error: 0.08580169826745987\n",
      "        td_error: \"[-0.37671185  0.46312332  0.04322863  0.27580023  0.11349392  0.11376143\\n\\\n",
      "          \\ -0.26273012  0.03103876  0.14038754  0.07682753 -0.02802896 -0.16460276\\n\\\n",
      "          \\ -0.02998352 -0.32838488  0.1392746   0.08012867  0.10872316 -0.2009635\\n\\\n",
      "          \\  0.12749958  0.11210299  1.3128505   0.19913006  0.20490599  0.19678307\\n\\\n",
      "          \\  0.07157683  0.02951384  0.2974429  -0.10805893 -0.43713188  0.3550377\\n\\\n",
      "          \\  0.34430218 -0.15468264]\"\n",
      "    num_agent_steps_sampled: 73000\n",
      "    num_agent_steps_trained: 576032\n",
      "    num_steps_sampled: 73000\n",
      "    num_steps_trained: 576032\n",
      "    num_target_updates: 143\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.43157894736842\n",
      "    ram_util_percent: 91.87894736842105\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04002439723257081\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.588325718487656\n",
      "    mean_inference_ms: 1.5760362506470915\n",
      "    mean_raw_obs_processing_ms: 0.5672207074625358\n",
      "  time_since_restore: 1145.4273221492767\n",
      "  time_this_iter_s: 13.154109716415405\n",
      "  time_total_s: 1145.4273221492767\n",
      "  timers:\n",
      "    learn_throughput: 3755.939\n",
      "    learn_time_ms: 8.52\n",
      "    load_throughput: 60349.698\n",
      "    load_time_ms: 0.53\n",
      "    update_time_ms: 1.64\n",
      "  timestamp: 1632002572\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 73000\n",
      "  training_iteration: 73\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         1145.43</td><td style=\"text-align: right;\">73000</td><td style=\"text-align: right;\">-1.37838</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           980.162</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 74000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-03-05\n",
      "  done: false\n",
      "  episode_len_mean: 980.4266666666666\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.36\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 75\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 73576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 13.869475364685059\n",
      "          mean_q: 5.429533958435059\n",
      "          min_q: 3.575193166732788\n",
      "        mean_td_error: -0.08233945816755295\n",
      "        td_error: \"[ 0.05362082  0.4168601   0.04468966  0.39814138  0.10251665  0.01419592\\n\\\n",
      "          \\  0.00975466 -0.07482576 -0.03859234 -0.2888298  -0.2932148  -0.27590752\\n\\\n",
      "          \\ -1.0341134  -0.15876389  0.7359803   0.12960911  0.15269566  0.04677582\\n\\\n",
      "          \\  0.08366632 -0.19501305 -0.10830975  0.11048555  0.10691404  0.03028297\\n\\\n",
      "          \\ -1.7972193  -0.11293221  0.14227104  0.2677822  -0.07361841  0.07247829\\n\\\n",
      "          \\ -0.9774513  -0.12479162]\"\n",
      "    num_agent_steps_sampled: 74000\n",
      "    num_agent_steps_trained: 584032\n",
      "    num_steps_sampled: 74000\n",
      "    num_steps_trained: 584032\n",
      "    num_target_updates: 145\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.46842105263158\n",
      "    ram_util_percent: 91.80526315789473\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04002121071076366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.547403796040234\n",
      "    mean_inference_ms: 1.575876971253908\n",
      "    mean_raw_obs_processing_ms: 0.5809041416561826\n",
      "  time_since_restore: 1158.605891942978\n",
      "  time_this_iter_s: 13.178569793701172\n",
      "  time_total_s: 1158.605891942978\n",
      "  timers:\n",
      "    learn_throughput: 3774.72\n",
      "    learn_time_ms: 8.477\n",
      "    load_throughput: 65818.815\n",
      "    load_time_ms: 0.486\n",
      "    update_time_ms: 1.664\n",
      "  timestamp: 1632002585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 74000\n",
      "  training_iteration: 74\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         1158.61</td><td style=\"text-align: right;\">74000</td><td style=\"text-align: right;\">   -1.36</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           980.427</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 75000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-04-03\n",
      "  done: false\n",
      "  episode_len_mean: 974.8421052631579\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.3421052631578947\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 76\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 74584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 9.3316650390625\n",
      "          mean_q: 5.086091995239258\n",
      "          min_q: 4.079010963439941\n",
      "        mean_td_error: -0.036798372864723206\n",
      "        td_error: \"[-3.48864555e-01  8.16211700e-01 -1.35403156e-01 -1.17522717e-01\\n\\\n",
      "          \\ -9.63006020e-02 -2.39575863e-01 -1.53174877e-01 -6.33630753e-02\\n -3.44028473e-02\\\n",
      "          \\ -3.60059738e-02  4.07901096e+00  1.29604340e-03\\n -6.44143105e-01 -5.31311989e-01\\\n",
      "          \\ -1.63933754e-01 -1.58757687e-01\\n -5.88685036e-01 -6.24891281e-01 -7.21101761e-02\\\n",
      "          \\ -5.63769341e-02\\n -6.85715675e-02  3.69911194e-02 -8.61678123e-01 -5.78052521e-01\\n\\\n",
      "          \\ -3.49015236e-01  6.75442696e-01 -1.41548634e-01 -2.74915218e-01\\n  1.18708611e-02\\\n",
      "          \\ -2.40028858e-01 -9.95812416e-02 -1.20156288e-01]\"\n",
      "    num_agent_steps_sampled: 75000\n",
      "    num_agent_steps_trained: 592032\n",
      "    num_steps_sampled: 75000\n",
      "    num_steps_trained: 592032\n",
      "    num_target_updates: 147\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.76829268292683\n",
      "    ram_util_percent: 91.80975609756096\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040018105949401445\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.507434853766568\n",
      "    mean_inference_ms: 1.5757197367571405\n",
      "    mean_raw_obs_processing_ms: 0.6017050383299481\n",
      "  time_since_restore: 1216.2115771770477\n",
      "  time_this_iter_s: 57.605685234069824\n",
      "  time_total_s: 1216.2115771770477\n",
      "  timers:\n",
      "    learn_throughput: 3803.096\n",
      "    learn_time_ms: 8.414\n",
      "    load_throughput: 65382.759\n",
      "    load_time_ms: 0.489\n",
      "    update_time_ms: 1.679\n",
      "  timestamp: 1632002643\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 75000\n",
      "  training_iteration: 75\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         1216.21</td><td style=\"text-align: right;\">75000</td><td style=\"text-align: right;\">-1.34211</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           974.842</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 76000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-04-16\n",
      "  done: false\n",
      "  episode_len_mean: 975.1688311688312\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.3636363636363635\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 77\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 75592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 9.72753620147705\n",
      "          mean_q: 5.459682464599609\n",
      "          min_q: 3.9012417793273926\n",
      "        mean_td_error: 0.007896468043327332\n",
      "        td_error: \"[ 0.30241156 -0.13912201 -1.6911564  -0.74585724  0.0873332  -0.06467819\\n\\\n",
      "          \\ -0.01604605 -0.2829671  -0.01056194  0.01828909 -0.16204739  0.10104084\\n\\\n",
      "          \\  0.31103897 -0.08339453  0.37299252 -0.01904917  0.07213783  0.02935886\\n\\\n",
      "          \\  0.21063232 -0.1679492   0.23936558 -0.15199566  0.24187851  0.04174423\\n\\\n",
      "          \\ -0.07491922  1.3246608   0.014153    0.08548737  0.15563774  0.3836851\\n\\\n",
      "          \\ -0.10159779 -0.02781868]\"\n",
      "    num_agent_steps_sampled: 76000\n",
      "    num_agent_steps_trained: 600032\n",
      "    num_steps_sampled: 76000\n",
      "    num_steps_trained: 600032\n",
      "    num_target_updates: 149\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.66315789473684\n",
      "    ram_util_percent: 92.44736842105264\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04001505243958754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.468375728787143\n",
      "    mean_inference_ms: 1.5755640370818014\n",
      "    mean_raw_obs_processing_ms: 0.6216231090692942\n",
      "  time_since_restore: 1229.7014479637146\n",
      "  time_this_iter_s: 13.48987078666687\n",
      "  time_total_s: 1229.7014479637146\n",
      "  timers:\n",
      "    learn_throughput: 3832.909\n",
      "    learn_time_ms: 8.349\n",
      "    load_throughput: 66237.836\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.648\n",
      "  timestamp: 1632002656\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 76\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">          1229.7</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-1.36364</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           975.169</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 77000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-04-30\n",
      "  done: false\n",
      "  episode_len_mean: 975.4871794871794\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.435897435897436\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 78\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 76600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.666291236877441\n",
      "          mean_q: 4.878495216369629\n",
      "          min_q: 3.9909725189208984\n",
      "        mean_td_error: 0.08551079779863358\n",
      "        td_error: \"[ 0.07304478  0.01241493  0.22065163  0.02516127 -0.07490158 -0.02698374\\n\\\n",
      "          \\  0.06401873  0.79779434  0.1181469   0.00655842  0.61131406 -0.85917616\\n\\\n",
      "          \\  0.77688026 -0.01812029  0.72464132 -0.06075764  0.19581652 -0.00195217\\n\\\n",
      "          \\ -0.14057684  0.18287468  1.08182049  0.02194977  0.01120853 -0.24968338\\n\\\n",
      "          \\ -0.11933851 -0.27468538 -0.0875926  -0.07162666 -0.26453209 -0.03692436\\n\\\n",
      "          \\  0.15240765 -0.05350733]\"\n",
      "    num_agent_steps_sampled: 77000\n",
      "    num_agent_steps_trained: 608032\n",
      "    num_steps_sampled: 77000\n",
      "    num_steps_trained: 608032\n",
      "    num_target_updates: 151\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.62500000000001\n",
      "    ram_util_percent: 92.49000000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04001224855631163\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.430242586225761\n",
      "    mean_inference_ms: 1.5754140393580742\n",
      "    mean_raw_obs_processing_ms: 0.6407044785570616\n",
      "  time_since_restore: 1243.6022148132324\n",
      "  time_this_iter_s: 13.900766849517822\n",
      "  time_total_s: 1243.6022148132324\n",
      "  timers:\n",
      "    learn_throughput: 3559.727\n",
      "    learn_time_ms: 8.989\n",
      "    load_throughput: 42989.567\n",
      "    load_time_ms: 0.744\n",
      "    update_time_ms: 1.873\n",
      "  timestamp: 1632002670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 77000\n",
      "  training_iteration: 77\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">          1243.6</td><td style=\"text-align: right;\">77000</td><td style=\"text-align: right;\"> -1.4359</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           975.487</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 78000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-04-45\n",
      "  done: false\n",
      "  episode_len_mean: 975.7974683544304\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.481012658227848\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 79\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 77608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 10.096378326416016\n",
      "          mean_q: 5.285458087921143\n",
      "          min_q: 4.096090793609619\n",
      "        mean_td_error: 0.06275033950805664\n",
      "        td_error: \"[-0.08715725  0.27012157 -0.16808987 -1.0034833  -0.06840849  0.07250309\\n\\\n",
      "          \\ -0.23974037  1.04884    -0.4981842  -0.15671349  0.05695343 -0.10464859\\n\\\n",
      "          \\ -0.33852577  0.35705233  0.01841021  0.02005672 -0.16369867  0.2794466\\n\\\n",
      "          \\ -0.16505527 -1.3570642  -0.02960253  0.6201229   0.05843306 -0.01018715\\n\\\n",
      "          \\  1.8030586   0.02185535 -0.41732645  1.7670116  -0.4475484   0.14601707\\n\\\n",
      "          \\ -0.01711273  0.740675  ]\"\n",
      "    num_agent_steps_sampled: 78000\n",
      "    num_agent_steps_trained: 616032\n",
      "    num_steps_sampled: 78000\n",
      "    num_steps_trained: 616032\n",
      "    num_target_updates: 153\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.042857142857144\n",
      "    ram_util_percent: 92.17142857142856\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0400096848160571\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.393084733428019\n",
      "    mean_inference_ms: 1.5752739863145797\n",
      "    mean_raw_obs_processing_ms: 0.6589877485847796\n",
      "  time_since_restore: 1258.1183714866638\n",
      "  time_this_iter_s: 14.516156673431396\n",
      "  time_total_s: 1258.1183714866638\n",
      "  timers:\n",
      "    learn_throughput: 3774.975\n",
      "    learn_time_ms: 8.477\n",
      "    load_throughput: 65555.206\n",
      "    load_time_ms: 0.488\n",
      "    update_time_ms: 1.657\n",
      "  timestamp: 1632002685\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 78000\n",
      "  training_iteration: 78\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         1258.12</td><td style=\"text-align: right;\">78000</td><td style=\"text-align: right;\">-1.48101</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           975.797</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 79000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-04-59\n",
      "  done: false\n",
      "  episode_len_mean: 976.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.5375\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 80\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 78616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.04141902923584\n",
      "          mean_q: 5.209404945373535\n",
      "          min_q: 3.8424580097198486\n",
      "        mean_td_error: -0.1394321620464325\n",
      "        td_error: \"[ 0.03987837 -1.7982445   0.09568667  0.02727652  0.00874329  0.33218622\\n\\\n",
      "          \\ -0.04227591 -0.02084303  0.09300613 -0.04793453 -0.1473136  -0.08823729\\n\\\n",
      "          \\  0.4290514   0.13245153 -1.2551026   0.02434444 -0.1421647   0.13038158\\n\\\n",
      "          \\  0.05952072 -0.44691133 -0.25656652 -0.09736252 -1.0663033  -0.2975688\\n\\\n",
      "          \\  0.01336098  0.7149019  -0.0137167  -0.47608566 -0.00615072 -0.32777977\\n\\\n",
      "          \\ -0.1023283   0.07027102]\"\n",
      "    num_agent_steps_sampled: 79000\n",
      "    num_agent_steps_trained: 624032\n",
      "    num_steps_sampled: 79000\n",
      "    num_steps_trained: 624032\n",
      "    num_target_updates: 155\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.309999999999995\n",
      "    ram_util_percent: 91.805\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040007157516167235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.35683074227268\n",
      "    mean_inference_ms: 1.5751360034689585\n",
      "    mean_raw_obs_processing_ms: 0.6765116124939442\n",
      "  time_since_restore: 1272.2358484268188\n",
      "  time_this_iter_s: 14.11747694015503\n",
      "  time_total_s: 1272.2358484268188\n",
      "  timers:\n",
      "    learn_throughput: 3797.92\n",
      "    learn_time_ms: 8.426\n",
      "    load_throughput: 66701.982\n",
      "    load_time_ms: 0.48\n",
      "    update_time_ms: 1.694\n",
      "  timestamp: 1632002699\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79000\n",
      "  training_iteration: 79\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         1272.24</td><td style=\"text-align: right;\">79000</td><td style=\"text-align: right;\"> -1.5375</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">             976.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 80000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-05-13\n",
      "  done: false\n",
      "  episode_len_mean: 976.395061728395\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6049382716049383\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 81\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 79624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 10.961960792541504\n",
      "          mean_q: 5.044727802276611\n",
      "          min_q: 3.7715983390808105\n",
      "        mean_td_error: 0.12077904492616653\n",
      "        td_error: \"[ 0.22200966  0.17058945 -0.03951645  0.05237198  0.1417551   0.09397745\\n\\\n",
      "          \\ -0.115026    1.0333796   0.24688101  0.07289362  0.19497013  0.29270792\\n\\\n",
      "          \\  0.02717829  0.20905113 -0.41639376 -0.0612607  -0.12194252  0.3076067\\n\\\n",
      "          \\ -0.23724699  0.01359034 -0.23556328 -0.13635254  0.92792964  0.01809597\\n\\\n",
      "          \\ -0.09600449  0.362741    0.70357656  0.50279427  0.12265778 -0.13953209\\n\\\n",
      "          \\  0.03989029 -0.29287958]\"\n",
      "    num_agent_steps_sampled: 80000\n",
      "    num_agent_steps_trained: 632032\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 632032\n",
      "    num_target_updates: 157\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.65\n",
      "    ram_util_percent: 91.73500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04000464693125309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.321413792805304\n",
      "    mean_inference_ms: 1.5750001254230566\n",
      "    mean_raw_obs_processing_ms: 0.6933095617611904\n",
      "  time_since_restore: 1286.0922303199768\n",
      "  time_this_iter_s: 13.856381893157959\n",
      "  time_total_s: 1286.0922303199768\n",
      "  timers:\n",
      "    learn_throughput: 3778.567\n",
      "    learn_time_ms: 8.469\n",
      "    load_throughput: 66237.836\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.645\n",
      "  timestamp: 1632002713\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 80\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         1286.09</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">-1.60494</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           976.395</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 81000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-05-26\n",
      "  done: false\n",
      "  episode_len_mean: 976.6829268292682\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.5975609756097562\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 82\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 80632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 9.423652648925781\n",
      "          mean_q: 5.280673027038574\n",
      "          min_q: 3.800093650817871\n",
      "        mean_td_error: 0.06217319518327713\n",
      "        td_error: \"[-0.18367958 -0.02014542 -0.17285585  0.0032177   0.5757017   0.02795649\\n\\\n",
      "          \\  0.53799486  1.0192566   0.39026165  0.04854918 -0.01270866 -0.13746929\\n\\\n",
      "          \\ -0.20625353 -0.02974415  0.34877205  0.04923964  0.23338223 -0.21770024\\n\\\n",
      "          \\ -0.02473068 -0.01448059 -0.9135437  -0.29598284 -0.08177614  0.4234085\\n\\\n",
      "          \\  0.33624554 -0.5351     -0.05980873  0.43236685  0.8679919   0.10224628\\n\\\n",
      "          \\ -0.10688162 -0.39418793]\"\n",
      "    num_agent_steps_sampled: 81000\n",
      "    num_agent_steps_trained: 640032\n",
      "    num_steps_sampled: 81000\n",
      "    num_steps_trained: 640032\n",
      "    num_target_updates: 159\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.68421052631579\n",
      "    ram_util_percent: 91.78947368421053\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04000222014962349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.286738156214422\n",
      "    mean_inference_ms: 1.574866516236865\n",
      "    mean_raw_obs_processing_ms: 0.7094150145875644\n",
      "  time_since_restore: 1299.4994263648987\n",
      "  time_this_iter_s: 13.407196044921875\n",
      "  time_total_s: 1299.4994263648987\n",
      "  timers:\n",
      "    learn_throughput: 3810.838\n",
      "    learn_time_ms: 8.397\n",
      "    load_throughput: 65664.25\n",
      "    load_time_ms: 0.487\n",
      "    update_time_ms: 1.661\n",
      "  timestamp: 1632002726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 81000\n",
      "  training_iteration: 81\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">          1299.5</td><td style=\"text-align: right;\">81000</td><td style=\"text-align: right;\">-1.59756</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           976.683</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 82000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-05-40\n",
      "  done: false\n",
      "  episode_len_mean: 976.9638554216867\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6024096385542168\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 83\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 81640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.5795698165893555\n",
      "          mean_q: 4.887807846069336\n",
      "          min_q: 3.692876100540161\n",
      "        mean_td_error: 0.3079577088356018\n",
      "        td_error: \"[-0.26141119  0.05470371 -0.1753974   0.09487867  0.32427406  0.02492428\\n\\\n",
      "          \\  0.56195521 -0.66763544  0.36764431  0.14032936 -0.14159489  0.61247969\\n\\\n",
      "          \\  4.19196224  0.0968585   0.07663393  0.01883602  0.03897619  1.02238941\\n\\\n",
      "          \\  0.08818579 -0.30791759 -0.48345709  0.04832077 -0.06423855  0.0519948\\n\\\n",
      "          \\  0.23393631  0.12506008  0.11964273  0.12581491  0.11075687  3.6928761\\n\\\n",
      "          \\  0.04355288 -0.31068802]\"\n",
      "    num_agent_steps_sampled: 82000\n",
      "    num_agent_steps_trained: 648032\n",
      "    num_steps_sampled: 82000\n",
      "    num_steps_trained: 648032\n",
      "    num_target_updates: 161\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.375\n",
      "    ram_util_percent: 91.735\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03999979106721083\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.252831501221715\n",
      "    mean_inference_ms: 1.5747338543235174\n",
      "    mean_raw_obs_processing_ms: 0.7248601313601949\n",
      "  time_since_restore: 1313.224487066269\n",
      "  time_this_iter_s: 13.72506070137024\n",
      "  time_total_s: 1313.224487066269\n",
      "  timers:\n",
      "    learn_throughput: 3786.776\n",
      "    learn_time_ms: 8.45\n",
      "    load_throughput: 66539.947\n",
      "    load_time_ms: 0.481\n",
      "    update_time_ms: 1.676\n",
      "  timestamp: 1632002740\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 82000\n",
      "  training_iteration: 82\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         1313.22</td><td style=\"text-align: right;\">82000</td><td style=\"text-align: right;\">-1.60241</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           976.964</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 83000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-05-54\n",
      "  done: false\n",
      "  episode_len_mean: 977.2380952380952\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6071428571428572\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 84\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 82648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.070055961608887\n",
      "          mean_q: 5.125551223754883\n",
      "          min_q: 3.9132354259490967\n",
      "        mean_td_error: -0.010079711675643921\n",
      "        td_error: \"[ 0.15291643 -0.01657057 -0.01295471  0.2625451   0.31207848  0.09876871\\n\\\n",
      "          \\  0.24383545  0.11523008  0.23648214  0.014956    0.05295277  0.02761889\\n\\\n",
      "          \\  0.01199293 -0.08328772 -0.4196577  -0.76366425 -0.09712791  0.04011106\\n\\\n",
      "          \\  0.12976599 -0.08596468  0.10480547  0.00337076  0.1002264   0.09862804\\n\\\n",
      "          \\  0.79832506  0.23434639  0.19220161  0.25046158 -1.1622868   0.1694212\\n\\\n",
      "          \\ -1.5809088   0.24883175]\"\n",
      "    num_agent_steps_sampled: 83000\n",
      "    num_agent_steps_trained: 656032\n",
      "    num_steps_sampled: 83000\n",
      "    num_steps_trained: 656032\n",
      "    num_target_updates: 163\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.300000000000004\n",
      "    ram_util_percent: 91.81052631578946\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0399973760201928\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.21965521370859\n",
      "    mean_inference_ms: 1.574602354254445\n",
      "    mean_raw_obs_processing_ms: 0.7396749531578042\n",
      "  time_since_restore: 1326.8721561431885\n",
      "  time_this_iter_s: 13.647669076919556\n",
      "  time_total_s: 1326.8721561431885\n",
      "  timers:\n",
      "    learn_throughput: 3806.742\n",
      "    learn_time_ms: 8.406\n",
      "    load_throughput: 65851.108\n",
      "    load_time_ms: 0.486\n",
      "    update_time_ms: 1.615\n",
      "  timestamp: 1632002754\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 83000\n",
      "  training_iteration: 83\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         1326.87</td><td style=\"text-align: right;\">83000</td><td style=\"text-align: right;\">-1.60714</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           977.238</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 84000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-06-08\n",
      "  done: false\n",
      "  episode_len_mean: 977.5058823529412\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.611764705882353\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 85\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 83656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 9.650200843811035\n",
      "          mean_q: 5.4829816818237305\n",
      "          min_q: 3.7778146266937256\n",
      "        mean_td_error: 0.03222028166055679\n",
      "        td_error: \"[-0.05923557  0.15593624  0.09618139 -0.17795944 -0.02966738  0.2949481\\n\\\n",
      "          \\  0.02300072  0.04925156  0.06809855  0.16468954  0.05687475  0.06223392\\n\\\n",
      "          \\  0.211133    0.1295371   0.11233711 -0.3395977   0.37054682  0.02727795\\n\\\n",
      "          \\ -1.787209   -0.1054101   0.19065619 -0.12501597  0.07405615  0.30725098\\n\\\n",
      "          \\ -0.13956404  0.2022686  -0.7908211   0.81182003  0.7159691  -0.3016882\\n\\\n",
      "          \\  0.79564476 -0.03249502]\"\n",
      "    num_agent_steps_sampled: 84000\n",
      "    num_agent_steps_trained: 664032\n",
      "    num_steps_sampled: 84000\n",
      "    num_steps_trained: 664032\n",
      "    num_target_updates: 165\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.615\n",
      "    ram_util_percent: 91.845\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0399951359902236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.187198108474806\n",
      "    mean_inference_ms: 1.574472872021267\n",
      "    mean_raw_obs_processing_ms: 0.7538875820283815\n",
      "  time_since_restore: 1340.6314585208893\n",
      "  time_this_iter_s: 13.759302377700806\n",
      "  time_total_s: 1340.6314585208893\n",
      "  timers:\n",
      "    learn_throughput: 3791.75\n",
      "    learn_time_ms: 8.439\n",
      "    load_throughput: 64770.644\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.688\n",
      "  timestamp: 1632002768\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 84000\n",
      "  training_iteration: 84\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1340.63</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-1.61176</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           977.506</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 85000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-06-21\n",
      "  done: false\n",
      "  episode_len_mean: 977.7674418604652\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6511627906976745\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 86\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 84664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.944268703460693\n",
      "          mean_q: 5.206399440765381\n",
      "          min_q: 4.024218559265137\n",
      "        mean_td_error: -0.233864888548851\n",
      "        td_error: \"[-9.6282434e-01  7.5492859e-03 -3.7268639e-02 -5.2454090e-01\\n -6.4367294e-02\\\n",
      "          \\ -6.0206051e+00  1.9392204e-01  8.5163593e-02\\n -1.3033867e-02  2.4462700e-02\\\n",
      "          \\ -3.2840014e-01  1.9505644e-01\\n -4.4355154e-01 -6.3424587e-02 -5.1822329e-01\\\n",
      "          \\  6.1513996e-01\\n  2.3114634e-01  5.5228233e-01  2.4655342e-02 -9.3878269e-02\\n\\\n",
      "          \\ -1.2220621e-01  6.6152716e-01  6.1321259e-02  1.4253616e-02\\n  8.1962919e-01\\\n",
      "          \\  6.8840122e-01  5.4678917e-03  7.2479248e-05\\n -4.0009031e+00  1.0772176e+00\\\n",
      "          \\ -2.3108482e-02  4.7539091e-01]\"\n",
      "    num_agent_steps_sampled: 85000\n",
      "    num_agent_steps_trained: 672032\n",
      "    num_steps_sampled: 85000\n",
      "    num_steps_trained: 672032\n",
      "    num_target_updates: 167\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.205\n",
      "    ram_util_percent: 91.85999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03999290524519717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.15542213163358\n",
      "    mean_inference_ms: 1.5743440292881665\n",
      "    mean_raw_obs_processing_ms: 0.7675276861470587\n",
      "  time_since_restore: 1354.3155753612518\n",
      "  time_this_iter_s: 13.684116840362549\n",
      "  time_total_s: 1354.3155753612518\n",
      "  timers:\n",
      "    learn_throughput: 3832.197\n",
      "    learn_time_ms: 8.35\n",
      "    load_throughput: 64200.578\n",
      "    load_time_ms: 0.498\n",
      "    update_time_ms: 1.663\n",
      "  timestamp: 1632002781\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 85000\n",
      "  training_iteration: 85\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         1354.32</td><td style=\"text-align: right;\">85000</td><td style=\"text-align: right;\">-1.65116</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           977.767</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 86000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-07-13\n",
      "  done: false\n",
      "  episode_len_mean: 969.9886363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.5454545454545454\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 88\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 85672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.183957576751709\n",
      "          mean_q: 5.162357330322266\n",
      "          min_q: 3.755309581756592\n",
      "        mean_td_error: -0.04847930371761322\n",
      "        td_error: \"[-0.02538919 -0.16598845  0.00725889  0.18054914  0.20013475 -0.46030807\\n\\\n",
      "          \\ -0.9466009  -0.11007452  0.35190725  0.236135    0.08260965  0.09291744\\n\\\n",
      "          \\ -0.15334797  0.04162788  0.14376259 -0.3228283   0.0427804   0.05255938\\n\\\n",
      "          \\  0.09442186 -0.05264139  0.30124855  0.5027046  -0.774137    0.21385956\\n\\\n",
      "          \\  0.12403774  0.16364908  0.02142906  0.19313765 -0.01986122 -1.6373739\\n\\\n",
      "          \\  0.03717518  0.03330755]\"\n",
      "    num_agent_steps_sampled: 86000\n",
      "    num_agent_steps_trained: 680032\n",
      "    num_steps_sampled: 86000\n",
      "    num_steps_trained: 680032\n",
      "    num_target_updates: 169\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.983561643835618\n",
      "    ram_util_percent: 91.91917808219178\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998847732985145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.093885521622322\n",
      "    mean_inference_ms: 1.5740931791401054\n",
      "    mean_raw_obs_processing_ms: 0.8035033507664076\n",
      "  time_since_restore: 1406.138399362564\n",
      "  time_this_iter_s: 51.822824001312256\n",
      "  time_total_s: 1406.138399362564\n",
      "  timers:\n",
      "    learn_throughput: 3695.849\n",
      "    learn_time_ms: 8.658\n",
      "    load_throughput: 61300.629\n",
      "    load_time_ms: 0.522\n",
      "    update_time_ms: 1.711\n",
      "  timestamp: 1632002833\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 86000\n",
      "  training_iteration: 86\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         1406.14</td><td style=\"text-align: right;\">86000</td><td style=\"text-align: right;\">-1.54545</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           969.989</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 87000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-07-28\n",
      "  done: false\n",
      "  episode_len_mean: 970.3258426966293\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.550561797752809\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 89\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 86680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.487869262695312\n",
      "          mean_q: 5.113153457641602\n",
      "          min_q: 3.8558523654937744\n",
      "        mean_td_error: -0.218490332365036\n",
      "        td_error: \"[-0.07389784  0.03155518 -0.06139302  0.09408188 -1.1150928   0.00995541\\n\\\n",
      "          \\ -0.34248734  0.41039228  0.06292152  0.18659544  0.07017326 -0.07457638\\n\\\n",
      "          \\  0.01288557 -0.06364202 -0.7879014  -0.19328976 -1.4518661  -0.03166723\\n\\\n",
      "          \\ -1.2235246  -0.2690115  -0.40443945 -1.0006981  -0.05812311 -0.07147074\\n\\\n",
      "          \\ -0.10623169 -0.36810255  0.2142086   1.6263804  -0.73965216 -0.11949492\\n\\\n",
      "          \\ -1.1823707   0.02809286]\"\n",
      "    num_agent_steps_sampled: 87000\n",
      "    num_agent_steps_trained: 688032\n",
      "    num_steps_sampled: 87000\n",
      "    num_steps_trained: 688032\n",
      "    num_target_updates: 171\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.63636363636364\n",
      "    ram_util_percent: 92.59545454545453\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998635843809835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.064287373947254\n",
      "    mean_inference_ms: 1.5739719734647677\n",
      "    mean_raw_obs_processing_ms: 0.8206022329081203\n",
      "  time_since_restore: 1421.401569366455\n",
      "  time_this_iter_s: 15.263170003890991\n",
      "  time_total_s: 1421.401569366455\n",
      "  timers:\n",
      "    learn_throughput: 3809.378\n",
      "    learn_time_ms: 8.4\n",
      "    load_throughput: 64032.121\n",
      "    load_time_ms: 0.5\n",
      "    update_time_ms: 1.669\n",
      "  timestamp: 1632002848\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 87000\n",
      "  training_iteration: 87\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">          1421.4</td><td style=\"text-align: right;\">87000</td><td style=\"text-align: right;\">-1.55056</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           970.326</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 88000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-07-42\n",
      "  done: false\n",
      "  episode_len_mean: 970.6555555555556\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.5555555555555556\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 90\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 87688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 17.46143913269043\n",
      "          mean_q: 5.854814529418945\n",
      "          min_q: 4.323664665222168\n",
      "        mean_td_error: -0.42296648025512695\n",
      "        td_error: \"[ 6.40258789e-02  6.88128948e-01  3.40538025e-02 -1.15030289e-01\\n\\\n",
      "          \\ -4.93211746e-02  1.19840145e-01 -1.21077538e-01  2.79125690e-01\\n  2.14655876e-01\\\n",
      "          \\ -2.75895596e-01 -6.16559982e-02 -1.26999378e-01\\n  1.53783560e+00 -1.00800037e-01\\\n",
      "          \\ -7.48481750e-02 -5.35387993e-02\\n -6.54697418e-04  5.95569611e-02  7.01227188e-02\\\n",
      "          \\  4.61826324e-02\\n -1.88840866e-01 -5.14488220e-02  1.00200653e-01 -2.32937336e-01\\n\\\n",
      "          \\ -4.73530197e+00 -1.83804512e-01 -5.16126060e+00 -4.40835953e-02\\n -4.61473942e+00\\\n",
      "          \\ -1.10058308e-01 -9.86981392e-02 -3.47661018e-01]\"\n",
      "    num_agent_steps_sampled: 88000\n",
      "    num_agent_steps_trained: 696032\n",
      "    num_steps_sampled: 88000\n",
      "    num_steps_trained: 696032\n",
      "    num_target_updates: 173\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.55\n",
      "    ram_util_percent: 92.82499999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998423470925864\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.03525419483811\n",
      "    mean_inference_ms: 1.573851537603661\n",
      "    mean_raw_obs_processing_ms: 0.8370487074564732\n",
      "  time_since_restore: 1434.8369245529175\n",
      "  time_this_iter_s: 13.435355186462402\n",
      "  time_total_s: 1434.8369245529175\n",
      "  timers:\n",
      "    learn_throughput: 3837.753\n",
      "    learn_time_ms: 8.338\n",
      "    load_throughput: 65274.646\n",
      "    load_time_ms: 0.49\n",
      "    update_time_ms: 1.695\n",
      "  timestamp: 1632002862\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 88000\n",
      "  training_iteration: 88\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         1434.84</td><td style=\"text-align: right;\">88000</td><td style=\"text-align: right;\">-1.55556</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           970.656</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 89000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-07-55\n",
      "  done: false\n",
      "  episode_len_mean: 970.978021978022\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.5384615384615385\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 91\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 88696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 9.635132789611816\n",
      "          mean_q: 5.365930080413818\n",
      "          min_q: 3.758962631225586\n",
      "        mean_td_error: -0.009814158082008362\n",
      "        td_error: \"[ 0.18218231  1.2739515   1.0268202  -0.30246592  0.11791039 -0.29903984\\n\\\n",
      "          \\ -0.01954985  1.7750473   0.79380226 -0.16491127  0.21543503  0.15265799\\n\\\n",
      "          \\ -0.30951214 -0.18532181 -2.143044    0.0427146   0.32904243 -0.02592897\\n\\\n",
      "          \\  0.2478981  -3.4020224  -0.20265388 -0.10731459  0.37664127  0.73116827\\n\\\n",
      "          \\ -0.16911936 -1.4565086  -0.5887079   0.0824337   0.72484875  0.3071704\\n\\\n",
      "          \\ -0.08679008  0.76911306]\"\n",
      "    num_agent_steps_sampled: 89000\n",
      "    num_agent_steps_trained: 704032\n",
      "    num_steps_sampled: 89000\n",
      "    num_steps_trained: 704032\n",
      "    num_target_updates: 175\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.66111111111112\n",
      "    ram_util_percent: 92.8611111111111\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0399821656845461\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 11.006723276818201\n",
      "    mean_inference_ms: 1.5737334941683285\n",
      "    mean_raw_obs_processing_ms: 0.8528689735041651\n",
      "  time_since_restore: 1447.9560377597809\n",
      "  time_this_iter_s: 13.119113206863403\n",
      "  time_total_s: 1447.9560377597809\n",
      "  timers:\n",
      "    learn_throughput: 3867.3\n",
      "    learn_time_ms: 8.275\n",
      "    load_throughput: 67273.685\n",
      "    load_time_ms: 0.476\n",
      "    update_time_ms: 1.646\n",
      "  timestamp: 1632002875\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89000\n",
      "  training_iteration: 89\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         1447.96</td><td style=\"text-align: right;\">89000</td><td style=\"text-align: right;\">-1.53846</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           970.978</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 90000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-08-08\n",
      "  done: false\n",
      "  episode_len_mean: 971.2934782608696\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.5869565217391304\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 92\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 89704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 28.37440299987793\n",
      "          mean_q: 6.029397487640381\n",
      "          min_q: 3.5319621562957764\n",
      "        mean_td_error: -0.014077536761760712\n",
      "        td_error: \"[-0.02937984  0.21643639  0.48509216  0.08848047 -0.5157914   2.596243\\n\\\n",
      "          \\ -0.43767452  0.23364139 -0.22201729  0.5047698   0.03336573 -0.01541805\\n\\\n",
      "          \\ -0.0267086   0.35969353 -0.06944275 -0.4031601  -0.17033339 -0.27728224\\n\\\n",
      "          \\  1.1810918  -0.06609964 -0.24528456 -0.0571084  -0.32868004 -0.02890539\\n\\\n",
      "          \\ -0.495255    0.01495552  0.0279479   0.02120686 -0.4965377  -0.00532436\\n\\\n",
      "          \\ -0.2689042  -2.0540981 ]\"\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_agent_steps_trained: 712032\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 712032\n",
      "    num_target_updates: 177\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.90526315789474\n",
      "    ram_util_percent: 92.85263157894735\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039980164894931336\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 10.978679618926023\n",
      "    mean_inference_ms: 1.573616924535477\n",
      "    mean_raw_obs_processing_ms: 0.8680922243564989\n",
      "  time_since_restore: 1461.093831062317\n",
      "  time_this_iter_s: 13.13779330253601\n",
      "  time_total_s: 1461.093831062317\n",
      "  timers:\n",
      "    learn_throughput: 3799.339\n",
      "    learn_time_ms: 8.423\n",
      "    load_throughput: 66270.542\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.668\n",
      "  timestamp: 1632002888\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 90\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         1461.09</td><td style=\"text-align: right;\">90000</td><td style=\"text-align: right;\">-1.58696</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           971.293</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 91000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-09-05\n",
      "  done: false\n",
      "  episode_len_mean: 967.4893617021277\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.627659574468085\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 94\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 90712\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 14.459506034851074\n",
      "          mean_q: 5.779153347015381\n",
      "          min_q: 4.159204006195068\n",
      "        mean_td_error: -0.07624220848083496\n",
      "        td_error: \"[-0.11429977  0.69165516  0.04216862 -2.0852156   0.17316675  0.66841507\\n\\\n",
      "          \\ -0.01026678  0.0413394  -0.02813387 -0.06036234  1.163518   -0.42647982\\n\\\n",
      "          \\ -0.14731741  0.02283955  0.28179264 -1.5002961   0.0446887  -4.3082466\\n\\\n",
      "          \\ -0.04602528  0.13838148  0.41094542 -0.9970403   0.18218136 -0.16119671\\n\\\n",
      "          \\ -0.18062925 -0.18043709 -0.2436266  -0.13013935  4.6292562  -0.10043001\\n\\\n",
      "          \\  0.09814835 -0.30810452]\"\n",
      "    num_agent_steps_sampled: 91000\n",
      "    num_agent_steps_trained: 720032\n",
      "    num_steps_sampled: 91000\n",
      "    num_steps_trained: 720032\n",
      "    num_target_updates: 179\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.45853658536586\n",
      "    ram_util_percent: 92.59146341463415\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039976318323338485\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 10.92419769810527\n",
      "    mean_inference_ms: 1.5733875075951806\n",
      "    mean_raw_obs_processing_ms: 0.9073115204922375\n",
      "  time_since_restore: 1518.2318925857544\n",
      "  time_this_iter_s: 57.1380615234375\n",
      "  time_total_s: 1518.2318925857544\n",
      "  timers:\n",
      "    learn_throughput: 3767.695\n",
      "    learn_time_ms: 8.493\n",
      "    load_throughput: 64830.086\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.654\n",
      "  timestamp: 1632002945\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 91000\n",
      "  training_iteration: 91\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         1518.23</td><td style=\"text-align: right;\">91000</td><td style=\"text-align: right;\">-1.62766</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           967.489</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 92000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-09-44\n",
      "  done: false\n",
      "  episode_len_mean: 962.1157894736842\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.568421052631579\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 95\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 91720\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 14.336594581604004\n",
      "          mean_q: 5.8506269454956055\n",
      "          min_q: 4.237345218658447\n",
      "        mean_td_error: 0.25702883303165436\n",
      "        td_error: \"[ 0.11348248  1.10902596  0.01885605  0.06904745  0.09226799  0.14167404\\n\\\n",
      "          \\ -0.04629374 -0.80413055  0.13224792  0.11833239  0.30472708  0.08764696\\n\\\n",
      "          \\ -0.03123522  0.12891102  0.57650232  6.32505226 -0.02182674  0.02399731\\n\\\n",
      "          \\  0.13843775 -0.16910648  0.05806351 -0.02874184 -0.10920429  0.03993225\\n\\\n",
      "          \\  0.144557    0.27726603 -2.67604828  1.22920084 -1.20777512  0.05015087\\n\\\n",
      "          \\  0.1841445   1.95576096]\"\n",
      "    num_agent_steps_sampled: 92000\n",
      "    num_agent_steps_trained: 728032\n",
      "    num_steps_sampled: 92000\n",
      "    num_steps_trained: 728032\n",
      "    num_target_updates: 181\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.61851851851852\n",
      "    ram_util_percent: 92.52777777777777\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03997444582482369\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 10.897770608437096\n",
      "    mean_inference_ms: 1.5732762171999681\n",
      "    mean_raw_obs_processing_ms: 0.9288209061905873\n",
      "  time_since_restore: 1556.6053717136383\n",
      "  time_this_iter_s: 38.37347912788391\n",
      "  time_total_s: 1556.6053717136383\n",
      "  timers:\n",
      "    learn_throughput: 3784.149\n",
      "    learn_time_ms: 8.456\n",
      "    load_throughput: 65296.876\n",
      "    load_time_ms: 0.49\n",
      "    update_time_ms: 1.7\n",
      "  timestamp: 1632002984\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 92000\n",
      "  training_iteration: 92\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1556.61</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">-1.56842</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           962.116</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 93000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-10-17\n",
      "  done: false\n",
      "  episode_len_mean: 960.4166666666666\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.5208333333333333\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 96\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 92728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.751564025878906\n",
      "          mean_q: 5.537589073181152\n",
      "          min_q: 4.339625835418701\n",
      "        mean_td_error: -0.06122833490371704\n",
      "        td_error: \"[-0.07784986  0.04567623 -0.03653336  0.03870249  1.0125751   0.14861965\\n\\\n",
      "          \\ -0.11653233 -0.00537252  0.34387684  0.13790512 -0.22363138 -0.05203056\\n\\\n",
      "          \\ -0.02809238  0.39641094 -0.28741217 -0.30357456  0.09381676  0.02618456\\n\\\n",
      "          \\  0.10426807  0.80903053  0.19325113 -0.06907749  0.33307266 -0.39547682\\n\\\n",
      "          \\  0.32992268 -3.3026638  -0.01673937  0.8066306   0.06106138  0.13166523\\n\\\n",
      "          \\ -0.9164424  -1.1405478 ]\"\n",
      "    num_agent_steps_sampled: 93000\n",
      "    num_agent_steps_trained: 736032\n",
      "    num_steps_sampled: 93000\n",
      "    num_steps_trained: 736032\n",
      "    num_target_updates: 183\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.60416666666667\n",
      "    ram_util_percent: 92.75625000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039972628179871794\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 10.871809359288713\n",
      "    mean_inference_ms: 1.573166294631527\n",
      "    mean_raw_obs_processing_ms: 0.9517963374876589\n",
      "  time_since_restore: 1589.9036045074463\n",
      "  time_this_iter_s: 33.29823279380798\n",
      "  time_total_s: 1589.9036045074463\n",
      "  timers:\n",
      "    learn_throughput: 3791.879\n",
      "    learn_time_ms: 8.439\n",
      "    load_throughput: 66526.755\n",
      "    load_time_ms: 0.481\n",
      "    update_time_ms: 1.641\n",
      "  timestamp: 1632003017\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 93000\n",
      "  training_iteration: 93\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">          1589.9</td><td style=\"text-align: right;\">93000</td><td style=\"text-align: right;\">-1.52083</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           960.417</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 94000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-11-07\n",
      "  done: false\n",
      "  episode_len_mean: 952.969387755102\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.510204081632653\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 98\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 93736\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 23.59074592590332\n",
      "          mean_q: 6.264981269836426\n",
      "          min_q: 3.81497859954834\n",
      "        mean_td_error: 0.25189635157585144\n",
      "        td_error: \"[-0.05787802 -0.154953    0.02178764 -0.04612923 -1.55039692 -0.3146019\\n\\\n",
      "          \\ -0.28590584 -0.24698973 -0.1915803  -1.13090229  0.8664155   3.8149786\\n\\\n",
      "          \\  0.21017504 -0.10257435  0.12666893  0.70469999  4.34145975 -1.04922009\\n\\\n",
      "          \\  1.05856466  0.51120567  0.26891804 -0.08020782  0.11541748 -0.1285634\\n\\\n",
      "          \\ -0.02126503  1.14280272  0.4385376  -0.78492975 -0.14726639  1.14840126\\n\\\n",
      "          \\ -0.05414724 -0.36183834]\"\n",
      "    num_agent_steps_sampled: 94000\n",
      "    num_agent_steps_trained: 744032\n",
      "    num_steps_sampled: 94000\n",
      "    num_steps_trained: 744032\n",
      "    num_target_updates: 185\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.877464788732397\n",
      "    ram_util_percent: 92.9619718309859\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039969140506271594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 10.821884320852675\n",
      "    mean_inference_ms: 1.5729527127580534\n",
      "    mean_raw_obs_processing_ms: 1.0030322912842964\n",
      "  time_since_restore: 1639.7352619171143\n",
      "  time_this_iter_s: 49.83165740966797\n",
      "  time_total_s: 1639.7352619171143\n",
      "  timers:\n",
      "    learn_throughput: 3818.677\n",
      "    learn_time_ms: 8.38\n",
      "    load_throughput: 66851.486\n",
      "    load_time_ms: 0.479\n",
      "    update_time_ms: 1.726\n",
      "  timestamp: 1632003067\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 94000\n",
      "  training_iteration: 94\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1639.74</td><td style=\"text-align: right;\">94000</td><td style=\"text-align: right;\"> -1.5102</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           952.969</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 95000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-11-23\n",
      "  done: false\n",
      "  episode_len_mean: 953.4444444444445\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.5454545454545454\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 99\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 94744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 13.069222450256348\n",
      "          mean_q: 5.776092052459717\n",
      "          min_q: 4.028746604919434\n",
      "        mean_td_error: 0.21886660158634186\n",
      "        td_error: \"[-1.3901463   0.16864347  0.27649975  0.7387161   0.07455254 -0.89976406\\n\\\n",
      "          \\  1.3262944   1.1246574   0.5441103   0.06071901  0.6740689   0.31981897\\n\\\n",
      "          \\  0.09435225  0.3287797   0.12316799 -0.5276475  -0.3489895  -0.23604107\\n\\\n",
      "          \\  0.6724856   0.09533548  0.0253005   0.14148235  0.24598074  0.451993\\n\\\n",
      "          \\  1.2376251   0.06102133  0.03748512  0.10183907  0.6526675   0.11551189\\n\\\n",
      "          \\  0.2081542   0.50505686]\"\n",
      "    num_agent_steps_sampled: 95000\n",
      "    num_agent_steps_trained: 752032\n",
      "    num_steps_sampled: 95000\n",
      "    num_steps_trained: 752032\n",
      "    num_target_updates: 187\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.32608695652173\n",
      "    ram_util_percent: 92.6695652173913\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03996745446728763\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 10.797890076155676\n",
      "    mean_inference_ms: 1.572849191241807\n",
      "    mean_raw_obs_processing_ms: 1.027523387549722\n",
      "  time_since_restore: 1655.959435224533\n",
      "  time_this_iter_s: 16.224173307418823\n",
      "  time_total_s: 1655.959435224533\n",
      "  timers:\n",
      "    learn_throughput: 3813.502\n",
      "    learn_time_ms: 8.391\n",
      "    load_throughput: 66427.977\n",
      "    load_time_ms: 0.482\n",
      "    update_time_ms: 1.738\n",
      "  timestamp: 1632003083\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 95000\n",
      "  training_iteration: 95\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1655.96</td><td style=\"text-align: right;\">95000</td><td style=\"text-align: right;\">-1.54545</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">           953.444</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 96000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-11-38\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.56\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 100\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 95752\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 15.72107219696045\n",
      "          mean_q: 6.109439849853516\n",
      "          min_q: 4.015453338623047\n",
      "        mean_td_error: 0.20302388072013855\n",
      "        td_error: \"[ 0.11672401  4.01545334  0.0949769   0.86669064  0.43465328  0.18786955\\n\\\n",
      "          \\  0.42696238  0.13427162  0.48371172  0.15128613 -1.38801479 -0.14559698\\n\\\n",
      "          \\  0.08562422  0.03486729 -0.03956795  0.10902071  0.12937832  0.3788085\\n\\\n",
      "          \\  1.1972456   0.12339067  0.20173693 -1.08473778  0.25536442 -1.1326704\\n\\\n",
      "          \\  0.06200886 -0.81823826  0.09998894  0.13977528  0.03364706  0.18247032\\n\\\n",
      "          \\  0.50882101  0.65084267]\"\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 760032\n",
      "    num_steps_sampled: 96000\n",
      "    num_steps_trained: 760032\n",
      "    num_target_updates: 189\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.41904761904761\n",
      "    ram_util_percent: 92.64285714285714\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03996578080037095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 10.774421768279144\n",
      "    mean_inference_ms: 1.5727471284699712\n",
      "    mean_raw_obs_processing_ms: 1.051185541280427\n",
      "  time_since_restore: 1670.6172206401825\n",
      "  time_this_iter_s: 14.657785415649414\n",
      "  time_total_s: 1670.6172206401825\n",
      "  timers:\n",
      "    learn_throughput: 3793.905\n",
      "    learn_time_ms: 8.435\n",
      "    load_throughput: 65912.551\n",
      "    load_time_ms: 0.485\n",
      "    update_time_ms: 1.646\n",
      "  timestamp: 1632003098\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 96000\n",
      "  training_iteration: 96\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1670.62</td><td style=\"text-align: right;\">96000</td><td style=\"text-align: right;\">   -1.56</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 97000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-11-52\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.59\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 101\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 96760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11.469679832458496\n",
      "          mean_q: 5.560299396514893\n",
      "          min_q: 4.124753475189209\n",
      "        mean_td_error: 0.0007730722427368164\n",
      "        td_error: \"[ 0.13140535  0.32448053  0.0033412   0.13895798  0.02251816  0.32260513\\n\\\n",
      "          \\  0.00265646  0.63658619  0.01287127  0.18529558 -0.12736511  0.01661539\\n\\\n",
      "          \\ -0.32416153  0.23092842  0.06334496 -0.10140657  0.17138624 -0.17482758\\n\\\n",
      "          \\  0.3496232  -1.36735773 -0.06061316 -0.80663967  0.28356457  0.73385048\\n\\\n",
      "          \\  0.38559246 -0.02060652 -0.20675182 -1.03883982  0.01237965  1.01662827\\n\\\n",
      "          \\ -0.68857861 -0.10274506]\"\n",
      "    num_agent_steps_sampled: 97000\n",
      "    num_agent_steps_trained: 768032\n",
      "    num_steps_sampled: 97000\n",
      "    num_steps_trained: 768032\n",
      "    num_target_updates: 191\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.37500000000001\n",
      "    ram_util_percent: 92.33999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03992657188250322\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 10.17673711212246\n",
      "    mean_inference_ms: 1.5709698902475444\n",
      "    mean_raw_obs_processing_ms: 1.0830805697390737\n",
      "  time_since_restore: 1684.5841443538666\n",
      "  time_this_iter_s: 13.966923713684082\n",
      "  time_total_s: 1684.5841443538666\n",
      "  timers:\n",
      "    learn_throughput: 3780.813\n",
      "    learn_time_ms: 8.464\n",
      "    load_throughput: 64639.63\n",
      "    load_time_ms: 0.495\n",
      "    update_time_ms: 1.712\n",
      "  timestamp: 1632003112\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 97000\n",
      "  training_iteration: 97\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1684.58</td><td style=\"text-align: right;\">97000</td><td style=\"text-align: right;\">   -1.59</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 98000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-12-06\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.54\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 102\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 97768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 10.605684280395508\n",
      "          mean_q: 5.620658874511719\n",
      "          min_q: 4.251209735870361\n",
      "        mean_td_error: 0.2742983400821686\n",
      "        td_error: \"[-0.06127024  0.00915623  0.27770662  0.31314754 -0.21834135  0.03785992\\n\\\n",
      "          \\  2.48453     0.34125328  0.19296122  0.35825443 -0.5511656   0.67392206\\n\\\n",
      "          \\ -0.12280846  0.83912086  0.20206976  0.2496996  -0.04560471  0.27110624\\n\\\n",
      "          \\  1.1475677   0.29148006  0.01713181 -0.18124199 -0.00486517 -0.38750744\\n\\\n",
      "          \\  0.896019    0.03079319  0.35603762 -0.03608274  0.6132784   0.3772521\\n\\\n",
      "          \\ -0.27455807  0.680645  ]\"\n",
      "    num_agent_steps_sampled: 98000\n",
      "    num_agent_steps_trained: 776032\n",
      "    num_steps_sampled: 98000\n",
      "    num_steps_trained: 776032\n",
      "    num_target_updates: 193\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.69047619047618\n",
      "    ram_util_percent: 92.0714285714286\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03990322236341839\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.87933998422654\n",
      "    mean_inference_ms: 1.5698823526369847\n",
      "    mean_raw_obs_processing_ms: 1.1145662397442604\n",
      "  time_since_restore: 1698.8844363689423\n",
      "  time_this_iter_s: 14.300292015075684\n",
      "  time_total_s: 1698.8844363689423\n",
      "  timers:\n",
      "    learn_throughput: 3633.064\n",
      "    learn_time_ms: 8.808\n",
      "    load_throughput: 38468.824\n",
      "    load_time_ms: 0.832\n",
      "    update_time_ms: 1.846\n",
      "  timestamp: 1632003126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 98000\n",
      "  training_iteration: 98\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1698.88</td><td style=\"text-align: right;\">98000</td><td style=\"text-align: right;\">   -1.54</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 99000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-12-20\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.54\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 103\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 98776\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.960637092590332\n",
      "          mean_q: 5.495017051696777\n",
      "          min_q: 3.9216325283050537\n",
      "        mean_td_error: -0.4446302503347397\n",
      "        td_error: \"[ -0.09145308   0.16289663  -0.70480108 -10.55238533   0.22941732\\n\\\n",
      "          \\  -1.22107601  -0.13656592   0.50849628   0.02391052  -0.34319162\\n  -0.13750148\\\n",
      "          \\  -0.21231174  -2.0005784    0.14781284   0.21486521\\n  -0.94745398  -1.55309439\\\n",
      "          \\   0.11712694  -0.09407616  -3.15011215\\n   4.39199877  -0.05601406   0.23978996\\\n",
      "          \\   0.36485577   0.17256069\\n   0.74821949   0.19447041   0.12266016   0.01919556\\\n",
      "          \\  -0.70746994\\n   0.351717    -0.33007622]\"\n",
      "    num_agent_steps_sampled: 99000\n",
      "    num_agent_steps_trained: 784032\n",
      "    num_steps_sampled: 99000\n",
      "    num_steps_trained: 784032\n",
      "    num_target_updates: 195\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.52499999999999\n",
      "    ram_util_percent: 91.915\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03988601489005554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.684382798798389\n",
      "    mean_inference_ms: 1.5691034237374495\n",
      "    mean_raw_obs_processing_ms: 1.1458042784680338\n",
      "  time_since_restore: 1712.9282765388489\n",
      "  time_this_iter_s: 14.043840169906616\n",
      "  time_total_s: 1712.9282765388489\n",
      "  timers:\n",
      "    learn_throughput: 3767.018\n",
      "    learn_time_ms: 8.495\n",
      "    load_throughput: 65523.202\n",
      "    load_time_ms: 0.488\n",
      "    update_time_ms: 1.701\n",
      "  timestamp: 1632003140\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99000\n",
      "  training_iteration: 99\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1712.93</td><td style=\"text-align: right;\">99000</td><td style=\"text-align: right;\">   -1.54</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 100000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-12-34\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.59\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 104\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 99784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 18.450458526611328\n",
      "          mean_q: 5.149038314819336\n",
      "          min_q: 3.700165271759033\n",
      "        mean_td_error: -0.11590038985013962\n",
      "        td_error: \"[-0.10037613 -2.498536   -0.04722452 -1.3986721  -0.08756638 -0.25310373\\n\\\n",
      "          \\  1.5249915  -0.13310099  0.03526783  0.13703966 -1.1079974  -0.09380531\\n\\\n",
      "          \\ -0.5660968   0.13200426  0.883842   -0.27546453 -0.11265182  0.01002026\\n\\\n",
      "          \\ -0.18308592 -0.1660161  -0.00919342 -1.0343561   0.05869341  0.07429123\\n\\\n",
      "          \\  0.08617067  2.1244087  -0.22692156 -0.08563042 -0.18730259 -0.12472963\\n\\\n",
      "          \\  0.38220072 -0.46591115]\"\n",
      "    num_agent_steps_sampled: 100000\n",
      "    num_agent_steps_trained: 792032\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 792032\n",
      "    num_target_updates: 197\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.29473684210525\n",
      "    ram_util_percent: 91.63684210526316\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03987443043813857\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.540562814736317\n",
      "    mean_inference_ms: 1.5685274278695058\n",
      "    mean_raw_obs_processing_ms: 1.1767493120955745\n",
      "  time_since_restore: 1726.4835290908813\n",
      "  time_this_iter_s: 13.55525255203247\n",
      "  time_total_s: 1726.4835290908813\n",
      "  timers:\n",
      "    learn_throughput: 3808.794\n",
      "    learn_time_ms: 8.402\n",
      "    load_throughput: 66195.368\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.719\n",
      "  timestamp: 1632003154\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 100\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         1726.48</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">   -1.59</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 101000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-12-47\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.59\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 105\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 100792\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.833839416503906\n",
      "          mean_q: 4.886911392211914\n",
      "          min_q: 4.173644542694092\n",
      "        mean_td_error: -0.10427293181419373\n",
      "        td_error: \"[-0.0404253   0.03361559 -0.46237803 -0.62374544 -0.03925705 -0.27043676\\n\\\n",
      "          \\  1.1208777  -0.47282076  0.9352565  -0.5398011   0.13975859 -0.4168725\\n\\\n",
      "          \\ -0.10652637 -0.02294493 -0.38097525  0.63635063 -0.1735282  -0.5378227\\n\\\n",
      "          \\  0.14843893  0.02628613 -0.07702732  0.01601791 -0.04257154 -0.28153896\\n\\\n",
      "          \\ -0.12380266  0.13743353  0.02292347 -0.6590028  -0.08339882 -1.0105357\\n\\\n",
      "          \\ -0.20531416  0.01703358]\"\n",
      "    num_agent_steps_sampled: 101000\n",
      "    num_agent_steps_trained: 800032\n",
      "    num_steps_sampled: 101000\n",
      "    num_steps_trained: 800032\n",
      "    num_target_updates: 199\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.18947368421052\n",
      "    ram_util_percent: 91.57368421052631\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039865266639994484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.427528364511659\n",
      "    mean_inference_ms: 1.568080963330342\n",
      "    mean_raw_obs_processing_ms: 1.2074137603891386\n",
      "  time_since_restore: 1739.8578538894653\n",
      "  time_this_iter_s: 13.374324798583984\n",
      "  time_total_s: 1739.8578538894653\n",
      "  timers:\n",
      "    learn_throughput: 3724.484\n",
      "    learn_time_ms: 8.592\n",
      "    load_throughput: 57957.392\n",
      "    load_time_ms: 0.552\n",
      "    update_time_ms: 1.718\n",
      "  timestamp: 1632003167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 101000\n",
      "  training_iteration: 101\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1739.86</td><td style=\"text-align: right;\">101000</td><td style=\"text-align: right;\">   -1.59</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 102000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-13-02\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.59\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 106\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 101800\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 13.76235294342041\n",
      "          mean_q: 5.35585880279541\n",
      "          min_q: 4.100808143615723\n",
      "        mean_td_error: 0.15698744356632233\n",
      "        td_error: \"[ 0.02375269 -0.2002263   0.74050856 -0.11707354  0.34490347  0.27918816\\n\\\n",
      "          \\ -0.03040266 -0.17820644  0.06344318  0.27888012  0.20758438  0.733304\\n\\\n",
      "          \\  0.08044815  0.08666039 -0.605824    0.24211168  1.083075   -0.02964544\\n\\\n",
      "          \\  0.18643951 -0.14252567 -0.05585289 -0.5532789  -0.01017332 -0.05329704\\n\\\n",
      "          \\  0.7468128   0.21986914  0.10067558 -0.06696796 -0.4386034   1.2185202\\n\\\n",
      "          \\ -0.17399025  1.043489  ]\"\n",
      "    num_agent_steps_sampled: 102000\n",
      "    num_agent_steps_trained: 808032\n",
      "    num_steps_sampled: 102000\n",
      "    num_steps_trained: 808032\n",
      "    num_target_updates: 201\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.53333333333333\n",
      "    ram_util_percent: 91.7142857142857\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03985815685767402\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.335261611249187\n",
      "    mean_inference_ms: 1.5677372111035965\n",
      "    mean_raw_obs_processing_ms: 1.2377988178146035\n",
      "  time_since_restore: 1754.1225187778473\n",
      "  time_this_iter_s: 14.264664888381958\n",
      "  time_total_s: 1754.1225187778473\n",
      "  timers:\n",
      "    learn_throughput: 3816.69\n",
      "    learn_time_ms: 8.384\n",
      "    load_throughput: 65446.522\n",
      "    load_time_ms: 0.489\n",
      "    update_time_ms: 1.691\n",
      "  timestamp: 1632003182\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 102000\n",
      "  training_iteration: 102\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1754.12</td><td style=\"text-align: right;\">102000</td><td style=\"text-align: right;\">   -1.59</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 103000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-13-15\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.59\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 107\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 102808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11.792896270751953\n",
      "          mean_q: 5.296958923339844\n",
      "          min_q: 3.8966522216796875\n",
      "        mean_td_error: 0.11812900751829147\n",
      "        td_error: \"[-0.57726717  0.80624247  0.35580349 -0.05777311  0.16667414 -0.01881695\\n\\\n",
      "          \\ -0.1092968  -0.24379778 -0.04573011  0.15769339  0.08618784  2.60634327\\n\\\n",
      "          \\  0.19209051 -0.06339169  0.07520962 -0.01193285  0.5934639   1.31798267\\n\\\n",
      "          \\ -0.9640379   3.41093206  0.79011774 -0.06534529  0.04953575 -0.05152035\\n\\\n",
      "          \\ -0.19303894 -0.35398436 -0.86375475 -0.20529175 -0.0995388  -0.05105233\\n\\\n",
      "          \\ -0.94883537 -1.90374231]\"\n",
      "    num_agent_steps_sampled: 103000\n",
      "    num_agent_steps_trained: 816032\n",
      "    num_steps_sampled: 103000\n",
      "    num_steps_trained: 816032\n",
      "    num_target_updates: 203\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.5\n",
      "    ram_util_percent: 91.63684210526314\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03985304966362107\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.258057456761065\n",
      "    mean_inference_ms: 1.5674721927355706\n",
      "    mean_raw_obs_processing_ms: 1.2679022311059418\n",
      "  time_since_restore: 1767.767008781433\n",
      "  time_this_iter_s: 13.644490003585815\n",
      "  time_total_s: 1767.767008781433\n",
      "  timers:\n",
      "    learn_throughput: 3745.332\n",
      "    learn_time_ms: 8.544\n",
      "    load_throughput: 62706.844\n",
      "    load_time_ms: 0.51\n",
      "    update_time_ms: 1.704\n",
      "  timestamp: 1632003195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 103000\n",
      "  training_iteration: 103\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1767.77</td><td style=\"text-align: right;\">103000</td><td style=\"text-align: right;\">   -1.59</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 104000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-13-29\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.57\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 108\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 103816\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.030160903930664\n",
      "          mean_q: 5.583282947540283\n",
      "          min_q: 4.580175399780273\n",
      "        mean_td_error: -0.158751979470253\n",
      "        td_error: \"[ 7.7330112e-02  2.1581411e-01  1.3086891e-01 -4.4746113e-01\\n -6.5709114e-02\\\n",
      "          \\ -3.8222647e-01 -1.5560260e+00 -2.4061918e-01\\n  1.1380100e-01  8.3200455e-02\\\n",
      "          \\  3.6926270e-02  3.0219412e-01\\n  3.0421829e-01  3.5466194e-02  1.0761261e-02\\\n",
      "          \\  4.8239231e-02\\n -8.7507725e-02  1.1368370e-01  1.0507488e-01  9.3600702e-01\\n\\\n",
      "          \\ -1.9344301e+00  2.0540380e-01 -3.0015087e-01  1.7508268e-01\\n -6.9168663e-01\\\n",
      "          \\  2.4607468e-01  6.4152241e-02 -2.3159981e-03\\n -3.1161981e+00  3.1841755e-01\\\n",
      "          \\  1.2149048e-01  1.0006094e-01]\"\n",
      "    num_agent_steps_sampled: 104000\n",
      "    num_agent_steps_trained: 824032\n",
      "    num_steps_sampled: 104000\n",
      "    num_steps_trained: 824032\n",
      "    num_target_updates: 205\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.325\n",
      "    ram_util_percent: 91.63499999999998\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039849133559770704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.191574654122302\n",
      "    mean_inference_ms: 1.567248631729521\n",
      "    mean_raw_obs_processing_ms: 1.2977190234608056\n",
      "  time_since_restore: 1781.8377978801727\n",
      "  time_this_iter_s: 14.070789098739624\n",
      "  time_total_s: 1781.8377978801727\n",
      "  timers:\n",
      "    learn_throughput: 3767.483\n",
      "    learn_time_ms: 8.494\n",
      "    load_throughput: 61401.587\n",
      "    load_time_ms: 0.521\n",
      "    update_time_ms: 1.73\n",
      "  timestamp: 1632003209\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 104000\n",
      "  training_iteration: 104\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1781.84</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">   -1.57</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 105000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-13-43\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.57\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 109\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 104824\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.591649055480957\n",
      "          mean_q: 5.571673393249512\n",
      "          min_q: 4.622751235961914\n",
      "        mean_td_error: -0.0851530134677887\n",
      "        td_error: \"[ 0.19980669  0.02764988  0.0602107  -1.4677024  -1.2465296  -0.02331781\\n\\\n",
      "          \\  0.13276339  0.07411432 -1.148776   -0.03171015 -0.12080908 -0.13644457\\n\\\n",
      "          \\  0.31711864 -0.07305813  0.47920227  0.14507914 -0.06791019  0.13290167\\n\\\n",
      "          \\  2.0646315   0.20509338 -0.05859804 -1.1672316  -0.27282286  0.19690704\\n\\\n",
      "          \\  0.134089   -0.50278664  0.24684429 -0.06951523  0.1087966   0.03161287\\n\\\n",
      "          \\ -0.99651     0.10200453]\"\n",
      "    num_agent_steps_sampled: 105000\n",
      "    num_agent_steps_trained: 832032\n",
      "    num_steps_sampled: 105000\n",
      "    num_steps_trained: 832032\n",
      "    num_target_updates: 207\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.4\n",
      "    ram_util_percent: 91.72500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039846526047645964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.133964384771684\n",
      "    mean_inference_ms: 1.5670688473090968\n",
      "    mean_raw_obs_processing_ms: 1.327262108055928\n",
      "  time_since_restore: 1795.9822657108307\n",
      "  time_this_iter_s: 14.144467830657959\n",
      "  time_total_s: 1795.9822657108307\n",
      "  timers:\n",
      "    learn_throughput: 3788.946\n",
      "    learn_time_ms: 8.446\n",
      "    load_throughput: 64462.671\n",
      "    load_time_ms: 0.496\n",
      "    update_time_ms: 1.732\n",
      "  timestamp: 1632003223\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 105000\n",
      "  training_iteration: 105\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1795.98</td><td style=\"text-align: right;\">105000</td><td style=\"text-align: right;\">   -1.57</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 106000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-13-57\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.57\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 110\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 105832\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 6.793123245239258\n",
      "          mean_q: 5.297770977020264\n",
      "          min_q: 4.485849380493164\n",
      "        mean_td_error: 0.06049320101737976\n",
      "        td_error: \"[ 1.9068341  -0.01373434 -0.10597515 -0.03117466 -0.25444365 -0.032372\\n\\\n",
      "          \\ -0.07112408  0.02974129 -0.25992584  0.01727724  0.16635132  0.0500555\\n\\\n",
      "          \\  0.08201265  1.0216999   0.09147358 -0.03710794  0.01066494 -0.17445898\\n\\\n",
      "          \\  1.3404408  -0.09436464 -0.66535616 -0.07839632  0.01132679  0.74999094\\n\\\n",
      "          \\ -0.14075136  0.02007532 -0.05743933 -0.13557482 -0.03966188  0.08201265\\n\\\n",
      "          \\ -1.4866152   0.03430176]\"\n",
      "    num_agent_steps_sampled: 106000\n",
      "    num_agent_steps_trained: 840032\n",
      "    num_steps_sampled: 106000\n",
      "    num_steps_trained: 840032\n",
      "    num_target_updates: 209\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.68999999999999\n",
      "    ram_util_percent: 91.72\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03984480530063805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.08394041511512\n",
      "    mean_inference_ms: 1.566937430996658\n",
      "    mean_raw_obs_processing_ms: 1.3565380767706592\n",
      "  time_since_restore: 1809.9126284122467\n",
      "  time_this_iter_s: 13.930362701416016\n",
      "  time_total_s: 1809.9126284122467\n",
      "  timers:\n",
      "    learn_throughput: 3509.933\n",
      "    learn_time_ms: 9.117\n",
      "    load_throughput: 53717.173\n",
      "    load_time_ms: 0.596\n",
      "    update_time_ms: 1.868\n",
      "  timestamp: 1632003237\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 106000\n",
      "  training_iteration: 106\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1809.91</td><td style=\"text-align: right;\">106000</td><td style=\"text-align: right;\">   -1.57</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 107000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-14-12\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.58\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 111\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 106840\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.017529487609863\n",
      "          mean_q: 5.206599235534668\n",
      "          min_q: 4.243963718414307\n",
      "        mean_td_error: -0.13491757214069366\n",
      "        td_error: \"[-0.1834774  -1.0923214   0.0348053  -0.0956769  -0.03885269 -0.01218271\\n\\\n",
      "          \\ -0.26487064  0.07461309 -0.04776144 -0.02771378 -0.20556927 -0.24360466\\n\\\n",
      "          \\  0.27549648  0.25149727  0.24346113 -0.1986022  -0.0034132   0.02812052\\n\\\n",
      "          \\ -0.11085081 -1.4127183   0.01594257 -0.13162947 -0.02623892 -0.25817442\\n\\\n",
      "          \\ -0.36922455 -0.0548377  -0.01455116 -0.39788437 -0.06654882  0.31856298\\n\\\n",
      "          \\ -0.15238428 -0.15077257]\"\n",
      "    num_agent_steps_sampled: 107000\n",
      "    num_agent_steps_trained: 848032\n",
      "    num_steps_sampled: 107000\n",
      "    num_steps_trained: 848032\n",
      "    num_target_updates: 211\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.975\n",
      "    ram_util_percent: 91.81499999999998\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039843652183647084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 9.039579456090856\n",
      "    mean_inference_ms: 1.5668348545519217\n",
      "    mean_raw_obs_processing_ms: 1.3855484725265677\n",
      "  time_since_restore: 1824.1419298648834\n",
      "  time_this_iter_s: 14.229301452636719\n",
      "  time_total_s: 1824.1419298648834\n",
      "  timers:\n",
      "    learn_throughput: 3775.665\n",
      "    learn_time_ms: 8.475\n",
      "    load_throughput: 65689.961\n",
      "    load_time_ms: 0.487\n",
      "    update_time_ms: 1.687\n",
      "  timestamp: 1632003252\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 107000\n",
      "  training_iteration: 107\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1824.14</td><td style=\"text-align: right;\">107000</td><td style=\"text-align: right;\">   -1.58</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 108000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-14-26\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.58\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 112\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 107848\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11.420970916748047\n",
      "          mean_q: 5.319430351257324\n",
      "          min_q: 4.312385559082031\n",
      "        mean_td_error: 0.031127527356147766\n",
      "        td_error: \"[-0.12719107 -0.06802368 -0.02359009 -0.77288198  0.02775431  0.04372215\\n\\\n",
      "          \\ -0.03736401 -0.06083059 -0.07666779 -0.09344721 -0.7118926  -0.04528856\\n\\\n",
      "          \\  0.23614359 -0.06109047 -1.04850912  0.08376551 -0.03794813 -0.29721546\\n\\\n",
      "          \\  0.97277212  0.30637169 -0.10075474 -0.04638386 -0.05964661 -0.00533485\\n\\\n",
      "          \\ -1.1926055   0.15671682 -0.04169846  0.05297232  0.03106403 -0.05086517\\n\\\n",
      "          \\  0.06723833  3.97678995]\"\n",
      "    num_agent_steps_sampled: 108000\n",
      "    num_agent_steps_trained: 856032\n",
      "    num_steps_sampled: 108000\n",
      "    num_steps_trained: 856032\n",
      "    num_target_updates: 213\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.095\n",
      "    ram_util_percent: 91.63999999999997\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03984297176608479\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.999843651297974\n",
      "    mean_inference_ms: 1.5667424989691625\n",
      "    mean_raw_obs_processing_ms: 1.4142946189976748\n",
      "  time_since_restore: 1838.077356338501\n",
      "  time_this_iter_s: 13.935426473617554\n",
      "  time_total_s: 1838.077356338501\n",
      "  timers:\n",
      "    learn_throughput: 3834.628\n",
      "    learn_time_ms: 8.345\n",
      "    load_throughput: 66761.703\n",
      "    load_time_ms: 0.479\n",
      "    update_time_ms: 1.73\n",
      "  timestamp: 1632003266\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 108000\n",
      "  training_iteration: 108\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1838.08</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">   -1.58</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 109000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-14-40\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.58\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 113\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 108856\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.388379096984863\n",
      "          mean_q: 5.07058048248291\n",
      "          min_q: 4.170893669128418\n",
      "        mean_td_error: 0.05031310021877289\n",
      "        td_error: \"[ 0.06512833 -0.08070612  0.01436615 -0.11228371 -0.11477232  0.05537224\\n\\\n",
      "          \\  0.3265524   0.18028164 -0.01859665  0.11560822  0.12998724  0.33706617\\n\\\n",
      "          \\  0.4863224   0.22030973  0.07259321  0.18447304 -0.10595179 -0.04632902\\n\\\n",
      "          \\  0.08017349  0.00434923  0.0572381  -0.04883051 -0.01350451  0.02533674\\n\\\n",
      "          \\  0.08609867 -0.10144377  0.02009344  0.08412552  0.14459562  0.2858243\\n\\\n",
      "          \\ -0.73205376  0.00859547]\"\n",
      "    num_agent_steps_sampled: 109000\n",
      "    num_agent_steps_trained: 864032\n",
      "    num_steps_sampled: 109000\n",
      "    num_steps_trained: 864032\n",
      "    num_target_updates: 215\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.269999999999996\n",
      "    ram_util_percent: 91.69000000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03984154818163592\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.963932672681368\n",
      "    mean_inference_ms: 1.566634424905537\n",
      "    mean_raw_obs_processing_ms: 1.4427781550016305\n",
      "  time_since_restore: 1852.0874826908112\n",
      "  time_this_iter_s: 14.01012635231018\n",
      "  time_total_s: 1852.0874826908112\n",
      "  timers:\n",
      "    learn_throughput: 3814.282\n",
      "    learn_time_ms: 8.39\n",
      "    load_throughput: 63553.07\n",
      "    load_time_ms: 0.504\n",
      "    update_time_ms: 1.745\n",
      "  timestamp: 1632003280\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109000\n",
      "  training_iteration: 109\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1852.09</td><td style=\"text-align: right;\">109000</td><td style=\"text-align: right;\">   -1.58</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 110000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-14-53\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.58\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 114\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 109864\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 25.80381202697754\n",
      "          mean_q: 5.795867919921875\n",
      "          min_q: 4.340205669403076\n",
      "        mean_td_error: -0.018080055713653564\n",
      "        td_error: \"[ 0.12469101  0.18461514 -0.01181507 -0.21026087 -0.03142023 -0.12302113\\n\\\n",
      "          \\ -0.16365051  0.20806551 -1.25117254 -0.0883193   0.01818943 -0.13062191\\n\\\n",
      "          \\ -0.14410639 -0.0139904  -0.02048874 -0.12962294  0.02919197 -0.08947468\\n\\\n",
      "          \\  0.10725451  0.16198635 -0.07896328  0.02325344  0.03416204  0.06609011\\n\\\n",
      "          \\  0.10098982 -0.79602432 -0.75788498 -0.14390945 -0.94972181 -1.10537004\\n\\\n",
      "          \\  0.26258183  4.34020567]\"\n",
      "    num_agent_steps_sampled: 110000\n",
      "    num_agent_steps_trained: 872032\n",
      "    num_steps_sampled: 110000\n",
      "    num_steps_trained: 872032\n",
      "    num_target_updates: 217\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.155\n",
      "    ram_util_percent: 91.72\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03983964115731111\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.931140896994465\n",
      "    mean_inference_ms: 1.5665154721596202\n",
      "    mean_raw_obs_processing_ms: 1.471004411089984\n",
      "  time_since_restore: 1865.843703508377\n",
      "  time_this_iter_s: 13.756220817565918\n",
      "  time_total_s: 1865.843703508377\n",
      "  timers:\n",
      "    learn_throughput: 3748.104\n",
      "    learn_time_ms: 8.538\n",
      "    load_throughput: 63949.747\n",
      "    load_time_ms: 0.5\n",
      "    update_time_ms: 1.807\n",
      "  timestamp: 1632003293\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 110000\n",
      "  training_iteration: 110\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1865.84</td><td style=\"text-align: right;\">110000</td><td style=\"text-align: right;\">   -1.58</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 111000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-15-08\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.58\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 115\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 110872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7.1304168701171875\n",
      "          mean_q: 5.2672038078308105\n",
      "          min_q: 4.501483917236328\n",
      "        mean_td_error: 0.17616581916809082\n",
      "        td_error: \"[ 0.086339   -0.36316252  0.7194176   0.25946665  0.04007816 -0.04938364\\n\\\n",
      "          \\  0.7729845   0.3029828   0.06143188 -0.41570473 -0.10172033 -0.18474865\\n\\\n",
      "          \\  0.08138466  1.3385005   1.7233558  -0.5036869  -0.00612211  0.23699379\\n\\\n",
      "          \\  0.12129879  0.01152706  0.36960125 -0.038342    0.11261082  0.08884573\\n\\\n",
      "          \\  0.10513306  0.29941702 -0.2421174   0.06366825  0.03428745  0.7037449\\n\\\n",
      "          \\ -0.06763601  0.0768609 ]\"\n",
      "    num_agent_steps_sampled: 111000\n",
      "    num_agent_steps_trained: 880032\n",
      "    num_steps_sampled: 111000\n",
      "    num_steps_trained: 880032\n",
      "    num_target_updates: 219\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.45\n",
      "    ram_util_percent: 91.74500000000002\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03983745315546355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.901230980268771\n",
      "    mean_inference_ms: 1.5663884971281556\n",
      "    mean_raw_obs_processing_ms: 1.4989790077885434\n",
      "  time_since_restore: 1879.9114165306091\n",
      "  time_this_iter_s: 14.067713022232056\n",
      "  time_total_s: 1879.9114165306091\n",
      "  timers:\n",
      "    learn_throughput: 3791.322\n",
      "    learn_time_ms: 8.44\n",
      "    load_throughput: 65893.136\n",
      "    load_time_ms: 0.486\n",
      "    update_time_ms: 1.695\n",
      "  timestamp: 1632003308\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 111000\n",
      "  training_iteration: 111\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1879.91</td><td style=\"text-align: right;\">111000</td><td style=\"text-align: right;\">   -1.58</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 112000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-15-21\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.58\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 116\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 111880\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 22.119192123413086\n",
      "          mean_q: 5.851083755493164\n",
      "          min_q: 4.83125114440918\n",
      "        mean_td_error: -0.3154113292694092\n",
      "        td_error: \"[-0.08311939 -0.63616467 -0.21151066 -0.5359535  -2.0944672  -0.33514595\\n\\\n",
      "          \\ -0.17258644  0.05889893  0.39913797 -0.23680544  0.01675367 -0.02480125\\n\\\n",
      "          \\ -0.5116253  -1.7061276  -0.10015821 -0.7784381   0.14383078  0.75023985\\n\\\n",
      "          \\ -0.10797071 -1.1458149  -0.21942854 -0.13468885 -0.34577608 -0.2359004\\n\\\n",
      "          \\ -0.16319466 -0.08835649 -0.17778444 -0.1913991  -1.040452   -0.8210082\\n\\\n",
      "          \\  0.78179646 -0.14514208]\"\n",
      "    num_agent_steps_sampled: 112000\n",
      "    num_agent_steps_trained: 888032\n",
      "    num_steps_sampled: 112000\n",
      "    num_steps_trained: 888032\n",
      "    num_target_updates: 221\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.42999999999999\n",
      "    ram_util_percent: 91.845\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039835415361203635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.873693023009979\n",
      "    mean_inference_ms: 1.5662655294836696\n",
      "    mean_raw_obs_processing_ms: 1.5267062451370854\n",
      "  time_since_restore: 1893.650873184204\n",
      "  time_this_iter_s: 13.73945665359497\n",
      "  time_total_s: 1893.650873184204\n",
      "  timers:\n",
      "    learn_throughput: 3819.112\n",
      "    learn_time_ms: 8.379\n",
      "    load_throughput: 61768.939\n",
      "    load_time_ms: 0.518\n",
      "    update_time_ms: 1.786\n",
      "  timestamp: 1632003321\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 112000\n",
      "  training_iteration: 112\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1893.65</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\">   -1.58</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 113000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-15-34\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.58\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 117\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 112888\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 36.83424377441406\n",
      "          mean_q: 6.488193511962891\n",
      "          min_q: 4.7673020362854\n",
      "        mean_td_error: -0.04933956265449524\n",
      "        td_error: \"[-7.16293335e-01 -4.33349609e-02  4.43973541e-02 -1.06835365e-02\\n\\\n",
      "          \\ -3.86152744e-01 -8.71706009e-03  3.58214378e-02  2.17537880e-02\\n -8.64656925e-01\\\n",
      "          \\  2.65262127e-01 -2.66876221e-02 -1.70564175e+00\\n  5.67474365e-02  2.22376537e+00\\\n",
      "          \\  2.17103958e-02 -4.08082008e-02\\n  1.38584137e-01 -7.86986351e-02 -2.43706703e-02\\\n",
      "          \\ -4.33826447e-02\\n -5.19242287e-02 -6.54846668e-01 -8.52108002e-04 -1.16439390e+00\\n\\\n",
      "          \\  5.62896729e-02  1.47772312e-01  1.94720268e-01  6.25530243e-01\\n  2.07257271e-01\\\n",
      "          \\  2.90656090e-01  1.77133083e-01 -2.64822006e-01]\"\n",
      "    num_agent_steps_sampled: 113000\n",
      "    num_agent_steps_trained: 896032\n",
      "    num_steps_sampled: 113000\n",
      "    num_steps_trained: 896032\n",
      "    num_target_updates: 223\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.32222222222222\n",
      "    ram_util_percent: 91.86111111111111\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03983333871955261\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.848308959413123\n",
      "    mean_inference_ms: 1.5661443703423583\n",
      "    mean_raw_obs_processing_ms: 1.5541892553731842\n",
      "  time_since_restore: 1906.617525100708\n",
      "  time_this_iter_s: 12.966651916503906\n",
      "  time_total_s: 1906.617525100708\n",
      "  timers:\n",
      "    learn_throughput: 3754.027\n",
      "    learn_time_ms: 8.524\n",
      "    load_throughput: 64770.644\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.732\n",
      "  timestamp: 1632003334\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 113000\n",
      "  training_iteration: 113\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1906.62</td><td style=\"text-align: right;\">113000</td><td style=\"text-align: right;\">   -1.58</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 114000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-15-49\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.56\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 118\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 113896\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 34.851951599121094\n",
      "          mean_q: 7.457161903381348\n",
      "          min_q: 4.699613094329834\n",
      "        mean_td_error: 0.4340208172798157\n",
      "        td_error: \"[ 0.03643942  0.25938702  0.03500557  0.4300995  -0.03821039  0.19815445\\n\\\n",
      "          \\  0.3473997   0.3824172   0.30263233  0.32459402  0.2736907   0.20979595\\n\\\n",
      "          \\  0.12913704  0.20560646  0.92189026  0.20742798  0.5925484   1.7346077\\n\\\n",
      "          \\  1.2933517   0.5692954   0.02840996  3.1537247   0.20261288  1.6787782\\n\\\n",
      "          \\  0.0991168   0.04753876  0.06903791 -0.15044165  0.80243397  0.1526351\\n\\\n",
      "          \\ -0.9855461   0.3750949 ]\"\n",
      "    num_agent_steps_sampled: 114000\n",
      "    num_agent_steps_trained: 904032\n",
      "    num_steps_sampled: 114000\n",
      "    num_steps_trained: 904032\n",
      "    num_target_updates: 225\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.98571428571429\n",
      "    ram_util_percent: 91.94285714285718\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0398311726671384\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.824989755900242\n",
      "    mean_inference_ms: 1.5660267913619679\n",
      "    mean_raw_obs_processing_ms: 1.5814346693345698\n",
      "  time_since_restore: 1920.884289741516\n",
      "  time_this_iter_s: 14.266764640808105\n",
      "  time_total_s: 1920.884289741516\n",
      "  timers:\n",
      "    learn_throughput: 3781.101\n",
      "    learn_time_ms: 8.463\n",
      "    load_throughput: 64798.787\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.748\n",
      "  timestamp: 1632003349\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 114000\n",
      "  training_iteration: 114\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1920.88</td><td style=\"text-align: right;\">114000</td><td style=\"text-align: right;\">   -1.56</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 115000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-16-02\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.58\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 119\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 114904\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11.366670608520508\n",
      "          mean_q: 5.200029373168945\n",
      "          min_q: 3.8618953227996826\n",
      "        mean_td_error: -0.18082290887832642\n",
      "        td_error: \"[-0.06666136  0.21295214 -0.44171    -0.10036516 -0.0909214  -2.5694776\\n\\\n",
      "          \\ -1.0144367   0.18952417 -0.32961702 -0.35230398  0.05591536 -0.10205412\\n\\\n",
      "          \\ -0.1157403  -0.03721285 -0.1048274  -0.18496752 -0.42591953  0.04443073\\n\\\n",
      "          \\  1.3787606  -0.27089596 -0.02948809  0.11715508 -2.0459166  -0.0915122\\n\\\n",
      "          \\ -0.13374901 -0.14884424 -0.10454893  0.9250479  -0.09354925  0.20309925\\n\\\n",
      "          \\ -0.05460596 -0.00389338]\"\n",
      "    num_agent_steps_sampled: 115000\n",
      "    num_agent_steps_trained: 912032\n",
      "    num_steps_sampled: 115000\n",
      "    num_steps_trained: 912032\n",
      "    num_target_updates: 227\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.131578947368425\n",
      "    ram_util_percent: 92.00526315789473\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03982867672745375\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.803311026550167\n",
      "    mean_inference_ms: 1.5659045104095812\n",
      "    mean_raw_obs_processing_ms: 1.6084446416348848\n",
      "  time_since_restore: 1934.3144619464874\n",
      "  time_this_iter_s: 13.430172204971313\n",
      "  time_total_s: 1934.3144619464874\n",
      "  timers:\n",
      "    learn_throughput: 3647.756\n",
      "    learn_time_ms: 8.773\n",
      "    load_throughput: 61094.145\n",
      "    load_time_ms: 0.524\n",
      "    update_time_ms: 1.722\n",
      "  timestamp: 1632003362\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 115000\n",
      "  training_iteration: 115\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1934.31</td><td style=\"text-align: right;\">115000</td><td style=\"text-align: right;\">   -1.58</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 116000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-16-16\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.55\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 120\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 115912\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 40.1797981262207\n",
      "          mean_q: 6.362932205200195\n",
      "          min_q: 3.9942150115966797\n",
      "        mean_td_error: -0.2186671942472458\n",
      "        td_error: \"[-1.3503742  -0.02906275 -0.15170622 -0.02097845 -3.3043556  -0.3748622\\n\\\n",
      "          \\ -0.5434127  -0.13711166 -0.14424849 -0.11265945 -0.2655878  -0.09600306\\n\\\n",
      "          \\ -0.0428915  -0.15104294 -0.08768463  0.07589006  0.00816345  0.69469166\\n\\\n",
      "          \\ -0.04398203  1.1053238  -0.3699441  -2.1361284   0.6900196  -0.03357267\\n\\\n",
      "          \\ -0.03785086 -0.07980394  0.00442648  0.78443    -0.08471727 -0.1596756\\n\\\n",
      "          \\ -0.23195744 -0.3706813 ]\"\n",
      "    num_agent_steps_sampled: 116000\n",
      "    num_agent_steps_trained: 920032\n",
      "    num_steps_sampled: 116000\n",
      "    num_steps_trained: 920032\n",
      "    num_target_updates: 229\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.505\n",
      "    ram_util_percent: 92.03999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039825270880902736\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.78255818372656\n",
      "    mean_inference_ms: 1.5657597184332375\n",
      "    mean_raw_obs_processing_ms: 1.6352102842393803\n",
      "  time_since_restore: 1948.0412719249725\n",
      "  time_this_iter_s: 13.726809978485107\n",
      "  time_total_s: 1948.0412719249725\n",
      "  timers:\n",
      "    learn_throughput: 3746.21\n",
      "    learn_time_ms: 8.542\n",
      "    load_throughput: 65751.104\n",
      "    load_time_ms: 0.487\n",
      "    update_time_ms: 1.749\n",
      "  timestamp: 1632003376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 116000\n",
      "  training_iteration: 116\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1948.04</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\">   -1.55</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 117000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-16-30\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.47\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 121\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 116920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 8.320173263549805\n",
      "          mean_q: 5.19840145111084\n",
      "          min_q: 4.46686315536499\n",
      "        mean_td_error: -0.4504578709602356\n",
      "        td_error: \"[-0.21636009 -0.4846387  -0.34149122  0.6303539  -0.06454086  0.33677578\\n\\\n",
      "          \\ -0.24920988 -0.35660267 -0.23102522 -0.198277   -0.25510216 -0.44755745\\n\\\n",
      "          \\ -0.13743544  0.22924328 -4.1435018  -0.06847334 -1.97929    -0.06104994\\n\\\n",
      "          \\ -0.7054663  -0.13073254 -0.12299252  0.11777735 -0.07616329 -0.186728\\n\\\n",
      "          \\ -1.351903    0.12073278 -1.1309533  -2.8703508  -0.5860214  -0.04409266\\n\\\n",
      "          \\  0.5172739   0.07315016]\"\n",
      "    num_agent_steps_sampled: 117000\n",
      "    num_agent_steps_trained: 928032\n",
      "    num_steps_sampled: 117000\n",
      "    num_steps_trained: 928032\n",
      "    num_target_updates: 231\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.136842105263156\n",
      "    ram_util_percent: 92.03684210526316\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0398218816121633\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.762724099276705\n",
      "    mean_inference_ms: 1.5656159926506765\n",
      "    mean_raw_obs_processing_ms: 1.661740411718059\n",
      "  time_since_restore: 1961.840674161911\n",
      "  time_this_iter_s: 13.799402236938477\n",
      "  time_total_s: 1961.840674161911\n",
      "  timers:\n",
      "    learn_throughput: 3743.494\n",
      "    learn_time_ms: 8.548\n",
      "    load_throughput: 65773.659\n",
      "    load_time_ms: 0.487\n",
      "    update_time_ms: 1.786\n",
      "  timestamp: 1632003390\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 117000\n",
      "  training_iteration: 117\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1961.84</td><td style=\"text-align: right;\">117000</td><td style=\"text-align: right;\">   -1.47</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 118000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-16-44\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.49\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 122\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 117928\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 63.3635139465332\n",
      "          mean_q: 7.111481666564941\n",
      "          min_q: 3.833169460296631\n",
      "        mean_td_error: 0.13383083045482635\n",
      "        td_error: \"[ 0.05556965  1.7495041   0.10017538 -0.03379703 -0.96499157 -0.13428879\\n\\\n",
      "          \\ -0.13905716 -0.6465025   0.15249014 -0.01035094 -0.09596825  0.09105396\\n\\\n",
      "          \\ -0.06620073 -0.01478004  0.7618127  -0.12531948  0.05758667  0.01855183\\n\\\n",
      "          \\ -0.09592438  0.03610468  3.9587975   0.05867243 -0.06918764  0.06149483\\n\\\n",
      "          \\  0.03138971 -0.23749447  0.13074493  0.20349789 -0.20105934  0.03277779\\n\\\n",
      "          \\ -0.31610346 -0.06661177]\"\n",
      "    num_agent_steps_sampled: 118000\n",
      "    num_agent_steps_trained: 936032\n",
      "    num_steps_sampled: 118000\n",
      "    num_steps_trained: 936032\n",
      "    num_target_updates: 233\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.13809523809525\n",
      "    ram_util_percent: 92.18571428571428\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981892168811487\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.744317752060397\n",
      "    mean_inference_ms: 1.5654817510779921\n",
      "    mean_raw_obs_processing_ms: 1.6880450808805472\n",
      "  time_since_restore: 1976.6231098175049\n",
      "  time_this_iter_s: 14.782435655593872\n",
      "  time_total_s: 1976.6231098175049\n",
      "  timers:\n",
      "    learn_throughput: 3633.939\n",
      "    learn_time_ms: 8.806\n",
      "    load_throughput: 61130.319\n",
      "    load_time_ms: 0.523\n",
      "    update_time_ms: 1.834\n",
      "  timestamp: 1632003404\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 118000\n",
      "  training_iteration: 118\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1976.62</td><td style=\"text-align: right;\">118000</td><td style=\"text-align: right;\">   -1.49</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 119000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-16-59\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.42\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 123\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 118936\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 50.57661437988281\n",
      "          mean_q: 7.384369373321533\n",
      "          min_q: 3.798485040664673\n",
      "        mean_td_error: 0.3615542948246002\n",
      "        td_error: \"[ 8.2304716e-01 -2.7142143e-01  1.1985712e+00 -8.8370323e-02\\n -4.2358875e-02\\\n",
      "          \\  4.7544003e-02  1.6414642e-01 -1.5208817e-01\\n -5.5801392e-02  8.3085537e-02\\\n",
      "          \\ -6.8659806e-01 -7.6835155e-02\\n -2.1849155e-02  3.7163258e-02 -2.3743286e+00\\\n",
      "          \\ -4.3267250e-02\\n -1.7975235e-01 -1.3012934e-01 -3.5874367e-02  2.1794319e-02\\n\\\n",
      "          \\ -5.8519363e-02 -1.5484190e-01  4.6836376e-02  1.3550520e-01\\n  4.4177818e-01\\\n",
      "          \\ -3.8754797e-01  7.0459843e-03  1.3082743e-01\\n  2.0956135e-01  1.2728773e+01\\\n",
      "          \\ -1.0694504e-02  2.6433611e-01]\"\n",
      "    num_agent_steps_sampled: 119000\n",
      "    num_agent_steps_trained: 944032\n",
      "    num_steps_sampled: 119000\n",
      "    num_steps_trained: 944032\n",
      "    num_target_updates: 235\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.96666666666666\n",
      "    ram_util_percent: 92.31904761904764\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981657802719679\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.7266648666201\n",
      "    mean_inference_ms: 1.5653576782856342\n",
      "    mean_raw_obs_processing_ms: 1.7141265014536284\n",
      "  time_since_restore: 1991.30766415596\n",
      "  time_this_iter_s: 14.6845543384552\n",
      "  time_total_s: 1991.30766415596\n",
      "  timers:\n",
      "    learn_throughput: 3718.293\n",
      "    learn_time_ms: 8.606\n",
      "    load_throughput: 64280.521\n",
      "    load_time_ms: 0.498\n",
      "    update_time_ms: 1.738\n",
      "  timestamp: 1632003419\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119000\n",
      "  training_iteration: 119\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1991.31</td><td style=\"text-align: right;\">119000</td><td style=\"text-align: right;\">   -1.42</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 120000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-17-13\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.43\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 124\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 119944\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 48.99871826171875\n",
      "          mean_q: 6.2579240798950195\n",
      "          min_q: 1.1091687679290771\n",
      "        mean_td_error: -0.01151391863822937\n",
      "        td_error: \"[ 0.04330397  0.00399923  0.1268692   0.11403656  0.09058762  0.26105165\\n\\\n",
      "          \\ -0.23593235  0.20379877  0.06356239  0.32057047  0.0374465   1.1091688\\n\\\n",
      "          \\  0.10902023  0.11287689  0.06737709  0.04793596  0.39315748  0.01858568\\n\\\n",
      "          \\  0.09438968  0.0640831   0.06654978  0.07672644 -3.3291245  -0.09560347\\n\\\n",
      "          \\  0.17166328  1.2744865   0.11112976  0.11274195 -2.233365    0.22283602\\n\\\n",
      "          \\  0.12603426  0.08159065]\"\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 952032\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 952032\n",
      "    num_target_updates: 237\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.06000000000001\n",
      "    ram_util_percent: 92.03\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981458481164004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.709860778181323\n",
      "    mean_inference_ms: 1.565238193427954\n",
      "    mean_raw_obs_processing_ms: 1.739986327892009\n",
      "  time_since_restore: 2004.8943283557892\n",
      "  time_this_iter_s: 13.586664199829102\n",
      "  time_total_s: 2004.8943283557892\n",
      "  timers:\n",
      "    learn_throughput: 3766.447\n",
      "    learn_time_ms: 8.496\n",
      "    load_throughput: 66319.66\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.839\n",
      "  timestamp: 1632003433\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 120\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         2004.89</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">   -1.43</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 121000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-17-27\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.38\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 125\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 120952\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 104.52686309814453\n",
      "          mean_q: 14.092302322387695\n",
      "          min_q: 2.5440211296081543\n",
      "        mean_td_error: 0.1588003784418106\n",
      "        td_error: \"[ 0.08722305  0.06453705 -0.10545492 -0.4023428  -0.07896042  0.16450739\\n\\\n",
      "          \\  0.07715034  0.04980516  0.25088358 -0.6453552   0.02611494 -0.03552246\\n\\\n",
      "          \\ -0.05977821  2.051602    9.680172   -0.06474209  0.04860067 -2.0846467\\n\\\n",
      "          \\  0.03889036 -0.88828564 -8.2847595   0.05932522 -0.3320608   0.04591846\\n\\\n",
      "          \\  4.5078964   0.5440211  -0.01222324  0.18344879  0.11726379  0.03730583\\n\\\n",
      "          \\  0.09899664 -0.05791807]\"\n",
      "    num_agent_steps_sampled: 121000\n",
      "    num_agent_steps_trained: 960032\n",
      "    num_steps_sampled: 121000\n",
      "    num_steps_trained: 960032\n",
      "    num_target_updates: 239\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.715\n",
      "    ram_util_percent: 91.97000000000003\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981296259455558\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.69385306836396\n",
      "    mean_inference_ms: 1.5651217972372142\n",
      "    mean_raw_obs_processing_ms: 1.765632211703069\n",
      "  time_since_restore: 2018.7801744937897\n",
      "  time_this_iter_s: 13.885846138000488\n",
      "  time_total_s: 2018.7801744937897\n",
      "  timers:\n",
      "    learn_throughput: 3658.195\n",
      "    learn_time_ms: 8.747\n",
      "    load_throughput: 50131.748\n",
      "    load_time_ms: 0.638\n",
      "    update_time_ms: 1.881\n",
      "  timestamp: 1632003447\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 121000\n",
      "  training_iteration: 121\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         2018.78</td><td style=\"text-align: right;\">121000</td><td style=\"text-align: right;\">   -1.38</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 122000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-17-40\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.39\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 126\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 121960\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 99.97863006591797\n",
      "          mean_q: 10.45620346069336\n",
      "          min_q: 4.532528400421143\n",
      "        mean_td_error: 0.1140296459197998\n",
      "        td_error: \"[ 0.12892866  0.17301607  0.10630131 -0.1529808   0.11536694 -4.2381134\\n\\\n",
      "          \\  0.15125418  1.35150337  0.10373163  0.16465664  0.14340734  0.13799191\\n\\\n",
      "          \\  0.20156574 -0.47883511  0.43221903  0.12083626  0.09161377 -0.20448542\\n\\\n",
      "          \\  0.17360449 -1.89165449  0.0878706   5.56438065  0.12045479 -5.44309998\\n\\\n",
      "          \\  0.10562754  0.12849092  0.14015961  4.5325284   0.17838812  0.20249605\\n\\\n",
      "          \\  0.270473    1.13125086]\"\n",
      "    num_agent_steps_sampled: 122000\n",
      "    num_agent_steps_trained: 968032\n",
      "    num_steps_sampled: 122000\n",
      "    num_steps_trained: 968032\n",
      "    num_target_updates: 241\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.75789473684211\n",
      "    ram_util_percent: 91.85263157894737\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981165244385565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.6786829196745\n",
      "    mean_inference_ms: 1.5650125560365908\n",
      "    mean_raw_obs_processing_ms: 1.791066525247257\n",
      "  time_since_restore: 2032.4336075782776\n",
      "  time_this_iter_s: 13.653433084487915\n",
      "  time_total_s: 2032.4336075782776\n",
      "  timers:\n",
      "    learn_throughput: 3833.708\n",
      "    learn_time_ms: 8.347\n",
      "    load_throughput: 64811.303\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.693\n",
      "  timestamp: 1632003460\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 122000\n",
      "  training_iteration: 122\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         2032.43</td><td style=\"text-align: right;\">122000</td><td style=\"text-align: right;\">   -1.39</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 123000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-17-55\n",
      "  done: false\n",
      "  episode_len_mean: 953.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.43\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 127\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 122968\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 72.11064147949219\n",
      "          mean_q: 9.643463134765625\n",
      "          min_q: 4.2192206382751465\n",
      "        mean_td_error: -0.0263185054063797\n",
      "        td_error: \"[ 0.04231739  0.13134623 -1.0706787   0.30342007  0.12127686 -0.21693087\\n\\\n",
      "          \\ -0.40242958  0.1704464   0.37257338  1.1550112   0.07358265 -0.09684372\\n\\\n",
      "          \\  0.05116081  0.0792551  -4.988163    0.07669258  7.665489    0.09948587\\n\\\n",
      "          \\ -1.0594497   0.10818768  0.413136    0.12355375  0.27672482  0.20635462\\n\\\n",
      "          \\  0.27062654  0.45266867 -5.3379135   0.16688967  0.09377575 -0.02697515\\n\\\n",
      "          \\  0.20497131 -0.30175447]\"\n",
      "    num_agent_steps_sampled: 123000\n",
      "    num_agent_steps_trained: 976032\n",
      "    num_steps_sampled: 123000\n",
      "    num_steps_trained: 976032\n",
      "    num_target_updates: 243\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.64285714285714\n",
      "    ram_util_percent: 91.7142857142857\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981062751414554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.664338152879349\n",
      "    mean_inference_ms: 1.5649109408074857\n",
      "    mean_raw_obs_processing_ms: 1.8162955256818998\n",
      "  time_since_restore: 2046.7263979911804\n",
      "  time_this_iter_s: 14.292790412902832\n",
      "  time_total_s: 2046.7263979911804\n",
      "  timers:\n",
      "    learn_throughput: 3794.935\n",
      "    learn_time_ms: 8.432\n",
      "    load_throughput: 64354.492\n",
      "    load_time_ms: 0.497\n",
      "    update_time_ms: 1.742\n",
      "  timestamp: 1632003475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 123000\n",
      "  training_iteration: 123\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         2046.73</td><td style=\"text-align: right;\">123000</td><td style=\"text-align: right;\">   -1.43</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            953.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 124000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-18-50\n",
      "  done: false\n",
      "  episode_len_mean: 947.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.42\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 129\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 123976\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 110.71464538574219\n",
      "          mean_q: 15.15568733215332\n",
      "          min_q: 4.3152337074279785\n",
      "        mean_td_error: 0.07841816544532776\n",
      "        td_error: \"[  2.3082352    0.08929586   0.04563046   0.10612774   0.85110235\\n\\\n",
      "          \\  -2.083537    -4.966896     0.40368986   2.5478516    0.02912235\\n  10.941429\\\n",
      "          \\    -4.966896     0.31935406   0.13607502   0.4597788\\n   0.02003384   0.16679192\\\n",
      "          \\  -3.6231184   -0.0157733   -0.03419542\\n   1.2856989    0.40562344   0.14989138\\\n",
      "          \\   0.79947376   0.2680087\\n   8.25209      0.08620882   0.21777487 -11.084183\\\n",
      "          \\     0.12078333\\n   0.01976013  -0.7458515 ]\"\n",
      "    num_agent_steps_sampled: 124000\n",
      "    num_agent_steps_trained: 984032\n",
      "    num_steps_sampled: 124000\n",
      "    num_steps_trained: 984032\n",
      "    num_target_updates: 245\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.860256410256408\n",
      "    ram_util_percent: 90.92051282051283\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980937034119087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.637586707863324\n",
      "    mean_inference_ms: 1.564732590656634\n",
      "    mean_raw_obs_processing_ms: 1.873055902096567\n",
      "  time_since_restore: 2101.901893377304\n",
      "  time_this_iter_s: 55.17549538612366\n",
      "  time_total_s: 2101.901893377304\n",
      "  timers:\n",
      "    learn_throughput: 3755.823\n",
      "    learn_time_ms: 8.52\n",
      "    load_throughput: 62351.448\n",
      "    load_time_ms: 0.513\n",
      "    update_time_ms: 1.8\n",
      "  timestamp: 1632003530\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 124000\n",
      "  training_iteration: 124\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">          2101.9</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\">   -1.42</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            947.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 125000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-19-05\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.47\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 130\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 124984\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 118.58659362792969\n",
      "          mean_q: 18.38507080078125\n",
      "          min_q: 5.124576091766357\n",
      "        mean_td_error: -0.15184485912322998\n",
      "        td_error: \"[ 1.06890202e-01  1.00399494e-01  9.93094444e-02 -4.49035168e-01\\n\\\n",
      "          \\  8.35909843e-02  9.76048470e-01  1.00399494e-01  3.77391338e-01\\n -1.03527336e+01\\\n",
      "          \\ -1.05122566e-01 -1.91589241e+01 -3.30825806e-01\\n  1.07495213e+00  2.71212769e+00\\\n",
      "          \\ -6.36408138e+00 -3.76257896e-01\\n -1.81816101e-01 -9.23590660e-02  1.80907249e-02\\\n",
      "          \\  1.23959503e+01\\n  8.19864273e-02 -3.03949833e-01  2.86422729e-01  8.34294128e+00\\n\\\n",
      "          \\  2.37584114e-02 -1.96843147e-02  7.45523834e+00 -5.05873203e-01\\n  4.70645905e-01\\\n",
      "          \\ -8.95781517e-02  6.25643730e-02 -1.29750443e+00]\"\n",
      "    num_agent_steps_sampled: 125000\n",
      "    num_agent_steps_trained: 992032\n",
      "    num_steps_sampled: 125000\n",
      "    num_steps_trained: 992032\n",
      "    num_target_updates: 247\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.27619047619048\n",
      "    ram_util_percent: 91.12857142857145\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980906771435245\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.62532678044607\n",
      "    mean_inference_ms: 1.564653345334292\n",
      "    mean_raw_obs_processing_ms: 1.8955202020649977\n",
      "  time_since_restore: 2116.6259229183197\n",
      "  time_this_iter_s: 14.724029541015625\n",
      "  time_total_s: 2116.6259229183197\n",
      "  timers:\n",
      "    learn_throughput: 3812.939\n",
      "    learn_time_ms: 8.392\n",
      "    load_throughput: 65625.723\n",
      "    load_time_ms: 0.488\n",
      "    update_time_ms: 1.746\n",
      "  timestamp: 1632003545\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 125000\n",
      "  training_iteration: 125\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         2116.63</td><td style=\"text-align: right;\">125000</td><td style=\"text-align: right;\">   -1.47</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 126000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-19-19\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.51\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 131\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 125992\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 140.0330810546875\n",
      "          mean_q: 22.694339752197266\n",
      "          min_q: 4.402455806732178\n",
      "        mean_td_error: -0.6348420977592468\n",
      "        td_error: \"[ 5.7121277e-02 -1.1732292e-01  2.3592117e+01 -4.4092026e+00\\n -2.9839062e+01\\\n",
      "          \\ -1.1725307e+00  3.6411762e-02 -1.3013363e-02\\n -3.0952930e-02 -3.8046837e-02\\\n",
      "          \\ -3.4483480e-01 -1.0302517e+01\\n -9.9323273e-02 -5.2494955e-01  9.6160746e-01\\\n",
      "          \\ -2.0381021e-01\\n  7.4131632e-01  4.9260178e+00  7.8700066e-02  1.1756884e+01\\n\\\n",
      "          \\  4.2144985e+00 -1.2615223e+01 -1.1532938e+01  4.0171776e+00\\n  1.2358189e-02\\\n",
      "          \\ -3.0279160e-03  2.0069075e-01 -1.0994148e-01\\n  8.4326887e-01  7.3663282e-01\\\n",
      "          \\ -1.2976646e-02 -1.1200767e+00]\"\n",
      "    num_agent_steps_sampled: 126000\n",
      "    num_agent_steps_trained: 1000032\n",
      "    num_steps_sampled: 126000\n",
      "    num_steps_trained: 1000032\n",
      "    num_target_updates: 249\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.230000000000004\n",
      "    ram_util_percent: 91.66\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039808597874374504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.613122034918621\n",
      "    mean_inference_ms: 1.5645694979110942\n",
      "    mean_raw_obs_processing_ms: 1.9179466709779083\n",
      "  time_since_restore: 2130.6166779994965\n",
      "  time_this_iter_s: 13.990755081176758\n",
      "  time_total_s: 2130.6166779994965\n",
      "  timers:\n",
      "    learn_throughput: 3759.453\n",
      "    learn_time_ms: 8.512\n",
      "    load_throughput: 63373.024\n",
      "    load_time_ms: 0.505\n",
      "    update_time_ms: 1.756\n",
      "  timestamp: 1632003559\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 126000\n",
      "  training_iteration: 126\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         2130.62</td><td style=\"text-align: right;\">126000</td><td style=\"text-align: right;\">   -1.51</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 127000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-19-32\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.57\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 132\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 127000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 153.73216247558594\n",
      "          mean_q: 33.666866302490234\n",
      "          min_q: 4.397109508514404\n",
      "        mean_td_error: 0.6231220364570618\n",
      "        td_error: \"[ 7.34156609e-01  1.15265846e-01  2.33414459e+00 -4.14037704e-03\\n\\\n",
      "          \\  2.73599148e-01 -1.58827972e+00 -2.26886978e+01  3.18119812e+00\\n  1.72153511e+01\\\n",
      "          \\ -3.86667252e-02 -4.35385704e-02  6.59013748e-01\\n  2.04039822e+01  6.81533813e-02\\\n",
      "          \\  1.32800579e-01  1.53877258e-01\\n -6.63985729e+00  1.76265106e+01  1.14440231e+01\\\n",
      "          \\  2.09174633e-01\\n  8.11322021e+00  3.91668797e-01 -3.07274418e+01 -5.98318863e+00\\n\\\n",
      "          \\  3.14382076e-01  2.65592575e-01  7.20171356e+00 -3.49674225e-02\\n -2.11589813e-01\\\n",
      "          \\  1.05156898e-01 -2.53599548e+00 -5.06712437e-01]\"\n",
      "    num_agent_steps_sampled: 127000\n",
      "    num_agent_steps_trained: 1008032\n",
      "    num_steps_sampled: 127000\n",
      "    num_steps_trained: 1008032\n",
      "    num_target_updates: 251\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.363157894736844\n",
      "    ram_util_percent: 91.78421052631579\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980767531676923\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.601298229789242\n",
      "    mean_inference_ms: 1.564474895171537\n",
      "    mean_raw_obs_processing_ms: 1.9403256010863295\n",
      "  time_since_restore: 2143.554243326187\n",
      "  time_this_iter_s: 12.937565326690674\n",
      "  time_total_s: 2143.554243326187\n",
      "  timers:\n",
      "    learn_throughput: 3779.014\n",
      "    learn_time_ms: 8.468\n",
      "    load_throughput: 63658.57\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.763\n",
      "  timestamp: 1632003572\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 127000\n",
      "  training_iteration: 127\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         2143.55</td><td style=\"text-align: right;\">127000</td><td style=\"text-align: right;\">   -1.57</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 128000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-19-45\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.61\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 133\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 127504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 130.22438049316406\n",
      "          mean_q: 17.354448318481445\n",
      "          min_q: 4.5104827880859375\n",
      "        mean_td_error: 2.1769731044769287\n",
      "        td_error: \"[-2.5334406e-01  8.0615044e-02  9.9905968e-02  1.4048147e-01\\n -2.0678711e-01\\\n",
      "          \\  1.5112640e+01  1.3609219e+00  2.2544813e-01\\n  1.4683318e+00 -2.0628223e+00\\\n",
      "          \\  4.5666218e-02  8.8665962e-02\\n -6.6633749e-01 -1.2847066e+00 -8.8176804e+00\\\n",
      "          \\  1.7911530e-01\\n -6.9504786e-01  4.6937752e-01 -9.3008137e-01 -6.1700850e+00\\n\\\n",
      "          \\ -1.5731907e-01  1.0962739e+00  7.2149563e-01 -3.9730549e-02\\n  2.1487408e+00\\\n",
      "          \\ -2.0100174e+01  1.3409233e-01  1.2976122e-01\\n -1.1241865e-01 -1.0801840e+00\\\n",
      "          \\ -3.0198097e-03  8.8741348e+01]\"\n",
      "    num_agent_steps_sampled: 128000\n",
      "    num_agent_steps_trained: 1016032\n",
      "    num_steps_sampled: 128000\n",
      "    num_steps_trained: 1016032\n",
      "    num_target_updates: 252\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.684210526315795\n",
      "    ram_util_percent: 91.53684210526318\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039806361161374856\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.589813160163223\n",
      "    mean_inference_ms: 1.5643692354586856\n",
      "    mean_raw_obs_processing_ms: 1.962647948463853\n",
      "  time_since_restore: 2156.783529281616\n",
      "  time_this_iter_s: 13.229285955429077\n",
      "  time_total_s: 2156.783529281616\n",
      "  timers:\n",
      "    learn_throughput: 3599.546\n",
      "    learn_time_ms: 8.89\n",
      "    load_throughput: 61286.634\n",
      "    load_time_ms: 0.522\n",
      "    update_time_ms: 1.827\n",
      "  timestamp: 1632003585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 128000\n",
      "  training_iteration: 128\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         2156.78</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\">   -1.61</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 129000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-19-58\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 134\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 128512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 157.3710479736328\n",
      "          mean_q: 29.76079750061035\n",
      "          min_q: 4.393553733825684\n",
      "        mean_td_error: 0.7168179601430893\n",
      "        td_error: \"[ 1.65990448e+00 -5.85985661e-01 -1.50390148e-01  9.79285240e-02\\n\\\n",
      "          \\ -1.50923252e-01 -1.02778625e+00  1.11563206e-01  5.10420799e-02\\n  3.49599838e-01\\\n",
      "          \\  8.55908394e-02 -1.03030344e+02  8.34196091e+00\\n  2.16890869e+01  1.11915207e+00\\\n",
      "          \\ -2.14418030e+00  1.31673288e+00\\n -1.33854675e+00  1.20293989e+01 -2.53938675e-01\\\n",
      "          \\  8.36439133e-02\\n -2.34273434e-01  6.64521618e+01  5.74646473e-01  7.09619522e-02\\n\\\n",
      "          \\ -4.87955093e-01  9.79285240e-02 -5.48372269e-02  1.37222004e+00\\n -5.14309502e+00\\\n",
      "          \\  1.72411699e+01  4.83108521e+00 -3.53484154e-02]\"\n",
      "    num_agent_steps_sampled: 129000\n",
      "    num_agent_steps_trained: 1024032\n",
      "    num_steps_sampled: 129000\n",
      "    num_steps_trained: 1024032\n",
      "    num_target_updates: 254\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.93888888888889\n",
      "    ram_util_percent: 91.27777777777777\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980518224874949\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.578851229015804\n",
      "    mean_inference_ms: 1.564269923700149\n",
      "    mean_raw_obs_processing_ms: 1.9849090193997403\n",
      "  time_since_restore: 2169.893526315689\n",
      "  time_this_iter_s: 13.109997034072876\n",
      "  time_total_s: 2169.893526315689\n",
      "  timers:\n",
      "    learn_throughput: 3761.729\n",
      "    learn_time_ms: 8.507\n",
      "    load_throughput: 65899.606\n",
      "    load_time_ms: 0.486\n",
      "    update_time_ms: 1.709\n",
      "  timestamp: 1632003598\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129000\n",
      "  training_iteration: 129\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         2169.89</td><td style=\"text-align: right;\">129000</td><td style=\"text-align: right;\">    -1.6</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 130000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-20-11\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 135\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 129520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 143.21339416503906\n",
      "          mean_q: 27.570688247680664\n",
      "          min_q: 5.676889896392822\n",
      "        mean_td_error: 1.244296669960022\n",
      "        td_error: \"[ -0.33402157 -10.573776     0.4773445    2.6053586   -2.0941353\\n\\\n",
      "          \\  -0.24772644  -0.48948336   1.4327469   12.3013      -0.5565748\\n  -3.8128433\\\n",
      "          \\    0.59499264   0.90169144   0.9408617   25.970268\\n   0.2935338   12.199669\\\n",
      "          \\     0.41272354  -1.0545206    0.11372662\\n   0.06825399   0.06660604  -0.5670996\\\n",
      "          \\    4.708435    16.187538\\n -10.05706     -0.6290293   -3.1143265    0.29054117\\\n",
      "          \\  -3.3648376\\n   0.08734465  -2.9400043 ]\"\n",
      "    num_agent_steps_sampled: 130000\n",
      "    num_agent_steps_trained: 1032032\n",
      "    num_steps_sampled: 130000\n",
      "    num_steps_trained: 1032032\n",
      "    num_target_updates: 256\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.38947368421052\n",
      "    ram_util_percent: 91.16842105263157\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980411195795816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.568341299779219\n",
      "    mean_inference_ms: 1.5641755241413366\n",
      "    mean_raw_obs_processing_ms: 2.007104610107085\n",
      "  time_since_restore: 2182.959887266159\n",
      "  time_this_iter_s: 13.06636095046997\n",
      "  time_total_s: 2182.959887266159\n",
      "  timers:\n",
      "    learn_throughput: 3751.299\n",
      "    learn_time_ms: 8.53\n",
      "    load_throughput: 65539.2\n",
      "    load_time_ms: 0.488\n",
      "    update_time_ms: 1.674\n",
      "  timestamp: 1632003611\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 130000\n",
      "  training_iteration: 130\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         2182.96</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\">    -1.6</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 131000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-20-24\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 136\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 130528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 228.38287353515625\n",
      "          mean_q: 29.906028747558594\n",
      "          min_q: 4.400881767272949\n",
      "        mean_td_error: -6.833395957946777\n",
      "        td_error: \"[ 3.66787910e-02  5.41732712e+01 -3.33318710e-02 -9.79433060e-02\\n\\\n",
      "          \\  3.37457657e-02 -6.72969818e-02 -5.21750679e+01 -2.33113098e+00\\n -9.51426029e-01\\\n",
      "          \\ -2.98962650e+01 -4.90719795e-01 -6.09412994e+01\\n -3.89505863e-01  1.37348175e-02\\\n",
      "          \\ -2.65603065e-02  2.82058525e+00\\n  2.61446190e+00 -1.89906960e+01  8.09049606e-02\\\n",
      "          \\ -6.21910095e-02\\n -2.19962406e+00  5.30729675e+00  1.37755432e+01 -4.48639393e-01\\n\\\n",
      "          \\  3.11929703e-01 -1.27705269e+02  1.59034729e-02  3.66787910e-02\\n -5.47268391e-01\\\n",
      "          \\ -3.54561806e-02 -5.28483868e-01  2.87799835e-02]\"\n",
      "    num_agent_steps_sampled: 131000\n",
      "    num_agent_steps_trained: 1040032\n",
      "    num_steps_sampled: 131000\n",
      "    num_steps_trained: 1040032\n",
      "    num_target_updates: 258\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.3421052631579\n",
      "    ram_util_percent: 91.13684210526314\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039803211155879696\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.558323082665634\n",
      "    mean_inference_ms: 1.564087176857344\n",
      "    mean_raw_obs_processing_ms: 2.029230889147574\n",
      "  time_since_restore: 2196.06861948967\n",
      "  time_this_iter_s: 13.108732223510742\n",
      "  time_total_s: 2196.06861948967\n",
      "  timers:\n",
      "    learn_throughput: 3789.631\n",
      "    learn_time_ms: 8.444\n",
      "    load_throughput: 65408.25\n",
      "    load_time_ms: 0.489\n",
      "    update_time_ms: 1.727\n",
      "  timestamp: 1632003624\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 131000\n",
      "  training_iteration: 131\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         2196.07</td><td style=\"text-align: right;\">131000</td><td style=\"text-align: right;\">    -1.6</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 132000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-20-37\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 137\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 131536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 232.2388916015625\n",
      "          mean_q: 58.04180145263672\n",
      "          min_q: 4.409919738769531\n",
      "        mean_td_error: 0.4654461145401001\n",
      "        td_error: \"[-2.14004517e-03  1.02498055e-01  8.41124535e-01  3.12428474e-02\\n\\\n",
      "          \\  8.23632240e-01  2.62722015e-01 -2.01880951e+01 -2.64411926e-01\\n  3.23005219e+01\\\n",
      "          \\  1.38807297e-01  9.32833862e+00  2.56406307e-01\\n  1.01213989e+01  4.86440277e+00\\\n",
      "          \\  2.39481926e-02 -1.29922199e+00\\n  4.48666143e+00  7.56386757e-01 -1.29202175e+00\\\n",
      "          \\  2.38231659e-01\\n  6.81056213e+00 -3.58323574e-01  4.74128342e+00  4.99863148e-01\\n\\\n",
      "          \\ -7.03618393e+01 -3.11712799e+01  2.28729248e-02 -2.33691216e-01\\n  2.42113342e+01\\\n",
      "          \\  3.17842484e+01  6.98487091e+00  4.33941841e-01]\"\n",
      "    num_agent_steps_sampled: 132000\n",
      "    num_agent_steps_trained: 1048032\n",
      "    num_steps_sampled: 132000\n",
      "    num_steps_trained: 1048032\n",
      "    num_target_updates: 260\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.72222222222222\n",
      "    ram_util_percent: 91.14999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039802410792006276\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.54879358687492\n",
      "    mean_inference_ms: 1.5640038840512525\n",
      "    mean_raw_obs_processing_ms: 2.051283788352476\n",
      "  time_since_restore: 2208.8794729709625\n",
      "  time_this_iter_s: 12.810853481292725\n",
      "  time_total_s: 2208.8794729709625\n",
      "  timers:\n",
      "    learn_throughput: 3821.515\n",
      "    learn_time_ms: 8.374\n",
      "    load_throughput: 64071.858\n",
      "    load_time_ms: 0.499\n",
      "    update_time_ms: 1.651\n",
      "  timestamp: 1632003637\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 132000\n",
      "  training_iteration: 132\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         2208.88</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\">    -1.6</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 133000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-20-49\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 138\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 132544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 281.3479309082031\n",
      "          mean_q: 66.58506774902344\n",
      "          min_q: 4.44781494140625\n",
      "        mean_td_error: -24.05250358581543\n",
      "        td_error: \"[ 4.0814400e-02 -2.1945877e+01 -6.4648209e+01  7.2230196e-01\\n -1.6453505e-01\\\n",
      "          \\ -5.0592899e-02  4.1486692e-01 -1.3331363e+02\\n -2.4866566e+02  2.1725378e+00\\\n",
      "          \\  2.2634792e-01 -1.9487592e+02\\n  1.5349655e+01 -7.0176392e+00  2.3265886e-01\\\n",
      "          \\ -5.4593468e+00\\n -8.0730915e-02  4.4970388e+00 -2.8357941e+01  1.3372903e+00\\n\\\n",
      "          \\ -8.0730915e-02 -3.2910889e+01  9.8680639e-01 -2.4247131e+00\\n  6.8208218e-02\\\n",
      "          \\ -7.9991341e-01 -3.1572372e+01 -3.3222389e+00\\n -5.6154251e-01 -1.8121445e+01\\\n",
      "          \\  3.2301807e-01 -1.6777344e+00]\"\n",
      "    num_agent_steps_sampled: 133000\n",
      "    num_agent_steps_trained: 1056032\n",
      "    num_steps_sampled: 133000\n",
      "    num_steps_trained: 1056032\n",
      "    num_target_updates: 262\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.788888888888884\n",
      "    ram_util_percent: 91.21666666666667\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039801640457168636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.5396317333915\n",
      "    mean_inference_ms: 1.5639242546193044\n",
      "    mean_raw_obs_processing_ms: 2.073260663848282\n",
      "  time_since_restore: 2221.3738362789154\n",
      "  time_this_iter_s: 12.49436330795288\n",
      "  time_total_s: 2221.3738362789154\n",
      "  timers:\n",
      "    learn_throughput: 3812.57\n",
      "    learn_time_ms: 8.393\n",
      "    load_throughput: 66444.42\n",
      "    load_time_ms: 0.482\n",
      "    update_time_ms: 1.71\n",
      "  timestamp: 1632003649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 133000\n",
      "  training_iteration: 133\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         2221.37</td><td style=\"text-align: right;\">133000</td><td style=\"text-align: right;\">    -1.6</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 134000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-21-03\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.6\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 139\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 133552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 172.01730346679688\n",
      "          mean_q: 38.08416748046875\n",
      "          min_q: 7.083944320678711\n",
      "        mean_td_error: -15.9613037109375\n",
      "        td_error: \"[-2.13291397e+01  1.99788761e+01 -8.87417793e-02  1.12881660e-01\\n\\\n",
      "          \\  4.67000961e-01 -1.33841515e-01  9.86137390e-01 -9.71817970e-02\\n  1.81667614e+00\\\n",
      "          \\  1.33610106e+01 -5.09634018e-02 -1.17672386e+01\\n -1.26952133e+01  4.52859421e+01\\\n",
      "          \\ -4.40296173e-01 -8.89231415e+01\\n -1.15492344e-01  5.27563095e-01  7.78665543e-02\\\n",
      "          \\ -1.15492344e-01\\n -4.73072205e+01 -1.14275208e+01 -1.96577873e+01  1.22005653e+01\\n\\\n",
      "          \\ -4.64455223e+00 -8.89231415e+01  1.04305267e-01 -2.23796951e+02\\n  8.87914658e-01\\\n",
      "          \\ -7.18210831e+01 -3.08554077e+00 -1.47967339e-01]\"\n",
      "    num_agent_steps_sampled: 134000\n",
      "    num_agent_steps_trained: 1064032\n",
      "    num_steps_sampled: 134000\n",
      "    num_steps_trained: 1064032\n",
      "    num_target_updates: 264\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.68947368421053\n",
      "    ram_util_percent: 91.38947368421053\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039800930824279546\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.53084004275332\n",
      "    mean_inference_ms: 1.563836044036772\n",
      "    mean_raw_obs_processing_ms: 2.0951585315850902\n",
      "  time_since_restore: 2234.8391082286835\n",
      "  time_this_iter_s: 13.465271949768066\n",
      "  time_total_s: 2234.8391082286835\n",
      "  timers:\n",
      "    learn_throughput: 3685.053\n",
      "    learn_time_ms: 8.684\n",
      "    load_throughput: 65747.883\n",
      "    load_time_ms: 0.487\n",
      "    update_time_ms: 1.751\n",
      "  timestamp: 1632003663\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 134000\n",
      "  training_iteration: 134\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         2234.84</td><td style=\"text-align: right;\">134000</td><td style=\"text-align: right;\">    -1.6</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 135000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-21-15\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.57\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 140\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 134560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 199.70114135742188\n",
      "          mean_q: 37.124183654785156\n",
      "          min_q: 4.404923439025879\n",
      "        mean_td_error: -2.7412545680999756\n",
      "        td_error: \"[ 1.33965302e+00  1.10315847e+00  1.24711037e-01 -1.22563381e+01\\n\\\n",
      "          \\ -5.80367470e+00 -3.34062576e-02 -1.34266319e+01  7.22034454e-01\\n  5.20637512e+00\\\n",
      "          \\  1.50131226e-01 -2.22187805e+00 -1.81460876e+01\\n -7.90606308e+00  8.50725174e-02\\\n",
      "          \\ -2.27318001e+01  1.44915152e+00\\n  3.48652840e-01 -1.68550606e+01  1.29599571e-02\\\n",
      "          \\  1.54750633e+00\\n  1.39075756e-01 -7.03248978e-02  1.06491852e+00 -8.66857529e-01\\n\\\n",
      "          \\  1.31204987e+00  1.03158474e-01  1.10284424e+01  3.12723160e+00\\n -1.86086884e+01\\\n",
      "          \\  1.30084610e+00  9.42109108e-01  9.94329453e-02]\"\n",
      "    num_agent_steps_sampled: 135000\n",
      "    num_agent_steps_trained: 1072032\n",
      "    num_steps_sampled: 135000\n",
      "    num_steps_trained: 1072032\n",
      "    num_target_updates: 266\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.25555555555556\n",
      "    ram_util_percent: 91.60555555555555\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980036272964434\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.522313999005\n",
      "    mean_inference_ms: 1.5637523411435026\n",
      "    mean_raw_obs_processing_ms: 2.1169670669650222\n",
      "  time_since_restore: 2247.181545972824\n",
      "  time_this_iter_s: 12.342437744140625\n",
      "  time_total_s: 2247.181545972824\n",
      "  timers:\n",
      "    learn_throughput: 3754.206\n",
      "    learn_time_ms: 8.524\n",
      "    load_throughput: 65366.838\n",
      "    load_time_ms: 0.49\n",
      "    update_time_ms: 1.692\n",
      "  timestamp: 1632003675\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 135000\n",
      "  training_iteration: 135\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         2247.18</td><td style=\"text-align: right;\">135000</td><td style=\"text-align: right;\">   -1.57</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 136000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-21-29\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.57\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 141\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 135568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 493.87420654296875\n",
      "          mean_q: 68.16954803466797\n",
      "          min_q: 4.563281059265137\n",
      "        mean_td_error: -16.53469467163086\n",
      "        td_error: \"[-1.36323395e+01  7.63998032e-02 -1.39093399e+00  3.67220592e+00\\n\\\n",
      "          \\ -7.08532333e-02 -7.61402321e+00  1.40557814e+00 -1.65819550e+00\\n -1.92967033e+00\\\n",
      "          \\ -8.43672752e-02 -1.53355598e-02 -2.86020813e+01\\n -3.69973564e+00 -1.65075302e-01\\\n",
      "          \\  2.16502190e-01 -1.30649231e+02\\n -1.70201508e+02  1.14453644e+02 -1.35752563e+01\\\n",
      "          \\ -6.70560837e-01\\n -1.48068619e+00 -1.15089331e+01 -6.22286797e-01  1.12467766e-01\\n\\\n",
      "          \\ -3.06899414e+01 -1.63861237e+01 -7.34231853e+00 -1.88411346e+02\\n  5.18283844e-02\\\n",
      "          \\ -2.59658051e+01 -3.44967842e-02  7.30223751e+00]\"\n",
      "    num_agent_steps_sampled: 136000\n",
      "    num_agent_steps_trained: 1080032\n",
      "    num_steps_sampled: 136000\n",
      "    num_steps_trained: 1080032\n",
      "    num_target_updates: 268\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.87368421052632\n",
      "    ram_util_percent: 91.62105263157893\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979988368992549\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.514226226966501\n",
      "    mean_inference_ms: 1.563673969392936\n",
      "    mean_raw_obs_processing_ms: 2.1386897691791136\n",
      "  time_since_restore: 2260.556296110153\n",
      "  time_this_iter_s: 13.374750137329102\n",
      "  time_total_s: 2260.556296110153\n",
      "  timers:\n",
      "    learn_throughput: 3778.493\n",
      "    learn_time_ms: 8.469\n",
      "    load_throughput: 63110.795\n",
      "    load_time_ms: 0.507\n",
      "    update_time_ms: 1.7\n",
      "  timestamp: 1632003689\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 136000\n",
      "  training_iteration: 136\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         2260.56</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\">   -1.57</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 137000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-21-42\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 142\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 136576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 503.5599365234375\n",
      "          mean_q: 70.009033203125\n",
      "          min_q: 4.608743667602539\n",
      "        mean_td_error: -9.721421241760254\n",
      "        td_error: \"[ 1.5287971e-01  1.1102009e-01  1.6353271e+01 -3.1657486e+01\\n  1.5844765e+00\\\n",
      "          \\  2.9537582e-01  1.1336670e+00 -1.3118792e+00\\n  1.0183716e-01  2.8896332e-04\\\n",
      "          \\ -2.1768770e+00  2.0037565e+00\\n -3.9556274e+01 -1.3410339e+01 -2.5715065e-01\\\n",
      "          \\ -2.5773357e+01\\n -6.5616608e-02 -9.8128540e+01 -9.5952415e-01 -1.2063379e+00\\n\\\n",
      "          \\  1.1165109e+00  8.6029530e-02  8.5937500e-02 -3.0164719e-02\\n  1.4383926e+00\\\n",
      "          \\  2.0521164e-02  3.5533714e-01 -5.1181097e+00\\n -1.4350917e+02 -1.6190977e+00\\\n",
      "          \\  2.8769104e+01  8.6029530e-02]\"\n",
      "    num_agent_steps_sampled: 137000\n",
      "    num_agent_steps_trained: 1088032\n",
      "    num_steps_sampled: 137000\n",
      "    num_steps_trained: 1088032\n",
      "    num_target_updates: 270\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.14736842105263\n",
      "    ram_util_percent: 91.65263157894735\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979953876733704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.506401902439539\n",
      "    mean_inference_ms: 1.5635982146153926\n",
      "    mean_raw_obs_processing_ms: 2.1603197611771217\n",
      "  time_since_restore: 2274.0255467891693\n",
      "  time_this_iter_s: 13.469250679016113\n",
      "  time_total_s: 2274.0255467891693\n",
      "  timers:\n",
      "    learn_throughput: 3821.689\n",
      "    learn_time_ms: 8.373\n",
      "    load_throughput: 65034.271\n",
      "    load_time_ms: 0.492\n",
      "    update_time_ms: 1.742\n",
      "  timestamp: 1632003702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 137000\n",
      "  training_iteration: 137\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         2274.03</td><td style=\"text-align: right;\">137000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 138000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-21-56\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 143\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 137584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 643.989990234375\n",
      "          mean_q: 77.16644287109375\n",
      "          min_q: 7.902019500732422\n",
      "        mean_td_error: 3.0512046813964844\n",
      "        td_error: \"[-1.7986259e+00 -1.6308889e+00 -1.5793381e+00  6.2945328e+00\\n  1.2340149e+01\\\n",
      "          \\ -8.1960487e-01  2.1730995e-01  2.1279335e-01\\n -8.8962555e+00  8.5600662e-01\\\n",
      "          \\  3.2338905e-01  1.7397060e+00\\n  8.0120544e+00 -5.7872009e-01 -1.4880820e+02\\\n",
      "          \\  5.2427101e-01\\n -8.8490963e-01 -9.4375702e+01  4.0546322e-01  2.1274323e+01\\n\\\n",
      "          \\ -2.7677250e+01  1.5682301e+01 -4.4818783e-01 -9.0213871e-01\\n  1.0005402e+01\\\n",
      "          \\  9.9437714e-02  1.3049555e-01 -1.6909180e+00\\n  2.6217599e+02  5.5325775e+00\\\n",
      "          \\  4.1538143e+00  3.7749283e+01]\"\n",
      "    num_agent_steps_sampled: 138000\n",
      "    num_agent_steps_trained: 1096032\n",
      "    num_steps_sampled: 138000\n",
      "    num_steps_trained: 1096032\n",
      "    num_target_updates: 272\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.21\n",
      "    ram_util_percent: 91.63999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0397993104161475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.498899120509634\n",
      "    mean_inference_ms: 1.5635260908976236\n",
      "    mean_raw_obs_processing_ms: 2.181859683661337\n",
      "  time_since_restore: 2287.5579805374146\n",
      "  time_this_iter_s: 13.53243374824524\n",
      "  time_total_s: 2287.5579805374146\n",
      "  timers:\n",
      "    learn_throughput: 3770.32\n",
      "    learn_time_ms: 8.487\n",
      "    load_throughput: 66016.294\n",
      "    load_time_ms: 0.485\n",
      "    update_time_ms: 1.718\n",
      "  timestamp: 1632003716\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 138000\n",
      "  training_iteration: 138\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         2287.56</td><td style=\"text-align: right;\">138000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 139000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-22-09\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 144\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 138592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 553.8908081054688\n",
      "          mean_q: 76.44802856445312\n",
      "          min_q: 5.461581230163574\n",
      "        mean_td_error: -6.75589656829834\n",
      "        td_error: \"[-7.0909653e+00  4.7808647e-02 -1.6905304e+01 -1.5049820e+01\\n -6.9725098e+01\\\n",
      "          \\ -6.8455696e-02  1.4737129e-02 -9.2100067e+00\\n  1.5920258e-01 -1.0555553e+00\\\n",
      "          \\  2.6817490e+01 -3.5458649e+01\\n  2.7687740e-01 -2.4295807e-02 -3.0349306e+01\\\n",
      "          \\ -4.1171143e+01\\n  6.8034744e-01 -3.4051132e-01 -9.9981127e+00  6.9579067e+00\\n\\\n",
      "          \\ -7.2669983e-03  8.0852509e-02  3.8466644e-01  4.9070358e-01\\n  2.7828007e+00\\\n",
      "          \\  1.5710068e-01 -1.7118942e+01 -6.6119766e-01\\n -6.7685699e-01  2.9387474e-02\\\n",
      "          \\  2.9232025e-02 -1.8631172e-01]\"\n",
      "    num_agent_steps_sampled: 139000\n",
      "    num_agent_steps_trained: 1104032\n",
      "    num_steps_sampled: 139000\n",
      "    num_steps_trained: 1104032\n",
      "    num_target_updates: 274\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.46842105263158\n",
      "    ram_util_percent: 91.66842105263159\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979909047059901\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.491742917140506\n",
      "    mean_inference_ms: 1.5634582455921293\n",
      "    mean_raw_obs_processing_ms: 2.2033090379641282\n",
      "  time_since_restore: 2301.1874170303345\n",
      "  time_this_iter_s: 13.629436492919922\n",
      "  time_total_s: 2301.1874170303345\n",
      "  timers:\n",
      "    learn_throughput: 3793.894\n",
      "    learn_time_ms: 8.435\n",
      "    load_throughput: 66273.814\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.727\n",
      "  timestamp: 1632003729\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 139000\n",
      "  training_iteration: 139\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         2301.19</td><td style=\"text-align: right;\">139000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 140000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-22-23\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 145\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 139600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 521.1785278320312\n",
      "          mean_q: 79.83258819580078\n",
      "          min_q: 5.705376148223877\n",
      "        mean_td_error: -2.2524412274360657\n",
      "        td_error: \"[ 4.38362427e+01 -3.02483559e-01  3.39034081e-01 -1.93448067e-02\\n\\\n",
      "          \\ -3.10145569e+00 -1.31507492e+00  1.52583122e-01 -8.21527100e+00\\n -4.40602303e-02\\\n",
      "          \\  6.60378647e+00  2.67186737e+00  5.46109009e+00\\n  8.99403381e+01  7.03750610e-01\\\n",
      "          \\  1.31893158e-01  1.74727917e-01\\n -7.88478851e-01  7.03145027e-01 -3.41124659e+01\\\n",
      "          \\  1.61293030e-01\\n  5.70537615e+00 -2.97292709e-01 -3.19461060e+00  3.31273079e-02\\n\\\n",
      "          \\ -2.38525511e+02  3.43273640e-01  5.13753834e+01 -2.67306519e+00\\n -2.16269989e+01\\\n",
      "          \\  9.94092941e-01  3.25089264e+01  2.98062325e-01]\"\n",
      "    num_agent_steps_sampled: 140000\n",
      "    num_agent_steps_trained: 1112032\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 1112032\n",
      "    num_target_updates: 276\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.17\n",
      "    ram_util_percent: 91.72500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979891769875961\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.484861661855135\n",
      "    mean_inference_ms: 1.5633927640958836\n",
      "    mean_raw_obs_processing_ms: 2.2246648596883505\n",
      "  time_since_restore: 2314.8815565109253\n",
      "  time_this_iter_s: 13.69413948059082\n",
      "  time_total_s: 2314.8815565109253\n",
      "  timers:\n",
      "    learn_throughput: 3820.536\n",
      "    learn_time_ms: 8.376\n",
      "    load_throughput: 64105.52\n",
      "    load_time_ms: 0.499\n",
      "    update_time_ms: 1.76\n",
      "  timestamp: 1632003743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 140\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         2314.88</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 141000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-22-38\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 146\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 140608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 306.8804931640625\n",
      "          mean_q: 40.764556884765625\n",
      "          min_q: 6.976559162139893\n",
      "        mean_td_error: -3.376688003540039\n",
      "        td_error: \"[-6.7514515e-01 -1.3272762e-01  1.4896980e+01 -1.0167761e+00\\n -1.4931956e+02\\\n",
      "          \\  7.9567566e+00 -1.0655441e+00  2.8060398e+00\\n -8.2406998e-02 -1.1607752e+00\\\n",
      "          \\  2.2022877e+00  6.1621414e+01\\n -4.2896191e+01 -3.5022736e-01 -1.2281237e+00\\\n",
      "          \\ -6.8670654e-01\\n  8.9876099e+00 -4.5815182e-01 -1.7181559e+00 -8.3276749e-01\\n\\\n",
      "          \\ -1.3045263e+00 -9.3230438e-01  9.1776657e-01  4.3939400e-01\\n -8.0361938e-01\\\n",
      "          \\  1.4170218e+00  1.6913071e+00  1.1713562e+00\\n  3.5278883e+00 -1.0225508e+01\\\n",
      "          \\ -4.4124603e-01 -3.5937357e-01]\"\n",
      "    num_agent_steps_sampled: 141000\n",
      "    num_agent_steps_trained: 1120032\n",
      "    num_steps_sampled: 141000\n",
      "    num_steps_trained: 1120032\n",
      "    num_target_updates: 278\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.735\n",
      "    ram_util_percent: 92.08500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979894704680679\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.478322084056703\n",
      "    mean_inference_ms: 1.5633315343893224\n",
      "    mean_raw_obs_processing_ms: 2.2459262094380623\n",
      "  time_since_restore: 2329.198964357376\n",
      "  time_this_iter_s: 14.317407846450806\n",
      "  time_total_s: 2329.198964357376\n",
      "  timers:\n",
      "    learn_throughput: 3792.661\n",
      "    learn_time_ms: 8.437\n",
      "    load_throughput: 60753.996\n",
      "    load_time_ms: 0.527\n",
      "    update_time_ms: 1.751\n",
      "  timestamp: 1632003758\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 141000\n",
      "  training_iteration: 141\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">          2329.2</td><td style=\"text-align: right;\">141000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 142000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-22-52\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 147\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 141616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 576.760009765625\n",
      "          mean_q: 66.59203338623047\n",
      "          min_q: 8.0011625289917\n",
      "        mean_td_error: -6.038294315338135\n",
      "        td_error: \"[ 1.68317986e+00 -1.67737961e-01  1.17758179e+00  9.20452118e-01\\n\\\n",
      "          \\ -2.26180450e+02 -1.10720634e-01  2.62359428e+00  2.69625854e+00\\n -2.67115593e-01\\\n",
      "          \\ -7.46213913e-01 -6.29575729e-01  2.74048126e+02\\n  1.46501541e-01  1.20773529e+02\\\n",
      "          \\ -8.41672611e+00 -1.08211189e+02\\n -2.34400787e+01 -3.70606155e+01  2.15929031e+00\\\n",
      "          \\ -1.20689484e+02\\n -1.65059090e-01 -6.77821159e-01  1.24916077e-01 -5.67871094e-01\\n\\\n",
      "          \\ -1.67225647e+00 -1.24307346e+00 -1.13493824e+00 -1.30463600e-01\\n  1.39526558e+00\\\n",
      "          \\ -1.85183525e-01 -6.78150864e+01 -1.46245480e+00]\"\n",
      "    num_agent_steps_sampled: 142000\n",
      "    num_agent_steps_trained: 1128032\n",
      "    num_steps_sampled: 142000\n",
      "    num_steps_trained: 1128032\n",
      "    num_target_updates: 280\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.68\n",
      "    ram_util_percent: 92.085\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979905551363017\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.472051412362674\n",
      "    mean_inference_ms: 1.5632750380086105\n",
      "    mean_raw_obs_processing_ms: 2.2670922713732082\n",
      "  time_since_restore: 2343.1777226924896\n",
      "  time_this_iter_s: 13.978758335113525\n",
      "  time_total_s: 2343.1777226924896\n",
      "  timers:\n",
      "    learn_throughput: 3824.499\n",
      "    learn_time_ms: 8.367\n",
      "    load_throughput: 65376.39\n",
      "    load_time_ms: 0.489\n",
      "    update_time_ms: 1.682\n",
      "  timestamp: 1632003772\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 142000\n",
      "  training_iteration: 142\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         2343.18</td><td style=\"text-align: right;\">142000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 143000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-23-05\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 148\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 142624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1220.16455078125\n",
      "          mean_q: 74.60267639160156\n",
      "          min_q: 7.277467250823975\n",
      "        mean_td_error: -3.822328567504883\n",
      "        td_error: \"[ 2.9599190e-02 -9.2009354e-01 -1.3942051e-01  3.7688255e-01\\n -1.5695129e+01\\\n",
      "          \\  1.6099548e-01  6.6012604e+01  1.8981075e-01\\n  7.0980103e+01 -1.3949030e+01\\\n",
      "          \\ -6.9472275e+01  3.5951805e-01\\n  1.1724548e+00  2.8203011e-01 -3.0353851e+00\\\n",
      "          \\ -9.4838867e+01\\n -6.7683887e-01  2.5266075e-01  5.8805132e-01 -3.9958954e-03\\n\\\n",
      "          \\ -3.2863693e+00 -6.7623566e+01  1.6967731e+01 -7.0121956e-01\\n -5.0917721e-01\\\n",
      "          \\  4.1265488e-01 -1.1528492e-01 -6.5568771e+00\\n  1.0967703e+00  3.0905104e-01\\\n",
      "          \\ -2.3230743e+00 -1.6588278e+00]\"\n",
      "    num_agent_steps_sampled: 143000\n",
      "    num_agent_steps_trained: 1136032\n",
      "    num_steps_sampled: 143000\n",
      "    num_steps_trained: 1136032\n",
      "    num_target_updates: 282\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.27499999999999\n",
      "    ram_util_percent: 91.97000000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979919294254671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.466053310722668\n",
      "    mean_inference_ms: 1.5632219341476559\n",
      "    mean_raw_obs_processing_ms: 2.288161537368861\n",
      "  time_since_restore: 2356.902119874954\n",
      "  time_this_iter_s: 13.7243971824646\n",
      "  time_total_s: 2356.902119874954\n",
      "  timers:\n",
      "    learn_throughput: 3802.514\n",
      "    learn_time_ms: 8.415\n",
      "    load_throughput: 66411.543\n",
      "    load_time_ms: 0.482\n",
      "    update_time_ms: 1.718\n",
      "  timestamp: 1632003785\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 143000\n",
      "  training_iteration: 143\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">          2356.9</td><td style=\"text-align: right;\">143000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 144000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-23-19\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 149\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 143632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1515.52783203125\n",
      "          mean_q: 115.62915802001953\n",
      "          min_q: 7.157209873199463\n",
      "        mean_td_error: -4.114800930023193\n",
      "        td_error: \"[-1.9483618e+01 -5.8464935e+01  3.4769440e-01 -4.1847420e-01\\n  9.7570839e+01\\\n",
      "          \\  1.0176277e-01  6.3782120e-01 -5.9731293e-01\\n -2.1746950e+00  8.1259171e+01\\\n",
      "          \\ -6.1333313e+00  1.2569977e+01\\n  1.3094721e+00  1.2955078e+01 -5.9542881e+01\\\n",
      "          \\ -3.1738586e+00\\n -2.0454016e+00  6.1174774e+00 -2.5867676e+01  1.1953421e+00\\n\\\n",
      "          \\ -7.5607300e-02 -1.3505626e+02 -9.3203545e-01 -5.8725723e+01\\n  2.0640694e+01\\\n",
      "          \\ -2.0343304e-02  8.4176922e-01  2.8833008e-01\\n  1.6326904e-03 -4.7791290e-01\\\n",
      "          \\ -1.6117554e+00  7.2911530e+00]\"\n",
      "    num_agent_steps_sampled: 144000\n",
      "    num_agent_steps_trained: 1144032\n",
      "    num_steps_sampled: 144000\n",
      "    num_steps_trained: 1144032\n",
      "    num_target_updates: 284\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.805263157894736\n",
      "    ram_util_percent: 92.12631578947367\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039799366178323754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.46034975217028\n",
      "    mean_inference_ms: 1.563172284412037\n",
      "    mean_raw_obs_processing_ms: 2.3091342613691084\n",
      "  time_since_restore: 2370.4889829158783\n",
      "  time_this_iter_s: 13.586863040924072\n",
      "  time_total_s: 2370.4889829158783\n",
      "  timers:\n",
      "    learn_throughput: 3840.278\n",
      "    learn_time_ms: 8.333\n",
      "    load_throughput: 65612.89\n",
      "    load_time_ms: 0.488\n",
      "    update_time_ms: 1.7\n",
      "  timestamp: 1632003799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 144000\n",
      "  training_iteration: 144\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         2370.49</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 145000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-23-32\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 150\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 144640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 463.1691589355469\n",
      "          mean_q: 64.67225646972656\n",
      "          min_q: 9.468818664550781\n",
      "        mean_td_error: -9.057037353515625\n",
      "        td_error: \"[ 9.8294830e-01  4.6783142e+00  1.4616509e+01 -2.1000137e+00\\n -1.2575615e+01\\\n",
      "          \\ -2.1692648e+00  2.1397686e-01 -3.2080860e+00\\n -7.9036522e-01 -9.4093323e-01\\\n",
      "          \\ -1.6005707e+00 -1.9035473e+00\\n -4.4056702e-01  1.8278885e-01  1.7235632e+00\\\n",
      "          \\  1.8753815e-01\\n -3.2669067e-02 -1.9434967e+01 -1.4302115e+02  5.1832520e+01\\n\\\n",
      "          \\  1.1731625e+00 -7.5757141e+00  3.5132507e+01  3.0811188e+01\\n -1.6971289e+02\\\n",
      "          \\ -6.9316864e-02  1.2598467e+00 -2.2604256e+00\\n  2.2257042e-01 -4.1902237e+01\\\n",
      "          \\ -1.3719475e+01 -9.3848324e+00]\"\n",
      "    num_agent_steps_sampled: 145000\n",
      "    num_agent_steps_trained: 1152032\n",
      "    num_steps_sampled: 145000\n",
      "    num_steps_trained: 1152032\n",
      "    num_target_updates: 286\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.16842105263158\n",
      "    ram_util_percent: 92.14736842105262\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979956229812304\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.454858555171862\n",
      "    mean_inference_ms: 1.563121653765214\n",
      "    mean_raw_obs_processing_ms: 2.3300090867957035\n",
      "  time_since_restore: 2383.8317637443542\n",
      "  time_this_iter_s: 13.342780828475952\n",
      "  time_total_s: 2383.8317637443542\n",
      "  timers:\n",
      "    learn_throughput: 3767.029\n",
      "    learn_time_ms: 8.495\n",
      "    load_throughput: 64733.157\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.749\n",
      "  timestamp: 1632003812\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 145000\n",
      "  training_iteration: 145\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         2383.83</td><td style=\"text-align: right;\">145000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 146000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-23-46\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 151\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 145648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 278.091552734375\n",
      "          mean_q: 50.61871337890625\n",
      "          min_q: 10.531462669372559\n",
      "        mean_td_error: 5.710849046707153\n",
      "        td_error: \"[ 3.54875851e+00  6.93782043e+01  1.11828232e+00  8.88366699e-02\\n\\\n",
      "          \\ -6.88156128e-01 -7.23104477e-01  1.49864197e-01 -3.61019516e+00\\n  2.36019135e-01\\\n",
      "          \\ -3.68103027e-01  3.76203537e-01  2.01286697e+01\\n -5.68010712e+00 -8.12683105e-02\\\n",
      "          \\ -5.67188263e-02  2.89916992e-03\\n  1.82722092e-01 -9.69842911e+00 -1.27721786e+00\\\n",
      "          \\ -6.76898956e-02\\n -8.77098083e-01 -5.42856216e-01  4.06718254e-01  1.18535995e+00\\n\\\n",
      "          \\ -5.37429810e-01 -1.01224899e+00  4.29498749e+01 -2.37816811e-01\\n  1.44489384e+00\\\n",
      "          \\  9.17457390e+00  5.78057404e+01  2.79884338e-02]\"\n",
      "    num_agent_steps_sampled: 146000\n",
      "    num_agent_steps_trained: 1160032\n",
      "    num_steps_sampled: 146000\n",
      "    num_steps_trained: 1160032\n",
      "    num_target_updates: 288\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.614999999999995\n",
      "    ram_util_percent: 92.11999999999998\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039799782036723776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.449589542105\n",
      "    mean_inference_ms: 1.563073201625003\n",
      "    mean_raw_obs_processing_ms: 2.3507864296937604\n",
      "  time_since_restore: 2397.4152839183807\n",
      "  time_this_iter_s: 13.58352017402649\n",
      "  time_total_s: 2397.4152839183807\n",
      "  timers:\n",
      "    learn_throughput: 3793.315\n",
      "    learn_time_ms: 8.436\n",
      "    load_throughput: 64798.787\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.695\n",
      "  timestamp: 1632003826\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 146000\n",
      "  training_iteration: 146\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         2397.42</td><td style=\"text-align: right;\">146000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 147000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-24-00\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 152\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 146656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 489.897216796875\n",
      "          mean_q: 78.93779754638672\n",
      "          min_q: 8.862565040588379\n",
      "        mean_td_error: 9.143287658691406\n",
      "        td_error: \"[ 1.8391113e+00  2.6453304e-01  1.1009064e+01 -4.2652702e-01\\n -4.1143131e-01\\\n",
      "          \\ -1.7222977e-01 -2.6001167e-01  7.4000931e-01\\n  7.3517246e+00  1.6858025e+00\\\n",
      "          \\  2.4667465e+01  4.9179935e-01\\n  3.9349419e+01  3.1224945e+01 -5.2714157e+00\\\n",
      "          \\ -1.5466034e+01\\n  7.0293808e-01  3.9140701e-02  4.1113281e-01 -1.6306793e+01\\n\\\n",
      "          \\  5.2656670e+00  1.5085163e+00  5.8587822e+01  1.3213539e-01\\n  7.6917648e-01\\\n",
      "          \\  2.5037994e+00  2.9599953e-01  1.1481984e+02\\n  1.0686779e+00 -5.3655624e-02\\\n",
      "          \\  5.7127857e-01  2.5653320e+01]\"\n",
      "    num_agent_steps_sampled: 147000\n",
      "    num_agent_steps_trained: 1168032\n",
      "    num_steps_sampled: 147000\n",
      "    num_steps_trained: 1168032\n",
      "    num_target_updates: 290\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.13157894736842\n",
      "    ram_util_percent: 92.23157894736843\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979996700536892\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.44466988621533\n",
      "    mean_inference_ms: 1.563028628885737\n",
      "    mean_raw_obs_processing_ms: 2.3714651665531763\n",
      "  time_since_restore: 2411.21706199646\n",
      "  time_this_iter_s: 13.801778078079224\n",
      "  time_total_s: 2411.21706199646\n",
      "  timers:\n",
      "    learn_throughput: 3786.039\n",
      "    learn_time_ms: 8.452\n",
      "    load_throughput: 65211.218\n",
      "    load_time_ms: 0.491\n",
      "    update_time_ms: 1.703\n",
      "  timestamp: 1632003840\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 147000\n",
      "  training_iteration: 147\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         2411.22</td><td style=\"text-align: right;\">147000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 148000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-24-14\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 153\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 147664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 725.5162353515625\n",
      "          mean_q: 65.88900756835938\n",
      "          min_q: 9.49797534942627\n",
      "        mean_td_error: 3.3126277923583984\n",
      "        td_error: \"[ 2.2894764e-01  1.8089301e+02  3.4914017e-03 -3.4182762e+01\\n  2.3294964e+00\\\n",
      "          \\  3.4914017e-03  5.2784920e-02  7.4597359e-01\\n  5.1174164e-03 -9.6123791e-01\\\n",
      "          \\  6.1544800e-01  1.3940281e+01\\n  6.8497658e-02 -6.6108322e-01  3.6769028e+01\\\n",
      "          \\  5.7642937e-01\\n  9.3127251e-01 -2.6325279e+01 -5.9739662e+01  2.7357445e+00\\n\\\n",
      "          \\  1.0637283e-02  1.5356884e+00 -3.5917664e-01  8.6359024e-02\\n  3.5465393e+00\\\n",
      "          \\  8.3150864e-02 -2.1338158e+00 -1.4040632e+00\\n -1.2148529e+01 -4.1115112e+00\\\n",
      "          \\  2.5852203e-01  2.6113243e+00]\"\n",
      "    num_agent_steps_sampled: 148000\n",
      "    num_agent_steps_trained: 1176032\n",
      "    num_steps_sampled: 148000\n",
      "    num_steps_trained: 1176032\n",
      "    num_target_updates: 292\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.275\n",
      "    ram_util_percent: 92.25\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980006393761641\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.440006529523497\n",
      "    mean_inference_ms: 1.5629813100883476\n",
      "    mean_raw_obs_processing_ms: 2.3920436805064638\n",
      "  time_since_restore: 2425.2430760860443\n",
      "  time_this_iter_s: 14.02601408958435\n",
      "  time_total_s: 2425.2430760860443\n",
      "  timers:\n",
      "    learn_throughput: 3733.746\n",
      "    learn_time_ms: 8.57\n",
      "    load_throughput: 63589.202\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.761\n",
      "  timestamp: 1632003854\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 148000\n",
      "  training_iteration: 148\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         2425.24</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 149000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 154\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 148672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2068.56396484375\n",
      "          mean_q: 205.95596313476562\n",
      "          min_q: 10.706277847290039\n",
      "        mean_td_error: -19.151592254638672\n",
      "        td_error: \"[-3.4098846e+01  3.0485153e-02  8.4907227e+00  4.5855713e+01\\n -4.9907207e-01\\\n",
      "          \\ -9.1204348e+00 -5.1201294e+01 -8.7647247e-01\\n  1.6125488e-01 -1.4004993e-01\\\n",
      "          \\  1.5950775e-01  4.7077370e-01\\n -5.6225586e-01  6.0791016e-02 -9.8380585e+00\\\n",
      "          \\ -4.4689697e+01\\n  5.1761627e-02 -1.1246681e-01 -4.9891052e+01 -6.6853142e-01\\n\\\n",
      "          \\  1.1144638e-01 -1.2369785e+00 -3.1000710e-01 -5.0218658e+02\\n -6.0385895e+00\\\n",
      "          \\ -1.8021297e-01 -1.1704010e+01 -4.1648865e-02\\n -7.5765984e+01  4.3298721e-02\\\n",
      "          \\  9.1121124e+01  3.9754379e+01]\"\n",
      "    num_agent_steps_sampled: 149000\n",
      "    num_agent_steps_trained: 1184032\n",
      "    num_steps_sampled: 149000\n",
      "    num_steps_trained: 1184032\n",
      "    num_target_updates: 294\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.209999999999994\n",
      "    ram_util_percent: 92.33\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980018330321463\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.435534799695747\n",
      "    mean_inference_ms: 1.5629340271688685\n",
      "    mean_raw_obs_processing_ms: 2.4125200592027185\n",
      "  time_since_restore: 2439.1874163150787\n",
      "  time_this_iter_s: 13.944340229034424\n",
      "  time_total_s: 2439.1874163150787\n",
      "  timers:\n",
      "    learn_throughput: 3776.558\n",
      "    learn_time_ms: 8.473\n",
      "    load_throughput: 65176.384\n",
      "    load_time_ms: 0.491\n",
      "    update_time_ms: 1.767\n",
      "  timestamp: 1632003868\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 149000\n",
      "  training_iteration: 149\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         2439.19</td><td style=\"text-align: right;\">149000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 150000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-24-42\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.53\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 155\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 149680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1149.2470703125\n",
      "          mean_q: 143.0561981201172\n",
      "          min_q: 13.051963806152344\n",
      "        mean_td_error: -0.7921695709228516\n",
      "        td_error: \"[-2.5551605e-01 -7.2691994e+00 -1.0362152e+01  9.1770172e-02\\n -3.9911728e+01\\\n",
      "          \\  1.7716660e+01  7.3879791e+01 -1.0917801e+02\\n  2.2664261e-01 -3.8656807e-01\\\n",
      "          \\ -2.1181384e+02  1.8288612e-01\\n -1.9678688e+01 -6.8282318e+00  6.6889038e+00\\\n",
      "          \\ -8.8530731e-01\\n  1.3457581e+01 -3.0259401e+01 -1.6140232e+00  7.0039749e-02\\n\\\n",
      "          \\  3.4989960e+02  1.8111076e+00 -1.3945887e+01 -2.5856972e-01\\n -1.6860390e-01\\\n",
      "          \\ -1.4209244e+01 -8.9720764e+00  1.3382187e+00\\n -6.3098907e-02  4.7109108e+01\\\n",
      "          \\ -2.0165653e+01 -4.1595932e+01]\"\n",
      "    num_agent_steps_sampled: 150000\n",
      "    num_agent_steps_trained: 1192032\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 1192032\n",
      "    num_target_updates: 296\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.445\n",
      "    ram_util_percent: 92.3\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980035341357131\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.431225499537124\n",
      "    mean_inference_ms: 1.5628866257635667\n",
      "    mean_raw_obs_processing_ms: 2.4328968861485523\n",
      "  time_since_restore: 2453.2310962677\n",
      "  time_this_iter_s: 14.04367995262146\n",
      "  time_total_s: 2453.2310962677\n",
      "  timers:\n",
      "    learn_throughput: 3739.718\n",
      "    learn_time_ms: 8.557\n",
      "    load_throughput: 64219.009\n",
      "    load_time_ms: 0.498\n",
      "    update_time_ms: 1.707\n",
      "  timestamp: 1632003882\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 150\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         2453.23</td><td style=\"text-align: right;\">150000</td><td style=\"text-align: right;\">   -1.53</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 151000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-24-55\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.49\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 156\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 150688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1231.4139404296875\n",
      "          mean_q: 211.2568359375\n",
      "          min_q: 13.984960556030273\n",
      "        mean_td_error: -59.25897216796875\n",
      "        td_error: \"[-5.0957263e+02  9.8135376e-01  3.8835526e-01 -6.0867120e+02\\n  6.6940918e+00\\\n",
      "          \\  2.4790619e+01 -1.7397308e-01  7.3856659e+00\\n -3.4508014e+02 -3.3976173e-01\\\n",
      "          \\ -4.2327881e-02  3.0239105e-01\\n -3.8907814e-01 -3.7870789e-01 -1.2035242e+02\\\n",
      "          \\  1.1767212e+01\\n -3.1364517e+00 -4.2622510e+02  3.2632515e+01  6.2467331e+01\\n\\\n",
      "          \\ -1.2128784e+01 -3.8564491e-01 -7.5695435e+01  1.4865208e-01\\n -2.0211439e+00\\\n",
      "          \\  2.8827286e-01 -6.2278717e+01  1.6541290e-01\\n  3.7042618e-02  3.5027191e+01\\\n",
      "          \\  4.4883728e-02  8.7463440e+01]\"\n",
      "    num_agent_steps_sampled: 151000\n",
      "    num_agent_steps_trained: 1200032\n",
      "    num_steps_sampled: 151000\n",
      "    num_steps_trained: 1200032\n",
      "    num_target_updates: 298\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.485\n",
      "    ram_util_percent: 92.23999999999998\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039800540727056355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.426989045645861\n",
      "    mean_inference_ms: 1.5628385654443526\n",
      "    mean_raw_obs_processing_ms: 2.4531719104313283\n",
      "  time_since_restore: 2466.805854320526\n",
      "  time_this_iter_s: 13.574758052825928\n",
      "  time_total_s: 2466.805854320526\n",
      "  timers:\n",
      "    learn_throughput: 3792.211\n",
      "    learn_time_ms: 8.438\n",
      "    load_throughput: 64308.24\n",
      "    load_time_ms: 0.498\n",
      "    update_time_ms: 1.739\n",
      "  timestamp: 1632003895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 151000\n",
      "  training_iteration: 151\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         2466.81</td><td style=\"text-align: right;\">151000</td><td style=\"text-align: right;\">   -1.49</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 152000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.42\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 157\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 151696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 996.1002807617188\n",
      "          mean_q: 122.8163070678711\n",
      "          min_q: 14.37661361694336\n",
      "        mean_td_error: -12.402143478393555\n",
      "        td_error: \"[-1.7475128e-02  2.0240784e-01 -1.7774002e+01  7.8368759e-01\\n  5.9998894e-01\\\n",
      "          \\  9.0307236e-02  8.8840027e+00  1.1309242e-01\\n -6.3673019e-02 -3.8562393e-01\\\n",
      "          \\ -6.6247940e-01  1.7457726e+01\\n -1.3631232e+02 -5.6952698e+01 -6.2047195e-01\\\n",
      "          \\  6.9200516e-02\\n  1.5921593e-01 -1.8702316e-01  4.5196030e+01 -2.8108365e+02\\n\\\n",
      "          \\ -2.2996521e-01 -4.4090881e+00  1.4915085e-01 -2.1937103e+00\\n -4.6337128e-02\\\n",
      "          \\  2.3148727e-01 -1.6390991e-01 -3.6029663e+00\\n  1.2977982e-01 -1.0528183e-01\\\n",
      "          \\  3.4189728e+01 -3.1373024e-01]\"\n",
      "    num_agent_steps_sampled: 152000\n",
      "    num_agent_steps_trained: 1208032\n",
      "    num_steps_sampled: 152000\n",
      "    num_steps_trained: 1208032\n",
      "    num_target_updates: 300\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.62105263157895\n",
      "    ram_util_percent: 92.13684210526314\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980060278337145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.422811571797103\n",
      "    mean_inference_ms: 1.5627869712639235\n",
      "    mean_raw_obs_processing_ms: 2.4733455280899004\n",
      "  time_since_restore: 2480.208231687546\n",
      "  time_this_iter_s: 13.402377367019653\n",
      "  time_total_s: 2480.208231687546\n",
      "  timers:\n",
      "    learn_throughput: 3764.599\n",
      "    learn_time_ms: 8.5\n",
      "    load_throughput: 63694.822\n",
      "    load_time_ms: 0.502\n",
      "    update_time_ms: 1.729\n",
      "  timestamp: 1632003909\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 152000\n",
      "  training_iteration: 152\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         2480.21</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\">   -1.42</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 153000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-25-22\n",
      "  done: false\n",
      "  episode_len_mean: 948.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.34\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 158\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 152704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1393.9150390625\n",
      "          mean_q: 134.62989807128906\n",
      "          min_q: 12.110156059265137\n",
      "        mean_td_error: 10.003263473510742\n",
      "        td_error: \"[ 3.57933044e-02 -1.05288017e+02 -1.06695465e+02 -9.17359924e+00\\n\\\n",
      "          \\ -5.63162231e+00 -5.27601242e-01  5.09214401e-01 -9.93368149e-01\\n  4.94326172e+01\\\n",
      "          \\  4.34814453e+01 -5.42867661e-01 -2.99253464e-01\\n -1.97563171e-02  4.31561127e+01\\\n",
      "          \\  2.14941978e-01 -2.20512390e-01\\n -1.24779701e-01  6.10528488e+01  2.14941978e-01\\\n",
      "          \\  4.80897408e+01\\n  1.37981476e+02 -1.28768921e-01 -1.15037918e-01 -6.49856567e-01\\n\\\n",
      "          \\  4.83630180e-01 -5.94682693e-01  2.44832039e-01 -1.46119690e+00\\n  8.07502747e+00\\\n",
      "          \\ -3.87550354e-01  1.60512939e+02 -5.27160645e-01]\"\n",
      "    num_agent_steps_sampled: 153000\n",
      "    num_agent_steps_trained: 1216032\n",
      "    num_steps_sampled: 153000\n",
      "    num_steps_trained: 1216032\n",
      "    num_target_updates: 302\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.210526315789465\n",
      "    ram_util_percent: 92.07894736842105\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0398005839973954\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.418725269883183\n",
      "    mean_inference_ms: 1.5627324250080716\n",
      "    mean_raw_obs_processing_ms: 2.493416984615929\n",
      "  time_since_restore: 2493.7260842323303\n",
      "  time_this_iter_s: 13.517852544784546\n",
      "  time_total_s: 2493.7260842323303\n",
      "  timers:\n",
      "    learn_throughput: 3798.242\n",
      "    learn_time_ms: 8.425\n",
      "    load_throughput: 62444.277\n",
      "    load_time_ms: 0.512\n",
      "    update_time_ms: 1.672\n",
      "  timestamp: 1632003922\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 153000\n",
      "  training_iteration: 153\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         2493.73</td><td style=\"text-align: right;\">153000</td><td style=\"text-align: right;\">   -1.34</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            948.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 154000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-25-53\n",
      "  done: false\n",
      "  episode_len_mean: 947.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.29\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 159\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 153712\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1992.997802734375\n",
      "          mean_q: 246.87750244140625\n",
      "          min_q: 12.505291938781738\n",
      "        mean_td_error: -14.795320510864258\n",
      "        td_error: \"[-3.49168777e-01 -2.60715485e-01  6.74560547e-01 -3.55745316e-01\\n\\\n",
      "          \\  9.62404861e+01  5.18431396e+01 -1.19168396e+02 -1.23107681e+02\\n -8.88760986e+01\\\n",
      "          \\  7.25891113e-01  7.72199707e+01 -1.23368179e+02\\n -3.93367767e-01  3.97872925e-02\\\n",
      "          \\ -1.75783234e+01 -1.36250214e+02\\n -3.26707306e+01 -9.10129547e-02  1.48675919e-01\\\n",
      "          \\ -2.22167236e+02\\n  1.00591919e+02 -1.82257614e+01 -1.22843361e+00  1.38188477e+01\\n\\\n",
      "          \\ -2.03613663e+00  6.49286041e+01  4.18024063e-02 -4.12645340e-02\\n -1.89666748e-01\\\n",
      "          \\ -2.32109070e-01  7.89160919e+00 -1.02530861e+00]\"\n",
      "    num_agent_steps_sampled: 154000\n",
      "    num_agent_steps_trained: 1224032\n",
      "    num_steps_sampled: 154000\n",
      "    num_steps_trained: 1224032\n",
      "    num_target_updates: 304\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.29545454545455\n",
      "    ram_util_percent: 91.84090909090911\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039800458890305354\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.414743951911241\n",
      "    mean_inference_ms: 1.5626740355600446\n",
      "    mean_raw_obs_processing_ms: 2.514448047590641\n",
      "  time_since_restore: 2524.0738813877106\n",
      "  time_this_iter_s: 30.34779715538025\n",
      "  time_total_s: 2524.0738813877106\n",
      "  timers:\n",
      "    learn_throughput: 3774.837\n",
      "    learn_time_ms: 8.477\n",
      "    load_throughput: 62496.614\n",
      "    load_time_ms: 0.512\n",
      "    update_time_ms: 1.761\n",
      "  timestamp: 1632003953\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 154000\n",
      "  training_iteration: 154\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         2524.07</td><td style=\"text-align: right;\">154000</td><td style=\"text-align: right;\">   -1.29</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">            947.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 155000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-26-08\n",
      "  done: false\n",
      "  episode_len_mean: 952.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.28\n",
      "  episode_reward_min: -13.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 160\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 154720\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2495.2822265625\n",
      "          mean_q: 339.42755126953125\n",
      "          min_q: 13.888855934143066\n",
      "        mean_td_error: 17.832822799682617\n",
      "        td_error: \"[-2.39486694e-02  6.55610046e+01  4.99398804e+00  1.55467987e-01\\n\\\n",
      "          \\  9.25764084e-01  3.58090210e+00 -2.69510193e+01 -1.52780533e-01\\n -5.78616714e+00\\\n",
      "          \\ -4.75472641e+01  4.86398697e-01  4.59678650e-01\\n  8.57591629e-01  3.79802246e+01\\\n",
      "          \\  3.34284973e+01 -1.54002075e+01\\n  1.47234924e+02 -4.87899780e-03 -3.72409821e-02\\\n",
      "          \\  3.50761414e-03\\n  4.05682564e+01  6.06916428e-01  7.73372650e-02  9.05132294e-02\\n\\\n",
      "          \\ -1.03003296e+02  1.52325989e+02  6.25074463e+01  2.14362000e+02\\n -2.56210327e-01\\\n",
      "          \\ -1.12989426e-01  3.37093353e+00  3.49042892e-01]\"\n",
      "    num_agent_steps_sampled: 155000\n",
      "    num_agent_steps_trained: 1232032\n",
      "    num_steps_sampled: 155000\n",
      "    num_steps_trained: 1232032\n",
      "    num_target_updates: 306\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.08571428571429\n",
      "    ram_util_percent: 91.43809523809523\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039800217238815855\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.410952386554516\n",
      "    mean_inference_ms: 1.5626125640175226\n",
      "    mean_raw_obs_processing_ms: 2.528341475204135\n",
      "  time_since_restore: 2539.1370372772217\n",
      "  time_this_iter_s: 15.063155889511108\n",
      "  time_total_s: 2539.1370372772217\n",
      "  timers:\n",
      "    learn_throughput: 3795.514\n",
      "    learn_time_ms: 8.431\n",
      "    load_throughput: 61466.261\n",
      "    load_time_ms: 0.521\n",
      "    update_time_ms: 1.77\n",
      "  timestamp: 1632003968\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 155000\n",
      "  training_iteration: 155\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         2539.14</td><td style=\"text-align: right;\">155000</td><td style=\"text-align: right;\">   -1.28</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                 -13</td><td style=\"text-align: right;\">             952.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 156000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-26-21\n",
      "  done: false\n",
      "  episode_len_mean: 952.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.15\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 161\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 155728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 963.393798828125\n",
      "          mean_q: 180.96278381347656\n",
      "          min_q: 15.037729263305664\n",
      "        mean_td_error: -42.53903579711914\n",
      "        td_error: \"[ 5.0020218e-03 -1.6011395e+02 -1.1930408e+00  4.3701839e-01\\n -2.5136804e+02\\\n",
      "          \\ -1.7512646e+00  1.1452426e+02 -4.0804863e-02\\n -4.7200012e-01  7.7711105e-02\\\n",
      "          \\ -1.0450718e+03  1.3235474e-01\\n -2.8005585e+01 -1.5387827e+02  4.5182228e-01\\\n",
      "          \\  8.9842133e+01\\n -1.1572815e+01 -1.6436462e+00  1.8015622e+02  1.3105866e+01\\n\\\n",
      "          \\ -6.2086670e+01 -5.8229084e+00  1.2774567e+01 -9.2855167e-01\\n -4.6849251e-01\\\n",
      "          \\  1.3378143e-01  3.7935669e+01 -1.6436462e+00\\n  1.1538200e+00  6.6661835e-02\\\n",
      "          \\  1.6006575e+00 -8.7585220e+01]\"\n",
      "    num_agent_steps_sampled: 156000\n",
      "    num_agent_steps_trained: 1240032\n",
      "    num_steps_sampled: 156000\n",
      "    num_steps_trained: 1240032\n",
      "    num_target_updates: 308\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.825\n",
      "    ram_util_percent: 91.72500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980001280523151\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.406967904897451\n",
      "    mean_inference_ms: 1.5625510885393112\n",
      "    mean_raw_obs_processing_ms: 2.5422432993795385\n",
      "  time_since_restore: 2552.7189149856567\n",
      "  time_this_iter_s: 13.581877708435059\n",
      "  time_total_s: 2552.7189149856567\n",
      "  timers:\n",
      "    learn_throughput: 3772.63\n",
      "    learn_time_ms: 8.482\n",
      "    load_throughput: 61834.39\n",
      "    load_time_ms: 0.518\n",
      "    update_time_ms: 1.746\n",
      "  timestamp: 1632003981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 156000\n",
      "  training_iteration: 156\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         2552.72</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\">   -1.15</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             952.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 157000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-26-34\n",
      "  done: false\n",
      "  episode_len_mean: 952.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.12\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 162\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 156736\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2912.80126953125\n",
      "          mean_q: 427.5055847167969\n",
      "          min_q: 15.750212669372559\n",
      "        mean_td_error: 35.6354204416275\n",
      "        td_error: \"[ 3.55523109e-01 -1.87916603e+01  5.12575150e-01  2.15365967e+02\\n\\\n",
      "          \\ -2.44496704e+02  5.57151566e+01  1.66343857e+02  3.91080856e-01\\n  5.96630096e-01\\\n",
      "          \\  5.61994553e-01  2.15800610e+02  5.21858154e+02\\n  3.72891846e+01  3.90201569e-01\\\n",
      "          \\  4.81506348e-01  1.65723705e+01\\n  8.34068298e-01  9.86373901e-01  1.78352417e+02\\\n",
      "          \\ -5.28094482e+00\\n  7.35575676e-01  7.51583328e+01  9.46305275e-01  1.87254395e+02\\n\\\n",
      "          \\  5.57201385e-01  3.86539459e-01  8.98654938e-01  2.42633057e+01\\n -2.18978516e+02\\\n",
      "          \\ -1.19347229e+01 -6.38108225e+01  1.01884460e+00]\"\n",
      "    num_agent_steps_sampled: 157000\n",
      "    num_agent_steps_trained: 1248032\n",
      "    num_steps_sampled: 157000\n",
      "    num_steps_trained: 1248032\n",
      "    num_target_updates: 310\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.577777777777776\n",
      "    ram_util_percent: 91.76111111111112\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0397998354682362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.40309951996867\n",
      "    mean_inference_ms: 1.5624924036766532\n",
      "    mean_raw_obs_processing_ms: 2.55615089951859\n",
      "  time_since_restore: 2565.646980524063\n",
      "  time_this_iter_s: 12.928065538406372\n",
      "  time_total_s: 2565.646980524063\n",
      "  timers:\n",
      "    learn_throughput: 3743.985\n",
      "    learn_time_ms: 8.547\n",
      "    load_throughput: 60325.286\n",
      "    load_time_ms: 0.53\n",
      "    update_time_ms: 1.704\n",
      "  timestamp: 1632003994\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 157000\n",
      "  training_iteration: 157\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         2565.65</td><td style=\"text-align: right;\">157000</td><td style=\"text-align: right;\">   -1.12</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             952.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 158000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-26-48\n",
      "  done: false\n",
      "  episode_len_mean: 952.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.08\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 163\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 157744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1137.68212890625\n",
      "          mean_q: 209.245361328125\n",
      "          min_q: 14.262331008911133\n",
      "        mean_td_error: -34.53140640258789\n",
      "        td_error: \"[-1.7280817e+02  1.0553445e+01  3.6447048e-01  6.1604691e-01\\n  1.2889671e-01\\\n",
      "          \\  5.2011204e-01  1.2639263e+01  4.0838745e+01\\n -1.0147343e+00 -1.2975464e+02\\\n",
      "          \\ -8.3345432e+00 -3.5735999e+02\\n  2.9501404e+01 -3.7111688e+02  1.2513626e+01\\\n",
      "          \\  6.5438843e-01\\n -3.0358337e+02  1.2513626e+01  3.6140442e-01  2.2993851e-01\\n\\\n",
      "          \\ -1.7746925e-01  7.1828842e-01  2.7861977e-01  1.8780231e-01\\n  6.8641357e+00\\\n",
      "          \\  2.4677307e+01  1.0596695e+01  3.1128265e+01\\n  4.0887939e+01  1.5437069e+00\\\n",
      "          \\  3.6447048e-01  4.6224213e-01]\"\n",
      "    num_agent_steps_sampled: 158000\n",
      "    num_agent_steps_trained: 1256032\n",
      "    num_steps_sampled: 158000\n",
      "    num_steps_trained: 1256032\n",
      "    num_target_updates: 312\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.239999999999995\n",
      "    ram_util_percent: 91.68999999999998\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979972660946331\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.39942094711093\n",
      "    mean_inference_ms: 1.5624376079101203\n",
      "    mean_raw_obs_processing_ms: 2.570060831746115\n",
      "  time_since_restore: 2579.366406917572\n",
      "  time_this_iter_s: 13.719426393508911\n",
      "  time_total_s: 2579.366406917572\n",
      "  timers:\n",
      "    learn_throughput: 3773.351\n",
      "    learn_time_ms: 8.481\n",
      "    load_throughput: 60144.169\n",
      "    load_time_ms: 0.532\n",
      "    update_time_ms: 1.765\n",
      "  timestamp: 1632004008\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 158000\n",
      "  training_iteration: 158\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         2579.37</td><td style=\"text-align: right;\">158000</td><td style=\"text-align: right;\">   -1.08</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             952.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 159000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-27-02\n",
      "  done: false\n",
      "  episode_len_mean: 952.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.06\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 164\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 158752\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1925.0301513671875\n",
      "          mean_q: 286.0334167480469\n",
      "          min_q: 15.463258743286133\n",
      "        mean_td_error: -25.253124237060547\n",
      "        td_error: \"[ 2.4294472e-01 -1.0859056e+02  9.3612366e+00  2.3196030e-01\\n  1.4670980e+01\\\n",
      "          \\ -1.2256311e+02  2.7475830e+01 -1.5974075e+01\\n -6.2832832e-01  2.3127937e-01\\\n",
      "          \\  1.9255829e-01 -3.9486938e+01\\n -4.4406586e+00  3.4707031e+01  1.1455536e-01\\\n",
      "          \\  9.2286758e+00\\n  2.1734047e-01 -3.2082825e+01  2.8442001e-01  2.6031876e-01\\n\\\n",
      "          \\ -4.1169861e+02 -1.0157959e+02  4.9163757e+01  2.7532578e-01\\n  6.5458298e-02\\\n",
      "          \\  1.2980591e+01  4.6288361e+01 -1.3804245e+02\\n -3.9486938e+01  2.2366524e-01\\\n",
      "          \\  7.9509735e-02  1.7831421e-01]\"\n",
      "    num_agent_steps_sampled: 159000\n",
      "    num_agent_steps_trained: 1264032\n",
      "    num_steps_sampled: 159000\n",
      "    num_steps_trained: 1264032\n",
      "    num_target_updates: 314\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.69000000000001\n",
      "    ram_util_percent: 91.55\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979961485133028\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.395793718896355\n",
      "    mean_inference_ms: 1.5623828556843633\n",
      "    mean_raw_obs_processing_ms: 2.5839709804336035\n",
      "  time_since_restore: 2593.317839384079\n",
      "  time_this_iter_s: 13.951432466506958\n",
      "  time_total_s: 2593.317839384079\n",
      "  timers:\n",
      "    learn_throughput: 3668.013\n",
      "    learn_time_ms: 8.724\n",
      "    load_throughput: 56311.193\n",
      "    load_time_ms: 0.568\n",
      "    update_time_ms: 1.772\n",
      "  timestamp: 1632004022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159000\n",
      "  training_iteration: 159\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         2593.32</td><td style=\"text-align: right;\">159000</td><td style=\"text-align: right;\">   -1.06</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             952.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 160000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-27-16\n",
      "  done: false\n",
      "  episode_len_mean: 952.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.1\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 165\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 159760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2538.556884765625\n",
      "          mean_q: 410.3038330078125\n",
      "          min_q: 15.684343338012695\n",
      "        mean_td_error: 27.758617401123047\n",
      "        td_error: \"[-3.23752441e+01 -8.85810852e+00 -5.69511719e+01 -5.56826248e+01\\n\\\n",
      "          \\  1.69364319e+01 -2.07830811e+01 -3.08162689e-01 -4.87287521e-01\\n  8.47648438e+02\\\n",
      "          \\  6.75337830e+01 -7.43037415e+00  1.21947296e+02\\n  1.49927521e+01  3.53314972e+00\\\n",
      "          \\  1.91778717e+01  4.12583740e+02\\n -3.25617371e+01 -1.65484428e-01  1.54388428e-01\\\n",
      "          \\  1.18281494e+02\\n  1.36333466e-01 -9.18841553e+00 -4.30875664e+01  1.77246094e-01\\n\\\n",
      "          \\ -1.09260986e+02 -3.74319458e+00 -1.99739456e-01 -2.31561661e-01\\n -3.45076294e+02\\\n",
      "          \\ -2.08073616e-01 -2.66833305e-01 -7.96124649e+00]\"\n",
      "    num_agent_steps_sampled: 160000\n",
      "    num_agent_steps_trained: 1272032\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 1272032\n",
      "    num_target_updates: 316\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.68947368421052\n",
      "    ram_util_percent: 91.53684210526316\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039799545777574274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.392172453185468\n",
      "    mean_inference_ms: 1.5623290929356117\n",
      "    mean_raw_obs_processing_ms: 2.5978790228715645\n",
      "  time_since_restore: 2607.1122348308563\n",
      "  time_this_iter_s: 13.794395446777344\n",
      "  time_total_s: 2607.1122348308563\n",
      "  timers:\n",
      "    learn_throughput: 3769.843\n",
      "    learn_time_ms: 8.488\n",
      "    load_throughput: 61803.07\n",
      "    load_time_ms: 0.518\n",
      "    update_time_ms: 1.717\n",
      "  timestamp: 1632004036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 160\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         2607.11</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\">    -1.1</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             952.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 161000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-27-28\n",
      "  done: false\n",
      "  episode_len_mean: 952.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.1\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 166\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 160768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1493.119140625\n",
      "          mean_q: 164.7334442138672\n",
      "          min_q: 14.880284309387207\n",
      "        mean_td_error: 20.78322461247444\n",
      "        td_error: \"[-2.29001999e-01 -2.94992447e-01  9.93612976e+01  1.05999184e+02\\n\\\n",
      "          \\  1.46336823e+02 -4.80672836e-01 -2.02745247e+00 -4.42937851e-01\\n -8.20379448e+00\\\n",
      "          \\ -4.34474945e-02 -4.30219650e-01 -6.35411263e-01\\n -2.74284363e-01 -3.86688232e-01\\\n",
      "          \\ -1.03340340e+00 -7.26486206e-01\\n  3.59244507e+02  3.39893074e+01 -3.10411453e-01\\\n",
      "          \\ -1.79534054e+00\\n -3.22248459e-01 -4.74123955e-01 -6.75734863e+01 -5.82994843e+00\\n\\\n",
      "          \\ -4.30751343e+01 -4.61099625e-01 -5.33815384e-01 -4.81994629e+00\\n  2.24680420e+02\\\n",
      "          \\ -2.01169968e-01  7.34644318e+00 -1.71289276e+02]\"\n",
      "    num_agent_steps_sampled: 161000\n",
      "    num_agent_steps_trained: 1280032\n",
      "    num_steps_sampled: 161000\n",
      "    num_steps_trained: 1280032\n",
      "    num_target_updates: 318\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.67777777777778\n",
      "    ram_util_percent: 91.53888888888889\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979950527234941\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.388554652632974\n",
      "    mean_inference_ms: 1.5622764879596043\n",
      "    mean_raw_obs_processing_ms: 2.611782130255211\n",
      "  time_since_restore: 2619.539375305176\n",
      "  time_this_iter_s: 12.427140474319458\n",
      "  time_total_s: 2619.539375305176\n",
      "  timers:\n",
      "    learn_throughput: 3774.954\n",
      "    learn_time_ms: 8.477\n",
      "    load_throughput: 62308.03\n",
      "    load_time_ms: 0.514\n",
      "    update_time_ms: 1.725\n",
      "  timestamp: 1632004048\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 161000\n",
      "  training_iteration: 161\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         2619.54</td><td style=\"text-align: right;\">161000</td><td style=\"text-align: right;\">    -1.1</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             952.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 162000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-27-42\n",
      "  done: false\n",
      "  episode_len_mean: 952.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.09\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 167\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 161776\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4195.1220703125\n",
      "          mean_q: 527.4654541015625\n",
      "          min_q: 14.452409744262695\n",
      "        mean_td_error: -18.611244201660156\n",
      "        td_error: \"[-5.2161636e+00  1.7713596e+01  3.1870227e+02  1.9787708e+02\\n -1.6140175e-01\\\n",
      "          \\  4.1070061e+00 -3.2570076e-01 -2.7756943e+01\\n  6.1541626e+01 -8.8580894e-01\\\n",
      "          \\  2.0850110e+02  1.2702179e-01\\n -1.3123522e+00  2.5493927e+00 -1.7868240e+01\\\n",
      "          \\ -2.1652380e+02\\n -4.0624609e+02  6.4728333e+01 -4.4341187e+01 -3.7188911e-01\\n\\\n",
      "          \\  4.1187096e-01 -1.5244293e-01 -5.4047775e-01 -2.0681274e+01\\n  2.5568420e+01\\\n",
      "          \\ -1.4913559e-01 -1.9060135e-01 -8.6128748e+02\\n -4.6761513e-01  1.0692041e+02\\\n",
      "          \\  1.9047928e-01 -1.9893646e-02]\"\n",
      "    num_agent_steps_sampled: 162000\n",
      "    num_agent_steps_trained: 1288032\n",
      "    num_steps_sampled: 162000\n",
      "    num_steps_trained: 1288032\n",
      "    num_target_updates: 320\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.27368421052631\n",
      "    ram_util_percent: 91.62631578947367\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979940880310606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.384987229608019\n",
      "    mean_inference_ms: 1.5622240617891325\n",
      "    mean_raw_obs_processing_ms: 2.625675000784258\n",
      "  time_since_restore: 2633.040295124054\n",
      "  time_this_iter_s: 13.500919818878174\n",
      "  time_total_s: 2633.040295124054\n",
      "  timers:\n",
      "    learn_throughput: 3760.97\n",
      "    learn_time_ms: 8.508\n",
      "    load_throughput: 62724.427\n",
      "    load_time_ms: 0.51\n",
      "    update_time_ms: 1.779\n",
      "  timestamp: 1632004062\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 162000\n",
      "  training_iteration: 162\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         2633.04</td><td style=\"text-align: right;\">162000</td><td style=\"text-align: right;\">   -1.09</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             952.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 163000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-27-55\n",
      "  done: false\n",
      "  episode_len_mean: 952.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.07\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 168\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 162784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1902.4520263671875\n",
      "          mean_q: 433.83697509765625\n",
      "          min_q: 15.732425689697266\n",
      "        mean_td_error: -52.846091747283936\n",
      "        td_error: \"[ 4.92991753e+01 -2.78690338e-01 -3.31163406e-02  1.87729836e-01\\n\\\n",
      "          \\ -1.00433533e+02 -4.47238312e+01 -2.03512878e+02 -2.78294678e+01\\n  6.87282715e+01\\\n",
      "          \\  1.57324257e+01  1.93057190e+02  2.19727173e+01\\n -3.23661499e+01  3.68160248e-01\\\n",
      "          \\  1.97848816e+01  4.17260437e+01\\n  1.01634979e-01 -2.81802246e+02 -1.05737650e+03\\\n",
      "          \\ -1.68044312e+02\\n -6.66796265e+01  9.84670639e-01 -3.41819946e+02  1.09731934e+02\\n\\\n",
      "          \\ -2.18479156e-01  6.99932861e+01 -2.10984077e+01  8.03060303e+01\\n  3.18746185e+00\\\n",
      "          \\ -2.23783493e-01 -2.00909729e+01  2.95387268e-01]\"\n",
      "    num_agent_steps_sampled: 163000\n",
      "    num_agent_steps_trained: 1296032\n",
      "    num_steps_sampled: 163000\n",
      "    num_steps_trained: 1296032\n",
      "    num_target_updates: 322\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.255\n",
      "    ram_util_percent: 91.73500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979924979167673\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.381463582381956\n",
      "    mean_inference_ms: 1.5621710676087008\n",
      "    mean_raw_obs_processing_ms: 2.6326785845844682\n",
      "  time_since_restore: 2646.490906238556\n",
      "  time_this_iter_s: 13.450611114501953\n",
      "  time_total_s: 2646.490906238556\n",
      "  timers:\n",
      "    learn_throughput: 3820.732\n",
      "    learn_time_ms: 8.375\n",
      "    load_throughput: 64182.158\n",
      "    load_time_ms: 0.499\n",
      "    update_time_ms: 1.724\n",
      "  timestamp: 1632004075\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 163000\n",
      "  training_iteration: 163\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         2646.49</td><td style=\"text-align: right;\">163000</td><td style=\"text-align: right;\">   -1.07</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             952.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 164000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-28-09\n",
      "  done: false\n",
      "  episode_len_mean: 960.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.13\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 169\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 163792\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2428.166015625\n",
      "          mean_q: 322.060546875\n",
      "          min_q: 13.918272972106934\n",
      "        mean_td_error: -52.16672134399414\n",
      "        td_error: \"[-8.9448929e-02 -4.7476578e+02  4.5831680e-02  6.5395355e-02\\n -8.9101562e+00\\\n",
      "          \\  5.5267914e+01 -1.2195587e-01 -3.8166809e-01\\n  3.8561058e-01 -8.6014264e+02\\\n",
      "          \\  3.0820465e-01  4.4250977e+01\\n  1.0725098e+02  1.2647125e+01  7.1468262e+01\\\n",
      "          \\  2.3487415e+00\\n -4.4924622e+01 -1.3534164e-01 -6.2778473e-02 -1.9586563e-02\\n\\\n",
      "          \\ -1.2165979e+02 -5.5158043e-01 -9.3423584e+01  4.0834618e-01\\n  4.5414673e+01\\\n",
      "          \\ -1.5377655e+01 -2.2300903e+02 -7.4210205e+00\\n -2.4342773e+01 -6.4681519e+01\\\n",
      "          \\ -9.9618912e-01 -6.8180069e+01]\"\n",
      "    num_agent_steps_sampled: 164000\n",
      "    num_agent_steps_trained: 1304032\n",
      "    num_steps_sampled: 164000\n",
      "    num_steps_trained: 1304032\n",
      "    num_target_updates: 324\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.3421052631579\n",
      "    ram_util_percent: 91.7421052631579\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039799070633040196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.377896713363782\n",
      "    mean_inference_ms: 1.5621173091955782\n",
      "    mean_raw_obs_processing_ms: 2.639545454332952\n",
      "  time_since_restore: 2659.7810304164886\n",
      "  time_this_iter_s: 13.29012417793274\n",
      "  time_total_s: 2659.7810304164886\n",
      "  timers:\n",
      "    learn_throughput: 3756.486\n",
      "    learn_time_ms: 8.519\n",
      "    load_throughput: 62883.118\n",
      "    load_time_ms: 0.509\n",
      "    update_time_ms: 1.776\n",
      "  timestamp: 1632004089\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 164000\n",
      "  training_iteration: 164\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         2659.78</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">   -1.13</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             960.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 165000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-28-22\n",
      "  done: false\n",
      "  episode_len_mean: 960.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.09\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 170\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 164800\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2581.08740234375\n",
      "          mean_q: 562.3529052734375\n",
      "          min_q: 15.93642520904541\n",
      "        mean_td_error: -13.054167747497559\n",
      "        td_error: \"[-2.3638208e+02  2.2103210e+02 -9.2769775e+01  2.0342041e+01\\n  3.0690193e-01\\\n",
      "          \\ -8.2641724e+01 -2.3257507e+02  2.3104973e+01\\n  7.7425003e-02 -5.1731018e+01\\\n",
      "          \\  6.2045097e-01  2.3789692e-01\\n -1.1681274e+01  4.5828470e+02 -1.4914520e+01\\\n",
      "          \\ -3.0878067e-02\\n  3.9531326e-01 -5.0325394e-02  6.7430420e+00  7.6677704e-01\\n\\\n",
      "          \\ -5.9235840e+00  3.1931360e+02  7.9625046e+01  4.2550659e+00\\n  3.4987354e-01\\\n",
      "          \\  6.6708183e-01 -5.2905273e-01 -5.0356671e+02\\n  4.1913605e-01  2.8797150e-01\\\n",
      "          \\ -1.2717786e+02 -1.9458887e+02]\"\n",
      "    num_agent_steps_sampled: 165000\n",
      "    num_agent_steps_trained: 1312032\n",
      "    num_steps_sampled: 165000\n",
      "    num_steps_trained: 1312032\n",
      "    num_target_updates: 326\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.12105263157895\n",
      "    ram_util_percent: 91.84210526315788\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979889346978587\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.374255293839957\n",
      "    mean_inference_ms: 1.5620644498173144\n",
      "    mean_raw_obs_processing_ms: 2.646501922316302\n",
      "  time_since_restore: 2673.127930879593\n",
      "  time_this_iter_s: 13.346900463104248\n",
      "  time_total_s: 2673.127930879593\n",
      "  timers:\n",
      "    learn_throughput: 3799.35\n",
      "    learn_time_ms: 8.422\n",
      "    load_throughput: 61831.542\n",
      "    load_time_ms: 0.518\n",
      "    update_time_ms: 1.723\n",
      "  timestamp: 1632004102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 165000\n",
      "  training_iteration: 165\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         2673.13</td><td style=\"text-align: right;\">165000</td><td style=\"text-align: right;\">   -1.09</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             960.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 166000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-28-34\n",
      "  done: false\n",
      "  episode_len_mean: 960.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.07\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 171\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 165808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3133.72265625\n",
      "          mean_q: 359.6444091796875\n",
      "          min_q: 13.563997268676758\n",
      "        mean_td_error: -82.5689697265625\n",
      "        td_error: \"[ 3.2658005e-01 -7.7986267e+01  1.4982178e+02  5.5385017e-01\\n -8.3495361e+01\\\n",
      "          \\ -1.0784616e+02 -4.3008804e-02 -1.7960739e-01\\n  2.2472477e-01  1.8756447e+01\\\n",
      "          \\ -3.3336348e+03  2.4475384e-01\\n  4.8575783e-01 -5.7816162e+01  5.2013184e+02\\\n",
      "          \\  4.4001961e-01\\n -1.5182544e+02 -5.4560608e+01  2.7801418e-01  1.8683910e-01\\n\\\n",
      "          \\  1.1613006e+02 -2.2832870e-01  9.5111847e-02 -1.0211876e+01\\n  1.7328453e-01\\\n",
      "          \\ -1.7960739e-01  3.7201309e-01  4.2748828e+02\\n  1.0647392e-01  8.3464622e-02\\\n",
      "          \\  3.0295181e-01 -4.0224075e-01]\"\n",
      "    num_agent_steps_sampled: 166000\n",
      "    num_agent_steps_trained: 1320032\n",
      "    num_steps_sampled: 166000\n",
      "    num_steps_trained: 1320032\n",
      "    num_target_updates: 328\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.73529411764706\n",
      "    ram_util_percent: 91.88235294117646\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979869154497489\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.370625321174792\n",
      "    mean_inference_ms: 1.562011929741654\n",
      "    mean_raw_obs_processing_ms: 2.65354372763792\n",
      "  time_since_restore: 2685.5337092876434\n",
      "  time_this_iter_s: 12.405778408050537\n",
      "  time_total_s: 2685.5337092876434\n",
      "  timers:\n",
      "    learn_throughput: 3805.36\n",
      "    learn_time_ms: 8.409\n",
      "    load_throughput: 63393.977\n",
      "    load_time_ms: 0.505\n",
      "    update_time_ms: 1.722\n",
      "  timestamp: 1632004114\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 166000\n",
      "  training_iteration: 166\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         2685.53</td><td style=\"text-align: right;\">166000</td><td style=\"text-align: right;\">   -1.07</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             960.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 167000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-28-48\n",
      "  done: false\n",
      "  episode_len_mean: 960.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.07\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 172\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 166816\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3180.5927734375\n",
      "          mean_q: 435.8996276855469\n",
      "          min_q: 15.364739418029785\n",
      "        mean_td_error: -38.33642578125\n",
      "        td_error: \"[-5.9183252e+02 -4.9023056e-01  9.3154526e-01 -2.8287201e+01\\n -1.9827856e+02\\\n",
      "          \\  1.3290977e-01  1.7555450e+01  1.0501061e+02\\n  5.1343250e-01  3.7409019e-01\\\n",
      "          \\  1.1231041e-01 -4.8115967e+01\\n -7.5722534e+01  1.5658665e+01  1.2103367e-01\\\n",
      "          \\  1.2780762e-01\\n  1.5675201e+01 -7.8543091e-01  5.7449121e+02  2.6330662e-01\\n\\\n",
      "          \\ -1.1179498e+02 -2.3018936e+02  2.0415405e+01  1.8604469e-01\\n  2.6567841e-01\\\n",
      "          \\ -1.1789557e+02 -2.7938843e-01 -4.2179108e-02\\n -6.2106514e-01 -5.7419678e+02\\\n",
      "          \\ -5.8446693e-01  5.1600456e-01]\"\n",
      "    num_agent_steps_sampled: 167000\n",
      "    num_agent_steps_trained: 1328032\n",
      "    num_steps_sampled: 167000\n",
      "    num_steps_trained: 1328032\n",
      "    num_target_updates: 330\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.18000000000001\n",
      "    ram_util_percent: 91.96499999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039798502004922034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.367094604281109\n",
      "    mean_inference_ms: 1.5619615466751156\n",
      "    mean_raw_obs_processing_ms: 2.6606672310575403\n",
      "  time_since_restore: 2699.4220185279846\n",
      "  time_this_iter_s: 13.888309240341187\n",
      "  time_total_s: 2699.4220185279846\n",
      "  timers:\n",
      "    learn_throughput: 3785.227\n",
      "    learn_time_ms: 8.454\n",
      "    load_throughput: 63495.945\n",
      "    load_time_ms: 0.504\n",
      "    update_time_ms: 1.816\n",
      "  timestamp: 1632004128\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 167000\n",
      "  training_iteration: 167\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         2699.42</td><td style=\"text-align: right;\">167000</td><td style=\"text-align: right;\">   -1.07</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             960.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 168000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-29-03\n",
      "  done: false\n",
      "  episode_len_mean: 960.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.04\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 173\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 167824\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 871.7964477539062\n",
      "          mean_q: 196.5671844482422\n",
      "          min_q: 12.628759384155273\n",
      "        mean_td_error: -45.96395492553711\n",
      "        td_error: \"[ 1.30884171e-01 -4.05906403e+02 -2.42701874e+01  3.06059265e+00\\n\\\n",
      "          \\ -6.96763992e-02 -2.98724060e+01  2.86169434e+00 -6.71844482e-01\\n -5.18484116e-01\\\n",
      "          \\ -1.56371277e+02 -3.34326385e+02 -2.30125336e+02\\n  7.54737854e-02 -3.92371178e-01\\\n",
      "          \\ -2.51779083e+02 -8.92848015e-01\\n -7.31155243e+01 -6.22329712e-02 -5.70220947e-02\\\n",
      "          \\  3.25682983e+01\\n  2.07386971e-01 -2.37056885e+01  7.11107483e+01  7.39870911e+01\\n\\\n",
      "          \\ -1.05847176e+02  1.42379761e+01  9.25598145e+00 -3.80244751e+01\\n -6.90530777e-01\\\n",
      "          \\ -4.84432220e-01 -5.08622169e-01 -6.50721550e-01]\"\n",
      "    num_agent_steps_sampled: 168000\n",
      "    num_agent_steps_trained: 1336032\n",
      "    num_steps_sampled: 168000\n",
      "    num_steps_trained: 1336032\n",
      "    num_target_updates: 332\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.385714285714286\n",
      "    ram_util_percent: 92.03333333333333\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979830537044797\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.363689551531214\n",
      "    mean_inference_ms: 1.5619132179214839\n",
      "    mean_raw_obs_processing_ms: 2.667866104211356\n",
      "  time_since_restore: 2713.658256292343\n",
      "  time_this_iter_s: 14.23623776435852\n",
      "  time_total_s: 2713.658256292343\n",
      "  timers:\n",
      "    learn_throughput: 3705.062\n",
      "    learn_time_ms: 8.637\n",
      "    load_throughput: 54433.925\n",
      "    load_time_ms: 0.588\n",
      "    update_time_ms: 1.767\n",
      "  timestamp: 1632004143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 168000\n",
      "  training_iteration: 168\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         2713.66</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\">   -1.04</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             960.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 169000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-29-16\n",
      "  done: false\n",
      "  episode_len_mean: 960.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.03\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 174\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 168832\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4641.740234375\n",
      "          mean_q: 447.77093505859375\n",
      "          min_q: 12.99421501159668\n",
      "        mean_td_error: -19.13065394759178\n",
      "        td_error: \"[ 4.78843689e-01  2.88478851e+00  5.13637543e-01 -1.25149902e+02\\n\\\n",
      "          \\ -1.04176903e+00 -9.74464417e-02  1.65946064e+01  1.93499756e+00\\n -4.12047485e+02\\\n",
      "          \\  2.33926941e+02 -9.33274269e-01  1.17472534e+01\\n -2.67426208e+02 -1.64144287e+01\\\n",
      "          \\ -4.01685715e-01 -7.26261139e-02\\n  6.27641602e+01  2.41241455e-02 -5.64117432e-02\\\n",
      "          \\ -3.15540161e+01\\n  3.66112709e-01 -6.19122505e-01  1.66629696e+01 -1.12832642e+01\\n\\\n",
      "          \\ -1.40302063e+02  8.48489075e+01  2.72920609e-01  2.96434402e-01\\n -3.17447510e+01\\\n",
      "          \\ -4.30145264e-01 -6.00079346e+00  7.77702332e-02]\"\n",
      "    num_agent_steps_sampled: 169000\n",
      "    num_agent_steps_trained: 1344032\n",
      "    num_steps_sampled: 169000\n",
      "    num_steps_trained: 1344032\n",
      "    num_target_updates: 334\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.352631578947374\n",
      "    ram_util_percent: 92.11578947368419\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979814678493514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.360401928245802\n",
      "    mean_inference_ms: 1.5618672987721332\n",
      "    mean_raw_obs_processing_ms: 2.6751369942650176\n",
      "  time_since_restore: 2727.1094715595245\n",
      "  time_this_iter_s: 13.451215267181396\n",
      "  time_total_s: 2727.1094715595245\n",
      "  timers:\n",
      "    learn_throughput: 3739.728\n",
      "    learn_time_ms: 8.557\n",
      "    load_throughput: 63340.126\n",
      "    load_time_ms: 0.505\n",
      "    update_time_ms: 1.72\n",
      "  timestamp: 1632004156\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169000\n",
      "  training_iteration: 169\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         2727.11</td><td style=\"text-align: right;\">169000</td><td style=\"text-align: right;\">   -1.03</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             960.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 170000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-29-31\n",
      "  done: false\n",
      "  episode_len_mean: 960.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.09\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 175\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 169840\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 17615.796875\n",
      "          mean_q: 1761.0594482421875\n",
      "          min_q: 12.809078216552734\n",
      "        mean_td_error: -357.99951171875\n",
      "        td_error: \"[ 9.4770898e+02 -4.7157097e-01 -7.0334148e-01 -1.6651523e+04\\n  1.0259613e+02\\\n",
      "          \\  2.4816030e+03  6.3013672e+01 -6.0428619e-01\\n  3.3589746e+02 -6.3221550e-01\\\n",
      "          \\ -3.7807465e-02 -5.2048767e+01\\n -1.8639526e+00 -3.1870789e+01  5.9295975e+01\\\n",
      "          \\ -3.0973053e-01\\n -1.5094109e+00 -3.3667450e+02  5.0028992e-01  1.6609932e+03\\n\\\n",
      "          \\  6.7764473e-01  2.5845886e+01 -1.2479883e+02 -1.5629578e-01\\n -3.1588659e+00\\\n",
      "          \\ -5.7622910e-01 -3.7100506e-01 -1.8457317e+00\\n  5.2536621e+00  1.3780402e+02\\\n",
      "          \\ -3.9460182e-01 -6.7622482e+01]\"\n",
      "    num_agent_steps_sampled: 170000\n",
      "    num_agent_steps_trained: 1352032\n",
      "    num_steps_sampled: 170000\n",
      "    num_steps_trained: 1352032\n",
      "    num_target_updates: 336\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.32\n",
      "    ram_util_percent: 92.10000000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979806130190084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.35728713290215\n",
      "    mean_inference_ms: 1.5618238492217904\n",
      "    mean_raw_obs_processing_ms: 2.6824775581835003\n",
      "  time_since_restore: 2741.5057027339935\n",
      "  time_this_iter_s: 14.396231174468994\n",
      "  time_total_s: 2741.5057027339935\n",
      "  timers:\n",
      "    learn_throughput: 3795.181\n",
      "    learn_time_ms: 8.432\n",
      "    load_throughput: 63974.132\n",
      "    load_time_ms: 0.5\n",
      "    update_time_ms: 1.774\n",
      "  timestamp: 1632004171\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 170000\n",
      "  training_iteration: 170\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         2741.51</td><td style=\"text-align: right;\">170000</td><td style=\"text-align: right;\">   -1.09</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">             960.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 171000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-29-45\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.14\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 176\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 170848\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 22060.951171875\n",
      "          mean_q: 3354.328125\n",
      "          min_q: 15.291378021240234\n",
      "        mean_td_error: -832.32421875\n",
      "        td_error: \"[ 4.3973083e+02 -1.6119082e+03 -2.5245476e-01 -9.3828320e+02\\n -4.8292908e+01\\\n",
      "          \\ -1.5231431e+03  2.4931335e-01 -2.5981445e+02\\n  1.6741787e+03 -7.4198975e+01\\\n",
      "          \\ -1.6551514e+00 -2.2780800e-01\\n  8.9840210e+01 -3.9709854e-01  8.3302612e+00\\\n",
      "          \\ -9.5007038e-01\\n  2.9351807e-01 -1.9791565e+01  8.9179321e+01 -9.6774219e+02\\n\\\n",
      "          \\  2.0166339e+02  1.0919006e+03  7.7910328e-01  1.3232231e-01\\n  7.5083359e+01\\\n",
      "          \\ -1.5970802e-01  2.0820947e+02  3.3038177e+01\\n  2.6279993e+02 -2.6095381e+04\\\n",
      "          \\  9.2061043e-02  7.3232092e+02]\"\n",
      "    num_agent_steps_sampled: 171000\n",
      "    num_agent_steps_trained: 1360032\n",
      "    num_steps_sampled: 171000\n",
      "    num_steps_trained: 1360032\n",
      "    num_target_updates: 338\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.35\n",
      "    ram_util_percent: 92.21363636363638\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979807414122991\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.354308176286343\n",
      "    mean_inference_ms: 1.5617838508450237\n",
      "    mean_raw_obs_processing_ms: 2.684009438437988\n",
      "  time_since_restore: 2756.441747188568\n",
      "  time_this_iter_s: 14.936044454574585\n",
      "  time_total_s: 2756.441747188568\n",
      "  timers:\n",
      "    learn_throughput: 3496.0\n",
      "    learn_time_ms: 9.153\n",
      "    load_throughput: 54912.744\n",
      "    load_time_ms: 0.583\n",
      "    update_time_ms: 1.799\n",
      "  timestamp: 1632004185\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 171000\n",
      "  training_iteration: 171\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         2756.44</td><td style=\"text-align: right;\">171000</td><td style=\"text-align: right;\">   -1.14</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 172000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-30-00\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.13\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 177\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 171856\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 12109.228515625\n",
      "          mean_q: 990.9964599609375\n",
      "          min_q: 13.41490650177002\n",
      "        mean_td_error: -53.64278793334961\n",
      "        td_error: \"[-8.76694679e-01 -4.68738586e+02  1.01978455e+01 -9.50947762e-01\\n\\\n",
      "          \\  1.58468750e+02  6.65956055e+02  2.70483017e-01 -1.04339404e+03\\n -3.72989014e+02\\\n",
      "          \\ -3.98896179e+01 -9.72503662e-01 -8.47931862e-01\\n  5.06882782e+01 -1.78661865e+02\\\n",
      "          \\ -6.00886345e-01 -1.18539856e+02\\n -1.56951599e+01 -2.45024414e+02 -7.88403015e+01\\\n",
      "          \\  6.19416237e-01\\n  1.78752441e+01  1.48566391e+02  4.25749779e-01 -2.70793533e+00\\n\\\n",
      "          \\ -5.36485596e+01  1.67696419e+01  3.05086975e+01 -1.95269287e+02\\n  1.13175964e+00\\\n",
      "          \\ -6.34390259e+00  7.14471436e+00 -1.20081043e+00]\"\n",
      "    num_agent_steps_sampled: 172000\n",
      "    num_agent_steps_trained: 1368032\n",
      "    num_steps_sampled: 172000\n",
      "    num_steps_trained: 1368032\n",
      "    num_target_updates: 340\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.71500000000001\n",
      "    ram_util_percent: 92.215\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979816467241583\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.351441684647254\n",
      "    mean_inference_ms: 1.5617477090800977\n",
      "    mean_raw_obs_processing_ms: 2.6856802790188734\n",
      "  time_since_restore: 2770.8981223106384\n",
      "  time_this_iter_s: 14.456375122070312\n",
      "  time_total_s: 2770.8981223106384\n",
      "  timers:\n",
      "    learn_throughput: 3805.663\n",
      "    learn_time_ms: 8.409\n",
      "    load_throughput: 57520.24\n",
      "    load_time_ms: 0.556\n",
      "    update_time_ms: 1.837\n",
      "  timestamp: 1632004200\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 172000\n",
      "  training_iteration: 172\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">          2770.9</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\">   -1.13</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 173000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-30-14\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.11\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 178\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 172864\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 21385.693359375\n",
      "          mean_q: 1292.348876953125\n",
      "          min_q: 12.029200553894043\n",
      "        mean_td_error: -235.90167236328125\n",
      "        td_error: \"[-2.81325977e+03  7.12939453e+00  2.30331421e-02 -1.26035004e+02\\n\\\n",
      "          \\  8.84328842e-01 -7.10559082e+01 -1.53410254e+03  5.84072113e-01\\n -4.61790405e+02\\\n",
      "          \\  2.81079559e+01  1.14762878e+02  1.23921631e+02\\n -1.12846704e+03  1.07305622e+00\\\n",
      "          \\  7.14211464e-01 -1.53410254e+03\\n -3.21336670e+01  1.19644547e+00  1.42707539e+00\\\n",
      "          \\  1.58190918e+00\\n -1.23733185e+02 -3.26786652e+01  3.45894814e-01  2.87353210e+01\\n\\\n",
      "          \\  1.07612801e+00  1.24809170e+00  5.28205872e+01  1.02898312e+00\\n -3.24245605e+01\\\n",
      "          \\ -5.04466820e+01 -3.88535500e+00  2.86011963e+01]\"\n",
      "    num_agent_steps_sampled: 173000\n",
      "    num_agent_steps_trained: 1376032\n",
      "    num_steps_sampled: 173000\n",
      "    num_steps_trained: 1376032\n",
      "    num_target_updates: 342\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.900000000000006\n",
      "    ram_util_percent: 92.13333333333333\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979818461600786\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.348629769927971\n",
      "    mean_inference_ms: 1.5617121038916206\n",
      "    mean_raw_obs_processing_ms: 2.6874827617738157\n",
      "  time_since_restore: 2784.989452600479\n",
      "  time_this_iter_s: 14.091330289840698\n",
      "  time_total_s: 2784.989452600479\n",
      "  timers:\n",
      "    learn_throughput: 3743.233\n",
      "    learn_time_ms: 8.549\n",
      "    load_throughput: 64589.859\n",
      "    load_time_ms: 0.495\n",
      "    update_time_ms: 1.786\n",
      "  timestamp: 1632004214\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 173000\n",
      "  training_iteration: 173\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         2784.99</td><td style=\"text-align: right;\">173000</td><td style=\"text-align: right;\">   -1.11</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 174000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-30-28\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.07\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 179\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 173872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11098.119140625\n",
      "          mean_q: 917.3375244140625\n",
      "          min_q: -495.302734375\n",
      "        mean_td_error: -41.79634094238281\n",
      "        td_error: \"[ 1.46098042e+00 -1.12641830e+01  5.56362305e+02 -1.13512039e-01\\n\\\n",
      "          \\ -9.14401855e+01  1.93771698e+02  1.81188110e+02 -2.14435425e+02\\n  2.69644043e+02\\\n",
      "          \\ -1.04378809e+03  6.23006821e-01  1.19164734e+02\\n  4.70107239e+02  1.06351173e+02\\\n",
      "          \\ -8.16693726e+01  1.53298759e+00\\n -2.33883953e+01 -8.32716553e+02 -3.07153702e+00\\\n",
      "          \\ -6.10510254e+02\\n  6.42148972e-01  4.88567009e+01 -1.52077942e+02  1.39524174e+00\\n\\\n",
      "          \\ -2.41203308e-02  1.01293945e+00 -1.74609947e+00  7.37897873e-01\\n  1.67406845e+00\\\n",
      "          \\ -2.39224792e+02  1.06418610e+01  2.82042503e+00]\"\n",
      "    num_agent_steps_sampled: 174000\n",
      "    num_agent_steps_trained: 1384032\n",
      "    num_steps_sampled: 174000\n",
      "    num_steps_trained: 1384032\n",
      "    num_target_updates: 344\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.105000000000004\n",
      "    ram_util_percent: 92.22999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979809378831036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.345813966792388\n",
      "    mean_inference_ms: 1.561672239457877\n",
      "    mean_raw_obs_processing_ms: 2.6894120629499634\n",
      "  time_since_restore: 2799.1832270622253\n",
      "  time_this_iter_s: 14.193774461746216\n",
      "  time_total_s: 2799.1832270622253\n",
      "  timers:\n",
      "    learn_throughput: 3581.995\n",
      "    learn_time_ms: 8.934\n",
      "    load_throughput: 60573.034\n",
      "    load_time_ms: 0.528\n",
      "    update_time_ms: 1.801\n",
      "  timestamp: 1632004228\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 174000\n",
      "  training_iteration: 174\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">         2799.18</td><td style=\"text-align: right;\">174000</td><td style=\"text-align: right;\">   -1.07</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 175000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-30-42\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -1.06\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 180\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 174880\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 32989.89453125\n",
      "          mean_q: 2439.75732421875\n",
      "          min_q: 16.949169158935547\n",
      "        mean_td_error: -8.747394561767578\n",
      "        td_error: \"[ 8.2971382e-01 -4.7920197e+01 -2.6235781e+03  7.5653458e-01\\n -3.5882874e+01\\\n",
      "          \\ -1.0396004e-01  1.7887166e+03 -3.2052051e+02\\n  1.8975714e+02 -3.1441162e+01\\\n",
      "          \\ -4.6306427e+01  5.1996796e+01\\n -7.9406357e-01 -1.6205359e+02  3.6380676e+01\\\n",
      "          \\ -5.1836182e+01\\n  2.0581226e+02 -8.2792908e+01  9.6579895e+00 -2.5426797e+02\\n\\\n",
      "          \\ -1.6479778e+00 -4.9822617e-01  7.1023560e-01  9.2378906e+01\\n -5.4324463e+01\\\n",
      "          \\ -1.6999016e+00  4.3473244e-01 -4.1340179e+00\\n -5.8012305e+02  7.1779251e-02\\\n",
      "          \\  1.4456035e+03  1.9690222e+02]\"\n",
      "    num_agent_steps_sampled: 175000\n",
      "    num_agent_steps_trained: 1392032\n",
      "    num_steps_sampled: 175000\n",
      "    num_steps_trained: 1392032\n",
      "    num_target_updates: 346\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.589999999999996\n",
      "    ram_util_percent: 92.22\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039798064252446926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.343019288627344\n",
      "    mean_inference_ms: 1.5616347478915367\n",
      "    mean_raw_obs_processing_ms: 2.691462484813049\n",
      "  time_since_restore: 2813.3413009643555\n",
      "  time_this_iter_s: 14.158073902130127\n",
      "  time_total_s: 2813.3413009643555\n",
      "  timers:\n",
      "    learn_throughput: 3668.755\n",
      "    learn_time_ms: 8.722\n",
      "    load_throughput: 62308.03\n",
      "    load_time_ms: 0.514\n",
      "    update_time_ms: 1.789\n",
      "  timestamp: 1632004242\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 175000\n",
      "  training_iteration: 175\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         2813.34</td><td style=\"text-align: right;\">175000</td><td style=\"text-align: right;\">   -1.06</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 176000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-30-56\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -0.98\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 181\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 175888\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 52375.16796875\n",
      "          mean_q: 5912.22998046875\n",
      "          min_q: 17.171812057495117\n",
      "        mean_td_error: -362.268310546875\n",
      "        td_error: \"[-3.86304688e+02  3.22223755e+02  2.03847656e+01  1.17435455e-02\\n\\\n",
      "          \\  3.98906708e-01 -1.04935974e+02 -1.99352127e+02 -4.23296436e+03\\n -2.64874414e+03\\\n",
      "          \\  6.42112732e+02 -1.08431435e+00 -3.04454803e-01\\n -1.77349091e-01 -7.04649353e+01\\\n",
      "          \\ -3.26217896e+02  9.48645020e+00\\n  1.58760498e+02  1.21025085e-01  1.57475586e+01\\\n",
      "          \\  1.25967712e+01\\n  1.26625293e+03  2.87326660e+01  2.19198227e-01 -2.33589478e+01\\n\\\n",
      "          \\ -3.86304688e+02 -3.64516211e+03  1.33607483e+02 -7.48825073e-01\\n -2.14394531e+03\\\n",
      "          \\ -6.35761261e-01 -1.82470322e-01 -3.23537903e+01]\"\n",
      "    num_agent_steps_sampled: 176000\n",
      "    num_agent_steps_trained: 1400032\n",
      "    num_steps_sampled: 176000\n",
      "    num_steps_trained: 1400032\n",
      "    num_target_updates: 348\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.17\n",
      "    ram_util_percent: 92.30499999999998\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979810542194156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.340246471497874\n",
      "    mean_inference_ms: 1.5615990973087406\n",
      "    mean_raw_obs_processing_ms: 2.693632133694337\n",
      "  time_since_restore: 2827.102714538574\n",
      "  time_this_iter_s: 13.76141357421875\n",
      "  time_total_s: 2827.102714538574\n",
      "  timers:\n",
      "    learn_throughput: 3528.749\n",
      "    learn_time_ms: 9.068\n",
      "    load_throughput: 48756.803\n",
      "    load_time_ms: 0.656\n",
      "    update_time_ms: 1.828\n",
      "  timestamp: 1632004256\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 176000\n",
      "  training_iteration: 176\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">          2827.1</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\">   -0.98</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 177000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-31-10\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -0.99\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 182\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 176896\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 53426.6953125\n",
      "          mean_q: 2838.44677734375\n",
      "          min_q: 17.184587478637695\n",
      "        mean_td_error: 69.4836357831955\n",
      "        td_error: \"[ 4.82445831e+01 -3.34509827e+02  4.97920990e+00 -1.83303223e+01\\n\\\n",
      "          \\ -6.55433655e-01 -4.95013290e+02  4.21630859e-01  5.60400009e-01\\n  3.68822075e+02\\\n",
      "          \\  7.15290070e-01 -5.45839453e+03 -9.13116837e+00\\n  5.09087891e+02  2.50383301e+01\\\n",
      "          \\ -1.82170349e+02  1.31999969e-01\\n  2.70004272e-01  2.71649361e+00 -7.91210327e+01\\\n",
      "          \\  5.60400009e-01\\n -1.01173920e+02 -7.76672363e+01 -4.87737274e+00  3.02820969e+00\\n\\\n",
      "          \\ -1.30139893e+02 -7.32212067e-02 -9.97134399e+00  6.49288330e+01\\n -2.90778717e+02\\\n",
      "          \\  3.56474976e+02  7.95619531e+03  7.33083649e+01]\"\n",
      "    num_agent_steps_sampled: 177000\n",
      "    num_agent_steps_trained: 1408032\n",
      "    num_steps_sampled: 177000\n",
      "    num_steps_trained: 1408032\n",
      "    num_target_updates: 350\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.239999999999995\n",
      "    ram_util_percent: 92.38000000000002\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039798183856483496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.337558236593182\n",
      "    mean_inference_ms: 1.5615657439928918\n",
      "    mean_raw_obs_processing_ms: 2.6959157552842754\n",
      "  time_since_restore: 2841.0002098083496\n",
      "  time_this_iter_s: 13.89749526977539\n",
      "  time_total_s: 2841.0002098083496\n",
      "  timers:\n",
      "    learn_throughput: 3707.273\n",
      "    learn_time_ms: 8.632\n",
      "    load_throughput: 56113.436\n",
      "    load_time_ms: 0.57\n",
      "    update_time_ms: 1.861\n",
      "  timestamp: 1632004270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 177000\n",
      "  training_iteration: 177\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">            2841</td><td style=\"text-align: right;\">177000</td><td style=\"text-align: right;\">   -0.99</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 178000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-31-25\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -0.97\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 183\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 177904\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 69554.375\n",
      "          mean_q: 4926.29931640625\n",
      "          min_q: 21.010923385620117\n",
      "        mean_td_error: 263.0444030761719\n",
      "        td_error: \"[-1.2141846e+01 -3.1279855e+02 -1.4180621e+02 -1.5280737e+02\\n -1.1006003e+03\\\n",
      "          \\  5.9560693e+02 -3.9569664e-01 -1.2072122e+03\\n -1.7972839e+02  7.9658081e+01\\\n",
      "          \\ -1.6159155e+02 -1.9957466e+01\\n -2.3319435e+01 -6.4299341e+02 -8.5011890e+02\\\n",
      "          \\ -6.8642502e+00\\n -6.8404266e+01  2.5812421e+02  1.1744499e-01 -5.7741165e-02\\n\\\n",
      "          \\  1.7908466e+02 -4.5431213e+00 -1.2239459e+02 -3.9800644e-02\\n -3.7546387e+01\\\n",
      "          \\  7.0542266e+03 -1.7972839e+02 -3.2622070e+01\\n  7.0542266e+03 -1.2072122e+03\\\n",
      "          \\ -2.9676221e+02 -4.1977325e+01]\"\n",
      "    num_agent_steps_sampled: 178000\n",
      "    num_agent_steps_trained: 1416032\n",
      "    num_steps_sampled: 178000\n",
      "    num_steps_trained: 1416032\n",
      "    num_target_updates: 352\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.17142857142857\n",
      "    ram_util_percent: 92.72380952380954\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979837957486179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.334955946731789\n",
      "    mean_inference_ms: 1.561535902906701\n",
      "    mean_raw_obs_processing_ms: 2.698308234895828\n",
      "  time_since_restore: 2855.7918446063995\n",
      "  time_this_iter_s: 14.791634798049927\n",
      "  time_total_s: 2855.7918446063995\n",
      "  timers:\n",
      "    learn_throughput: 3171.069\n",
      "    learn_time_ms: 10.091\n",
      "    load_throughput: 24264.255\n",
      "    load_time_ms: 1.319\n",
      "    update_time_ms: 1.859\n",
      "  timestamp: 1632004285\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 178000\n",
      "  training_iteration: 178\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">         2855.79</td><td style=\"text-align: right;\">178000</td><td style=\"text-align: right;\">   -0.97</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 179000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-31-39\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -0.95\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 184\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 178912\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 77765.1484375\n",
      "          mean_q: 7302.859375\n",
      "          min_q: 18.879148483276367\n",
      "        mean_td_error: -211.25900268554688\n",
      "        td_error: \"[-1.7149414e+01 -1.7435455e+01  9.6850281e+01 -2.0302505e+00\\n -4.5012598e+03\\\n",
      "          \\ -1.1766510e+01 -1.9701965e+02 -5.6179180e+03\\n  1.5225334e+01  6.1326172e+03\\\n",
      "          \\  1.3822373e+03 -1.3249241e+03\\n -8.3698997e+00  1.8818164e+02 -1.9286926e+01\\\n",
      "          \\ -4.1679932e+01\\n -4.3988770e+01  2.2711487e+00 -2.2247095e+02  2.5724731e+01\\n\\\n",
      "          \\  8.2023506e+00 -1.5662872e+02  4.6401520e+00 -2.1316772e+01\\n  6.7255096e+00\\\n",
      "          \\ -1.9373074e+00  7.7737823e+01 -1.3314476e+00\\n -7.4041748e-01 -2.2812070e+03\\\n",
      "          \\ -2.0637848e+02 -5.8614273e+00]\"\n",
      "    num_agent_steps_sampled: 179000\n",
      "    num_agent_steps_trained: 1424032\n",
      "    num_steps_sampled: 179000\n",
      "    num_steps_trained: 1424032\n",
      "    num_target_updates: 354\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.040000000000006\n",
      "    ram_util_percent: 92.71\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979867464727457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.332411434495894\n",
      "    mean_inference_ms: 1.5615092535726338\n",
      "    mean_raw_obs_processing_ms: 2.700805758307136\n",
      "  time_since_restore: 2869.9134814739227\n",
      "  time_this_iter_s: 14.121636867523193\n",
      "  time_total_s: 2869.9134814739227\n",
      "  timers:\n",
      "    learn_throughput: 3647.875\n",
      "    learn_time_ms: 8.772\n",
      "    load_throughput: 60379.562\n",
      "    load_time_ms: 0.53\n",
      "    update_time_ms: 1.806\n",
      "  timestamp: 1632004299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179000\n",
      "  training_iteration: 179\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         2869.91</td><td style=\"text-align: right;\">179000</td><td style=\"text-align: right;\">   -0.95</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-31-53\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -0.91\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 185\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 179920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4835.345703125\n",
      "          mean_q: 1306.60693359375\n",
      "          min_q: 24.45329475402832\n",
      "        mean_td_error: -277.11297607421875\n",
      "        td_error: \"[-2.9463970e+03  6.3235107e+01 -1.1827158e+03 -4.8302612e+01\\n  1.3218407e+01\\\n",
      "          \\ -6.6435623e-01  2.3843896e+02 -1.8931396e+01\\n  1.5474860e+02  9.0508118e+01\\\n",
      "          \\ -3.8399731e+01 -1.3736748e+03\\n  1.7938428e+02 -1.1541885e+01 -3.4068491e+03\\\n",
      "          \\  3.3098071e+02\\n  5.1818030e+02  3.7447998e+01  2.6111157e+02  5.4826776e+02\\n\\\n",
      "          \\ -1.0144795e+03  1.3216602e+02 -6.8226990e+01 -8.8970947e-01\\n  1.2444658e+02\\\n",
      "          \\ -7.7407188e+00 -6.5099756e+02 -1.3165161e+01\\n -3.8381386e-01  4.4525049e+02\\\n",
      "          \\ -1.1142571e+03 -1.0738245e+02]\"\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_agent_steps_trained: 1432032\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 1432032\n",
      "    num_target_updates: 356\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.95789473684211\n",
      "    ram_util_percent: 92.63157894736841\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039798912698767515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.329878044444003\n",
      "    mean_inference_ms: 1.5614840650859854\n",
      "    mean_raw_obs_processing_ms: 2.7034050404924965\n",
      "  time_since_restore: 2883.3140931129456\n",
      "  time_this_iter_s: 13.400611639022827\n",
      "  time_total_s: 2883.3140931129456\n",
      "  timers:\n",
      "    learn_throughput: 3660.45\n",
      "    learn_time_ms: 8.742\n",
      "    load_throughput: 59982.896\n",
      "    load_time_ms: 0.533\n",
      "    update_time_ms: 1.767\n",
      "  timestamp: 1632004313\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 180\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         2883.31</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">   -0.91</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 181000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-32-06\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -0.85\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 186\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 180928\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 20792.89453125\n",
      "          mean_q: 1206.2979736328125\n",
      "          min_q: 19.606090545654297\n",
      "        mean_td_error: -482.18475341796875\n",
      "        td_error: \"[-6.85966797e+01  8.13254395e+01 -5.26833191e+02 -3.05141068e+00\\n\\\n",
      "          \\ -1.55899353e+01 -9.01391602e+00 -5.35058289e+02  1.28614502e+01\\n -4.01136475e+01\\\n",
      "          \\ -2.02117737e+02 -3.05141068e+00 -5.62921524e-01\\n  1.50096802e+02  1.06700516e+02\\\n",
      "          \\ -8.58595703e+02 -9.51366425e-02\\n -1.83877991e+02  3.78934860e-01 -1.10241187e+03\\\n",
      "          \\  5.11216187e+02\\n -2.11533691e+02 -1.02477837e+00 -2.77263641e-01  2.95705986e+00\\n\\\n",
      "          \\  2.38563538e-01 -1.37374207e+02 -1.74758270e+02  6.85514259e+00\\n  6.79618835e-01\\\n",
      "          \\  4.93048096e+01 -1.05762012e+04 -1.70238660e+03]\"\n",
      "    num_agent_steps_sampled: 181000\n",
      "    num_agent_steps_trained: 1440032\n",
      "    num_steps_sampled: 181000\n",
      "    num_steps_trained: 1440032\n",
      "    num_target_updates: 358\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.42\n",
      "    ram_util_percent: 92.60999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979926854345361\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.327386918026859\n",
      "    mean_inference_ms: 1.5614625388592456\n",
      "    mean_raw_obs_processing_ms: 2.7061004338939707\n",
      "  time_since_restore: 2897.1471602916718\n",
      "  time_this_iter_s: 13.833067178726196\n",
      "  time_total_s: 2897.1471602916718\n",
      "  timers:\n",
      "    learn_throughput: 3652.839\n",
      "    learn_time_ms: 8.76\n",
      "    load_throughput: 62942.097\n",
      "    load_time_ms: 0.508\n",
      "    update_time_ms: 1.869\n",
      "  timestamp: 1632004326\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 181000\n",
      "  training_iteration: 181\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         2897.15</td><td style=\"text-align: right;\">181000</td><td style=\"text-align: right;\">   -0.85</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 182000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-32-20\n",
      "  done: false\n",
      "  episode_len_mean: 965.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: -0.91\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 187\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 181936\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 41783.49609375\n",
      "          mean_q: 2525.735595703125\n",
      "          min_q: 21.09420394897461\n",
      "        mean_td_error: 165.27715784311295\n",
      "        td_error: \"[-2.00589600e+02  7.66467969e+03 -7.86058350e+01 -8.11591309e+02\\n\\\n",
      "          \\ -5.70583344e-01 -5.90286621e+02 -3.30104065e+00 -2.54770279e-01\\n  2.74337158e+01\\\n",
      "          \\ -2.49060249e+00  5.17890625e+01  5.32777344e+02\\n  9.89841166e+02  9.96989822e+00\\\n",
      "          \\ -2.98366089e+01  5.32777344e+02\\n -5.22831299e+02 -1.51165039e+02 -1.16138916e+02\\\n",
      "          \\ -1.98629932e+03\\n -9.07221680e+01  4.49274658e+02 -2.65062256e+01 -4.91359863e+01\\n\\\n",
      "          \\ -2.76274170e+02 -6.44487381e-01 -1.66861725e+00 -3.81412506e-02\\n -3.31879883e+01\\\n",
      "          \\ -1.24592590e+00 -1.75793091e+02  1.79504517e+02]\"\n",
      "    num_agent_steps_sampled: 182000\n",
      "    num_agent_steps_trained: 1448032\n",
      "    num_steps_sampled: 182000\n",
      "    num_steps_trained: 1448032\n",
      "    num_target_updates: 360\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.53684210526317\n",
      "    ram_util_percent: 92.38947368421051\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03979969998165337\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.324920393479944\n",
      "    mean_inference_ms: 1.5614426076572543\n",
      "    mean_raw_obs_processing_ms: 2.704449128830628\n",
      "  time_since_restore: 2910.4357335567474\n",
      "  time_this_iter_s: 13.288573265075684\n",
      "  time_total_s: 2910.4357335567474\n",
      "  timers:\n",
      "    learn_throughput: 3659.412\n",
      "    learn_time_ms: 8.745\n",
      "    load_throughput: 40469.69\n",
      "    load_time_ms: 0.791\n",
      "    update_time_ms: 1.764\n",
      "  timestamp: 1632004340\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 182000\n",
      "  training_iteration: 182\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         2910.44</td><td style=\"text-align: right;\">182000</td><td style=\"text-align: right;\">   -0.91</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            965.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 183000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-32-33\n",
      "  done: false\n",
      "  episode_len_mean: 972.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -1.04\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 188\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 182944\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 180828.984375\n",
      "          mean_q: 10143.8955078125\n",
      "          min_q: 21.722522735595703\n",
      "        mean_td_error: -73.16952514648438\n",
      "        td_error: \"[ 3.5768203e+03 -2.6677246e+02 -2.9872952e+00 -7.3577100e+02\\n  1.3751221e-01\\\n",
      "          \\  2.1063141e+01 -1.5321732e-02  2.1282402e+01\\n -3.2585522e+02  4.3293594e+03\\\n",
      "          \\ -1.6632404e+02 -1.0441647e+00\\n  5.5637775e+02 -3.7641016e+02 -9.4012207e+01\\\n",
      "          \\ -4.5137215e-01\\n  7.3680305e-01  1.0702295e+02  1.4261703e+00 -6.4114912e+03\\n\\\n",
      "          \\ -1.0264645e+04 -3.5441895e+01  1.0725130e+04  3.7262158e+02\\n  5.9226294e+02\\\n",
      "          \\  2.0767358e+02  1.4157568e+02 -3.9723201e+03\\n -5.4058594e+02 -1.5321732e-02\\\n",
      "          \\  1.3900244e+02  6.0223877e+01]\"\n",
      "    num_agent_steps_sampled: 183000\n",
      "    num_agent_steps_trained: 1456032\n",
      "    num_steps_sampled: 183000\n",
      "    num_steps_trained: 1456032\n",
      "    num_target_updates: 362\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.67894736842104\n",
      "    ram_util_percent: 92.39473684210527\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980017396767357\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.322424885126956\n",
      "    mean_inference_ms: 1.5614236077487234\n",
      "    mean_raw_obs_processing_ms: 2.7026875745200254\n",
      "  time_since_restore: 2924.0515518188477\n",
      "  time_this_iter_s: 13.61581826210022\n",
      "  time_total_s: 2924.0515518188477\n",
      "  timers:\n",
      "    learn_throughput: 3698.609\n",
      "    learn_time_ms: 8.652\n",
      "    load_throughput: 61783.156\n",
      "    load_time_ms: 0.518\n",
      "    update_time_ms: 1.814\n",
      "  timestamp: 1632004353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 183000\n",
      "  training_iteration: 183\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         2924.05</td><td style=\"text-align: right;\">183000</td><td style=\"text-align: right;\">   -1.04</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            972.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 184000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-33-05\n",
      "  done: false\n",
      "  episode_len_mean: 971.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -1.07\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 189\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 183952\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 182937.703125\n",
      "          mean_q: 7587.21044921875\n",
      "          min_q: 25.68196678161621\n",
      "        mean_td_error: 184.9785596728325\n",
      "        td_error: \"[ 4.62071533e+01  2.54782295e+01 -6.76148914e+02  1.15638794e+02\\n\\\n",
      "          \\ -1.33516846e+01  1.83629150e+02 -9.08158081e+02  6.99493164e+02\\n  1.91065674e+01\\\n",
      "          \\  1.37983437e+01  3.90775681e-01 -3.74203589e+03\\n  3.81931274e+02  8.30416016e+02\\\n",
      "          \\ -6.70754395e+01 -2.13203125e+01\\n  2.04064209e+02  7.49484253e+01  4.88399506e-01\\\n",
      "          \\ -1.19639282e+01\\n  5.49255371e-01  1.49729004e+01  1.21070312e+02 -9.07756348e+01\\n\\\n",
      "          \\  2.13960449e+03 -2.96541214e-01  3.26108398e+01 -1.68567395e+03\\n -2.22890091e+00\\\n",
      "          \\  7.60345312e+03  7.20147514e+00  6.23290283e+02]\"\n",
      "    num_agent_steps_sampled: 184000\n",
      "    num_agent_steps_trained: 1464032\n",
      "    num_steps_sampled: 184000\n",
      "    num_steps_trained: 1464032\n",
      "    num_target_updates: 364\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.54666666666667\n",
      "    ram_util_percent: 92.15555555555555\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980068463811608\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.319801234326956\n",
      "    mean_inference_ms: 1.5614063103956553\n",
      "    mean_raw_obs_processing_ms: 2.702000761901928\n",
      "  time_since_restore: 2955.259549856186\n",
      "  time_this_iter_s: 31.207998037338257\n",
      "  time_total_s: 2955.259549856186\n",
      "  timers:\n",
      "    learn_throughput: 3497.066\n",
      "    learn_time_ms: 9.151\n",
      "    load_throughput: 31955.841\n",
      "    load_time_ms: 1.001\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1632004385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 184000\n",
      "  training_iteration: 184\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">         2955.26</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\">   -1.07</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            971.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 185000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-33-18\n",
      "  done: false\n",
      "  episode_len_mean: 971.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -1.08\n",
      "  episode_reward_min: -9.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 190\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 184960\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 201567.5625\n",
      "          mean_q: 10597.87109375\n",
      "          min_q: 24.250181198120117\n",
      "        mean_td_error: -7419.61572265625\n",
      "        td_error: \"[ 8.4889453e+02  1.6965781e+02 -2.8188305e+00  2.5017480e+02\\n -1.2179858e+04\\\n",
      "          \\ -4.3788750e+03  4.9580078e+01  6.7103088e+01\\n -2.8377295e+02 -2.8472900e-01\\\n",
      "          \\ -2.6470361e+02 -1.5673218e+01\\n -1.3773071e+02  2.0924097e+02 -8.7175293e+01\\\n",
      "          \\ -2.1857300e+01\\n -1.4394109e+04 -8.2221641e+03 -1.9557144e+05 -1.2197933e+00\\n\\\n",
      "          \\  8.5424194e+01  2.0602563e+02  1.0535181e+02 -9.9549512e+02\\n -2.7783623e+03\\\n",
      "          \\  9.6780640e+01  3.8183203e+02  1.1117706e+00\\n  4.7758102e+01 -9.2419897e+02\\\n",
      "          \\  1.6313745e+02  1.4994958e+02]\"\n",
      "    num_agent_steps_sampled: 185000\n",
      "    num_agent_steps_trained: 1472032\n",
      "    num_steps_sampled: 185000\n",
      "    num_steps_trained: 1472032\n",
      "    num_target_updates: 366\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.18421052631578\n",
      "    ram_util_percent: 92.18947368421053\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980125823856981\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.31721710297388\n",
      "    mean_inference_ms: 1.5613919570032575\n",
      "    mean_raw_obs_processing_ms: 2.7014459699167257\n",
      "  time_since_restore: 2968.5437319278717\n",
      "  time_this_iter_s: 13.284182071685791\n",
      "  time_total_s: 2968.5437319278717\n",
      "  timers:\n",
      "    learn_throughput: 3565.675\n",
      "    learn_time_ms: 8.974\n",
      "    load_throughput: 58183.513\n",
      "    load_time_ms: 0.55\n",
      "    update_time_ms: 1.744\n",
      "  timestamp: 1632004398\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 185000\n",
      "  training_iteration: 185\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         2968.54</td><td style=\"text-align: right;\">185000</td><td style=\"text-align: right;\">   -1.08</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">            971.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 186000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-33-31\n",
      "  done: false\n",
      "  episode_len_mean: 971.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -1.18\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 191\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 185968\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 107471.0078125\n",
      "          mean_q: 5805.1220703125\n",
      "          min_q: 25.90681266784668\n",
      "        mean_td_error: -7647.15087890625\n",
      "        td_error: \"[-8.9277954e+01 -2.9522656e+02  5.4601440e+01  3.6862610e+01\\n  2.9128198e+02\\\n",
      "          \\ -9.2071533e-01  4.0400391e+01 -4.4790039e+01\\n -2.0515918e+02  1.3384564e+02\\\n",
      "          \\  1.3226509e-01 -1.1407600e+03\\n -5.1962852e-01 -5.4640331e+00  2.2220713e+03\\\n",
      "          \\ -1.0656683e+02\\n -6.2673008e+03 -5.6819141e+02  3.3235535e+01 -2.4495142e+02\\n\\\n",
      "          \\ -2.3382597e+05  8.0553174e+02  2.7827148e+01  4.6403858e+01\\n -3.1582428e+01\\\n",
      "          \\ -1.2490303e+03 -5.2768682e+03  2.7491113e+02\\n  7.9095459e+02  7.3555374e-01\\\n",
      "          \\  5.5987549e-01 -1.1562250e+02]\"\n",
      "    num_agent_steps_sampled: 186000\n",
      "    num_agent_steps_trained: 1480032\n",
      "    num_steps_sampled: 186000\n",
      "    num_steps_trained: 1480032\n",
      "    num_target_updates: 368\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.10526315789474\n",
      "    ram_util_percent: 91.82631578947368\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0398018811396762\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.314692380403722\n",
      "    mean_inference_ms: 1.5613795207581145\n",
      "    mean_raw_obs_processing_ms: 2.7010206681371485\n",
      "  time_since_restore: 2981.619364261627\n",
      "  time_this_iter_s: 13.075632333755493\n",
      "  time_total_s: 2981.619364261627\n",
      "  timers:\n",
      "    learn_throughput: 3634.687\n",
      "    learn_time_ms: 8.804\n",
      "    load_throughput: 59623.174\n",
      "    load_time_ms: 0.537\n",
      "    update_time_ms: 1.765\n",
      "  timestamp: 1632004411\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 186000\n",
      "  training_iteration: 186\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         2981.62</td><td style=\"text-align: right;\">186000</td><td style=\"text-align: right;\">   -1.18</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            971.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 187000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-34-23\n",
      "  done: false\n",
      "  episode_len_mean: 966.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -1.08\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 193\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 186976\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 121021.9765625\n",
      "          mean_q: 8400.529296875\n",
      "          min_q: 25.381282806396484\n",
      "        mean_td_error: -195.3454476594925\n",
      "        td_error: \"[ 4.07347412e+02 -4.82292175e-02  2.59380703e+01 -7.46618652e+00\\n\\\n",
      "          \\ -5.68628320e+03 -2.07014084e+00  6.70772656e+03 -1.12312851e+01\\n -7.36485596e+01\\\n",
      "          \\ -1.77078613e+02  2.41135645e+03  2.79991398e+01\\n -9.15024672e+02  7.36468506e+01\\\n",
      "          \\  2.47704315e+00  2.03315430e+01\\n  2.48374451e+02  5.82124901e+01  1.78278564e+02\\\n",
      "          \\ -5.04308105e+02\\n  8.00393311e+02  1.38750977e+02  9.46484375e+00 -4.41356201e+01\\n\\\n",
      "          \\ -1.51475906e-01  6.02317383e+02  2.58235931e-02 -3.59126953e+02\\n -2.76366211e+02\\\n",
      "          \\  9.88161087e-01 -4.50268555e+03 -5.40505859e+03]\"\n",
      "    num_agent_steps_sampled: 187000\n",
      "    num_agent_steps_trained: 1488032\n",
      "    num_steps_sampled: 187000\n",
      "    num_steps_trained: 1488032\n",
      "    num_target_updates: 370\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.5041095890411\n",
      "    ram_util_percent: 91.34931506849317\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0398031150364294\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.309862154887535\n",
      "    mean_inference_ms: 1.5613607830765261\n",
      "    mean_raw_obs_processing_ms: 2.699960851580834\n",
      "  time_since_restore: 3033.530281305313\n",
      "  time_this_iter_s: 51.91091704368591\n",
      "  time_total_s: 3033.530281305313\n",
      "  timers:\n",
      "    learn_throughput: 3657.577\n",
      "    learn_time_ms: 8.749\n",
      "    load_throughput: 16866.821\n",
      "    load_time_ms: 1.897\n",
      "    update_time_ms: 1.751\n",
      "  timestamp: 1632004463\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 187000\n",
      "  training_iteration: 187\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         3033.53</td><td style=\"text-align: right;\">187000</td><td style=\"text-align: right;\">   -1.08</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            966.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 188000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-34-37\n",
      "  done: false\n",
      "  episode_len_mean: 970.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -1.13\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 194\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 187984\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 57488.546875\n",
      "          mean_q: 8608.6025390625\n",
      "          min_q: 26.5113468170166\n",
      "        mean_td_error: -877.3699951171875\n",
      "        td_error: \"[-6.5067627e+01 -5.2688379e+02 -6.8569287e+02 -6.0104004e+01\\n  3.4070642e+02\\\n",
      "          \\ -1.4430408e+02 -1.0373389e+02  2.3135986e+00\\n  2.0650757e+01  3.6110391e+03\\\n",
      "          \\ -3.1445435e+01 -6.6067261e+01\\n  1.1702881e+00 -7.1298750e+03 -5.4546356e-02\\\n",
      "          \\ -9.5375443e+00\\n -7.0672417e-01  1.3520352e+03 -5.4314819e+01 -1.0759176e+04\\n\\\n",
      "          \\ -1.8919434e+02  1.6102958e+03  5.6934045e+02 -3.9632051e+03\\n -5.1629053e+02\\\n",
      "          \\ -6.2613398e+03 -6.9507263e+01  7.8622818e-02\\n  2.2155884e+01 -4.9243042e+03\\\n",
      "          \\ -1.6329102e+01 -2.8492432e+01]\"\n",
      "    num_agent_steps_sampled: 188000\n",
      "    num_agent_steps_trained: 1496032\n",
      "    num_steps_sampled: 188000\n",
      "    num_steps_trained: 1496032\n",
      "    num_target_updates: 372\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.565\n",
      "    ram_util_percent: 92.34000000000002\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980373549006562\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.307468524321159\n",
      "    mean_inference_ms: 1.5613526067495649\n",
      "    mean_raw_obs_processing_ms: 2.697020658280522\n",
      "  time_since_restore: 3047.177486896515\n",
      "  time_this_iter_s: 13.647205591201782\n",
      "  time_total_s: 3047.177486896515\n",
      "  timers:\n",
      "    learn_throughput: 3694.985\n",
      "    learn_time_ms: 8.66\n",
      "    load_throughput: 61466.261\n",
      "    load_time_ms: 0.521\n",
      "    update_time_ms: 1.748\n",
      "  timestamp: 1632004477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 188000\n",
      "  training_iteration: 188\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">         3047.18</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">   -1.13</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            970.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 189000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-34-50\n",
      "  done: false\n",
      "  episode_len_mean: 975.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -1.18\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 195\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 188992\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 25301.6015625\n",
      "          mean_q: 5728.7109375\n",
      "          min_q: 29.767778396606445\n",
      "        mean_td_error: -67.91275024414062\n",
      "        td_error: \"[-5.0538633e+03 -5.8638843e+02  1.8066788e-01  1.7191992e+02\\n  9.7107646e+03\\\n",
      "          \\ -5.3940430e+01 -1.0274713e+03 -2.6397556e+02\\n -7.7701172e+01  2.4931427e+02\\\n",
      "          \\ -3.4537982e+02  3.7211816e+02\\n -3.7842031e+03 -4.0642993e+02 -4.5084381e+01\\\n",
      "          \\  3.7425232e-01\\n  4.0666577e+02 -2.3979277e+03 -6.0844165e+02  6.2463164e+03\\n\\\n",
      "          \\  6.5118711e+03 -3.3219434e+02  2.7107715e+02 -7.1812744e+00\\n  1.3148508e+03\\\n",
      "          \\ -2.8000500e+02 -1.6615234e+02 -2.0692175e+02\\n  1.4049585e+03 -2.4915259e+02\\\n",
      "          \\ -1.1590594e+04 -1.3506111e+03]\"\n",
      "    num_agent_steps_sampled: 189000\n",
      "    num_agent_steps_trained: 1504032\n",
      "    num_steps_sampled: 189000\n",
      "    num_steps_trained: 1504032\n",
      "    num_target_updates: 374\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.073684210526324\n",
      "    ram_util_percent: 92.42105263157896\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039804374440097955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.305081094963983\n",
      "    mean_inference_ms: 1.5613446639657977\n",
      "    mean_raw_obs_processing_ms: 2.6915685662150985\n",
      "  time_since_restore: 3060.5347621440887\n",
      "  time_this_iter_s: 13.357275247573853\n",
      "  time_total_s: 3060.5347621440887\n",
      "  timers:\n",
      "    learn_throughput: 3690.606\n",
      "    learn_time_ms: 8.671\n",
      "    load_throughput: 61124.751\n",
      "    load_time_ms: 0.524\n",
      "    update_time_ms: 1.711\n",
      "  timestamp: 1632004490\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189000\n",
      "  training_iteration: 189\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         3060.53</td><td style=\"text-align: right;\">189000</td><td style=\"text-align: right;\">   -1.18</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            975.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 190000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-35-03\n",
      "  done: false\n",
      "  episode_len_mean: 977.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -1.24\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 196\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 190000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 311015.3125\n",
      "          mean_q: 17752.19921875\n",
      "          min_q: 27.90301513671875\n",
      "        mean_td_error: -1341.8975830078125\n",
      "        td_error: \"[ 5.47193604e+01  3.92685254e+03 -3.87941284e+02 -4.25080811e+02\\n\\\n",
      "          \\ -1.52096338e+03 -2.11293516e+04  1.17744141e+03  3.20449524e+01\\n -8.24340820e+01\\\n",
      "          \\  3.34848047e+03 -1.12298877e+03 -5.96849060e+00\\n  1.67480469e+00  1.08733154e+02\\\n",
      "          \\ -3.10252295e+03 -3.56765137e+01\\n  2.54574336e+04  1.17574341e+02 -1.06225342e+02\\\n",
      "          \\  4.52869141e+02\\n  2.67946777e+01  4.49613721e+03 -4.25136475e+02 -5.69779816e+01\\n\\\n",
      "          \\  2.60003198e+03 -1.52139453e+03  1.47565193e+01  1.75830841e-01\\n -5.44918750e+04\\\n",
      "          \\ -1.78943062e+00 -1.76318909e+02 -1.63799805e+02]\"\n",
      "    num_agent_steps_sampled: 190000\n",
      "    num_agent_steps_trained: 1512032\n",
      "    num_steps_sampled: 190000\n",
      "    num_steps_trained: 1512032\n",
      "    num_target_updates: 376\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.68888888888889\n",
      "    ram_util_percent: 92.39999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039804993152417985\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.302716098571373\n",
      "    mean_inference_ms: 1.5613374065713475\n",
      "    mean_raw_obs_processing_ms: 2.684160700963621\n",
      "  time_since_restore: 3073.4227492809296\n",
      "  time_this_iter_s: 12.88798713684082\n",
      "  time_total_s: 3073.4227492809296\n",
      "  timers:\n",
      "    learn_throughput: 3696.491\n",
      "    learn_time_ms: 8.657\n",
      "    load_throughput: 60864.197\n",
      "    load_time_ms: 0.526\n",
      "    update_time_ms: 1.796\n",
      "  timestamp: 1632004503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 190000\n",
      "  training_iteration: 190\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   190</td><td style=\"text-align: right;\">         3073.42</td><td style=\"text-align: right;\">190000</td><td style=\"text-align: right;\">   -1.24</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            977.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 191000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-35-17\n",
      "  done: false\n",
      "  episode_len_mean: 977.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0\n",
      "  episode_reward_mean: -1.25\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 197\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 190504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 731710.5\n",
      "          mean_q: 31354.5234375\n",
      "          min_q: 30.33088493347168\n",
      "        mean_td_error: 2099.89013671875\n",
      "        td_error: \"[ 2.0036719e+02  5.8350916e+02  8.9580957e+02  4.6771533e+02\\n -4.3077472e+02\\\n",
      "          \\  2.0095703e+01 -9.6564355e+02  1.1329526e+03\\n -5.2511089e+03 -1.4971934e+03\\\n",
      "          \\ -4.1396515e+01  7.0686680e+03\\n -4.6367163e+02 -1.7078857e+01  2.6337720e+02\\\n",
      "          \\  1.4421188e+03\\n  6.1188698e-01  9.5839160e+02 -1.6207174e+03 -2.1772485e+02\\n\\\n",
      "          \\ -1.5014648e+01  5.7793984e+03 -3.7321914e+03 -2.3602534e+03\\n -4.6063745e+02\\\n",
      "          \\ -6.5936035e+01  6.7736062e+04 -2.5611052e+03\\n  1.6899980e+03 -2.1634111e+03\\\n",
      "          \\  3.8038818e+02  4.4087988e+02]\"\n",
      "    num_agent_steps_sampled: 191000\n",
      "    num_agent_steps_trained: 1520032\n",
      "    num_steps_sampled: 191000\n",
      "    num_steps_trained: 1520032\n",
      "    num_target_updates: 377\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.82000000000001\n",
      "    ram_util_percent: 92.06000000000002\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980560648720765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.300127393307095\n",
      "    mean_inference_ms: 1.5613305390413874\n",
      "    mean_raw_obs_processing_ms: 2.6733575357825576\n",
      "  time_since_restore: 3087.0081005096436\n",
      "  time_this_iter_s: 13.58535122871399\n",
      "  time_total_s: 3087.0081005096436\n",
      "  timers:\n",
      "    learn_throughput: 3682.283\n",
      "    learn_time_ms: 8.69\n",
      "    load_throughput: 61610.157\n",
      "    load_time_ms: 0.519\n",
      "    update_time_ms: 1.701\n",
      "  timestamp: 1632004517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 191000\n",
      "  training_iteration: 191\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">         3087.01</td><td style=\"text-align: right;\">191000</td><td style=\"text-align: right;\">   -1.25</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            977.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 192000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-35-29\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.3\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 198\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 191512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1051102.125\n",
      "          mean_q: 63606.44140625\n",
      "          min_q: 153.42092895507812\n",
      "        mean_td_error: 14635.427734375\n",
      "        td_error: \"[ 3.2068072e+05  1.2394756e+03  3.3159149e+02  1.8389478e+02\\n  1.3054461e+04\\\n",
      "          \\ -4.2379688e+02 -3.6283711e+03 -9.4425781e+02\\n -2.5415247e+03  5.6743213e+02\\\n",
      "          \\ -1.0860176e+03  8.3906372e+01\\n -1.2532295e+03  7.0513965e+02  1.9976039e+04\\\n",
      "          \\  3.6349156e+04\\n  7.1329053e+02 -6.4780005e+02  8.3906372e+01  1.1339406e+02\\n\\\n",
      "          \\  4.7831689e+02  1.5413818e+00  1.2662271e+03  7.0513965e+02\\n  1.4920096e+02\\\n",
      "          \\ -6.7880176e+02  3.7678558e+02  1.3978271e+02\\n  1.7277893e+01  7.5701172e+01\\\n",
      "          \\  8.0139688e+04  2.1054180e+03]\"\n",
      "    num_agent_steps_sampled: 192000\n",
      "    num_agent_steps_trained: 1528032\n",
      "    num_steps_sampled: 192000\n",
      "    num_steps_trained: 1528032\n",
      "    num_target_updates: 379\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.388888888888886\n",
      "    ram_util_percent: 91.76666666666667\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980622716306931\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.297475930065918\n",
      "    mean_inference_ms: 1.5613233058674783\n",
      "    mean_raw_obs_processing_ms: 2.6624382292907773\n",
      "  time_since_restore: 3099.7872302532196\n",
      "  time_this_iter_s: 12.77912974357605\n",
      "  time_total_s: 3099.7872302532196\n",
      "  timers:\n",
      "    learn_throughput: 3644.893\n",
      "    learn_time_ms: 8.779\n",
      "    load_throughput: 57922.375\n",
      "    load_time_ms: 0.552\n",
      "    update_time_ms: 1.761\n",
      "  timestamp: 1632004529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 192000\n",
      "  training_iteration: 192\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">         3099.79</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\">    -1.3</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 193000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-35-43\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.25\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 199\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 192520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 211920.03125\n",
      "          mean_q: 24030.33984375\n",
      "          min_q: 30.766138076782227\n",
      "        mean_td_error: 3957.16748046875\n",
      "        td_error: \"[ 2.9573975e+01  2.0870004e+02  1.5802817e+03  7.0749219e+03\\n -3.5272146e+03\\\n",
      "          \\  2.4473213e+01  2.1179706e+05 -1.1491199e+02\\n  3.3746777e+02 -2.8574375e+03\\\n",
      "          \\  8.8444062e+03 -2.7004722e+03\\n -2.4101953e+02  1.6116411e+03  7.1096420e-02\\\n",
      "          \\ -1.3870049e-01\\n -6.9217285e+01 -9.2536829e+02 -9.0196436e+02 -9.8773984e+03\\n\\\n",
      "          \\ -8.7633618e+02 -1.1299072e+03 -6.7046890e+03 -3.6127383e+03\\n -7.1360891e+04\\\n",
      "          \\ -6.7391406e+02 -1.7254883e+01  7.7961230e+02\\n -4.2440796e+02 -1.1201798e+03\\\n",
      "          \\  5.9377930e+01  1.4172114e+03]\"\n",
      "    num_agent_steps_sampled: 193000\n",
      "    num_agent_steps_trained: 1536032\n",
      "    num_steps_sampled: 193000\n",
      "    num_steps_trained: 1536032\n",
      "    num_target_updates: 381\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.152631578947364\n",
      "    ram_util_percent: 91.69473684210526\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039806902873369875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.294580426859444\n",
      "    mean_inference_ms: 1.561317018017717\n",
      "    mean_raw_obs_processing_ms: 2.651751148569511\n",
      "  time_since_restore: 3113.217437505722\n",
      "  time_this_iter_s: 13.430207252502441\n",
      "  time_total_s: 3113.217437505722\n",
      "  timers:\n",
      "    learn_throughput: 3707.549\n",
      "    learn_time_ms: 8.631\n",
      "    load_throughput: 62733.222\n",
      "    load_time_ms: 0.51\n",
      "    update_time_ms: 1.734\n",
      "  timestamp: 1632004543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 193000\n",
      "  training_iteration: 193\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">         3113.22</td><td style=\"text-align: right;\">193000</td><td style=\"text-align: right;\">   -1.25</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 194000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-35-56\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.22\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 200\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 193528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2895383.0\n",
      "          mean_q: 144348.15625\n",
      "          min_q: -2343.015625\n",
      "        mean_td_error: 2412.6090689897537\n",
      "        td_error: \"[ 2.20464661e+02 -1.89095469e+04  3.11005859e+01  4.68676758e+02\\n\\\n",
      "          \\  4.03315938e+04 -8.96943359e+02 -1.01282031e+03  3.59307500e+04\\n  4.94671875e+02\\\n",
      "          \\  7.31083813e+03  2.70517188e+03  4.99675537e+02\\n  3.09629395e+02  2.99722168e+02\\\n",
      "          \\ -4.58230642e+03  1.66357832e+04\\n -3.95529785e+01 -2.18398352e+03 -2.01693203e+04\\\n",
      "          \\  3.53800415e+02\\n  4.63418750e+04  1.71934814e+02  7.13871094e+02  2.77826211e+04\\n\\\n",
      "          \\  3.55584717e+02  1.92900156e+04  8.84225293e+03 -5.45460005e+04\\n  1.07150879e+02\\\n",
      "          \\ -2.74335781e+04  5.29568359e+02 -2.74921027e+03]\"\n",
      "    num_agent_steps_sampled: 194000\n",
      "    num_agent_steps_trained: 1544032\n",
      "    num_steps_sampled: 194000\n",
      "    num_steps_trained: 1544032\n",
      "    num_target_updates: 383\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.705\n",
      "    ram_util_percent: 91.63000000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039807579199473676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.29161991367428\n",
      "    mean_inference_ms: 1.561310927773697\n",
      "    mean_raw_obs_processing_ms: 2.64129075823352\n",
      "  time_since_restore: 3126.849096775055\n",
      "  time_this_iter_s: 13.631659269332886\n",
      "  time_total_s: 3126.849096775055\n",
      "  timers:\n",
      "    learn_throughput: 3727.773\n",
      "    learn_time_ms: 8.584\n",
      "    load_throughput: 61542.358\n",
      "    load_time_ms: 0.52\n",
      "    update_time_ms: 1.716\n",
      "  timestamp: 1632004556\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 194000\n",
      "  training_iteration: 194\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">         3126.85</td><td style=\"text-align: right;\">194000</td><td style=\"text-align: right;\">   -1.22</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 195000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-36-10\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.21\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 201\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 194536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 588731.5625\n",
      "          mean_q: 83258.734375\n",
      "          min_q: 195.33189392089844\n",
      "        mean_td_error: -148044.37498664856\n",
      "        td_error: \"[-2.55565918e+02  4.10237305e+02 -1.61255125e+05  5.99863281e+01\\n\\\n",
      "          \\  8.24258209e+02  9.59709473e+01 -1.57526367e+02  6.65893555e+01\\n  6.82650000e+03\\\n",
      "          \\ -5.08679590e+03  2.93792892e+02 -1.73771875e+03\\n  1.83125732e+02  3.82835938e+04\\\n",
      "          \\ -2.25394062e+04 -7.44641113e+01\\n  1.19627793e+04 -5.24253848e+04  2.33897522e+02\\\n",
      "          \\ -9.65134277e+03\\n -4.42232965e+06 -9.71041309e+03 -1.02881758e+04  8.11484375e+01\\n\\\n",
      "          \\ -3.88531641e+03 -1.87778546e+03 -5.98768438e+04  3.70114331e+03\\n -3.60866250e+04\\\n",
      "          \\ -2.30809464e+02  8.76539795e+02 -3.85061426e+03]\"\n",
      "    num_agent_steps_sampled: 195000\n",
      "    num_agent_steps_trained: 1552032\n",
      "    num_steps_sampled: 195000\n",
      "    num_steps_trained: 1552032\n",
      "    num_target_updates: 385\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.84736842105263\n",
      "    ram_util_percent: 91.57894736842104\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039808288823767975\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.288655714129938\n",
      "    mean_inference_ms: 1.5613059344318676\n",
      "    mean_raw_obs_processing_ms: 2.6310502570520016\n",
      "  time_since_restore: 3140.329111814499\n",
      "  time_this_iter_s: 13.48001503944397\n",
      "  time_total_s: 3140.329111814499\n",
      "  timers:\n",
      "    learn_throughput: 3740.677\n",
      "    learn_time_ms: 8.555\n",
      "    load_throughput: 63634.424\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.69\n",
      "  timestamp: 1632004570\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 195000\n",
      "  training_iteration: 195\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         3140.33</td><td style=\"text-align: right;\">195000</td><td style=\"text-align: right;\">   -1.21</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 196000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-36-23\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.21\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 202\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 195544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 587530.3125\n",
      "          mean_q: 78772.75\n",
      "          min_q: 65.19821166992188\n",
      "        mean_td_error: 210.865234375\n",
      "        td_error: \"[-6.6316943e+02  2.0502439e+03 -6.0463812e+04 -4.0759570e+02\\n -1.7123567e+03\\\n",
      "          \\ -2.6498219e+04  4.5798926e+02 -4.2879517e+02\\n  1.2973971e+04  7.5451172e+01\\\n",
      "          \\ -2.3619497e+03 -9.4541992e+01\\n  3.8433544e+05 -3.2552594e+04 -1.1904727e+03\\\n",
      "          \\ -7.4859617e+04\\n  5.0841663e+02  5.2780859e+02  2.0465529e+02 -1.0014703e+05\\n\\\n",
      "          \\ -5.0574023e+02 -4.6880812e+04 -1.3915186e+02 -1.7386050e+03\\n -1.7464098e+04\\\n",
      "          \\  5.0114258e+01 -4.7264014e+02 -3.1529814e+03\\n -1.3171229e+04 -3.2892939e+03\\\n",
      "          \\ -6.1607993e+03 -8.0886841e+01]\"\n",
      "    num_agent_steps_sampled: 196000\n",
      "    num_agent_steps_trained: 1560032\n",
      "    num_steps_sampled: 196000\n",
      "    num_steps_trained: 1560032\n",
      "    num_target_updates: 387\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.66315789473684\n",
      "    ram_util_percent: 91.67894736842105\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03980888920934632\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.285668601994253\n",
      "    mean_inference_ms: 1.5612982375763729\n",
      "    mean_raw_obs_processing_ms: 2.621024466349086\n",
      "  time_since_restore: 3153.735880613327\n",
      "  time_this_iter_s: 13.406768798828125\n",
      "  time_total_s: 3153.735880613327\n",
      "  timers:\n",
      "    learn_throughput: 3730.291\n",
      "    learn_time_ms: 8.578\n",
      "    load_throughput: 62374.63\n",
      "    load_time_ms: 0.513\n",
      "    update_time_ms: 1.708\n",
      "  timestamp: 1632004583\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 196000\n",
      "  training_iteration: 196\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   196</td><td style=\"text-align: right;\">         3153.74</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">   -1.21</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 197000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-36-37\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.26\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 203\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 196552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7017997.0\n",
      "          mean_q: 353639.84375\n",
      "          min_q: 430.2085266113281\n",
      "        mean_td_error: -483713.78125\n",
      "        td_error: \"[-4.7913250e+04  6.1321219e+04  1.0979258e+03 -1.9194219e+03\\n -4.0458813e+02\\\n",
      "          \\ -2.0025363e+04 -4.2319961e+03  6.4518066e+01\\n -7.7374480e+06 -1.3855124e+02\\\n",
      "          \\ -5.5034160e+03  3.3816000e+04\\n -9.9378984e+03 -1.4786963e+02  1.9922094e+04\\\n",
      "          \\ -2.7518140e+02\\n  8.1309922e+03  1.0661587e+03 -7.7374480e+06 -2.3006494e+03\\n\\\n",
      "          \\  2.1495413e+03  8.2122227e+03  3.6406671e+02 -5.8591031e+04\\n -1.9099326e+03\\\n",
      "          \\  7.7100488e+03  4.1004102e+02  9.3286621e+01\\n  1.3623733e+03 -4.2109777e+04\\\n",
      "          \\  4.2537188e+04  3.2061997e+03]\"\n",
      "    num_agent_steps_sampled: 197000\n",
      "    num_agent_steps_trained: 1568032\n",
      "    num_steps_sampled: 197000\n",
      "    num_steps_trained: 1568032\n",
      "    num_target_updates: 389\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.11000000000001\n",
      "    ram_util_percent: 91.58\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039809475993356803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.282700571829146\n",
      "    mean_inference_ms: 1.5612907695231255\n",
      "    mean_raw_obs_processing_ms: 2.611209384335582\n",
      "  time_since_restore: 3167.758524656296\n",
      "  time_this_iter_s: 14.02264404296875\n",
      "  time_total_s: 3167.758524656296\n",
      "  timers:\n",
      "    learn_throughput: 3663.248\n",
      "    learn_time_ms: 8.735\n",
      "    load_throughput: 59414.665\n",
      "    load_time_ms: 0.539\n",
      "    update_time_ms: 1.744\n",
      "  timestamp: 1632004597\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 197000\n",
      "  training_iteration: 197\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">         3167.76</td><td style=\"text-align: right;\">197000</td><td style=\"text-align: right;\">   -1.26</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 198000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-36-51\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.21\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 204\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 197560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2395983.5\n",
      "          mean_q: 202524.875\n",
      "          min_q: 252.1014404296875\n",
      "        mean_td_error: 13602.181640625\n",
      "        td_error: \"[-1.9733301e+02 -1.8184734e+04 -5.1598599e+03 -2.2511361e+04\\n -3.7491973e+03\\\n",
      "          \\ -4.8321500e+04 -2.0966094e+03 -1.0685991e+04\\n  2.4521167e+02 -1.6934180e+02\\\n",
      "          \\ -6.9933875e+04  6.1026764e+01\\n  9.1440686e+02  6.4581512e+05  9.9904375e+03\\\n",
      "          \\  1.7759131e+02\\n -3.5152441e+02  1.3619502e+03 -4.9077686e+02  1.3117456e+02\\n\\\n",
      "          \\ -1.5941797e+02 -2.5663945e+04 -3.6656641e+03 -3.3292461e+03\\n -2.3676787e+03\\\n",
      "          \\ -2.0311655e+03 -2.8993652e+03 -8.6251709e+03\\n -8.6045898e+01  2.7904260e+02\\\n",
      "          \\  6.9730000e+03  6.9177246e-01]\"\n",
      "    num_agent_steps_sampled: 198000\n",
      "    num_agent_steps_trained: 1576032\n",
      "    num_steps_sampled: 198000\n",
      "    num_steps_trained: 1576032\n",
      "    num_target_updates: 391\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.19\n",
      "    ram_util_percent: 91.65\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981011216816313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.279792833074417\n",
      "    mean_inference_ms: 1.561284650834034\n",
      "    mean_raw_obs_processing_ms: 2.6015986647297025\n",
      "  time_since_restore: 3181.6598842144012\n",
      "  time_this_iter_s: 13.901359558105469\n",
      "  time_total_s: 3181.6598842144012\n",
      "  timers:\n",
      "    learn_throughput: 3684.456\n",
      "    learn_time_ms: 8.685\n",
      "    load_throughput: 59207.609\n",
      "    load_time_ms: 0.54\n",
      "    update_time_ms: 1.757\n",
      "  timestamp: 1632004611\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 198000\n",
      "  training_iteration: 198\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   198</td><td style=\"text-align: right;\">         3181.66</td><td style=\"text-align: right;\">198000</td><td style=\"text-align: right;\">   -1.21</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 199000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-37-05\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.21\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 205\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 198568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5833923.5\n",
      "          mean_q: 694610.5\n",
      "          min_q: 432.8189392089844\n",
      "        mean_td_error: -446281.40625\n",
      "        td_error: \"[-1.1774053e+05  3.3672598e+03 -4.3279188e+04  1.6318250e+04\\n  1.4109264e+04\\\n",
      "          \\  1.8123641e+04  4.4398125e+03  4.8380019e+05\\n -3.7098242e+02  4.2312500e+04\\\n",
      "          \\ -2.1043750e+05 -5.5307910e+03\\n  5.0837891e+01 -4.9042520e+03 -1.8048730e+04\\\n",
      "          \\ -1.3035233e+04\\n -1.8354048e+03 -4.5010273e+04  5.3794292e+03 -7.6734625e+04\\n\\\n",
      "          \\  1.6769150e+03 -1.0194685e+03 -6.5769678e+02  1.3773701e+03\\n -2.0915825e+05\\\n",
      "          \\ -1.3993050e+07 -5.8386445e+03 -7.1848926e+02\\n -2.0915825e+05  4.2434125e+04\\\n",
      "          \\  4.2434125e+04 -3.0086780e+02]\"\n",
      "    num_agent_steps_sampled: 199000\n",
      "    num_agent_steps_trained: 1584032\n",
      "    num_steps_sampled: 199000\n",
      "    num_steps_trained: 1584032\n",
      "    num_target_updates: 393\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.695\n",
      "    ram_util_percent: 91.765\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981076032514795\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.276962927959\n",
      "    mean_inference_ms: 1.5612791093843998\n",
      "    mean_raw_obs_processing_ms: 2.59218756935221\n",
      "  time_since_restore: 3195.5759642124176\n",
      "  time_this_iter_s: 13.916079998016357\n",
      "  time_total_s: 3195.5759642124176\n",
      "  timers:\n",
      "    learn_throughput: 3489.292\n",
      "    learn_time_ms: 9.171\n",
      "    load_throughput: 58289.641\n",
      "    load_time_ms: 0.549\n",
      "    update_time_ms: 1.807\n",
      "  timestamp: 1632004625\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199000\n",
      "  training_iteration: 199\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">         3195.58</td><td style=\"text-align: right;\">199000</td><td style=\"text-align: right;\">   -1.21</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 200000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-37-18\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.21\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 206\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 199576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1913444.0\n",
      "          mean_q: 227469.90625\n",
      "          min_q: -2827.6884765625\n",
      "        mean_td_error: -1187919.3727741241\n",
      "        td_error: \"[-6.87324922e+04 -2.23545586e+04 -7.63146924e+03  4.46512500e+04\\n\\\n",
      "          \\  7.39916250e+04  3.13765438e+05 -8.05873750e+04 -7.05495654e+03\\n -1.93660088e+04\\\n",
      "          \\  9.95724688e+04 -2.05294250e+05 -2.13205625e+05\\n -1.13751594e+05 -1.81956338e+07\\\n",
      "          \\  3.26028000e+05 -6.53542031e+04\\n  1.61121484e+04 -4.61698193e+03 -6.53542031e+04\\\n",
      "          \\  7.13878418e+03\\n  5.33330518e+03 -1.57154059e+06 -1.91039922e+04  6.67671875e+02\\n\\\n",
      "          \\ -1.75380859e+02  4.65294922e+02 -2.67170625e+04 -1.96415859e+04\\n -1.81956338e+07\\\n",
      "          \\  4.84369531e+03 -6.19803516e+03  1.95825781e+03]\"\n",
      "    num_agent_steps_sampled: 200000\n",
      "    num_agent_steps_trained: 1592032\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 1592032\n",
      "    num_target_updates: 395\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.511111111111106\n",
      "    ram_util_percent: 91.83888888888889\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981135380304061\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.274063765409068\n",
      "    mean_inference_ms: 1.5612719034793452\n",
      "    mean_raw_obs_processing_ms: 2.5829712693267037\n",
      "  time_since_restore: 3208.1583893299103\n",
      "  time_this_iter_s: 12.582425117492676\n",
      "  time_total_s: 3208.1583893299103\n",
      "  timers:\n",
      "    learn_throughput: 3586.092\n",
      "    learn_time_ms: 8.923\n",
      "    load_throughput: 51624.189\n",
      "    load_time_ms: 0.62\n",
      "    update_time_ms: 1.762\n",
      "  timestamp: 1632004638\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 200\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         3208.16</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">   -1.21</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 201000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-37-30\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.21\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 207\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 200584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2295334.0\n",
      "          mean_q: 294823.1875\n",
      "          min_q: 766.5291748046875\n",
      "        mean_td_error: 24335.236366271973\n",
      "        td_error: \"[-8.08932812e+03  5.58098438e+03 -5.41116016e+03  2.77759500e+05\\n\\\n",
      "          \\  2.56552344e+03 -1.14641094e+04  1.45676422e+05 -1.03960594e+05\\n  3.71258125e+04\\\n",
      "          \\ -4.23134961e+04  6.65099062e+04 -1.92422656e+03\\n  1.94307766e+05  3.26669727e+03\\\n",
      "          \\  8.02197734e+04 -2.56159375e+03\\n  1.92020000e+04  3.54944719e+05 -2.10894594e+05\\\n",
      "          \\  2.54573047e+03\\n -6.44230000e+04 -3.12897930e+04  7.43440703e+04  1.76979473e+04\\n\\\n",
      "          \\  1.25988781e+05 -4.50404844e+04 -2.65876750e+05 -8.17715625e+03\\n  1.65894759e+05\\\n",
      "          \\  1.78141211e+03  4.70954980e+03  3.24953613e+01]\"\n",
      "    num_agent_steps_sampled: 201000\n",
      "    num_agent_steps_trained: 1600032\n",
      "    num_steps_sampled: 201000\n",
      "    num_steps_trained: 1600032\n",
      "    num_target_updates: 397\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.94705882352941\n",
      "    ram_util_percent: 91.78235294117647\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039811974378572555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.271113592018377\n",
      "    mean_inference_ms: 1.5612651095764591\n",
      "    mean_raw_obs_processing_ms: 2.573944320015716\n",
      "  time_since_restore: 3220.1066501140594\n",
      "  time_this_iter_s: 11.94826078414917\n",
      "  time_total_s: 3220.1066501140594\n",
      "  timers:\n",
      "    learn_throughput: 3552.933\n",
      "    learn_time_ms: 9.007\n",
      "    load_throughput: 60521.138\n",
      "    load_time_ms: 0.529\n",
      "    update_time_ms: 1.703\n",
      "  timestamp: 1632004650\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 201000\n",
      "  training_iteration: 201\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         3220.11</td><td style=\"text-align: right;\">201000</td><td style=\"text-align: right;\">   -1.21</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 202000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-37-42\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.21\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 208\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 201592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11505769.0\n",
      "          mean_q: 2029633.5\n",
      "          min_q: 5782.97509765625\n",
      "        mean_td_error: -2055200.1933441162\n",
      "        td_error: \"[-1.93988050e+06 -4.96892750e+05 -2.50860250e+05  1.89495654e+03\\n\\\n",
      "          \\  4.10849000e+05 -3.99944031e+05  4.44343000e+05 -2.41913250e+06\\n  6.74000195e+04\\\n",
      "          \\ -3.50756055e+03 -2.72975125e+05  1.68186758e+04\\n -5.49369150e+06  3.19498328e+05\\\n",
      "          \\  1.10946000e+05 -2.95764508e+07\\n -3.86304844e+04  3.22361164e+05  9.30480781e+04\\\n",
      "          \\  1.58056672e+05\\n -5.15679539e+05  2.66433672e+04 -2.26965723e+03 -3.20023984e+04\\n\\\n",
      "          \\  4.71015625e+01  3.90180906e+05  1.38563850e+06 -1.42603516e+03\\n -1.00797125e+05\\\n",
      "          \\ -2.95764508e+07  1.01764000e+06  5.88819000e+05]\"\n",
      "    num_agent_steps_sampled: 202000\n",
      "    num_agent_steps_trained: 1608032\n",
      "    num_steps_sampled: 202000\n",
      "    num_steps_trained: 1608032\n",
      "    num_target_updates: 399\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.21764705882352\n",
      "    ram_util_percent: 91.86470588235295\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981260319058822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.26806765782279\n",
      "    mean_inference_ms: 1.5612587016357033\n",
      "    mean_raw_obs_processing_ms: 2.565102991764957\n",
      "  time_since_restore: 3231.907995700836\n",
      "  time_this_iter_s: 11.801345586776733\n",
      "  time_total_s: 3231.907995700836\n",
      "  timers:\n",
      "    learn_throughput: 3530.382\n",
      "    learn_time_ms: 9.064\n",
      "    load_throughput: 58787.494\n",
      "    load_time_ms: 0.544\n",
      "    update_time_ms: 1.739\n",
      "  timestamp: 1632004662\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 202000\n",
      "  training_iteration: 202\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   202</td><td style=\"text-align: right;\">         3231.91</td><td style=\"text-align: right;\">202000</td><td style=\"text-align: right;\">   -1.21</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 203000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-37-53\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.21\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 209\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 202600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 43128888.0\n",
      "          mean_q: 4782765.0\n",
      "          min_q: 5134.30078125\n",
      "        mean_td_error: -2120074.2198791504\n",
      "        td_error: \"[ 1.71827500e+04 -5.04750188e+05 -3.04043125e+04  2.88159000e+06\\n\\\n",
      "          \\  1.76810156e+03  1.11704594e+05  3.33173000e+05 -2.55841562e+05\\n -4.11278000e+05\\\n",
      "          \\ -8.51811719e+04  4.40244800e+06 -1.04366500e+05\\n -2.05244750e+05  2.06983398e+02\\\n",
      "          \\ -1.15969062e+05 -3.72728964e+07\\n -3.90170625e+04 -2.43315047e+05  4.59221200e+06\\\n",
      "          \\ -1.71552344e+05\\n -4.04960900e+06 -3.72728964e+07  6.01717090e+04 -2.49273500e+05\\n\\\n",
      "          \\  1.29532222e+06 -4.03023688e+05 -2.57532227e+03 -3.15978945e+04\\n -1.02205133e+05\\\n",
      "          \\ -2.05907031e+03  8.29363750e+04 -6.80344102e+04]\"\n",
      "    num_agent_steps_sampled: 203000\n",
      "    num_agent_steps_trained: 1616032\n",
      "    num_steps_sampled: 203000\n",
      "    num_steps_trained: 1616032\n",
      "    num_target_updates: 401\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.49375\n",
      "    ram_util_percent: 92.025\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039813259696059894\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.264911107212285\n",
      "    mean_inference_ms: 1.5612531246291632\n",
      "    mean_raw_obs_processing_ms: 2.556441617748693\n",
      "  time_since_restore: 3243.382021665573\n",
      "  time_this_iter_s: 11.474025964736938\n",
      "  time_total_s: 3243.382021665573\n",
      "  timers:\n",
      "    learn_throughput: 3680.455\n",
      "    learn_time_ms: 8.695\n",
      "    load_throughput: 60540.247\n",
      "    load_time_ms: 0.529\n",
      "    update_time_ms: 1.751\n",
      "  timestamp: 1632004673\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 203000\n",
      "  training_iteration: 203\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   203</td><td style=\"text-align: right;\">         3243.38</td><td style=\"text-align: right;\">203000</td><td style=\"text-align: right;\">   -1.21</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 204000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-38-05\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.21\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 210\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 203608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 27563712.0\n",
      "          mean_q: 3651834.0\n",
      "          min_q: 7713.92919921875\n",
      "        mean_td_error: 693627.0625\n",
      "        td_error: \"[-1.8606641e+03 -8.5955062e+04  8.7821000e+04  3.2595516e+04\\n -7.6990125e+04\\\n",
      "          \\ -3.2932922e+04 -1.1445500e+05  3.7108562e+04\\n  2.9531875e+05 -2.5699880e+06\\\n",
      "          \\ -2.2469438e+04  6.9003500e+04\\n -5.5030391e+03 -1.5638669e+05 -1.5232500e+04\\\n",
      "          \\ -1.1833515e+06\\n  4.2538312e+05 -2.7402516e+04 -5.9721734e+04  6.6109758e+04\\n\\\n",
      "          \\  8.7821000e+04  3.1361816e+03  5.9056016e+03 -2.6580300e+05\\n  2.4901472e+07\\\n",
      "          \\  1.6588600e+05  9.6317894e+05 -1.6364416e+05\\n  6.5393219e+05 -7.3283359e+04\\\n",
      "          \\ -9.5324981e+05  2.0962488e+05]\"\n",
      "    num_agent_steps_sampled: 204000\n",
      "    num_agent_steps_trained: 1624032\n",
      "    num_steps_sampled: 204000\n",
      "    num_steps_trained: 1624032\n",
      "    num_target_updates: 403\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.52352941176471\n",
      "    ram_util_percent: 92.32352941176471\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981384530959556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.261664129083895\n",
      "    mean_inference_ms: 1.561245765923962\n",
      "    mean_raw_obs_processing_ms: 2.5479564718658505\n",
      "  time_since_restore: 3254.862065553665\n",
      "  time_this_iter_s: 11.480043888092041\n",
      "  time_total_s: 3254.862065553665\n",
      "  timers:\n",
      "    learn_throughput: 3680.849\n",
      "    learn_time_ms: 8.694\n",
      "    load_throughput: 58112.975\n",
      "    load_time_ms: 0.551\n",
      "    update_time_ms: 1.729\n",
      "  timestamp: 1632004685\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 204000\n",
      "  training_iteration: 204\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">         3254.86</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\">   -1.21</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 205000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-38-16\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 211\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 204616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 43080792.0\n",
      "          mean_q: 7873250.0\n",
      "          min_q: 17680.693359375\n",
      "        mean_td_error: 1338492.75\n",
      "        td_error: \"[ 4.5636188e+05  2.2023975e+03 -1.2725600e+06  7.1772480e+06\\n -2.5283047e+03\\\n",
      "          \\ -2.3247656e+04 -7.9335000e+05  3.4166364e+07\\n -1.3271550e+06  4.6910525e+05\\\n",
      "          \\  3.1677862e+05  7.0033080e+06\\n -8.5492825e+05 -2.6040531e+05 -3.2132805e+06\\\n",
      "          \\ -1.5148610e+06\\n -2.4461544e+05  4.8640660e+06 -1.1500383e+04 -2.0124800e+05\\n\\\n",
      "          \\  4.0761288e+06  2.0608788e+05  3.9309930e+04  5.5441250e+04\\n  2.1783502e+05\\\n",
      "          \\ -3.1692453e+04 -1.5445670e+06  1.9675320e+06\\n -8.5492825e+05 -7.4275700e+06\\\n",
      "          \\ -4.7906550e+05  1.8714960e+06]\"\n",
      "    num_agent_steps_sampled: 205000\n",
      "    num_agent_steps_trained: 1632032\n",
      "    num_steps_sampled: 205000\n",
      "    num_steps_trained: 1632032\n",
      "    num_target_updates: 405\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.275\n",
      "    ram_util_percent: 92.4125\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981438057334032\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.258301514276404\n",
      "    mean_inference_ms: 1.5612344934164124\n",
      "    mean_raw_obs_processing_ms: 2.539641905735182\n",
      "  time_since_restore: 3266.223233938217\n",
      "  time_this_iter_s: 11.361168384552002\n",
      "  time_total_s: 3266.223233938217\n",
      "  timers:\n",
      "    learn_throughput: 3631.707\n",
      "    learn_time_ms: 8.811\n",
      "    load_throughput: 63622.359\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.76\n",
      "  timestamp: 1632004696\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 205000\n",
      "  training_iteration: 205\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   205</td><td style=\"text-align: right;\">         3266.22</td><td style=\"text-align: right;\">205000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 206000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-38-27\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 212\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 205624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 47374324.0\n",
      "          mean_q: 6666175.0\n",
      "          min_q: 17532.912109375\n",
      "        mean_td_error: -2031177.875\n",
      "        td_error: \"[-2.1160000e+06 -4.2267578e+03 -4.0051744e+05 -2.5132850e+05\\n -2.3409108e+06\\\n",
      "          \\  5.3795164e+04  4.5956300e+05 -8.8769969e+04\\n -6.5526000e+05 -9.3900547e+03\\\n",
      "          \\  5.9710859e+04 -7.9908800e+05\\n -5.8936656e+07 -2.3279966e+05 -1.5003330e+04\\\n",
      "          \\ -1.5554125e+05\\n  1.8873191e+05 -2.6974650e+05 -1.9104640e+06 -1.3151453e+04\\n\\\n",
      "          \\  2.7329400e+05  1.3275146e+06  6.7442188e+02 -5.4017969e+04\\n -1.0058456e+05\\\n",
      "          \\  4.9124325e+05 -3.7258500e+04  6.0887200e+05\\n  1.6719600e+05  1.3195178e+05\\\n",
      "          \\ -2.9446178e+05 -7.5060227e+04]\"\n",
      "    num_agent_steps_sampled: 206000\n",
      "    num_agent_steps_trained: 1640032\n",
      "    num_steps_sampled: 206000\n",
      "    num_steps_trained: 1640032\n",
      "    num_target_updates: 407\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.89375\n",
      "    ram_util_percent: 92.5\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981495728959975\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.25483090040837\n",
      "    mean_inference_ms: 1.561224158895801\n",
      "    mean_raw_obs_processing_ms: 2.5314952151029555\n",
      "  time_since_restore: 3277.491674184799\n",
      "  time_this_iter_s: 11.268440246582031\n",
      "  time_total_s: 3277.491674184799\n",
      "  timers:\n",
      "    learn_throughput: 3676.261\n",
      "    learn_time_ms: 8.704\n",
      "    load_throughput: 61244.685\n",
      "    load_time_ms: 0.522\n",
      "    update_time_ms: 1.761\n",
      "  timestamp: 1632004707\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 206000\n",
      "  training_iteration: 206\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">         3277.49</td><td style=\"text-align: right;\">206000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 207000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-38-39\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 213\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 206632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 70275888.0\n",
      "          mean_q: 10748561.0\n",
      "          min_q: 44094.18359375\n",
      "        mean_td_error: -1061084.8768310547\n",
      "        td_error: \"[-2.16966016e+03  2.69137600e+06  6.06500375e+05  6.16553265e+07\\n\\\n",
      "          \\ -8.79921656e+05 -7.36400980e+07 -1.84496000e+05  1.66986125e+05\\n -1.65230250e+05\\\n",
      "          \\ -7.99644125e+05 -2.61750000e+03  5.97027500e+04\\n  1.27136200e+06  1.53725400e+06\\\n",
      "          \\  5.56724000e+05  1.53725400e+06\\n -7.47780000e+04 -1.85428350e+06  8.86791562e+04\\\n",
      "          \\  1.11261688e+05\\n -2.17523156e+05 -2.62454500e+07 -6.47909000e+05  2.22049625e+05\\n\\\n",
      "          \\  5.54919000e+05 -9.80468500e+05 -5.67841375e+05  3.39844000e+05\\n  4.59175600e+06\\\n",
      "          \\ -1.35643410e+05 -4.02793324e+06  4.80296094e+05]\"\n",
      "    num_agent_steps_sampled: 207000\n",
      "    num_agent_steps_trained: 1648032\n",
      "    num_steps_sampled: 207000\n",
      "    num_steps_trained: 1648032\n",
      "    num_target_updates: 409\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.39375\n",
      "    ram_util_percent: 92.46875\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0398155328192118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.251245278533123\n",
      "    mean_inference_ms: 1.5612138180929693\n",
      "    mean_raw_obs_processing_ms: 2.523512657989168\n",
      "  time_since_restore: 3288.7139751911163\n",
      "  time_this_iter_s: 11.222301006317139\n",
      "  time_total_s: 3288.7139751911163\n",
      "  timers:\n",
      "    learn_throughput: 3710.922\n",
      "    learn_time_ms: 8.623\n",
      "    load_throughput: 63319.209\n",
      "    load_time_ms: 0.505\n",
      "    update_time_ms: 1.74\n",
      "  timestamp: 1632004719\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 207000\n",
      "  training_iteration: 207\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   207</td><td style=\"text-align: right;\">         3288.71</td><td style=\"text-align: right;\">207000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 208000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-38-51\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 214\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 207640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 128242880.0\n",
      "          mean_q: 7273338.5\n",
      "          min_q: -23120.453125\n",
      "        mean_td_error: -3468437.5\n",
      "        td_error: \"[ 4.6921362e+05 -2.8073750e+05 -4.8297800e+05 -1.4868538e+05\\n  4.4878477e+03\\\n",
      "          \\ -2.5038756e+05 -4.4597862e+05 -4.0432900e+05\\n -7.3508644e+05 -6.6342000e+04\\\n",
      "          \\  8.4257850e+06 -1.5923184e+05\\n -1.9728826e+07 -9.3843906e+03  8.8946594e+04\\\n",
      "          \\ -4.8084160e+06\\n -4.5254656e+05 -4.2556160e+04  1.6455262e+05  1.0252950e+05\\n\\\n",
      "          \\  2.8854875e+05  1.6059406e+04 -1.2601020e+06 -9.1426464e+07\\n  6.8179812e+05\\\n",
      "          \\  3.2523582e+06  1.9262775e+04 -2.6196960e+06\\n -5.9126875e+04 -1.3083108e+06\\\n",
      "          \\  1.7285375e+05  1.2800289e+04]\"\n",
      "    num_agent_steps_sampled: 208000\n",
      "    num_agent_steps_trained: 1656032\n",
      "    num_steps_sampled: 208000\n",
      "    num_steps_trained: 1656032\n",
      "    num_target_updates: 411\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.944444444444436\n",
      "    ram_util_percent: 92.76666666666667\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981620084272664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.247600251728656\n",
      "    mean_inference_ms: 1.5612061752217832\n",
      "    mean_raw_obs_processing_ms: 2.5156908917004803\n",
      "  time_since_restore: 3300.960368156433\n",
      "  time_this_iter_s: 12.246392965316772\n",
      "  time_total_s: 3300.960368156433\n",
      "  timers:\n",
      "    learn_throughput: 3320.24\n",
      "    learn_time_ms: 9.638\n",
      "    load_throughput: 45153.147\n",
      "    load_time_ms: 0.709\n",
      "    update_time_ms: 1.833\n",
      "  timestamp: 1632004731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 208000\n",
      "  training_iteration: 208\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">         3300.96</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 209000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-39-03\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 215\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 208648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 153194496.0\n",
      "          mean_q: 22034152.0\n",
      "          min_q: 102824.9296875\n",
      "        mean_td_error: -1618905.25\n",
      "        td_error: \"[ 2.89687200e+06  1.77787200e+06  1.00331600e+06 -9.54801250e+05\\n\\\n",
      "          \\ -2.75884250e+06 -3.93833625e+05  5.32356750e+05 -4.19964440e+07\\n -2.79589200e+06\\\n",
      "          \\  2.40939500e+05  2.21609200e+06 -6.13254688e+04\\n  1.22023960e+07 -1.32029450e+06\\\n",
      "          \\ -2.14045600e+06 -3.12703125e+03\\n  2.86888000e+05 -4.32008750e+04 -2.02713500e+05\\\n",
      "          \\ -3.63954875e+05\\n -1.85909375e+05 -2.33928520e+07 -4.41781600e+06 -2.19938219e+05\\n\\\n",
      "          \\ -2.67011562e+04  5.01805625e+04 -1.16051375e+05 -1.07494000e+06\\n  3.71211188e+05\\\n",
      "          \\  1.25075200e+06  2.09271600e+06  5.74253600e+06]\"\n",
      "    num_agent_steps_sampled: 209000\n",
      "    num_agent_steps_trained: 1664032\n",
      "    num_steps_sampled: 209000\n",
      "    num_steps_trained: 1664032\n",
      "    num_target_updates: 413\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.016666666666666\n",
      "    ram_util_percent: 93.09444444444443\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981702481403091\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.243879188923723\n",
      "    mean_inference_ms: 1.5612018117964788\n",
      "    mean_raw_obs_processing_ms: 2.508026007777322\n",
      "  time_since_restore: 3313.464218854904\n",
      "  time_this_iter_s: 12.50385069847107\n",
      "  time_total_s: 3313.464218854904\n",
      "  timers:\n",
      "    learn_throughput: 3371.525\n",
      "    learn_time_ms: 9.491\n",
      "    load_throughput: 39780.002\n",
      "    load_time_ms: 0.804\n",
      "    update_time_ms: 1.958\n",
      "  timestamp: 1632004743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209000\n",
      "  training_iteration: 209\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">         3313.46</td><td style=\"text-align: right;\">209000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 210000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-39-15\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 216\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 209656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 155340224.0\n",
      "          mean_q: 25131962.0\n",
      "          min_q: 275241.78125\n",
      "        mean_td_error: -9072584.767578125\n",
      "        td_error: \"[-5.20806844e+05  1.36527272e+08 -2.64543000e+05 -1.30258975e+06\\n\\\n",
      "          \\ -2.54059812e+05 -4.58641438e+05 -5.72938400e+06 -2.49446400e+07\\n -1.43625475e+07\\\n",
      "          \\ -4.72262350e+06 -2.79225428e+07  3.68803188e+05\\n  2.71978312e+05  4.97328781e+05\\\n",
      "          \\ -1.40948000e+05  1.36527272e+08\\n -2.65788750e+05  2.50120850e+06 -3.72046500e+05\\\n",
      "          \\ -2.00561560e+08\\n -4.20917625e+05 -8.32827950e+06 -3.73217300e+06 -2.00561560e+08\\n\\\n",
      "          \\ -9.62017500e+04 -5.46191360e+07 -2.74773500e+05  3.88797875e+05\\n -8.38744800e+06\\\n",
      "          \\ -4.33127000e+05 -9.84731000e+05 -7.74430400e+06]\"\n",
      "    num_agent_steps_sampled: 210000\n",
      "    num_agent_steps_trained: 1672032\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 1672032\n",
      "    num_target_updates: 415\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.035294117647055\n",
      "    ram_util_percent: 93.36470588235295\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981796400733433\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.240085982426649\n",
      "    mean_inference_ms: 1.5612003790753386\n",
      "    mean_raw_obs_processing_ms: 2.5005141152773223\n",
      "  time_since_restore: 3325.313037633896\n",
      "  time_this_iter_s: 11.8488187789917\n",
      "  time_total_s: 3325.313037633896\n",
      "  timers:\n",
      "    learn_throughput: 3376.453\n",
      "    learn_time_ms: 9.477\n",
      "    load_throughput: 52056.676\n",
      "    load_time_ms: 0.615\n",
      "    update_time_ms: 1.802\n",
      "  timestamp: 1632004755\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 210\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   210</td><td style=\"text-align: right;\">         3325.31</td><td style=\"text-align: right;\">210000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 211000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-39-27\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 217\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 210664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 217363392.0\n",
      "          mean_q: 33545224.0\n",
      "          min_q: 48563.14453125\n",
      "        mean_td_error: 5463373.0\n",
      "        td_error: \"[ 1.4294170e+06 -1.0333815e+06 -1.0454891e+04  1.0186875e+06\\n  3.9382588e+05\\\n",
      "          \\  1.9676482e+08  2.9057520e+06 -1.6147650e+05\\n  1.9214044e+07  1.2722690e+06\\\n",
      "          \\ -5.9062297e+04 -1.4977188e+03\\n  1.6800400e+06 -3.0555920e+06 -1.0822250e+05\\\n",
      "          \\  1.9676482e+08\\n  3.9586504e+07 -2.6802000e+04  1.3845868e+06 -2.6267971e+08\\n\\\n",
      "          \\  3.9628838e+05  5.5402075e+05  1.0220660e+06  2.4264250e+04\\n  2.2840466e+05\\\n",
      "          \\  3.7189950e+05  7.0391838e+05  1.5889030e+06\\n  1.7561450e+06 -1.0333815e+06\\\n",
      "          \\ -3.3078310e+07  7.0151840e+06]\"\n",
      "    num_agent_steps_sampled: 211000\n",
      "    num_agent_steps_trained: 1680032\n",
      "    num_steps_sampled: 211000\n",
      "    num_steps_trained: 1680032\n",
      "    num_target_updates: 417\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.362500000000004\n",
      "    ram_util_percent: 93.26875\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981900232116132\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.236278092527389\n",
      "    mean_inference_ms: 1.5612018415966502\n",
      "    mean_raw_obs_processing_ms: 2.4931519652932064\n",
      "  time_since_restore: 3336.8492362499237\n",
      "  time_this_iter_s: 11.536198616027832\n",
      "  time_total_s: 3336.8492362499237\n",
      "  timers:\n",
      "    learn_throughput: 3531.785\n",
      "    learn_time_ms: 9.061\n",
      "    load_throughput: 53174.489\n",
      "    load_time_ms: 0.602\n",
      "    update_time_ms: 1.806\n",
      "  timestamp: 1632004767\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 211000\n",
      "  training_iteration: 211\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   211</td><td style=\"text-align: right;\">         3336.85</td><td style=\"text-align: right;\">211000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 212000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-39-39\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.22\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 218\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 211672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 575018688.0\n",
      "          mean_q: 53516648.0\n",
      "          min_q: 52412.515625\n",
      "        mean_td_error: -26282090.0\n",
      "        td_error: \"[ 1.5038460e+06 -1.4108300e+06  1.6453636e+06  2.4636184e+07\\n  1.4861700e+05\\\n",
      "          \\ -8.4028000e+06 -1.1675055e+06 -2.7846204e+07\\n  3.2888810e+06  1.4064800e+07\\\n",
      "          \\ -2.5118475e+05 -1.3022848e+07\\n -5.4820400e+05 -6.8945312e+01  3.3225800e+05\\\n",
      "          \\  6.0137344e+05\\n -5.4126825e+05 -1.5878875e+06 -1.2035832e+07  2.8323260e+06\\n\\\n",
      "          \\ -4.2965525e+05 -4.4114198e+08 -6.0396375e+04 -4.4114198e+08\\n  2.4791408e+07\\\n",
      "          \\ -2.2404950e+06 -1.7945460e+06  2.6336069e+05\\n -4.9252212e+07  8.8337040e+07\\\n",
      "          \\ -1.9373875e+04 -5.7701012e+05]\"\n",
      "    num_agent_steps_sampled: 212000\n",
      "    num_agent_steps_trained: 1688032\n",
      "    num_steps_sampled: 212000\n",
      "    num_steps_trained: 1688032\n",
      "    num_target_updates: 419\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.19444444444444\n",
      "    ram_util_percent: 92.44444444444444\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039820217401150625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.232375568520075\n",
      "    mean_inference_ms: 1.561206566488252\n",
      "    mean_raw_obs_processing_ms: 2.485935295621539\n",
      "  time_since_restore: 3349.2569677829742\n",
      "  time_this_iter_s: 12.407731533050537\n",
      "  time_total_s: 3349.2569677829742\n",
      "  timers:\n",
      "    learn_throughput: 3261.1\n",
      "    learn_time_ms: 9.813\n",
      "    load_throughput: 52947.938\n",
      "    load_time_ms: 0.604\n",
      "    update_time_ms: 2.455\n",
      "  timestamp: 1632004779\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 212000\n",
      "  training_iteration: 212\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">         3349.26</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">   -1.22</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 213000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-39-52\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.2\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 219\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 212680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 981776000.0\n",
      "          mean_q: 110752576.0\n",
      "          min_q: 105576.859375\n",
      "        mean_td_error: -13428005.852539062\n",
      "        td_error: \"[-7.05435812e+08 -4.70580000e+05 -1.32814080e+07  9.41764062e+03\\n\\\n",
      "          \\ -4.56751040e+07  3.07203750e+04 -8.10699000e+05  6.13298750e+04\\n  2.16317500e+05\\\n",
      "          \\ -4.36732325e+07  2.33340100e+06  2.84249688e+04\\n  2.63392000e+06 -4.24829040e+07\\\n",
      "          \\ -4.46704312e+05  2.61440000e+04\\n  4.46606376e+08 -5.35869600e+06  3.98685760e+07\\\n",
      "          \\  2.12807438e+05\\n -1.91175750e+05 -1.36102080e+07 -1.87888362e+06  1.96969900e+06\\n\\\n",
      "          \\ -3.47328000e+06 -5.15487210e+07  1.05576859e+05 -1.60104000e+06\\n  7.81267800e+06\\\n",
      "          \\  2.26443125e+04 -6.43343750e+05 -1.05242831e+06]\"\n",
      "    num_agent_steps_sampled: 213000\n",
      "    num_agent_steps_trained: 1696032\n",
      "    num_steps_sampled: 213000\n",
      "    num_steps_trained: 1696032\n",
      "    num_target_updates: 421\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.33888888888889\n",
      "    ram_util_percent: 92.57777777777778\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03982151416778957\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.228473799912424\n",
      "    mean_inference_ms: 1.5612119270789082\n",
      "    mean_raw_obs_processing_ms: 2.4788607679512067\n",
      "  time_since_restore: 3361.8181204795837\n",
      "  time_this_iter_s: 12.561152696609497\n",
      "  time_total_s: 3361.8181204795837\n",
      "  timers:\n",
      "    learn_throughput: 3708.645\n",
      "    learn_time_ms: 8.628\n",
      "    load_throughput: 60055.362\n",
      "    load_time_ms: 0.533\n",
      "    update_time_ms: 1.733\n",
      "  timestamp: 1632004792\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 213000\n",
      "  training_iteration: 213\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   213</td><td style=\"text-align: right;\">         3361.82</td><td style=\"text-align: right;\">213000</td><td style=\"text-align: right;\">    -1.2</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 214000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-40-05\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.19\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 220\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 213688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1179778944.0\n",
      "          mean_q: 189176528.0\n",
      "          min_q: 98169.953125\n",
      "        mean_td_error: -6299258.5\n",
      "        td_error: \"[-3.7162880e+07  1.5278040e+07  6.2710150e+08 -5.1735575e+05\\n -7.9204125e+05\\\n",
      "          \\ -1.1032326e+09  6.2710150e+08 -4.1363280e+06\\n -2.5196080e+08  1.6363200e+05\\\n",
      "          \\  6.5212469e+04 -3.9424968e+07\\n -8.4925008e+07 -4.4460300e+06  2.3234112e+08\\\n",
      "          \\ -1.5174905e+06\\n  3.0429500e+06 -8.7308200e+05 -1.1985712e+07 -1.1064969e+07\\n\\\n",
      "          \\ -9.5270125e+05 -9.0265792e+07 -7.9204125e+05 -7.5966025e+05\\n -3.9791350e+05\\\n",
      "          \\  3.2510720e+07 -1.1033092e+06 -6.3485008e+07\\n -9.0054384e+07 -1.3981025e+06\\\n",
      "          \\  3.5366125e+05  6.1713664e+07]\"\n",
      "    num_agent_steps_sampled: 214000\n",
      "    num_agent_steps_trained: 1704032\n",
      "    num_steps_sampled: 214000\n",
      "    num_steps_trained: 1704032\n",
      "    num_target_updates: 423\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.45\n",
      "    ram_util_percent: 92.47777777777777\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03982282192024986\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.224550534421098\n",
      "    mean_inference_ms: 1.5612179261172054\n",
      "    mean_raw_obs_processing_ms: 2.4719248422643405\n",
      "  time_since_restore: 3374.434794187546\n",
      "  time_this_iter_s: 12.616673707962036\n",
      "  time_total_s: 3374.434794187546\n",
      "  timers:\n",
      "    learn_throughput: 3576.326\n",
      "    learn_time_ms: 8.948\n",
      "    load_throughput: 50890.168\n",
      "    load_time_ms: 0.629\n",
      "    update_time_ms: 1.87\n",
      "  timestamp: 1632004805\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 214000\n",
      "  training_iteration: 214\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   214</td><td style=\"text-align: right;\">         3374.43</td><td style=\"text-align: right;\">214000</td><td style=\"text-align: right;\">   -1.19</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 215000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-40-17\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.19\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 221\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 214696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2319050240.0\n",
      "          mean_q: 404889536.0\n",
      "          min_q: 164563.3125\n",
      "        mean_td_error: -131451432.0\n",
      "        td_error: \"[ 7.8976256e+07 -8.2693331e+05 -3.4677125e+05 -3.5679100e+05\\n -9.6430720e+06\\\n",
      "          \\ -1.7389248e+07 -1.5934309e+09 -1.1262147e+07\\n -2.7361300e+05 -3.8172352e+07\\\n",
      "          \\  6.4062080e+06  2.0340486e+08\\n -8.0461775e+05  2.7506342e+08  6.7495424e+07\\\n",
      "          \\  1.9876594e+04\\n  3.3554725e+05  7.2146560e+07  7.0820875e+04 -4.9316480e+07\\n\\\n",
      "          \\ -3.3965276e+07  8.7622800e+05  6.7414220e+06  7.9707025e+06\\n  4.1469180e+06\\\n",
      "          \\ -2.4316812e+04  3.6700344e+07 -1.6843424e+07\\n -1.5934309e+09 -1.5934309e+09\\\n",
      "          \\ -6.9169280e+06 -3.6556800e+05]\"\n",
      "    num_agent_steps_sampled: 215000\n",
      "    num_agent_steps_trained: 1712032\n",
      "    num_steps_sampled: 215000\n",
      "    num_steps_trained: 1712032\n",
      "    num_target_updates: 425\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.144444444444446\n",
      "    ram_util_percent: 92.67222222222223\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03982415657309102\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.22059015326633\n",
      "    mean_inference_ms: 1.561224160036992\n",
      "    mean_raw_obs_processing_ms: 2.4651246748682247\n",
      "  time_since_restore: 3386.8226957321167\n",
      "  time_this_iter_s: 12.387901544570923\n",
      "  time_total_s: 3386.8226957321167\n",
      "  timers:\n",
      "    learn_throughput: 3678.569\n",
      "    learn_time_ms: 8.699\n",
      "    load_throughput: 60101.078\n",
      "    load_time_ms: 0.532\n",
      "    update_time_ms: 1.732\n",
      "  timestamp: 1632004817\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 215000\n",
      "  training_iteration: 215\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   215</td><td style=\"text-align: right;\">         3386.82</td><td style=\"text-align: right;\">215000</td><td style=\"text-align: right;\">   -1.19</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 216000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-40-30\n",
      "  done: false\n",
      "  episode_len_mean: 985.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.18\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 222\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 215704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1628687360.0\n",
      "          mean_q: 342052416.0\n",
      "          min_q: 1370578.375\n",
      "        mean_td_error: -85193872.0\n",
      "        td_error: \"[-7.7887462e+05 -2.3917739e+08  8.2885760e+06 -9.0500225e+05\\n  4.2504188e+05\\\n",
      "          \\  1.1827679e+09 -2.1901473e+09 -7.7213720e+06\\n  2.6078131e+08 -4.3303950e+06\\\n",
      "          \\ -8.0825575e+05  2.3309467e+08\\n  4.2771354e+08 -8.2482560e+07  1.3938118e+06\\\n",
      "          \\ -2.1901473e+09\\n  3.9779600e+05 -7.0233216e+07 -1.5280594e+08 -1.2512300e+07\\n\\\n",
      "          \\  1.4374944e+07 -1.3174845e+06  2.3309467e+08  4.5465680e+06\\n  1.2583666e+08\\\n",
      "          \\ -8.8550560e+06 -8.3443800e+07 -5.1073652e+07\\n -1.4941888e+08 -1.9148578e+06\\\n",
      "          \\  9.3280000e+05  2.8221600e+07]\"\n",
      "    num_agent_steps_sampled: 216000\n",
      "    num_agent_steps_trained: 1720032\n",
      "    num_steps_sampled: 216000\n",
      "    num_steps_trained: 1720032\n",
      "    num_target_updates: 427\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.35\n",
      "    ram_util_percent: 92.69999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03982549797893944\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.216543215548437\n",
      "    mean_inference_ms: 1.561230524809677\n",
      "    mean_raw_obs_processing_ms: 2.458457682251943\n",
      "  time_since_restore: 3399.8086845874786\n",
      "  time_this_iter_s: 12.985988855361938\n",
      "  time_total_s: 3399.8086845874786\n",
      "  timers:\n",
      "    learn_throughput: 3646.924\n",
      "    learn_time_ms: 8.775\n",
      "    load_throughput: 59163.241\n",
      "    load_time_ms: 0.541\n",
      "    update_time_ms: 1.737\n",
      "  timestamp: 1632004830\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 216000\n",
      "  training_iteration: 216\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   216</td><td style=\"text-align: right;\">         3399.81</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\">   -1.18</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            985.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 217000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-40-59\n",
      "  done: false\n",
      "  episode_len_mean: 984.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.18\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 223\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 216712\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2159449088.0\n",
      "          mean_q: 564501696.0\n",
      "          min_q: 89996.8125\n",
      "        mean_td_error: 112878984.0\n",
      "        td_error: \"[ 1.45553675e+06  1.13077888e+06  2.02161248e+08  1.71396608e+09\\n\\\n",
      "          \\ -9.34924000e+05 -6.33284160e+07 -9.02641500e+05  1.71396608e+09\\n -1.21774484e+05\\\n",
      "          \\ -3.52683520e+07  1.66755275e+06  4.22513920e+07\\n  7.98403200e+06 -3.59809824e+08\\\n",
      "          \\ -7.34814000e+05 -1.18484750e+06\\n  6.12902400e+07 -3.15199904e+08 -2.12273536e+08\\\n",
      "          \\  1.51645440e+07\\n  8.24934400e+06  8.25434062e+04 -7.95967520e+07  5.85860800e+06\\n\\\n",
      "          \\  1.85419600e+06  2.02161248e+08  2.02161248e+08  3.96851200e+06\\n  4.23436640e+07\\\n",
      "          \\  7.68069000e+05  1.85419600e+06  4.51144224e+08]\"\n",
      "    num_agent_steps_sampled: 217000\n",
      "    num_agent_steps_trained: 1728032\n",
      "    num_steps_sampled: 217000\n",
      "    num_steps_trained: 1728032\n",
      "    num_target_updates: 429\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.785714285714285\n",
      "    ram_util_percent: 92.51904761904761\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039826758254945235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.212421227420613\n",
      "    mean_inference_ms: 1.5612351882827633\n",
      "    mean_raw_obs_processing_ms: 2.452676844196064\n",
      "  time_since_restore: 3429.121724128723\n",
      "  time_this_iter_s: 29.313039541244507\n",
      "  time_total_s: 3429.121724128723\n",
      "  timers:\n",
      "    learn_throughput: 3473.786\n",
      "    learn_time_ms: 9.212\n",
      "    load_throughput: 30860.326\n",
      "    load_time_ms: 1.037\n",
      "    update_time_ms: 1.839\n",
      "  timestamp: 1632004859\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 217000\n",
      "  training_iteration: 217\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   217</td><td style=\"text-align: right;\">         3429.12</td><td style=\"text-align: right;\">217000</td><td style=\"text-align: right;\">   -1.18</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">             984.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 218000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-41-14\n",
      "  done: false\n",
      "  episode_len_mean: 984.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.18\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 224\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 217720\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2953282816.0\n",
      "          mean_q: 581915392.0\n",
      "          min_q: 3932462.75\n",
      "        mean_td_error: -106468192.0\n",
      "        td_error: \"[ 1.2905600e+07 -3.6579200e+07  2.5182349e+08  3.7893150e+05\\n  5.4206400e+06\\\n",
      "          \\  2.7022080e+06 -1.0820992e+07  2.1023629e+09\\n -2.9999925e+05 -1.4644710e+06\\\n",
      "          \\ -9.0821632e+07  9.9378540e+06\\n  2.1023629e+09 -4.3478918e+08  2.2738110e+06\\\n",
      "          \\ -3.8748666e+08\\n -3.4689640e+07  6.2608038e+08  1.2111712e+08 -5.6703360e+06\\n\\\n",
      "          \\ -1.4069200e+06  9.6837000e+04 -1.6160066e+07 -1.1717688e+09\\n -2.7163450e+08\\\n",
      "          \\ -1.3107500e+05 -4.5107569e+09  2.3062110e+06\\n -1.1717688e+09 -1.4651238e+08\\\n",
      "          \\ -3.5964163e+08  5.6521460e+06]\"\n",
      "    num_agent_steps_sampled: 218000\n",
      "    num_agent_steps_trained: 1736032\n",
      "    num_steps_sampled: 218000\n",
      "    num_steps_trained: 1736032\n",
      "    num_target_updates: 431\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.59523809523809\n",
      "    ram_util_percent: 92.10952380952381\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0398280728182281\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.208391717635646\n",
      "    mean_inference_ms: 1.5612413116960033\n",
      "    mean_raw_obs_processing_ms: 2.447020505331249\n",
      "  time_since_restore: 3443.9400973320007\n",
      "  time_this_iter_s: 14.818373203277588\n",
      "  time_total_s: 3443.9400973320007\n",
      "  timers:\n",
      "    learn_throughput: 3627.771\n",
      "    learn_time_ms: 8.821\n",
      "    load_throughput: 61771.782\n",
      "    load_time_ms: 0.518\n",
      "    update_time_ms: 1.757\n",
      "  timestamp: 1632004874\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 218000\n",
      "  training_iteration: 218\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">         3443.94</td><td style=\"text-align: right;\">218000</td><td style=\"text-align: right;\">   -1.18</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">             984.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 219000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-41-28\n",
      "  done: false\n",
      "  episode_len_mean: 984.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.19\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 225\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 218728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5565146624.0\n",
      "          mean_q: 1403057664.0\n",
      "          min_q: 3422784.0\n",
      "        mean_td_error: -419618176.0\n",
      "        td_error: \"[-1.4154966e+07 -2.6109616e+07 -4.6511104e+07 -6.5617750e+05\\n -1.8381414e+08\\\n",
      "          \\  1.8903040e+06 -2.5766400e+07 -3.7147960e+06\\n -5.6673843e+08  1.9825024e+07\\\n",
      "          \\  5.1671526e+08  5.1485980e+07\\n -6.4064881e+09 -1.4571699e+08 -1.7377446e+08\\\n",
      "          \\ -2.0036403e+08\\n  1.6501760e+06 -1.9108695e+06  3.9919650e+05  8.9824115e+08\\n\\\n",
      "          \\  2.4848896e+07 -4.8714627e+08 -1.8998541e+08  5.9444723e+08\\n -4.4141930e+08\\\n",
      "          \\  1.1991624e+07  4.4387295e+06  3.1231110e+08\\n -9.1000832e+07 -6.4064881e+09\\\n",
      "          \\  7.8469980e+06 -4.6211341e+08]\"\n",
      "    num_agent_steps_sampled: 219000\n",
      "    num_agent_steps_trained: 1744032\n",
      "    num_steps_sampled: 219000\n",
      "    num_steps_trained: 1744032\n",
      "    num_target_updates: 433\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.99\n",
      "    ram_util_percent: 92.17999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03982944643793877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.20437568267466\n",
      "    mean_inference_ms: 1.5612481840679826\n",
      "    mean_raw_obs_processing_ms: 2.441483846271625\n",
      "  time_since_restore: 3457.530480861664\n",
      "  time_this_iter_s: 13.590383529663086\n",
      "  time_total_s: 3457.530480861664\n",
      "  timers:\n",
      "    learn_throughput: 3676.352\n",
      "    learn_time_ms: 8.704\n",
      "    load_throughput: 57663.571\n",
      "    load_time_ms: 0.555\n",
      "    update_time_ms: 1.721\n",
      "  timestamp: 1632004888\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219000\n",
      "  training_iteration: 219\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   219</td><td style=\"text-align: right;\">         3457.53</td><td style=\"text-align: right;\">219000</td><td style=\"text-align: right;\">   -1.19</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">             984.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 220000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-41-41\n",
      "  done: false\n",
      "  episode_len_mean: 984.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.17\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 226\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 219736\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5403550720.0\n",
      "          mean_q: 567587456.0\n",
      "          min_q: 1919846.625\n",
      "        mean_td_error: 31175820.0\n",
      "        td_error: \"[ 3.8553920e+07 -2.6915740e+06  5.7499200e+05 -4.8589373e+08\\n  8.7504750e+05\\\n",
      "          \\ -1.3894528e+07  1.9659712e+07 -2.5720480e+06\\n -3.7900580e+06 -8.9619750e+05\\\n",
      "          \\ -2.0573501e+08  3.0461860e+06\\n  9.0824576e+07 -1.5915155e+08  1.5302848e+07\\\n",
      "          \\ -1.3894528e+07\\n  7.3491411e+08 -2.6151660e+06  1.9060224e+07 -6.0880397e+08\\n\\\n",
      "          \\  1.3163720e+06  9.0824576e+07  2.5852862e+05  1.0624440e+06\\n  2.8867700e+05\\\n",
      "          \\  5.2168000e+04  2.3507095e+06  5.9527450e+08\\n  7.9201792e+08  6.8509125e+05\\\n",
      "          \\ -2.0262500e+05  9.0824576e+07]\"\n",
      "    num_agent_steps_sampled: 220000\n",
      "    num_agent_steps_trained: 1752032\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 1752032\n",
      "    num_target_updates: 435\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.642105263157895\n",
      "    ram_util_percent: 92.10526315789473\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039830841887270235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.20038689100499\n",
      "    mean_inference_ms: 1.5612549067250476\n",
      "    mean_raw_obs_processing_ms: 2.4360650746484858\n",
      "  time_since_restore: 3470.974134206772\n",
      "  time_this_iter_s: 13.443653345108032\n",
      "  time_total_s: 3470.974134206772\n",
      "  timers:\n",
      "    learn_throughput: 3440.501\n",
      "    learn_time_ms: 9.301\n",
      "    load_throughput: 53056.777\n",
      "    load_time_ms: 0.603\n",
      "    update_time_ms: 1.803\n",
      "  timestamp: 1632004901\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 220\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   220</td><td style=\"text-align: right;\">         3470.97</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">   -1.17</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">             984.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 221000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-41-55\n",
      "  done: false\n",
      "  episode_len_mean: 984.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.12\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 227\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 220744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7036249088.0\n",
      "          mean_q: 1860403712.0\n",
      "          min_q: 3860467.5\n",
      "        mean_td_error: -166002976.0\n",
      "        td_error: \"[-8.0315760e+06 -2.5925296e+08  4.2571040e+06 -4.8716644e+07\\n -8.1479280e+06\\\n",
      "          \\ -2.7198080e+07 -2.9647744e+08 -9.2180000e+05\\n -1.4475320e+06 -2.9928602e+09\\\n",
      "          \\ -3.7514394e+08  2.0640735e+06\\n -7.6627507e+08  1.3138179e+07 -2.3436749e+08\\\n",
      "          \\ -2.7428954e+08\\n -1.8639230e+06 -9.1257280e+06  9.9850720e+07 -2.3436749e+08\\n\\\n",
      "          \\ -3.4634750e+05 -2.3436749e+08 -2.7198080e+07  5.6324928e+07\\n -3.7514394e+08\\\n",
      "          \\ -1.7671530e+06  4.5649971e+08  3.6189000e+04\\n  5.7945549e+08  4.3524736e+07\\\n",
      "          \\ -8.9273600e+05 -3.8904320e+08]\"\n",
      "    num_agent_steps_sampled: 221000\n",
      "    num_agent_steps_trained: 1760032\n",
      "    num_steps_sampled: 221000\n",
      "    num_steps_trained: 1760032\n",
      "    num_target_updates: 437\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.235\n",
      "    ram_util_percent: 92.07499999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03983226818240061\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.196384599218556\n",
      "    mean_inference_ms: 1.5612623998136952\n",
      "    mean_raw_obs_processing_ms: 2.430761706620319\n",
      "  time_since_restore: 3484.819147348404\n",
      "  time_this_iter_s: 13.84501314163208\n",
      "  time_total_s: 3484.819147348404\n",
      "  timers:\n",
      "    learn_throughput: 3645.368\n",
      "    learn_time_ms: 8.778\n",
      "    load_throughput: 61278.24\n",
      "    load_time_ms: 0.522\n",
      "    update_time_ms: 1.758\n",
      "  timestamp: 1632004915\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 221000\n",
      "  training_iteration: 221\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   221</td><td style=\"text-align: right;\">         3484.82</td><td style=\"text-align: right;\">221000</td><td style=\"text-align: right;\">   -1.12</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">             984.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 222000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-42-09\n",
      "  done: false\n",
      "  episode_len_mean: 985.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: -1.06\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 228\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 221752\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 10855632896.0\n",
      "          mean_q: 1460984576.0\n",
      "          min_q: 5959612.0\n",
      "        mean_td_error: 3038740.90625\n",
      "        td_error: \"[-4.22056960e+07 -5.27237120e+07  2.18350200e+06 -2.71181120e+07\\n\\\n",
      "          \\  1.83655900e+06 -1.49296768e+08  5.15094000e+06 -1.54265600e+07\\n  3.15453040e+07\\\n",
      "          \\ -9.97124800e+06 -4.87010692e+08 -3.14727586e+08\\n -3.14618466e+08  7.02785200e+06\\\n",
      "          \\ -5.86464960e+07 -3.14727586e+08\\n -1.01119360e+07 -3.66638400e+06 -9.78713200e+06\\\n",
      "          \\ -4.41098896e+08\\n -4.84657652e+08  5.95961200e+06  1.42849792e+09 -4.22056960e+07\\n\\\n",
      "          \\ -1.54265600e+07  1.22023497e+08 -1.49296768e+08 -1.54265600e+07\\n  1.73729120e+07\\\n",
      "          \\  3.23116400e+06  1.42849792e+09  2.06303100e+06]\"\n",
      "    num_agent_steps_sampled: 222000\n",
      "    num_agent_steps_trained: 1768032\n",
      "    num_steps_sampled: 222000\n",
      "    num_steps_trained: 1768032\n",
      "    num_target_updates: 439\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.089473684210525\n",
      "    ram_util_percent: 91.92105263157896\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03983372614961461\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.19242414793902\n",
      "    mean_inference_ms: 1.561271271944255\n",
      "    mean_raw_obs_processing_ms: 2.422214934366566\n",
      "  time_since_restore: 3498.553996324539\n",
      "  time_this_iter_s: 13.734848976135254\n",
      "  time_total_s: 3498.553996324539\n",
      "  timers:\n",
      "    learn_throughput: 3686.814\n",
      "    learn_time_ms: 8.68\n",
      "    load_throughput: 61726.328\n",
      "    load_time_ms: 0.518\n",
      "    update_time_ms: 1.752\n",
      "  timestamp: 1632004929\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 222000\n",
      "  training_iteration: 222\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   222</td><td style=\"text-align: right;\">         3498.55</td><td style=\"text-align: right;\">222000</td><td style=\"text-align: right;\">   -1.06</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">             985.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 223000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-42-22\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -1.09\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 229\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 222760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 10243731456.0\n",
      "          mean_q: 1036630656.0\n",
      "          min_q: 2971707.25\n",
      "        mean_td_error: -39208236.0\n",
      "        td_error: \"[ 4.7520768e+07 -4.6320640e+06  2.5913725e+06  2.4513128e+08\\n  8.7064304e+07\\\n",
      "          \\  6.0199200e+06 -6.6921562e+08 -8.6460544e+07\\n  9.0627330e+06 -6.3976384e+08\\\n",
      "          \\  3.6346230e+06  1.1078426e+08\\n -8.7018600e+06  2.6714050e+05  2.9197901e+08\\\n",
      "          \\ -7.3483490e+06\\n -7.4791990e+06  2.2685636e+07  1.1078426e+08  2.1176452e+06\\n\\\n",
      "          \\  1.6433254e+08 -1.6336675e+08  2.2685636e+07 -1.8277942e+08\\n  3.2330160e+06\\\n",
      "          \\ -1.3813120e+07 -1.3991500e+05  4.0877696e+07\\n -6.6921562e+08 -8.7018600e+06\\\n",
      "          \\  8.0257000e+04  3.6102520e+07]\"\n",
      "    num_agent_steps_sampled: 223000\n",
      "    num_agent_steps_trained: 1776032\n",
      "    num_steps_sampled: 223000\n",
      "    num_steps_trained: 1776032\n",
      "    num_target_updates: 441\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.836842105263166\n",
      "    ram_util_percent: 91.81052631578946\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03983520985690483\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.18844041816211\n",
      "    mean_inference_ms: 1.561280252282985\n",
      "    mean_raw_obs_processing_ms: 2.4135793148546125\n",
      "  time_since_restore: 3511.9103906154633\n",
      "  time_this_iter_s: 13.356394290924072\n",
      "  time_total_s: 3511.9103906154633\n",
      "  timers:\n",
      "    learn_throughput: 3661.309\n",
      "    learn_time_ms: 8.74\n",
      "    load_throughput: 63968.034\n",
      "    load_time_ms: 0.5\n",
      "    update_time_ms: 1.778\n",
      "  timestamp: 1632004942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 223000\n",
      "  training_iteration: 223\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   223</td><td style=\"text-align: right;\">         3511.91</td><td style=\"text-align: right;\">223000</td><td style=\"text-align: right;\">   -1.09</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 224000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-42-35\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -1.04\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 230\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 223768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4011736064.0\n",
      "          mean_q: 763646144.0\n",
      "          min_q: 6541528.5\n",
      "        mean_td_error: -60839376.0\n",
      "        td_error: \"[-4.1455062e+08 -1.3440308e+07 -1.8336486e+08  9.3562400e+05\\n  3.9721368e+07\\\n",
      "          \\  6.5288560e+06 -8.1092800e+06 -2.0648998e+08\\n -4.1178112e+08  2.6671800e+06\\\n",
      "          \\ -6.6369792e+07 -1.2767528e+07\\n -1.8336486e+08  1.0791240e+08 -7.9989760e+06\\\n",
      "          \\ -3.9565280e+06\\n -2.4242256e+07  1.2620220e+06 -6.5927680e+07 -4.7885510e+08\\n\\\n",
      "          \\ -8.6604240e+06  3.7881280e+06  2.5200100e+05  2.5539180e+07\\n -6.9254984e+07\\\n",
      "          \\ -5.6595580e+06 -1.9582080e+07  2.6671800e+06\\n -2.5515650e+06  6.3740928e+07\\\n",
      "          \\ -1.4704176e+07 -2.4312800e+05]\"\n",
      "    num_agent_steps_sampled: 224000\n",
      "    num_agent_steps_trained: 1784032\n",
      "    num_steps_sampled: 224000\n",
      "    num_steps_trained: 1784032\n",
      "    num_target_updates: 443\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.62105263157895\n",
      "    ram_util_percent: 91.98947368421054\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039836789762684593\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.184360526594213\n",
      "    mean_inference_ms: 1.5612906151284542\n",
      "    mean_raw_obs_processing_ms: 2.4050822350920096\n",
      "  time_since_restore: 3524.7484741210938\n",
      "  time_this_iter_s: 12.838083505630493\n",
      "  time_total_s: 3524.7484741210938\n",
      "  timers:\n",
      "    learn_throughput: 3276.856\n",
      "    learn_time_ms: 9.765\n",
      "    load_throughput: 48377.209\n",
      "    load_time_ms: 0.661\n",
      "    update_time_ms: 1.825\n",
      "  timestamp: 1632004955\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 224000\n",
      "  training_iteration: 224\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">         3524.75</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\">   -1.04</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 225000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-42-48\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -1.0\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 231\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 224776\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 17301368832.0\n",
      "          mean_q: 1074491904.0\n",
      "          min_q: 4751443.5\n",
      "        mean_td_error: -143588608.0\n",
      "        td_error: \"[-1.3425920e+06  1.0304505e+08  4.8484256e+08 -1.7539436e+07\\n  4.3286060e+06\\\n",
      "          \\ -1.2480963e+09 -1.3852211e+08  3.2534600e+05\\n -1.3080644e+07 -1.8003895e+06\\\n",
      "          \\ -4.0085056e+07 -5.8807904e+08\\n  4.0264000e+05 -6.0020685e+08  3.1250640e+07\\\n",
      "          \\  5.7272800e+05\\n -9.2649984e+07  4.0301930e+06  2.5246692e+07 -1.8308992e+07\\n\\\n",
      "          \\ -5.8807904e+08 -1.1048092e+09  1.6484720e+06 -1.9744554e+08\\n -5.3373680e+06\\\n",
      "          \\ -7.1044000e+05 -1.0988552e+07 -9.2649984e+07\\n -4.1429360e+06  1.7893960e+06\\\n",
      "          \\ -4.8110208e+08 -7.3414880e+06]\"\n",
      "    num_agent_steps_sampled: 225000\n",
      "    num_agent_steps_trained: 1792032\n",
      "    num_steps_sampled: 225000\n",
      "    num_steps_trained: 1792032\n",
      "    num_target_updates: 445\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.511111111111106\n",
      "    ram_util_percent: 92.61111111111109\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03983846026690565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.18025883722378\n",
      "    mean_inference_ms: 1.5613025678104606\n",
      "    mean_raw_obs_processing_ms: 2.396721017558018\n",
      "  time_since_restore: 3537.9051349163055\n",
      "  time_this_iter_s: 13.156660795211792\n",
      "  time_total_s: 3537.9051349163055\n",
      "  timers:\n",
      "    learn_throughput: 3325.86\n",
      "    learn_time_ms: 9.622\n",
      "    load_throughput: 54827.503\n",
      "    load_time_ms: 0.584\n",
      "    update_time_ms: 1.812\n",
      "  timestamp: 1632004968\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 225000\n",
      "  training_iteration: 225\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   225</td><td style=\"text-align: right;\">         3537.91</td><td style=\"text-align: right;\">225000</td><td style=\"text-align: right;\">      -1</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 226000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-43-02\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.94\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 232\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 225784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5107991040.0\n",
      "          mean_q: 669839872.0\n",
      "          min_q: 6863411.0\n",
      "        mean_td_error: -50651368.0\n",
      "        td_error: \"[-1.79265536e+08  1.94341400e+06  1.20339984e+08 -1.69684480e+08\\n\\\n",
      "          \\  3.74796300e+06  2.76646200e+06  1.94287600e+06 -3.87757248e+08\\n  1.45263640e+07\\\n",
      "          \\  3.75626240e+07  4.52538880e+07  9.51858880e+07\\n  2.48909312e+08 -1.10861312e+08\\\n",
      "          \\  4.28524120e+07 -1.32852096e+08\\n  5.72260160e+07  7.70371280e+07 -3.88321000e+06\\\n",
      "          \\  4.24046560e+07\\n -1.76198605e+09  9.38691200e+06 -4.02088000e+07  1.13686000e+05\\n\\\n",
      "          \\  6.34490080e+07  4.51844320e+07  4.49424000e+07 -5.02326720e+07\\n  1.39788752e+08\\\n",
      "          \\ -1.09843350e+06  1.24252984e+08 -1.83105600e+06]\"\n",
      "    num_agent_steps_sampled: 226000\n",
      "    num_agent_steps_trained: 1800032\n",
      "    num_steps_sampled: 226000\n",
      "    num_steps_trained: 1800032\n",
      "    num_target_updates: 447\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.559999999999995\n",
      "    ram_util_percent: 92.59500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03984025339313324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.17623468390272\n",
      "    mean_inference_ms: 1.5613175948995062\n",
      "    mean_raw_obs_processing_ms: 2.388493388761065\n",
      "  time_since_restore: 3551.583960533142\n",
      "  time_this_iter_s: 13.678825616836548\n",
      "  time_total_s: 3551.583960533142\n",
      "  timers:\n",
      "    learn_throughput: 3690.646\n",
      "    learn_time_ms: 8.671\n",
      "    load_throughput: 64549.477\n",
      "    load_time_ms: 0.496\n",
      "    update_time_ms: 1.708\n",
      "  timestamp: 1632004982\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 226000\n",
      "  training_iteration: 226\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   226</td><td style=\"text-align: right;\">         3551.58</td><td style=\"text-align: right;\">226000</td><td style=\"text-align: right;\">   -0.94</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 227000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-43-15\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 233\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 226792\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 14383218688.0\n",
      "          mean_q: 1873872512.0\n",
      "          min_q: 5748847.0\n",
      "        mean_td_error: 221137328.0\n",
      "        td_error: \"[ 2.6206042e+09  4.4469376e+07 -4.3124650e+06 -2.6317640e+06\\n  3.8857626e+08\\\n",
      "          \\  4.7488200e+05 -3.8630688e+07  4.1842534e+08\\n  1.8680160e+08  5.0340800e+05\\\n",
      "          \\ -5.0042740e+06 -7.1497555e+06\\n  5.3719680e+06 -4.3124650e+06 -1.0928416e+07\\\n",
      "          \\  1.9156275e+08\\n  5.0346344e+07  4.2884800e+06  6.4304486e+08  6.4304486e+08\\n\\\n",
      "          \\  2.4008160e+07  1.5302822e+07  1.3063200e+05  2.5124212e+07\\n -6.8819680e+06\\\n",
      "          \\  2.6206042e+09 -1.2353400e+05 -5.4118605e+08\\n  1.9156275e+08  4.9958800e+06\\\n",
      "          \\  4.3215000e+06 -3.8600877e+08]\"\n",
      "    num_agent_steps_sampled: 227000\n",
      "    num_agent_steps_trained: 1808032\n",
      "    num_steps_sampled: 227000\n",
      "    num_steps_trained: 1808032\n",
      "    num_target_updates: 449\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.26842105263158\n",
      "    ram_util_percent: 92.39999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039842078358060876\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.172251667176047\n",
      "    mean_inference_ms: 1.5613329229916875\n",
      "    mean_raw_obs_processing_ms: 2.380396045827421\n",
      "  time_since_restore: 3564.758741378784\n",
      "  time_this_iter_s: 13.17478084564209\n",
      "  time_total_s: 3564.758741378784\n",
      "  timers:\n",
      "    learn_throughput: 3599.469\n",
      "    learn_time_ms: 8.89\n",
      "    load_throughput: 54834.223\n",
      "    load_time_ms: 0.584\n",
      "    update_time_ms: 1.783\n",
      "  timestamp: 1632004995\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 227000\n",
      "  training_iteration: 227\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   227</td><td style=\"text-align: right;\">         3564.76</td><td style=\"text-align: right;\">227000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 228000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-43-28\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 234\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 227800\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5689352192.0\n",
      "          mean_q: 576475392.0\n",
      "          min_q: 7686164.0\n",
      "        mean_td_error: -142945232.0\n",
      "        td_error: \"[-1.22950784e+08 -7.84458560e+07 -4.26494400e+07 -1.33101168e+08\\n\\\n",
      "          \\ -3.02316128e+08  1.45897120e+08 -2.41457520e+07 -1.60173040e+07\\n  8.17550480e+07\\\n",
      "          \\  2.90331712e+08 -1.26088320e+08  6.11446800e+07\\n -2.14143400e+06 -8.36364800e+06\\\n",
      "          \\ -6.42464000e+06 -8.27888000e+07\\n -1.38294600e+07 -1.98104243e+09  3.82365600e+06\\\n",
      "          \\ -3.48521600e+07\\n -1.67795632e+08 -7.25096576e+08 -2.73406080e+07 -1.47585880e+07\\n\\\n",
      "          \\ -2.48131968e+08 -2.07964416e+08 -1.09930528e+08 -5.12695808e+08\\n  8.37397400e+06\\\n",
      "          \\  2.82310400e+06 -1.00950616e+08 -7.85745920e+07]\"\n",
      "    num_agent_steps_sampled: 228000\n",
      "    num_agent_steps_trained: 1816032\n",
      "    num_steps_sampled: 228000\n",
      "    num_steps_trained: 1816032\n",
      "    num_target_updates: 451\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.50526315789474\n",
      "    ram_util_percent: 92.34210526315789\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03984390339375449\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.16831994356691\n",
      "    mean_inference_ms: 1.5613486573281588\n",
      "    mean_raw_obs_processing_ms: 2.3724271597311652\n",
      "  time_since_restore: 3577.893716812134\n",
      "  time_this_iter_s: 13.13497543334961\n",
      "  time_total_s: 3577.893716812134\n",
      "  timers:\n",
      "    learn_throughput: 3678.75\n",
      "    learn_time_ms: 8.699\n",
      "    load_throughput: 61899.981\n",
      "    load_time_ms: 0.517\n",
      "    update_time_ms: 1.746\n",
      "  timestamp: 1632005008\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 228000\n",
      "  training_iteration: 228\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   228</td><td style=\"text-align: right;\">         3577.89</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 229000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-43-42\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 235\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 228808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7901500416.0\n",
      "          mean_q: 1112727552.0\n",
      "          min_q: 8690228.0\n",
      "        mean_td_error: -253791776.0\n",
      "        td_error: \"[ 2.3729800e+08  1.1047396e+07 -1.3627500e+07  4.8373472e+07\\n -4.3209354e+08\\\n",
      "          \\ -1.4010022e+08  2.3223080e+07 -2.3148800e+07\\n -6.9297696e+07 -1.2641486e+09\\\n",
      "          \\  2.0663104e+07 -1.2195664e+07\\n  3.5628640e+06  4.6929152e+07 -3.9943520e+06\\\n",
      "          \\ -7.5277760e+06\\n -8.6013747e+08  1.6964772e+09 -3.5174400e+05 -7.1994800e+05\\n\\\n",
      "          \\ -2.5964192e+07 -2.3848561e+09  6.1592992e+07  6.2600704e+07\\n -2.4369400e+06\\\n",
      "          \\  2.3433440e+06 -8.8835584e+07 -4.9991086e+09\\n  2.2175040e+07 -1.6677984e+07\\\n",
      "          \\ -7.4637440e+06 -4.9365120e+06]\"\n",
      "    num_agent_steps_sampled: 229000\n",
      "    num_agent_steps_trained: 1824032\n",
      "    num_steps_sampled: 229000\n",
      "    num_steps_trained: 1824032\n",
      "    num_target_updates: 453\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.28947368421053\n",
      "    ram_util_percent: 92.3578947368421\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039845734585848905\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.164440748669191\n",
      "    mean_inference_ms: 1.561364829987728\n",
      "    mean_raw_obs_processing_ms: 2.364584564768221\n",
      "  time_since_restore: 3591.175470352173\n",
      "  time_this_iter_s: 13.281753540039062\n",
      "  time_total_s: 3591.175470352173\n",
      "  timers:\n",
      "    learn_throughput: 3703.477\n",
      "    learn_time_ms: 8.641\n",
      "    load_throughput: 64817.563\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 2.775\n",
      "  timestamp: 1632005022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229000\n",
      "  training_iteration: 229\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   229</td><td style=\"text-align: right;\">         3591.18</td><td style=\"text-align: right;\">229000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 230000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-43-55\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 236\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 229816\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 12548227072.0\n",
      "          mean_q: 2066803200.0\n",
      "          min_q: 28487556.0\n",
      "        mean_td_error: 234811984.0\n",
      "        td_error: \"[ 3.7860800e+07  1.4139187e+08  3.0534464e+07  1.4947414e+08\\n -4.2197792e+07\\\n",
      "          \\  4.9611760e+06  2.3907360e+08 -2.3213776e+07\\n  1.2335174e+08 -2.1246072e+07\\\n",
      "          \\  3.8602776e+07 -3.2898419e+08\\n  5.7124992e+07  5.0191316e+07  2.3729920e+07\\\n",
      "          \\  1.4194800e+06\\n  3.2730440e+09  1.7328256e+07  1.2163492e+09  3.0799200e+07\\n\\\n",
      "          \\ -1.4602842e+08  1.7367514e+09 -5.0050752e+07  9.1284480e+07\\n  7.3760176e+07\\\n",
      "          \\  1.2134324e+07  4.5122086e+08  4.5122086e+08\\n  9.1284480e+07 -2.1657526e+08\\\n",
      "          \\ -2.8680800e+06  2.2543820e+06]\"\n",
      "    num_agent_steps_sampled: 230000\n",
      "    num_agent_steps_trained: 1832032\n",
      "    num_steps_sampled: 230000\n",
      "    num_steps_trained: 1832032\n",
      "    num_target_updates: 455\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.4611111111111\n",
      "    ram_util_percent: 92.45555555555556\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03984757676985609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.160610399135125\n",
      "    mean_inference_ms: 1.5613815192250688\n",
      "    mean_raw_obs_processing_ms: 2.3568668477255277\n",
      "  time_since_restore: 3604.418493270874\n",
      "  time_this_iter_s: 13.243022918701172\n",
      "  time_total_s: 3604.418493270874\n",
      "  timers:\n",
      "    learn_throughput: 3677.662\n",
      "    learn_time_ms: 8.701\n",
      "    load_throughput: 64776.896\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.681\n",
      "  timestamp: 1632005035\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 230000\n",
      "  training_iteration: 230\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">         3604.42</td><td style=\"text-align: right;\">230000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 231000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-44-08\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 237\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 230824\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 11170814976.0\n",
      "          mean_q: 3132253440.0\n",
      "          min_q: 27920560.0\n",
      "        mean_td_error: -713813632.0\n",
      "        td_error: \"[ 1.58433280e+08 -6.11768934e+09 -2.38148736e+08  8.67898368e+08\\n\\\n",
      "          \\  5.34660480e+07 -1.74232870e+09  8.92922368e+08 -7.15612160e+07\\n  1.05322394e+09\\\n",
      "          \\ -1.23358080e+08  2.50823040e+08 -4.38734976e+08\\n -2.43833600e+06  8.48411520e+07\\\n",
      "          \\ -6.39660000e+04 -5.04914600e+06\\n -1.69005824e+08 -5.81706240e+07  1.62764800e+07\\\n",
      "          \\ -1.15122600e+06\\n -1.74232870e+09  1.70613760e+08 -6.26613600e+06 -4.36199040e+07\\n\\\n",
      "          \\ -4.36199040e+07  1.06178048e+08 -7.95512320e+08 -1.61130209e+10\\n  3.74980480e+07\\\n",
      "          \\  1.19882650e+09 -2.87460000e+05 -2.06822400e+07]\"\n",
      "    num_agent_steps_sampled: 231000\n",
      "    num_agent_steps_trained: 1840032\n",
      "    num_steps_sampled: 231000\n",
      "    num_steps_trained: 1840032\n",
      "    num_target_updates: 457\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.115\n",
      "    ram_util_percent: 92.535\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039849390244431813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.156857531106077\n",
      "    mean_inference_ms: 1.5613983053206058\n",
      "    mean_raw_obs_processing_ms: 2.349270243646248\n",
      "  time_since_restore: 3617.7524201869965\n",
      "  time_this_iter_s: 13.333926916122437\n",
      "  time_total_s: 3617.7524201869965\n",
      "  timers:\n",
      "    learn_throughput: 3700.149\n",
      "    learn_time_ms: 8.648\n",
      "    load_throughput: 63128.605\n",
      "    load_time_ms: 0.507\n",
      "    update_time_ms: 1.757\n",
      "  timestamp: 1632005048\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 231000\n",
      "  training_iteration: 231\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   231</td><td style=\"text-align: right;\">         3617.75</td><td style=\"text-align: right;\">231000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 232000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-44-22\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 238\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 231832\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 23468427264.0\n",
      "          mean_q: 4917138944.0\n",
      "          min_q: 22219726.0\n",
      "        mean_td_error: -347895680.0\n",
      "        td_error: \"[ 8.5560192e+07 -5.3294600e+06  1.0310400e+05 -1.8029568e+07\\n  3.3780288e+07\\\n",
      "          \\  4.8194496e+07 -1.8029568e+07  7.9649792e+07\\n -2.8319032e+07  1.7858540e+09\\\n",
      "          \\ -9.0374287e+09 -7.4212480e+06\\n  1.2860068e+09  3.8905651e+08  3.8905651e+08\\\n",
      "          \\  1.6402523e+08\\n -3.2312128e+07 -7.6663800e+05 -2.0292432e+08  4.0784000e+05\\n\\\n",
      "          \\ -4.8536480e+06  2.7193958e+09 -5.7226720e+06 -2.6941050e+08\\n -7.8424960e+07\\\n",
      "          \\ -2.3160832e+07 -6.6519296e+07 -3.7644288e+07\\n -1.2281110e+09  4.2224211e+08\\\n",
      "          \\  1.1397984e+08 -7.5855672e+09]\"\n",
      "    num_agent_steps_sampled: 232000\n",
      "    num_agent_steps_trained: 1848032\n",
      "    num_steps_sampled: 232000\n",
      "    num_steps_trained: 1848032\n",
      "    num_target_updates: 459\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.17368421052631\n",
      "    ram_util_percent: 92.53684210526315\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03985119830923058\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.153232858911313\n",
      "    mean_inference_ms: 1.5614158010083217\n",
      "    mean_raw_obs_processing_ms: 2.341791058705326\n",
      "  time_since_restore: 3631.727205991745\n",
      "  time_this_iter_s: 13.974785804748535\n",
      "  time_total_s: 3631.727205991745\n",
      "  timers:\n",
      "    learn_throughput: 3695.107\n",
      "    learn_time_ms: 8.66\n",
      "    load_throughput: 64437.913\n",
      "    load_time_ms: 0.497\n",
      "    update_time_ms: 1.709\n",
      "  timestamp: 1632005062\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 232000\n",
      "  training_iteration: 232\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   232</td><td style=\"text-align: right;\">         3631.73</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 233000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-44-35\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 239\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 232840\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 25646485504.0\n",
      "          mean_q: 4159374336.0\n",
      "          min_q: 27110702.0\n",
      "        mean_td_error: -621244608.0\n",
      "        td_error: \"[ 1.9506419e+08 -5.2274784e+07 -5.8983040e+06 -4.8070640e+06\\n -1.1802730e+08\\\n",
      "          \\ -5.7334848e+07 -2.8085680e+06 -1.6691016e+09\\n -1.0657785e+10  1.4060240e+08\\\n",
      "          \\  9.8273638e+08 -8.0598234e+08\\n  8.0773120e+07  7.7765632e+07 -8.8405320e+06\\\n",
      "          \\  5.6331920e+07\\n -2.9403120e+06  9.9472704e+07 -5.6415200e+06 -4.3148360e+06\\n\\\n",
      "          \\  4.5493440e+06  3.0803640e+06 -8.0598234e+08 -2.3636568e+07\\n -1.7564672e+07\\\n",
      "          \\  6.6979840e+06 -3.3895547e+09  9.8242600e+06\\n -9.9543501e+08 -2.2352650e+09\\\n",
      "          \\ -7.5129549e+08  7.7765632e+07]\"\n",
      "    num_agent_steps_sampled: 233000\n",
      "    num_agent_steps_trained: 1856032\n",
      "    num_steps_sampled: 233000\n",
      "    num_steps_trained: 1856032\n",
      "    num_target_updates: 461\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.06315789473684\n",
      "    ram_util_percent: 92.6157894736842\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03985303405421459\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.149625286908503\n",
      "    mean_inference_ms: 1.5614335589373067\n",
      "    mean_raw_obs_processing_ms: 2.3344263359268864\n",
      "  time_since_restore: 3644.726295232773\n",
      "  time_this_iter_s: 12.999089241027832\n",
      "  time_total_s: 3644.726295232773\n",
      "  timers:\n",
      "    learn_throughput: 3635.652\n",
      "    learn_time_ms: 8.802\n",
      "    load_throughput: 64465.768\n",
      "    load_time_ms: 0.496\n",
      "    update_time_ms: 1.705\n",
      "  timestamp: 1632005075\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 233000\n",
      "  training_iteration: 233\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   233</td><td style=\"text-align: right;\">         3644.73</td><td style=\"text-align: right;\">233000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 234000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-44-49\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 240\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 233848\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 45024129024.0\n",
      "          mean_q: 8003854848.0\n",
      "          min_q: 32259666.0\n",
      "        mean_td_error: 186796672.0\n",
      "        td_error: \"[ 5.2950424e+07 -1.5649300e+06  5.8590208e+08  7.8198784e+08\\n  1.0654387e+08\\\n",
      "          \\  7.8198784e+08 -4.5649280e+06 -3.8340080e+06\\n -5.1923302e+08 -3.6312678e+08\\\n",
      "          \\  7.8198784e+08 -2.9696128e+07\\n  7.7214515e+08  7.8198784e+08  5.7701560e+06\\\n",
      "          \\  5.7701560e+06\\n  1.8743665e+09  1.3866199e+09  2.0969165e+08  1.3866199e+09\\n\\\n",
      "          \\ -5.2257935e+09  1.0441498e+08  1.1468176e+07  2.0654003e+08\\n -1.5097200e+06\\\n",
      "          \\  4.7227216e+07 -9.2068720e+06 -1.0087130e+08\\n  8.3965440e+07  5.3944320e+06\\\n",
      "          \\ -6.2138800e+05  2.2641746e+09]\"\n",
      "    num_agent_steps_sampled: 234000\n",
      "    num_agent_steps_trained: 1864032\n",
      "    num_steps_sampled: 234000\n",
      "    num_steps_trained: 1864032\n",
      "    num_target_updates: 463\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.16000000000001\n",
      "    ram_util_percent: 92.72\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03985486348854821\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.146146303984647\n",
      "    mean_inference_ms: 1.5614513339179306\n",
      "    mean_raw_obs_processing_ms: 2.3271756849210736\n",
      "  time_since_restore: 3658.43234705925\n",
      "  time_this_iter_s: 13.70605182647705\n",
      "  time_total_s: 3658.43234705925\n",
      "  timers:\n",
      "    learn_throughput: 3483.659\n",
      "    learn_time_ms: 9.186\n",
      "    load_throughput: 63607.283\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.743\n",
      "  timestamp: 1632005089\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 234000\n",
      "  training_iteration: 234\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   234</td><td style=\"text-align: right;\">         3658.43</td><td style=\"text-align: right;\">234000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 235000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-45-02\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 241\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 234856\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 51375665152.0\n",
      "          mean_q: 5954769920.0\n",
      "          min_q: 36036368.0\n",
      "        mean_td_error: -205789728.0\n",
      "        td_error: \"[ 4.0802778e+08  4.8085402e+08 -8.9338650e+08  4.8085402e+08\\n  4.8042330e+08\\\n",
      "          \\ -1.1923672e+07 -5.2335456e+07 -1.2247137e+09\\n -9.7296640e+06  1.7748844e+07\\\n",
      "          \\ -4.2712589e+08 -1.4185702e+08\\n  8.0514304e+07 -1.0632878e+09  2.5037312e+07\\\n",
      "          \\  1.3626081e+09\\n  8.2833920e+06  8.0514304e+07 -8.6178515e+08  1.1845112e+07\\n\\\n",
      "          \\ -1.0395320e+09 -5.2335456e+07 -9.2636160e+06 -1.0759360e+06\\n -1.4185702e+08\\\n",
      "          \\ -3.5985367e+09 -1.0571917e+08 -5.6395290e+08\\n  3.7927296e+08 -5.9273933e+08\\\n",
      "          \\ -2.6971776e+07  4.1687450e+08]\"\n",
      "    num_agent_steps_sampled: 235000\n",
      "    num_agent_steps_trained: 1872032\n",
      "    num_steps_sampled: 235000\n",
      "    num_steps_trained: 1872032\n",
      "    num_target_updates: 465\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.142105263157895\n",
      "    ram_util_percent: 92.66842105263157\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03985671557773717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.142697702940502\n",
      "    mean_inference_ms: 1.5614692213840196\n",
      "    mean_raw_obs_processing_ms: 2.32003688397142\n",
      "  time_since_restore: 3671.7874884605408\n",
      "  time_this_iter_s: 13.355141401290894\n",
      "  time_total_s: 3671.7874884605408\n",
      "  timers:\n",
      "    learn_throughput: 3717.623\n",
      "    learn_time_ms: 8.608\n",
      "    load_throughput: 62721.495\n",
      "    load_time_ms: 0.51\n",
      "    update_time_ms: 1.676\n",
      "  timestamp: 1632005102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 235000\n",
      "  training_iteration: 235\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   235</td><td style=\"text-align: right;\">         3671.79</td><td style=\"text-align: right;\">235000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 236000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-45-16\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 242\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 235864\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 63905857536.0\n",
      "          mean_q: 6224834048.0\n",
      "          min_q: 49910216.0\n",
      "        mean_td_error: -414267136.0\n",
      "        td_error: \"[-1.8382234e+08  5.4828608e+08  2.6462618e+09  1.2556083e+08\\n  2.2953600e+08\\\n",
      "          \\  3.1900598e+09 -1.5510681e+10  5.6295035e+09\\n  4.9227600e+06 -1.7040280e+06\\\n",
      "          \\  5.6122016e+07 -7.6363600e+06\\n  5.4828608e+08 -7.8487560e+06  5.4083400e+06\\\n",
      "          \\  4.1562624e+07\\n -1.8382234e+08 -7.2929728e+07 -2.2660112e+07  9.0291917e+08\\n\\\n",
      "          \\  3.1522931e+08  3.9482240e+06  4.5360435e+08  3.1660186e+08\\n  4.5159936e+08\\\n",
      "          \\  1.4857695e+09  4.1562624e+07 -1.2320600e+06\\n  1.1021312e+09 -1.5510681e+10\\\n",
      "          \\ -2.8641946e+08  4.3401242e+08]\"\n",
      "    num_agent_steps_sampled: 236000\n",
      "    num_agent_steps_trained: 1880032\n",
      "    num_steps_sampled: 236000\n",
      "    num_steps_trained: 1880032\n",
      "    num_target_updates: 467\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.06315789473685\n",
      "    ram_util_percent: 92.86842105263158\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03985860678496669\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.139282749430386\n",
      "    mean_inference_ms: 1.5614889597405355\n",
      "    mean_raw_obs_processing_ms: 2.3130082796652927\n",
      "  time_since_restore: 3685.5105469226837\n",
      "  time_this_iter_s: 13.723058462142944\n",
      "  time_total_s: 3685.5105469226837\n",
      "  timers:\n",
      "    learn_throughput: 3439.663\n",
      "    learn_time_ms: 9.303\n",
      "    load_throughput: 37790.778\n",
      "    load_time_ms: 0.847\n",
      "    update_time_ms: 1.777\n",
      "  timestamp: 1632005116\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 236000\n",
      "  training_iteration: 236\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">         3685.51</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 237000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-45-30\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 243\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 236872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 74817757184.0\n",
      "          mean_q: 14889256960.0\n",
      "          min_q: 47862776.0\n",
      "        mean_td_error: 413898240.0\n",
      "        td_error: \"[-1.7503980e+09 -1.5883981e+08  2.7783168e+07 -1.2980634e+08\\n -1.1360088e+07\\\n",
      "          \\ -1.1203789e+09 -1.1342400e+05 -5.1640115e+08\\n  5.6047360e+08  3.6243712e+09\\\n",
      "          \\  1.2103189e+08 -1.9291034e+08\\n  2.4348262e+09  5.0014240e+06  4.8296080e+06\\\n",
      "          \\ -1.9291034e+08\\n -4.4430848e+08  1.3985160e+06  4.7369728e+07  3.1928115e+09\\n\\\n",
      "          \\  6.7211760e+06 -1.1541115e+09  7.4309440e+06  1.9814482e+09\\n -1.0338796e+07\\\n",
      "          \\ -3.6873626e+08 -1.9291034e+08  3.1928115e+09\\n  4.7238881e+09 -5.1907280e+06\\\n",
      "          \\ -4.4430848e+08  5.5692280e+06]\"\n",
      "    num_agent_steps_sampled: 237000\n",
      "    num_agent_steps_trained: 1888032\n",
      "    num_steps_sampled: 237000\n",
      "    num_steps_trained: 1888032\n",
      "    num_target_updates: 469\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.25500000000001\n",
      "    ram_util_percent: 92.86500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039860522156564764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.135893754149004\n",
      "    mean_inference_ms: 1.5615093668464408\n",
      "    mean_raw_obs_processing_ms: 2.306087481881601\n",
      "  time_since_restore: 3699.0068821907043\n",
      "  time_this_iter_s: 13.49633526802063\n",
      "  time_total_s: 3699.0068821907043\n",
      "  timers:\n",
      "    learn_throughput: 3718.458\n",
      "    learn_time_ms: 8.606\n",
      "    load_throughput: 62621.998\n",
      "    load_time_ms: 0.511\n",
      "    update_time_ms: 1.72\n",
      "  timestamp: 1632005130\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 237000\n",
      "  training_iteration: 237\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   237</td><td style=\"text-align: right;\">         3699.01</td><td style=\"text-align: right;\">237000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 238000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-45-43\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 244\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 237880\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 36570570752.0\n",
      "          mean_q: 6109776896.0\n",
      "          min_q: 43097984.0\n",
      "        mean_td_error: -2201340928.0\n",
      "        td_error: \"[-2.1791340e+07  1.7222043e+08  2.8285056e+07  1.0506148e+09\\n -3.8959002e+08\\\n",
      "          \\  1.6037568e+08  1.2127700e+07  4.7595930e+08\\n -5.5882240e+07 -9.9287245e+08\\\n",
      "          \\ -5.6483968e+07  8.4454800e+05\\n  2.0280852e+09  8.8675280e+06  2.7562496e+08\\\n",
      "          \\  2.0280852e+09\\n -7.2379392e+07 -5.2539008e+08 -6.0342720e+06 -2.1825262e+10\\n\\\n",
      "          \\ -3.7215437e+08 -1.5180240e+06 -2.6206495e+09 -2.0075173e+09\\n -1.0700626e+09\\\n",
      "          \\ -2.1825262e+10 -2.4959142e+08 -7.6924864e+07\\n -5.5882240e+07 -1.5634258e+09\\\n",
      "          \\ -1.0700626e+09 -2.1825262e+10]\"\n",
      "    num_agent_steps_sampled: 238000\n",
      "    num_agent_steps_trained: 1896032\n",
      "    num_steps_sampled: 238000\n",
      "    num_steps_trained: 1896032\n",
      "    num_target_updates: 471\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.16315789473684\n",
      "    ram_util_percent: 92.82105263157894\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039862452155163854\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.132525460194552\n",
      "    mean_inference_ms: 1.561529294112732\n",
      "    mean_raw_obs_processing_ms: 2.299270935973521\n",
      "  time_since_restore: 3712.4815559387207\n",
      "  time_this_iter_s: 13.474673748016357\n",
      "  time_total_s: 3712.4815559387207\n",
      "  timers:\n",
      "    learn_throughput: 3699.262\n",
      "    learn_time_ms: 8.65\n",
      "    load_throughput: 64047.398\n",
      "    load_time_ms: 0.5\n",
      "    update_time_ms: 1.731\n",
      "  timestamp: 1632005143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 238000\n",
      "  training_iteration: 238\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   238</td><td style=\"text-align: right;\">         3712.48</td><td style=\"text-align: right;\">238000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 239000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-45-57\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.88\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 245\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 238888\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 116446420992.0\n",
      "          mean_q: 21949935616.0\n",
      "          min_q: 56284436.0\n",
      "        mean_td_error: -2468628992.0\n",
      "        td_error: \"[ 8.97859584e+08  4.28757146e+09  1.29937971e+09 -3.06934579e+09\\n\\\n",
      "          \\  2.75741920e+07 -2.44889969e+10  4.73945600e+06  1.21478416e+08\\n  9.71578400e+06\\\n",
      "          \\ -1.74499430e+09  2.18804634e+09 -2.36514304e+08\\n -1.83303578e+09 -8.87649200e+06\\\n",
      "          \\ -1.63919232e+08  7.84302080e+07\\n  2.58408192e+08 -4.90192896e+09 -3.40995328e+08\\\n",
      "          \\ -4.18668544e+08\\n -5.36702976e+09  4.28757146e+09 -2.44889969e+10 -2.44889969e+10\\n\\\n",
      "          \\  1.00571546e+09 -4.39704781e+09 -1.15344800e+06  2.08472208e+08\\n  6.46798400e+06\\\n",
      "          \\  6.46798400e+06  7.84302080e+07  2.18804634e+09]\"\n",
      "    num_agent_steps_sampled: 239000\n",
      "    num_agent_steps_trained: 1904032\n",
      "    num_steps_sampled: 239000\n",
      "    num_steps_trained: 1904032\n",
      "    num_target_updates: 473\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.242105263157896\n",
      "    ram_util_percent: 92.83157894736841\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03986440188362251\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.12916459488825\n",
      "    mean_inference_ms: 1.5615495364140404\n",
      "    mean_raw_obs_processing_ms: 2.292558409287185\n",
      "  time_since_restore: 3725.8450701236725\n",
      "  time_this_iter_s: 13.363514184951782\n",
      "  time_total_s: 3725.8450701236725\n",
      "  timers:\n",
      "    learn_throughput: 3718.89\n",
      "    learn_time_ms: 8.605\n",
      "    load_throughput: 62959.812\n",
      "    load_time_ms: 0.508\n",
      "    update_time_ms: 1.733\n",
      "  timestamp: 1632005157\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239000\n",
      "  training_iteration: 239\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   239</td><td style=\"text-align: right;\">         3725.85</td><td style=\"text-align: right;\">239000</td><td style=\"text-align: right;\">   -0.88</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 240000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-46-10\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 246\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 239896\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 115813081088.0\n",
      "          mean_q: 28275890176.0\n",
      "          min_q: 32622396.0\n",
      "        mean_td_error: -612964928.0\n",
      "        td_error: \"[-2.8246412e+07 -7.4798040e+06 -2.9142364e+09 -7.0026609e+09\\n -2.9142364e+09\\\n",
      "          \\ -1.1468464e+10  1.9812352e+07 -6.1146522e+09\\n  8.7904160e+06  8.4908000e+05\\\n",
      "          \\  1.5266458e+08 -2.6611430e+08\\n  2.2589855e+09  5.6357437e+09 -7.9839840e+06\\\n",
      "          \\  6.3080612e+09\\n  4.0945408e+07  2.7932947e+08  4.6009549e+09 -2.0833004e+07\\n\\\n",
      "          \\  1.1810325e+08 -3.8483722e+09  1.3478728e+09  1.7367040e+07\\n  3.6327168e+07\\\n",
      "          \\  1.7423949e+08  2.9915264e+08  1.7367040e+07\\n -3.2275853e+08  1.0579149e+08\\\n",
      "          \\ -6.5459240e+06 -6.1146522e+09]\"\n",
      "    num_agent_steps_sampled: 240000\n",
      "    num_agent_steps_trained: 1912032\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 1912032\n",
      "    num_target_updates: 475\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.2\n",
      "    ram_util_percent: 92.84210526315788\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03986618499708793\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.125786482570577\n",
      "    mean_inference_ms: 1.5615661838961001\n",
      "    mean_raw_obs_processing_ms: 2.2859475478800566\n",
      "  time_since_restore: 3739.203952074051\n",
      "  time_this_iter_s: 13.358881950378418\n",
      "  time_total_s: 3739.203952074051\n",
      "  timers:\n",
      "    learn_throughput: 3709.65\n",
      "    learn_time_ms: 8.626\n",
      "    load_throughput: 63649.513\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.722\n",
      "  timestamp: 1632005170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 240\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   240</td><td style=\"text-align: right;\">          3739.2</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 241000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-46-24\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 247\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 240904\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 144873799680.0\n",
      "          mean_q: 47740866560.0\n",
      "          min_q: 47909612.0\n",
      "        mean_td_error: -934323072.0\n",
      "        td_error: \"[ 3.9852851e+09  2.7653219e+08  1.4727588e+09 -5.1059548e+09\\n -2.0807600e+05\\\n",
      "          \\ -6.3717908e+09 -4.5804216e+09 -1.9423150e+09\\n  1.8111365e+09  1.7763184e+07\\\n",
      "          \\ -1.3290127e+09 -1.9026960e+07\\n -9.2221276e+09 -1.8618860e+09 -6.3717908e+09\\\n",
      "          \\  1.2623380e+09\\n -1.9423150e+09 -1.3211904e+07 -1.3168812e+09  3.9852851e+09\\n\\\n",
      "          \\ -3.4338000e+07  6.5170227e+08 -3.7846467e+09  1.8111365e+09\\n -4.6169869e+08\\\n",
      "          \\  7.4546000e+06  1.7170432e+07 -8.5291827e+08\\n  1.8404040e+06  3.4288120e+06\\\n",
      "          \\  2.9938640e+06  5.3787440e+06]\"\n",
      "    num_agent_steps_sampled: 241000\n",
      "    num_agent_steps_trained: 1920032\n",
      "    num_steps_sampled: 241000\n",
      "    num_steps_trained: 1920032\n",
      "    num_target_updates: 477\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.875\n",
      "    ram_util_percent: 92.83999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03986793362931438\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.122424942992096\n",
      "    mean_inference_ms: 1.5615819339183081\n",
      "    mean_raw_obs_processing_ms: 2.2794365737612505\n",
      "  time_since_restore: 3753.1100425720215\n",
      "  time_this_iter_s: 13.906090497970581\n",
      "  time_total_s: 3753.1100425720215\n",
      "  timers:\n",
      "    learn_throughput: 3561.267\n",
      "    learn_time_ms: 8.986\n",
      "    load_throughput: 61144.243\n",
      "    load_time_ms: 0.523\n",
      "    update_time_ms: 1.791\n",
      "  timestamp: 1632005184\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 241000\n",
      "  training_iteration: 241\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   241</td><td style=\"text-align: right;\">         3753.11</td><td style=\"text-align: right;\">241000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 242000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-46-39\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 248\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 241912\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 164071636992.0\n",
      "          mean_q: 27133157376.0\n",
      "          min_q: 52442656.0\n",
      "        mean_td_error: 1876754304.0\n",
      "        td_error: \"[ 5.1535544e+09  4.9476567e+09  1.5299920e+06  3.6826724e+09\\n  7.7749898e+09\\\n",
      "          \\  5.1535544e+09 -1.7123190e+09  4.5752200e+07\\n  1.7980192e+07  5.1535544e+09\\\n",
      "          \\ -1.6781382e+08 -1.8533908e+09\\n  2.1859354e+08  1.2340077e+08 -3.4501760e+07\\\n",
      "          \\ -2.2634660e+09\\n -6.8613312e+07  6.4052429e+08  1.4339461e+09  7.7749898e+09\\n\\\n",
      "          \\ -1.4563686e+08  6.1671956e+09  5.3559245e+09  4.5361120e+06\\n  5.3425848e+09\\\n",
      "          \\  5.9961235e+08  1.5299920e+06  3.0070368e+07\\n  7.7928980e+09 -8.4944486e+08\\\n",
      "          \\ -2.8016640e+08  1.4435100e+07]\"\n",
      "    num_agent_steps_sampled: 242000\n",
      "    num_agent_steps_trained: 1928032\n",
      "    num_steps_sampled: 242000\n",
      "    num_steps_trained: 1928032\n",
      "    num_target_updates: 479\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.12857142857143\n",
      "    ram_util_percent: 93.30952380952382\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039869814799493274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.11910800944959\n",
      "    mean_inference_ms: 1.5616007026241314\n",
      "    mean_raw_obs_processing_ms: 2.27302408213925\n",
      "  time_since_restore: 3767.7486519813538\n",
      "  time_this_iter_s: 14.638609409332275\n",
      "  time_total_s: 3767.7486519813538\n",
      "  timers:\n",
      "    learn_throughput: 3587.136\n",
      "    learn_time_ms: 8.921\n",
      "    load_throughput: 57182.059\n",
      "    load_time_ms: 0.56\n",
      "    update_time_ms: 1.826\n",
      "  timestamp: 1632005199\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 242000\n",
      "  training_iteration: 242\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">         3767.75</td><td style=\"text-align: right;\">242000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 243000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-46-53\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 249\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 242920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 128320307200.0\n",
      "          mean_q: 27364421632.0\n",
      "          min_q: 54928636.0\n",
      "        mean_td_error: -2957865662.125\n",
      "        td_error: \"[-4.98838221e+09 -2.26865376e+08 -2.36824576e+08 -1.64119429e+10\\n\\\n",
      "          \\ -1.95338920e+07 -4.68529971e+09 -4.15314739e+09  4.13054034e+09\\n -8.65067008e+09\\\n",
      "          \\ -8.20822426e+09 -4.68529971e+09  2.52746652e+08\\n -5.73681664e+09 -1.95338920e+07\\\n",
      "          \\ -1.62516992e+08 -1.64119429e+10\\n -3.09777203e+09 -6.02040730e+09 -4.32603008e+08\\\n",
      "          \\ -1.64119429e+10\\n  1.08047168e+08  9.75782560e+07  1.99452000e+06 -4.33063066e+09\\n\\\n",
      "          \\ -5.66063808e+08 -6.02040730e+09 -2.13819280e+07  6.14572000e+06\\n -8.65067008e+09\\\n",
      "          \\ -6.02040730e+09  2.68124858e+10  1.08047168e+08]\"\n",
      "    num_agent_steps_sampled: 243000\n",
      "    num_agent_steps_trained: 1936032\n",
      "    num_steps_sampled: 243000\n",
      "    num_steps_trained: 1936032\n",
      "    num_target_updates: 481\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.36\n",
      "    ram_util_percent: 93.34\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03987172823054345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.11582607054735\n",
      "    mean_inference_ms: 1.5616202101135932\n",
      "    mean_raw_obs_processing_ms: 2.2667072199575635\n",
      "  time_since_restore: 3781.692689180374\n",
      "  time_this_iter_s: 13.944037199020386\n",
      "  time_total_s: 3781.692689180374\n",
      "  timers:\n",
      "    learn_throughput: 3713.386\n",
      "    learn_time_ms: 8.617\n",
      "    load_throughput: 64041.286\n",
      "    load_time_ms: 0.5\n",
      "    update_time_ms: 1.741\n",
      "  timestamp: 1632005213\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 243000\n",
      "  training_iteration: 243\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   243</td><td style=\"text-align: right;\">         3781.69</td><td style=\"text-align: right;\">243000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 244000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-47-06\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 250\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 243928\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 157825597440.0\n",
      "          mean_q: 60398919680.0\n",
      "          min_q: 36098496.0\n",
      "        mean_td_error: 6959602176.0\n",
      "        td_error: \"[ 5.1150640e+06  1.3904404e+10  5.2795638e+09  2.6467985e+10\\n  2.6467985e+10\\\n",
      "          \\  5.7930957e+09  1.9714703e+09  1.4883533e+09\\n  1.4852358e+10 -4.6231060e+09\\\n",
      "          \\  1.4852358e+10  2.6409370e+09\\n -6.6799380e+09 -5.2247088e+07  6.6374369e+09\\\n",
      "          \\ -6.6799380e+09\\n  8.6014525e+09  2.6467985e+10  4.3150760e+06  2.5064336e+07\\n\\\n",
      "          \\  8.6263400e+06  1.2995461e+09  2.6467985e+10  7.8611120e+06\\n  2.4058675e+09\\\n",
      "          \\  8.6014525e+09  8.1866158e+09  5.2795638e+09\\n  1.3904404e+10  8.6797988e+09\\\n",
      "          \\ -1.8461072e+07  1.0459361e+10]\"\n",
      "    num_agent_steps_sampled: 244000\n",
      "    num_agent_steps_trained: 1944032\n",
      "    num_steps_sampled: 244000\n",
      "    num_steps_trained: 1944032\n",
      "    num_target_updates: 483\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.53157894736843\n",
      "    ram_util_percent: 93.18947368421053\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03987367755787592\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.112590344121946\n",
      "    mean_inference_ms: 1.5616401693612212\n",
      "    mean_raw_obs_processing_ms: 2.260484700909125\n",
      "  time_since_restore: 3795.4169795513153\n",
      "  time_this_iter_s: 13.724290370941162\n",
      "  time_total_s: 3795.4169795513153\n",
      "  timers:\n",
      "    learn_throughput: 3723.884\n",
      "    learn_time_ms: 8.593\n",
      "    load_throughput: 61376.316\n",
      "    load_time_ms: 0.521\n",
      "    update_time_ms: 1.734\n",
      "  timestamp: 1632005226\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 244000\n",
      "  training_iteration: 244\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   244</td><td style=\"text-align: right;\">         3795.42</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 245000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-47-21\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 251\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 244936\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 246220177408.0\n",
      "          mean_q: 52612751360.0\n",
      "          min_q: 70029232.0\n",
      "        mean_td_error: -2642975744.0\n",
      "        td_error: \"[-4.6120960e+07 -3.5271475e+09 -4.6120960e+07 -1.4555791e+09\\n -9.5575327e+09\\\n",
      "          \\ -2.3407456e+10  1.8660319e+10  1.8660319e+10\\n -2.3407456e+10 -5.5061463e+09\\\n",
      "          \\ -4.4042650e+09  3.1403323e+09\\n  5.2048200e+06 -3.0782259e+09 -8.8114463e+09\\\n",
      "          \\ -4.9685627e+09\\n -5.5061463e+09 -7.2482529e+09  5.5138473e+09 -6.2472909e+09\\n\\\n",
      "          \\  1.8660319e+10 -9.5575327e+09 -4.4042650e+09 -5.5061463e+09\\n -1.4840824e+07\\\n",
      "          \\ -5.5355474e+09 -4.4842025e+09 -6.2472909e+09\\n -4.3953357e+08 -2.6297303e+09\\\n",
      "          \\ -3.6022682e+09  4.2354854e+08]\"\n",
      "    num_agent_steps_sampled: 245000\n",
      "    num_agent_steps_trained: 1952032\n",
      "    num_steps_sampled: 245000\n",
      "    num_steps_trained: 1952032\n",
      "    num_target_updates: 485\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.228571428571435\n",
      "    ram_util_percent: 93.36666666666666\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03987569624086812\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.109407246054372\n",
      "    mean_inference_ms: 1.5616626693344327\n",
      "    mean_raw_obs_processing_ms: 2.2543546053121784\n",
      "  time_since_restore: 3809.8016164302826\n",
      "  time_this_iter_s: 14.384636878967285\n",
      "  time_total_s: 3809.8016164302826\n",
      "  timers:\n",
      "    learn_throughput: 3539.152\n",
      "    learn_time_ms: 9.042\n",
      "    load_throughput: 56036.126\n",
      "    load_time_ms: 0.571\n",
      "    update_time_ms: 1.793\n",
      "  timestamp: 1632005241\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 245000\n",
      "  training_iteration: 245\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   245</td><td style=\"text-align: right;\">          3809.8</td><td style=\"text-align: right;\">245000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 246000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-47-35\n",
      "  done: false\n",
      "  episode_len_mean: 990.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 252\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 245944\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 195554017280.0\n",
      "          mean_q: 72729804800.0\n",
      "          min_q: 71349152.0\n",
      "        mean_td_error: -1778429184.0\n",
      "        td_error: \"[-1.8051105e+10  2.0050911e+10  6.8809114e+08  4.3519539e+08\\n -3.3922048e+09\\\n",
      "          \\  6.3414764e+09 -1.0329825e+10 -9.4452672e+07\\n -3.3922048e+09  5.5929120e+06\\\n",
      "          \\ -7.9961293e+08 -8.3394642e+09\\n -1.3305984e+07  4.1003418e+09  4.3519539e+08\\\n",
      "          \\  4.5944750e+09\\n  2.4315822e+09 -1.8051105e+10 -2.1596201e+09 -4.0830857e+10\\n\\\n",
      "          \\ -6.4139284e+09  5.6717312e+09  4.3519539e+08  3.4603172e+09\\n  3.4603172e+09\\\n",
      "          \\ -2.0197540e+09 -1.4296064e+09 -1.0373857e+09\\n  5.0518359e+09  2.9147680e+06\\\n",
      "          \\  5.6717312e+09 -3.3922048e+09]\"\n",
      "    num_agent_steps_sampled: 246000\n",
      "    num_agent_steps_trained: 1960032\n",
      "    num_steps_sampled: 246000\n",
      "    num_steps_trained: 1960032\n",
      "    num_target_updates: 487\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.37500000000001\n",
      "    ram_util_percent: 93.28\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03987777642677176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.106255612556916\n",
      "    mean_inference_ms: 1.5616865594100273\n",
      "    mean_raw_obs_processing_ms: 2.2483157706826833\n",
      "  time_since_restore: 3824.1263420581818\n",
      "  time_this_iter_s: 14.32472562789917\n",
      "  time_total_s: 3824.1263420581818\n",
      "  timers:\n",
      "    learn_throughput: 3648.887\n",
      "    learn_time_ms: 8.77\n",
      "    load_throughput: 60360.554\n",
      "    load_time_ms: 0.53\n",
      "    update_time_ms: 1.746\n",
      "  timestamp: 1632005255\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 246000\n",
      "  training_iteration: 246\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">         3824.13</td><td style=\"text-align: right;\">246000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 247000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-48-06\n",
      "  done: false\n",
      "  episode_len_mean: 989.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 253\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 246952\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 156954869760.0\n",
      "          mean_q: 66512691200.0\n",
      "          min_q: 55504328.0\n",
      "        mean_td_error: -9807820800.0\n",
      "        td_error: \"[-9.5961498e+09 -8.7417815e+09 -3.1174414e+10 -2.6957742e+09\\n -2.7264205e+09\\\n",
      "          \\ -3.1174414e+10  9.2523971e+09 -3.1174414e+10\\n -2.7264205e+09 -3.1174414e+10\\\n",
      "          \\ -2.6957742e+09 -3.3373809e+09\\n -4.6140375e+09 -5.4724239e+09 -3.1174414e+10\\\n",
      "          \\  2.7144110e+09\\n -3.1174414e+10  3.5164488e+09 -1.0766054e+09 -1.1743068e+09\\n\\\n",
      "          \\ -4.8965253e+09 -2.0355891e+09 -1.2479480e+10 -3.7987451e+09\\n -1.5725961e+10\\\n",
      "          \\ -9.1035730e+09 -1.5725961e+10 -2.0355891e+09\\n -3.1174414e+10  2.7144110e+09\\\n",
      "          \\  1.9248800e+05 -3.1687229e+09]\"\n",
      "    num_agent_steps_sampled: 247000\n",
      "    num_agent_steps_trained: 1968032\n",
      "    num_steps_sampled: 247000\n",
      "    num_steps_trained: 1968032\n",
      "    num_target_updates: 489\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.24444444444445\n",
      "    ram_util_percent: 92.84888888888887\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039879879527980215\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.103103774369975\n",
      "    mean_inference_ms: 1.5617111650103257\n",
      "    mean_raw_obs_processing_ms: 2.2430653554671\n",
      "  time_since_restore: 3855.193989753723\n",
      "  time_this_iter_s: 31.067647695541382\n",
      "  time_total_s: 3855.193989753723\n",
      "  timers:\n",
      "    learn_throughput: 3693.724\n",
      "    learn_time_ms: 8.663\n",
      "    load_throughput: 63417.94\n",
      "    load_time_ms: 0.505\n",
      "    update_time_ms: 1.709\n",
      "  timestamp: 1632005286\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 247000\n",
      "  training_iteration: 247\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   247</td><td style=\"text-align: right;\">         3855.19</td><td style=\"text-align: right;\">247000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 248000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-48-19\n",
      "  done: false\n",
      "  episode_len_mean: 989.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 254\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 247960\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 186536443904.0\n",
      "          mean_q: 91715616768.0\n",
      "          min_q: 81804416.0\n",
      "        mean_td_error: -2487122432.0\n",
      "        td_error: \"[ 4.6908539e+09 -4.3333386e+09 -4.7210080e+06  9.2514017e+09\\n  4.6908539e+09\\\n",
      "          \\ -9.0171924e+09  6.9566300e+09  3.6788347e+09\\n  1.2078408e+10  4.5413335e+09\\\n",
      "          \\  1.2078408e+10  1.7285202e+09\\n -6.3252152e+09  6.4358810e+08  4.6908539e+09\\\n",
      "          \\ -9.0171924e+09\\n -3.3000538e+10 -8.7550525e+09  1.1768365e+10 -9.6036536e+09\\n\\\n",
      "          \\ -1.5202083e+10 -6.3252152e+09 -1.5202083e+10  1.3501353e+10\\n -3.3000538e+10\\\n",
      "          \\ -4.1732800e+05 -9.6036536e+09 -6.9092803e+09\\n -6.4726630e+08 -1.5202083e+10\\\n",
      "          \\  1.3501353e+10 -1.2391547e+09]\"\n",
      "    num_agent_steps_sampled: 248000\n",
      "    num_agent_steps_trained: 1976032\n",
      "    num_steps_sampled: 248000\n",
      "    num_steps_trained: 1976032\n",
      "    num_target_updates: 491\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.03157894736841\n",
      "    ram_util_percent: 92.33157894736841\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03988198607204763\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.099937214191419\n",
      "    mean_inference_ms: 1.5617364679724781\n",
      "    mean_raw_obs_processing_ms: 2.2378992216089113\n",
      "  time_since_restore: 3868.450974225998\n",
      "  time_this_iter_s: 13.25698447227478\n",
      "  time_total_s: 3868.450974225998\n",
      "  timers:\n",
      "    learn_throughput: 3682.727\n",
      "    learn_time_ms: 8.689\n",
      "    load_throughput: 62619.076\n",
      "    load_time_ms: 0.511\n",
      "    update_time_ms: 1.715\n",
      "  timestamp: 1632005299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 248000\n",
      "  training_iteration: 248\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">         3868.45</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 249000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-48-32\n",
      "  done: false\n",
      "  episode_len_mean: 989.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 255\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 248968\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 210118852608.0\n",
      "          mean_q: 94164058112.0\n",
      "          min_q: 201425952.0\n",
      "        mean_td_error: 4527597568.0\n",
      "        td_error: \"[ 1.9169935e+09  3.9733156e+09 -9.2481188e+09  1.0022912e+09\\n  1.9169935e+09\\\n",
      "          \\  7.6987156e+09  1.6707109e+10  1.0022912e+09\\n  1.0112778e+10  8.4063355e+09\\\n",
      "          \\ -4.7299215e+09  1.8783388e+10\\n  1.0112778e+10  3.4290074e+09  4.2771415e+09\\\n",
      "          \\  1.0112778e+10\\n -6.9354578e+09  1.0112778e+10  1.0022912e+09  2.4313201e+09\\n\\\n",
      "          \\ -2.9167780e+09  5.8652754e+09 -7.5565015e+09  1.3256008e+09\\n  1.0022912e+09\\\n",
      "          \\  1.0708926e+10  1.6707109e+10  5.8652754e+09\\n -7.3863987e+08  7.3671311e+09\\\n",
      "          \\  4.4596982e+09  1.0708926e+10]\"\n",
      "    num_agent_steps_sampled: 249000\n",
      "    num_agent_steps_trained: 1984032\n",
      "    num_steps_sampled: 249000\n",
      "    num_steps_trained: 1984032\n",
      "    num_target_updates: 493\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.25555555555556\n",
      "    ram_util_percent: 92.2888888888889\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03988408303992924\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.09674335808548\n",
      "    mean_inference_ms: 1.561762052869223\n",
      "    mean_raw_obs_processing_ms: 2.232816587501955\n",
      "  time_since_restore: 3881.487942457199\n",
      "  time_this_iter_s: 13.036968231201172\n",
      "  time_total_s: 3881.487942457199\n",
      "  timers:\n",
      "    learn_throughput: 3666.159\n",
      "    learn_time_ms: 8.728\n",
      "    load_throughput: 63474.925\n",
      "    load_time_ms: 0.504\n",
      "    update_time_ms: 1.706\n",
      "  timestamp: 1632005312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249000\n",
      "  training_iteration: 249\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   249</td><td style=\"text-align: right;\">         3881.49</td><td style=\"text-align: right;\">249000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 250000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-48-46\n",
      "  done: false\n",
      "  episode_len_mean: 989.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 256\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 249976\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 226253684736.0\n",
      "          mean_q: 107748548608.0\n",
      "          min_q: 140234672.0\n",
      "        mean_td_error: 1010247680.0\n",
      "        td_error: \"[ 1.2379199e+10 -2.4969380e+09 -8.6196593e+09  2.3587630e+09\\n -3.2297037e+09\\\n",
      "          \\ -5.7508168e+09 -6.2464000e+09 -1.0841129e+09\\n  8.0274432e+07  2.0616561e+09\\\n",
      "          \\ -1.3862961e+10  1.0876764e+10\\n -9.7584742e+08  5.3906964e+09 -1.2644096e+07\\\n",
      "          \\ -8.9223660e+09\\n  3.5999089e+09  3.3291141e+09  5.2859863e+09 -9.7584742e+08\\n\\\n",
      "          \\ -1.3862961e+10  1.0265504e+10  6.4452045e+09  2.3587630e+09\\n -8.5657190e+08\\\n",
      "          \\ -5.7508168e+09  8.9480407e+09  4.8165519e+09\\n  1.4831886e+10 -1.0841129e+09\\\n",
      "          \\  2.1546066e+09  1.0876764e+10]\"\n",
      "    num_agent_steps_sampled: 250000\n",
      "    num_agent_steps_trained: 1992032\n",
      "    num_steps_sampled: 250000\n",
      "    num_steps_trained: 1992032\n",
      "    num_target_updates: 495\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.305263157894736\n",
      "    ram_util_percent: 92.26842105263158\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039886184710468335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.093555290579216\n",
      "    mean_inference_ms: 1.5617880094765284\n",
      "    mean_raw_obs_processing_ms: 2.2278159465034455\n",
      "  time_since_restore: 3894.612107038498\n",
      "  time_this_iter_s: 13.124164581298828\n",
      "  time_total_s: 3894.612107038498\n",
      "  timers:\n",
      "    learn_throughput: 3719.148\n",
      "    learn_time_ms: 8.604\n",
      "    load_throughput: 63764.42\n",
      "    load_time_ms: 0.502\n",
      "    update_time_ms: 1.722\n",
      "  timestamp: 1632005326\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 250000\n",
      "  training_iteration: 250\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         3894.61</td><td style=\"text-align: right;\">250000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 251000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-48-59\n",
      "  done: false\n",
      "  episode_len_mean: 989.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 257\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 250984\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 238880243712.0\n",
      "          mean_q: 92620963840.0\n",
      "          min_q: 93761392.0\n",
      "        mean_td_error: 1658405376.0\n",
      "        td_error: \"[-4.2423501e+08  4.6953513e+09 -3.3226793e+09  7.1476644e+09\\n  2.5052611e+09\\\n",
      "          \\ -5.8019680e+06  4.6953513e+09  9.4306304e+09\\n -4.2082222e+09  1.9392430e+09\\\n",
      "          \\  5.8630717e+09  8.9101681e+09\\n -1.8338886e+09 -5.7469665e+09 -1.8338886e+09\\\n",
      "          \\ -7.3102480e+06\\n  1.9659653e+09  2.0895580e+09 -5.7469665e+09 -5.8171392e+09\\n\\\n",
      "          \\  8.9101681e+09  2.1022310e+08  1.9392430e+09 -4.2423501e+08\\n  8.9101681e+09\\\n",
      "          \\  2.5946194e+09 -6.4196444e+09  2.0895580e+09\\n  6.9981133e+09  2.5946194e+09\\\n",
      "          \\  9.4306304e+09 -4.0596577e+09]\"\n",
      "    num_agent_steps_sampled: 251000\n",
      "    num_agent_steps_trained: 2000032\n",
      "    num_steps_sampled: 251000\n",
      "    num_steps_trained: 2000032\n",
      "    num_target_updates: 497\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.27894736842106\n",
      "    ram_util_percent: 92.06842105263158\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039888282475677876\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.090386926617452\n",
      "    mean_inference_ms: 1.5618142110478619\n",
      "    mean_raw_obs_processing_ms: 2.222894839554838\n",
      "  time_since_restore: 3907.7477493286133\n",
      "  time_this_iter_s: 13.135642290115356\n",
      "  time_total_s: 3907.7477493286133\n",
      "  timers:\n",
      "    learn_throughput: 3698.09\n",
      "    learn_time_ms: 8.653\n",
      "    load_throughput: 63140.485\n",
      "    load_time_ms: 0.507\n",
      "    update_time_ms: 1.733\n",
      "  timestamp: 1632005339\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 251000\n",
      "  training_iteration: 251\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   251</td><td style=\"text-align: right;\">         3907.75</td><td style=\"text-align: right;\">251000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 252000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-49-12\n",
      "  done: false\n",
      "  episode_len_mean: 989.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.89\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 258\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 251992\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 235906662400.0\n",
      "          mean_q: 98598395904.0\n",
      "          min_q: 134124624.0\n",
      "        mean_td_error: 257378688.0\n",
      "        td_error: \"[-7.1326925e+08  1.6886932e+10  1.6886932e+10  7.1850394e+08\\n  5.6909609e+09\\\n",
      "          \\  6.6561192e+07 -1.4189937e+09  2.0366787e+09\\n -5.4967337e+09 -1.4189937e+09\\\n",
      "          \\  6.9854986e+09  5.1176653e+09\\n  2.0366787e+09 -2.1714698e+09 -4.3136287e+09\\\n",
      "          \\  1.1670417e+10\\n  5.6909609e+09 -9.8810266e+08 -2.0465582e+09 -1.4189937e+09\\n\\\n",
      "          \\ -1.1458314e+10 -1.3825135e+10 -1.7463970e+10  5.6909609e+09\\n  2.0366787e+09\\\n",
      "          \\ -4.8858481e+09  2.3571169e+09 -1.1458314e+10\\n  6.7720356e+09  8.8388403e+08\\\n",
      "          \\ -2.7950285e+09 -1.4189937e+09]\"\n",
      "    num_agent_steps_sampled: 252000\n",
      "    num_agent_steps_trained: 2008032\n",
      "    num_steps_sampled: 252000\n",
      "    num_steps_trained: 2008032\n",
      "    num_target_updates: 499\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.57368421052632\n",
      "    ram_util_percent: 91.95263157894738\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039890380014921574\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.087229254281537\n",
      "    mean_inference_ms: 1.5618406595265424\n",
      "    mean_raw_obs_processing_ms: 2.218052858948841\n",
      "  time_since_restore: 3920.8948957920074\n",
      "  time_this_iter_s: 13.147146463394165\n",
      "  time_total_s: 3920.8948957920074\n",
      "  timers:\n",
      "    learn_throughput: 3692.21\n",
      "    learn_time_ms: 8.667\n",
      "    load_throughput: 64077.976\n",
      "    load_time_ms: 0.499\n",
      "    update_time_ms: 1.751\n",
      "  timestamp: 1632005352\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 252000\n",
      "  training_iteration: 252\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   252</td><td style=\"text-align: right;\">         3920.89</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\">   -0.89</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 253000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-49-24\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.9\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 259\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 253000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 247555162112.0\n",
      "          mean_q: 95509676032.0\n",
      "          min_q: 78137552.0\n",
      "        mean_td_error: -4017153536.0\n",
      "        td_error: \"[-2.1448153e+10 -2.1089198e+09 -6.4910623e+09 -9.1703050e+09\\n -7.5104748e+09\\\n",
      "          \\ -2.1690900e+09  1.2702731e+10 -4.2538844e+09\\n  2.1230387e+08 -9.1703050e+09\\\n",
      "          \\ -1.1347943e+10 -1.1347943e+10\\n -3.7683364e+09 -1.5256617e+09 -9.1703050e+09\\\n",
      "          \\ -4.8709632e+07\\n -4.3967088e+07  2.5005916e+09 -1.0567680e+08 -1.4915387e+10\\n\\\n",
      "          \\ -8.7078420e+09 -2.1448153e+10 -2.6562744e+09 -1.0105160e+09\\n  4.6096220e+09\\\n",
      "          \\ -4.6155612e+09 -2.0544225e+09 -2.6562744e+09\\n  1.2702731e+10 -2.0899348e+09\\\n",
      "          \\  1.1211735e+09 -2.5629655e+09]\"\n",
      "    num_agent_steps_sampled: 253000\n",
      "    num_agent_steps_trained: 2016032\n",
      "    num_steps_sampled: 253000\n",
      "    num_steps_trained: 2016032\n",
      "    num_target_updates: 501\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.33888888888889\n",
      "    ram_util_percent: 91.98888888888888\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03989246228897494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.084027739705252\n",
      "    mean_inference_ms: 1.5618667704915934\n",
      "    mean_raw_obs_processing_ms: 2.212225542931886\n",
      "  time_since_restore: 3933.417597055435\n",
      "  time_this_iter_s: 12.522701263427734\n",
      "  time_total_s: 3933.417597055435\n",
      "  timers:\n",
      "    learn_throughput: 3682.889\n",
      "    learn_time_ms: 8.689\n",
      "    load_throughput: 62383.327\n",
      "    load_time_ms: 0.513\n",
      "    update_time_ms: 1.726\n",
      "  timestamp: 1632005364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 253000\n",
      "  training_iteration: 253\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   253</td><td style=\"text-align: right;\">         3933.42</td><td style=\"text-align: right;\">253000</td><td style=\"text-align: right;\">    -0.9</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 254000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-49-37\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.9\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 260\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 253504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 178831147008.0\n",
      "          mean_q: 56909586432.0\n",
      "          min_q: 162607408.0\n",
      "        mean_td_error: -23191678976.0\n",
      "        td_error: \"[-2.2647921e+10  4.6782054e+08  3.4919793e+09  2.3576945e+09\\n -1.3290972e+11\\\n",
      "          \\  2.6195395e+09 -3.9662192e+07  3.9222395e+09\\n -1.3290972e+11  4.8016328e+09\\\n",
      "          \\  2.2158640e+07  1.6242281e+10\\n  3.9222395e+09 -1.3290972e+11  5.4367519e+09\\\n",
      "          \\ -4.5304013e+08\\n -1.3290972e+11  3.9222395e+09 -2.2647921e+10  3.3568696e+09\\n\\\n",
      "          \\  9.3963715e+09  6.6441216e+08  1.4559846e+09  9.3963715e+09\\n  7.2516403e+09\\\n",
      "          \\  1.0692411e+10 -9.2372992e+07 -1.4511063e+09\\n -1.3290972e+11  1.6242281e+10\\\n",
      "          \\ -3.0062920e+09 -1.3290972e+11]\"\n",
      "    num_agent_steps_sampled: 254000\n",
      "    num_agent_steps_trained: 2024032\n",
      "    num_steps_sampled: 254000\n",
      "    num_steps_trained: 2024032\n",
      "    num_target_updates: 502\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.400000000000006\n",
      "    ram_util_percent: 92.05\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039894492529939936\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.080724004548758\n",
      "    mean_inference_ms: 1.5618922684521335\n",
      "    mean_raw_obs_processing_ms: 2.206481231116831\n",
      "  time_since_restore: 3946.1826939582825\n",
      "  time_this_iter_s: 12.76509690284729\n",
      "  time_total_s: 3946.1826939582825\n",
      "  timers:\n",
      "    learn_throughput: 3677.48\n",
      "    learn_time_ms: 8.702\n",
      "    load_throughput: 62519.903\n",
      "    load_time_ms: 0.512\n",
      "    update_time_ms: 1.704\n",
      "  timestamp: 1632005377\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 254000\n",
      "  training_iteration: 254\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">         3946.18</td><td style=\"text-align: right;\">254000</td><td style=\"text-align: right;\">    -0.9</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 255000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-49-50\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.9\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 261\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 254512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 261219385344.0\n",
      "          mean_q: 65076084736.0\n",
      "          min_q: 158459984.0\n",
      "        mean_td_error: -33445056512.0\n",
      "        td_error: \"[-1.4673002e+11  7.4378854e+09 -1.2997837e+09 -3.7613158e+09\\n -4.8584960e+06\\\n",
      "          \\ -1.4673002e+11 -1.4673002e+11  2.7953234e+09\\n  3.3048904e+09 -1.2997837e+09\\\n",
      "          \\  3.4412462e+09 -1.8533652e+10\\n  4.4181258e+09 -1.9096117e+10 -1.9096117e+10\\\n",
      "          \\ -1.9314278e+09\\n  4.4181258e+09 -1.4673002e+11  7.7104288e+07  4.4181258e+09\\n\\\n",
      "          \\ -1.2997837e+09 -6.4784138e+09  2.8668887e+09 -1.4673002e+11\\n  5.9256832e+08\\\n",
      "          \\ -6.4784138e+09  4.8466656e+07 -1.4673002e+11\\n  6.5613120e+06  1.7301668e+09\\\n",
      "          \\ -1.4673002e+11  5.9256832e+08]\"\n",
      "    num_agent_steps_sampled: 255000\n",
      "    num_agent_steps_trained: 2032032\n",
      "    num_steps_sampled: 255000\n",
      "    num_steps_trained: 2032032\n",
      "    num_target_updates: 504\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.52222222222221\n",
      "    ram_util_percent: 92.02777777777779\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03989650346003796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.077414359177435\n",
      "    mean_inference_ms: 1.5619174853611084\n",
      "    mean_raw_obs_processing_ms: 2.2008189719110036\n",
      "  time_since_restore: 3959.041045665741\n",
      "  time_this_iter_s: 12.858351707458496\n",
      "  time_total_s: 3959.041045665741\n",
      "  timers:\n",
      "    learn_throughput: 3690.352\n",
      "    learn_time_ms: 8.671\n",
      "    load_throughput: 62377.528\n",
      "    load_time_ms: 0.513\n",
      "    update_time_ms: 1.714\n",
      "  timestamp: 1632005390\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 255000\n",
      "  training_iteration: 255\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   255</td><td style=\"text-align: right;\">         3959.04</td><td style=\"text-align: right;\">255000</td><td style=\"text-align: right;\">    -0.9</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 256000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-50-03\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.86\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 262\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 255520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 289180254208.0\n",
      "          mean_q: 100018323456.0\n",
      "          min_q: 178388992.0\n",
      "        mean_td_error: -26857500672.0\n",
      "        td_error: \"[-2.3490367e+10 -7.1966269e+09 -1.7000759e+11  2.7959296e+09\\n -2.2082234e+10\\\n",
      "          \\ -2.3993795e+09 -9.4396908e+09 -3.9433380e+09\\n -2.3993795e+09  2.7194163e+09\\\n",
      "          \\ -2.2082234e+10 -2.3123395e+09\\n -1.3040910e+10 -6.0804301e+09 -4.2819994e+09\\\n",
      "          \\ -2.1982126e+09\\n -1.7000759e+11 -2.0421018e+08 -1.3241385e+09 -1.7000759e+11\\n\\\n",
      "          \\ -2.7669120e+06 -2.0421018e+08 -2.2082234e+10 -2.3993795e+09\\n -7.1966269e+09\\\n",
      "          \\  8.8215388e+09  2.3733862e+08 -1.3040910e+10\\n -1.7000759e+11 -2.2082234e+10\\\n",
      "          \\  6.0202608e+07 -4.5601587e+09]\"\n",
      "    num_agent_steps_sampled: 256000\n",
      "    num_agent_steps_trained: 2040032\n",
      "    num_steps_sampled: 256000\n",
      "    num_steps_trained: 2040032\n",
      "    num_target_updates: 506\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.305263157894736\n",
      "    ram_util_percent: 92.0\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03989849439169868\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.07414597669474\n",
      "    mean_inference_ms: 1.5619419755951212\n",
      "    mean_raw_obs_processing_ms: 2.1952365410151717\n",
      "  time_since_restore: 3971.853539466858\n",
      "  time_this_iter_s: 12.812493801116943\n",
      "  time_total_s: 3971.853539466858\n",
      "  timers:\n",
      "    learn_throughput: 3695.229\n",
      "    learn_time_ms: 8.66\n",
      "    load_throughput: 63637.442\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.723\n",
      "  timestamp: 1632005403\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 256000\n",
      "  training_iteration: 256\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   256</td><td style=\"text-align: right;\">         3971.85</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">   -0.86</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 257000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-50-15\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.86\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 263\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 256528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 329256239104.0\n",
      "          mean_q: 145667325952.0\n",
      "          min_q: 305939648.0\n",
      "        mean_td_error: -29383036928.0\n",
      "        td_error: \"[ 1.8317640e+09 -9.3723361e+09 -6.2982554e+09  3.3980744e+09\\n -9.2788326e+09\\\n",
      "          \\ -4.7878963e+09 -2.0566491e+11 -2.6121318e+09\\n -9.3723361e+09  1.8317640e+09\\\n",
      "          \\ -5.2872561e+09 -6.2982554e+09\\n -2.0566491e+11 -4.7878963e+09  5.6215470e+09\\\n",
      "          \\ -7.0064210e+09\\n  8.0019456e+07 -7.0064210e+09 -8.6845030e+08 -3.8555238e+09\\n\\\n",
      "          \\ -8.6845030e+08 -2.0566491e+11 -1.4424965e+09 -4.2178580e+10\\n  2.8037284e+09\\\n",
      "          \\ -1.4424965e+09  2.4777497e+10 -1.0883219e+10\\n -9.2788326e+09 -1.9104604e+10\\\n",
      "          \\ -2.0566491e+11  4.0888115e+09]\"\n",
      "    num_agent_steps_sampled: 257000\n",
      "    num_agent_steps_trained: 2048032\n",
      "    num_steps_sampled: 257000\n",
      "    num_steps_trained: 2048032\n",
      "    num_target_updates: 508\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.34117647058824\n",
      "    ram_util_percent: 92.05294117647058\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039900438483240576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.070846306445063\n",
      "    mean_inference_ms: 1.5619647503084741\n",
      "    mean_raw_obs_processing_ms: 2.189733140380161\n",
      "  time_since_restore: 3984.139291524887\n",
      "  time_this_iter_s: 12.285752058029175\n",
      "  time_total_s: 3984.139291524887\n",
      "  timers:\n",
      "    learn_throughput: 3686.49\n",
      "    learn_time_ms: 8.68\n",
      "    load_throughput: 63571.131\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.71\n",
      "  timestamp: 1632005415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 257000\n",
      "  training_iteration: 257\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   257</td><td style=\"text-align: right;\">         3984.14</td><td style=\"text-align: right;\">257000</td><td style=\"text-align: right;\">   -0.86</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 258000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-50-27\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.86\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 264\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 257536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 290071511040.0\n",
      "          mean_q: 87753998336.0\n",
      "          min_q: 24990512.0\n",
      "        mean_td_error: -40579457024.0\n",
      "        td_error: \"[-2.0846787e+11  5.5091036e+09  4.0818512e+10  7.8140375e+09\\n -1.8952692e+10\\\n",
      "          \\ -2.0846787e+11 -4.4808274e+09 -1.9280192e+07\\n -1.1682693e+10  4.1614377e+09\\\n",
      "          \\  1.7325425e+09 -2.9471072e+08\\n -3.0582272e+07 -3.9757414e+09  6.0527452e+09\\\n",
      "          \\ -2.0846787e+11\\n -2.0846787e+11 -4.4835963e+09 -2.4332544e+07 -3.9757414e+09\\n\\\n",
      "          \\ -4.4835963e+09 -2.0948550e+10 -1.8952692e+10 -2.0846787e+11\\n  1.1927618e+10\\\n",
      "          \\ -2.0948550e+10  8.1137992e+09  9.7837957e+09\\n -9.4398259e+09 -7.0080000e+06\\\n",
      "          \\ -2.0846787e+11 -2.0948550e+10]\"\n",
      "    num_agent_steps_sampled: 258000\n",
      "    num_agent_steps_trained: 2056032\n",
      "    num_steps_sampled: 258000\n",
      "    num_steps_trained: 2056032\n",
      "    num_target_updates: 510\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.388888888888886\n",
      "    ram_util_percent: 92.07222222222221\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03990237952024815\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.067496175369392\n",
      "    mean_inference_ms: 1.561986494260031\n",
      "    mean_raw_obs_processing_ms: 2.18430676839158\n",
      "  time_since_restore: 3996.2786350250244\n",
      "  time_this_iter_s: 12.139343500137329\n",
      "  time_total_s: 3996.2786350250244\n",
      "  timers:\n",
      "    learn_throughput: 3635.721\n",
      "    learn_time_ms: 8.802\n",
      "    load_throughput: 64157.614\n",
      "    load_time_ms: 0.499\n",
      "    update_time_ms: 1.761\n",
      "  timestamp: 1632005427\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 258000\n",
      "  training_iteration: 258\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   258</td><td style=\"text-align: right;\">         3996.28</td><td style=\"text-align: right;\">258000</td><td style=\"text-align: right;\">   -0.86</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 259000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-50-39\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 265\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 258544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 257662648320.0\n",
      "          mean_q: 104596471808.0\n",
      "          min_q: 528049728.0\n",
      "        mean_td_error: -47211855872.0\n",
      "        td_error: \"[-3.9519568e+10 -2.5694631e+11 -3.9519568e+10 -4.0462418e+09\\n  4.8049013e+10\\\n",
      "          \\  2.0982006e+09 -2.5694631e+11 -1.4613056e+07\\n  1.1056718e+10  8.9227264e+07\\\n",
      "          \\  7.8972518e+08  1.5051129e+10\\n  2.6416415e+09  1.6463643e+10  1.1056718e+10\\\n",
      "          \\ -4.2938860e+09\\n -1.2000961e+10  1.1056718e+10 -1.4408253e+09 -2.5694631e+11\\n\\\n",
      "          \\  2.0982006e+09 -3.9088947e+09  1.8539254e+08  4.8049013e+10\\n -4.8155034e+08\\\n",
      "          \\  1.5051129e+10 -4.0462418e+09 -2.5694631e+11\\n -2.5694631e+11 -4.0462418e+09\\\n",
      "          \\ -3.9519568e+10 -2.5694631e+11]\"\n",
      "    num_agent_steps_sampled: 259000\n",
      "    num_agent_steps_trained: 2064032\n",
      "    num_steps_sampled: 259000\n",
      "    num_steps_trained: 2064032\n",
      "    num_target_updates: 512\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.6\n",
      "    ram_util_percent: 92.13749999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03990429234223266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.064071176447127\n",
      "    mean_inference_ms: 1.5620066608188161\n",
      "    mean_raw_obs_processing_ms: 2.1789560739182887\n",
      "  time_since_restore: 4007.571360349655\n",
      "  time_this_iter_s: 11.292725324630737\n",
      "  time_total_s: 4007.571360349655\n",
      "  timers:\n",
      "    learn_throughput: 3628.31\n",
      "    learn_time_ms: 8.82\n",
      "    load_throughput: 62476.25\n",
      "    load_time_ms: 0.512\n",
      "    update_time_ms: 1.804\n",
      "  timestamp: 1632005439\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259000\n",
      "  training_iteration: 259\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   259</td><td style=\"text-align: right;\">         4007.57</td><td style=\"text-align: right;\">259000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 260000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-50-50\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 266\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 259552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 446889164800.0\n",
      "          mean_q: 153885114368.0\n",
      "          min_q: 571566592.0\n",
      "        mean_td_error: -16009356288.0\n",
      "        td_error: \"[-7.0094193e+09 -1.2647989e+10  2.0203700e+10  1.5103836e+09\\n  2.0203700e+10\\\n",
      "          \\  6.6013512e+09  8.8077517e+09  8.8077517e+09\\n  6.6013512e+09 -3.5146465e+09\\\n",
      "          \\ -2.7719569e+11  7.8884192e+07\\n -4.0306606e+09  2.0203700e+10 -1.2686607e+10\\\n",
      "          \\  6.6013512e+09\\n  5.3171978e+09  7.3677865e+09 -3.5290366e+10 -7.0094193e+09\\n\\\n",
      "          \\ -2.6167960e+10  5.2939354e+10 -4.1340436e+09 -2.5186468e+09\\n -3.0396285e+10\\\n",
      "          \\ -3.2954941e+09 -4.1699901e+09  6.2433772e+09\\n -2.6167960e+10  5.2939354e+10\\\n",
      "          \\ -2.7719569e+11 -3.2954941e+09]\"\n",
      "    num_agent_steps_sampled: 260000\n",
      "    num_agent_steps_trained: 2072032\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 2072032\n",
      "    num_target_updates: 514\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.5875\n",
      "    ram_util_percent: 92.23125000000002\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03990620391736299\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.060656835647649\n",
      "    mean_inference_ms: 1.5620264958981769\n",
      "    mean_raw_obs_processing_ms: 2.173679885645543\n",
      "  time_since_restore: 4018.946609735489\n",
      "  time_this_iter_s: 11.37524938583374\n",
      "  time_total_s: 4018.946609735489\n",
      "  timers:\n",
      "    learn_throughput: 3764.25\n",
      "    learn_time_ms: 8.501\n",
      "    load_throughput: 64842.615\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.707\n",
      "  timestamp: 1632005450\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 260\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   260</td><td style=\"text-align: right;\">         4018.95</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 261000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-51-03\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 267\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 260560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 440121917440.0\n",
      "          mean_q: 137869000704.0\n",
      "          min_q: 487261280.0\n",
      "        mean_td_error: -61456547840.0\n",
      "        td_error: \"[ 3.6858593e+09  1.5413412e+10  1.1528888e+10 -1.7741775e+10\\n -5.0263491e+09\\\n",
      "          \\ -3.1379253e+11  5.7428096e+07  4.2630656e+07\\n  1.1614536e+09  1.1528888e+10\\\n",
      "          \\ -1.7741775e+10 -2.1930148e+09\\n -5.0263491e+09  1.6245069e+08 -1.7741775e+10\\\n",
      "          \\ -2.1925396e+09\\n -3.1379253e+11 -3.1379253e+11 -2.1930148e+09 -3.1379253e+11\\n\\\n",
      "          \\ -9.7601618e+09  6.9069677e+10 -1.7432347e+10 -3.1379253e+11\\n -3.1379253e+11\\\n",
      "          \\ -4.4041421e+10 -3.6116890e+09 -2.5583804e+10\\n -4.6470595e+09 -1.8824192e+10\\\n",
      "          \\ -2.7619901e+09  1.4179552e+07]\"\n",
      "    num_agent_steps_sampled: 261000\n",
      "    num_agent_steps_trained: 2080032\n",
      "    num_steps_sampled: 261000\n",
      "    num_steps_trained: 2080032\n",
      "    num_target_updates: 516\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.17777777777778\n",
      "    ram_util_percent: 92.24999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03990810973074411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.057225454075175\n",
      "    mean_inference_ms: 1.5620456658341002\n",
      "    mean_raw_obs_processing_ms: 2.16847754123441\n",
      "  time_since_restore: 4031.328790664673\n",
      "  time_this_iter_s: 12.38218092918396\n",
      "  time_total_s: 4031.328790664673\n",
      "  timers:\n",
      "    learn_throughput: 3688.983\n",
      "    learn_time_ms: 8.674\n",
      "    load_throughput: 64805.045\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.751\n",
      "  timestamp: 1632005463\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 261000\n",
      "  training_iteration: 261\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   261</td><td style=\"text-align: right;\">         4031.33</td><td style=\"text-align: right;\">261000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 262000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-51-15\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 268\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 261568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 604402876416.0\n",
      "          mean_q: 207903916032.0\n",
      "          min_q: 836548096.0\n",
      "        mean_td_error: -35111387136.0\n",
      "        td_error: \"[ 8.1107190e+09  7.7960667e+10 -4.1485435e+09  1.8055823e+10\\n -4.9112752e+10\\\n",
      "          \\  1.2542935e+09  5.6760730e+09  1.2542935e+09\\n  1.8055823e+10  2.4920670e+10\\\n",
      "          \\ -3.6930971e+11  1.2140823e+10\\n  5.9703460e+09  5.9412992e+09  6.6232975e+09\\\n",
      "          \\ -3.6930971e+11\\n  7.7960667e+10  9.8727363e+09 -3.6930971e+11  4.3682365e+09\\n\\\n",
      "          \\  1.2542935e+09  2.0349977e+10 -1.0368500e+10  3.0034002e+10\\n  1.4049182e+10\\\n",
      "          \\  1.2542935e+09  1.2803047e+10  1.2140823e+10\\n  3.3732952e+10  1.1174137e+10\\\n",
      "          \\ -3.6930971e+11  2.3458611e+09]\"\n",
      "    num_agent_steps_sampled: 262000\n",
      "    num_agent_steps_trained: 2088032\n",
      "    num_steps_sampled: 262000\n",
      "    num_steps_trained: 2088032\n",
      "    num_target_updates: 518\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.77058823529413\n",
      "    ram_util_percent: 92.34705882352942\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0399100139896083\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.053788253255577\n",
      "    mean_inference_ms: 1.5620631984914655\n",
      "    mean_raw_obs_processing_ms: 2.1633465723203456\n",
      "  time_since_restore: 4043.7663383483887\n",
      "  time_this_iter_s: 12.43754768371582\n",
      "  time_total_s: 4043.7663383483887\n",
      "  timers:\n",
      "    learn_throughput: 3691.012\n",
      "    learn_time_ms: 8.67\n",
      "    load_throughput: 64431.726\n",
      "    load_time_ms: 0.497\n",
      "    update_time_ms: 1.684\n",
      "  timestamp: 1632005475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 262000\n",
      "  training_iteration: 262\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   262</td><td style=\"text-align: right;\">         4043.77</td><td style=\"text-align: right;\">262000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 263000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-51-26\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 269\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 262576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 621378863104.0\n",
      "          mean_q: 111011872768.0\n",
      "          min_q: 605030912.0\n",
      "        mean_td_error: -46502309888.0\n",
      "        td_error: \"[-2.8289108e+10  1.2081498e+08 -9.1309844e+09 -3.4863415e+10\\n -2.4888115e+10\\\n",
      "          \\ -1.7420919e+10  7.2950907e+10 -1.5921889e+10\\n -3.9688382e+11  8.6506209e+09\\\n",
      "          \\ -3.4152233e+10  2.6130842e+09\\n -2.8289108e+10 -3.4863415e+10 -1.2823970e+10\\\n",
      "          \\  5.2135872e+07\\n  1.2956582e+08  2.6173824e+07 -1.7420919e+10 -1.2937814e+10\\n\\\n",
      "          \\  1.1076160e+08 -1.8025087e+10 -8.3981271e+09 -2.2790459e+10\\n -3.9688382e+11\\\n",
      "          \\ -1.2937814e+10  5.3314816e+07 -1.2823970e+10\\n -3.4863415e+10 -3.9688382e+11\\\n",
      "          \\ -4.2003988e+09  2.9112730e+09]\"\n",
      "    num_agent_steps_sampled: 263000\n",
      "    num_agent_steps_trained: 2096032\n",
      "    num_steps_sampled: 263000\n",
      "    num_steps_trained: 2096032\n",
      "    num_target_updates: 520\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.6\n",
      "    ram_util_percent: 92.43529411764706\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03991192578066431\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.050309130797896\n",
      "    mean_inference_ms: 1.562080065591579\n",
      "    mean_raw_obs_processing_ms: 2.158285385813718\n",
      "  time_since_restore: 4055.1665387153625\n",
      "  time_this_iter_s: 11.400200366973877\n",
      "  time_total_s: 4055.1665387153625\n",
      "  timers:\n",
      "    learn_throughput: 3691.428\n",
      "    learn_time_ms: 8.669\n",
      "    load_throughput: 64892.776\n",
      "    load_time_ms: 0.493\n",
      "    update_time_ms: 1.659\n",
      "  timestamp: 1632005486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 263000\n",
      "  training_iteration: 263\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   263</td><td style=\"text-align: right;\">         4055.17</td><td style=\"text-align: right;\">263000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 264000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-51-39\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 270\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 263584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 506804240384.0\n",
      "          mean_q: 156995239936.0\n",
      "          min_q: 968840896.0\n",
      "        mean_td_error: -58791493632.0\n",
      "        td_error: \"[-3.3603912e+09  9.0646720e+07  1.9052528e+10  8.6157558e+09\\n -7.0219284e+09\\\n",
      "          \\ -2.8182774e+09  9.4031634e+10 -1.9944686e+10\\n  2.1089830e+08 -2.1599273e+10\\\n",
      "          \\ -2.1599273e+10 -1.0962862e+09\\n  4.4851853e+08 -4.3487838e+11 -3.8314967e+09\\\n",
      "          \\ -9.9860152e+09\\n  2.1089830e+08 -1.0292986e+10 -4.3487838e+11 -2.1599273e+10\\n\\\n",
      "          \\ -1.0292986e+10 -1.8179850e+10 -6.5939374e+09  8.0391762e+09\\n  1.9052528e+10\\\n",
      "          \\  5.1544719e+09 -2.3411884e+10 -6.7767435e+10\\n -4.3487838e+11 -1.8179850e+10\\\n",
      "          \\ -4.3487838e+11 -2.9145524e+10]\"\n",
      "    num_agent_steps_sampled: 264000\n",
      "    num_agent_steps_trained: 2104032\n",
      "    num_steps_sampled: 264000\n",
      "    num_steps_trained: 2104032\n",
      "    num_target_updates: 522\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.241176470588236\n",
      "    ram_util_percent: 92.45882352941177\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039913832301105644\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.046807913298544\n",
      "    mean_inference_ms: 1.5620965720730777\n",
      "    mean_raw_obs_processing_ms: 2.1532943831328457\n",
      "  time_since_restore: 4067.1947543621063\n",
      "  time_this_iter_s: 12.028215646743774\n",
      "  time_total_s: 4067.1947543621063\n",
      "  timers:\n",
      "    learn_throughput: 3654.351\n",
      "    learn_time_ms: 8.757\n",
      "    load_throughput: 62774.299\n",
      "    load_time_ms: 0.51\n",
      "    update_time_ms: 1.739\n",
      "  timestamp: 1632005499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 264000\n",
      "  training_iteration: 264\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   264</td><td style=\"text-align: right;\">         4067.19</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 265000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-51-52\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 271\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 264592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 672933871616.0\n",
      "          mean_q: 232342781952.0\n",
      "          min_q: 195669008.0\n",
      "        mean_td_error: -24397457408.0\n",
      "        td_error: \"[ 7.3548366e+10 -1.6409412e+10 -2.1690909e+10 -4.8756516e+11\\n -2.1765964e+10\\\n",
      "          \\  7.3548366e+10 -2.5799557e+10 -1.2840665e+10\\n -1.6178610e+10 -2.5799557e+10\\\n",
      "          \\ -2.5799557e+10  7.3548366e+10\\n -1.7024483e+10 -9.1158938e+09 -2.3170056e+10\\\n",
      "          \\ -1.6561209e+10\\n -8.4901560e+09 -6.1582246e+10 -3.2782713e+10 -3.5289440e+10\\n\\\n",
      "          \\ -9.1158938e+09 -7.5883565e+08 -5.6449434e+08 -1.6493445e+10\\n -3.5289440e+10\\\n",
      "          \\  2.3787046e+08 -4.2444718e+09  6.1208960e+07\\n -1.7284145e+10 -1.7767563e+10\\\n",
      "          \\ -2.1049541e+10 -2.1229404e+10]\"\n",
      "    num_agent_steps_sampled: 265000\n",
      "    num_agent_steps_trained: 2112032\n",
      "    num_steps_sampled: 265000\n",
      "    num_steps_trained: 2112032\n",
      "    num_target_updates: 524\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.33888888888889\n",
      "    ram_util_percent: 92.57777777777777\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0399157514971969\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.043372981270155\n",
      "    mean_inference_ms: 1.5621134272047246\n",
      "    mean_raw_obs_processing_ms: 2.148372348475361\n",
      "  time_since_restore: 4080.13827085495\n",
      "  time_this_iter_s: 12.943516492843628\n",
      "  time_total_s: 4080.13827085495\n",
      "  timers:\n",
      "    learn_throughput: 3658.475\n",
      "    learn_time_ms: 8.747\n",
      "    load_throughput: 64219.009\n",
      "    load_time_ms: 0.498\n",
      "    update_time_ms: 1.719\n",
      "  timestamp: 1632005512\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 265000\n",
      "  training_iteration: 265\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   265</td><td style=\"text-align: right;\">         4080.14</td><td style=\"text-align: right;\">265000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 266000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-52-04\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 272\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 265600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 561683955712.0\n",
      "          mean_q: 135426400256.0\n",
      "          min_q: 1527517952.0\n",
      "        mean_td_error: -93752745984.0\n",
      "        td_error: \"[-1.0854528e+07  1.3016803e+10 -2.7013284e+09  2.5769837e+10\\n -5.6606786e+11\\\n",
      "          \\  7.8629315e+09  4.9477619e+08 -1.9522355e+09\\n -5.6606786e+11  2.3262372e+10\\\n",
      "          \\  2.5512952e+10 -1.8684314e+08\\n -1.8135613e+09  5.9266826e+09  1.9537912e+10\\\n",
      "          \\ -1.6197222e+09\\n -6.4013853e+10 -5.7857464e+09  5.4409626e+09  5.5760650e+09\\n\\\n",
      "          \\ -5.6606786e+11 -4.7233634e+10 -4.7233634e+10 -4.7233634e+10\\n  1.3940916e+10\\\n",
      "          \\ -5.6606786e+11  1.0935239e+10  1.7331110e+10\\n -6.4013853e+10 -4.7233634e+10\\\n",
      "          \\ -1.3324657e+10 -5.6606786e+11]\"\n",
      "    num_agent_steps_sampled: 266000\n",
      "    num_agent_steps_trained: 2120032\n",
      "    num_steps_sampled: 266000\n",
      "    num_steps_trained: 2120032\n",
      "    num_target_updates: 526\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.18888888888889\n",
      "    ram_util_percent: 92.53333333333333\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03991766611598569\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.0398946680025\n",
      "    mean_inference_ms: 1.5621301939291214\n",
      "    mean_raw_obs_processing_ms: 2.1435178170388984\n",
      "  time_since_restore: 4092.515742778778\n",
      "  time_this_iter_s: 12.377471923828125\n",
      "  time_total_s: 4092.515742778778\n",
      "  timers:\n",
      "    learn_throughput: 3753.303\n",
      "    learn_time_ms: 8.526\n",
      "    load_throughput: 66705.297\n",
      "    load_time_ms: 0.48\n",
      "    update_time_ms: 1.774\n",
      "  timestamp: 1632005524\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 266000\n",
      "  training_iteration: 266\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   266</td><td style=\"text-align: right;\">         4092.52</td><td style=\"text-align: right;\">266000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 267000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-52-15\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 273\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 266608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 798886002688.0\n",
      "          mean_q: 214292348928.0\n",
      "          min_q: 1232879488.0\n",
      "        mean_td_error: -95747653632.0\n",
      "        td_error: \"[-8.1519141e+10 -1.3978340e+10  8.3616006e+10 -6.4436224e+07\\n -6.2865126e+11\\\n",
      "          \\ -1.3061521e+10  2.9036577e+10 -1.4664729e+10\\n  1.2037210e+10  1.6952148e+10\\\n",
      "          \\ -1.3061521e+10  2.3547232e+10\\n  1.8468012e+10  1.7998053e+10 -6.2865126e+11\\\n",
      "          \\ -2.1066547e+08\\n -1.3061521e+10 -6.2865126e+11 -8.1519141e+10  1.1612127e+10\\n\\\n",
      "          \\ -6.2865126e+11  8.6581248e+09  1.7993466e+10  2.3547232e+10\\n  4.1342894e+10\\\n",
      "          \\ -6.2865126e+11  1.7998053e+10 -3.3882342e+08\\n  4.4037259e+10  1.6952148e+10\\\n",
      "          \\ -5.8140643e+10 -1.4844658e+10]\"\n",
      "    num_agent_steps_sampled: 267000\n",
      "    num_agent_steps_trained: 2128032\n",
      "    num_steps_sampled: 267000\n",
      "    num_steps_trained: 2128032\n",
      "    num_target_updates: 528\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.3875\n",
      "    ram_util_percent: 92.65625\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039919545157352236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.036318169761493\n",
      "    mean_inference_ms: 1.5621452307202082\n",
      "    mean_raw_obs_processing_ms: 2.138729887701815\n",
      "  time_since_restore: 4103.842084169388\n",
      "  time_this_iter_s: 11.326341390609741\n",
      "  time_total_s: 4103.842084169388\n",
      "  timers:\n",
      "    learn_throughput: 3690.687\n",
      "    learn_time_ms: 8.67\n",
      "    load_throughput: 65268.298\n",
      "    load_time_ms: 0.49\n",
      "    update_time_ms: 1.697\n",
      "  timestamp: 1632005535\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 267000\n",
      "  training_iteration: 267\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   267</td><td style=\"text-align: right;\">         4103.84</td><td style=\"text-align: right;\">267000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 268000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-52-27\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.84\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 274\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 267616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 706194309120.0\n",
      "          mean_q: 202802937856.0\n",
      "          min_q: 489903104.0\n",
      "        mean_td_error: -14839459840.0\n",
      "        td_error: \"[ 2.2801792e+07  3.8203384e+10 -4.7819129e+10  3.8203384e+10\\n  1.4841840e+10\\\n",
      "          \\  2.1363360e+10  9.4281728e+09 -5.0469274e+08\\n  9.2711158e+09  1.4219411e+10\\\n",
      "          \\ -1.4223442e+09 -1.4515674e+08\\n  8.5834240e+06  5.5050240e+07  1.2620644e+10\\\n",
      "          \\  7.7945856e+07\\n -1.6392202e+09  3.4976399e+09 -1.9290880e+07  2.1783680e+08\\n\\\n",
      "          \\  1.8000773e+10  9.2977725e+09  9.2711158e+09  1.3872384e+07\\n  3.9785267e+09\\\n",
      "          \\  9.4281728e+09 -6.5715241e+09 -4.5261128e+09\\n  3.8203384e+10  1.4841840e+10\\\n",
      "          \\ -6.8148645e+11  4.2044948e+09]\"\n",
      "    num_agent_steps_sampled: 268000\n",
      "    num_agent_steps_trained: 2136032\n",
      "    num_steps_sampled: 268000\n",
      "    num_steps_trained: 2136032\n",
      "    num_target_updates: 530\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.39411764705883\n",
      "    ram_util_percent: 92.70588235294117\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039921382376867466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.0326929816859\n",
      "    mean_inference_ms: 1.5621583646245147\n",
      "    mean_raw_obs_processing_ms: 2.1340073235399104\n",
      "  time_since_restore: 4115.210108280182\n",
      "  time_this_iter_s: 11.368024110794067\n",
      "  time_total_s: 4115.210108280182\n",
      "  timers:\n",
      "    learn_throughput: 3728.26\n",
      "    learn_time_ms: 8.583\n",
      "    load_throughput: 65009.071\n",
      "    load_time_ms: 0.492\n",
      "    update_time_ms: 1.705\n",
      "  timestamp: 1632005547\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 268000\n",
      "  training_iteration: 268\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   268</td><td style=\"text-align: right;\">         4115.21</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">   -0.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 269000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-52-38\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.78\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 275\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 268624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 571397963776.0\n",
      "          mean_q: 171512430592.0\n",
      "          min_q: 2751737088.0\n",
      "        mean_td_error: -149339570176.0\n",
      "        td_error: \"[-4.6363509e+10 -7.1770665e+09 -3.7419368e+10 -3.4792833e+10\\n -4.5312524e+10\\\n",
      "          \\ -3.7419368e+10 -7.7451310e+11 -2.1486043e+10\\n -3.7011816e+10 -2.7206877e+10\\\n",
      "          \\ -7.7451310e+11 -3.7011816e+10\\n  8.3875840e+06 -7.7451310e+11  8.3875840e+06\\\n",
      "          \\ -7.7451310e+11\\n -7.7451310e+11 -3.4792833e+10 -3.8158213e+10 -4.5312524e+10\\n\\\n",
      "          \\ -2.1486043e+10  3.6893696e+07 -2.7298726e+10 -2.4408064e+10\\n -2.9503635e+10\\\n",
      "          \\ -1.9376734e+10 -9.5217697e+10 -7.2136262e+10\\n -7.2136262e+10 -4.5312524e+10\\\n",
      "          \\ -3.3185300e+10 -1.6828334e+10]\"\n",
      "    num_agent_steps_sampled: 269000\n",
      "    num_agent_steps_trained: 2144032\n",
      "    num_steps_sampled: 269000\n",
      "    num_steps_trained: 2144032\n",
      "    num_target_updates: 532\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.4875\n",
      "    ram_util_percent: 92.7625\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03992318828035109\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.028960678952783\n",
      "    mean_inference_ms: 1.5621697505033743\n",
      "    mean_raw_obs_processing_ms: 2.1293486966578334\n",
      "  time_since_restore: 4126.52201795578\n",
      "  time_this_iter_s: 11.311909675598145\n",
      "  time_total_s: 4126.52201795578\n",
      "  timers:\n",
      "    learn_throughput: 3750.702\n",
      "    learn_time_ms: 8.532\n",
      "    load_throughput: 66224.763\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.713\n",
      "  timestamp: 1632005558\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269000\n",
      "  training_iteration: 269\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   269</td><td style=\"text-align: right;\">         4126.52</td><td style=\"text-align: right;\">269000</td><td style=\"text-align: right;\">   -0.78</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 270000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-52-49\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.73\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 276\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 269632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 938328719360.0\n",
      "          mean_q: 326024724480.0\n",
      "          min_q: 3433058048.0\n",
      "        mean_td_error: -107625037824.0\n",
      "        td_error: \"[ 2.7082228e+10  6.3482163e+08  1.7919279e+10  2.7082228e+10\\n  2.9459743e+09\\\n",
      "          \\  1.5958639e+10 -8.7493483e+11 -2.7659862e+10\\n -6.6034074e+08 -1.0968640e+11\\\n",
      "          \\  9.8778153e+09  1.8745420e+10\\n -4.3264737e+09 -8.7493483e+11  3.7976932e+10\\\n",
      "          \\ -1.0968640e+11\\n  4.4871057e+10  1.0222273e+10 -2.7659862e+10  2.9358817e+09\\n\\\n",
      "          \\  2.0749959e+10 -5.6375706e+08 -7.3427517e+09  1.8745420e+10\\n  7.2637481e+09\\\n",
      "          \\  1.0222273e+10 -7.3500426e+09  3.0308270e+10\\n  2.0049363e+10 -8.7493483e+11\\\n",
      "          \\ -8.7493483e+11  2.7082228e+10]\"\n",
      "    num_agent_steps_sampled: 270000\n",
      "    num_agent_steps_trained: 2152032\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 2152032\n",
      "    num_target_updates: 534\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.443749999999994\n",
      "    ram_util_percent: 92.8125\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03992487775631464\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.02510193009893\n",
      "    mean_inference_ms: 1.562177735562315\n",
      "    mean_raw_obs_processing_ms: 2.1247523485711817\n",
      "  time_since_restore: 4137.815867424011\n",
      "  time_this_iter_s: 11.293849468231201\n",
      "  time_total_s: 4137.815867424011\n",
      "  timers:\n",
      "    learn_throughput: 3711.65\n",
      "    learn_time_ms: 8.622\n",
      "    load_throughput: 62824.25\n",
      "    load_time_ms: 0.509\n",
      "    update_time_ms: 1.77\n",
      "  timestamp: 1632005569\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 270\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   270</td><td style=\"text-align: right;\">         4137.82</td><td style=\"text-align: right;\">270000</td><td style=\"text-align: right;\">   -0.73</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 271000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-53-01\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.71\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 277\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 270640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 772336386048.0\n",
      "          mean_q: 187412774912.0\n",
      "          min_q: 3711897856.0\n",
      "        mean_td_error: -142952103936.0\n",
      "        td_error: \"[ 1.7798136e+10  5.8336215e+09 -9.8589488e+11  6.2559130e+08\\n  1.3776355e+10\\\n",
      "          \\  1.7798136e+10  1.4660608e+08 -9.8589488e+11\\n  1.0005651e+10 -9.8589488e+11\\\n",
      "          \\  3.3158922e+09  2.9564596e+10\\n  1.7952375e+10  1.0005651e+10  3.1064064e+08\\\n",
      "          \\  5.9372012e+09\\n  2.3669047e+10  6.1291385e+10  5.8336215e+09 -1.2542950e+08\\n\\\n",
      "          \\  1.7952375e+10  1.6331408e+10  2.9564596e+10  2.9564596e+10\\n  1.3776355e+10\\\n",
      "          \\ -5.8401280e+07  1.1511890e+10 -9.8589488e+11\\n  4.8826880e+08 -9.8589488e+11\\\n",
      "          \\  1.2075942e+10  6.1195264e+07]\"\n",
      "    num_agent_steps_sampled: 271000\n",
      "    num_agent_steps_trained: 2160032\n",
      "    num_steps_sampled: 271000\n",
      "    num_steps_trained: 2160032\n",
      "    num_target_updates: 536\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.39375\n",
      "    ram_util_percent: 92.81875\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039926496605029935\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.021146934002223\n",
      "    mean_inference_ms: 1.5621826305883004\n",
      "    mean_raw_obs_processing_ms: 2.120217830714454\n",
      "  time_since_restore: 4149.176017522812\n",
      "  time_this_iter_s: 11.36015009880066\n",
      "  time_total_s: 4149.176017522812\n",
      "  timers:\n",
      "    learn_throughput: 3626.497\n",
      "    learn_time_ms: 8.824\n",
      "    load_throughput: 53920.026\n",
      "    load_time_ms: 0.593\n",
      "    update_time_ms: 1.788\n",
      "  timestamp: 1632005581\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 271000\n",
      "  training_iteration: 271\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   271</td><td style=\"text-align: right;\">         4149.18</td><td style=\"text-align: right;\">271000</td><td style=\"text-align: right;\">   -0.71</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 272000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-53-12\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.66\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 278\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 271648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1170793299968.0\n",
      "          mean_q: 239594717184.0\n",
      "          min_q: 2131611520.0\n",
      "        mean_td_error: -183879073792.0\n",
      "        td_error: \"[ 2.39936799e+10 -1.05573096e+12 -5.14849178e+09 -3.25506499e+10\\n\\\n",
      "          \\ -2.76784742e+09 -1.22765312e+09 -4.92519424e+10  8.13147750e+09\\n -1.05573096e+12\\\n",
      "          \\ -1.24028045e+09 -3.25506499e+10 -3.04333542e+09\\n -1.35187407e+11 -5.90090240e+07\\\n",
      "          \\ -1.05573096e+12  6.06620877e+09\\n -5.35644078e+10 -5.14849178e+09 -1.35187407e+11\\\n",
      "          \\ -2.56061440e+08\\n -2.76784742e+09  5.06987520e+07  1.52986378e+10 -5.88550636e+10\\n\\\n",
      "          \\ -1.05573096e+12  4.09857946e+09  6.43471770e+09 -8.63653069e+09\\n -2.14681088e+08\\\n",
      "          \\ -1.35187407e+11 -1.05573096e+12 -6.70452941e+09]\"\n",
      "    num_agent_steps_sampled: 272000\n",
      "    num_agent_steps_trained: 2168032\n",
      "    num_steps_sampled: 272000\n",
      "    num_steps_trained: 2168032\n",
      "    num_target_updates: 538\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.3875\n",
      "    ram_util_percent: 92.925\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03992803767789614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.017116275791066\n",
      "    mean_inference_ms: 1.56218472645336\n",
      "    mean_raw_obs_processing_ms: 2.1157434142379317\n",
      "  time_since_restore: 4160.601742267609\n",
      "  time_this_iter_s: 11.425724744796753\n",
      "  time_total_s: 4160.601742267609\n",
      "  timers:\n",
      "    learn_throughput: 3721.747\n",
      "    learn_time_ms: 8.598\n",
      "    load_throughput: 64437.913\n",
      "    load_time_ms: 0.497\n",
      "    update_time_ms: 1.745\n",
      "  timestamp: 1632005592\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 272000\n",
      "  training_iteration: 272\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   272</td><td style=\"text-align: right;\">          4160.6</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">   -0.66</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 273000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-53-23\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.65\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 279\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 272656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1328712384512.0\n",
      "          mean_q: 205086588928.0\n",
      "          min_q: 1719708672.0\n",
      "        mean_td_error: -285070917632.0\n",
      "        td_error: \"[-3.2752640e+08  1.9974308e+10 -1.1926869e+12 -1.6462438e+11\\n -5.6227441e+09\\\n",
      "          \\ -1.1926869e+12 -1.6462438e+11  1.3893370e+10\\n -1.6462438e+11  1.8617663e+10\\\n",
      "          \\  4.1067802e+09 -1.1926869e+12\\n -1.1926869e+12  2.3106109e+09 -2.2773248e+08\\\n",
      "          \\ -2.2409728e+08\\n -1.1183653e+10 -1.1926869e+12 -1.1926869e+12  2.8065174e+10\\n\\\n",
      "          \\ -1.8049401e+10 -1.6462438e+11  3.6443488e+10 -1.6462438e+11\\n  3.6443488e+10\\\n",
      "          \\  1.3893370e+10 -1.1926869e+12  2.2290104e+10\\n -2.2311219e+08 -1.6462438e+11\\\n",
      "          \\  4.6311342e+10  7.7941309e+09]\"\n",
      "    num_agent_steps_sampled: 273000\n",
      "    num_agent_steps_trained: 2176032\n",
      "    num_steps_sampled: 273000\n",
      "    num_steps_trained: 2176032\n",
      "    num_target_updates: 540\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.482352941176465\n",
      "    ram_util_percent: 93.01176470588236\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0399295307024339\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.012999704812488\n",
      "    mean_inference_ms: 1.5621848243106333\n",
      "    mean_raw_obs_processing_ms: 2.1113289690764807\n",
      "  time_since_restore: 4171.897224187851\n",
      "  time_this_iter_s: 11.29548192024231\n",
      "  time_total_s: 4171.897224187851\n",
      "  timers:\n",
      "    learn_throughput: 3711.527\n",
      "    learn_time_ms: 8.622\n",
      "    load_throughput: 64323.65\n",
      "    load_time_ms: 0.497\n",
      "    update_time_ms: 1.735\n",
      "  timestamp: 1632005603\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 273000\n",
      "  training_iteration: 273\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   273</td><td style=\"text-align: right;\">          4171.9</td><td style=\"text-align: right;\">273000</td><td style=\"text-align: right;\">   -0.65</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 274000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-53-35\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.6\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 280\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 273664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 712479408128.0\n",
      "          mean_q: 107452530688.0\n",
      "          min_q: 1802890368.0\n",
      "        mean_td_error: -479813369856.0\n",
      "        td_error: \"[-2.1082423e+11  7.3520906e+09 -1.3495489e+12 -3.5026432e+08\\n  6.5134490e+08\\\n",
      "          \\  6.2351360e+06 -3.4759578e+09 -1.3495489e+12\\n -1.3495489e+12 -1.1983903e+09\\\n",
      "          \\ -5.2069376e+08 -1.3495489e+12\\n  9.0296320e+06 -6.3184517e+09 -5.7807053e+08\\\n",
      "          \\ -9.6577126e+09\\n -1.3495489e+12 -1.3495489e+12  2.7288079e+09 -2.1082423e+11\\n\\\n",
      "          \\  6.5134490e+08 -2.7385201e+10 -1.3495489e+12 -1.3495489e+12\\n -2.7466269e+10\\\n",
      "          \\ -2.2194848e+10  2.7288079e+09  6.5134490e+08\\n -2.9756948e+09 -1.3495489e+12\\\n",
      "          \\ -1.3495489e+12 -1.3495489e+12]\"\n",
      "    num_agent_steps_sampled: 274000\n",
      "    num_agent_steps_trained: 2184032\n",
      "    num_steps_sampled: 274000\n",
      "    num_steps_trained: 2184032\n",
      "    num_target_updates: 542\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.5\n",
      "    ram_util_percent: 93.06875\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03993095681624712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.008804002553132\n",
      "    mean_inference_ms: 1.562182257932006\n",
      "    mean_raw_obs_processing_ms: 2.1069736649469966\n",
      "  time_since_restore: 4183.384583950043\n",
      "  time_this_iter_s: 11.487359762191772\n",
      "  time_total_s: 4183.384583950043\n",
      "  timers:\n",
      "    learn_throughput: 3659.821\n",
      "    learn_time_ms: 8.744\n",
      "    load_throughput: 63919.291\n",
      "    load_time_ms: 0.501\n",
      "    update_time_ms: 1.753\n",
      "  timestamp: 1632005615\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 274000\n",
      "  training_iteration: 274\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   274</td><td style=\"text-align: right;\">         4183.38</td><td style=\"text-align: right;\">274000</td><td style=\"text-align: right;\">    -0.6</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 275000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-53-46\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.61\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 281\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 274672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1654218162176.0\n",
      "          mean_q: 231313014784.0\n",
      "          min_q: 2886946048.0\n",
      "        mean_td_error: -370539462656.0\n",
      "        td_error: \"[-1.4736441e+12 -3.7313905e+10 -2.8656927e+10 -3.7196872e+09\\n  5.1099351e+09\\\n",
      "          \\ -2.2537603e+11 -1.4736441e+12 -1.4736441e+12\\n -1.0858936e+09 -5.1715637e+10\\\n",
      "          \\ -5.0794332e+10  5.5710822e+08\\n -2.2537603e+11 -1.4736441e+12 -6.5886029e+09\\\n",
      "          \\ -3.8304874e+10\\n -2.2537603e+11 -5.4437872e+10 -1.4736441e+12  5.5757824e+08\\n\\\n",
      "          \\  4.6241587e+08  1.0832794e+09 -5.7229496e+10 -5.1715637e+10\\n -2.2537603e+11\\\n",
      "          \\  7.1662490e+08 -1.4736441e+12 -4.3171348e+09\\n -1.6785203e+08 -2.2537603e+11\\\n",
      "          \\ -1.4736441e+12 -3.7313905e+10]\"\n",
      "    num_agent_steps_sampled: 275000\n",
      "    num_agent_steps_trained: 2192032\n",
      "    num_steps_sampled: 275000\n",
      "    num_steps_trained: 2192032\n",
      "    num_target_updates: 544\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.5875\n",
      "    ram_util_percent: 93.13125\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03993232190866421\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.004552244073865\n",
      "    mean_inference_ms: 1.5621776084757817\n",
      "    mean_raw_obs_processing_ms: 2.1026755031885376\n",
      "  time_since_restore: 4194.697012901306\n",
      "  time_this_iter_s: 11.312428951263428\n",
      "  time_total_s: 4194.697012901306\n",
      "  timers:\n",
      "    learn_throughput: 3699.007\n",
      "    learn_time_ms: 8.651\n",
      "    load_throughput: 65173.219\n",
      "    load_time_ms: 0.491\n",
      "    update_time_ms: 2.694\n",
      "  timestamp: 1632005626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 275000\n",
      "  training_iteration: 275\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   275</td><td style=\"text-align: right;\">          4194.7</td><td style=\"text-align: right;\">275000</td><td style=\"text-align: right;\">   -0.61</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 276000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-53-58\n",
      "  done: false\n",
      "  episode_len_mean: 990.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.59\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 282\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 275680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1850316292096.0\n",
      "          mean_q: 215605968896.0\n",
      "          min_q: 3972528384.0\n",
      "        mean_td_error: -659208863744.0\n",
      "        td_error: \"[ 5.6441610e+09  1.5692339e+09 -4.2560979e+10 -3.7807964e+11\\n -2.4011735e+10\\\n",
      "          \\ -1.7030958e+12 -1.7030958e+12 -1.7030958e+12\\n -3.2188621e+08 -1.7030958e+12\\\n",
      "          \\ -2.5851462e+10 -1.2746957e+09\\n -1.7030958e+12 -1.7030958e+12 -1.7030958e+12\\\n",
      "          \\ -1.7030958e+12\\n -3.7100650e+10 -5.4326446e+09 -1.7030958e+12 -2.7945352e+09\\n\\\n",
      "          \\ -3.7100650e+10  3.2106404e+09  3.2106404e+09  1.5692339e+09\\n  7.3555932e+09\\\n",
      "          \\  1.1940454e+08 -1.7030958e+12 -1.7030958e+12\\n -3.7100650e+10 -5.4326446e+09\\\n",
      "          \\ -8.3151389e+10 -1.7030958e+12]\"\n",
      "    num_agent_steps_sampled: 276000\n",
      "    num_agent_steps_trained: 2200032\n",
      "    num_steps_sampled: 276000\n",
      "    num_steps_trained: 2200032\n",
      "    num_target_updates: 546\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.20625\n",
      "    ram_util_percent: 93.1125\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03993359736623284\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.000237939836039\n",
      "    mean_inference_ms: 1.5621699821931967\n",
      "    mean_raw_obs_processing_ms: 2.098434579228102\n",
      "  time_since_restore: 4206.049080133438\n",
      "  time_this_iter_s: 11.352067232131958\n",
      "  time_total_s: 4206.049080133438\n",
      "  timers:\n",
      "    learn_throughput: 3698.813\n",
      "    learn_time_ms: 8.651\n",
      "    load_throughput: 63658.57\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.687\n",
      "  timestamp: 1632005638\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 276000\n",
      "  training_iteration: 276\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   276</td><td style=\"text-align: right;\">         4206.05</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">   -0.59</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 277000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-54-26\n",
      "  done: false\n",
      "  episode_len_mean: 989.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.59\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 283\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 276688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1697804189696.0\n",
      "          mean_q: 471505993728.0\n",
      "          min_q: 19375493120.0\n",
      "        mean_td_error: -295491338240.0\n",
      "        td_error: \"[ 1.81075722e+10 -1.29134441e+12  3.86574336e+08 -1.29134441e+12\\n\\\n",
      "          \\  6.28946371e+10 -1.29134441e+12  1.33896982e+12 -5.50473564e+10\\n -1.29134441e+12\\\n",
      "          \\ -1.20180941e+09 -3.37508827e+11  1.20811815e+11\\n  1.33896982e+12 -5.57895680e+07\\\n",
      "          \\ -1.48729446e+09 -3.37508827e+11\\n -1.68802058e+12  3.16381184e+08  3.24834099e+10\\\n",
      "          \\  3.86574336e+08\\n -3.37508827e+11 -2.40645530e+09 -1.29134441e+12 -1.45778688e+09\\n\\\n",
      "          \\ -1.29134441e+12 -1.68802058e+12  1.20811815e+11 -1.48729446e+09\\n -1.29134441e+12\\\n",
      "          \\ -1.99548928e+08 -3.37508827e+11  1.33896982e+12]\"\n",
      "    num_agent_steps_sampled: 277000\n",
      "    num_agent_steps_trained: 2208032\n",
      "    num_steps_sampled: 277000\n",
      "    num_steps_trained: 2208032\n",
      "    num_target_updates: 548\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 31.6025\n",
      "    ram_util_percent: 93.13250000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03993479236992578\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.995812046223012\n",
      "    mean_inference_ms: 1.5621593476004214\n",
      "    mean_raw_obs_processing_ms: 2.0948508211478174\n",
      "  time_since_restore: 4233.951765298843\n",
      "  time_this_iter_s: 27.902685165405273\n",
      "  time_total_s: 4233.951765298843\n",
      "  timers:\n",
      "    learn_throughput: 3719.529\n",
      "    learn_time_ms: 8.603\n",
      "    load_throughput: 64130.024\n",
      "    load_time_ms: 0.499\n",
      "    update_time_ms: 1.731\n",
      "  timestamp: 1632005666\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 277000\n",
      "  training_iteration: 277\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   277</td><td style=\"text-align: right;\">         4233.95</td><td style=\"text-align: right;\">277000</td><td style=\"text-align: right;\">   -0.59</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 278000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-54-39\n",
      "  done: false\n",
      "  episode_len_mean: 989.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: -0.59\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 284\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 277696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1980165521408.0\n",
      "          mean_q: 441016713216.0\n",
      "          min_q: 22581078016.0\n",
      "        mean_td_error: -694745825280.0\n",
      "        td_error: \"[ 6.67474330e+09 -1.92481028e+12  1.32165442e+12 -4.95925330e+10\\n\\\n",
      "          \\ -1.92481028e+12 -1.92481028e+12 -1.92481028e+12 -1.92481028e+12\\n  1.33373624e+11\\\n",
      "          \\  5.14340659e+10 -1.49070388e+12 -9.18353920e+09\\n -1.92481028e+12 -4.95925330e+10\\\n",
      "          \\ -1.92481028e+12  1.32165442e+12\\n -1.92481028e+12  1.32165442e+12 -1.49070388e+12\\\n",
      "          \\ -1.92481028e+12\\n -4.95925330e+10 -4.75996160e+07 -1.49070388e+12  2.33842278e+09\\n\\\n",
      "          \\  1.41083914e+10 -5.72579840e+07 -1.92481028e+12 -2.75779584e+08\\n  1.32165442e+12\\\n",
      "          \\ -1.92481028e+12 -1.92481028e+12  1.76385843e+09]\"\n",
      "    num_agent_steps_sampled: 278000\n",
      "    num_agent_steps_trained: 2216032\n",
      "    num_steps_sampled: 278000\n",
      "    num_steps_trained: 2216032\n",
      "    num_target_updates: 550\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.931578947368415\n",
      "    ram_util_percent: 93.17894736842106\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039935920805111096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.991369375367838\n",
      "    mean_inference_ms: 1.5621458209277792\n",
      "    mean_raw_obs_processing_ms: 2.0913205716906393\n",
      "  time_since_restore: 4246.830568313599\n",
      "  time_this_iter_s: 12.878803014755249\n",
      "  time_total_s: 4246.830568313599\n",
      "  timers:\n",
      "    learn_throughput: 3640.474\n",
      "    learn_time_ms: 8.79\n",
      "    load_throughput: 64041.286\n",
      "    load_time_ms: 0.5\n",
      "    update_time_ms: 1.859\n",
      "  timestamp: 1632005679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 278000\n",
      "  training_iteration: 278\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   278</td><td style=\"text-align: right;\">         4246.83</td><td style=\"text-align: right;\">278000</td><td style=\"text-align: right;\">   -0.59</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 279000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-54-50\n",
      "  done: false\n",
      "  episode_len_mean: 989.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: -0.61\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 285\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 278704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1651165495296.0\n",
      "          mean_q: 394638065664.0\n",
      "          min_q: 23163770880.0\n",
      "        mean_td_error: -312254201856.0\n",
      "        td_error: \"[ 1.0870587e+11  1.0992323e+12 -2.3828260e+11  1.6709842e+11\\n -2.3828260e+11\\\n",
      "          \\  6.2333338e+08  1.7827574e+09 -1.4364323e+12\\n  1.0992323e+12 -2.9056614e+08\\\n",
      "          \\ -1.6730125e+11  1.1435377e+09\\n -1.2150948e+09 -6.2506271e+10  1.0992323e+12\\\n",
      "          \\ -1.8580976e+12\\n  1.6709842e+11 -1.8580976e+12 -1.5556485e+11  7.3005793e+09\\n\\\n",
      "          \\ -2.9221683e+09 -1.4364323e+12  4.8298435e+10 -1.8580976e+12\\n -1.4364323e+12\\\n",
      "          \\ -1.4364323e+12 -1.0420634e+08 -1.4364323e+12\\n -1.4364323e+12  1.0992323e+12\\\n",
      "          \\  1.1435377e+09  1.6709842e+11]\"\n",
      "    num_agent_steps_sampled: 279000\n",
      "    num_agent_steps_trained: 2224032\n",
      "    num_steps_sampled: 279000\n",
      "    num_steps_trained: 2224032\n",
      "    num_target_updates: 552\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.3875\n",
      "    ram_util_percent: 93.70625\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0399370052210791\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.986890926221228\n",
      "    mean_inference_ms: 1.5621304701658623\n",
      "    mean_raw_obs_processing_ms: 2.0878426017047866\n",
      "  time_since_restore: 4258.175514698029\n",
      "  time_this_iter_s: 11.344946384429932\n",
      "  time_total_s: 4258.175514698029\n",
      "  timers:\n",
      "    learn_throughput: 3664.488\n",
      "    learn_time_ms: 8.732\n",
      "    load_throughput: 61902.836\n",
      "    load_time_ms: 0.517\n",
      "    update_time_ms: 1.725\n",
      "  timestamp: 1632005690\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279000\n",
      "  training_iteration: 279\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   279</td><td style=\"text-align: right;\">         4258.18</td><td style=\"text-align: right;\">279000</td><td style=\"text-align: right;\">   -0.61</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 280000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-55-02\n",
      "  done: false\n",
      "  episode_len_mean: 989.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.62\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 286\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 279712\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2283872976896.0\n",
      "          mean_q: 655779364864.0\n",
      "          min_q: 15282058240.0\n",
      "        mean_td_error: -299156701184.0\n",
      "        td_error: \"[-3.14260455e+11  9.06425795e+10 -2.32520260e+12  1.21275639e+12\\n\\\n",
      "          \\  1.09246808e+11  1.09246808e+11 -3.14260455e+11 -2.82817331e+09\\n -8.28721070e+10\\\n",
      "          \\  4.61621821e+10  4.61621821e+10  7.42648381e+10\\n -1.02918554e+09 -1.88598610e+12\\\n",
      "          \\ -2.32520260e+12 -3.14260455e+11\\n  9.06425795e+10 -4.49404928e+09 -7.10534349e+09\\\n",
      "          \\  1.21275639e+12\\n -1.88598610e+12  6.02515702e+10 -1.66041600e+09 -2.32520260e+12\\n\\\n",
      "          \\  1.21275639e+12 -1.88598610e+12 -1.71465933e+09 -5.04607642e+09\\n  2.56251003e+10\\\n",
      "          \\  8.76669829e+10 -3.14260455e+11  4.61621821e+10]\"\n",
      "    num_agent_steps_sampled: 280000\n",
      "    num_agent_steps_trained: 2232032\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 2232032\n",
      "    num_target_updates: 554\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.51875\n",
      "    ram_util_percent: 93.73125\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039938007490890694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.982369197702627\n",
      "    mean_inference_ms: 1.5621122548999031\n",
      "    mean_raw_obs_processing_ms: 2.0844155165398024\n",
      "  time_since_restore: 4269.856789827347\n",
      "  time_this_iter_s: 11.681275129318237\n",
      "  time_total_s: 4269.856789827347\n",
      "  timers:\n",
      "    learn_throughput: 3714.043\n",
      "    learn_time_ms: 8.616\n",
      "    load_throughput: 66388.548\n",
      "    load_time_ms: 0.482\n",
      "    update_time_ms: 1.703\n",
      "  timestamp: 1632005702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 280\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   280</td><td style=\"text-align: right;\">         4269.86</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">   -0.62</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 281000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-55-13\n",
      "  done: false\n",
      "  episode_len_mean: 989.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.56\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 287\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 280720\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2614527262720.0\n",
      "          mean_q: 682323476480.0\n",
      "          min_q: 19419090944.0\n",
      "        mean_td_error: -681286565888.0\n",
      "        td_error: \"[-9.6035635e+08 -4.2637092e+11 -1.8218661e+12 -9.6035635e+08\\n -2.6180662e+11\\\n",
      "          \\  9.2266447e+10  1.1961540e+12 -9.8316321e+10\\n -1.4747356e+11 -1.4747356e+11\\\n",
      "          \\ -2.3844563e+12  4.0257946e+08\\n -1.8218661e+12  9.2266447e+10 -8.9500959e+09\\\n",
      "          \\  1.1961540e+12\\n -1.8218661e+12 -5.1665469e+09 -2.4844317e+11 -1.5984009e+10\\n\\\n",
      "          \\ -1.8218661e+12 -1.8218661e+12 -2.4844317e+11 -2.3844563e+12\\n  3.1809126e+10\\\n",
      "          \\  1.2640993e+09 -1.8218661e+12 -2.4844317e+11\\n -2.3844563e+12 -1.8218661e+12\\\n",
      "          \\ -2.3844563e+12 -2.6180662e+11]\"\n",
      "    num_agent_steps_sampled: 281000\n",
      "    num_agent_steps_trained: 2240032\n",
      "    num_steps_sampled: 281000\n",
      "    num_steps_trained: 2240032\n",
      "    num_target_updates: 556\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.17058823529411\n",
      "    ram_util_percent: 93.81764705882352\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03993896805148582\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.977812715857656\n",
      "    mean_inference_ms: 1.562092028630409\n",
      "    mean_raw_obs_processing_ms: 2.0810393307533426\n",
      "  time_since_restore: 4281.193269729614\n",
      "  time_this_iter_s: 11.336479902267456\n",
      "  time_total_s: 4281.193269729614\n",
      "  timers:\n",
      "    learn_throughput: 3694.801\n",
      "    learn_time_ms: 8.661\n",
      "    load_throughput: 66201.898\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.685\n",
      "  timestamp: 1632005713\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 281000\n",
      "  training_iteration: 281\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   281</td><td style=\"text-align: right;\">         4281.19</td><td style=\"text-align: right;\">281000</td><td style=\"text-align: right;\">   -0.56</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 282000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-55-24\n",
      "  done: false\n",
      "  episode_len_mean: 989.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.49\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 288\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 281728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3588494458880.0\n",
      "          mean_q: 1219859054592.0\n",
      "          min_q: 77385777152.0\n",
      "        mean_td_error: -260748902400.0\n",
      "        td_error: \"[-2.4017528e+11 -2.4017528e+11 -6.7776807e+10 -2.6462836e+12\\n  1.4609062e+11\\\n",
      "          \\  5.9382006e+09  4.6361805e+11 -8.6417474e+10\\n  1.4263513e+12 -3.6928389e+09\\\n",
      "          \\ -1.8071388e+09  1.4263513e+12\\n -8.6417474e+10 -3.0905690e+11 -2.6462836e+12\\\n",
      "          \\ -8.6417474e+10\\n -1.0927735e+10 -4.8483041e+09  1.4609062e+11 -9.5689196e+09\\n\\\n",
      "          \\ -4.5425544e+11 -2.6462836e+12 -2.6462836e+12 -1.1317903e+09\\n  4.6361805e+11\\\n",
      "          \\ -8.6417474e+10 -6.7776807e+10 -8.6417474e+10\\n -1.0927735e+10  2.0298629e+10\\\n",
      "          \\ -3.5619144e+09  5.8331136e+08]\"\n",
      "    num_agent_steps_sampled: 282000\n",
      "    num_agent_steps_trained: 2248032\n",
      "    num_steps_sampled: 282000\n",
      "    num_steps_trained: 2248032\n",
      "    num_target_updates: 558\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.412499999999994\n",
      "    ram_util_percent: 93.8875\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03993987510651351\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.973216597742948\n",
      "    mean_inference_ms: 1.5620695789874304\n",
      "    mean_raw_obs_processing_ms: 2.077713120931038\n",
      "  time_since_restore: 4292.72717499733\n",
      "  time_this_iter_s: 11.533905267715454\n",
      "  time_total_s: 4292.72717499733\n",
      "  timers:\n",
      "    learn_throughput: 3711.507\n",
      "    learn_time_ms: 8.622\n",
      "    load_throughput: 66277.087\n",
      "    load_time_ms: 0.483\n",
      "    update_time_ms: 1.702\n",
      "  timestamp: 1632005724\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 282000\n",
      "  training_iteration: 282\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   282</td><td style=\"text-align: right;\">         4292.73</td><td style=\"text-align: right;\">282000</td><td style=\"text-align: right;\">   -0.49</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            989.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 283000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-55-36\n",
      "  done: false\n",
      "  episode_len_mean: 990.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.44\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 289\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 282736\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3752063664128.0\n",
      "          mean_q: 1681592549376.0\n",
      "          min_q: 95636447232.0\n",
      "        mean_td_error: -202647994368.0\n",
      "        td_error: \"[-1.9321078e+10 -2.3155999e+10  9.1756036e+11  9.1756036e+11\\n  1.5086400e+12\\\n",
      "          \\  1.5857566e+10  9.1756036e+11 -2.7202028e+09\\n  2.3742382e+10 -2.1949501e+11\\\n",
      "          \\  1.5086400e+12 -3.1716803e+09\\n -3.3731862e+12 -3.3731862e+12  1.5086400e+12\\\n",
      "          \\  9.1756036e+11\\n  1.5086400e+12 -2.1949501e+11 -3.3731862e+12 -2.1949501e+11\\n\\\n",
      "          \\ -2.1670920e+10 -3.1174656e+09 -3.3731862e+12 -3.3731862e+12\\n -2.1949501e+11\\\n",
      "          \\ -2.1949501e+11  9.1756036e+11 -2.1925642e+10\\n -1.9321078e+10 -2.3054746e+09\\\n",
      "          \\  1.5857566e+10  9.1756036e+11]\"\n",
      "    num_agent_steps_sampled: 283000\n",
      "    num_agent_steps_trained: 2256032\n",
      "    num_steps_sampled: 283000\n",
      "    num_steps_trained: 2256032\n",
      "    num_target_updates: 560\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.34705882352941\n",
      "    ram_util_percent: 93.88235294117646\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03994072150378941\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.968559112698704\n",
      "    mean_inference_ms: 1.562044226399725\n",
      "    mean_raw_obs_processing_ms: 2.0735038632011356\n",
      "  time_since_restore: 4304.169704914093\n",
      "  time_this_iter_s: 11.442529916763306\n",
      "  time_total_s: 4304.169704914093\n",
      "  timers:\n",
      "    learn_throughput: 3714.105\n",
      "    learn_time_ms: 8.616\n",
      "    load_throughput: 66381.981\n",
      "    load_time_ms: 0.482\n",
      "    update_time_ms: 1.689\n",
      "  timestamp: 1632005736\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 283000\n",
      "  training_iteration: 283\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   283</td><td style=\"text-align: right;\">         4304.17</td><td style=\"text-align: right;\">283000</td><td style=\"text-align: right;\">   -0.44</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 284000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-55-47\n",
      "  done: false\n",
      "  episode_len_mean: 990.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.41\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 290\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 283744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5426854232064.0\n",
      "          mean_q: 575092228096.0\n",
      "          min_q: 48508956672.0\n",
      "        mean_td_error: -310566354944.0\n",
      "        td_error: \"[-1.54346783e+10  1.06147578e+11  1.16647526e+10  1.06147578e+11\\n\\\n",
      "          \\ -4.12455404e+10 -2.32442757e+10 -2.69724713e+10 -1.14319426e+11\\n -4.19583046e+12\\\n",
      "          \\  1.74647173e+10 -1.08673106e+10 -1.62258731e+11\\n -1.75344517e+10 -1.77490166e+10\\\n",
      "          \\ -1.08673106e+10 -1.62890383e+10\\n -1.86992558e+10 -1.60525517e+10 -3.94012262e+10\\\n",
      "          \\  1.65508048e+12\\n -1.59508398e+10  3.77400484e+10  1.65508048e+12 -1.03398539e+11\\n\\\n",
      "          \\ -1.62258731e+11 -2.10318131e+10 -4.19583046e+12 -6.35527823e+10\\n -4.19583046e+12\\\n",
      "          \\ -8.95028429e+09 -2.30681805e+09 -3.15726889e+10]\"\n",
      "    num_agent_steps_sampled: 284000\n",
      "    num_agent_steps_trained: 2264032\n",
      "    num_steps_sampled: 284000\n",
      "    num_steps_trained: 2264032\n",
      "    num_target_updates: 562\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.318749999999994\n",
      "    ram_util_percent: 93.6875\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03994153028615608\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.963870955661872\n",
      "    mean_inference_ms: 1.562016376938557\n",
      "    mean_raw_obs_processing_ms: 2.069348325812457\n",
      "  time_since_restore: 4315.521518468857\n",
      "  time_this_iter_s: 11.351813554763794\n",
      "  time_total_s: 4315.521518468857\n",
      "  timers:\n",
      "    learn_throughput: 3666.76\n",
      "    learn_time_ms: 8.727\n",
      "    load_throughput: 64639.63\n",
      "    load_time_ms: 0.495\n",
      "    update_time_ms: 1.732\n",
      "  timestamp: 1632005747\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 284000\n",
      "  training_iteration: 284\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   284</td><td style=\"text-align: right;\">         4315.52</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">   -0.41</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">            990.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 285000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-55-59\n",
      "  done: false\n",
      "  episode_len_mean: 990.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.31\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 291\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 284752\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 963184689152.0\n",
      "          mean_q: 541386014720.0\n",
      "          min_q: 78464425984.0\n",
      "        mean_td_error: 13233136640.0\n",
      "        td_error: \"[-6.1623501e+08 -3.9251214e+10 -1.4934722e+11 -6.2586683e+10\\n -6.2586683e+10\\\n",
      "          \\  1.9436326e+11 -7.4359767e+09  4.7639757e+09\\n  1.1189125e+09 -5.3855519e+09\\\n",
      "          \\  5.9448361e+09  8.3294683e+10\\n -3.7625364e+10  4.7639757e+09  3.3219543e+09\\\n",
      "          \\ -1.4934606e+10\\n  8.3294683e+10 -7.4359767e+09 -2.4832901e+09  4.5550469e+09\\n\\\n",
      "          \\ -1.6157173e+11  4.7639757e+09  2.2565624e+11  2.2565624e+11\\n  9.1281162e+09\\\n",
      "          \\  4.5785825e+09  4.5550469e+09 -7.4359767e+09\\n  5.9805532e+09  2.2565624e+11\\\n",
      "          \\  5.2332282e+10 -1.6157173e+11]\"\n",
      "    num_agent_steps_sampled: 285000\n",
      "    num_agent_steps_trained: 2272032\n",
      "    num_steps_sampled: 285000\n",
      "    num_steps_trained: 2272032\n",
      "    num_target_updates: 564\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.9125\n",
      "    ram_util_percent: 93.55625\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03994227484842096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.959172450470057\n",
      "    mean_inference_ms: 1.5619855528882056\n",
      "    mean_raw_obs_processing_ms: 2.065245206029674\n",
      "  time_since_restore: 4326.88298034668\n",
      "  time_this_iter_s: 11.361461877822876\n",
      "  time_total_s: 4326.88298034668\n",
      "  timers:\n",
      "    learn_throughput: 3697.102\n",
      "    learn_time_ms: 8.655\n",
      "    load_throughput: 64814.433\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.658\n",
      "  timestamp: 1632005759\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 285000\n",
      "  training_iteration: 285\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   285</td><td style=\"text-align: right;\">         4326.88</td><td style=\"text-align: right;\">285000</td><td style=\"text-align: right;\">   -0.31</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">            990.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 286000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-56-11\n",
      "  done: false\n",
      "  episode_len_mean: 990.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.26\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 292\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 285760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1442413281280.0\n",
      "          mean_q: 780323389440.0\n",
      "          min_q: 64852164608.0\n",
      "        mean_td_error: -29474934784.0\n",
      "        td_error: \"[-4.1103262e+10 -2.8829614e+10 -7.5949670e+09 -1.3425770e+10\\n -4.6661042e+10\\\n",
      "          \\ -7.0129418e+09 -2.1255107e+11 -2.5972802e+10\\n -9.1107492e+09  7.9363686e+09\\\n",
      "          \\  7.9363686e+09 -1.5875703e+10\\n -1.1919294e+10 -9.1107492e+09  7.9363686e+09\\\n",
      "          \\ -3.7737890e+10\\n -1.1814175e+10  2.3180673e+10 -5.1833143e+10 -6.6949480e+10\\n\\\n",
      "          \\  7.9363686e+09 -2.9224370e+10 -9.1107492e+09 -1.3914079e+10\\n -2.4618467e+10\\\n",
      "          \\ -2.1255107e+11 -1.5120007e+10 -3.5526279e+10\\n -2.5972802e+10  2.3180673e+10\\\n",
      "          \\ -6.6949480e+10  9.1851981e+09]\"\n",
      "    num_agent_steps_sampled: 286000\n",
      "    num_agent_steps_trained: 2280032\n",
      "    num_steps_sampled: 286000\n",
      "    num_steps_trained: 2280032\n",
      "    num_target_updates: 566\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.358823529411765\n",
      "    ram_util_percent: 93.58823529411764\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039943011125120775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.954467210381489\n",
      "    mean_inference_ms: 1.5619534066871665\n",
      "    mean_raw_obs_processing_ms: 2.0591310900183872\n",
      "  time_since_restore: 4338.667508602142\n",
      "  time_this_iter_s: 11.784528255462646\n",
      "  time_total_s: 4338.667508602142\n",
      "  timers:\n",
      "    learn_throughput: 3534.268\n",
      "    learn_time_ms: 9.054\n",
      "    load_throughput: 57439.007\n",
      "    load_time_ms: 0.557\n",
      "    update_time_ms: 1.903\n",
      "  timestamp: 1632005771\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 286000\n",
      "  training_iteration: 286\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   286</td><td style=\"text-align: right;\">         4338.67</td><td style=\"text-align: right;\">286000</td><td style=\"text-align: right;\">   -0.26</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">            990.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 287000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-56-23\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.26\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 293\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 286768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1893072371712.0\n",
      "          mean_q: 1092806246400.0\n",
      "          min_q: 94273781760.0\n",
      "        mean_td_error: -4790087168.0\n",
      "        td_error: \"[ 1.2290621e+10  4.1689219e+10 -2.2699311e+11  8.8246845e+09\\n  8.6388244e+09\\\n",
      "          \\  2.0159136e+10 -2.2699311e+11  1.2416831e+11\\n  7.3679593e+10  4.7563440e+10\\\n",
      "          \\  1.6355189e+10 -5.8881475e+09\\n -5.2612694e+10  9.6893927e+10 -1.9051708e+10\\\n",
      "          \\ -5.2612694e+10\\n -4.5819494e+10  1.2416831e+11  8.6388244e+09  4.7563440e+10\\n\\\n",
      "          \\  1.7886716e+10  1.6619299e+10 -5.2612694e+10  6.3573852e+09\\n  1.6355189e+10\\\n",
      "          \\  1.4221574e+10  8.6005645e+10  6.4102072e+09\\n -2.2699311e+11 -3.2823706e+10\\\n",
      "          \\  8.6388244e+09 -1.4010679e+10]\"\n",
      "    num_agent_steps_sampled: 287000\n",
      "    num_agent_steps_trained: 2288032\n",
      "    num_steps_sampled: 287000\n",
      "    num_steps_trained: 2288032\n",
      "    num_target_updates: 568\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.829411764705874\n",
      "    ram_util_percent: 93.77647058823528\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03994379479814591\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.949706680448318\n",
      "    mean_inference_ms: 1.5619219931505013\n",
      "    mean_raw_obs_processing_ms: 2.05296007564823\n",
      "  time_since_restore: 4350.790954113007\n",
      "  time_this_iter_s: 12.123445510864258\n",
      "  time_total_s: 4350.790954113007\n",
      "  timers:\n",
      "    learn_throughput: 3680.99\n",
      "    learn_time_ms: 8.693\n",
      "    load_throughput: 47830.7\n",
      "    load_time_ms: 0.669\n",
      "    update_time_ms: 1.778\n",
      "  timestamp: 1632005783\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 287000\n",
      "  training_iteration: 287\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   287</td><td style=\"text-align: right;\">         4350.79</td><td style=\"text-align: right;\">287000</td><td style=\"text-align: right;\">   -0.26</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 288000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-56-35\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.23\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 294\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 287776\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2251067228160.0\n",
      "          mean_q: 1077734408192.0\n",
      "          min_q: 68138164224.0\n",
      "        mean_td_error: -13760190464.0\n",
      "        td_error: \"[-1.0416816e+10  9.2573860e+09  1.2695634e+09 -7.8452621e+10\\n -1.0416816e+10\\\n",
      "          \\ -1.9481100e+10 -6.2455808e+09 -1.5538848e+10\\n  2.3623107e+10  9.2573860e+09\\\n",
      "          \\ -1.7870725e+10 -2.0929249e+09\\n -1.3116047e+09 -1.3116047e+09 -1.5999173e+10\\\n",
      "          \\ -1.9523437e+10\\n -1.7870725e+10 -4.2996597e+10 -1.3116047e+09 -6.2455808e+09\\n\\\n",
      "          \\ -1.9102958e+10 -1.7807625e+11 -9.3905224e+09 -2.5815286e+10\\n -3.2190956e+09\\\n",
      "          \\  1.1319063e+11 -1.5529279e+10 -9.3905224e+09\\n -8.7541514e+09 -4.2996597e+10\\\n",
      "          \\ -1.5470821e+10 -2.0929249e+09]\"\n",
      "    num_agent_steps_sampled: 288000\n",
      "    num_agent_steps_trained: 2296032\n",
      "    num_steps_sampled: 288000\n",
      "    num_steps_trained: 2296032\n",
      "    num_target_updates: 570\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.81666666666666\n",
      "    ram_util_percent: 93.68333333333334\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03994462574262238\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.9449231732891645\n",
      "    mean_inference_ms: 1.5618913556378065\n",
      "    mean_raw_obs_processing_ms: 2.0468524360269895\n",
      "  time_since_restore: 4363.249305725098\n",
      "  time_this_iter_s: 12.458351612091064\n",
      "  time_total_s: 4363.249305725098\n",
      "  timers:\n",
      "    learn_throughput: 3340.985\n",
      "    learn_time_ms: 9.578\n",
      "    load_throughput: 49283.149\n",
      "    load_time_ms: 0.649\n",
      "    update_time_ms: 1.866\n",
      "  timestamp: 1632005795\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 288000\n",
      "  training_iteration: 288\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   288</td><td style=\"text-align: right;\">         4363.25</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\">   -0.23</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 289000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-56-48\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.22\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 295\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 288784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2230482894848.0\n",
      "          mean_q: 1173173305344.0\n",
      "          min_q: 92331679744.0\n",
      "        mean_td_error: -8534242304.0\n",
      "        td_error: \"[ 1.5326085e+09 -2.4598413e+10  1.3812905e+11 -3.8381289e+10\\n -2.4598413e+10\\\n",
      "          \\ -5.2333117e+10 -2.6645758e+10 -1.6706306e+10\\n  7.2679424e+08 -3.8381289e+10\\\n",
      "          \\ -9.2808806e+09 -2.6645758e+10\\n  5.6259486e+10  1.5326085e+09  1.5326085e+09\\\n",
      "          \\  1.5326085e+09\\n -5.5375167e+10 -3.5849896e+10  1.3812905e+11 -6.8565074e+09\\n\\\n",
      "          \\ -8.9046516e+10 -1.2327191e+10 -3.2639468e+10 -1.0955219e+10\\n -2.5912017e+10\\\n",
      "          \\ -2.5912017e+10 -2.0125975e+10 -8.9046516e+10\\n -2.1251490e+10 -4.3293082e+09\\\n",
      "          \\ -9.9173663e+09  8.4645315e+10]\"\n",
      "    num_agent_steps_sampled: 289000\n",
      "    num_agent_steps_trained: 2304032\n",
      "    num_steps_sampled: 289000\n",
      "    num_steps_trained: 2304032\n",
      "    num_target_updates: 572\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.47894736842105\n",
      "    ram_util_percent: 93.84736842105262\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03994551320671524\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.9401558926697655\n",
      "    mean_inference_ms: 1.561861968970413\n",
      "    mean_raw_obs_processing_ms: 2.0408065917686242\n",
      "  time_since_restore: 4376.379270553589\n",
      "  time_this_iter_s: 13.129964828491211\n",
      "  time_total_s: 4376.379270553589\n",
      "  timers:\n",
      "    learn_throughput: 3517.328\n",
      "    learn_time_ms: 9.098\n",
      "    load_throughput: 53852.958\n",
      "    load_time_ms: 0.594\n",
      "    update_time_ms: 1.919\n",
      "  timestamp: 1632005808\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289000\n",
      "  training_iteration: 289\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   289</td><td style=\"text-align: right;\">         4376.38</td><td style=\"text-align: right;\">289000</td><td style=\"text-align: right;\">   -0.22</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 290000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-57-02\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.19\n",
      "  episode_reward_min: -8.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 296\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 289792\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2743560568832.0\n",
      "          mean_q: 1527769464832.0\n",
      "          min_q: 88712380416.0\n",
      "        mean_td_error: -5856232448.0\n",
      "        td_error: \"[-7.5249746e+09  2.3892886e+10  2.3892886e+10 -4.4930490e+10\\n  7.6061082e+09\\\n",
      "          \\ -4.0593129e+10  2.8502131e+10  9.9004170e+09\\n -5.8715013e+09  1.0139206e+10\\\n",
      "          \\ -4.6303805e+10 -6.6231992e+09\\n -1.4647820e+10 -7.8793933e+09 -1.4647820e+10\\\n",
      "          \\  3.6622828e+09\\n -4.6303805e+10 -2.4282006e+10 -2.6379796e+09 -1.2412649e+10\\n\\\n",
      "          \\ -8.5229568e+09  4.5644186e+08 -7.8155612e+09 -3.0090199e+09\\n -1.4647820e+10\\\n",
      "          \\ -1.4647820e+10 -9.4839767e+09 -6.6231992e+09\\n -8.5229568e+09  1.0382003e+11\\\n",
      "          \\ -4.4930490e+10 -6.4094536e+09]\"\n",
      "    num_agent_steps_sampled: 290000\n",
      "    num_agent_steps_trained: 2312032\n",
      "    num_steps_sampled: 290000\n",
      "    num_steps_trained: 2312032\n",
      "    num_target_updates: 574\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.20526315789474\n",
      "    ram_util_percent: 93.91052631578947\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039946478704703046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.935430323034828\n",
      "    mean_inference_ms: 1.5618345757757064\n",
      "    mean_raw_obs_processing_ms: 2.0348222514939263\n",
      "  time_since_restore: 4389.699069023132\n",
      "  time_this_iter_s: 13.319798469543457\n",
      "  time_total_s: 4389.699069023132\n",
      "  timers:\n",
      "    learn_throughput: 3359.55\n",
      "    learn_time_ms: 9.525\n",
      "    load_throughput: 58105.428\n",
      "    load_time_ms: 0.551\n",
      "    update_time_ms: 1.875\n",
      "  timestamp: 1632005822\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 290000\n",
      "  training_iteration: 290\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   290</td><td style=\"text-align: right;\">          4389.7</td><td style=\"text-align: right;\">290000</td><td style=\"text-align: right;\">   -0.19</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 291000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-57-14\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.11\n",
      "  episode_reward_min: -5.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 297\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 290800\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3000733794304.0\n",
      "          mean_q: 1246842322944.0\n",
      "          min_q: 100465491968.0\n",
      "        mean_td_error: -5554753024.0\n",
      "        td_error: \"[-3.6803969e+10  1.2987531e+10 -7.5437179e+09 -3.4134426e+09\\n -1.5594373e+09\\\n",
      "          \\ -3.6803969e+10 -1.5594373e+09  1.9583074e+10\\n -1.4967333e+10 -4.8129802e+10\\\n",
      "          \\ -1.2382044e+09  1.8156225e+10\\n -4.8129802e+10  1.0802561e+10  3.6185047e+09\\\n",
      "          \\ -8.0162324e+09\\n  2.9582131e+08 -1.5594373e+09 -7.5437179e+09  2.9582131e+08\\n\\\n",
      "          \\ -3.9005323e+10  6.9563843e+09 -3.2641843e+09  5.1259638e+09\\n -1.3340508e+09\\\n",
      "          \\  1.9367461e+10  1.4934344e+10  2.9582131e+08\\n  1.0350674e+09  3.5116548e+10\\\n",
      "          \\ -6.3891735e+10 -1.5594373e+09]\"\n",
      "    num_agent_steps_sampled: 291000\n",
      "    num_agent_steps_trained: 2320032\n",
      "    num_steps_sampled: 291000\n",
      "    num_steps_trained: 2320032\n",
      "    num_target_updates: 576\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.53333333333333\n",
      "    ram_util_percent: 93.95\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039947513711659284\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.930695750073689\n",
      "    mean_inference_ms: 1.5618084282104516\n",
      "    mean_raw_obs_processing_ms: 2.0288980252999864\n",
      "  time_since_restore: 4402.504359722137\n",
      "  time_this_iter_s: 12.805290699005127\n",
      "  time_total_s: 4402.504359722137\n",
      "  timers:\n",
      "    learn_throughput: 3602.609\n",
      "    learn_time_ms: 8.882\n",
      "    load_throughput: 63075.205\n",
      "    load_time_ms: 0.507\n",
      "    update_time_ms: 1.72\n",
      "  timestamp: 1632005834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 291000\n",
      "  training_iteration: 291\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   291</td><td style=\"text-align: right;\">          4402.5</td><td style=\"text-align: right;\">291000</td><td style=\"text-align: right;\">   -0.11</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 292000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-57-27\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.11\n",
      "  episode_reward_min: -5.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 298\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 291808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3279354331136.0\n",
      "          mean_q: 1718753689600.0\n",
      "          min_q: 122283982848.0\n",
      "        mean_td_error: -5099985408.0\n",
      "        td_error: \"[-2.57396572e+10 -2.90140979e+09 -3.07573555e+09  1.83437885e+10\\n\\\n",
      "          \\ -1.02314803e+10 -1.30976973e+10 -1.29761280e+09 -1.31368878e+10\\n -1.63845243e+10\\\n",
      "          \\ -2.94997197e+10 -2.78033859e+10  1.83437885e+10\\n -2.57396572e+10 -3.07573555e+09\\\n",
      "          \\ -2.57396572e+10 -2.90140979e+09\\n -2.19650458e+10 -4.74267648e+09 -2.64096973e+10\\\n",
      "          \\ -2.97744466e+10\\n -2.94997197e+10  7.07694428e+10 -8.22371942e+09 -3.07573555e+09\\n\\\n",
      "          \\ -5.23836948e+10  1.83437885e+10  1.04609415e+11 -2.90140979e+09\\n  2.28995891e+10\\\n",
      "          \\ -2.73872978e+10 -1.29761280e+09 -8.22371942e+09]\"\n",
      "    num_agent_steps_sampled: 292000\n",
      "    num_agent_steps_trained: 2328032\n",
      "    num_steps_sampled: 292000\n",
      "    num_steps_trained: 2328032\n",
      "    num_target_updates: 578\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.227777777777774\n",
      "    ram_util_percent: 93.76111111111112\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03994858478321921\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.925992934286402\n",
      "    mean_inference_ms: 1.5617835810940872\n",
      "    mean_raw_obs_processing_ms: 2.023034226555043\n",
      "  time_since_restore: 4415.297462940216\n",
      "  time_this_iter_s: 12.793103218078613\n",
      "  time_total_s: 4415.297462940216\n",
      "  timers:\n",
      "    learn_throughput: 3514.538\n",
      "    learn_time_ms: 9.105\n",
      "    load_throughput: 53063.07\n",
      "    load_time_ms: 0.603\n",
      "    update_time_ms: 1.754\n",
      "  timestamp: 1632005847\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 292000\n",
      "  training_iteration: 292\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   292</td><td style=\"text-align: right;\">          4415.3</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">   -0.11</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 293000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-57-40\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.11\n",
      "  episode_reward_min: -5.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 299\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 292816\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3438160379904.0\n",
      "          mean_q: 1760592265216.0\n",
      "          min_q: 129754906624.0\n",
      "        mean_td_error: -34728683008.0\n",
      "        td_error: \"[-3.25496340e+10 -3.03296676e+10 -3.68875930e+10 -8.45608387e+10\\n\\\n",
      "          \\ -5.38163282e+10 -3.70709627e+10 -5.38163282e+10 -2.64210022e+09\\n -1.54114212e+10\\\n",
      "          \\ -4.50752020e+10 -5.18190531e+10 -5.18190531e+10\\n -7.65946757e+10  9.49747712e+09\\\n",
      "          \\ -7.33759406e+10  1.30580505e+11\\n -3.08947190e+10 -3.25496340e+10 -4.34642616e+10\\\n",
      "          \\ -2.64210022e+09\\n -5.38163282e+10 -7.33759406e+10 -1.14512364e+10 -5.38163282e+10\\n\\\n",
      "          \\ -3.55679601e+10  9.49747712e+09 -3.68018063e+10 -3.31467981e+10\\n -5.38163282e+10\\\n",
      "          \\ -4.50752020e+10 -3.69607311e+10 -7.17451428e+10]\"\n",
      "    num_agent_steps_sampled: 293000\n",
      "    num_agent_steps_trained: 2336032\n",
      "    num_steps_sampled: 293000\n",
      "    num_steps_trained: 2336032\n",
      "    num_target_updates: 580\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.53684210526316\n",
      "    ram_util_percent: 93.74736842105263\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03994965127950886\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.9212967240545105\n",
      "    mean_inference_ms: 1.5617584750285525\n",
      "    mean_raw_obs_processing_ms: 2.0172298298261753\n",
      "  time_since_restore: 4428.1349556446075\n",
      "  time_this_iter_s: 12.83749270439148\n",
      "  time_total_s: 4428.1349556446075\n",
      "  timers:\n",
      "    learn_throughput: 3500.112\n",
      "    learn_time_ms: 9.143\n",
      "    load_throughput: 49495.788\n",
      "    load_time_ms: 0.647\n",
      "    update_time_ms: 1.746\n",
      "  timestamp: 1632005860\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 293000\n",
      "  training_iteration: 293\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   293</td><td style=\"text-align: right;\">         4428.13</td><td style=\"text-align: right;\">293000</td><td style=\"text-align: right;\">   -0.11</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 294000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-57-53\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.11\n",
      "  episode_reward_min: -5.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 300\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 293824\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3611855683584.0\n",
      "          mean_q: 1786396278784.0\n",
      "          min_q: 156167733248.0\n",
      "        mean_td_error: 24417370112.0\n",
      "        td_error: \"[ 1.92097812e+10  1.90738596e+10 -7.54417664e+09  2.12735099e+10\\n\\\n",
      "          \\  1.51760404e+10 -1.59184323e+10  3.04202383e+10  2.89026867e+10\\n  2.79311811e+10\\\n",
      "          \\  2.62495273e+10  3.36401531e+10  1.92097812e+10\\n -1.59184323e+10 -1.36257208e+10\\\n",
      "          \\  1.56167733e+11  2.79311811e+10\\n  2.40200909e+09 -1.36257208e+10  2.62495273e+10\\\n",
      "          \\ -1.45004954e+10\\n  2.12735099e+10  1.56167733e+11  1.90738596e+10  2.79311811e+10\\n\\\n",
      "          \\  1.95861545e+10 -1.45004954e+10 -1.59184323e+10  1.56167733e+11\\n  1.90738596e+10\\\n",
      "          \\  1.65473812e+10  8.47118336e+08  2.40200909e+09]\"\n",
      "    num_agent_steps_sampled: 294000\n",
      "    num_agent_steps_trained: 2344032\n",
      "    num_steps_sampled: 294000\n",
      "    num_steps_trained: 2344032\n",
      "    num_target_updates: 582\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.71111111111111\n",
      "    ram_util_percent: 93.82222222222222\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03995076312610401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.91659526991039\n",
      "    mean_inference_ms: 1.5617341464727843\n",
      "    mean_raw_obs_processing_ms: 2.0114833370678378\n",
      "  time_since_restore: 4441.003236532211\n",
      "  time_this_iter_s: 12.86828088760376\n",
      "  time_total_s: 4441.003236532211\n",
      "  timers:\n",
      "    learn_throughput: 3569.393\n",
      "    learn_time_ms: 8.965\n",
      "    load_throughput: 62630.764\n",
      "    load_time_ms: 0.511\n",
      "    update_time_ms: 1.764\n",
      "  timestamp: 1632005873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 294000\n",
      "  training_iteration: 294\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   294</td><td style=\"text-align: right;\">            4441</td><td style=\"text-align: right;\">294000</td><td style=\"text-align: right;\">   -0.11</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 295000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-58-05\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.09\n",
      "  episode_reward_min: -5.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 301\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 294832\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3784581840896.0\n",
      "          mean_q: 1532952313856.0\n",
      "          min_q: 158321655808.0\n",
      "        mean_td_error: -23050627072.0\n",
      "        td_error: \"[-2.1421425e+10 -2.1425357e+10 -1.6954032e+10 -6.6686157e+08\\n -5.4372860e+10\\\n",
      "          \\ -4.8770417e+09 -2.1707358e+10  2.9568369e+10\\n -1.6954032e+10 -2.1668889e+10\\\n",
      "          \\ -1.5556674e+10 -3.5947282e+10\\n -2.6454000e+10 -1.8820547e+10 -3.5947282e+10\\\n",
      "          \\ -3.3684718e+10\\n -1.2793479e+10 -1.9406520e+10 -2.2330933e+10 -1.8820547e+10\\n\\\n",
      "          \\ -1.2793479e+10 -3.3684718e+10 -2.1707358e+10 -3.3684718e+10\\n -2.2899589e+10\\\n",
      "          \\ -3.3684718e+10 -1.7158111e+10 -3.2634307e+10\\n -2.1425357e+10 -2.4815600e+10\\\n",
      "          \\ -2.2899589e+10 -6.9991055e+10]\"\n",
      "    num_agent_steps_sampled: 295000\n",
      "    num_agent_steps_trained: 2352032\n",
      "    num_steps_sampled: 295000\n",
      "    num_steps_trained: 2352032\n",
      "    num_target_updates: 584\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.4\n",
      "    ram_util_percent: 93.93529411764706\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039951904165052586\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.9118651405695735\n",
      "    mean_inference_ms: 1.5617099539448676\n",
      "    mean_raw_obs_processing_ms: 2.0057938504812975\n",
      "  time_since_restore: 4452.951479434967\n",
      "  time_this_iter_s: 11.948242902755737\n",
      "  time_total_s: 4452.951479434967\n",
      "  timers:\n",
      "    learn_throughput: 3648.51\n",
      "    learn_time_ms: 8.771\n",
      "    load_throughput: 61680.941\n",
      "    load_time_ms: 0.519\n",
      "    update_time_ms: 1.741\n",
      "  timestamp: 1632005885\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 295000\n",
      "  training_iteration: 295\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   295</td><td style=\"text-align: right;\">         4452.95</td><td style=\"text-align: right;\">295000</td><td style=\"text-align: right;\">   -0.09</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 296000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-58-17\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.07\n",
      "  episode_reward_min: -5.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 302\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 295840\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3892822147072.0\n",
      "          mean_q: 1917747593216.0\n",
      "          min_q: 170408919040.0\n",
      "        mean_td_error: -11913349632.0\n",
      "        td_error: \"[-4.23068959e+10 -1.90727389e+11  6.58561434e+09 -4.00094659e+10\\n\\\n",
      "          \\ -4.00094659e+10  4.77868851e+09 -4.00094659e+10 -2.37145948e+10\\n -6.91509658e+10\\\n",
      "          \\ -5.31965542e+09  1.70870997e+11  4.41824051e+09\\n -2.37145948e+10 -4.23068959e+10\\\n",
      "          \\  9.62479391e+10 -4.00094659e+10\\n -3.13272566e+10 -2.90833039e+10 -2.71308554e+10\\\n",
      "          \\  9.62479391e+10\\n -2.97132360e+10 -8.95282381e+09 -1.39621827e+10 -4.00094659e+10\\n\\\n",
      "          \\ -4.00094659e+10 -3.69683333e+10 -2.37145948e+10 -2.90833039e+10\\n  1.06083123e+09\\\n",
      "          \\  1.70870997e+11  4.07620813e+09 -6.91509658e+10]\"\n",
      "    num_agent_steps_sampled: 296000\n",
      "    num_agent_steps_trained: 2360032\n",
      "    num_steps_sampled: 296000\n",
      "    num_steps_trained: 2360032\n",
      "    num_target_updates: 586\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.444444444444436\n",
      "    ram_util_percent: 94.08888888888887\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03995308932468413\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.907120297350069\n",
      "    mean_inference_ms: 1.5616860748919126\n",
      "    mean_raw_obs_processing_ms: 2.0001611492445934\n",
      "  time_since_restore: 4465.236870765686\n",
      "  time_this_iter_s: 12.285391330718994\n",
      "  time_total_s: 4465.236870765686\n",
      "  timers:\n",
      "    learn_throughput: 3600.29\n",
      "    learn_time_ms: 8.888\n",
      "    load_throughput: 56431.941\n",
      "    load_time_ms: 0.567\n",
      "    update_time_ms: 1.816\n",
      "  timestamp: 1632005897\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 296000\n",
      "  training_iteration: 296\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   296</td><td style=\"text-align: right;\">         4465.24</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">   -0.07</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 297000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-58-29\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 303\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 296848\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4188999778304.0\n",
      "          mean_q: 1311388205056.0\n",
      "          min_q: 173865369600.0\n",
      "        mean_td_error: 23712996352.0\n",
      "        td_error: \"[ 1.74067204e+11 -6.77578670e+10  4.72791777e+10  3.46659226e+09\\n\\\n",
      "          \\  9.26258299e+10 -4.10858291e+09  4.96163881e+10  5.28986931e+10\\n  2.91774136e+10\\\n",
      "          \\  3.64618711e+10  5.11903662e+10 -7.03830426e+09\\n  4.04899758e+10  7.73944115e+09\\\n",
      "          \\  3.64618711e+10  5.49621596e+10\\n  7.73944115e+09  3.64618711e+10  6.02417398e+10\\\n",
      "          \\  3.56054467e+10\\n  4.79657984e+10 -1.77001923e+10  4.72791777e+10  3.56054467e+10\\n\\\n",
      "          \\ -7.43464796e+10  5.09256663e+10 -7.43464796e+10  5.44201769e+10\\n -1.77001923e+10\\\n",
      "          \\  3.57789860e+10  7.69972634e+09 -7.43464796e+10]\"\n",
      "    num_agent_steps_sampled: 297000\n",
      "    num_agent_steps_trained: 2368032\n",
      "    num_steps_sampled: 297000\n",
      "    num_steps_trained: 2368032\n",
      "    num_target_updates: 588\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.73529411764706\n",
      "    ram_util_percent: 94.16470588235293\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03995426979408874\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.902316471605152\n",
      "    mean_inference_ms: 1.5616612026375254\n",
      "    mean_raw_obs_processing_ms: 1.9945838569351013\n",
      "  time_since_restore: 4477.032152414322\n",
      "  time_this_iter_s: 11.795281648635864\n",
      "  time_total_s: 4477.032152414322\n",
      "  timers:\n",
      "    learn_throughput: 3638.777\n",
      "    learn_time_ms: 8.794\n",
      "    load_throughput: 60619.542\n",
      "    load_time_ms: 0.528\n",
      "    update_time_ms: 1.75\n",
      "  timestamp: 1632005909\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 297000\n",
      "  training_iteration: 297\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   297</td><td style=\"text-align: right;\">         4477.03</td><td style=\"text-align: right;\">297000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 298000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-58-41\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 304\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 297856\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3433079242752.0\n",
      "          mean_q: 851537166336.0\n",
      "          min_q: 171815829504.0\n",
      "        mean_td_error: -9427300352.0\n",
      "        td_error: \"[-2.22822400e+10  6.65337856e+09 -2.01135882e+10 -2.49655460e+10\\n\\\n",
      "          \\ -2.01135882e+10 -3.79366605e+09 -2.21942907e+10 -4.42826097e+10\\n -2.99148247e+10\\\n",
      "          \\  1.80294222e+11  1.08708659e+10  1.93768161e+10\\n -4.42826097e+10 -1.17078360e+11\\\n",
      "          \\ -2.01135882e+10  9.45261773e+09\\n -2.60174643e+10  1.00237148e+10 -3.23152773e+10\\\n",
      "          \\ -5.80489052e+10\\n -3.09618278e+10  6.65337856e+09  1.32493967e+10  1.80294222e+11\\n\\\n",
      "          \\ -5.20670904e+10 -4.42826097e+10  1.93768161e+10  8.58583859e+09\\n -2.51643331e+10\\\n",
      "          \\ -4.42826097e+10 -3.99472394e+10 -4.42826097e+10]\"\n",
      "    num_agent_steps_sampled: 298000\n",
      "    num_agent_steps_trained: 2376032\n",
      "    num_steps_sampled: 298000\n",
      "    num_steps_trained: 2376032\n",
      "    num_target_updates: 590\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.976470588235294\n",
      "    ram_util_percent: 94.24705882352941\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03995545596149896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.8974623101735\n",
      "    mean_inference_ms: 1.5616362511317434\n",
      "    mean_raw_obs_processing_ms: 1.9890619822086304\n",
      "  time_since_restore: 4488.861454963684\n",
      "  time_this_iter_s: 11.829302549362183\n",
      "  time_total_s: 4488.861454963684\n",
      "  timers:\n",
      "    learn_throughput: 3604.641\n",
      "    learn_time_ms: 8.877\n",
      "    load_throughput: 62621.998\n",
      "    load_time_ms: 0.511\n",
      "    update_time_ms: 1.878\n",
      "  timestamp: 1632005921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 298000\n",
      "  training_iteration: 298\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   298</td><td style=\"text-align: right;\">         4488.86</td><td style=\"text-align: right;\">298000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 299000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-58-53\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 305\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 298864\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3553919238144.0\n",
      "          mean_q: 952310890496.0\n",
      "          min_q: 180322729984.0\n",
      "        mean_td_error: -45461878272.0\n",
      "        td_error: \"[ 7.42911181e+09  6.98231194e+10 -8.26367672e+10 -2.18674463e+10\\n\\\n",
      "          \\  7.42911181e+09  8.46582579e+09 -9.31460547e+10 -8.26367672e+10\\n -8.66047754e+10\\\n",
      "          \\ -1.47822871e+11 -6.47110328e+10  6.98231194e+10\\n  4.60593562e+09 -3.25808947e+09\\\n",
      "          \\ -8.42746429e+10 -4.28483199e+11\\n  1.00022518e+10 -8.61903258e+10 -6.47110328e+10\\\n",
      "          \\ -7.85581343e+10\\n  6.98231194e+10  1.01006868e+10  1.81434974e+11 -4.28483199e+11\\n\\\n",
      "          \\ -1.61133363e+10 -3.73978563e+10 -5.95916227e+10  1.81434974e+11\\n -9.16743782e+10\\\n",
      "          \\  1.01025055e+10 -4.73953731e+10 -7.96979364e+10]\"\n",
      "    num_agent_steps_sampled: 299000\n",
      "    num_agent_steps_trained: 2384032\n",
      "    num_steps_sampled: 299000\n",
      "    num_steps_trained: 2384032\n",
      "    num_target_updates: 592\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.32941176470588\n",
      "    ram_util_percent: 94.28823529411765\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039956639786117056\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.89256710429984\n",
      "    mean_inference_ms: 1.561611042688524\n",
      "    mean_raw_obs_processing_ms: 1.9835952217763355\n",
      "  time_since_restore: 4501.099750041962\n",
      "  time_this_iter_s: 12.238295078277588\n",
      "  time_total_s: 4501.099750041962\n",
      "  timers:\n",
      "    learn_throughput: 3590.053\n",
      "    learn_time_ms: 8.914\n",
      "    load_throughput: 61390.353\n",
      "    load_time_ms: 0.521\n",
      "    update_time_ms: 1.741\n",
      "  timestamp: 1632005933\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299000\n",
      "  training_iteration: 299\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   299</td><td style=\"text-align: right;\">          4501.1</td><td style=\"text-align: right;\">299000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-59-05\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 306\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 299872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4443085471744.0\n",
      "          mean_q: 1167347286016.0\n",
      "          min_q: 172345163776.0\n",
      "        mean_td_error: 18928576512.0\n",
      "        td_error: \"[ 1.67891960e+11  3.00535644e+10 -7.02637179e+10  3.06690130e+10\\n\\\n",
      "          \\  3.31860541e+10  3.00535644e+10  9.68389427e+09 -7.02637179e+10\\n  3.84197591e+10\\\n",
      "          \\  1.23839529e+11  3.16538880e+10  1.21793757e+11\\n  5.15309568e+10  3.16538880e+10\\\n",
      "          \\  3.85852867e+10  1.67891960e+11\\n -4.08424940e+11  5.15309568e+10  9.68389427e+09\\\n",
      "          \\ -7.55756237e+10\\n  1.86605158e+11  4.28776489e+10 -1.53044910e+10  1.67891960e+11\\n\\\n",
      "          \\  3.84197591e+10  9.21501696e+08  3.00535644e+10  1.86605158e+11\\n  1.40870943e+10\\\n",
      "          \\  9.68389427e+09  8.70421299e+09 -4.08424940e+11]\"\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_agent_steps_trained: 2392032\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 2392032\n",
      "    num_target_updates: 594\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.805882352941175\n",
      "    ram_util_percent: 94.30000000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039957844881793464\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.887698464008261\n",
      "    mean_inference_ms: 1.5615866078160243\n",
      "    mean_raw_obs_processing_ms: 1.978182169012269\n",
      "  time_since_restore: 4513.2916605472565\n",
      "  time_this_iter_s: 12.1919105052948\n",
      "  time_total_s: 4513.2916605472565\n",
      "  timers:\n",
      "    learn_throughput: 3641.126\n",
      "    learn_time_ms: 8.788\n",
      "    load_throughput: 64736.279\n",
      "    load_time_ms: 0.494\n",
      "    update_time_ms: 1.717\n",
      "  timestamp: 1632005945\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 300\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   300</td><td style=\"text-align: right;\">         4513.29</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 301000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-59-18\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 307\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 300880\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3685372133376.0\n",
      "          mean_q: 1075719241728.0\n",
      "          min_q: 174552940544.0\n",
      "        mean_td_error: 223953619456.0\n",
      "        td_error: \"[-3.66550057e+10  1.74552941e+11 -4.09849037e+10 -8.30229709e+09\\n\\\n",
      "          \\  1.20829741e+12  1.20829741e+12 -3.66550057e+10 -4.09978798e+10\\n -3.36666296e+10\\\n",
      "          \\  7.18479360e+09 -4.09849037e+10 -3.84564593e+10\\n -3.87072983e+10 -4.09978798e+10\\\n",
      "          \\ -1.01298471e+11 -4.09978798e+10\\n  1.20829741e+12  1.20829741e+12  1.20829741e+12\\\n",
      "          \\ -1.16854784e+10\\n -3.36666296e+10  1.20829741e+12 -3.66550057e+10 -1.11197028e+11\\n\\\n",
      "          \\  1.20829741e+12 -1.79860111e+10 -6.22212940e+11 -3.40184924e+10\\n  7.18479360e+09\\\n",
      "          \\ -4.09849037e+10 -3.66887240e+10 -3.66887240e+10]\"\n",
      "    num_agent_steps_sampled: 301000\n",
      "    num_agent_steps_trained: 2400032\n",
      "    num_steps_sampled: 301000\n",
      "    num_steps_trained: 2400032\n",
      "    num_target_updates: 596\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.97777777777778\n",
      "    ram_util_percent: 94.30555555555556\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03995906275707255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.882885221061011\n",
      "    mean_inference_ms: 1.5615628234383307\n",
      "    mean_raw_obs_processing_ms: 1.9728224922616115\n",
      "  time_since_restore: 4525.384085893631\n",
      "  time_this_iter_s: 12.092425346374512\n",
      "  time_total_s: 4525.384085893631\n",
      "  timers:\n",
      "    learn_throughput: 3650.048\n",
      "    learn_time_ms: 8.767\n",
      "    load_throughput: 62965.72\n",
      "    load_time_ms: 0.508\n",
      "    update_time_ms: 1.734\n",
      "  timestamp: 1632005958\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 301000\n",
      "  training_iteration: 301\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   301</td><td style=\"text-align: right;\">         4525.38</td><td style=\"text-align: right;\">301000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 302000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-59-31\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 308\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 301888\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5075949846528.0\n",
      "          mean_q: 737508720640.0\n",
      "          min_q: 205348274176.0\n",
      "        mean_td_error: -44593099776.0\n",
      "        td_error: \"[-6.55050408e+11 -1.16111933e+10  2.07501033e+11 -3.14338509e+09\\n\\\n",
      "          \\ -5.89185024e+10 -4.61727662e+10 -1.36880128e+09 -2.08733798e+09\\n -5.06783334e+09\\\n",
      "          \\ -4.71719936e+10 -9.44635904e+08 -2.44598374e+09\\n -4.71719936e+10 -6.71044076e+10\\\n",
      "          \\  2.07501033e+11  6.73395245e+11\\n -1.27932662e+10  1.40012421e+10 -2.44598374e+09\\\n",
      "          \\  6.73395245e+11\\n -4.03168297e+10 -1.26286889e+10 -5.16528538e+10  1.40012421e+10\\n\\\n",
      "          \\ -6.55050408e+11 -5.89185024e+10 -6.55050408e+11 -1.23506524e+10\\n -6.55050408e+11\\\n",
      "          \\ -5.48417700e+10 -3.28949760e+09 -5.41257236e+10]\"\n",
      "    num_agent_steps_sampled: 302000\n",
      "    num_agent_steps_trained: 2408032\n",
      "    num_steps_sampled: 302000\n",
      "    num_steps_trained: 2408032\n",
      "    num_target_updates: 598\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.84\n",
      "    ram_util_percent: 94.16000000000003\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03996030875266297\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.878150791273589\n",
      "    mean_inference_ms: 1.5615405537591422\n",
      "    mean_raw_obs_processing_ms: 1.9675155646976237\n",
      "  time_since_restore: 4539.242690563202\n",
      "  time_this_iter_s: 13.858604669570923\n",
      "  time_total_s: 4539.242690563202\n",
      "  timers:\n",
      "    learn_throughput: 3607.509\n",
      "    learn_time_ms: 8.87\n",
      "    load_throughput: 59859.838\n",
      "    load_time_ms: 0.535\n",
      "    update_time_ms: 1.765\n",
      "  timestamp: 1632005971\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 302000\n",
      "  training_iteration: 302\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   302</td><td style=\"text-align: right;\">         4539.24</td><td style=\"text-align: right;\">302000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 303000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-59-44\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 309\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 302896\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3585211891712.0\n",
      "          mean_q: 712300560384.0\n",
      "          min_q: 229988106240.0\n",
      "        mean_td_error: 50860693504.0\n",
      "        td_error: \"[ 2.45186396e+11 -2.23952896e+08 -9.39327488e+08  9.00901765e+10\\n\\\n",
      "          \\  1.60572867e+10 -6.35456717e+09  7.88701184e+09  2.45186396e+11\\n -4.13719069e+11\\\n",
      "          \\ -4.13719069e+11 -6.21551288e+10  8.97463091e+10\\n  3.17685268e+10  1.60572867e+10\\\n",
      "          \\  1.33932483e+10  8.11718410e+10\\n -2.23952896e+08  9.37302426e+10  8.94533632e+09\\\n",
      "          \\  9.37302426e+10\\n  8.91798159e+10 -2.23952896e+08  9.27397904e+11  1.33932483e+10\\n\\\n",
      "          \\  7.88701184e+09  8.93409034e+10 -4.13719069e+11  8.11718410e+10\\n  9.37302426e+10\\\n",
      "          \\ -4.13719069e+11  9.27397904e+11  9.00901765e+10]\"\n",
      "    num_agent_steps_sampled: 303000\n",
      "    num_agent_steps_trained: 2416032\n",
      "    num_steps_sampled: 303000\n",
      "    num_steps_trained: 2416032\n",
      "    num_target_updates: 600\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.150000000000006\n",
      "    ram_util_percent: 94.17777777777779\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03996155080178896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.873512705149292\n",
      "    mean_inference_ms: 1.5615190197018134\n",
      "    mean_raw_obs_processing_ms: 1.9622606367583444\n",
      "  time_since_restore: 4551.904276847839\n",
      "  time_this_iter_s: 12.661586284637451\n",
      "  time_total_s: 4551.904276847839\n",
      "  timers:\n",
      "    learn_throughput: 3618.021\n",
      "    learn_time_ms: 8.845\n",
      "    load_throughput: 62838.957\n",
      "    load_time_ms: 0.509\n",
      "    update_time_ms: 1.734\n",
      "  timestamp: 1632005984\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 303000\n",
      "  training_iteration: 303\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   303</td><td style=\"text-align: right;\">          4551.9</td><td style=\"text-align: right;\">303000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 304000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_22-59-57\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 310\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 303904\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4224321323008.0\n",
      "          mean_q: 672574668800.0\n",
      "          min_q: 251474558976.0\n",
      "        mean_td_error: 21037775872.0\n",
      "        td_error: \"[-3.20716800e+09 -2.92315988e+11  8.19838976e+09 -2.92315988e+11\\n\\\n",
      "          \\ -3.09028454e+10  2.65807233e+11 -6.46489702e+09 -2.92717199e+10\\n  8.15561114e+09\\\n",
      "          \\ -2.92315988e+11 -2.32707850e+10 -2.32707850e+10\\n  2.65807233e+11  2.65807233e+11\\\n",
      "          \\  1.01655839e+10  1.01655839e+10\\n -9.91281807e+10 -1.67857357e+09 -2.92315988e+11\\\n",
      "          \\  3.84725418e+11\\n -3.09028454e+10  3.84725418e+11 -3.33879706e+09 -3.09028454e+10\\n\\\n",
      "          \\  8.19838976e+09 -1.39575624e+10  2.65807233e+11  8.19838976e+09\\n  2.65807233e+11\\\n",
      "          \\ -2.92717199e+10  8.27416576e+09  8.19838976e+09]\"\n",
      "    num_agent_steps_sampled: 304000\n",
      "    num_agent_steps_trained: 2424032\n",
      "    num_steps_sampled: 304000\n",
      "    num_steps_trained: 2424032\n",
      "    num_target_updates: 602\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.46666666666667\n",
      "    ram_util_percent: 94.1888888888889\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039962785027797564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.868967950907725\n",
      "    mean_inference_ms: 1.561497849439168\n",
      "    mean_raw_obs_processing_ms: 1.9570566702157899\n",
      "  time_since_restore: 4564.440171957016\n",
      "  time_this_iter_s: 12.535895109176636\n",
      "  time_total_s: 4564.440171957016\n",
      "  timers:\n",
      "    learn_throughput: 3624.019\n",
      "    learn_time_ms: 8.83\n",
      "    load_throughput: 48108.437\n",
      "    load_time_ms: 0.665\n",
      "    update_time_ms: 1.717\n",
      "  timestamp: 1632005997\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 304000\n",
      "  training_iteration: 304\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   304</td><td style=\"text-align: right;\">         4564.44</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 305000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-00-09\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 311\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 304912\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 732938633216.0\n",
      "          mean_q: 483838525440.0\n",
      "          min_q: 270468153344.0\n",
      "        mean_td_error: -407221749760.0\n",
      "        td_error: \"[ 1.26173184e+08  2.70608220e+11  1.11519334e+09 -3.79348582e+09\\n\\\n",
      "          \\ -1.34276710e+09 -1.71566681e+12 -1.71566681e+12  1.39846287e+10\\n -3.79348582e+09\\\n",
      "          \\ -7.67819776e+08 -3.79348582e+09 -3.79348582e+09\\n -3.62423910e+09 -1.71566681e+12\\\n",
      "          \\  2.07591014e+10 -1.71566681e+12\\n -1.71566681e+12 -2.27247391e+10 -1.71566681e+12\\\n",
      "          \\ -2.17396675e+10\\n -5.51960576e+09 -2.17396675e+10  1.36473805e+09  2.70608220e+11\\n\\\n",
      "          \\  1.11519334e+09 -2.17396675e+10 -2.27247391e+10 -1.71566681e+12\\n  3.77041715e+09\\\n",
      "          \\ -2.27247391e+10 -1.71566681e+12  2.70608220e+11]\"\n",
      "    num_agent_steps_sampled: 305000\n",
      "    num_agent_steps_trained: 2432032\n",
      "    num_steps_sampled: 305000\n",
      "    num_steps_trained: 2432032\n",
      "    num_target_updates: 604\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.92777777777778\n",
      "    ram_util_percent: 94.12777777777777\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039964039011084675\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.864519210982824\n",
      "    mean_inference_ms: 1.5614779520748194\n",
      "    mean_raw_obs_processing_ms: 1.9519034086135798\n",
      "  time_since_restore: 4576.99765086174\n",
      "  time_this_iter_s: 12.557478904724121\n",
      "  time_total_s: 4576.99765086174\n",
      "  timers:\n",
      "    learn_throughput: 3625.497\n",
      "    learn_time_ms: 8.826\n",
      "    load_throughput: 65338.199\n",
      "    load_time_ms: 0.49\n",
      "    update_time_ms: 1.763\n",
      "  timestamp: 1632006009\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 305000\n",
      "  training_iteration: 305\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   305</td><td style=\"text-align: right;\">            4577</td><td style=\"text-align: right;\">305000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 306000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-00-22\n",
      "  done: false\n",
      "  episode_len_mean: 995.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 312\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 305920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 974521106432.0\n",
      "          mean_q: 440214257664.0\n",
      "          min_q: 305121099776.0\n",
      "        mean_td_error: 10797324288.0\n",
      "        td_error: \"[-7.37093222e+09 -7.73639373e+09 -7.11530906e+09 -7.37093222e+09\\n\\\n",
      "          \\ -5.36641536e+08 -2.59285647e+10 -7.11530906e+09 -3.40036813e+10\\n  5.97432730e+09\\\n",
      "          \\  1.71442176e+08 -5.36641536e+08  5.97432730e+09\\n -7.11530906e+09 -3.17662167e+10\\\n",
      "          \\ -3.16833792e+10 -7.52232038e+09\\n  2.37911736e+10 -3.17428859e+10  3.06924978e+11\\\n",
      "          \\  3.06924978e+11\\n -7.37093222e+09 -7.11530906e+09 -1.24505293e+09 -7.37093222e+09\\n\\\n",
      "          \\ -3.43950623e+10 -7.11530906e+09  1.44676291e+10  3.00285952e+08\\n -7.11530906e+09\\\n",
      "          \\ -5.36641536e+08 -7.52232038e+09 -3.16833792e+10]\"\n",
      "    num_agent_steps_sampled: 306000\n",
      "    num_agent_steps_trained: 2440032\n",
      "    num_steps_sampled: 306000\n",
      "    num_steps_trained: 2440032\n",
      "    num_target_updates: 606\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.699999999999996\n",
      "    ram_util_percent: 94.04444444444445\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03996535701608455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.8601724063077185\n",
      "    mean_inference_ms: 1.5614600219729124\n",
      "    mean_raw_obs_processing_ms: 1.9468003683592077\n",
      "  time_since_restore: 4589.792732477188\n",
      "  time_this_iter_s: 12.795081615447998\n",
      "  time_total_s: 4589.792732477188\n",
      "  timers:\n",
      "    learn_throughput: 3160.734\n",
      "    learn_time_ms: 10.124\n",
      "    load_throughput: 56727.696\n",
      "    load_time_ms: 0.564\n",
      "    update_time_ms: 1.76\n",
      "  timestamp: 1632006022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 306000\n",
      "  training_iteration: 306\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   306</td><td style=\"text-align: right;\">         4589.79</td><td style=\"text-align: right;\">306000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 307000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-00-52\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 313\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 306928\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 979151880192.0\n",
      "          mean_q: 389181997056.0\n",
      "          min_q: 274085445632.0\n",
      "        mean_td_error: -219581339648.0\n",
      "        td_error: \"[-1.17683244e+12 -7.23378176e+10  6.19816550e+09 -1.17683244e+12\\n\\\n",
      "          \\  3.21469743e+11 -3.80115354e+09 -1.17683244e+12  3.21469743e+11\\n -4.16736870e+09\\\n",
      "          \\  8.50408243e+09  3.21469743e+11  8.48370074e+09\\n -4.16736870e+09 -7.45472000e+07\\\n",
      "          \\ -1.17683244e+12 -1.17683244e+12\\n -4.89455616e+09 -2.70362214e+09 -3.80115354e+09\\\n",
      "          \\ -3.80115354e+09\\n -1.17683244e+12  8.48370074e+09  8.48370074e+09 -4.89455616e+09\\n\\\n",
      "          \\ -4.16736870e+09 -1.17683244e+12 -4.16736870e+09  8.48370074e+09\\n -2.34376397e+09\\\n",
      "          \\ -3.80115354e+09 -4.16884326e+09  3.21469743e+11]\"\n",
      "    num_agent_steps_sampled: 307000\n",
      "    num_agent_steps_trained: 2448032\n",
      "    num_steps_sampled: 307000\n",
      "    num_steps_trained: 2448032\n",
      "    num_target_updates: 608\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.02325581395349\n",
      "    ram_util_percent: 93.5860465116279\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03996670382208853\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.855948849779691\n",
      "    mean_inference_ms: 1.5614447062089558\n",
      "    mean_raw_obs_processing_ms: 1.9422951720744548\n",
      "  time_since_restore: 4620.09937953949\n",
      "  time_this_iter_s: 30.306647062301636\n",
      "  time_total_s: 4620.09937953949\n",
      "  timers:\n",
      "    learn_throughput: 3574.231\n",
      "    learn_time_ms: 8.953\n",
      "    load_throughput: 52228.861\n",
      "    load_time_ms: 0.613\n",
      "    update_time_ms: 1.828\n",
      "  timestamp: 1632006052\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 307000\n",
      "  training_iteration: 307\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   307</td><td style=\"text-align: right;\">          4620.1</td><td style=\"text-align: right;\">307000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 308000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-01-08\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 314\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 307936\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2725644337152.0\n",
      "          mean_q: 578755756032.0\n",
      "          min_q: 270675705856.0\n",
      "        mean_td_error: -106153482240.0\n",
      "        td_error: \"[ 2.45812429e+09  1.47386532e+10 -1.09513671e+11 -5.20588493e+10\\n\\\n",
      "          \\  1.58806835e+10 -1.07151950e+11  1.47386532e+10 -1.17996257e+10\\n  1.47386532e+10\\\n",
      "          \\  2.45812429e+09  3.44229052e+11 -1.03343292e+11\\n  1.58806835e+10 -5.28392520e+10\\\n",
      "          \\  2.45812429e+09  3.44229052e+11\\n -1.07151950e+11 -1.07972854e+11 -5.20588493e+10\\\n",
      "          \\ -5.95729121e+10\\n -6.41643971e+10 -9.51114727e+11 -9.51114727e+11 -1.07972854e+11\\n\\\n",
      "          \\ -6.42617508e+10 -6.46139740e+10 -1.09513671e+11 -1.06602758e+11\\n -9.51114727e+11\\\n",
      "          \\ -6.42617508e+10  1.47386532e+10  1.47386532e+10]\"\n",
      "    num_agent_steps_sampled: 308000\n",
      "    num_agent_steps_trained: 2456032\n",
      "    num_steps_sampled: 308000\n",
      "    num_steps_trained: 2456032\n",
      "    num_target_updates: 610\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.57727272727273\n",
      "    ram_util_percent: 93.99999999999999\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03996803570520162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.851875806344006\n",
      "    mean_inference_ms: 1.561428947828189\n",
      "    mean_raw_obs_processing_ms: 1.937836541822703\n",
      "  time_since_restore: 4635.367968320847\n",
      "  time_this_iter_s: 15.268588781356812\n",
      "  time_total_s: 4635.367968320847\n",
      "  timers:\n",
      "    learn_throughput: 3644.596\n",
      "    learn_time_ms: 8.78\n",
      "    load_throughput: 59309.646\n",
      "    load_time_ms: 0.54\n",
      "    update_time_ms: 1.79\n",
      "  timestamp: 1632006068\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 308000\n",
      "  training_iteration: 308\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   308</td><td style=\"text-align: right;\">         4635.37</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 309000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-01-21\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 315\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 308944\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 2175221104640.0\n",
      "          mean_q: 975790145536.0\n",
      "          min_q: 311248289792.0\n",
      "        mean_td_error: 88533835776.0\n",
      "        td_error: \"[-3.38234573e+09  1.97503877e+10 -7.46656236e+10  5.24933267e+11\\n\\\n",
      "          \\  3.56483072e+09  5.24933267e+11  2.06042563e+10  5.24933267e+11\\n -1.27184195e+12\\\n",
      "          \\  1.97503877e+10  9.76096461e+09  3.61137046e+11\\n  5.24933267e+11  5.24933267e+11\\\n",
      "          \\  7.03237325e+09 -3.38234573e+09\\n  5.24933267e+11  9.27268864e+08  5.24933267e+11\\\n",
      "          \\  3.61137046e+11\\n -1.27184195e+12 -8.18334925e+09  1.97503877e+10 -4.68156416e+08\\n\\\n",
      "          \\  1.89566157e+09  3.61137046e+11  9.76096461e+09  5.24933267e+11\\n  2.04042404e+10\\\n",
      "          \\  2.06042563e+10  9.76096461e+09  2.04042404e+10]\"\n",
      "    num_agent_steps_sampled: 309000\n",
      "    num_agent_steps_trained: 2464032\n",
      "    num_steps_sampled: 309000\n",
      "    num_steps_trained: 2464032\n",
      "    num_target_updates: 612\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.0\n",
      "    ram_util_percent: 93.83684210526314\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039969252829539774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.8478751921607355\n",
      "    mean_inference_ms: 1.5614105014786563\n",
      "    mean_raw_obs_processing_ms: 1.9334241562261574\n",
      "  time_since_restore: 4648.492352962494\n",
      "  time_this_iter_s: 13.124384641647339\n",
      "  time_total_s: 4648.492352962494\n",
      "  timers:\n",
      "    learn_throughput: 3645.814\n",
      "    learn_time_ms: 8.777\n",
      "    load_throughput: 61709.3\n",
      "    load_time_ms: 0.519\n",
      "    update_time_ms: 1.722\n",
      "  timestamp: 1632006081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309000\n",
      "  training_iteration: 309\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   309</td><td style=\"text-align: right;\">         4648.49</td><td style=\"text-align: right;\">309000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 310000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-01-33\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 316\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 309952\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3229355868160.0\n",
      "          mean_q: 654939389952.0\n",
      "          min_q: 356082450432.0\n",
      "        mean_td_error: -1286399558656.0\n",
      "        td_error: \"[-3.62791895e+10 -3.14254950e+09 -2.85560688e+12  3.60593031e+11\\n\\\n",
      "          \\ -2.48778319e+12 -2.85560688e+12 -9.13551524e+10 -2.48778319e+12\\n  3.60593031e+11\\\n",
      "          \\ -9.13551524e+10 -2.48778319e+12  3.60593031e+11\\n -2.85560688e+12 -9.49749678e+10\\\n",
      "          \\ -2.94472909e+09 -2.48778319e+12\\n -2.48778319e+12 -9.40494029e+09 -9.13551524e+10\\\n",
      "          \\ -2.48778319e+12\\n -2.48778319e+12 -2.85560688e+12 -2.48778319e+12 -3.47498086e+09\\n\\\n",
      "          \\ -2.85560688e+12 -1.50046769e+11 -4.51723264e+09 -8.26261504e+09\\n -2.48778319e+12\\\n",
      "          \\ -2.48778319e+12 -1.58020076e+10 -2.48778319e+12]\"\n",
      "    num_agent_steps_sampled: 310000\n",
      "    num_agent_steps_trained: 2472032\n",
      "    num_steps_sampled: 310000\n",
      "    num_steps_trained: 2472032\n",
      "    num_target_updates: 614\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.211764705882345\n",
      "    ram_util_percent: 93.58235294117647\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03997040772110218\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.843951329526963\n",
      "    mean_inference_ms: 1.5613906828112423\n",
      "    mean_raw_obs_processing_ms: 1.9290573216713525\n",
      "  time_since_restore: 4660.901828289032\n",
      "  time_this_iter_s: 12.409475326538086\n",
      "  time_total_s: 4660.901828289032\n",
      "  timers:\n",
      "    learn_throughput: 3619.182\n",
      "    learn_time_ms: 8.842\n",
      "    load_throughput: 62389.127\n",
      "    load_time_ms: 0.513\n",
      "    update_time_ms: 1.811\n",
      "  timestamp: 1632006093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 310000\n",
      "  training_iteration: 310\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   310</td><td style=\"text-align: right;\">          4660.9</td><td style=\"text-align: right;\">310000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 311000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-01-46\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 317\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 310960\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 1214269358080.0\n",
      "          mean_q: 583312211968.0\n",
      "          min_q: 385932361728.0\n",
      "        mean_td_error: 58431821824.0\n",
      "        td_error: \"[ 2.11531203e+10  5.17066588e+10 -3.18968627e+10  1.96007035e+10\\n\\\n",
      "          \\ -3.11915643e+10  8.17265770e+11  8.17265770e+11  1.23917763e+10\\n  1.50214410e+10\\\n",
      "          \\ -3.27856947e+10 -1.06959353e+12  3.86171437e+11\\n -2.80782111e+10 -3.18968627e+10\\\n",
      "          \\  5.36285020e+10  2.01770271e+10\\n  3.86171437e+11 -3.27856947e+10 -3.27856947e+10\\\n",
      "          \\  8.17265770e+11\\n  2.15329014e+10 -3.23907092e+10 -3.11915643e+10 -3.93852682e+10\\n\\\n",
      "          \\ -3.27856947e+10 -3.27856947e+10 -3.27856947e+10 -3.27856947e+10\\n  5.36285020e+10\\\n",
      "          \\ -3.42443622e+10 -3.18968627e+10 -3.18968627e+10]\"\n",
      "    num_agent_steps_sampled: 311000\n",
      "    num_agent_steps_trained: 2480032\n",
      "    num_steps_sampled: 311000\n",
      "    num_steps_trained: 2480032\n",
      "    num_target_updates: 616\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.0421052631579\n",
      "    ram_util_percent: 93.54210526315788\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03997150782365421\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.84011892364688\n",
      "    mean_inference_ms: 1.5613706571504447\n",
      "    mean_raw_obs_processing_ms: 1.9247355678532774\n",
      "  time_since_restore: 4673.682082653046\n",
      "  time_this_iter_s: 12.780254364013672\n",
      "  time_total_s: 4673.682082653046\n",
      "  timers:\n",
      "    learn_throughput: 3555.276\n",
      "    learn_time_ms: 9.001\n",
      "    load_throughput: 59822.485\n",
      "    load_time_ms: 0.535\n",
      "    update_time_ms: 1.762\n",
      "  timestamp: 1632006106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 311000\n",
      "  training_iteration: 311\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   311</td><td style=\"text-align: right;\">         4673.68</td><td style=\"text-align: right;\">311000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 312000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-01-59\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 318\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 311968\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 7422651400192.0\n",
      "          mean_q: 1460042727424.0\n",
      "          min_q: 424975859712.0\n",
      "        mean_td_error: 399949083648.0\n",
      "        td_error: \"[ 1.69021407e+11 -2.11919110e+11 -2.11919110e+11  1.35061012e+11\\n\\\n",
      "          \\  1.34280810e+12  1.35045480e+11  1.69021407e+11 -1.29345913e+11\\n  1.35061012e+11\\\n",
      "          \\  1.69021407e+11  1.29897562e+11  5.49481120e+11\\n  8.47320842e+11  5.49481120e+11\\\n",
      "          \\  1.15362444e+12  7.79292180e+10\\n  1.21886278e+11  5.24059279e+11  1.34280810e+12\\\n",
      "          \\ -2.16305762e+11\\n -1.22397196e+11 -2.11919110e+11 -2.16305762e+11 -1.29345913e+11\\n\\\n",
      "          \\  1.34280810e+12  1.15362444e+12  5.49481120e+11  1.34280810e+12\\n  1.15362444e+12\\\n",
      "          \\  1.34280810e+12 -6.80386888e+10 -1.20814830e+11]\"\n",
      "    num_agent_steps_sampled: 312000\n",
      "    num_agent_steps_trained: 2488032\n",
      "    num_steps_sampled: 312000\n",
      "    num_steps_trained: 2488032\n",
      "    num_target_updates: 618\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.83888888888888\n",
      "    ram_util_percent: 93.1611111111111\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039972482867828465\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.836358147412681\n",
      "    mean_inference_ms: 1.561348620788818\n",
      "    mean_raw_obs_processing_ms: 1.920457925655357\n",
      "  time_since_restore: 4686.699928045273\n",
      "  time_this_iter_s: 13.017845392227173\n",
      "  time_total_s: 4686.699928045273\n",
      "  timers:\n",
      "    learn_throughput: 3668.835\n",
      "    learn_time_ms: 8.722\n",
      "    load_throughput: 61339.851\n",
      "    load_time_ms: 0.522\n",
      "    update_time_ms: 1.719\n",
      "  timestamp: 1632006119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 312000\n",
      "  training_iteration: 312\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   312</td><td style=\"text-align: right;\">          4686.7</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 313000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-02-12\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 319\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 312976\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5910152871936.0\n",
      "          mean_q: 914123915264.0\n",
      "          min_q: 438848618496.0\n",
      "        mean_td_error: 147052525568.0\n",
      "        td_error: \"[-7.21715200e+09  1.01199620e+12 -3.80180890e+10 -7.55208684e+10\\n\\\n",
      "          \\ -7.44283832e+10 -6.98564608e+10 -7.21715200e+09 -4.38173041e+10\\n -4.64679731e+10\\\n",
      "          \\  9.24373549e+11  9.24373549e+11 -7.66086578e+11\\n -6.22844314e+09  4.44844147e+11\\\n",
      "          \\ -3.88349297e+10 -7.51886664e+10\\n -1.89174252e+10  9.24373549e+11 -7.21715200e+09\\\n",
      "          \\  3.28023933e+11\\n  9.24373549e+11 -7.51886664e+10  9.24373549e+11 -3.41416018e+10\\n\\\n",
      "          \\ -7.66086578e+11 -1.66675415e+10 -3.80180890e+10  9.24373549e+11\\n  4.44844147e+11\\\n",
      "          \\ -6.22844314e+09 -9.28348242e+10 -7.66086578e+11]\"\n",
      "    num_agent_steps_sampled: 313000\n",
      "    num_agent_steps_trained: 2496032\n",
      "    num_steps_sampled: 313000\n",
      "    num_steps_trained: 2496032\n",
      "    num_target_updates: 620\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.82631578947369\n",
      "    ram_util_percent: 92.84736842105264\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03997342215186569\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.832655465823405\n",
      "    mean_inference_ms: 1.5613255782786544\n",
      "    mean_raw_obs_processing_ms: 1.916224122232271\n",
      "  time_since_restore: 4699.877544403076\n",
      "  time_this_iter_s: 13.177616357803345\n",
      "  time_total_s: 4699.877544403076\n",
      "  timers:\n",
      "    learn_throughput: 3642.381\n",
      "    learn_time_ms: 8.785\n",
      "    load_throughput: 65389.13\n",
      "    load_time_ms: 0.489\n",
      "    update_time_ms: 1.73\n",
      "  timestamp: 1632006132\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 313000\n",
      "  training_iteration: 313\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   313</td><td style=\"text-align: right;\">         4699.88</td><td style=\"text-align: right;\">313000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 314000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-02-26\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 320\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 313984\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 4160693469184.0\n",
      "          mean_q: 954292633600.0\n",
      "          min_q: 461874167808.0\n",
      "        mean_td_error: 298596568064.0\n",
      "        td_error: \"[-6.72101827e+10 -6.68379382e+10 -2.29916541e+11 -1.05752723e+11\\n\\\n",
      "          \\  1.14480218e+12 -5.90612398e+10 -8.78991770e+10 -1.78194350e+10\\n -1.78194350e+10\\\n",
      "          \\  1.34449191e+12 -1.97671649e+10  1.14480218e+12\\n -1.97671649e+10  4.74404487e+11\\\n",
      "          \\  3.32172722e+11 -1.95562373e+10\\n -1.87838300e+10 -6.16269087e+10  3.32172722e+11\\\n",
      "          \\ -6.72382976e+10\\n -6.72382976e+10  1.34449191e+12 -1.87838300e+10 -1.88517253e+10\\n\\\n",
      "          \\ -5.81091983e+10  1.34449191e+12  3.32172722e+11  3.32172722e+11\\n  1.34449191e+12\\\n",
      "          \\ -1.87838300e+10 -1.95562373e+10  1.14480218e+12]\"\n",
      "    num_agent_steps_sampled: 314000\n",
      "    num_agent_steps_trained: 2504032\n",
      "    num_steps_sampled: 314000\n",
      "    num_steps_trained: 2504032\n",
      "    num_target_updates: 622\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.68421052631579\n",
      "    ram_util_percent: 92.63684210526316\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03997435204582891\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.829003289318456\n",
      "    mean_inference_ms: 1.5613025525508812\n",
      "    mean_raw_obs_processing_ms: 1.9120337247066233\n",
      "  time_since_restore: 4713.033345460892\n",
      "  time_this_iter_s: 13.155801057815552\n",
      "  time_total_s: 4713.033345460892\n",
      "  timers:\n",
      "    learn_throughput: 3621.496\n",
      "    learn_time_ms: 8.836\n",
      "    load_throughput: 63580.165\n",
      "    load_time_ms: 0.503\n",
      "    update_time_ms: 1.764\n",
      "  timestamp: 1632006146\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 314000\n",
      "  training_iteration: 314\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   314</td><td style=\"text-align: right;\">         4713.03</td><td style=\"text-align: right;\">314000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 315000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-02-39\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 321\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 314992\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5567777079296.0\n",
      "          mean_q: 1222719307776.0\n",
      "          min_q: 504673501184.0\n",
      "        mean_td_error: -101836897280.0\n",
      "        td_error: \"[ 3.42784082e+10 -4.41042207e+10 -4.07234150e+09  3.86260009e+10\\n\\\n",
      "          \\  4.05328364e+10  5.05259688e+11 -4.94665728e+09  5.05259688e+11\\n -4.07234150e+09\\\n",
      "          \\ -5.09450650e+09  5.05259688e+11 -6.99396915e+09\\n -2.26221752e+10 -1.63160575e+12\\\n",
      "          \\  4.05328364e+10  1.42070907e+10\\n  3.42784082e+10  4.25327329e+10 -1.63160575e+12\\\n",
      "          \\  5.05259688e+11\\n  4.05328364e+10 -1.63160575e+12 -4.57067725e+09 -4.57067725e+09\\n\\\n",
      "          \\  2.42914427e+10 -4.57067725e+09 -4.57067725e+09 -4.07234150e+09\\n -1.63160575e+12\\\n",
      "          \\  5.05259688e+11  4.05328364e+10  5.05259688e+11]\"\n",
      "    num_agent_steps_sampled: 315000\n",
      "    num_agent_steps_trained: 2512032\n",
      "    num_steps_sampled: 315000\n",
      "    num_steps_trained: 2512032\n",
      "    num_target_updates: 624\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.73684210526316\n",
      "    ram_util_percent: 92.53684210526316\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039975287668223454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.825410010503787\n",
      "    mean_inference_ms: 1.561280275835805\n",
      "    mean_raw_obs_processing_ms: 1.9078861900246722\n",
      "  time_since_restore: 4726.262141704559\n",
      "  time_this_iter_s: 13.228796243667603\n",
      "  time_total_s: 4726.262141704559\n",
      "  timers:\n",
      "    learn_throughput: 3571.454\n",
      "    learn_time_ms: 8.96\n",
      "    load_throughput: 65459.29\n",
      "    load_time_ms: 0.489\n",
      "    update_time_ms: 1.739\n",
      "  timestamp: 1632006159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 315000\n",
      "  training_iteration: 315\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   315</td><td style=\"text-align: right;\">         4726.26</td><td style=\"text-align: right;\">315000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 316000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-02-52\n",
      "  done: false\n",
      "  episode_len_mean: 994.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 322\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 316000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 5404056616960.0\n",
      "          mean_q: 964949442560.0\n",
      "          min_q: 522411048960.0\n",
      "        mean_td_error: -761826136064.0\n",
      "        td_error: \"[ 3.05630806e+11  1.12162832e+11 -3.51413364e+12  2.62607077e+11\\n\\\n",
      "          \\  5.24009964e+11  4.04708065e+10  3.10154691e+11  5.24009964e+11\\n -3.51413364e+12\\\n",
      "          \\ -3.51413364e+12  1.79356500e+11  2.62607077e+11\\n  2.51920384e+09 -3.51413364e+12\\\n",
      "          \\  2.30090342e+09  2.62601900e+11\\n  9.62883092e+10  4.48142377e+10  5.24009964e+11\\\n",
      "          \\ -3.51413364e+12\\n -1.57523221e+12  3.05630806e+11 -3.51413364e+12 -3.51413364e+12\\n\\\n",
      "          \\  5.24009964e+11  2.17130664e+11  3.05630806e+11  3.10154691e+11\\n  2.30090342e+09\\\n",
      "          \\ -3.51413364e+12  2.57173094e+09  1.88891202e+11]\"\n",
      "    num_agent_steps_sampled: 316000\n",
      "    num_agent_steps_trained: 2520032\n",
      "    num_steps_sampled: 316000\n",
      "    num_steps_trained: 2520032\n",
      "    num_target_updates: 626\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.20000000000001\n",
      "    ram_util_percent: 92.50526315789473\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03997620378822821\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.821853833146238\n",
      "    mean_inference_ms: 1.5612584236413878\n",
      "    mean_raw_obs_processing_ms: 1.903780962647084\n",
      "  time_since_restore: 4739.577903985977\n",
      "  time_this_iter_s: 13.315762281417847\n",
      "  time_total_s: 4739.577903985977\n",
      "  timers:\n",
      "    learn_throughput: 3309.573\n",
      "    learn_time_ms: 9.669\n",
      "    load_throughput: 55629.68\n",
      "    load_time_ms: 0.575\n",
      "    update_time_ms: 2.031\n",
      "  timestamp: 1632006172\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 316000\n",
      "  training_iteration: 316\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   316</td><td style=\"text-align: right;\">         4739.58</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 317000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-03-06\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 323\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 316504\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 3289936560128.0\n",
      "          mean_q: 1460954988544.0\n",
      "          min_q: 577682276352.0\n",
      "        mean_td_error: -655233449984.0\n",
      "        td_error: \"[ 9.0720829e+09  1.0088612e+10 -2.6573826e+12 -3.7723701e+10\\n  1.3172933e+10\\\n",
      "          \\  1.0814423e+10  7.7778125e+09 -2.6573826e+12\\n  3.0034690e+10  2.8276163e+09\\\n",
      "          \\  7.7778125e+09  4.3819467e+10\\n -2.6573826e+12  5.1605799e+10  3.8273024e+07\\\n",
      "          \\  1.7520853e+10\\n  5.2200473e+10 -4.6997832e+10 -4.6997832e+10 -4.6997832e+10\\n\\\n",
      "          \\ -2.6573826e+12  5.8296238e+09  4.1131377e+10 -3.2378978e+10\\n -2.6573826e+12\\\n",
      "          \\  3.4777989e+09 -2.6573826e+12 -2.6573826e+12\\n  3.6124754e+09  1.8410557e+11\\\n",
      "          \\ -2.6573826e+12  7.7778125e+09]\"\n",
      "    num_agent_steps_sampled: 317000\n",
      "    num_agent_steps_trained: 2528032\n",
      "    num_steps_sampled: 317000\n",
      "    num_steps_trained: 2528032\n",
      "    num_target_updates: 627\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.58421052631579\n",
      "    ram_util_percent: 92.56315789473686\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03997713738472473\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.8183397892415485\n",
      "    mean_inference_ms: 1.5612371788340358\n",
      "    mean_raw_obs_processing_ms: 1.8989603986818273\n",
      "  time_since_restore: 4753.033548116684\n",
      "  time_this_iter_s: 13.455644130706787\n",
      "  time_total_s: 4753.033548116684\n",
      "  timers:\n",
      "    learn_throughput: 3558.745\n",
      "    learn_time_ms: 8.992\n",
      "    load_throughput: 60480.231\n",
      "    load_time_ms: 0.529\n",
      "    update_time_ms: 1.773\n",
      "  timestamp: 1632006186\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 317000\n",
      "  training_iteration: 317\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   317</td><td style=\"text-align: right;\">         4753.03</td><td style=\"text-align: right;\">317000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 318000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-03-19\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 324\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 317512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 10563040051200.0\n",
      "          mean_q: 2233423626240.0\n",
      "          min_q: 678469697536.0\n",
      "        mean_td_error: 144112615424.0\n",
      "        td_error: \"[-4.65399448e+11 -3.21715700e+11 -4.96579379e+09  9.08394496e+08\\n\\\n",
      "          \\ -9.21246106e+09  8.01840824e+10 -4.65399448e+11  6.80790196e+11\\n  3.23456205e+10\\\n",
      "          \\  6.80790196e+11  6.80790196e+11  5.78781839e+10\\n  6.63977984e+09  3.23456205e+10\\\n",
      "          \\  5.78781839e+10  5.91547597e+09\\n  2.19579023e+10  6.80790196e+11  1.01693522e+11\\\n",
      "          \\  1.35742882e+11\\n  6.80790196e+11  5.89727007e+10  6.80790196e+11  6.80790196e+11\\n\\\n",
      "          \\ -1.29121124e+11  1.35742882e+11  5.76059474e+10 -3.21715700e+11\\n  5.90476739e+10\\\n",
      "          \\  6.80790196e+11  3.23456205e+10  5.60732570e+09]\"\n",
      "    num_agent_steps_sampled: 318000\n",
      "    num_agent_steps_trained: 2536032\n",
      "    num_steps_sampled: 318000\n",
      "    num_steps_trained: 2536032\n",
      "    num_target_updates: 629\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.905263157894744\n",
      "    ram_util_percent: 92.61052631578949\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039978114319665664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.814777796529568\n",
      "    mean_inference_ms: 1.5612167304817188\n",
      "    mean_raw_obs_processing_ms: 1.894184404016581\n",
      "  time_since_restore: 4766.521764755249\n",
      "  time_this_iter_s: 13.488216638565063\n",
      "  time_total_s: 4766.521764755249\n",
      "  timers:\n",
      "    learn_throughput: 3571.245\n",
      "    learn_time_ms: 8.96\n",
      "    load_throughput: 58684.678\n",
      "    load_time_ms: 0.545\n",
      "    update_time_ms: 1.814\n",
      "  timestamp: 1632006199\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 318000\n",
      "  training_iteration: 318\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   318</td><td style=\"text-align: right;\">         4766.52</td><td style=\"text-align: right;\">318000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 319000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-03-33\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 325\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 318520\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 17612922683392.0\n",
      "          mean_q: 2992028254208.0\n",
      "          min_q: 727886987264.0\n",
      "        mean_td_error: 40213020672.0\n",
      "        td_error: \"[ 8.85101691e+10  7.96375777e+10  5.21410314e+10  1.00253630e+11\\n\\\n",
      "          \\  1.00253630e+11  8.85101691e+10  1.62089992e+11  5.37899172e+10\\n  2.54442013e+11\\\n",
      "          \\ -7.22791825e+11  1.27718064e+11  2.99258348e+10\\n  8.99061514e+10  9.71023319e+10\\\n",
      "          \\  1.00253630e+11  3.30387292e+10\\n  2.86454579e+10  2.27410444e+11 -2.40659726e+11\\\n",
      "          \\  1.00253630e+11\\n  1.67243481e+11 -7.22791825e+11  2.86454579e+10  1.27718064e+11\\n\\\n",
      "          \\  2.27410444e+11  2.54442013e+11  1.17198750e+11  1.27718064e+11\\n  6.93355807e+10\\\n",
      "          \\ -7.22791825e+11  7.32331770e+11  2.99258348e+10]\"\n",
      "    num_agent_steps_sampled: 319000\n",
      "    num_agent_steps_trained: 2544032\n",
      "    num_steps_sampled: 319000\n",
      "    num_steps_trained: 2544032\n",
      "    num_target_updates: 631\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.540000000000006\n",
      "    ram_util_percent: 92.92500000000001\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03997910999894363\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.811220528987866\n",
      "    mean_inference_ms: 1.5611972745995726\n",
      "    mean_raw_obs_processing_ms: 1.8894521845621717\n",
      "  time_since_restore: 4780.01988697052\n",
      "  time_this_iter_s: 13.498122215270996\n",
      "  time_total_s: 4780.01988697052\n",
      "  timers:\n",
      "    learn_throughput: 3587.28\n",
      "    learn_time_ms: 8.92\n",
      "    load_throughput: 58820.987\n",
      "    load_time_ms: 0.544\n",
      "    update_time_ms: 1.794\n",
      "  timestamp: 1632006213\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319000\n",
      "  training_iteration: 319\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   319</td><td style=\"text-align: right;\">         4780.02</td><td style=\"text-align: right;\">319000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 320000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-03-46\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 326\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 319528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 28441319571456.0\n",
      "          mean_q: 4692955889664.0\n",
      "          min_q: 641469841408.0\n",
      "        mean_td_error: -520358987776.0\n",
      "        td_error: \"[-5.30580714e+12 -1.60473809e+11  1.20129611e+12  1.20129611e+12\\n\\\n",
      "          \\ -1.58579294e+11 -1.34428754e+11 -4.43347763e+10 -1.53286476e+11\\n  8.12344410e+11\\\n",
      "          \\  1.36127513e+11 -1.60941081e+11 -6.54956954e+10\\n -1.56705620e+11 -1.60473809e+11\\\n",
      "          \\ -1.26823589e+12 -1.34428754e+11\\n -5.30580714e+12  1.67927874e+11  5.51875379e+10\\\n",
      "          \\ -1.26823589e+12\\n  2.22786355e+10 -1.56705620e+11  6.09993359e+10  3.73646295e+10\\n\\\n",
      "          \\ -1.60473809e+11 -1.34428754e+11  1.20129611e+12 -1.26823589e+12\\n  6.09993359e+10\\\n",
      "          \\  4.75666186e+10 -5.30580714e+12 -1.53286476e+11]\"\n",
      "    num_agent_steps_sampled: 320000\n",
      "    num_agent_steps_trained: 2552032\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 2552032\n",
      "    num_target_updates: 633\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.48947368421052\n",
      "    ram_util_percent: 92.94736842105262\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0399801126806357\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.807669140456812\n",
      "    mean_inference_ms: 1.5611787334633365\n",
      "    mean_raw_obs_processing_ms: 1.8847636050872156\n",
      "  time_since_restore: 4793.3661460876465\n",
      "  time_this_iter_s: 13.346259117126465\n",
      "  time_total_s: 4793.3661460876465\n",
      "  timers:\n",
      "    learn_throughput: 3679.436\n",
      "    learn_time_ms: 8.697\n",
      "    load_throughput: 61576.239\n",
      "    load_time_ms: 0.52\n",
      "    update_time_ms: 1.711\n",
      "  timestamp: 1632006226\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 320\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   320</td><td style=\"text-align: right;\">         4793.37</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 321000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-03-58\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 327\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 320536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 32326067159040.0\n",
      "          mean_q: 8123516977152.0\n",
      "          min_q: 787628359680.0\n",
      "        mean_td_error: -572700622848.0\n",
      "        td_error: \"[-1.8409262e+12  3.7901409e+11  2.0636756e+11  1.2357245e+11\\n -2.3518970e+10\\\n",
      "          \\  1.2357245e+11  4.0434008e+10  5.1242598e+09\\n  5.1242598e+09  5.1242598e+09\\\n",
      "          \\  3.7901409e+11 -2.3518970e+10\\n -1.7585865e+10  1.2357245e+11 -1.3487938e+11\\\n",
      "          \\ -4.2562159e+10\\n -3.6075922e+12 -1.8409262e+12 -2.3518970e+10 -3.6075922e+12\\n\\\n",
      "          \\ -1.8409262e+12  1.2357245e+11  5.5004889e+10  1.2802327e+10\\n -2.3518970e+10\\\n",
      "          \\  1.8356371e+10 -3.6075922e+12  5.1147375e+10\\n  5.2536410e+10 -3.6075922e+12\\\n",
      "          \\  2.0636756e+11  5.1242598e+09]\"\n",
      "    num_agent_steps_sampled: 321000\n",
      "    num_agent_steps_trained: 2560032\n",
      "    num_steps_sampled: 321000\n",
      "    num_steps_trained: 2560032\n",
      "    num_target_updates: 635\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.023529411764706\n",
      "    ram_util_percent: 92.97058823529413\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998108061807512\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.80408259300808\n",
      "    mean_inference_ms: 1.5611588272705461\n",
      "    mean_raw_obs_processing_ms: 1.8801176666110069\n",
      "  time_since_restore: 4805.514430761337\n",
      "  time_this_iter_s: 12.148284673690796\n",
      "  time_total_s: 4805.514430761337\n",
      "  timers:\n",
      "    learn_throughput: 3662.308\n",
      "    learn_time_ms: 8.738\n",
      "    load_throughput: 63069.277\n",
      "    load_time_ms: 0.507\n",
      "    update_time_ms: 1.706\n",
      "  timestamp: 1632006238\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 321000\n",
      "  training_iteration: 321\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   321</td><td style=\"text-align: right;\">         4805.51</td><td style=\"text-align: right;\">321000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 322000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-04-10\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 328\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 321544\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 51672130781184.0\n",
      "          mean_q: 4516596416512.0\n",
      "          min_q: 929147650048.0\n",
      "        mean_td_error: -2092688998400.0\n",
      "        td_error: \"[ 1.06218127e+10 -1.15821521e+13  1.68438989e+11 -1.15821521e+13\\n\\\n",
      "          \\  9.24424602e+09  1.68301363e+11 -1.15821521e+13  5.48012032e+08\\n -1.15821521e+13\\\n",
      "          \\ -1.15821521e+13 -1.15821521e+13  2.14481109e+11\\n  1.02735348e+11  1.44949379e+11\\\n",
      "          \\  2.20654666e+11  2.20654666e+11\\n -1.47775816e+11  1.06218127e+10  1.84485623e+12\\\n",
      "          \\  8.55808410e+09\\n  1.40575506e+11  1.20447566e+11  1.53573130e+10  1.06218127e+10\\n\\\n",
      "          \\ -1.18475457e+11  1.06218127e+10  1.06218127e+10 -1.51817617e+11\\n  9.24424602e+09\\\n",
      "          \\  1.48734149e+11 -7.86532663e+11  1.40575506e+11]\"\n",
      "    num_agent_steps_sampled: 322000\n",
      "    num_agent_steps_trained: 2568032\n",
      "    num_steps_sampled: 322000\n",
      "    num_steps_trained: 2568032\n",
      "    num_target_updates: 637\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.1764705882353\n",
      "    ram_util_percent: 93.04705882352943\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998201118571079\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.800455921479657\n",
      "    mean_inference_ms: 1.5611377894640477\n",
      "    mean_raw_obs_processing_ms: 1.8755140126430112\n",
      "  time_since_restore: 4817.4034512043\n",
      "  time_this_iter_s: 11.889020442962646\n",
      "  time_total_s: 4817.4034512043\n",
      "  timers:\n",
      "    learn_throughput: 3538.722\n",
      "    learn_time_ms: 9.043\n",
      "    load_throughput: 55542.201\n",
      "    load_time_ms: 0.576\n",
      "    update_time_ms: 1.824\n",
      "  timestamp: 1632006250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 322000\n",
      "  training_iteration: 322\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   322</td><td style=\"text-align: right;\">          4817.4</td><td style=\"text-align: right;\">322000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 323000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-04-22\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 329\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 322552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 47856580820992.0\n",
      "          mean_q: 6848774668288.0\n",
      "          min_q: 972854001664.0\n",
      "        mean_td_error: -1664403499008.0\n",
      "        td_error: \"[-4.84214047e+10 -1.31090953e+13  6.75994272e+11 -6.98037043e+11\\n\\\n",
      "          \\ -9.58055580e+11 -1.31090953e+13  4.59777966e+11 -5.11239520e+11\\n -1.07758748e+11\\\n",
      "          \\  1.57342381e+12  6.95054238e+11  1.01943869e+10\\n -4.84214047e+10 -9.22778337e+10\\\n",
      "          \\ -1.52462164e+11 -1.31090953e+13\\n -9.16085277e+11  6.62925607e+11  2.92424253e+10\\\n",
      "          \\ -9.20872550e+10\\n -1.31090953e+13 -5.69215549e+10 -9.22778337e+10  6.75994272e+11\\n\\\n",
      "          \\ -9.58055580e+11 -3.90114181e+10 -5.11239520e+11  2.92424253e+10\\n -5.86251633e+10\\\n",
      "          \\ -9.54816266e+10 -1.07833983e+11 -9.20872550e+10]\"\n",
      "    num_agent_steps_sampled: 323000\n",
      "    num_agent_steps_trained: 2576032\n",
      "    num_steps_sampled: 323000\n",
      "    num_steps_trained: 2576032\n",
      "    num_target_updates: 639\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.4470588235294\n",
      "    ram_util_percent: 93.29411764705883\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998295606634892\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.796800034142174\n",
      "    mean_inference_ms: 1.5611175751757715\n",
      "    mean_raw_obs_processing_ms: 1.8709518862025087\n",
      "  time_since_restore: 4829.343779087067\n",
      "  time_this_iter_s: 11.940327882766724\n",
      "  time_total_s: 4829.343779087067\n",
      "  timers:\n",
      "    learn_throughput: 3435.42\n",
      "    learn_time_ms: 9.315\n",
      "    load_throughput: 55579.0\n",
      "    load_time_ms: 0.576\n",
      "    update_time_ms: 1.885\n",
      "  timestamp: 1632006262\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 323000\n",
      "  training_iteration: 323\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   323</td><td style=\"text-align: right;\">         4829.34</td><td style=\"text-align: right;\">323000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 324000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-04-35\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 330\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 323560\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 83271933231104.0\n",
      "          mean_q: 9627220574208.0\n",
      "          min_q: 978049957888.0\n",
      "        mean_td_error: -1871523880960.0\n",
      "        td_error: \"[ 1.08829750e+12  1.63158426e+09 -1.02349799e+11  4.19706569e+11\\n\\\n",
      "          \\ -1.30915082e+13 -2.56286917e+11 -1.02349799e+11 -2.09607721e+10\\n -2.56286917e+11\\\n",
      "          \\  1.46238341e+10  4.38647862e+12  4.38647862e+12\\n  4.19706569e+11 -2.56286917e+11\\\n",
      "          \\  1.63158426e+09  3.61168896e+10\\n  1.46238341e+10 -3.59473218e+11 -1.30915082e+13\\\n",
      "          \\ -1.28611621e+12\\n -4.37115945e+10  9.37689088e+10 -1.96767174e+12 -1.49207253e+11\\n\\\n",
      "          \\ -9.20425595e+10 -1.30915082e+13 -1.30915082e+13 -9.93085358e+10\\n -1.30915082e+13\\\n",
      "          \\ -3.27048757e+11  3.61168896e+10 -1.13036493e+10]\"\n",
      "    num_agent_steps_sampled: 324000\n",
      "    num_agent_steps_trained: 2584032\n",
      "    num_steps_sampled: 324000\n",
      "    num_steps_trained: 2584032\n",
      "    num_target_updates: 641\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.305555555555564\n",
      "    ram_util_percent: 93.23888888888888\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998388432660473\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.7931567696211115\n",
      "    mean_inference_ms: 1.5610971378353122\n",
      "    mean_raw_obs_processing_ms: 1.866431091521825\n",
      "  time_since_restore: 4841.778484344482\n",
      "  time_this_iter_s: 12.434705257415771\n",
      "  time_total_s: 4841.778484344482\n",
      "  timers:\n",
      "    learn_throughput: 3533.784\n",
      "    learn_time_ms: 9.055\n",
      "    load_throughput: 56108.745\n",
      "    load_time_ms: 0.57\n",
      "    update_time_ms: 1.81\n",
      "  timestamp: 1632006275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 324000\n",
      "  training_iteration: 324\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   324</td><td style=\"text-align: right;\">         4841.78</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 325000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-04-47\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 331\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 324568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 97752188977152.0\n",
      "          mean_q: 10679617585152.0\n",
      "          min_q: 1280648019968.0\n",
      "        mean_td_error: -2529547128832.0\n",
      "        td_error: \"[-7.99755469e+10 -1.65616382e+13 -7.99755469e+10  5.88263064e+11\\n\\\n",
      "          \\  1.15368526e+12  2.90977874e+11  1.28064802e+12 -5.80947804e+10\\n  1.94950857e+11\\\n",
      "          \\ -1.65616382e+13  1.88363702e+11  2.03053335e+11\\n -9.05458483e+10 -1.65616382e+13\\\n",
      "          \\  1.51355785e+11  1.28064802e+12\\n -9.05458483e+10 -3.13458793e+12  2.34422272e+11\\\n",
      "          \\ -4.38820667e+11\\n -7.66583767e+10 -1.65616382e+13  2.02538353e+11 -2.25917796e+11\\n\\\n",
      "          \\ -1.65616382e+13 -7.66583767e+10 -7.66583767e+10  2.77979726e+11\\n  2.02538353e+11\\\n",
      "          \\  2.02538353e+11 -4.38820667e+11  2.77979726e+11]\"\n",
      "    num_agent_steps_sampled: 325000\n",
      "    num_agent_steps_trained: 2592032\n",
      "    num_steps_sampled: 325000\n",
      "    num_steps_trained: 2592032\n",
      "    num_target_updates: 643\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.88888888888889\n",
      "    ram_util_percent: 93.37777777777778\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039984808154316334\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.7895190458613515\n",
      "    mean_inference_ms: 1.5610771422163068\n",
      "    mean_raw_obs_processing_ms: 1.8619510209856662\n",
      "  time_since_restore: 4854.427445411682\n",
      "  time_this_iter_s: 12.648961067199707\n",
      "  time_total_s: 4854.427445411682\n",
      "  timers:\n",
      "    learn_throughput: 3376.946\n",
      "    learn_time_ms: 9.476\n",
      "    load_throughput: 49315.744\n",
      "    load_time_ms: 0.649\n",
      "    update_time_ms: 2.082\n",
      "  timestamp: 1632006287\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 325000\n",
      "  training_iteration: 325\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   325</td><td style=\"text-align: right;\">         4854.43</td><td style=\"text-align: right;\">325000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 326000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-05-00\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 332\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 325576\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 117290842456064.0\n",
      "          mean_q: 22946414329856.0\n",
      "          min_q: 1630739628032.0\n",
      "        mean_td_error: -2457665699840.0\n",
      "        td_error: \"[ 2.51417068e+10 -3.29138989e+12 -1.97727735e+13 -1.97727735e+13\\n\\\n",
      "          \\  2.33859659e+12  1.38960830e+11  2.00791399e+12 -2.78679624e+12\\n -2.78679624e+12\\\n",
      "          \\  8.89153651e+11  1.15837121e+12 -1.97727735e+13\\n -1.27776326e+11 -3.29138989e+12\\\n",
      "          \\ -1.48640891e+10  7.87537592e+11\\n -2.12635274e+12  7.87537592e+11 -1.48640891e+10\\\n",
      "          \\ -3.04518398e+11\\n -3.29138989e+12  7.87537592e+11 -2.12635274e+12 -2.12635274e+12\\n\\\n",
      "          \\ -2.85652287e+11 -2.09888477e+11 -2.64533443e+11  1.38960830e+11\\n  1.38960830e+11\\\n",
      "          \\ -3.29138989e+12 -2.78679624e+12  6.01449300e+11]\"\n",
      "    num_agent_steps_sampled: 326000\n",
      "    num_agent_steps_trained: 2600032\n",
      "    num_steps_sampled: 326000\n",
      "    num_steps_trained: 2600032\n",
      "    num_target_updates: 645\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.71666666666667\n",
      "    ram_util_percent: 93.46666666666667\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998570304110139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.785875520332971\n",
      "    mean_inference_ms: 1.5610562187990693\n",
      "    mean_raw_obs_processing_ms: 1.8575109537059469\n",
      "  time_since_restore: 4867.328450679779\n",
      "  time_this_iter_s: 12.901005268096924\n",
      "  time_total_s: 4867.328450679779\n",
      "  timers:\n",
      "    learn_throughput: 3558.01\n",
      "    learn_time_ms: 8.994\n",
      "    load_throughput: 51536.969\n",
      "    load_time_ms: 0.621\n",
      "    update_time_ms: 1.836\n",
      "  timestamp: 1632006300\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 326000\n",
      "  training_iteration: 326\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   326</td><td style=\"text-align: right;\">         4867.33</td><td style=\"text-align: right;\">326000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 327000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-05-13\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 333\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 326584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 129320785805312.0\n",
      "          mean_q: 16209342889984.0\n",
      "          min_q: 2016397361152.0\n",
      "        mean_td_error: -2404790349824.0\n",
      "        td_error: \"[-1.20001554e+12  1.46752537e+12  1.46752537e+12 -1.73944047e+13\\n\\\n",
      "          \\  5.62453807e+11  2.01639736e+12 -1.73944047e+13  1.45172595e+12\\n  8.51653427e+09\\\n",
      "          \\  1.45172595e+12  1.46640077e+12 -2.02667930e+12\\n  1.64046832e+11  8.52674740e+11\\\n",
      "          \\ -1.73944047e+13  1.46752537e+12\\n  3.88852613e+11  1.46640077e+12 -1.73944047e+13\\\n",
      "          \\ -2.02667930e+12\\n  1.41512671e+11  5.35746314e+10  4.68731822e+10  1.46640077e+12\\n\\\n",
      "          \\ -1.73944047e+13 -1.28184222e+11  1.41512671e+11  9.99644201e+11\\n -1.68317420e+12\\\n",
      "          \\ -2.02667930e+12  1.46640077e+12  5.62453807e+11]\"\n",
      "    num_agent_steps_sampled: 327000\n",
      "    num_agent_steps_trained: 2608032\n",
      "    num_steps_sampled: 327000\n",
      "    num_steps_trained: 2608032\n",
      "    num_target_updates: 647\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.06666666666666\n",
      "    ram_util_percent: 93.42777777777778\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998658426393507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.7822327319394935\n",
      "    mean_inference_ms: 1.5610356600841448\n",
      "    mean_raw_obs_processing_ms: 1.8531108999118424\n",
      "  time_since_restore: 4879.926957130432\n",
      "  time_this_iter_s: 12.598506450653076\n",
      "  time_total_s: 4879.926957130432\n",
      "  timers:\n",
      "    learn_throughput: 3518.121\n",
      "    learn_time_ms: 9.096\n",
      "    load_throughput: 49579.893\n",
      "    load_time_ms: 0.645\n",
      "    update_time_ms: 1.869\n",
      "  timestamp: 1632006313\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 327000\n",
      "  training_iteration: 327\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   327</td><td style=\"text-align: right;\">         4879.93</td><td style=\"text-align: right;\">327000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 328000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-05-26\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 334\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 327592\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 111280513875968.0\n",
      "          mean_q: 9882190217216.0\n",
      "          min_q: 2669803995136.0\n",
      "        mean_td_error: -6839336468480.0\n",
      "        td_error: \"[-4.25613328e+11 -2.47933258e+13 -3.78652852e+11  2.93232181e+11\\n\\\n",
      "          \\ -4.29591626e+11 -2.47933258e+13  9.87750728e+11 -2.47933258e+13\\n  1.45770676e+11\\\n",
      "          \\  2.30623805e+10 -2.47933258e+13 -2.47933258e+13\\n -1.37984213e+11  1.11878078e+12\\\n",
      "          \\  1.45770676e+11 -2.47933258e+13\\n -2.47933258e+13 -3.78652852e+11 -3.78652852e+11\\\n",
      "          \\  9.35669006e+11\\n -4.25613328e+11  2.30623805e+10 -8.08619868e+10 -2.47933258e+13\\n\\\n",
      "          \\ -8.68194714e+10  3.19716065e+11 -2.47933258e+13  7.18689272e+11\\n -1.77649746e+10\\\n",
      "          \\ -3.78652852e+11  2.66980400e+12  1.87170816e+10]\"\n",
      "    num_agent_steps_sampled: 328000\n",
      "    num_agent_steps_trained: 2616032\n",
      "    num_steps_sampled: 328000\n",
      "    num_steps_trained: 2616032\n",
      "    num_target_updates: 649\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.18421052631578\n",
      "    ram_util_percent: 93.27368421052631\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998747272696482\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.778596566629104\n",
      "    mean_inference_ms: 1.5610160526071417\n",
      "    mean_raw_obs_processing_ms: 1.8487504069305016\n",
      "  time_since_restore: 4892.734402894974\n",
      "  time_this_iter_s: 12.807445764541626\n",
      "  time_total_s: 4892.734402894974\n",
      "  timers:\n",
      "    learn_throughput: 3659.342\n",
      "    learn_time_ms: 8.745\n",
      "    load_throughput: 63919.291\n",
      "    load_time_ms: 0.501\n",
      "    update_time_ms: 1.735\n",
      "  timestamp: 1632006326\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 328000\n",
      "  training_iteration: 328\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   328</td><td style=\"text-align: right;\">         4892.73</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 329000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-05-38\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 335\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 328600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 191375387656192.0\n",
      "          mean_q: 57511432421376.0\n",
      "          min_q: 3506214010880.0\n",
      "        mean_td_error: 1482244120576.0\n",
      "        td_error: \"[-6.53715833e+11 -5.48066034e+11 -3.95876762e+11  2.07170096e+12\\n\\\n",
      "          \\  7.70750336e+12  4.91052335e+11  1.22993435e+13  1.22993435e+13\\n  1.68252513e+12\\\n",
      "          \\  4.91052335e+11 -3.48614159e+13  2.90787636e+12\\n  4.52542123e+12  4.52542123e+12\\\n",
      "          \\  4.52542123e+12 -2.23277220e+11\\n  1.22993435e+13  1.22993435e+13  4.28596003e+11\\\n",
      "          \\  4.56322554e+12\\n  1.64373096e+12  1.22993435e+13  2.86087289e+12  4.52542123e+12\\n\\\n",
      "          \\  2.90787636e+12  4.56322554e+12  1.22993435e+13  1.22993435e+13\\n -3.48614159e+13\\\n",
      "          \\  1.28441993e+13  4.47646899e+12 -3.48614159e+13]\"\n",
      "    num_agent_steps_sampled: 329000\n",
      "    num_agent_steps_trained: 2624032\n",
      "    num_steps_sampled: 329000\n",
      "    num_steps_trained: 2624032\n",
      "    num_target_updates: 651\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.36666666666667\n",
      "    ram_util_percent: 93.27222222222221\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998834738018862\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.774967323355288\n",
      "    mean_inference_ms: 1.56099716018496\n",
      "    mean_raw_obs_processing_ms: 1.8444286745052747\n",
      "  time_since_restore: 4905.546011686325\n",
      "  time_this_iter_s: 12.811608791351318\n",
      "  time_total_s: 4905.546011686325\n",
      "  timers:\n",
      "    learn_throughput: 3579.493\n",
      "    learn_time_ms: 8.94\n",
      "    load_throughput: 52912.453\n",
      "    load_time_ms: 0.605\n",
      "    update_time_ms: 1.801\n",
      "  timestamp: 1632006338\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329000\n",
      "  training_iteration: 329\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   329</td><td style=\"text-align: right;\">         4905.55</td><td style=\"text-align: right;\">329000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 330000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-05-52\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 336\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 329608\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 204555082006528.0\n",
      "          mean_q: 46461257515008.0\n",
      "          min_q: 1872720560128.0\n",
      "        mean_td_error: -2911645728768.0\n",
      "        td_error: \"[-3.73657960e+11 -5.04647123e+11 -3.47886060e+10 -3.47886060e+10\\n\\\n",
      "          \\  3.90648037e+11  1.37006416e+11  5.26031205e+12 -5.30545902e+12\\n -3.49890538e+13\\\n",
      "          \\  5.74640095e+12 -3.49890538e+13  3.05731994e+11\\n -3.73657960e+11  1.25829225e+12\\\n",
      "          \\  1.37006416e+11  8.45757913e+12\\n -2.74146525e+11  8.45757913e+12 -2.55415288e+11\\\n",
      "          \\  5.74640095e+12\\n  8.45757913e+12 -3.49890538e+13  5.26031205e+12 -3.73657960e+11\\n\\\n",
      "          \\ -3.49890538e+13 -1.03636219e+12 -3.72285112e+11  8.45757913e+12\\n -1.03636219e+12\\\n",
      "          \\ -5.61345987e+11  1.33657579e+12 -2.08887480e+12]\"\n",
      "    num_agent_steps_sampled: 330000\n",
      "    num_agent_steps_trained: 2632032\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 2632032\n",
      "    num_target_updates: 653\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.078947368421055\n",
      "    ram_util_percent: 93.40526315789474\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03998925813076262\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.771348382396798\n",
      "    mean_inference_ms: 1.5609794938381043\n",
      "    mean_raw_obs_processing_ms: 1.8401442708256588\n",
      "  time_since_restore: 4918.64756321907\n",
      "  time_this_iter_s: 13.101551532745361\n",
      "  time_total_s: 4918.64756321907\n",
      "  timers:\n",
      "    learn_throughput: 3550.424\n",
      "    learn_time_ms: 9.013\n",
      "    load_throughput: 53339.319\n",
      "    load_time_ms: 0.6\n",
      "    update_time_ms: 1.779\n",
      "  timestamp: 1632006352\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 330\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   330</td><td style=\"text-align: right;\">         4918.65</td><td style=\"text-align: right;\">330000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 331000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-06-05\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 337\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 330616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 212795614298112.0\n",
      "          mean_q: 35857524326400.0\n",
      "          min_q: 2730442620928.0\n",
      "        mean_td_error: -665189023744.0\n",
      "        td_error: \"[-3.0743636e+13  2.8488090e+12  2.5084156e+12  3.1120561e+12\\n  3.5051799e+10\\\n",
      "          \\  3.1293555e+12  3.1293555e+12  1.6834363e+10\\n -1.0859525e+11 -3.0743636e+13\\\n",
      "          \\  3.0094456e+12  1.1690196e+12\\n -6.0217151e+11  5.7670673e+12 -8.5912034e+11\\\n",
      "          \\ -2.1751928e+12\\n  3.0094456e+12  1.7824104e+12  2.5084156e+12  5.5314481e+10\\n\\\n",
      "          \\ -1.8698574e+11 -6.1072160e+11  1.6834363e+10  1.6834363e+10\\n  2.7297579e+10\\\n",
      "          \\ -1.6984388e+12  2.3345968e+11  3.0094456e+12\\n  3.0094456e+12  3.1120561e+12\\\n",
      "          \\  2.4276621e+12  2.5084156e+12]\"\n",
      "    num_agent_steps_sampled: 331000\n",
      "    num_agent_steps_trained: 2640032\n",
      "    num_steps_sampled: 331000\n",
      "    num_steps_trained: 2640032\n",
      "    num_target_updates: 655\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.74210526315789\n",
      "    ram_util_percent: 93.4263157894737\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039990236592671514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.767737887505418\n",
      "    mean_inference_ms: 1.5609638672347532\n",
      "    mean_raw_obs_processing_ms: 1.8358979542045573\n",
      "  time_since_restore: 4932.0038475990295\n",
      "  time_this_iter_s: 13.356284379959106\n",
      "  time_total_s: 4932.0038475990295\n",
      "  timers:\n",
      "    learn_throughput: 3461.995\n",
      "    learn_time_ms: 9.243\n",
      "    load_throughput: 37804.616\n",
      "    load_time_ms: 0.846\n",
      "    update_time_ms: 1.848\n",
      "  timestamp: 1632006365\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 331000\n",
      "  training_iteration: 331\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   331</td><td style=\"text-align: right;\">            4932</td><td style=\"text-align: right;\">331000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 332000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-06-18\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 338\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 331624\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 226476527976448.0\n",
      "          mean_q: 41718091087872.0\n",
      "          min_q: 3166478270464.0\n",
      "        mean_td_error: 11119755264.0\n",
      "        td_error: \"[ 2.09881924e+11 -2.27624301e+12  9.48222034e+10 -1.25392912e+11\\n\\\n",
      "          \\ -6.46541476e+10  8.63004262e+10  5.89372693e+12 -5.14994995e+11\\n  4.10404258e+11\\\n",
      "          \\  8.81983488e+10  2.35917017e+11 -2.27624301e+12\\n  8.63004262e+10  2.35917017e+11\\\n",
      "          \\ -1.02312496e+12 -1.31222995e+12\\n -9.88257190e+11 -2.41742905e+11  2.85825040e+11\\\n",
      "          \\  2.35917017e+11\\n  2.35917017e+11  2.35917017e+11  2.85825040e+11 -2.61147853e+10\\n\\\n",
      "          \\ -1.96922573e+12 -6.46541476e+10  2.85825040e+11  5.89372693e+12\\n -7.62478854e+11\\\n",
      "          \\  7.89240087e+11 -2.27624301e+12 -1.31222995e+12]\"\n",
      "    num_agent_steps_sampled: 332000\n",
      "    num_agent_steps_trained: 2648032\n",
      "    num_steps_sampled: 332000\n",
      "    num_steps_trained: 2648032\n",
      "    num_target_updates: 657\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.089473684210525\n",
      "    ram_util_percent: 93.35263157894735\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03999128283517287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.764108699994154\n",
      "    mean_inference_ms: 1.5609500261048024\n",
      "    mean_raw_obs_processing_ms: 1.8316893614811809\n",
      "  time_since_restore: 4945.238066673279\n",
      "  time_this_iter_s: 13.234219074249268\n",
      "  time_total_s: 4945.238066673279\n",
      "  timers:\n",
      "    learn_throughput: 3624.391\n",
      "    learn_time_ms: 8.829\n",
      "    load_throughput: 62238.687\n",
      "    load_time_ms: 0.514\n",
      "    update_time_ms: 1.769\n",
      "  timestamp: 1632006378\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 332000\n",
      "  training_iteration: 332\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   332</td><td style=\"text-align: right;\">         4945.24</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 333000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-06-31\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 339\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 332632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 260799843008512.0\n",
      "          mean_q: 59944262959104.0\n",
      "          min_q: 4947282231296.0\n",
      "        mean_td_error: -11113615851520.0\n",
      "        td_error: \"[-3.9830214e+13 -6.7879777e+12 -3.9830214e+13 -1.3047725e+12\\n -3.9830214e+13\\\n",
      "          \\  1.5220815e+12  8.2383261e+11 -3.9830214e+13\\n -3.9830214e+13  2.2451286e+12\\\n",
      "          \\ -1.0721737e+12  1.5220815e+12\\n  2.2451286e+12  1.0503930e+13 -2.4464536e+11\\\n",
      "          \\ -1.7887558e+12\\n  5.7979961e+10  7.9081085e+11  1.0491129e+12 -3.9830214e+13\\n\\\n",
      "          \\ -3.9830214e+13  2.0301155e+12 -6.7879777e+12 -3.9830214e+13\\n  2.0999234e+12\\\n",
      "          \\  2.0301155e+12 -3.9830214e+13 -1.7887558e+12\\n  2.2451286e+12 -1.2881767e+12\\\n",
      "          \\ -6.7879777e+12  1.5220815e+12]\"\n",
      "    num_agent_steps_sampled: 333000\n",
      "    num_agent_steps_trained: 2656032\n",
      "    num_steps_sampled: 333000\n",
      "    num_steps_trained: 2656032\n",
      "    num_target_updates: 659\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.39473684210526\n",
      "    ram_util_percent: 93.32105263157894\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039992381324210506\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.7605005385795165\n",
      "    mean_inference_ms: 1.5609378636322544\n",
      "    mean_raw_obs_processing_ms: 1.8275180588282915\n",
      "  time_since_restore: 4958.469432115555\n",
      "  time_this_iter_s: 13.231365442276001\n",
      "  time_total_s: 4958.469432115555\n",
      "  timers:\n",
      "    learn_throughput: 3385.071\n",
      "    learn_time_ms: 9.453\n",
      "    load_throughput: 53663.479\n",
      "    load_time_ms: 0.596\n",
      "    update_time_ms: 1.942\n",
      "  timestamp: 1632006391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 333000\n",
      "  training_iteration: 333\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   333</td><td style=\"text-align: right;\">         4958.47</td><td style=\"text-align: right;\">333000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 334000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-06-45\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 340\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 333640\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 289383521452032.0\n",
      "          mean_q: 33528888688640.0\n",
      "          min_q: 6166922919936.0\n",
      "        mean_td_error: -5893274468352.0\n",
      "        td_error: \"[-4.7468960e+13  4.9513308e+12  4.6486221e+12 -3.2456625e+12\\n -4.7468960e+13\\\n",
      "          \\  4.8897269e+12 -4.7468960e+13 -4.7468960e+13\\n  3.5335910e+12  4.8897269e+12\\\n",
      "          \\ -1.9148308e+12 -3.3205697e+12\\n -1.1963308e+12  4.6486221e+12  3.5335910e+12\\\n",
      "          \\  7.1490653e+11\\n -4.7468960e+13  4.9513308e+12 -1.6576560e+12  1.1118915e+13\\n\\\n",
      "          \\ -1.9477740e+12  1.1118915e+13  4.8897269e+12 -9.7946383e+11\\n -1.9510791e+12\\\n",
      "          \\ -1.9148308e+12  4.9954370e+12  4.9513308e+12\\n -3.3205697e+12 -5.9562105e+11\\\n",
      "          \\ -1.0803059e+12 -1.9510791e+12]\"\n",
      "    num_agent_steps_sampled: 334000\n",
      "    num_agent_steps_trained: 2664032\n",
      "    num_steps_sampled: 334000\n",
      "    num_steps_trained: 2664032\n",
      "    num_target_updates: 661\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.66842105263158\n",
      "    ram_util_percent: 93.52631578947367\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03999353676180385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.756881730620125\n",
      "    mean_inference_ms: 1.5609274517503937\n",
      "    mean_raw_obs_processing_ms: 1.8233837617480035\n",
      "  time_since_restore: 4971.664237499237\n",
      "  time_this_iter_s: 13.194805383682251\n",
      "  time_total_s: 4971.664237499237\n",
      "  timers:\n",
      "    learn_throughput: 3375.545\n",
      "    learn_time_ms: 9.48\n",
      "    load_throughput: 47672.703\n",
      "    load_time_ms: 0.671\n",
      "    update_time_ms: 1.743\n",
      "  timestamp: 1632006405\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 334000\n",
      "  training_iteration: 334\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   334</td><td style=\"text-align: right;\">         4971.66</td><td style=\"text-align: right;\">334000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 335000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-06-58\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 341\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 334648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 220310179676160.0\n",
      "          mean_q: 32643028615168.0\n",
      "          min_q: 8001786740736.0\n",
      "        mean_td_error: -10219353538560.0\n",
      "        td_error: \"[ 5.0120360e+11  5.0120360e+11 -4.8894134e+13  1.5053724e+12\\n -1.3251201e+12\\\n",
      "          \\  3.6621223e+12  3.6621223e+12 -1.3251201e+12\\n -4.8894134e+13 -1.3251201e+12\\\n",
      "          \\  4.5372513e+11 -2.2450778e+12\\n -4.8894134e+13 -6.3405294e+11 -6.8226227e+11\\\n",
      "          \\ -4.8570565e+11\\n  2.1323842e+12  3.6621223e+12 -1.6765084e+12 -4.8894134e+13\\n\\\n",
      "          \\  1.7188588e+12 -4.8894134e+13  3.1128363e+12 -4.8894134e+13\\n  2.9962619e+12\\\n",
      "          \\ -4.8894134e+13 -6.8226227e+11  1.5053724e+12\\n -1.6765084e+12  4.5372513e+11\\\n",
      "          \\  3.6010386e+12 -2.1709801e+12]\"\n",
      "    num_agent_steps_sampled: 335000\n",
      "    num_agent_steps_trained: 2672032\n",
      "    num_steps_sampled: 335000\n",
      "    num_steps_trained: 2672032\n",
      "    num_target_updates: 663\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.194736842105264\n",
      "    ram_util_percent: 94.17894736842106\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03999474964225794\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.753279432727193\n",
      "    mean_inference_ms: 1.5609187821768453\n",
      "    mean_raw_obs_processing_ms: 1.8192859853865775\n",
      "  time_since_restore: 4985.298458814621\n",
      "  time_this_iter_s: 13.634221315383911\n",
      "  time_total_s: 4985.298458814621\n",
      "  timers:\n",
      "    learn_throughput: 3614.397\n",
      "    learn_time_ms: 8.853\n",
      "    load_throughput: 60472.056\n",
      "    load_time_ms: 0.529\n",
      "    update_time_ms: 1.735\n",
      "  timestamp: 1632006418\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 335000\n",
      "  training_iteration: 335\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   335</td><td style=\"text-align: right;\">          4985.3</td><td style=\"text-align: right;\">335000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 336000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-07-11\n",
      "  done: false\n",
      "  episode_len_mean: 995.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 342\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 335656\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 321620908441600.0\n",
      "          mean_q: 57373909581824.0\n",
      "          min_q: 7788220645376.0\n",
      "        mean_td_error: -7660888391680.0\n",
      "        td_error: \"[-1.7376477e+11 -2.2575422e+11 -5.8202784e+11 -5.8202784e+11\\n  6.2021173e+11\\\n",
      "          \\  3.2668595e+11  2.3229639e+12 -4.1902599e+13\\n -2.2575422e+11 -4.1902599e+13\\\n",
      "          \\  6.2021173e+11  3.9617508e+11\\n -5.5689871e+09  6.2021173e+11 -4.1902599e+13\\\n",
      "          \\  1.2956467e+12\\n -5.2311359e+10  4.6373169e+11 -9.5284521e+11 -2.2575422e+11\\n\\\n",
      "          \\ -4.1902599e+13  1.2956467e+12  2.3229639e+12 -2.0725283e+12\\n  2.3229639e+12\\\n",
      "          \\ -6.5033522e+11 -4.7741665e+10 -4.1902599e+13\\n -5.8202784e+11 -5.8202784e+11\\\n",
      "          \\  6.2021173e+11 -4.1902599e+13]\"\n",
      "    num_agent_steps_sampled: 336000\n",
      "    num_agent_steps_trained: 2680032\n",
      "    num_steps_sampled: 336000\n",
      "    num_steps_trained: 2680032\n",
      "    num_target_updates: 665\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.784210526315796\n",
      "    ram_util_percent: 94.21052631578948\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.039995946825554726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.7496697345534304\n",
      "    mean_inference_ms: 1.560909257184679\n",
      "    mean_raw_obs_processing_ms: 1.815223782742016\n",
      "  time_since_restore: 4998.255965948105\n",
      "  time_this_iter_s: 12.957507133483887\n",
      "  time_total_s: 4998.255965948105\n",
      "  timers:\n",
      "    learn_throughput: 3627.516\n",
      "    learn_time_ms: 8.821\n",
      "    load_throughput: 64642.743\n",
      "    load_time_ms: 0.495\n",
      "    update_time_ms: 1.738\n",
      "  timestamp: 1632006431\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 336000\n",
      "  training_iteration: 336\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   336</td><td style=\"text-align: right;\">         4998.26</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=192076)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 337000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-07-41\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 343\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 336664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 328353940766720.0\n",
      "          mean_q: 72605851713536.0\n",
      "          min_q: 10495273730048.0\n",
      "        mean_td_error: -2530713010176.0\n",
      "        td_error: \"[-3.3988847e+12 -4.4126794e+12 -2.2623268e+12  5.2012515e+12\\n -5.7222722e+12\\\n",
      "          \\  7.1135165e+12 -6.7052325e+12 -2.7803999e+12\\n  8.9637142e+12 -4.4126794e+12\\\n",
      "          \\ -4.4126794e+12  8.9637142e+12\\n  7.1135165e+12 -7.3808845e+12 -5.5874505e+12\\\n",
      "          \\ -3.3287653e+12\\n  7.0735721e+12 -5.7222722e+12  8.9637142e+12 -2.7803999e+12\\n\\\n",
      "          \\  7.1135165e+12 -7.3808845e+12 -4.0845034e+13 -8.1379249e+11\\n -3.4010447e+12\\\n",
      "          \\ -3.3287653e+12 -4.0845034e+13 -5.7222722e+12\\n  8.9637142e+12  7.1135165e+12\\\n",
      "          \\ -3.4363220e+12  7.1135165e+12]\"\n",
      "    num_agent_steps_sampled: 337000\n",
      "    num_agent_steps_trained: 2688032\n",
      "    num_steps_sampled: 337000\n",
      "    num_steps_trained: 2688032\n",
      "    num_target_updates: 667\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.99285714285714\n",
      "    ram_util_percent: 93.94285714285715\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03999719920408299\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.746061094612747\n",
      "    mean_inference_ms: 1.5609009565178105\n",
      "    mean_raw_obs_processing_ms: 1.8116918432921734\n",
      "  time_since_restore: 5028.1752846241\n",
      "  time_this_iter_s: 29.919318675994873\n",
      "  time_total_s: 5028.1752846241\n",
      "  timers:\n",
      "    learn_throughput: 3695.107\n",
      "    learn_time_ms: 8.66\n",
      "    load_throughput: 64617.846\n",
      "    load_time_ms: 0.495\n",
      "    update_time_ms: 1.731\n",
      "  timestamp: 1632006461\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 337000\n",
      "  training_iteration: 337\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   337</td><td style=\"text-align: right;\">         5028.18</td><td style=\"text-align: right;\">337000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 338000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-07-56\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 344\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 337672\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 348527502819328.0\n",
      "          mean_q: 47044127358976.0\n",
      "          min_q: 10575522299904.0\n",
      "        mean_td_error: -3936948060160.0\n",
      "        td_error: \"[-1.86850161e+12 -4.79060820e+12  3.89149622e+11 -8.97725759e+11\\n\\\n",
      "          \\ -5.48580150e+12 -1.95011228e+12  3.89149622e+11 -4.56554394e+12\\n -1.35462681e+13\\\n",
      "          \\ -1.35462681e+13 -8.97725759e+11 -1.79391116e+12\\n  1.06989355e+11  1.06989355e+11\\\n",
      "          \\ -3.39040692e+12 -1.79391116e+12\\n -8.97725759e+11 -1.79391116e+12 -1.35462681e+13\\\n",
      "          \\ -2.61452779e+12\\n -1.35462681e+13  2.57268122e+10 -3.33169086e+12 -1.35462681e+13\\n\\\n",
      "          \\  3.89149622e+11 -3.34093930e+12 -3.43370682e+12 -3.43370682e+12\\n -6.36966299e+12\\\n",
      "          \\ -3.38630699e+12 -3.43370682e+12 -1.88022260e+11]\"\n",
      "    num_agent_steps_sampled: 338000\n",
      "    num_agent_steps_trained: 2696032\n",
      "    num_steps_sampled: 338000\n",
      "    num_steps_trained: 2696032\n",
      "    num_target_updates: 669\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.36190476190476\n",
      "    ram_util_percent: 93.49047619047617\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03999849269209331\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.742492475919776\n",
      "    mean_inference_ms: 1.560893602650984\n",
      "    mean_raw_obs_processing_ms: 1.8081935366428763\n",
      "  time_since_restore: 5042.622852563858\n",
      "  time_this_iter_s: 14.4475679397583\n",
      "  time_total_s: 5042.622852563858\n",
      "  timers:\n",
      "    learn_throughput: 3699.038\n",
      "    learn_time_ms: 8.651\n",
      "    load_throughput: 64965.018\n",
      "    load_time_ms: 0.493\n",
      "    update_time_ms: 1.72\n",
      "  timestamp: 1632006476\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 338000\n",
      "  training_iteration: 338\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   338</td><td style=\"text-align: right;\">         5042.62</td><td style=\"text-align: right;\">338000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 339000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-08-09\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.02\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 345\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 338680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 355006897192960.0\n",
      "          mean_q: 70389279490048.0\n",
      "          min_q: 10535011614720.0\n",
      "        mean_td_error: 749459734528.0\n",
      "        td_error: \"[-1.91863403e+12  1.19189851e+12  4.83046667e+12  4.83046667e+12\\n\\\n",
      "          \\  1.25940479e+12 -4.14892163e+11  3.97716278e+12  1.19528856e+12\\n  4.83046667e+12\\\n",
      "          \\ -5.30373935e+11 -3.42774042e+12  2.17486406e+12\\n  1.98593584e+12 -2.89127216e+12\\\n",
      "          \\  1.25940479e+12  1.25940479e+12\\n  1.25940479e+12  1.02498094e+12  2.17486406e+12\\\n",
      "          \\ -6.14633308e+10\\n -1.36351475e+12 -2.89127216e+12  1.19528856e+12  4.83046667e+12\\n\\\n",
      "          \\  1.19528856e+12 -2.89097436e+12 -8.24910545e+11 -4.14892163e+11\\n -2.89097436e+12\\\n",
      "          \\ -1.32233822e+11  1.98593584e+12  2.17486406e+12]\"\n",
      "    num_agent_steps_sampled: 339000\n",
      "    num_agent_steps_trained: 2704032\n",
      "    num_steps_sampled: 339000\n",
      "    num_steps_trained: 2704032\n",
      "    num_target_updates: 671\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.0578947368421\n",
      "    ram_util_percent: 94.00526315789475\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0399998544916654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.73893449577903\n",
      "    mean_inference_ms: 1.5608878561890884\n",
      "    mean_raw_obs_processing_ms: 1.8047282161987073\n",
      "  time_since_restore: 5056.105883598328\n",
      "  time_this_iter_s: 13.483031034469604\n",
      "  time_total_s: 5056.105883598328\n",
      "  timers:\n",
      "    learn_throughput: 3590.044\n",
      "    learn_time_ms: 8.914\n",
      "    load_throughput: 60668.864\n",
      "    load_time_ms: 0.527\n",
      "    update_time_ms: 1.771\n",
      "  timestamp: 1632006489\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 339000\n",
      "  training_iteration: 339\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   339</td><td style=\"text-align: right;\">         5056.11</td><td style=\"text-align: right;\">339000</td><td style=\"text-align: right;\">   -0.02</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 340000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-08-22\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 346\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 339688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 358568834367488.0\n",
      "          mean_q: 98710998482944.0\n",
      "          min_q: 10835066880000.0\n",
      "        mean_td_error: 111533293568.0\n",
      "        td_error: \"[-1.5832868e+11  4.0648678e+12  4.0648678e+12 -2.8792261e+12\\n  2.7227387e+12\\\n",
      "          \\ -1.5832868e+11  1.1933969e+12  2.1962047e+12\\n -1.5832868e+11 -1.5947918e+12\\\n",
      "          \\  1.1933969e+12 -2.0479570e+12\\n -1.5947918e+12 -7.2546989e+12  1.1933969e+12\\\n",
      "          \\ -2.2819740e+11\\n  4.0648678e+12  1.1933969e+12 -1.3230460e+12  5.9773655e+11\\n\\\n",
      "          \\  1.1866944e+11  1.1933969e+12  1.1866944e+11 -2.2819740e+11\\n -1.5832868e+11\\\n",
      "          \\ -3.3741267e+12  2.7227387e+12 -3.3741267e+12\\n  2.7227387e+12 -4.3218318e+11\\\n",
      "          \\  4.9568494e+11 -1.3230460e+12]\"\n",
      "    num_agent_steps_sampled: 340000\n",
      "    num_agent_steps_trained: 2712032\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 2712032\n",
      "    num_target_updates: 673\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.64736842105263\n",
      "    ram_util_percent: 94.13157894736841\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040001278921182465\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.735377380225061\n",
      "    mean_inference_ms: 1.5608838123155409\n",
      "    mean_raw_obs_processing_ms: 1.8012955210364412\n",
      "  time_since_restore: 5069.136151790619\n",
      "  time_this_iter_s: 13.03026819229126\n",
      "  time_total_s: 5069.136151790619\n",
      "  timers:\n",
      "    learn_throughput: 3639.793\n",
      "    learn_time_ms: 8.792\n",
      "    load_throughput: 60442.1\n",
      "    load_time_ms: 0.529\n",
      "    update_time_ms: 1.741\n",
      "  timestamp: 1632006502\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 340\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   340</td><td style=\"text-align: right;\">         5069.14</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 341000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-08-35\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 347\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 340696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 359324245295104.0\n",
      "          mean_q: 56743388250112.0\n",
      "          min_q: 18748887007232.0\n",
      "        mean_td_error: 3016510406656.0\n",
      "        td_error: \"[ 5.92265085e+11  1.55992038e+12  1.08495530e+13  5.86858627e+11\\n\\\n",
      "          \\  3.37875514e+12  1.09617296e+12  1.17993741e+12  1.00678395e+12\\n  2.92391957e+12\\\n",
      "          \\  1.00678395e+12  1.08495530e+13  4.63028722e+12\\n  1.08495530e+13  2.92391957e+12\\\n",
      "          \\ -2.11066185e+12  7.86759575e+12\\n  7.86759575e+12  2.92391957e+12  2.92391957e+12\\\n",
      "          \\  2.92391957e+12\\n -1.97178006e+12  5.95043811e+12 -1.37682223e+12 -1.37682223e+12\\n\\\n",
      "          \\  3.04271589e+11  1.17599896e+12  4.63028722e+12  5.09842817e+11\\n  3.37875514e+12\\\n",
      "          \\  1.09617296e+12  7.86759575e+12  5.09842817e+11]\"\n",
      "    num_agent_steps_sampled: 341000\n",
      "    num_agent_steps_trained: 2720032\n",
      "    num_steps_sampled: 341000\n",
      "    num_steps_trained: 2720032\n",
      "    num_target_updates: 675\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.43888888888889\n",
      "    ram_util_percent: 94.0388888888889\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040002714870034255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.7318005171277555\n",
      "    mean_inference_ms: 1.560879526068065\n",
      "    mean_raw_obs_processing_ms: 1.7978951294346386\n",
      "  time_since_restore: 5082.000799655914\n",
      "  time_this_iter_s: 12.86464786529541\n",
      "  time_total_s: 5082.000799655914\n",
      "  timers:\n",
      "    learn_throughput: 3482.132\n",
      "    learn_time_ms: 9.19\n",
      "    load_throughput: 64209.792\n",
      "    load_time_ms: 0.498\n",
      "    update_time_ms: 1.759\n",
      "  timestamp: 1632006515\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 341000\n",
      "  training_iteration: 341\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   341</td><td style=\"text-align: right;\">            5082</td><td style=\"text-align: right;\">341000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 342000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-08-48\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 348\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 341704\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 355719660437504.0\n",
      "          mean_q: 82391632707584.0\n",
      "          min_q: 15153506549760.0\n",
      "        mean_td_error: -5682806915072.0\n",
      "        td_error: \"[-8.0612552e+12 -8.0612552e+12 -8.0612552e+12 -7.9604702e+12\\n -8.3316577e+12\\\n",
      "          \\  1.3930508e+13 -3.9210367e+12 -7.9604702e+12\\n -1.7474741e+13 -6.2581994e+12\\\n",
      "          \\  1.4321451e+11 -5.3203907e+12\\n -7.9604702e+12 -8.0612552e+12 -3.9210367e+12\\\n",
      "          \\ -1.7474741e+13\\n -5.9979134e+12 -2.5687994e+12 -7.9616404e+12 -5.9979134e+12\\n\\\n",
      "          \\ -1.0031337e+13 -6.1109803e+12 -5.8341426e+12 -1.0584339e+13\\n -1.1380690e+13\\\n",
      "          \\ -8.0612552e+12 -2.5687994e+12 -6.2581994e+12\\n -5.2442138e+12  1.3930508e+13\\\n",
      "          \\ -2.5687994e+12  1.4321451e+11]\"\n",
      "    num_agent_steps_sampled: 342000\n",
      "    num_agent_steps_trained: 2728032\n",
      "    num_steps_sampled: 342000\n",
      "    num_steps_trained: 2728032\n",
      "    num_target_updates: 677\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.72105263157895\n",
      "    ram_util_percent: 93.84210526315789\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04000409393491403\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.72818657898645\n",
      "    mean_inference_ms: 1.560873050753172\n",
      "    mean_raw_obs_processing_ms: 1.7945264224242579\n",
      "  time_since_restore: 5094.908942222595\n",
      "  time_this_iter_s: 12.908142566680908\n",
      "  time_total_s: 5094.908942222595\n",
      "  timers:\n",
      "    learn_throughput: 3594.447\n",
      "    learn_time_ms: 8.903\n",
      "    load_throughput: 64222.081\n",
      "    load_time_ms: 0.498\n",
      "    update_time_ms: 1.782\n",
      "  timestamp: 1632006528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 342000\n",
      "  training_iteration: 342\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   342</td><td style=\"text-align: right;\">         5094.91</td><td style=\"text-align: right;\">342000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 343000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-09-01\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 349\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 342712\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 212835225305088.0\n",
      "          mean_q: 72133195595776.0\n",
      "          min_q: 19462610747392.0\n",
      "        mean_td_error: -1316435525632.0\n",
      "        td_error: \"[-3.0076431e+12  4.4153606e+12  6.6616662e+11 -2.8825774e+12\\n -4.8234035e+12\\\n",
      "          \\  1.2663338e+12  6.6616662e+11 -3.6464398e+12\\n -1.3357768e+12 -3.6126715e+12\\\n",
      "          \\ -3.9331750e+12 -2.8825774e+12\\n  6.6616662e+11 -1.3357768e+12 -1.0662592e+12\\\n",
      "          \\  1.2663338e+12\\n -3.1322832e+12 -5.3462444e+12 -1.0662592e+12 -4.3621894e+12\\n\\\n",
      "          \\  4.4153606e+12 -3.1322832e+12 -3.9331750e+12  6.6616662e+11\\n -2.8825774e+12\\\n",
      "          \\  6.8569321e+11 -2.8825774e+12  6.6616662e+11\\n  4.6530266e+12 -1.0662592e+12\\\n",
      "          \\ -2.8210889e+12 -3.0076431e+12]\"\n",
      "    num_agent_steps_sampled: 343000\n",
      "    num_agent_steps_trained: 2736032\n",
      "    num_steps_sampled: 343000\n",
      "    num_steps_trained: 2736032\n",
      "    num_target_updates: 679\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.33888888888889\n",
      "    ram_util_percent: 93.78888888888889\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04000548431045952\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.724554755926482\n",
      "    mean_inference_ms: 1.5608669097781143\n",
      "    mean_raw_obs_processing_ms: 1.7911894898100378\n",
      "  time_since_restore: 5107.930325746536\n",
      "  time_this_iter_s: 13.02138352394104\n",
      "  time_total_s: 5107.930325746536\n",
      "  timers:\n",
      "    learn_throughput: 3674.118\n",
      "    learn_time_ms: 8.71\n",
      "    load_throughput: 62235.801\n",
      "    load_time_ms: 0.514\n",
      "    update_time_ms: 1.744\n",
      "  timestamp: 1632006541\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 343000\n",
      "  training_iteration: 343\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   343</td><td style=\"text-align: right;\">         5107.93</td><td style=\"text-align: right;\">343000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 344000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-09-14\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 350\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 343720\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 361657519833088.0\n",
      "          mean_q: 69876924284928.0\n",
      "          min_q: 23404103073792.0\n",
      "        mean_td_error: -3615563710464.0\n",
      "        td_error: \"[-3.9493818e+12 -7.0819103e+12 -6.6412861e+12 -7.0819103e+12\\n -6.5993724e+12\\\n",
      "          \\  9.2051970e+11 -6.5993724e+12 -3.9284271e+12\\n -6.5993724e+12 -3.9140721e+12\\\n",
      "          \\ -3.9493818e+12  5.4388798e+12\\n -3.5338689e+11 -6.5993724e+12 -6.6412861e+12\\\n",
      "          \\ -4.6485052e+12\\n -3.9284271e+12 -8.0386353e+12  1.7248446e+11 -6.6412861e+12\\n\\\n",
      "          \\  4.8200103e+12 -3.9140721e+12  1.8430820e+11 -1.3664015e+12\\n -6.6595733e+12\\\n",
      "          \\ -3.9284271e+12 -7.0819103e+12 -1.3664015e+12\\n -7.0819103e+12  4.8200103e+12\\\n",
      "          \\ -7.0819103e+12 -3.7825911e+11]\"\n",
      "    num_agent_steps_sampled: 344000\n",
      "    num_agent_steps_trained: 2744032\n",
      "    num_steps_sampled: 344000\n",
      "    num_steps_trained: 2744032\n",
      "    num_target_updates: 681\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.09473684210527\n",
      "    ram_util_percent: 93.84736842105262\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04000691033346199\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.720913557330646\n",
      "    mean_inference_ms: 1.5608619578874714\n",
      "    mean_raw_obs_processing_ms: 1.7878840017887965\n",
      "  time_since_restore: 5121.092513561249\n",
      "  time_this_iter_s: 13.162187814712524\n",
      "  time_total_s: 5121.092513561249\n",
      "  timers:\n",
      "    learn_throughput: 3451.081\n",
      "    learn_time_ms: 9.272\n",
      "    load_throughput: 54758.161\n",
      "    load_time_ms: 0.584\n",
      "    update_time_ms: 1.717\n",
      "  timestamp: 1632006554\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 344000\n",
      "  training_iteration: 344\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   344</td><td style=\"text-align: right;\">         5121.09</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 345000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-09-28\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 351\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 344728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 358820895260672.0\n",
      "          mean_q: 112694271148032.0\n",
      "          min_q: 42732873580544.0\n",
      "        mean_td_error: 1109123530752.0\n",
      "        td_error: \"[ 1.4294272e+12 -2.3008274e+12  1.3718981e+12 -1.4964186e+12\\n -1.4499038e+12\\\n",
      "          \\ -8.8769928e+11 -2.3008274e+12  1.2574943e+13\\n -1.4499038e+12  1.6845663e+13\\\n",
      "          \\  1.9459557e+12 -1.4499038e+12\\n -8.8769928e+11 -2.2985625e+11  1.6845663e+13\\\n",
      "          \\ -2.3008274e+12\\n -2.3008274e+12 -8.8769928e+11 -1.4499038e+12  1.4294272e+12\\n\\\n",
      "          \\ -7.0405461e+12  8.5726876e+12 -1.4499038e+12  1.3388596e+12\\n -1.4499038e+12\\\n",
      "          \\ -8.8769928e+11 -1.4499038e+12  1.3388596e+12\\n  8.6720591e+11  8.6720591e+11\\\n",
      "          \\  8.6720591e+11  8.6720591e+11]\"\n",
      "    num_agent_steps_sampled: 345000\n",
      "    num_agent_steps_trained: 2752032\n",
      "    num_steps_sampled: 345000\n",
      "    num_steps_trained: 2752032\n",
      "    num_target_updates: 683\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.72631578947368\n",
      "    ram_util_percent: 93.75263157894737\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04000830092438552\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.717253210941459\n",
      "    mean_inference_ms: 1.5608555405700346\n",
      "    mean_raw_obs_processing_ms: 1.7846088815480061\n",
      "  time_since_restore: 5134.417971611023\n",
      "  time_this_iter_s: 13.32545804977417\n",
      "  time_total_s: 5134.417971611023\n",
      "  timers:\n",
      "    learn_throughput: 3630.98\n",
      "    learn_time_ms: 8.813\n",
      "    load_throughput: 63262.504\n",
      "    load_time_ms: 0.506\n",
      "    update_time_ms: 1.783\n",
      "  timestamp: 1632006568\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 345000\n",
      "  training_iteration: 345\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   345</td><td style=\"text-align: right;\">         5134.42</td><td style=\"text-align: right;\">345000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 346000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-09-41\n",
      "  done: false\n",
      "  episode_len_mean: 994.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 352\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 345736\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 352232750972928.0\n",
      "          mean_q: 168548055908352.0\n",
      "          min_q: 43596606603264.0\n",
      "        mean_td_error: -7208998797312.0\n",
      "        td_error: \"[-9.6387455e+12 -9.6387455e+12 -9.4051731e+12 -5.3764183e+12\\n -4.3197766e+12\\\n",
      "          \\ -1.2617070e+13 -2.2390872e+12 -9.6387455e+12\\n -4.5265600e+12 -4.5265600e+12\\\n",
      "          \\ -4.4320078e+12  2.0376013e+12\\n -9.6387455e+12 -1.0345620e+13 -4.5265600e+12\\\n",
      "          \\ -1.2617070e+13\\n -4.5265600e+12  8.0653110e+11 -5.8943267e+12 -1.0495323e+13\\n\\\n",
      "          \\ -1.0495323e+13 -5.9891977e+12 -1.0918847e+13 -1.2617070e+13\\n -1.0345620e+13\\\n",
      "          \\ -2.2390872e+12 -1.0345620e+13 -1.1409732e+13\\n -4.5265600e+12 -1.1409732e+13\\\n",
      "          \\ -9.6387455e+12  8.0653110e+11]\"\n",
      "    num_agent_steps_sampled: 346000\n",
      "    num_agent_steps_trained: 2760032\n",
      "    num_steps_sampled: 346000\n",
      "    num_steps_trained: 2760032\n",
      "    num_target_updates: 685\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.59473684210527\n",
      "    ram_util_percent: 93.77894736842104\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04000968883245913\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.713571502769394\n",
      "    mean_inference_ms: 1.560848914118777\n",
      "    mean_raw_obs_processing_ms: 1.7813644303276848\n",
      "  time_since_restore: 5147.749538183212\n",
      "  time_this_iter_s: 13.331566572189331\n",
      "  time_total_s: 5147.749538183212\n",
      "  timers:\n",
      "    learn_throughput: 3586.523\n",
      "    learn_time_ms: 8.922\n",
      "    load_throughput: 65912.551\n",
      "    load_time_ms: 0.485\n",
      "    update_time_ms: 1.794\n",
      "  timestamp: 1632006581\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 346000\n",
      "  training_iteration: 346\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   346</td><td style=\"text-align: right;\">         5147.75</td><td style=\"text-align: right;\">346000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            994.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 347000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-09-55\n",
      "  done: false\n",
      "  episode_len_mean: 995.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 353\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 346744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 352115109134336.0\n",
      "          mean_q: 112552050688000.0\n",
      "          min_q: 44878532706304.0\n",
      "        mean_td_error: 545720893440.0\n",
      "        td_error: \"[-9.70360619e+11  6.41175703e+12 -1.02679917e+12 -1.72653910e+12\\n\\\n",
      "          \\ -3.39856484e+12 -1.02679917e+12 -3.30785043e+12 -4.55179292e+12\\n  3.10311387e+11\\\n",
      "          \\ -1.72653910e+12  2.81790120e+12  8.85870559e+11\\n  6.27071097e+12 -9.70360619e+11\\\n",
      "          \\  8.85870559e+11  6.27071097e+12\\n  1.68496936e+12 -5.41046342e+12 -1.06959785e+12\\\n",
      "          \\  6.27071097e+12\\n  6.27071097e+12  6.27071097e+12 -3.39856484e+12  1.80308935e+11\\n\\\n",
      "          \\  8.85870559e+11 -1.17687976e+12  9.69823748e+11  1.80308935e+11\\n  1.68496936e+12\\\n",
      "          \\ -9.70360619e+11  9.69823748e+11 -1.02679917e+12]\"\n",
      "    num_agent_steps_sampled: 347000\n",
      "    num_agent_steps_trained: 2768032\n",
      "    num_steps_sampled: 347000\n",
      "    num_steps_trained: 2768032\n",
      "    num_target_updates: 687\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.45789473684211\n",
      "    ram_util_percent: 93.94210526315791\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04001111024782657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.709888225716757\n",
      "    mean_inference_ms: 1.5608430696263762\n",
      "    mean_raw_obs_processing_ms: 1.7774510124188907\n",
      "  time_since_restore: 5161.197042226791\n",
      "  time_this_iter_s: 13.447504043579102\n",
      "  time_total_s: 5161.197042226791\n",
      "  timers:\n",
      "    learn_throughput: 3701.955\n",
      "    learn_time_ms: 8.644\n",
      "    load_throughput: 65577.626\n",
      "    load_time_ms: 0.488\n",
      "    update_time_ms: 1.766\n",
      "  timestamp: 1632006595\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 347000\n",
      "  training_iteration: 347\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   347</td><td style=\"text-align: right;\">          5161.2</td><td style=\"text-align: right;\">347000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 348000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-10-08\n",
      "  done: false\n",
      "  episode_len_mean: 995.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 354\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 347752\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 345976191582208.0\n",
      "          mean_q: 110004514324480.0\n",
      "          min_q: 50611106086912.0\n",
      "        mean_td_error: 194091286528.0\n",
      "        td_error: \"[ 4.8921439e+12 -6.0153030e+11 -7.2867224e+12  1.1017627e+13\\n -6.3160262e+12\\\n",
      "          \\ -6.3160262e+12  4.8921439e+12 -3.0813706e+12\\n  4.8921439e+12  4.8921439e+12\\\n",
      "          \\ -3.0813706e+12 -4.6440341e+12\\n  4.8921439e+12 -3.8174206e+12  4.8921439e+12\\\n",
      "          \\  4.8921439e+12\\n -4.6440341e+12 -3.0813706e+12 -6.3160262e+12  4.8921439e+12\\n\\\n",
      "          \\  4.8921439e+12 -2.0721036e+12 -2.1639421e+12  1.1017627e+13\\n  2.8602427e+12\\\n",
      "          \\ -2.0721036e+12  2.8602427e+12  4.8921439e+12\\n -6.3160262e+12 -5.2003665e+12\\\n",
      "          \\ -6.3160262e+12  2.8602427e+12]\"\n",
      "    num_agent_steps_sampled: 348000\n",
      "    num_agent_steps_trained: 2776032\n",
      "    num_steps_sampled: 348000\n",
      "    num_steps_trained: 2776032\n",
      "    num_target_updates: 689\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.27368421052631\n",
      "    ram_util_percent: 94.01052631578948\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040012549887124924\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.70621878973609\n",
      "    mean_inference_ms: 1.56083789717869\n",
      "    mean_raw_obs_processing_ms: 1.7735702452354574\n",
      "  time_since_restore: 5174.45894575119\n",
      "  time_this_iter_s: 13.261903524398804\n",
      "  time_total_s: 5174.45894575119\n",
      "  timers:\n",
      "    learn_throughput: 3675.396\n",
      "    learn_time_ms: 8.707\n",
      "    load_throughput: 65548.803\n",
      "    load_time_ms: 0.488\n",
      "    update_time_ms: 1.676\n",
      "  timestamp: 1632006608\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 348000\n",
      "  training_iteration: 348\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   348</td><td style=\"text-align: right;\">         5174.46</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 349000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-10-21\n",
      "  done: false\n",
      "  episode_len_mean: 995.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 355\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 348760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 350710688382976.0\n",
      "          mean_q: 155946739302400.0\n",
      "          min_q: 51867988000768.0\n",
      "        mean_td_error: 3805382967296.0\n",
      "        td_error: \"[-7.8948545e+11  4.4057473e+12 -3.1875704e+12  5.6943046e+12\\n  1.1809818e+13\\\n",
      "          \\  1.1809818e+13  6.1835198e+12  1.1739320e+13\\n  1.3666099e+13  5.8843401e+12\\\n",
      "          \\  5.8843401e+12  1.3666099e+13\\n -6.9377689e+12 -4.0018945e+12 -2.8437884e+12\\\n",
      "          \\  6.7901420e+12\\n  1.1809818e+13 -4.4844114e+12 -2.3765472e+12 -3.1875704e+12\\n\\\n",
      "          \\ -1.8465339e+12  1.1739320e+13  4.4057473e+12  4.4057473e+12\\n  1.1739320e+13\\\n",
      "          \\ -4.0018945e+12  5.8843401e+12  7.9605373e+11\\n  6.7901420e+12  6.7537899e+12\\\n",
      "          \\ -3.2405360e+12 -3.1875704e+12]\"\n",
      "    num_agent_steps_sampled: 349000\n",
      "    num_agent_steps_trained: 2784032\n",
      "    num_steps_sampled: 349000\n",
      "    num_steps_trained: 2784032\n",
      "    num_target_updates: 691\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.352631578947374\n",
      "    ram_util_percent: 94.05263157894736\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040014025896644344\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.702573591572383\n",
      "    mean_inference_ms: 1.5608337584994192\n",
      "    mean_raw_obs_processing_ms: 1.769721499015338\n",
      "  time_since_restore: 5187.830730199814\n",
      "  time_this_iter_s: 13.371784448623657\n",
      "  time_total_s: 5187.830730199814\n",
      "  timers:\n",
      "    learn_throughput: 3667.953\n",
      "    learn_time_ms: 8.724\n",
      "    load_throughput: 58480.122\n",
      "    load_time_ms: 0.547\n",
      "    update_time_ms: 1.777\n",
      "  timestamp: 1632006621\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 349000\n",
      "  training_iteration: 349\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   349</td><td style=\"text-align: right;\">         5187.83</td><td style=\"text-align: right;\">349000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 350000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-10-34\n",
      "  done: false\n",
      "  episode_len_mean: 995.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 356\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 349768\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 337898700275712.0\n",
      "          mean_q: 182682709393408.0\n",
      "          min_q: 40777526804480.0\n",
      "        mean_td_error: 2734591836160.0\n",
      "        td_error: \"[-2.6285871e+12  4.8187520e+12  3.0360553e+12 -8.4825185e+11\\n  4.8801566e+12\\\n",
      "          \\  4.9901270e+12  4.9901270e+12  4.8801566e+12\\n  6.1341696e+12  3.0360553e+12\\\n",
      "          \\  6.1341696e+12  4.8801566e+12\\n  4.8187520e+12  4.0077581e+12  3.0806827e+12\\\n",
      "          \\  4.8187520e+12\\n -7.4321221e+12  4.8801566e+12 -7.6202073e+12  4.9901270e+12\\n\\\n",
      "          \\  7.1427068e+12  6.1341696e+12  6.6554713e+12  4.8187520e+12\\n -7.4321221e+12\\\n",
      "          \\  6.6554713e+12  3.0806827e+12  4.1272622e+12\\n -7.6202073e+12  4.8187520e+12\\\n",
      "          \\ -8.4825185e+11  4.1272622e+12]\"\n",
      "    num_agent_steps_sampled: 350000\n",
      "    num_agent_steps_trained: 2792032\n",
      "    num_steps_sampled: 350000\n",
      "    num_steps_trained: 2792032\n",
      "    num_target_updates: 693\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.88421052631579\n",
      "    ram_util_percent: 94.13157894736841\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04001551185241959\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.698944473558189\n",
      "    mean_inference_ms: 1.5608299827789653\n",
      "    mean_raw_obs_processing_ms: 1.7659048924843632\n",
      "  time_since_restore: 5200.940416097641\n",
      "  time_this_iter_s: 13.109685897827148\n",
      "  time_total_s: 5200.940416097641\n",
      "  timers:\n",
      "    learn_throughput: 3601.633\n",
      "    learn_time_ms: 8.885\n",
      "    load_throughput: 60079.556\n",
      "    load_time_ms: 0.533\n",
      "    update_time_ms: 1.79\n",
      "  timestamp: 1632006634\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 350000\n",
      "  training_iteration: 350\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   350</td><td style=\"text-align: right;\">         5200.94</td><td style=\"text-align: right;\">350000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 351000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-10-47\n",
      "  done: false\n",
      "  episode_len_mean: 995.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 357\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 350776\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 330558970265600.0\n",
      "          mean_q: 159590700285952.0\n",
      "          min_q: 40866529935360.0\n",
      "        mean_td_error: 1062244188160.0\n",
      "        td_error: \"[ 3.3198084e+12  3.3198084e+12  1.6040109e+12  3.3198084e+12\\n  5.5834239e+12\\\n",
      "          \\  3.3198084e+12  5.5834239e+12  1.6040109e+12\\n  5.5834239e+12  3.3147417e+12\\\n",
      "          \\ -5.3560004e+12  3.6958194e+12\\n -5.8708512e+12 -6.1160670e+12 -5.3560004e+12\\\n",
      "          \\ -6.1160670e+12\\n -4.2054944e+12  6.4419812e+12  3.3198084e+12 -6.1160670e+12\\n\\\n",
      "          \\  1.6040109e+12  6.4419812e+12  3.6958194e+12  6.4419812e+12\\n  2.9680405e+12\\\n",
      "          \\ -4.2054944e+12 -5.8708512e+12  3.3147417e+12\\n  2.9680405e+12 -6.1160670e+12\\\n",
      "          \\  6.4419812e+12  5.4342996e+12]\"\n",
      "    num_agent_steps_sampled: 351000\n",
      "    num_agent_steps_trained: 2800032\n",
      "    num_steps_sampled: 351000\n",
      "    num_steps_trained: 2800032\n",
      "    num_target_updates: 695\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.91052631578947\n",
      "    ram_util_percent: 94.14736842105262\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.040017001051747804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.695329617905544\n",
      "    mean_inference_ms: 1.5608265433783737\n",
      "    mean_raw_obs_processing_ms: 1.7621200727439785\n",
      "  time_since_restore: 5214.017027378082\n",
      "  time_this_iter_s: 13.076611280441284\n",
      "  time_total_s: 5214.017027378082\n",
      "  timers:\n",
      "    learn_throughput: 3666.52\n",
      "    learn_time_ms: 8.728\n",
      "    load_throughput: 64246.675\n",
      "    load_time_ms: 0.498\n",
      "    update_time_ms: 1.781\n",
      "  timestamp: 1632006647\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 351000\n",
      "  training_iteration: 351\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   351</td><td style=\"text-align: right;\">         5214.02</td><td style=\"text-align: right;\">351000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_my_env_79012_00000:\n",
      "  agent_timesteps_total: 352000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-09-18_23-11-01\n",
      "  done: false\n",
      "  episode_len_mean: 995.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 1\n",
      "  episodes_total: 358\n",
      "  experiment_id: 98a41dadbf62479daa2164e8e1e6c341\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    last_target_update_ts: 351784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005\n",
      "          max_q: 323968812711936.0\n",
      "          mean_q: 151137013465088.0\n",
      "          min_q: 46382425571328.0\n",
      "        mean_td_error: -96602161152.0\n",
      "        td_error: \"[-1.1834313e+12  9.6820475e+11  2.3339540e+12  2.2371117e+12\\n  2.2371117e+12\\\n",
      "          \\  1.7532568e+12 -1.5168281e+11 -2.1350140e+12\\n  2.3339540e+12  9.6820475e+11\\\n",
      "          \\  1.7532568e+12 -1.1834313e+12\\n  1.9062441e+12 -4.3291844e+12  9.6820475e+11\\\n",
      "          \\ -1.0158940e+12\\n -4.3291844e+12 -1.1834313e+12 -4.3291844e+12  2.3339540e+12\\n\\\n",
      "          \\ -1.5168281e+11  1.9476460e+12 -2.1547230e+12  1.9062441e+12\\n -1.1834313e+12\\\n",
      "          \\  9.6820475e+11 -1.1834313e+12 -1.1834313e+12\\n -2.1547230e+12  2.2371117e+12\\\n",
      "          \\ -4.3291844e+12  2.2371117e+12]\"\n",
      "    num_agent_steps_sampled: 352000\n",
      "    num_agent_steps_trained: 2808032\n",
      "    num_steps_sampled: 352000\n",
      "    num_steps_trained: 2808032\n",
      "    num_target_updates: 697\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.757894736842104\n",
      "    ram_util_percent: 94.16842105263159\n",
      "  pid: 192079\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04001850706057953\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.691728038932883\n",
      "    mean_inference_ms: 1.5608235951880394\n",
      "    mean_raw_obs_processing_ms: 1.7583667239742105\n",
      "  time_since_restore: 5227.090800046921\n",
      "  time_this_iter_s: 13.073772668838501\n",
      "  time_total_s: 5227.090800046921\n",
      "  timers:\n",
      "    learn_throughput: 3616.023\n",
      "    learn_time_ms: 8.85\n",
      "    load_throughput: 62051.654\n",
      "    load_time_ms: 0.516\n",
      "    update_time_ms: 1.74\n",
      "  timestamp: 1632006661\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 352000\n",
      "  training_iteration: 352\n",
      "  trial_id: '79012_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/15.6 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/8 CPUs, 1.0/1 GPUs, 0.0/7.71 GiB heap, 0.0/3.85 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/DQN_2021-09-18_21-43-33<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_my_env_79012_00000</td><td>RUNNING </td><td>192.168.3.5:192079</td><td style=\"text-align: right;\">   352</td><td style=\"text-align: right;\">         5227.09</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            995.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 23:11:08,744\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2021-09-18 23:11:08,744\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2021-09-18 23:11:09,049\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "Process _WandbLoggingProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/integration/wandb.py\", line 200, in run\n",
      "    result = self.queue.get()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/util.py\", line 322, in _exit_function\n",
      "    p.join()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n",
      "Process wandb_internal:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/wandb/sdk/internal/internal.py\", line 152, in wandb_internal\n",
      "    thread.join()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_191968/3738382257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         },\n\u001b[0;32m---> 30\u001b[0;31m         loggers=[WandbLogger])\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0mtune_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_staging_grace_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             trial = self.trial_executor.get_next_available_trial(\n\u001b[0;32m--> 675\u001b[0;31m                 timeout=timeout)  # blocking\n\u001b[0m\u001b[1;32m    676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_should_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mfetch_local\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         )\n\u001b[1;32m   1795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "tune.run(DQNTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 1,\n",
    "             \"exploration_config\": {\n",
    "                    # The Exploration class to use.\n",
    "                    \"type\": \"EpsilonGreedy\",\n",
    "                    \"initial_epsilon\": 1.0,\n",
    "                    \"final_epsilon\": 0.02,\n",
    "                    \"epsilon_timesteps\": 200000,  # Timesteps over which to anneal epsilon.\n",
    "             },\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"DQN C17 pretrained (AnnaCNN)\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
