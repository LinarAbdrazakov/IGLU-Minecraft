{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            #nn.ELU(),\n",
    "        )\n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        target_features = target_features.reshape(target_features.shape[0], -1)\n",
    "        features = torch.cat([visual_features, target_features], dim=1)\n",
    "        features = self.policy_network(features)\n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592760ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2362368"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_features_dim = 512\n",
    "target_features_dim = 9 * 11 * 11\n",
    "policy_hidden_dim = 256 \n",
    "\n",
    "policy_network = nn.Sequential(\n",
    "    nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(512, policy_hidden_dim),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "    nn.ELU(),\n",
    "    #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "    #nn.ELU(),\n",
    ")\n",
    "\n",
    "sum(p.numel() for p in policy_network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "tasks = []\n",
    "for i in range(1,156):\n",
    "    if ('C'+str(i)) == 'C38': continue\n",
    "    tasks.append('C'+str(i))\n",
    "    \n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "            \n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=250)\n",
    "    env.update_taskset(TaskSet(preset=tasks))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-11-07 14:13:17,442\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-11-07 14:13:17,458\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id 81db5_00000 but id da758_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=558908)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558908)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO All Tasks 2 pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/da758_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/da758_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211107_141318-da758_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558908)\u001b[0m 2021-11-07 14:13:20,885\tWARNING ppo.py:143 -- `train_batch_size` (5000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1666.\n",
      "\u001b[2m\u001b[36m(pid=558908)\u001b[0m 2021-11-07 14:13:20,885\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=558908)\u001b[0m 2021-11-07 14:13:20,885\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558908)\u001b[0m 2021-11-07 14:13:28,938\tINFO trainable.py:109 -- Trainable.setup took 10.511 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=558908)\u001b[0m 2021-11-07 14:13:28,938\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 9996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-17-03\n",
      "  done: false\n",
      "  episode_len_mean: 99.54545454545455\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.860000000000003\n",
      "  episode_reward_mean: -0.8212121212121217\n",
      "  episode_reward_min: -1.6100000000000012\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 99\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8820862466453487\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007245431269884351\n",
      "          policy_loss: -0.016355366078324808\n",
      "          total_loss: 0.007637977097024265\n",
      "          vf_explained_var: -0.17715410888195038\n",
      "          vf_loss: 0.051365118665206766\n",
      "    num_agent_steps_sampled: 9996\n",
      "    num_agent_steps_trained: 9996\n",
      "    num_steps_sampled: 9996\n",
      "    num_steps_trained: 9996\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.94967320261438\n",
      "    ram_util_percent: 49.699673202614385\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044525879742515276\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 53.92694482804299\n",
      "    mean_inference_ms: 2.8400597351528964\n",
      "    mean_raw_obs_processing_ms: 1.0543486656862708\n",
      "  time_since_restore: 214.07208633422852\n",
      "  time_this_iter_s: 214.07208633422852\n",
      "  time_total_s: 214.07208633422852\n",
      "  timers:\n",
      "    learn_throughput: 936.232\n",
      "    learn_time_ms: 10676.843\n",
      "    load_throughput: 89114.183\n",
      "    load_time_ms: 112.171\n",
      "    sample_throughput: 49.179\n",
      "    sample_time_ms: 203255.566\n",
      "    update_time_ms: 13.113\n",
      "  timestamp: 1636294623\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9996\n",
      "  training_iteration: 1\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         214.072</td><td style=\"text-align: right;\">9996</td><td style=\"text-align: right;\">-0.821212</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           99.5455</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 19992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-19-00\n",
      "  done: false\n",
      "  episode_len_mean: 99.0990099009901\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.610000000000003\n",
      "  episode_reward_mean: -0.7611881188118819\n",
      "  episode_reward_min: -1.6100000000000012\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 200\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.871961500705817\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00986026421275549\n",
      "          policy_loss: -0.02017569362034655\n",
      "          total_loss: 0.0231408148812942\n",
      "          vf_explained_var: -0.02427317015826702\n",
      "          vf_loss: 0.07006406934661233\n",
      "    num_agent_steps_sampled: 19992\n",
      "    num_agent_steps_trained: 19992\n",
      "    num_steps_sampled: 19992\n",
      "    num_steps_trained: 19992\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04047619047618\n",
      "    ram_util_percent: 55.783333333333324\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0459362979871434\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.558430122358544\n",
      "    mean_inference_ms: 2.885848629575845\n",
      "    mean_raw_obs_processing_ms: 0.8123051082208768\n",
      "  time_since_restore: 331.5330717563629\n",
      "  time_this_iter_s: 117.4609854221344\n",
      "  time_total_s: 331.5330717563629\n",
      "  timers:\n",
      "    learn_throughput: 935.366\n",
      "    learn_time_ms: 10686.725\n",
      "    load_throughput: 89721.861\n",
      "    load_time_ms: 111.411\n",
      "    sample_throughput: 64.52\n",
      "    sample_time_ms: 154929.721\n",
      "    update_time_ms: 12.351\n",
      "  timestamp: 1636294740\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19992\n",
      "  training_iteration: 2\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         331.533</td><td style=\"text-align: right;\">19992</td><td style=\"text-align: right;\">-0.761188</td><td style=\"text-align: right;\">                2.61</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">            99.099</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 29988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-20-54\n",
      "  done: false\n",
      "  episode_len_mean: 101.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.439999999999999\n",
      "  episode_reward_mean: -0.7144000000000007\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 298\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8546294130830683\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013411636420832186\n",
      "          policy_loss: -0.02397455284610773\n",
      "          total_loss: 0.007206196466890665\n",
      "          vf_explained_var: 0.27785927057266235\n",
      "          vf_loss: 0.05704471586097\n",
      "    num_agent_steps_sampled: 29988\n",
      "    num_agent_steps_trained: 29988\n",
      "    num_steps_sampled: 29988\n",
      "    num_steps_trained: 29988\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.19197530864197\n",
      "    ram_util_percent: 55.858024691358025\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046533420219674174\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.932255276421245\n",
      "    mean_inference_ms: 2.8922871796939957\n",
      "    mean_raw_obs_processing_ms: 0.7418277874551262\n",
      "  time_since_restore: 445.07330799102783\n",
      "  time_this_iter_s: 113.54023623466492\n",
      "  time_total_s: 445.07330799102783\n",
      "  timers:\n",
      "    learn_throughput: 935.99\n",
      "    learn_time_ms: 10679.604\n",
      "    load_throughput: 90615.851\n",
      "    load_time_ms: 110.312\n",
      "    sample_throughput: 72.686\n",
      "    sample_time_ms: 137522.689\n",
      "    update_time_ms: 14.467\n",
      "  timestamp: 1636294854\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29988\n",
      "  training_iteration: 3\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         445.073</td><td style=\"text-align: right;\">29988</td><td style=\"text-align: right;\"> -0.7144</td><td style=\"text-align: right;\">                2.44</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">            101.47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 39984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-23-15\n",
      "  done: false\n",
      "  episode_len_mean: 99.11881188118812\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.92000000000001\n",
      "  episode_reward_mean: -0.20445544554455455\n",
      "  episode_reward_min: -1.7800000000000007\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 399\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.830136453595936\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017423643066140772\n",
      "          policy_loss: -0.030083215927593727\n",
      "          total_loss: 0.11269993615360596\n",
      "          vf_explained_var: 0.2986709177494049\n",
      "          vf_loss: 0.16759978749462937\n",
      "    num_agent_steps_sampled: 39984\n",
      "    num_agent_steps_trained: 39984\n",
      "    num_steps_sampled: 39984\n",
      "    num_steps_trained: 39984\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.1039800995025\n",
      "    ram_util_percent: 54.23084577114429\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04641826164548625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.279593471565406\n",
      "    mean_inference_ms: 2.8938653722377414\n",
      "    mean_raw_obs_processing_ms: 2.0117389007283037\n",
      "  time_since_restore: 586.2971928119659\n",
      "  time_this_iter_s: 141.2238848209381\n",
      "  time_total_s: 586.2971928119659\n",
      "  timers:\n",
      "    learn_throughput: 936.13\n",
      "    learn_time_ms: 10678.009\n",
      "    load_throughput: 90996.033\n",
      "    load_time_ms: 109.851\n",
      "    sample_throughput: 73.638\n",
      "    sample_time_ms: 135744.414\n",
      "    update_time_ms: 15.112\n",
      "  timestamp: 1636294995\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39984\n",
      "  training_iteration: 4\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         586.297</td><td style=\"text-align: right;\">39984</td><td style=\"text-align: right;\">-0.204455</td><td style=\"text-align: right;\">                4.92</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           99.1188</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 49980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-25-20\n",
      "  done: false\n",
      "  episode_len_mean: 101.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.530000000000007\n",
      "  episode_reward_mean: 0.3536000000000008\n",
      "  episode_reward_min: -2.129999999999999\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 498\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.786437828724201\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.021151041119131263\n",
      "          policy_loss: -0.02813620950278436\n",
      "          total_loss: 0.281179541330307\n",
      "          vf_explained_var: 0.2791663408279419\n",
      "          vf_loss: 0.3329499189686189\n",
      "    num_agent_steps_sampled: 49980\n",
      "    num_agent_steps_trained: 49980\n",
      "    num_steps_sampled: 49980\n",
      "    num_steps_trained: 49980\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94357541899443\n",
      "    ram_util_percent: 53.86871508379888\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046256129534244704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.384400782136034\n",
      "    mean_inference_ms: 2.8864459582802056\n",
      "    mean_raw_obs_processing_ms: 1.7398125669979259\n",
      "  time_since_restore: 711.6353077888489\n",
      "  time_this_iter_s: 125.33811497688293\n",
      "  time_total_s: 711.6353077888489\n",
      "  timers:\n",
      "    learn_throughput: 936.028\n",
      "    learn_time_ms: 10679.168\n",
      "    load_throughput: 91051.731\n",
      "    load_time_ms: 109.784\n",
      "    sample_throughput: 76.015\n",
      "    sample_time_ms: 131500.219\n",
      "    update_time_ms: 13.777\n",
      "  timestamp: 1636295120\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 49980\n",
      "  training_iteration: 5\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         711.635</td><td style=\"text-align: right;\">49980</td><td style=\"text-align: right;\">  0.3536</td><td style=\"text-align: right;\">                6.53</td><td style=\"text-align: right;\">               -2.13</td><td style=\"text-align: right;\">            101.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 59976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-27-32\n",
      "  done: false\n",
      "  episode_len_mean: 99.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.5700000000000145\n",
      "  episode_reward_mean: 0.5062000000000011\n",
      "  episode_reward_min: -1.970000000000001\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 597\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7670964473333113\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019107513359859694\n",
      "          policy_loss: -0.03416342549344413\n",
      "          total_loss: 0.26162091678279076\n",
      "          vf_explained_var: 0.3989444673061371\n",
      "          vf_loss: 0.3177230527640408\n",
      "    num_agent_steps_sampled: 59976\n",
      "    num_agent_steps_trained: 59976\n",
      "    num_steps_sampled: 59976\n",
      "    num_steps_trained: 59976\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69095744680853\n",
      "    ram_util_percent: 54.3345744680851\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046320481143824505\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96734227235947\n",
      "    mean_inference_ms: 2.8843666473286538\n",
      "    mean_raw_obs_processing_ms: 1.5691464462471458\n",
      "  time_since_restore: 843.6577517986298\n",
      "  time_this_iter_s: 132.02244400978088\n",
      "  time_total_s: 843.6577517986298\n",
      "  timers:\n",
      "    learn_throughput: 934.364\n",
      "    learn_time_ms: 10698.181\n",
      "    load_throughput: 91139.228\n",
      "    load_time_ms: 109.678\n",
      "    sample_throughput: 77.031\n",
      "    sample_time_ms: 129766.44\n",
      "    update_time_ms: 12.778\n",
      "  timestamp: 1636295252\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59976\n",
      "  training_iteration: 6\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         843.658</td><td style=\"text-align: right;\">59976</td><td style=\"text-align: right;\">  0.5062</td><td style=\"text-align: right;\">                4.57</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">             99.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 69972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-29-43\n",
      "  done: false\n",
      "  episode_len_mean: 99.3529411764706\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.080000000000013\n",
      "  episode_reward_mean: 0.7449019607843149\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 699\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7409817080212453\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02057950165455991\n",
      "          policy_loss: -0.03479871365568067\n",
      "          total_loss: 0.22171845538621274\n",
      "          vf_explained_var: 0.534519612789154\n",
      "          vf_loss: 0.27775313418645126\n",
      "    num_agent_steps_sampled: 69972\n",
      "    num_agent_steps_trained: 69972\n",
      "    num_steps_sampled: 69972\n",
      "    num_steps_trained: 69972\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.98333333333332\n",
      "    ram_util_percent: 54.43548387096775\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04616248282699181\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.74006614332715\n",
      "    mean_inference_ms: 2.8874116380530905\n",
      "    mean_raw_obs_processing_ms: 1.4417478009716123\n",
      "  time_since_restore: 973.8909070491791\n",
      "  time_this_iter_s: 130.23315525054932\n",
      "  time_total_s: 973.8909070491791\n",
      "  timers:\n",
      "    learn_throughput: 933.746\n",
      "    learn_time_ms: 10705.267\n",
      "    load_throughput: 91440.635\n",
      "    load_time_ms: 109.317\n",
      "    sample_throughput: 77.924\n",
      "    sample_time_ms: 128278.281\n",
      "    update_time_ms: 12.839\n",
      "  timestamp: 1636295383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69972\n",
      "  training_iteration: 7\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         973.891</td><td style=\"text-align: right;\">69972</td><td style=\"text-align: right;\">0.744902</td><td style=\"text-align: right;\">                5.08</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           99.3529</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 79968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-32-10\n",
      "  done: false\n",
      "  episode_len_mean: 95.62135922330097\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.760000000000013\n",
      "  episode_reward_mean: 0.8657281553398075\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 802\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.734050679614401\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019611230072854584\n",
      "          policy_loss: -0.035234777718527704\n",
      "          total_loss: 0.29533397680801204\n",
      "          vf_explained_var: 0.4814901649951935\n",
      "          vf_loss: 0.34908420741558077\n",
      "    num_agent_steps_sampled: 79968\n",
      "    num_agent_steps_trained: 79968\n",
      "    num_steps_sampled: 79968\n",
      "    num_steps_trained: 79968\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.73033175355452\n",
      "    ram_util_percent: 54.25071090047394\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04614371203792033\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.61523895468156\n",
      "    mean_inference_ms: 2.8869852636015905\n",
      "    mean_raw_obs_processing_ms: 1.9643545298288412\n",
      "  time_since_restore: 1121.3913860321045\n",
      "  time_this_iter_s: 147.50047898292542\n",
      "  time_total_s: 1121.3913860321045\n",
      "  timers:\n",
      "    learn_throughput: 933.533\n",
      "    learn_time_ms: 10707.706\n",
      "    load_throughput: 91458.588\n",
      "    load_time_ms: 109.295\n",
      "    sample_throughput: 77.294\n",
      "    sample_time_ms: 129323.943\n",
      "    update_time_ms: 12.394\n",
      "  timestamp: 1636295530\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79968\n",
      "  training_iteration: 8\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         1121.39</td><td style=\"text-align: right;\">79968</td><td style=\"text-align: right;\">0.865728</td><td style=\"text-align: right;\">                6.76</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           95.6214</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 89964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-34-20\n",
      "  done: false\n",
      "  episode_len_mean: 97.6504854368932\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.88000000000001\n",
      "  episode_reward_mean: 0.9886407766990313\n",
      "  episode_reward_min: -1.870000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 905\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.717897022483695\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01972981722506659\n",
      "          policy_loss: -0.038824943502425636\n",
      "          total_loss: 0.27620428455675133\n",
      "          vf_explained_var: 0.5166344046592712\n",
      "          vf_loss: 0.33332978025970295\n",
      "    num_agent_steps_sampled: 89964\n",
      "    num_agent_steps_trained: 89964\n",
      "    num_steps_sampled: 89964\n",
      "    num_steps_trained: 89964\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.98695652173912\n",
      "    ram_util_percent: 54.64021739130435\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046381160052791526\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.48433555980535\n",
      "    mean_inference_ms: 2.8879884093181976\n",
      "    mean_raw_obs_processing_ms: 1.8222749667245777\n",
      "  time_since_restore: 1250.8233604431152\n",
      "  time_this_iter_s: 129.43197441101074\n",
      "  time_total_s: 1250.8233604431152\n",
      "  timers:\n",
      "    learn_throughput: 932.926\n",
      "    learn_time_ms: 10714.674\n",
      "    load_throughput: 91467.81\n",
      "    load_time_ms: 109.284\n",
      "    sample_throughput: 78.018\n",
      "    sample_time_ms: 128124.232\n",
      "    update_time_ms: 12.521\n",
      "  timestamp: 1636295660\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89964\n",
      "  training_iteration: 9\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         1250.82</td><td style=\"text-align: right;\">89964</td><td style=\"text-align: right;\">0.988641</td><td style=\"text-align: right;\">                6.88</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">           97.6505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 99960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-36-34\n",
      "  done: false\n",
      "  episode_len_mean: 94.8952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.750000000000011\n",
      "  episode_reward_mean: 1.1550476190476213\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 1010\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.706044305287875\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02049848573933016\n",
      "          policy_loss: -0.038340762248819965\n",
      "          total_loss: 0.26899709751925027\n",
      "          vf_explained_var: 0.5775786638259888\n",
      "          vf_loss: 0.3251739848882724\n",
      "    num_agent_steps_sampled: 99960\n",
      "    num_agent_steps_trained: 99960\n",
      "    num_steps_sampled: 99960\n",
      "    num_steps_trained: 99960\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9734375\n",
      "    ram_util_percent: 54.61875\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04663125913152196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.48060521292109\n",
      "    mean_inference_ms: 2.8889115333757474\n",
      "    mean_raw_obs_processing_ms: 1.7098175866734822\n",
      "  time_since_restore: 1385.1555333137512\n",
      "  time_this_iter_s: 134.332172870636\n",
      "  time_total_s: 1385.1555333137512\n",
      "  timers:\n",
      "    learn_throughput: 932.172\n",
      "    learn_time_ms: 10723.347\n",
      "    load_throughput: 91486.328\n",
      "    load_time_ms: 109.262\n",
      "    sample_throughput: 78.307\n",
      "    sample_time_ms: 127650.897\n",
      "    update_time_ms: 12.806\n",
      "  timestamp: 1636295794\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99960\n",
      "  training_iteration: 10\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         1385.16</td><td style=\"text-align: right;\">99960</td><td style=\"text-align: right;\"> 1.15505</td><td style=\"text-align: right;\">                6.75</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           94.8952</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 109956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-39-13\n",
      "  done: false\n",
      "  episode_len_mean: 90.75454545454545\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.330000000000011\n",
      "  episode_reward_mean: 0.8753636363636383\n",
      "  episode_reward_min: -2.2499999999999987\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 1120\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7002450193095413\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.022519630569657986\n",
      "          policy_loss: -0.030922873155810895\n",
      "          total_loss: 0.34228461658279613\n",
      "          vf_explained_var: 0.5162562131881714\n",
      "          vf_loss: 0.38500918899463793\n",
      "    num_agent_steps_sampled: 109956\n",
      "    num_agent_steps_trained: 109956\n",
      "    num_steps_sampled: 109956\n",
      "    num_steps_trained: 109956\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.39118942731277\n",
      "    ram_util_percent: 54.30792951541851\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046781447532993424\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.678464879397886\n",
      "    mean_inference_ms: 2.891231903359371\n",
      "    mean_raw_obs_processing_ms: 2.090332422892681\n",
      "  time_since_restore: 1543.9872205257416\n",
      "  time_this_iter_s: 158.83168721199036\n",
      "  time_total_s: 1543.9872205257416\n",
      "  timers:\n",
      "    learn_throughput: 931.287\n",
      "    learn_time_ms: 10733.531\n",
      "    load_throughput: 91948.015\n",
      "    load_time_ms: 108.714\n",
      "    sample_throughput: 81.856\n",
      "    sample_time_ms: 122116.753\n",
      "    update_time_ms: 13.402\n",
      "  timestamp: 1636295953\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109956\n",
      "  training_iteration: 11\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         1543.99</td><td style=\"text-align: right;\">109956</td><td style=\"text-align: right;\">0.875364</td><td style=\"text-align: right;\">                6.33</td><td style=\"text-align: right;\">               -2.25</td><td style=\"text-align: right;\">           90.7545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 119952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-41-36\n",
      "  done: false\n",
      "  episode_len_mean: 93.58333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.890000000000011\n",
      "  episode_reward_mean: 1.3081481481481514\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 1228\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.684723307332422\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01826688786241325\n",
      "          policy_loss: -0.040454565876155583\n",
      "          total_loss: 0.29623451474576423\n",
      "          vf_explained_var: 0.6440403461456299\n",
      "          vf_loss: 0.3450410887726352\n",
      "    num_agent_steps_sampled: 119952\n",
      "    num_agent_steps_trained: 119952\n",
      "    num_steps_sampled: 119952\n",
      "    num_steps_trained: 119952\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92266009852216\n",
      "    ram_util_percent: 54.66847290640394\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046694695940444765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.836436764833614\n",
      "    mean_inference_ms: 2.89062180715056\n",
      "    mean_raw_obs_processing_ms: 1.9765794118461866\n",
      "  time_since_restore: 1686.7108776569366\n",
      "  time_this_iter_s: 142.72365713119507\n",
      "  time_total_s: 1686.7108776569366\n",
      "  timers:\n",
      "    learn_throughput: 930.264\n",
      "    learn_time_ms: 10745.341\n",
      "    load_throughput: 92146.949\n",
      "    load_time_ms: 108.479\n",
      "    sample_throughput: 80.203\n",
      "    sample_time_ms: 124633.97\n",
      "    update_time_ms: 13.47\n",
      "  timestamp: 1636296096\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119952\n",
      "  training_iteration: 12\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         1686.71</td><td style=\"text-align: right;\">119952</td><td style=\"text-align: right;\"> 1.30815</td><td style=\"text-align: right;\">                6.89</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           93.5833</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 129948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-43-58\n",
      "  done: false\n",
      "  episode_len_mean: 93.79439252336448\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.930000000000012\n",
      "  episode_reward_mean: 0.8791588785046748\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 1335\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6899115258811888\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018723338247744675\n",
      "          policy_loss: -0.0397244668016449\n",
      "          total_loss: 0.2832878552815025\n",
      "          vf_explained_var: 0.5968801379203796\n",
      "          vf_loss: 0.33095405597526295\n",
      "    num_agent_steps_sampled: 129948\n",
      "    num_agent_steps_trained: 129948\n",
      "    num_steps_sampled: 129948\n",
      "    num_steps_trained: 129948\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94630541871923\n",
      "    ram_util_percent: 54.76748768472906\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04657842670523988\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95368314020666\n",
      "    mean_inference_ms: 2.8908138543204642\n",
      "    mean_raw_obs_processing_ms: 1.8832757082827907\n",
      "  time_since_restore: 1828.971265554428\n",
      "  time_this_iter_s: 142.26038789749146\n",
      "  time_total_s: 1828.971265554428\n",
      "  timers:\n",
      "    learn_throughput: 929.084\n",
      "    learn_time_ms: 10758.987\n",
      "    load_throughput: 92115.69\n",
      "    load_time_ms: 108.516\n",
      "    sample_throughput: 78.403\n",
      "    sample_time_ms: 127494.361\n",
      "    update_time_ms: 13.877\n",
      "  timestamp: 1636296238\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129948\n",
      "  training_iteration: 13\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         1828.97</td><td style=\"text-align: right;\">129948</td><td style=\"text-align: right;\">0.879159</td><td style=\"text-align: right;\">                6.93</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           93.7944</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 139944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-46-40\n",
      "  done: false\n",
      "  episode_len_mean: 92.01851851851852\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.760000000000013\n",
      "  episode_reward_mean: 1.2630555555555585\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 1443\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6751801329800204\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01840517653679139\n",
      "          policy_loss: -0.04302873565759669\n",
      "          total_loss: 0.2892321335533873\n",
      "          vf_explained_var: 0.5749748945236206\n",
      "          vf_loss: 0.3403774273892244\n",
      "    num_agent_steps_sampled: 139944\n",
      "    num_agent_steps_trained: 139944\n",
      "    num_steps_sampled: 139944\n",
      "    num_steps_trained: 139944\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.14439655172413\n",
      "    ram_util_percent: 54.5073275862069\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04650867971640409\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.128407622180625\n",
      "    mean_inference_ms: 2.8901767097642197\n",
      "    mean_raw_obs_processing_ms: 2.1596491659235397\n",
      "  time_since_restore: 1991.2557964324951\n",
      "  time_this_iter_s: 162.28453087806702\n",
      "  time_total_s: 1991.2557964324951\n",
      "  timers:\n",
      "    learn_throughput: 928.191\n",
      "    learn_time_ms: 10769.341\n",
      "    load_throughput: 91796.905\n",
      "    load_time_ms: 108.893\n",
      "    sample_throughput: 77.136\n",
      "    sample_time_ms: 129589.806\n",
      "    update_time_ms: 13.78\n",
      "  timestamp: 1636296400\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 139944\n",
      "  training_iteration: 14\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         1991.26</td><td style=\"text-align: right;\">139944</td><td style=\"text-align: right;\"> 1.26306</td><td style=\"text-align: right;\">                6.76</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           92.0185</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 149940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-48-57\n",
      "  done: false\n",
      "  episode_len_mean: 90.70642201834862\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.770000000000012\n",
      "  episode_reward_mean: 0.9337614678899103\n",
      "  episode_reward_min: -2.139999999999998\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 1552\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.658400615871462\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018323252420940628\n",
      "          policy_loss: -0.04517949232672397\n",
      "          total_loss: 0.2716158012644603\n",
      "          vf_explained_var: 0.6060242056846619\n",
      "          vf_loss: 0.32482700494364797\n",
      "    num_agent_steps_sampled: 149940\n",
      "    num_agent_steps_trained: 149940\n",
      "    num_steps_sampled: 149940\n",
      "    num_steps_trained: 149940\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00153061224489\n",
      "    ram_util_percent: 54.703571428571436\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046451790967273775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.172497952710884\n",
      "    mean_inference_ms: 2.8899681776788793\n",
      "    mean_raw_obs_processing_ms: 2.0650426222265237\n",
      "  time_since_restore: 2128.3124606609344\n",
      "  time_this_iter_s: 137.05666422843933\n",
      "  time_total_s: 2128.3124606609344\n",
      "  timers:\n",
      "    learn_throughput: 927.761\n",
      "    learn_time_ms: 10774.324\n",
      "    load_throughput: 91908.126\n",
      "    load_time_ms: 108.761\n",
      "    sample_throughput: 76.448\n",
      "    sample_time_ms: 130756.4\n",
      "    update_time_ms: 13.869\n",
      "  timestamp: 1636296537\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 149940\n",
      "  training_iteration: 15\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         2128.31</td><td style=\"text-align: right;\">149940</td><td style=\"text-align: right;\">0.933761</td><td style=\"text-align: right;\">                8.77</td><td style=\"text-align: right;\">               -2.14</td><td style=\"text-align: right;\">           90.7064</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 159936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-51-13\n",
      "  done: false\n",
      "  episode_len_mean: 92.46788990825688\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.610000000000014\n",
      "  episode_reward_mean: 1.3847706422018382\n",
      "  episode_reward_min: -2.0300000000000002\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 1661\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6285750951522435\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01967987895916084\n",
      "          policy_loss: -0.04613908043879474\n",
      "          total_loss: 0.25112690013061223\n",
      "          vf_explained_var: 0.6467298269271851\n",
      "          vf_loss: 0.3036258530858745\n",
      "    num_agent_steps_sampled: 159936\n",
      "    num_agent_steps_trained: 159936\n",
      "    num_steps_sampled: 159936\n",
      "    num_steps_trained: 159936\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97357512953369\n",
      "    ram_util_percent: 54.852849740932655\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04640117158446287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.16071920902609\n",
      "    mean_inference_ms: 2.8903272891851532\n",
      "    mean_raw_obs_processing_ms: 1.9797369476860578\n",
      "  time_since_restore: 2263.9765000343323\n",
      "  time_this_iter_s: 135.66403937339783\n",
      "  time_total_s: 2263.9765000343323\n",
      "  timers:\n",
      "    learn_throughput: 928.384\n",
      "    learn_time_ms: 10767.1\n",
      "    load_throughput: 92088.578\n",
      "    load_time_ms: 108.548\n",
      "    sample_throughput: 76.231\n",
      "    sample_time_ms: 131127.386\n",
      "    update_time_ms: 14.664\n",
      "  timestamp: 1636296673\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159936\n",
      "  training_iteration: 16\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         2263.98</td><td style=\"text-align: right;\">159936</td><td style=\"text-align: right;\"> 1.38477</td><td style=\"text-align: right;\">                6.61</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">           92.4679</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 169932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-53-27\n",
      "  done: false\n",
      "  episode_len_mean: 93.5233644859813\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.520000000000014\n",
      "  episode_reward_mean: 1.5498130841121525\n",
      "  episode_reward_min: -1.7500000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 1768\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.638743826874301\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019775111787829452\n",
      "          policy_loss: -0.050694598601414606\n",
      "          total_loss: 0.20706236890445534\n",
      "          vf_explained_var: 0.6662006974220276\n",
      "          vf_loss: 0.2641221027725782\n",
      "    num_agent_steps_sampled: 169932\n",
      "    num_agent_steps_trained: 169932\n",
      "    num_steps_sampled: 169932\n",
      "    num_steps_trained: 169932\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94583333333333\n",
      "    ram_util_percent: 54.80677083333334\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04639369465345024\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.15445973549216\n",
      "    mean_inference_ms: 2.8910117997552263\n",
      "    mean_raw_obs_processing_ms: 1.9078676326638477\n",
      "  time_since_restore: 2398.4257678985596\n",
      "  time_this_iter_s: 134.4492678642273\n",
      "  time_total_s: 2398.4257678985596\n",
      "  timers:\n",
      "    learn_throughput: 928.536\n",
      "    learn_time_ms: 10765.328\n",
      "    load_throughput: 91930.293\n",
      "    load_time_ms: 108.735\n",
      "    sample_throughput: 75.986\n",
      "    sample_time_ms: 131551.0\n",
      "    update_time_ms: 14.367\n",
      "  timestamp: 1636296807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169932\n",
      "  training_iteration: 17\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         2398.43</td><td style=\"text-align: right;\">169932</td><td style=\"text-align: right;\"> 1.54981</td><td style=\"text-align: right;\">                6.52</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           93.5234</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 179928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-55-59\n",
      "  done: false\n",
      "  episode_len_mean: 92.32407407407408\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.850000000000016\n",
      "  episode_reward_mean: 1.4772222222222253\n",
      "  episode_reward_min: -2.1099999999999994\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 1876\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.638011506683806\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02283782265869246\n",
      "          policy_loss: -0.049128306470811366\n",
      "          total_loss: 0.24516482626955605\n",
      "          vf_explained_var: 0.6130090355873108\n",
      "          vf_loss: 0.2975499516209731\n",
      "    num_agent_steps_sampled: 179928\n",
      "    num_agent_steps_trained: 179928\n",
      "    num_steps_sampled: 179928\n",
      "    num_steps_trained: 179928\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.44351851851853\n",
      "    ram_util_percent: 54.574074074074076\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04640194978709804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.13465044894119\n",
      "    mean_inference_ms: 2.891020176684711\n",
      "    mean_raw_obs_processing_ms: 2.1210089018243496\n",
      "  time_since_restore: 2549.645344018936\n",
      "  time_this_iter_s: 151.2195761203766\n",
      "  time_total_s: 2549.645344018936\n",
      "  timers:\n",
      "    learn_throughput: 928.689\n",
      "    learn_time_ms: 10763.562\n",
      "    load_throughput: 91995.145\n",
      "    load_time_ms: 108.658\n",
      "    sample_throughput: 75.771\n",
      "    sample_time_ms: 131924.092\n",
      "    update_time_ms: 15.088\n",
      "  timestamp: 1636296959\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179928\n",
      "  training_iteration: 18\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         2549.65</td><td style=\"text-align: right;\">179928</td><td style=\"text-align: right;\"> 1.47722</td><td style=\"text-align: right;\">               12.85</td><td style=\"text-align: right;\">               -2.11</td><td style=\"text-align: right;\">           92.3241</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 189924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_14-58-13\n",
      "  done: false\n",
      "  episode_len_mean: 92.43518518518519\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.580000000000014\n",
      "  episode_reward_mean: 1.640555555555559\n",
      "  episode_reward_min: -1.5900000000000003\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 1984\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6059755575962558\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02030402589392296\n",
      "          policy_loss: -0.048229821126621504\n",
      "          total_loss: 0.31303357128531506\n",
      "          vf_explained_var: 0.6252217888832092\n",
      "          vf_loss: 0.3564864088072736\n",
      "    num_agent_steps_sampled: 189924\n",
      "    num_agent_steps_trained: 189924\n",
      "    num_steps_sampled: 189924\n",
      "    num_steps_trained: 189924\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.93612565445028\n",
      "    ram_util_percent: 55.02251308900523\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046372774538872105\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.114979130504224\n",
      "    mean_inference_ms: 2.890561076349444\n",
      "    mean_raw_obs_processing_ms: 2.0465172067659374\n",
      "  time_since_restore: 2683.701857805252\n",
      "  time_this_iter_s: 134.05651378631592\n",
      "  time_total_s: 2683.701857805252\n",
      "  timers:\n",
      "    learn_throughput: 929.162\n",
      "    learn_time_ms: 10758.081\n",
      "    load_throughput: 92031.412\n",
      "    load_time_ms: 108.615\n",
      "    sample_throughput: 75.503\n",
      "    sample_time_ms: 132391.951\n",
      "    update_time_ms: 15.145\n",
      "  timestamp: 1636297093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189924\n",
      "  training_iteration: 19\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">          2683.7</td><td style=\"text-align: right;\">189924</td><td style=\"text-align: right;\"> 1.64056</td><td style=\"text-align: right;\">                8.58</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           92.4352</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 199920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-00-28\n",
      "  done: false\n",
      "  episode_len_mean: 93.50467289719626\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.540000000000013\n",
      "  episode_reward_mean: 1.4850467289719669\n",
      "  episode_reward_min: -1.8700000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 2091\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6134792022216016\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01586250293409381\n",
      "          policy_loss: -0.05380484594398329\n",
      "          total_loss: 0.2339131554461315\n",
      "          vf_explained_var: 0.7450557351112366\n",
      "          vf_loss: 0.27771602658889233\n",
      "    num_agent_steps_sampled: 199920\n",
      "    num_agent_steps_trained: 199920\n",
      "    num_steps_sampled: 199920\n",
      "    num_steps_trained: 199920\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8616580310881\n",
      "    ram_util_percent: 55.013471502590676\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04635033031902243\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.121113749785216\n",
      "    mean_inference_ms: 2.8895981082189137\n",
      "    mean_raw_obs_processing_ms: 1.9809485603624044\n",
      "  time_since_restore: 2818.987654685974\n",
      "  time_this_iter_s: 135.28579688072205\n",
      "  time_total_s: 2818.987654685974\n",
      "  timers:\n",
      "    learn_throughput: 929.817\n",
      "    learn_time_ms: 10750.505\n",
      "    load_throughput: 91942.409\n",
      "    load_time_ms: 108.72\n",
      "    sample_throughput: 75.444\n",
      "    sample_time_ms: 132496.084\n",
      "    update_time_ms: 14.112\n",
      "  timestamp: 1636297228\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199920\n",
      "  training_iteration: 20\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         2818.99</td><td style=\"text-align: right;\">199920</td><td style=\"text-align: right;\"> 1.48505</td><td style=\"text-align: right;\">                8.54</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">           93.5047</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 209916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-03-03\n",
      "  done: false\n",
      "  episode_len_mean: 89.59821428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.290000000000017\n",
      "  episode_reward_mean: 1.286875000000003\n",
      "  episode_reward_min: -2.2399999999999993\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 2203\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.59970557852688\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01636536260594722\n",
      "          policy_loss: -0.05545460235279722\n",
      "          total_loss: 0.22322561198956947\n",
      "          vf_explained_var: 0.6840986609458923\n",
      "          vf_loss: 0.26739492715997065\n",
      "    num_agent_steps_sampled: 209916\n",
      "    num_agent_steps_trained: 209916\n",
      "    num_steps_sampled: 209916\n",
      "    num_steps_trained: 209916\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.33257918552036\n",
      "    ram_util_percent: 54.68235294117646\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0464010772825969\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.152486130476156\n",
      "    mean_inference_ms: 2.8899243540041226\n",
      "    mean_raw_obs_processing_ms: 2.170660132328783\n",
      "  time_since_restore: 2973.3294088840485\n",
      "  time_this_iter_s: 154.34175419807434\n",
      "  time_total_s: 2973.3294088840485\n",
      "  timers:\n",
      "    learn_throughput: 930.672\n",
      "    learn_time_ms: 10740.624\n",
      "    load_throughput: 91608.745\n",
      "    load_time_ms: 109.116\n",
      "    sample_throughput: 75.694\n",
      "    sample_time_ms: 132057.522\n",
      "    update_time_ms: 13.1\n",
      "  timestamp: 1636297383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209916\n",
      "  training_iteration: 21\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         2973.33</td><td style=\"text-align: right;\">209916</td><td style=\"text-align: right;\"> 1.28688</td><td style=\"text-align: right;\">                8.29</td><td style=\"text-align: right;\">               -2.24</td><td style=\"text-align: right;\">           89.5982</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 219912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-05-28\n",
      "  done: false\n",
      "  episode_len_mean: 93.37383177570094\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.200000000000007\n",
      "  episode_reward_mean: 1.7000000000000035\n",
      "  episode_reward_min: -2.0700000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 2310\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6017333087758123\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015276478339103585\n",
      "          policy_loss: -0.053364515661174415\n",
      "          total_loss: 0.2223557772839235\n",
      "          vf_explained_var: 0.7182268500328064\n",
      "          vf_loss: 0.2669358967938739\n",
      "    num_agent_steps_sampled: 219912\n",
      "    num_agent_steps_trained: 219912\n",
      "    num_steps_sampled: 219912\n",
      "    num_steps_trained: 219912\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.51497584541063\n",
      "    ram_util_percent: 55.05942028985506\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04636113818229711\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.08452058288323\n",
      "    mean_inference_ms: 2.8893261592883457\n",
      "    mean_raw_obs_processing_ms: 2.1803815869356233\n",
      "  time_since_restore: 3118.727602005005\n",
      "  time_this_iter_s: 145.39819312095642\n",
      "  time_total_s: 3118.727602005005\n",
      "  timers:\n",
      "    learn_throughput: 931.629\n",
      "    learn_time_ms: 10729.598\n",
      "    load_throughput: 91561.45\n",
      "    load_time_ms: 109.173\n",
      "    sample_throughput: 75.535\n",
      "    sample_time_ms: 132336.605\n",
      "    update_time_ms: 12.435\n",
      "  timestamp: 1636297528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219912\n",
      "  training_iteration: 22\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         3118.73</td><td style=\"text-align: right;\">219912</td><td style=\"text-align: right;\">     1.7</td><td style=\"text-align: right;\">                 7.2</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           93.3738</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 229908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-07-41\n",
      "  done: false\n",
      "  episode_len_mean: 94.49056603773585\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.430000000000016\n",
      "  episode_reward_mean: 1.7924528301886842\n",
      "  episode_reward_min: -2.1200000000000006\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2416\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6091130841491568\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015214492016119362\n",
      "          policy_loss: -0.052206186439173345\n",
      "          total_loss: 0.20765486498737437\n",
      "          vf_explained_var: 0.7371765971183777\n",
      "          vf_loss: 0.25129166699818567\n",
      "    num_agent_steps_sampled: 229908\n",
      "    num_agent_steps_trained: 229908\n",
      "    num_steps_sampled: 229908\n",
      "    num_steps_trained: 229908\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.15368421052632\n",
      "    ram_util_percent: 55.195789473684194\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04635829105235019\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06529375681166\n",
      "    mean_inference_ms: 2.889906801788304\n",
      "    mean_raw_obs_processing_ms: 2.1159156192945305\n",
      "  time_since_restore: 3251.8090665340424\n",
      "  time_this_iter_s: 133.08146452903748\n",
      "  time_total_s: 3251.8090665340424\n",
      "  timers:\n",
      "    learn_throughput: 932.692\n",
      "    learn_time_ms: 10717.366\n",
      "    load_throughput: 91466.788\n",
      "    load_time_ms: 109.286\n",
      "    sample_throughput: 76.055\n",
      "    sample_time_ms: 131431.272\n",
      "    update_time_ms: 11.867\n",
      "  timestamp: 1636297661\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229908\n",
      "  training_iteration: 23\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         3251.81</td><td style=\"text-align: right;\">229908</td><td style=\"text-align: right;\"> 1.79245</td><td style=\"text-align: right;\">               10.43</td><td style=\"text-align: right;\">               -2.12</td><td style=\"text-align: right;\">           94.4906</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 239904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-10-10\n",
      "  done: false\n",
      "  episode_len_mean: 92.79439252336448\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.880000000000013\n",
      "  episode_reward_mean: 1.3263551401869202\n",
      "  episode_reward_min: -2.24\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 2523\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6107060636210644\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013849373056023252\n",
      "          policy_loss: -0.05776918463281586\n",
      "          total_loss: 0.17764241255214835\n",
      "          vf_explained_var: 0.7662463784217834\n",
      "          vf_loss: 0.22996805449708915\n",
      "    num_agent_steps_sampled: 239904\n",
      "    num_agent_steps_trained: 239904\n",
      "    num_steps_sampled: 239904\n",
      "    num_steps_trained: 239904\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.74905660377358\n",
      "    ram_util_percent: 55.06273584905661\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04629453420644469\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01524754449875\n",
      "    mean_inference_ms: 2.888046603636323\n",
      "    mean_raw_obs_processing_ms: 2.19415171354416\n",
      "  time_since_restore: 3400.569899559021\n",
      "  time_this_iter_s: 148.76083302497864\n",
      "  time_total_s: 3400.569899559021\n",
      "  timers:\n",
      "    learn_throughput: 933.403\n",
      "    learn_time_ms: 10709.206\n",
      "    load_throughput: 91688.52\n",
      "    load_time_ms: 109.021\n",
      "    sample_throughput: 76.841\n",
      "    sample_time_ms: 130087.637\n",
      "    update_time_ms: 11.746\n",
      "  timestamp: 1636297810\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239904\n",
      "  training_iteration: 24\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         3400.57</td><td style=\"text-align: right;\">239904</td><td style=\"text-align: right;\"> 1.32636</td><td style=\"text-align: right;\">                6.88</td><td style=\"text-align: right;\">               -2.24</td><td style=\"text-align: right;\">           92.7944</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 249900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-12-37\n",
      "  done: false\n",
      "  episode_len_mean: 93.86915887850468\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.840000000000009\n",
      "  episode_reward_mean: 1.9255140186915933\n",
      "  episode_reward_min: -1.7700000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 2630\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6094704676897096\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015078788866954924\n",
      "          policy_loss: -0.058682930969402324\n",
      "          total_loss: 0.19279801591864637\n",
      "          vf_explained_var: 0.7444475889205933\n",
      "          vf_loss: 0.24322428456865824\n",
      "    num_agent_steps_sampled: 249900\n",
      "    num_agent_steps_trained: 249900\n",
      "    num_steps_sampled: 249900\n",
      "    num_steps_trained: 249900\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.64809523809525\n",
      "    ram_util_percent: 55.1447619047619\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046325268211839916\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.969308304210195\n",
      "    mean_inference_ms: 2.8868605979324493\n",
      "    mean_raw_obs_processing_ms: 2.203633675016344\n",
      "  time_since_restore: 3547.3498678207397\n",
      "  time_this_iter_s: 146.77996826171875\n",
      "  time_total_s: 3547.3498678207397\n",
      "  timers:\n",
      "    learn_throughput: 933.362\n",
      "    learn_time_ms: 10709.666\n",
      "    load_throughput: 91625.081\n",
      "    load_time_ms: 109.097\n",
      "    sample_throughput: 76.271\n",
      "    sample_time_ms: 131058.989\n",
      "    update_time_ms: 12.372\n",
      "  timestamp: 1636297957\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249900\n",
      "  training_iteration: 25\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         3547.35</td><td style=\"text-align: right;\">249900</td><td style=\"text-align: right;\"> 1.92551</td><td style=\"text-align: right;\">                8.84</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           93.8692</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 259896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-14-47\n",
      "  done: false\n",
      "  episode_len_mean: 94.74528301886792\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.760000000000014\n",
      "  episode_reward_mean: 1.7713207547169856\n",
      "  episode_reward_min: -1.940000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2736\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6108538896609574\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01379613712697335\n",
      "          policy_loss: -0.06169816500738136\n",
      "          total_loss: 0.15544778294542916\n",
      "          vf_explained_var: 0.7594130039215088\n",
      "          vf_loss: 0.2118251613412912\n",
      "    num_agent_steps_sampled: 259896\n",
      "    num_agent_steps_trained: 259896\n",
      "    num_steps_sampled: 259896\n",
      "    num_steps_trained: 259896\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94784946236558\n",
      "    ram_util_percent: 55.270430107526884\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04631217400625006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.92790114786156\n",
      "    mean_inference_ms: 2.8881069666038055\n",
      "    mean_raw_obs_processing_ms: 2.1466322534144235\n",
      "  time_since_restore: 3677.9159741401672\n",
      "  time_this_iter_s: 130.5661063194275\n",
      "  time_total_s: 3677.9159741401672\n",
      "  timers:\n",
      "    learn_throughput: 933.523\n",
      "    learn_time_ms: 10707.826\n",
      "    load_throughput: 91437.644\n",
      "    load_time_ms: 109.32\n",
      "    sample_throughput: 76.568\n",
      "    sample_time_ms: 130551.056\n",
      "    update_time_ms: 11.816\n",
      "  timestamp: 1636298087\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259896\n",
      "  training_iteration: 26\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         3677.92</td><td style=\"text-align: right;\">259896</td><td style=\"text-align: right;\"> 1.77132</td><td style=\"text-align: right;\">                6.76</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           94.7453</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 269892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-17-01\n",
      "  done: false\n",
      "  episode_len_mean: 93.93396226415095\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.040000000000008\n",
      "  episode_reward_mean: 1.4718867924528343\n",
      "  episode_reward_min: -2.0300000000000002\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2842\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5977021584144007\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01471472682495184\n",
      "          policy_loss: -0.05705817122665099\n",
      "          total_loss: 0.16943415715398952\n",
      "          vf_explained_var: 0.758998453617096\n",
      "          vf_loss: 0.21894736185860939\n",
      "    num_agent_steps_sampled: 269892\n",
      "    num_agent_steps_trained: 269892\n",
      "    num_steps_sampled: 269892\n",
      "    num_steps_trained: 269892\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.07068062827226\n",
      "    ram_util_percent: 55.23298429319372\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04628845397068409\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.908661322964505\n",
      "    mean_inference_ms: 2.887528752063432\n",
      "    mean_raw_obs_processing_ms: 2.0939639431920876\n",
      "  time_since_restore: 3811.537496805191\n",
      "  time_this_iter_s: 133.6215226650238\n",
      "  time_total_s: 3811.537496805191\n",
      "  timers:\n",
      "    learn_throughput: 933.402\n",
      "    learn_time_ms: 10709.213\n",
      "    load_throughput: 91438.9\n",
      "    load_time_ms: 109.319\n",
      "    sample_throughput: 76.617\n",
      "    sample_time_ms: 130466.394\n",
      "    update_time_ms: 12.336\n",
      "  timestamp: 1636298221\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269892\n",
      "  training_iteration: 27\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         3811.54</td><td style=\"text-align: right;\">269892</td><td style=\"text-align: right;\"> 1.47189</td><td style=\"text-align: right;\">                7.04</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">            93.934</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 279888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-19-46\n",
      "  done: false\n",
      "  episode_len_mean: 89.7090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.450000000000017\n",
      "  episode_reward_mean: 1.927181818181823\n",
      "  episode_reward_min: -1.5900000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 2952\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5961202947502464\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014860427716147399\n",
      "          policy_loss: -0.059911946554341886\n",
      "          total_loss: 0.15723997231763906\n",
      "          vf_explained_var: 0.796622097492218\n",
      "          vf_loss: 0.2092592091164273\n",
      "    num_agent_steps_sampled: 279888\n",
      "    num_agent_steps_trained: 279888\n",
      "    num_steps_sampled: 279888\n",
      "    num_steps_trained: 279888\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.87659574468086\n",
      "    ram_util_percent: 55.12340425531915\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0462344618079206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.87630047381702\n",
      "    mean_inference_ms: 2.8860159748086898\n",
      "    mean_raw_obs_processing_ms: 2.2223291200536535\n",
      "  time_since_restore: 3976.8124108314514\n",
      "  time_this_iter_s: 165.27491402626038\n",
      "  time_total_s: 3976.8124108314514\n",
      "  timers:\n",
      "    learn_throughput: 933.629\n",
      "    learn_time_ms: 10706.606\n",
      "    load_throughput: 91549.794\n",
      "    load_time_ms: 109.186\n",
      "    sample_throughput: 75.799\n",
      "    sample_time_ms: 131875.755\n",
      "    update_time_ms: 11.187\n",
      "  timestamp: 1636298386\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279888\n",
      "  training_iteration: 28\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         3976.81</td><td style=\"text-align: right;\">279888</td><td style=\"text-align: right;\"> 1.92718</td><td style=\"text-align: right;\">               10.45</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           89.7091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 289884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-22-27\n",
      "  done: false\n",
      "  episode_len_mean: 94.51886792452831\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.65000000000001\n",
      "  episode_reward_mean: 1.8350000000000048\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 3058\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.606220671865675\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014981504349387097\n",
      "          policy_loss: -0.06278664395213127\n",
      "          total_loss: 0.15470395680103038\n",
      "          vf_explained_var: 0.771485447883606\n",
      "          vf_loss: 0.2094230675512654\n",
      "    num_agent_steps_sampled: 289884\n",
      "    num_agent_steps_trained: 289884\n",
      "    num_steps_sampled: 289884\n",
      "    num_steps_trained: 289884\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.1401746724891\n",
      "    ram_util_percent: 55.3943231441048\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04620853571649846\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.79623139592005\n",
      "    mean_inference_ms: 2.8844873886314026\n",
      "    mean_raw_obs_processing_ms: 2.2961703348768\n",
      "  time_since_restore: 4137.228857278824\n",
      "  time_this_iter_s: 160.41644644737244\n",
      "  time_total_s: 4137.228857278824\n",
      "  timers:\n",
      "    learn_throughput: 933.6\n",
      "    learn_time_ms: 10706.944\n",
      "    load_throughput: 91580.27\n",
      "    load_time_ms: 109.15\n",
      "    sample_throughput: 74.314\n",
      "    sample_time_ms: 134511.177\n",
      "    update_time_ms: 11.321\n",
      "  timestamp: 1636298547\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289884\n",
      "  training_iteration: 29\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         4137.23</td><td style=\"text-align: right;\">289884</td><td style=\"text-align: right;\">   1.835</td><td style=\"text-align: right;\">                8.65</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           94.5189</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 299880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-24-52\n",
      "  done: false\n",
      "  episode_len_mean: 94.28971962616822\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.800000000000013\n",
      "  episode_reward_mean: 1.85009345794393\n",
      "  episode_reward_min: -1.780000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 3165\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5891247506834505\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015358496355499707\n",
      "          policy_loss: -0.059769737040703624\n",
      "          total_loss: 0.1456004789704059\n",
      "          vf_explained_var: 0.8247190117835999\n",
      "          vf_loss: 0.19627288896749673\n",
      "    num_agent_steps_sampled: 299880\n",
      "    num_agent_steps_trained: 299880\n",
      "    num_steps_sampled: 299880\n",
      "    num_steps_trained: 299880\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.03750000000001\n",
      "    ram_util_percent: 55.462500000000006\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04619119297958009\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.74889128201889\n",
      "    mean_inference_ms: 2.8841127884620743\n",
      "    mean_raw_obs_processing_ms: 2.2997601350678765\n",
      "  time_since_restore: 4282.634947538376\n",
      "  time_this_iter_s: 145.406090259552\n",
      "  time_total_s: 4282.634947538376\n",
      "  timers:\n",
      "    learn_throughput: 933.715\n",
      "    learn_time_ms: 10705.623\n",
      "    load_throughput: 91680.079\n",
      "    load_time_ms: 109.031\n",
      "    sample_throughput: 73.758\n",
      "    sample_time_ms: 135524.208\n",
      "    update_time_ms: 11.692\n",
      "  timestamp: 1636298692\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299880\n",
      "  training_iteration: 30\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         4282.63</td><td style=\"text-align: right;\">299880</td><td style=\"text-align: right;\"> 1.85009</td><td style=\"text-align: right;\">                 8.8</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           94.2897</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 309876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-27-24\n",
      "  done: false\n",
      "  episode_len_mean: 91.87962962962963\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.67000000000001\n",
      "  episode_reward_mean: 1.9979629629629683\n",
      "  episode_reward_min: -2.0600000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 3273\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.596006913470407\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015571455984420897\n",
      "          policy_loss: -0.06325977725796719\n",
      "          total_loss: 0.1750385210960785\n",
      "          vf_explained_var: 0.7946008443832397\n",
      "          vf_loss: 0.22878464420572814\n",
      "    num_agent_steps_sampled: 309876\n",
      "    num_agent_steps_trained: 309876\n",
      "    num_steps_sampled: 309876\n",
      "    num_steps_trained: 309876\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.98617511520737\n",
      "    ram_util_percent: 55.276958525345634\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04616345005125546\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.7575906098471\n",
      "    mean_inference_ms: 2.883280084049704\n",
      "    mean_raw_obs_processing_ms: 2.349029092773195\n",
      "  time_since_restore: 4434.725605726242\n",
      "  time_this_iter_s: 152.0906581878662\n",
      "  time_total_s: 4434.725605726242\n",
      "  timers:\n",
      "    learn_throughput: 933.08\n",
      "    learn_time_ms: 10712.908\n",
      "    load_throughput: 91848.065\n",
      "    load_time_ms: 108.832\n",
      "    sample_throughput: 73.885\n",
      "    sample_time_ms: 135291.382\n",
      "    update_time_ms: 12.449\n",
      "  timestamp: 1636298844\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309876\n",
      "  training_iteration: 31\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         4434.73</td><td style=\"text-align: right;\">309876</td><td style=\"text-align: right;\"> 1.99796</td><td style=\"text-align: right;\">                8.67</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           91.8796</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 319872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-29-41\n",
      "  done: false\n",
      "  episode_len_mean: 95.31428571428572\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.490000000000016\n",
      "  episode_reward_mean: 1.691523809523814\n",
      "  episode_reward_min: -2.04\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3378\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5799128216555993\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014030958009944609\n",
      "          policy_loss: -0.06791372190142035\n",
      "          total_loss: 0.1109447383791463\n",
      "          vf_explained_var: 0.7991345524787903\n",
      "          vf_loss: 0.1726933110282462\n",
      "    num_agent_steps_sampled: 319872\n",
      "    num_agent_steps_trained: 319872\n",
      "    num_steps_sampled: 319872\n",
      "    num_steps_trained: 319872\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0723076923077\n",
      "    ram_util_percent: 55.39794871794872\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046171827118766634\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.76812027636428\n",
      "    mean_inference_ms: 2.8829190737570394\n",
      "    mean_raw_obs_processing_ms: 2.303695143550204\n",
      "  time_since_restore: 4571.21800327301\n",
      "  time_this_iter_s: 136.4923975467682\n",
      "  time_total_s: 4571.21800327301\n",
      "  timers:\n",
      "    learn_throughput: 932.905\n",
      "    learn_time_ms: 10714.921\n",
      "    load_throughput: 91701.094\n",
      "    load_time_ms: 109.006\n",
      "    sample_throughput: 74.377\n",
      "    sample_time_ms: 134396.875\n",
      "    update_time_ms: 14.123\n",
      "  timestamp: 1636298981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319872\n",
      "  training_iteration: 32\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         4571.22</td><td style=\"text-align: right;\">319872</td><td style=\"text-align: right;\"> 1.69152</td><td style=\"text-align: right;\">                6.49</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           95.3143</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 329868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-32-06\n",
      "  done: false\n",
      "  episode_len_mean: 95.04761904761905\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.630000000000017\n",
      "  episode_reward_mean: 1.5121904761904803\n",
      "  episode_reward_min: -2.3599999999999968\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3483\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.590950656140971\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014188218601459362\n",
      "          policy_loss: -0.07142950187986478\n",
      "          total_loss: 0.09122342598170806\n",
      "          vf_explained_var: 0.8201923370361328\n",
      "          vf_loss: 0.1562398978548809\n",
      "    num_agent_steps_sampled: 329868\n",
      "    num_agent_steps_trained: 329868\n",
      "    num_steps_sampled: 329868\n",
      "    num_steps_trained: 329868\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78792270531402\n",
      "    ram_util_percent: 55.406280193236725\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04614359009738623\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.75714078488083\n",
      "    mean_inference_ms: 2.8823116733002614\n",
      "    mean_raw_obs_processing_ms: 2.308641580853037\n",
      "  time_since_restore: 4716.715343952179\n",
      "  time_this_iter_s: 145.4973406791687\n",
      "  time_total_s: 4716.715343952179\n",
      "  timers:\n",
      "    learn_throughput: 932.628\n",
      "    learn_time_ms: 10718.095\n",
      "    load_throughput: 91695.318\n",
      "    load_time_ms: 109.013\n",
      "    sample_throughput: 73.697\n",
      "    sample_time_ms: 135636.195\n",
      "    update_time_ms: 13.12\n",
      "  timestamp: 1636299126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329868\n",
      "  training_iteration: 33\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         4716.72</td><td style=\"text-align: right;\">329868</td><td style=\"text-align: right;\"> 1.51219</td><td style=\"text-align: right;\">                8.63</td><td style=\"text-align: right;\">               -2.36</td><td style=\"text-align: right;\">           95.0476</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 339864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-34-38\n",
      "  done: false\n",
      "  episode_len_mean: 91.8256880733945\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.980000000000011\n",
      "  episode_reward_mean: 1.6242201834862422\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 3592\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.577089279737228\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014481722452376226\n",
      "          policy_loss: -0.0660507208468695\n",
      "          total_loss: 0.11527525235174431\n",
      "          vf_explained_var: 0.7954672574996948\n",
      "          vf_loss: 0.1741056910644357\n",
      "    num_agent_steps_sampled: 339864\n",
      "    num_agent_steps_trained: 339864\n",
      "    num_steps_sampled: 339864\n",
      "    num_steps_trained: 339864\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.6078341013825\n",
      "    ram_util_percent: 55.31751152073732\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04611129798961756\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.75350053243419\n",
      "    mean_inference_ms: 2.880819240107931\n",
      "    mean_raw_obs_processing_ms: 2.363936232279669\n",
      "  time_since_restore: 4868.586982250214\n",
      "  time_this_iter_s: 151.87163829803467\n",
      "  time_total_s: 4868.586982250214\n",
      "  timers:\n",
      "    learn_throughput: 932.253\n",
      "    learn_time_ms: 10722.412\n",
      "    load_throughput: 91758.934\n",
      "    load_time_ms: 108.938\n",
      "    sample_throughput: 73.53\n",
      "    sample_time_ms: 135943.743\n",
      "    update_time_ms: 12.293\n",
      "  timestamp: 1636299278\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 339864\n",
      "  training_iteration: 34\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         4868.59</td><td style=\"text-align: right;\">339864</td><td style=\"text-align: right;\"> 1.62422</td><td style=\"text-align: right;\">                6.98</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           91.8257</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 349860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-36-49\n",
      "  done: false\n",
      "  episode_len_mean: 96.83495145631068\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.980000000000011\n",
      "  episode_reward_mean: 2.0331067961165106\n",
      "  episode_reward_min: -1.9500000000000013\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 3695\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.577457818414411\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016689053047347937\n",
      "          policy_loss: -0.06761236127752523\n",
      "          total_loss: 0.12520136356942801\n",
      "          vf_explained_var: 0.8258298635482788\n",
      "          vf_loss: 0.1805685537795608\n",
      "    num_agent_steps_sampled: 349860\n",
      "    num_agent_steps_trained: 349860\n",
      "    num_steps_sampled: 349860\n",
      "    num_steps_trained: 349860\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.81344086021502\n",
      "    ram_util_percent: 55.31344086021505\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04612629691293968\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.726984865006656\n",
      "    mean_inference_ms: 2.8813930638389578\n",
      "    mean_raw_obs_processing_ms: 2.3119300520044184\n",
      "  time_since_restore: 4998.987082958221\n",
      "  time_this_iter_s: 130.4001007080078\n",
      "  time_total_s: 4998.987082958221\n",
      "  timers:\n",
      "    learn_throughput: 932.475\n",
      "    learn_time_ms: 10719.859\n",
      "    load_throughput: 91539.26\n",
      "    load_time_ms: 109.199\n",
      "    sample_throughput: 74.426\n",
      "    sample_time_ms: 134308.796\n",
      "    update_time_ms: 11.73\n",
      "  timestamp: 1636299409\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 349860\n",
      "  training_iteration: 35\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         4998.99</td><td style=\"text-align: right;\">349860</td><td style=\"text-align: right;\"> 2.03311</td><td style=\"text-align: right;\">                8.98</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">            96.835</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 359856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-39-02\n",
      "  done: false\n",
      "  episode_len_mean: 95.87619047619047\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.920000000000014\n",
      "  episode_reward_mean: 1.9503809523809572\n",
      "  episode_reward_min: -1.850000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3800\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5778674042122995\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013657537506351576\n",
      "          policy_loss: -0.0714271578953689\n",
      "          total_loss: 0.09254649960730447\n",
      "          vf_explained_var: 0.844637393951416\n",
      "          vf_loss: 0.15863875422594895\n",
      "    num_agent_steps_sampled: 359856\n",
      "    num_agent_steps_trained: 359856\n",
      "    num_steps_sampled: 359856\n",
      "    num_steps_trained: 359856\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94240837696336\n",
      "    ram_util_percent: 55.400000000000006\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04612867645632436\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.70958744924045\n",
      "    mean_inference_ms: 2.8815269554072627\n",
      "    mean_raw_obs_processing_ms: 2.2778794222434553\n",
      "  time_since_restore: 5132.651563882828\n",
      "  time_this_iter_s: 133.66448092460632\n",
      "  time_total_s: 5132.651563882828\n",
      "  timers:\n",
      "    learn_throughput: 932.384\n",
      "    learn_time_ms: 10720.901\n",
      "    load_throughput: 91731.329\n",
      "    load_time_ms: 108.97\n",
      "    sample_throughput: 74.255\n",
      "    sample_time_ms: 134617.613\n",
      "    update_time_ms: 12.347\n",
      "  timestamp: 1636299542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 359856\n",
      "  training_iteration: 36\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         5132.65</td><td style=\"text-align: right;\">359856</td><td style=\"text-align: right;\"> 1.95038</td><td style=\"text-align: right;\">                8.92</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           95.8762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 369852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-41-28\n",
      "  done: false\n",
      "  episode_len_mean: 95.04716981132076\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.740000000000013\n",
      "  episode_reward_mean: 1.6333018867924571\n",
      "  episode_reward_min: -2.0999999999999996\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 3906\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5804361274099756\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013561249009486423\n",
      "          policy_loss: -0.07196720903938333\n",
      "          total_loss: 0.08177560055429418\n",
      "          vf_explained_var: 0.8351461887359619\n",
      "          vf_loss: 0.14865294955670832\n",
      "    num_agent_steps_sampled: 369852\n",
      "    num_agent_steps_trained: 369852\n",
      "    num_steps_sampled: 369852\n",
      "    num_steps_trained: 369852\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.79278846153846\n",
      "    ram_util_percent: 55.33894230769231\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04611354606560162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.68764151881056\n",
      "    mean_inference_ms: 2.880426549791707\n",
      "    mean_raw_obs_processing_ms: 2.2764176503501994\n",
      "  time_since_restore: 5278.522801160812\n",
      "  time_this_iter_s: 145.87123727798462\n",
      "  time_total_s: 5278.522801160812\n",
      "  timers:\n",
      "    learn_throughput: 932.88\n",
      "    learn_time_ms: 10715.21\n",
      "    load_throughput: 91757.046\n",
      "    load_time_ms: 108.94\n",
      "    sample_throughput: 73.582\n",
      "    sample_time_ms: 135849.281\n",
      "    update_time_ms: 11.477\n",
      "  timestamp: 1636299688\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 369852\n",
      "  training_iteration: 37\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         5278.52</td><td style=\"text-align: right;\">369852</td><td style=\"text-align: right;\">  1.6333</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">           95.0472</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 379848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-43-54\n",
      "  done: false\n",
      "  episode_len_mean: 96.24271844660194\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.750000000000016\n",
      "  episode_reward_mean: 2.2839805825242787\n",
      "  episode_reward_min: -1.5700000000000007\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4009\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5801565744937993\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0159658019011001\n",
      "          policy_loss: -0.06857081058506782\n",
      "          total_loss: 0.106750553755615\n",
      "          vf_explained_var: 0.8618919253349304\n",
      "          vf_loss: 0.16475083600156581\n",
      "    num_agent_steps_sampled: 379848\n",
      "    num_agent_steps_trained: 379848\n",
      "    num_steps_sampled: 379848\n",
      "    num_steps_trained: 379848\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.19903846153846\n",
      "    ram_util_percent: 55.28557692307693\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04610235055456585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.630706603905324\n",
      "    mean_inference_ms: 2.879881375900836\n",
      "    mean_raw_obs_processing_ms: 2.3251924891960147\n",
      "  time_since_restore: 5424.504304647446\n",
      "  time_this_iter_s: 145.9815034866333\n",
      "  time_total_s: 5424.504304647446\n",
      "  timers:\n",
      "    learn_throughput: 932.702\n",
      "    learn_time_ms: 10717.246\n",
      "    load_throughput: 91591.514\n",
      "    load_time_ms: 109.137\n",
      "    sample_throughput: 74.643\n",
      "    sample_time_ms: 133917.424\n",
      "    update_time_ms: 11.928\n",
      "  timestamp: 1636299834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 379848\n",
      "  training_iteration: 38\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">          5424.5</td><td style=\"text-align: right;\">379848</td><td style=\"text-align: right;\"> 2.28398</td><td style=\"text-align: right;\">                8.75</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           96.2427</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 389844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-46-08\n",
      "  done: false\n",
      "  episode_len_mean: 95.36190476190477\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.560000000000015\n",
      "  episode_reward_mean: 2.008952380952386\n",
      "  episode_reward_min: -2.1499999999999977\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 4114\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5671299068336815\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01662269888277713\n",
      "          policy_loss: -0.06767251343251421\n",
      "          total_loss: 0.14815283579608568\n",
      "          vf_explained_var: 0.8191425204277039\n",
      "          vf_loss: 0.20362806187735663\n",
      "    num_agent_steps_sampled: 389844\n",
      "    num_agent_steps_trained: 389844\n",
      "    num_steps_sampled: 389844\n",
      "    num_steps_trained: 389844\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1434554973822\n",
      "    ram_util_percent: 55.395287958115176\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04618004964662617\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.625603300417175\n",
      "    mean_inference_ms: 2.880169469574531\n",
      "    mean_raw_obs_processing_ms: 2.285595282531732\n",
      "  time_since_restore: 5557.912195682526\n",
      "  time_this_iter_s: 133.40789103507996\n",
      "  time_total_s: 5557.912195682526\n",
      "  timers:\n",
      "    learn_throughput: 932.834\n",
      "    learn_time_ms: 10715.737\n",
      "    load_throughput: 91626.883\n",
      "    load_time_ms: 109.095\n",
      "    sample_throughput: 76.179\n",
      "    sample_time_ms: 131217.969\n",
      "    update_time_ms: 12.187\n",
      "  timestamp: 1636299968\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 389844\n",
      "  training_iteration: 39\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         5557.91</td><td style=\"text-align: right;\">389844</td><td style=\"text-align: right;\"> 2.00895</td><td style=\"text-align: right;\">                8.56</td><td style=\"text-align: right;\">               -2.15</td><td style=\"text-align: right;\">           95.3619</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 399840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-48-33\n",
      "  done: false\n",
      "  episode_len_mean: 94.22641509433963\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.270000000000016\n",
      "  episode_reward_mean: 2.0293396226415146\n",
      "  episode_reward_min: -1.7900000000000011\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 4220\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.567954599347889\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015875299987843195\n",
      "          policy_loss: -0.0676957944010058\n",
      "          total_loss: 0.15062292527455168\n",
      "          vf_explained_var: 0.8293734788894653\n",
      "          vf_loss: 0.20783234760165215\n",
      "    num_agent_steps_sampled: 399840\n",
      "    num_agent_steps_trained: 399840\n",
      "    num_steps_sampled: 399840\n",
      "    num_steps_trained: 399840\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.58067632850243\n",
      "    ram_util_percent: 55.41304347826089\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04619013614102329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.59895483837778\n",
      "    mean_inference_ms: 2.8793956648689423\n",
      "    mean_raw_obs_processing_ms: 2.2917716346673345\n",
      "  time_since_restore: 5703.093265533447\n",
      "  time_this_iter_s: 145.18106985092163\n",
      "  time_total_s: 5703.093265533447\n",
      "  timers:\n",
      "    learn_throughput: 932.86\n",
      "    learn_time_ms: 10715.432\n",
      "    load_throughput: 91664.304\n",
      "    load_time_ms: 109.05\n",
      "    sample_throughput: 76.191\n",
      "    sample_time_ms: 131195.738\n",
      "    update_time_ms: 11.964\n",
      "  timestamp: 1636300113\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 399840\n",
      "  training_iteration: 40\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         5703.09</td><td style=\"text-align: right;\">399840</td><td style=\"text-align: right;\"> 2.02934</td><td style=\"text-align: right;\">                8.27</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           94.2264</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 409836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-51-12\n",
      "  done: false\n",
      "  episode_len_mean: 93.01851851851852\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.750000000000014\n",
      "  episode_reward_mean: 1.9288888888888946\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 4328\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5520285384267822\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01528005583188881\n",
      "          policy_loss: -0.06972825568264876\n",
      "          total_loss: 0.11499245790287088\n",
      "          vf_explained_var: 0.8531769514083862\n",
      "          vf_loss: 0.1754311204673006\n",
      "    num_agent_steps_sampled: 409836\n",
      "    num_agent_steps_trained: 409836\n",
      "    num_steps_sampled: 409836\n",
      "    num_steps_trained: 409836\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.56079295154184\n",
      "    ram_util_percent: 55.38325991189427\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04613971020368218\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.573236641778244\n",
      "    mean_inference_ms: 2.878475265193554\n",
      "    mean_raw_obs_processing_ms: 2.3269988738975074\n",
      "  time_since_restore: 5861.930636405945\n",
      "  time_this_iter_s: 158.83737087249756\n",
      "  time_total_s: 5861.930636405945\n",
      "  timers:\n",
      "    learn_throughput: 933.251\n",
      "    learn_time_ms: 10710.944\n",
      "    load_throughput: 91672.301\n",
      "    load_time_ms: 109.041\n",
      "    sample_throughput: 75.799\n",
      "    sample_time_ms: 131875.203\n",
      "    update_time_ms: 11.688\n",
      "  timestamp: 1636300272\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 409836\n",
      "  training_iteration: 41\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         5861.93</td><td style=\"text-align: right;\">409836</td><td style=\"text-align: right;\"> 1.92889</td><td style=\"text-align: right;\">                8.75</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           93.0185</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 419832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-53-27\n",
      "  done: false\n",
      "  episode_len_mean: 94.5904761904762\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.83000000000001\n",
      "  episode_reward_mean: 1.9240952380952427\n",
      "  episode_reward_min: -2.0300000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 4433\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.561146357935718\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014464100696988828\n",
      "          policy_loss: -0.07120111835881686\n",
      "          total_loss: 0.10623972564617283\n",
      "          vf_explained_var: 0.8271787166595459\n",
      "          vf_loss: 0.17010127793615445\n",
      "    num_agent_steps_sampled: 419832\n",
      "    num_agent_steps_trained: 419832\n",
      "    num_steps_sampled: 419832\n",
      "    num_steps_trained: 419832\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79635416666666\n",
      "    ram_util_percent: 55.35\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046167480192711774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.575901940271365\n",
      "    mean_inference_ms: 2.878871115051283\n",
      "    mean_raw_obs_processing_ms: 2.292737589758468\n",
      "  time_since_restore: 5996.796595811844\n",
      "  time_this_iter_s: 134.86595940589905\n",
      "  time_total_s: 5996.796595811844\n",
      "  timers:\n",
      "    learn_throughput: 932.849\n",
      "    learn_time_ms: 10715.557\n",
      "    load_throughput: 91808.504\n",
      "    load_time_ms: 108.879\n",
      "    sample_throughput: 75.895\n",
      "    sample_time_ms: 131708.511\n",
      "    update_time_ms: 11.0\n",
      "  timestamp: 1636300407\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 419832\n",
      "  training_iteration: 42\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">          5996.8</td><td style=\"text-align: right;\">419832</td><td style=\"text-align: right;\">  1.9241</td><td style=\"text-align: right;\">                8.83</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">           94.5905</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 429828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-55-53\n",
      "  done: false\n",
      "  episode_len_mean: 95.48076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.460000000000013\n",
      "  episode_reward_mean: 1.8645192307692364\n",
      "  episode_reward_min: -1.950000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 4537\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5704195495344635\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014213499088408391\n",
      "          policy_loss: -0.07241350992415578\n",
      "          total_loss: 0.08840426810754415\n",
      "          vf_explained_var: 0.8568517565727234\n",
      "          vf_loss: 0.15414184471512707\n",
      "    num_agent_steps_sampled: 429828\n",
      "    num_agent_steps_trained: 429828\n",
      "    num_steps_sampled: 429828\n",
      "    num_steps_trained: 429828\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.02067307692307\n",
      "    ram_util_percent: 55.332692307692305\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04619469262283264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.543405170135706\n",
      "    mean_inference_ms: 2.8786368866480077\n",
      "    mean_raw_obs_processing_ms: 2.3009425862047332\n",
      "  time_since_restore: 6142.84136390686\n",
      "  time_this_iter_s: 146.04476809501648\n",
      "  time_total_s: 6142.84136390686\n",
      "  timers:\n",
      "    learn_throughput: 932.044\n",
      "    learn_time_ms: 10724.817\n",
      "    load_throughput: 91795.478\n",
      "    load_time_ms: 108.894\n",
      "    sample_throughput: 75.869\n",
      "    sample_time_ms: 131754.224\n",
      "    update_time_ms: 10.974\n",
      "  timestamp: 1636300553\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 429828\n",
      "  training_iteration: 43\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         6142.84</td><td style=\"text-align: right;\">429828</td><td style=\"text-align: right;\"> 1.86452</td><td style=\"text-align: right;\">               10.46</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           95.4808</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 439824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_15-58-20\n",
      "  done: false\n",
      "  episode_len_mean: 93.24074074074075\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.000000000000011\n",
      "  episode_reward_mean: 1.8581481481481532\n",
      "  episode_reward_min: -2.040000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 4645\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5593346715992333\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014686770218649028\n",
      "          policy_loss: -0.07193645442812106\n",
      "          total_loss: 0.08329966200881789\n",
      "          vf_explained_var: 0.8537670969963074\n",
      "          vf_loss: 0.147371164492817\n",
      "    num_agent_steps_sampled: 439824\n",
      "    num_agent_steps_trained: 439824\n",
      "    num_steps_sampled: 439824\n",
      "    num_steps_trained: 439824\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.0009523809524\n",
      "    ram_util_percent: 55.305238095238096\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04616277319834444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.52952144349896\n",
      "    mean_inference_ms: 2.8778820601648873\n",
      "    mean_raw_obs_processing_ms: 2.3310677221801175\n",
      "  time_since_restore: 6289.517397642136\n",
      "  time_this_iter_s: 146.67603373527527\n",
      "  time_total_s: 6289.517397642136\n",
      "  timers:\n",
      "    learn_throughput: 932.179\n",
      "    learn_time_ms: 10723.266\n",
      "    load_throughput: 91295.541\n",
      "    load_time_ms: 109.491\n",
      "    sample_throughput: 76.169\n",
      "    sample_time_ms: 131235.32\n",
      "    update_time_ms: 11.337\n",
      "  timestamp: 1636300700\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 439824\n",
      "  training_iteration: 44\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         6289.52</td><td style=\"text-align: right;\">439824</td><td style=\"text-align: right;\"> 1.85815</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           93.2407</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 449820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-00-39\n",
      "  done: false\n",
      "  episode_len_mean: 94.82857142857142\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.240000000000014\n",
      "  episode_reward_mean: 1.5230476190476232\n",
      "  episode_reward_min: -1.8500000000000008\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 4750\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.56350114080641\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014893604130610746\n",
      "          policy_loss: -0.07071394389813654\n",
      "          total_loss: 0.09965109720061986\n",
      "          vf_explained_var: 0.8395570516586304\n",
      "          vf_loss: 0.16207055969912018\n",
      "    num_agent_steps_sampled: 449820\n",
      "    num_agent_steps_trained: 449820\n",
      "    num_steps_sampled: 449820\n",
      "    num_steps_trained: 449820\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5959595959596\n",
      "    ram_util_percent: 55.224747474747474\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04615468063033617\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.54416641152054\n",
      "    mean_inference_ms: 2.8783284354254066\n",
      "    mean_raw_obs_processing_ms: 2.298786701907116\n",
      "  time_since_restore: 6428.6635711193085\n",
      "  time_this_iter_s: 139.14617347717285\n",
      "  time_total_s: 6428.6635711193085\n",
      "  timers:\n",
      "    learn_throughput: 932.177\n",
      "    learn_time_ms: 10723.291\n",
      "    load_throughput: 91460.902\n",
      "    load_time_ms: 109.293\n",
      "    sample_throughput: 75.664\n",
      "    sample_time_ms: 132110.427\n",
      "    update_time_ms: 10.874\n",
      "  timestamp: 1636300839\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 449820\n",
      "  training_iteration: 45\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         6428.66</td><td style=\"text-align: right;\">449820</td><td style=\"text-align: right;\"> 1.52305</td><td style=\"text-align: right;\">                8.24</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           94.8286</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 459816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-02-58\n",
      "  done: false\n",
      "  episode_len_mean: 94.95283018867924\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.730000000000014\n",
      "  episode_reward_mean: 1.7146226415094385\n",
      "  episode_reward_min: -2.219999999999999\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 4856\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.564808814953535\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015036150505772602\n",
      "          policy_loss: -0.07232849399248759\n",
      "          total_loss: 0.10650955833590184\n",
      "          vf_explained_var: 0.817345380783081\n",
      "          vf_loss: 0.17023190990981893\n",
      "    num_agent_steps_sampled: 459816\n",
      "    num_agent_steps_trained: 459816\n",
      "    num_steps_sampled: 459816\n",
      "    num_steps_trained: 459816\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59899497487437\n",
      "    ram_util_percent: 55.4105527638191\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04615345058245326\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.58141825002222\n",
      "    mean_inference_ms: 2.87848506684315\n",
      "    mean_raw_obs_processing_ms: 2.2638703404884355\n",
      "  time_since_restore: 6568.209861755371\n",
      "  time_this_iter_s: 139.54629063606262\n",
      "  time_total_s: 6568.209861755371\n",
      "  timers:\n",
      "    learn_throughput: 931.777\n",
      "    learn_time_ms: 10727.885\n",
      "    load_throughput: 91236.476\n",
      "    load_time_ms: 109.561\n",
      "    sample_throughput: 75.331\n",
      "    sample_time_ms: 132693.83\n",
      "    update_time_ms: 10.478\n",
      "  timestamp: 1636300978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 459816\n",
      "  training_iteration: 46\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         6568.21</td><td style=\"text-align: right;\">459816</td><td style=\"text-align: right;\"> 1.71462</td><td style=\"text-align: right;\">                6.73</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           94.9528</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 469812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-05-32\n",
      "  done: false\n",
      "  episode_len_mean: 93.1588785046729\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.490000000000016\n",
      "  episode_reward_mean: 2.128411214953277\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 4963\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5591368204508074\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013272293279782063\n",
      "          policy_loss: -0.07708250068796751\n",
      "          total_loss: 0.06380885333682482\n",
      "          vf_explained_var: 0.881742537021637\n",
      "          vf_loss: 0.13624677850076786\n",
      "    num_agent_steps_sampled: 469812\n",
      "    num_agent_steps_trained: 469812\n",
      "    num_steps_sampled: 469812\n",
      "    num_steps_trained: 469812\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.73059360730593\n",
      "    ram_util_percent: 55.5255707762557\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046107312476407536\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.60469687689716\n",
      "    mean_inference_ms: 2.878862518801144\n",
      "    mean_raw_obs_processing_ms: 2.2644000391501087\n",
      "  time_since_restore: 6721.456665277481\n",
      "  time_this_iter_s: 153.24680352210999\n",
      "  time_total_s: 6721.456665277481\n",
      "  timers:\n",
      "    learn_throughput: 931.339\n",
      "    learn_time_ms: 10732.928\n",
      "    load_throughput: 91240.844\n",
      "    load_time_ms: 109.556\n",
      "    sample_throughput: 74.918\n",
      "    sample_time_ms: 133426.082\n",
      "    update_time_ms: 10.473\n",
      "  timestamp: 1636301132\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 469812\n",
      "  training_iteration: 47\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         6721.46</td><td style=\"text-align: right;\">469812</td><td style=\"text-align: right;\"> 2.12841</td><td style=\"text-align: right;\">                6.49</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           93.1589</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 479808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-08-14\n",
      "  done: false\n",
      "  episode_len_mean: 90.80733944954129\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.380000000000011\n",
      "  episode_reward_mean: 2.0915596330275275\n",
      "  episode_reward_min: -1.8200000000000012\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 5072\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5439931936753104\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014731597551140304\n",
      "          policy_loss: -0.06985943971329138\n",
      "          total_loss: 0.09755601076743542\n",
      "          vf_explained_var: 0.8305252194404602\n",
      "          vf_loss: 0.15929496026414836\n",
      "    num_agent_steps_sampled: 479808\n",
      "    num_agent_steps_trained: 479808\n",
      "    num_steps_sampled: 479808\n",
      "    num_steps_trained: 479808\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.76206896551724\n",
      "    ram_util_percent: 55.5051724137931\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04610799800810462\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.59059079819863\n",
      "    mean_inference_ms: 2.877405296936729\n",
      "    mean_raw_obs_processing_ms: 2.3397202983523506\n",
      "  time_since_restore: 6883.7867436409\n",
      "  time_this_iter_s: 162.33007836341858\n",
      "  time_total_s: 6883.7867436409\n",
      "  timers:\n",
      "    learn_throughput: 930.558\n",
      "    learn_time_ms: 10741.942\n",
      "    load_throughput: 91227.106\n",
      "    load_time_ms: 109.573\n",
      "    sample_throughput: 74.016\n",
      "    sample_time_ms: 135051.728\n",
      "    update_time_ms: 10.536\n",
      "  timestamp: 1636301294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 479808\n",
      "  training_iteration: 48\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         6883.79</td><td style=\"text-align: right;\">479808</td><td style=\"text-align: right;\"> 2.09156</td><td style=\"text-align: right;\">               10.38</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           90.8073</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 489804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-10-29\n",
      "  done: false\n",
      "  episode_len_mean: 94.27102803738318\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.390000000000008\n",
      "  episode_reward_mean: 2.112803738317763\n",
      "  episode_reward_min: -1.8000000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 5179\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5340808964183186\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015145745135985541\n",
      "          policy_loss: -0.07466301664582685\n",
      "          total_loss: 0.1092842457219003\n",
      "          vf_explained_var: 0.8428395390510559\n",
      "          vf_loss: 0.17478416958011878\n",
      "    num_agent_steps_sampled: 489804\n",
      "    num_agent_steps_trained: 489804\n",
      "    num_steps_sampled: 489804\n",
      "    num_steps_trained: 489804\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.75520833333333\n",
      "    ram_util_percent: 55.6484375\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04612114996941299\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.59046181918758\n",
      "    mean_inference_ms: 2.8778223775252556\n",
      "    mean_raw_obs_processing_ms: 2.3086302266102856\n",
      "  time_since_restore: 7018.570507049561\n",
      "  time_this_iter_s: 134.7837634086609\n",
      "  time_total_s: 7018.570507049561\n",
      "  timers:\n",
      "    learn_throughput: 929.976\n",
      "    learn_time_ms: 10748.669\n",
      "    load_throughput: 91134.183\n",
      "    load_time_ms: 109.684\n",
      "    sample_throughput: 73.944\n",
      "    sample_time_ms: 135182.897\n",
      "    update_time_ms: 10.108\n",
      "  timestamp: 1636301429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 489804\n",
      "  training_iteration: 49\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         7018.57</td><td style=\"text-align: right;\">489804</td><td style=\"text-align: right;\">  2.1128</td><td style=\"text-align: right;\">                8.39</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">            94.271</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 499800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-12-57\n",
      "  done: false\n",
      "  episode_len_mean: 93.23584905660377\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.180000000000012\n",
      "  episode_reward_mean: 2.1808490566037797\n",
      "  episode_reward_min: -1.9100000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 5285\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.545594003261664\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014180963433161142\n",
      "          policy_loss: -0.0785960048628159\n",
      "          total_loss: 0.07677128519066888\n",
      "          vf_explained_var: 0.8591193556785583\n",
      "          vf_loss: 0.1485172223458942\n",
      "    num_agent_steps_sampled: 499800\n",
      "    num_agent_steps_trained: 499800\n",
      "    num_steps_sampled: 499800\n",
      "    num_steps_trained: 499800\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.85781990521328\n",
      "    ram_util_percent: 55.73127962085308\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046099097798490384\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.58632100908762\n",
      "    mean_inference_ms: 2.877375668374395\n",
      "    mean_raw_obs_processing_ms: 2.3101453659471405\n",
      "  time_since_restore: 7166.3068289756775\n",
      "  time_this_iter_s: 147.73632192611694\n",
      "  time_total_s: 7166.3068289756775\n",
      "  timers:\n",
      "    learn_throughput: 929.566\n",
      "    learn_time_ms: 10753.403\n",
      "    load_throughput: 90766.088\n",
      "    load_time_ms: 110.129\n",
      "    sample_throughput: 73.808\n",
      "    sample_time_ms: 135432.689\n",
      "    update_time_ms: 10.443\n",
      "  timestamp: 1636301577\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 499800\n",
      "  training_iteration: 50\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         7166.31</td><td style=\"text-align: right;\">499800</td><td style=\"text-align: right;\"> 2.18085</td><td style=\"text-align: right;\">                7.18</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           93.2358</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 509796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-15-36\n",
      "  done: false\n",
      "  episode_len_mean: 91.33333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.870000000000009\n",
      "  episode_reward_mean: 1.8480180180180235\n",
      "  episode_reward_min: -1.980000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 5396\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.532992374387562\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014236835710875905\n",
      "          policy_loss: -0.07746718386108549\n",
      "          total_loss: 0.07171642978667704\n",
      "          vf_explained_var: 0.8644962906837463\n",
      "          vf_loss: 0.14208024507468073\n",
      "    num_agent_steps_sampled: 509796\n",
      "    num_agent_steps_trained: 509796\n",
      "    num_steps_sampled: 509796\n",
      "    num_steps_trained: 509796\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.55859030837004\n",
      "    ram_util_percent: 55.668281938326\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0460571630691793\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.58736060636473\n",
      "    mean_inference_ms: 2.8772027303701506\n",
      "    mean_raw_obs_processing_ms: 2.3367921317229468\n",
      "  time_since_restore: 7325.79000878334\n",
      "  time_this_iter_s: 159.48317980766296\n",
      "  time_total_s: 7325.79000878334\n",
      "  timers:\n",
      "    learn_throughput: 929.344\n",
      "    learn_time_ms: 10755.972\n",
      "    load_throughput: 90802.612\n",
      "    load_time_ms: 110.085\n",
      "    sample_throughput: 73.774\n",
      "    sample_time_ms: 135495.331\n",
      "    update_time_ms: 9.742\n",
      "  timestamp: 1636301736\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 509796\n",
      "  training_iteration: 51\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         7325.79</td><td style=\"text-align: right;\">509796</td><td style=\"text-align: right;\"> 1.84802</td><td style=\"text-align: right;\">                6.87</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           91.3333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 519792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-17-59\n",
      "  done: false\n",
      "  episode_len_mean: 91.18181818181819\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.620000000000015\n",
      "  episode_reward_mean: 2.0980909090909146\n",
      "  episode_reward_min: -1.8600000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 5506\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.524516623244326\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015742568719724428\n",
      "          policy_loss: -0.07358359354269556\n",
      "          total_loss: 0.09564714084307735\n",
      "          vf_explained_var: 0.8636862635612488\n",
      "          vf_loss: 0.15861236117461808\n",
      "    num_agent_steps_sampled: 519792\n",
      "    num_agent_steps_trained: 519792\n",
      "    num_steps_sampled: 519792\n",
      "    num_steps_trained: 519792\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87303921568626\n",
      "    ram_util_percent: 55.7186274509804\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04612577985630845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.62099958211248\n",
      "    mean_inference_ms: 2.8775924164973112\n",
      "    mean_raw_obs_processing_ms: 2.309658204250145\n",
      "  time_since_restore: 7468.501216650009\n",
      "  time_this_iter_s: 142.7112078666687\n",
      "  time_total_s: 7468.501216650009\n",
      "  timers:\n",
      "    learn_throughput: 929.839\n",
      "    learn_time_ms: 10750.244\n",
      "    load_throughput: 90879.078\n",
      "    load_time_ms: 109.992\n",
      "    sample_throughput: 73.346\n",
      "    sample_time_ms: 136286.082\n",
      "    update_time_ms: 9.55\n",
      "  timestamp: 1636301879\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 519792\n",
      "  training_iteration: 52\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">          7468.5</td><td style=\"text-align: right;\">519792</td><td style=\"text-align: right;\"> 2.09809</td><td style=\"text-align: right;\">                8.62</td><td style=\"text-align: right;\">               -1.86</td><td style=\"text-align: right;\">           91.1818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 529788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-20-33\n",
      "  done: false\n",
      "  episode_len_mean: 91.49074074074075\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.430000000000016\n",
      "  episode_reward_mean: 2.2202777777777833\n",
      "  episode_reward_min: -2.1299999999999994\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 5614\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.527949186675569\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014769316274662285\n",
      "          policy_loss: -0.07696815397845119\n",
      "          total_loss: 0.08713866675065624\n",
      "          vf_explained_var: 0.8555226922035217\n",
      "          vf_loss: 0.15573996261128376\n",
      "    num_agent_steps_sampled: 529788\n",
      "    num_agent_steps_trained: 529788\n",
      "    num_steps_sampled: 529788\n",
      "    num_steps_trained: 529788\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.53681818181818\n",
      "    ram_util_percent: 55.82272727272726\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046122586276825965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.64708523671183\n",
      "    mean_inference_ms: 2.8770725273695783\n",
      "    mean_raw_obs_processing_ms: 2.3108191855151667\n",
      "  time_since_restore: 7622.479387998581\n",
      "  time_this_iter_s: 153.97817134857178\n",
      "  time_total_s: 7622.479387998581\n",
      "  timers:\n",
      "    learn_throughput: 930.389\n",
      "    learn_time_ms: 10743.891\n",
      "    load_throughput: 90768.701\n",
      "    load_time_ms: 110.126\n",
      "    sample_throughput: 72.918\n",
      "    sample_time_ms: 137084.662\n",
      "    update_time_ms: 10.634\n",
      "  timestamp: 1636302033\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 529788\n",
      "  training_iteration: 53\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         7622.48</td><td style=\"text-align: right;\">529788</td><td style=\"text-align: right;\"> 2.22028</td><td style=\"text-align: right;\">               10.43</td><td style=\"text-align: right;\">               -2.13</td><td style=\"text-align: right;\">           91.4907</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 539784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-23-07\n",
      "  done: false\n",
      "  episode_len_mean: 90.61261261261261\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.600000000000016\n",
      "  episode_reward_mean: 2.196396396396401\n",
      "  episode_reward_min: -1.870000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 5725\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5242018518284857\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014813252982191945\n",
      "          policy_loss: -0.07621061086463622\n",
      "          total_loss: 0.08345162549541674\n",
      "          vf_explained_var: 0.8602564930915833\n",
      "          vf_loss: 0.15115781093223227\n",
      "    num_agent_steps_sampled: 539784\n",
      "    num_agent_steps_trained: 539784\n",
      "    num_steps_sampled: 539784\n",
      "    num_steps_trained: 539784\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.59132420091325\n",
      "    ram_util_percent: 55.81780821917809\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04609013147391953\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.666814568910745\n",
      "    mean_inference_ms: 2.8765625228922675\n",
      "    mean_raw_obs_processing_ms: 2.3158458877650907\n",
      "  time_since_restore: 7776.377554893494\n",
      "  time_this_iter_s: 153.89816689491272\n",
      "  time_total_s: 7776.377554893494\n",
      "  timers:\n",
      "    learn_throughput: 930.534\n",
      "    learn_time_ms: 10742.223\n",
      "    load_throughput: 91257.407\n",
      "    load_time_ms: 109.536\n",
      "    sample_throughput: 72.535\n",
      "    sample_time_ms: 137808.438\n",
      "    update_time_ms: 11.474\n",
      "  timestamp: 1636302187\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 539784\n",
      "  training_iteration: 54\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         7776.38</td><td style=\"text-align: right;\">539784</td><td style=\"text-align: right;\">  2.1964</td><td style=\"text-align: right;\">                 8.6</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">           90.6126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 549780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-25-35\n",
      "  done: false\n",
      "  episode_len_mean: 91.39090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.780000000000015\n",
      "  episode_reward_mean: 2.0540909090909145\n",
      "  episode_reward_min: -1.8500000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 5835\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.522494824727376\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0140641469732893\n",
      "          policy_loss: -0.07968450096141325\n",
      "          total_loss: 0.07265520009220156\n",
      "          vf_explained_var: 0.8725035190582275\n",
      "          vf_loss: 0.14552476265205022\n",
      "    num_agent_steps_sampled: 549780\n",
      "    num_agent_steps_trained: 549780\n",
      "    num_steps_sampled: 549780\n",
      "    num_steps_trained: 549780\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.83981042654028\n",
      "    ram_util_percent: 55.73270142180095\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046087181032479774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6712393787162\n",
      "    mean_inference_ms: 2.876075639290351\n",
      "    mean_raw_obs_processing_ms: 2.3151861762371957\n",
      "  time_since_restore: 7924.302449703217\n",
      "  time_this_iter_s: 147.9248948097229\n",
      "  time_total_s: 7924.302449703217\n",
      "  timers:\n",
      "    learn_throughput: 930.439\n",
      "    learn_time_ms: 10743.314\n",
      "    load_throughput: 91144.684\n",
      "    load_time_ms: 109.672\n",
      "    sample_throughput: 72.077\n",
      "    sample_time_ms: 138684.669\n",
      "    update_time_ms: 11.878\n",
      "  timestamp: 1636302335\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 549780\n",
      "  training_iteration: 55\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">          7924.3</td><td style=\"text-align: right;\">549780</td><td style=\"text-align: right;\"> 2.05409</td><td style=\"text-align: right;\">                8.78</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           91.3909</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 559776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-27-55\n",
      "  done: false\n",
      "  episode_len_mean: 91.71296296296296\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.800000000000015\n",
      "  episode_reward_mean: 2.191388888888895\n",
      "  episode_reward_min: -1.890000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 5943\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.53522239281581\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015464562596789137\n",
      "          policy_loss: -0.07699231628296721\n",
      "          total_loss: 0.0968958381547505\n",
      "          vf_explained_var: 0.8440979719161987\n",
      "          vf_loss: 0.1640101716384037\n",
      "    num_agent_steps_sampled: 559776\n",
      "    num_agent_steps_trained: 559776\n",
      "    num_steps_sampled: 559776\n",
      "    num_steps_trained: 559776\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77349999999998\n",
      "    ram_util_percent: 55.73350000000001\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04610283826908509\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6952838033778\n",
      "    mean_inference_ms: 2.876488119066976\n",
      "    mean_raw_obs_processing_ms: 2.2884527325994135\n",
      "  time_since_restore: 8064.135405778885\n",
      "  time_this_iter_s: 139.83295607566833\n",
      "  time_total_s: 8064.135405778885\n",
      "  timers:\n",
      "    learn_throughput: 931.095\n",
      "    learn_time_ms: 10735.747\n",
      "    load_throughput: 91155.84\n",
      "    load_time_ms: 109.658\n",
      "    sample_throughput: 72.059\n",
      "    sample_time_ms: 138720.502\n",
      "    update_time_ms: 12.503\n",
      "  timestamp: 1636302475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 559776\n",
      "  training_iteration: 56\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         8064.14</td><td style=\"text-align: right;\">559776</td><td style=\"text-align: right;\"> 2.19139</td><td style=\"text-align: right;\">                 8.8</td><td style=\"text-align: right;\">               -1.89</td><td style=\"text-align: right;\">            91.713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 569772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-30-39\n",
      "  done: false\n",
      "  episode_len_mean: 90.17117117117117\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.750000000000012\n",
      "  episode_reward_mean: 2.180180180180186\n",
      "  episode_reward_min: -2.1899999999999946\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 6054\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.529910491266821\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014673865935924763\n",
      "          policy_loss: -0.07442047044029858\n",
      "          total_loss: 0.08197846586664773\n",
      "          vf_explained_var: 0.8836137652397156\n",
      "          vf_loss: 0.14826914014883785\n",
      "    num_agent_steps_sampled: 569772\n",
      "    num_agent_steps_trained: 569772\n",
      "    num_steps_sampled: 569772\n",
      "    num_steps_trained: 569772\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.72808510638298\n",
      "    ram_util_percent: 55.314468085106384\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04610084472159873\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.68992593080451\n",
      "    mean_inference_ms: 2.875759354736865\n",
      "    mean_raw_obs_processing_ms: 2.322061416752839\n",
      "  time_since_restore: 8228.792776823044\n",
      "  time_this_iter_s: 164.65737104415894\n",
      "  time_total_s: 8228.792776823044\n",
      "  timers:\n",
      "    learn_throughput: 930.931\n",
      "    learn_time_ms: 10737.639\n",
      "    load_throughput: 91127.884\n",
      "    load_time_ms: 109.692\n",
      "    sample_throughput: 71.472\n",
      "    sample_time_ms: 139859.199\n",
      "    update_time_ms: 13.159\n",
      "  timestamp: 1636302639\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 569772\n",
      "  training_iteration: 57\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         8228.79</td><td style=\"text-align: right;\">569772</td><td style=\"text-align: right;\"> 2.18018</td><td style=\"text-align: right;\">                8.75</td><td style=\"text-align: right;\">               -2.19</td><td style=\"text-align: right;\">           90.1712</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 579768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-33-12\n",
      "  done: false\n",
      "  episode_len_mean: 91.69090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.060000000000016\n",
      "  episode_reward_mean: 1.8883636363636416\n",
      "  episode_reward_min: -2.4199999999999955\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 6164\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.546999739581703\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01514762145677973\n",
      "          policy_loss: -0.07697513151165639\n",
      "          total_loss: 0.07620279411904705\n",
      "          vf_explained_var: 0.8709275722503662\n",
      "          vf_loss: 0.1441397468599244\n",
      "    num_agent_steps_sampled: 579768\n",
      "    num_agent_steps_trained: 579768\n",
      "    num_steps_sampled: 579768\n",
      "    num_steps_trained: 579768\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.82811059907834\n",
      "    ram_util_percent: 55.30276497695853\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04607392982568503\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.699416699852165\n",
      "    mean_inference_ms: 2.875742401279288\n",
      "    mean_raw_obs_processing_ms: 2.319462024536496\n",
      "  time_since_restore: 8381.049971103668\n",
      "  time_this_iter_s: 152.2571942806244\n",
      "  time_total_s: 8381.049971103668\n",
      "  timers:\n",
      "    learn_throughput: 931.013\n",
      "    learn_time_ms: 10736.69\n",
      "    load_throughput: 91111.329\n",
      "    load_time_ms: 109.712\n",
      "    sample_throughput: 71.99\n",
      "    sample_time_ms: 138853.135\n",
      "    update_time_ms: 12.716\n",
      "  timestamp: 1636302792\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 579768\n",
      "  training_iteration: 58\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         8381.05</td><td style=\"text-align: right;\">579768</td><td style=\"text-align: right;\"> 1.88836</td><td style=\"text-align: right;\">               14.06</td><td style=\"text-align: right;\">               -2.42</td><td style=\"text-align: right;\">           91.6909</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 589764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-35-30\n",
      "  done: false\n",
      "  episode_len_mean: 91.91588785046729\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.670000000000012\n",
      "  episode_reward_mean: 1.9292523364486036\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 6271\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5469099193556697\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013852522687118242\n",
      "          policy_loss: -0.08131109522974007\n",
      "          total_loss: 0.05720965184239495\n",
      "          vf_explained_var: 0.8883196711540222\n",
      "          vf_loss: 0.13243206675427083\n",
      "    num_agent_steps_sampled: 589764\n",
      "    num_agent_steps_trained: 589764\n",
      "    num_steps_sampled: 589764\n",
      "    num_steps_trained: 589764\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87929292929292\n",
      "    ram_util_percent: 55.37929292929294\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04608580144249278\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.710392070020035\n",
      "    mean_inference_ms: 2.8763969241157485\n",
      "    mean_raw_obs_processing_ms: 2.294870631464631\n",
      "  time_since_restore: 8519.482124328613\n",
      "  time_this_iter_s: 138.43215322494507\n",
      "  time_total_s: 8519.482124328613\n",
      "  timers:\n",
      "    learn_throughput: 931.673\n",
      "    learn_time_ms: 10729.081\n",
      "    load_throughput: 91181.513\n",
      "    load_time_ms: 109.627\n",
      "    sample_throughput: 71.798\n",
      "    sample_time_ms: 139224.709\n",
      "    update_time_ms: 13.646\n",
      "  timestamp: 1636302930\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 589764\n",
      "  training_iteration: 59\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         8519.48</td><td style=\"text-align: right;\">589764</td><td style=\"text-align: right;\"> 1.92925</td><td style=\"text-align: right;\">                6.67</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           91.9159</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 599760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-37-59\n",
      "  done: false\n",
      "  episode_len_mean: 90.58558558558559\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.78000000000001\n",
      "  episode_reward_mean: 1.8138738738738784\n",
      "  episode_reward_min: -1.9500000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 6382\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5309097277812467\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015351514849588018\n",
      "          policy_loss: -0.07559093122617301\n",
      "          total_loss: 0.08376154069287273\n",
      "          vf_explained_var: 0.8537603616714478\n",
      "          vf_loss: 0.14968889787729478\n",
      "    num_agent_steps_sampled: 599760\n",
      "    num_agent_steps_trained: 599760\n",
      "    num_steps_sampled: 599760\n",
      "    num_steps_trained: 599760\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.45471698113208\n",
      "    ram_util_percent: 55.38301886792454\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04607841938932963\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.71552306424473\n",
      "    mean_inference_ms: 2.8766515543523186\n",
      "    mean_raw_obs_processing_ms: 2.295011506199002\n",
      "  time_since_restore: 8668.339699029922\n",
      "  time_this_iter_s: 148.8575747013092\n",
      "  time_total_s: 8668.339699029922\n",
      "  timers:\n",
      "    learn_throughput: 931.952\n",
      "    learn_time_ms: 10725.88\n",
      "    load_throughput: 91406.426\n",
      "    load_time_ms: 109.358\n",
      "    sample_throughput: 71.738\n",
      "    sample_time_ms: 139340.705\n",
      "    update_time_ms: 13.825\n",
      "  timestamp: 1636303079\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 599760\n",
      "  training_iteration: 60\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         8668.34</td><td style=\"text-align: right;\">599760</td><td style=\"text-align: right;\"> 1.81387</td><td style=\"text-align: right;\">                8.78</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           90.5856</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 609756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-40-45\n",
      "  done: false\n",
      "  episode_len_mean: 90.49549549549549\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.550000000000013\n",
      "  episode_reward_mean: 2.0107207207207254\n",
      "  episode_reward_min: -1.8200000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 6493\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5183654834062623\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014342680566373276\n",
      "          policy_loss: -0.0780673203846583\n",
      "          total_loss: 0.06909490151123868\n",
      "          vf_explained_var: 0.876209557056427\n",
      "          vf_loss: 0.1396714557837854\n",
      "    num_agent_steps_sampled: 609756\n",
      "    num_agent_steps_trained: 609756\n",
      "    num_steps_sampled: 609756\n",
      "    num_steps_trained: 609756\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.09409282700423\n",
      "    ram_util_percent: 55.378059071729965\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04606145621405746\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.73046116036289\n",
      "    mean_inference_ms: 2.87573074172008\n",
      "    mean_raw_obs_processing_ms: 2.3277527521074917\n",
      "  time_since_restore: 8834.523471832275\n",
      "  time_this_iter_s: 166.1837728023529\n",
      "  time_total_s: 8834.523471832275\n",
      "  timers:\n",
      "    learn_throughput: 932.163\n",
      "    learn_time_ms: 10723.443\n",
      "    load_throughput: 91381.383\n",
      "    load_time_ms: 109.388\n",
      "    sample_throughput: 71.393\n",
      "    sample_time_ms: 140013.131\n",
      "    update_time_ms: 13.949\n",
      "  timestamp: 1636303245\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 609756\n",
      "  training_iteration: 61\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         8834.52</td><td style=\"text-align: right;\">609756</td><td style=\"text-align: right;\"> 2.01072</td><td style=\"text-align: right;\">               10.55</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           90.4955</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 619752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-43-02\n",
      "  done: false\n",
      "  episode_len_mean: 91.36697247706422\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.800000000000011\n",
      "  episode_reward_mean: 1.7664220183486277\n",
      "  episode_reward_min: -1.9700000000000009\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 6602\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5197524671880607\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014416355685275108\n",
      "          policy_loss: -0.07902193694797337\n",
      "          total_loss: 0.07330178211912768\n",
      "          vf_explained_var: 0.845158040523529\n",
      "          vf_loss: 0.1446789818059685\n",
      "    num_agent_steps_sampled: 619752\n",
      "    num_agent_steps_trained: 619752\n",
      "    num_steps_sampled: 619752\n",
      "    num_steps_trained: 619752\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01384615384615\n",
      "    ram_util_percent: 55.386153846153846\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04604153030412555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.74442634496995\n",
      "    mean_inference_ms: 2.8759356058433805\n",
      "    mean_raw_obs_processing_ms: 2.301375587338436\n",
      "  time_since_restore: 8970.916933774948\n",
      "  time_this_iter_s: 136.39346194267273\n",
      "  time_total_s: 8970.916933774948\n",
      "  timers:\n",
      "    learn_throughput: 932.025\n",
      "    learn_time_ms: 10725.032\n",
      "    load_throughput: 91337.427\n",
      "    load_time_ms: 109.44\n",
      "    sample_throughput: 71.718\n",
      "    sample_time_ms: 139379.498\n",
      "    update_time_ms: 13.95\n",
      "  timestamp: 1636303382\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 619752\n",
      "  training_iteration: 62\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         8970.92</td><td style=\"text-align: right;\">619752</td><td style=\"text-align: right;\"> 1.76642</td><td style=\"text-align: right;\">                 8.8</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">            91.367</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 629748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-45-29\n",
      "  done: false\n",
      "  episode_len_mean: 93.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.880000000000011\n",
      "  episode_reward_mean: 2.093364485981314\n",
      "  episode_reward_min: -1.930000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 6709\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.530753030328669\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015146882652015562\n",
      "          policy_loss: -0.07482523645600701\n",
      "          total_loss: 0.09030468026255695\n",
      "          vf_explained_var: 0.8503482937812805\n",
      "          vf_loss: 0.15593095369732532\n",
      "    num_agent_steps_sampled: 629748\n",
      "    num_agent_steps_trained: 629748\n",
      "    num_steps_sampled: 629748\n",
      "    num_steps_trained: 629748\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.61857142857144\n",
      "    ram_util_percent: 55.43714285714285\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04605672599537537\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.73329012657521\n",
      "    mean_inference_ms: 2.8756695396255756\n",
      "    mean_raw_obs_processing_ms: 2.303229313576639\n",
      "  time_since_restore: 9117.96266913414\n",
      "  time_this_iter_s: 147.0457353591919\n",
      "  time_total_s: 9117.96266913414\n",
      "  timers:\n",
      "    learn_throughput: 932.124\n",
      "    learn_time_ms: 10723.895\n",
      "    load_throughput: 91597.777\n",
      "    load_time_ms: 109.129\n",
      "    sample_throughput: 72.075\n",
      "    sample_time_ms: 138688.707\n",
      "    update_time_ms: 13.099\n",
      "  timestamp: 1636303529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 629748\n",
      "  training_iteration: 63\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         9117.96</td><td style=\"text-align: right;\">629748</td><td style=\"text-align: right;\"> 2.09336</td><td style=\"text-align: right;\">                6.88</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">                93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 639744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-48-10\n",
      "  done: false\n",
      "  episode_len_mean: 92.1574074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.600000000000014\n",
      "  episode_reward_mean: 2.065833333333338\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 6817\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5338203717500734\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014881890157984329\n",
      "          policy_loss: -0.07909329196151632\n",
      "          total_loss: 0.07051155927360185\n",
      "          vf_explained_var: 0.8739203810691833\n",
      "          vf_loss: 0.14104024731577972\n",
      "    num_agent_steps_sampled: 639744\n",
      "    num_agent_steps_trained: 639744\n",
      "    num_steps_sampled: 639744\n",
      "    num_steps_trained: 639744\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.43478260869566\n",
      "    ram_util_percent: 55.413913043478246\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04600859337631235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.70959884089156\n",
      "    mean_inference_ms: 2.87455272460048\n",
      "    mean_raw_obs_processing_ms: 2.359419324935899\n",
      "  time_since_restore: 9279.407679319382\n",
      "  time_this_iter_s: 161.4450101852417\n",
      "  time_total_s: 9279.407679319382\n",
      "  timers:\n",
      "    learn_throughput: 931.48\n",
      "    learn_time_ms: 10731.31\n",
      "    load_throughput: 91507.853\n",
      "    load_time_ms: 109.237\n",
      "    sample_throughput: 71.688\n",
      "    sample_time_ms: 139436.607\n",
      "    update_time_ms: 12.564\n",
      "  timestamp: 1636303690\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 639744\n",
      "  training_iteration: 64\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         9279.41</td><td style=\"text-align: right;\">639744</td><td style=\"text-align: right;\"> 2.06583</td><td style=\"text-align: right;\">                10.6</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           92.1574</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 649740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-50-47\n",
      "  done: false\n",
      "  episode_len_mean: 92.31818181818181\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.980000000000013\n",
      "  episode_reward_mean: 2.319272727272733\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 6927\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.510494092794565\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015082894544785222\n",
      "          policy_loss: -0.0758405262652116\n",
      "          total_loss: 0.0986602287245994\n",
      "          vf_explained_var: 0.8823567628860474\n",
      "          vf_loss: 0.1652449752864802\n",
      "    num_agent_steps_sampled: 649740\n",
      "    num_agent_steps_trained: 649740\n",
      "    num_steps_sampled: 649740\n",
      "    num_steps_trained: 649740\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.36696428571429\n",
      "    ram_util_percent: 55.44687499999999\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0460045677045475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.695711169716546\n",
      "    mean_inference_ms: 2.8740498243589596\n",
      "    mean_raw_obs_processing_ms: 2.379717440456394\n",
      "  time_since_restore: 9436.169775724411\n",
      "  time_this_iter_s: 156.7620964050293\n",
      "  time_total_s: 9436.169775724411\n",
      "  timers:\n",
      "    learn_throughput: 931.768\n",
      "    learn_time_ms: 10727.995\n",
      "    load_throughput: 91737.532\n",
      "    load_time_ms: 108.963\n",
      "    sample_throughput: 71.235\n",
      "    sample_time_ms: 140324.145\n",
      "    update_time_ms: 12.564\n",
      "  timestamp: 1636303847\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 649740\n",
      "  training_iteration: 65\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         9436.17</td><td style=\"text-align: right;\">649740</td><td style=\"text-align: right;\"> 2.31927</td><td style=\"text-align: right;\">               10.98</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           92.3182</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 659736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-53-08\n",
      "  done: false\n",
      "  episode_len_mean: 92.66666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.910000000000013\n",
      "  episode_reward_mean: 1.9100925925925976\n",
      "  episode_reward_min: -2.0300000000000002\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 7035\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.519284813424461\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013587904436048188\n",
      "          policy_loss: -0.08074892077786036\n",
      "          total_loss: 0.04687129759715281\n",
      "          vf_explained_var: 0.885489821434021\n",
      "          vf_loss: 0.12185812075025378\n",
      "    num_agent_steps_sampled: 659736\n",
      "    num_agent_steps_trained: 659736\n",
      "    num_steps_sampled: 659736\n",
      "    num_steps_trained: 659736\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69651741293532\n",
      "    ram_util_percent: 55.4820895522388\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045985260760633126\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.72135054164641\n",
      "    mean_inference_ms: 2.874299831961397\n",
      "    mean_raw_obs_processing_ms: 2.3537387107990004\n",
      "  time_since_restore: 9577.072381734848\n",
      "  time_this_iter_s: 140.902606010437\n",
      "  time_total_s: 9577.072381734848\n",
      "  timers:\n",
      "    learn_throughput: 931.628\n",
      "    learn_time_ms: 10729.601\n",
      "    load_throughput: 92242.639\n",
      "    load_time_ms: 108.366\n",
      "    sample_throughput: 71.181\n",
      "    sample_time_ms: 140430.823\n",
      "    update_time_ms: 11.679\n",
      "  timestamp: 1636303988\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 659736\n",
      "  training_iteration: 66\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         9577.07</td><td style=\"text-align: right;\">659736</td><td style=\"text-align: right;\"> 1.91009</td><td style=\"text-align: right;\">                8.91</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">           92.6667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 669732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-55-49\n",
      "  done: false\n",
      "  episode_len_mean: 92.19626168224299\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.700000000000014\n",
      "  episode_reward_mean: 1.826261682242995\n",
      "  episode_reward_min: -1.930000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 7142\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5149064901547553\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01448949894752467\n",
      "          policy_loss: -0.07940300489879316\n",
      "          total_loss: 0.07568906313683997\n",
      "          vf_explained_var: 0.8735856413841248\n",
      "          vf_loss: 0.1472322430859646\n",
      "    num_agent_steps_sampled: 669732\n",
      "    num_agent_steps_trained: 669732\n",
      "    num_steps_sampled: 669732\n",
      "    num_steps_trained: 669732\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.75676855895198\n",
      "    ram_util_percent: 55.37816593886464\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04596035583487839\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.715168159149414\n",
      "    mean_inference_ms: 2.8738448387436173\n",
      "    mean_raw_obs_processing_ms: 2.38150300022501\n",
      "  time_since_restore: 9737.75196146965\n",
      "  time_this_iter_s: 160.67957973480225\n",
      "  time_total_s: 9737.75196146965\n",
      "  timers:\n",
      "    learn_throughput: 932.241\n",
      "    learn_time_ms: 10722.549\n",
      "    load_throughput: 91972.764\n",
      "    load_time_ms: 108.684\n",
      "    sample_throughput: 71.38\n",
      "    sample_time_ms: 140039.375\n",
      "    update_time_ms: 11.673\n",
      "  timestamp: 1636304149\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 669732\n",
      "  training_iteration: 67\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         9737.75</td><td style=\"text-align: right;\">669732</td><td style=\"text-align: right;\"> 1.82626</td><td style=\"text-align: right;\">                 8.7</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">           92.1963</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 679728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_16-58-23\n",
      "  done: false\n",
      "  episode_len_mean: 93.06542056074767\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.970000000000011\n",
      "  episode_reward_mean: 2.1183177570093514\n",
      "  episode_reward_min: -2.1000000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 7249\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.526982937511216\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013811302593073088\n",
      "          policy_loss: -0.07886498366347236\n",
      "          total_loss: 0.07247549689008703\n",
      "          vf_explained_var: 0.8864032626152039\n",
      "          vf_loss: 0.14514643417623563\n",
      "    num_agent_steps_sampled: 679728\n",
      "    num_agent_steps_trained: 679728\n",
      "    num_steps_sampled: 679728\n",
      "    num_steps_trained: 679728\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.14796380090498\n",
      "    ram_util_percent: 55.44343891402715\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04594617331593479\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.73239135523474\n",
      "    mean_inference_ms: 2.873585151074311\n",
      "    mean_raw_obs_processing_ms: 2.3795603915688925\n",
      "  time_since_restore: 9892.503121614456\n",
      "  time_this_iter_s: 154.7511601448059\n",
      "  time_total_s: 9892.503121614456\n",
      "  timers:\n",
      "    learn_throughput: 932.802\n",
      "    learn_time_ms: 10716.097\n",
      "    load_throughput: 91997.446\n",
      "    load_time_ms: 108.655\n",
      "    sample_throughput: 71.25\n",
      "    sample_time_ms: 140295.017\n",
      "    update_time_ms: 12.22\n",
      "  timestamp: 1636304303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 679728\n",
      "  training_iteration: 68\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">          9892.5</td><td style=\"text-align: right;\">679728</td><td style=\"text-align: right;\"> 2.11832</td><td style=\"text-align: right;\">                8.97</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">           93.0654</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 689724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-00-39\n",
      "  done: false\n",
      "  episode_len_mean: 94.75471698113208\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.80000000000002\n",
      "  episode_reward_mean: 1.9030188679245326\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 7355\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5305906124604056\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014205923328810084\n",
      "          policy_loss: -0.08023752068830096\n",
      "          total_loss: 0.06980001435129561\n",
      "          vf_explained_var: 0.8702053427696228\n",
      "          vf_loss: 0.1429805718999133\n",
      "    num_agent_steps_sampled: 689724\n",
      "    num_agent_steps_trained: 689724\n",
      "    num_steps_sampled: 689724\n",
      "    num_steps_trained: 689724\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.86391752577319\n",
      "    ram_util_percent: 55.35721649484537\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04598241494201538\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.73220025492582\n",
      "    mean_inference_ms: 2.873994598066883\n",
      "    mean_raw_obs_processing_ms: 2.358122730646507\n",
      "  time_since_restore: 10028.416161060333\n",
      "  time_this_iter_s: 135.91303944587708\n",
      "  time_total_s: 10028.416161060333\n",
      "  timers:\n",
      "    learn_throughput: 932.526\n",
      "    learn_time_ms: 10719.275\n",
      "    load_throughput: 91952.653\n",
      "    load_time_ms: 108.708\n",
      "    sample_throughput: 71.379\n",
      "    sample_time_ms: 140041.092\n",
      "    update_time_ms: 11.006\n",
      "  timestamp: 1636304439\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 689724\n",
      "  training_iteration: 69\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         10028.4</td><td style=\"text-align: right;\">689724</td><td style=\"text-align: right;\"> 1.90302</td><td style=\"text-align: right;\">                 8.8</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           94.7547</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 699720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-03-05\n",
      "  done: false\n",
      "  episode_len_mean: 94.23364485981308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.770000000000014\n",
      "  episode_reward_mean: 1.759158878504677\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 7462\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.524011458494724\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014640452362593316\n",
      "          policy_loss: -0.07918056072746842\n",
      "          total_loss: 0.07342005537138281\n",
      "          vf_explained_var: 0.8598913550376892\n",
      "          vf_loss: 0.1444879491901041\n",
      "    num_agent_steps_sampled: 699720\n",
      "    num_agent_steps_trained: 699720\n",
      "    num_steps_sampled: 699720\n",
      "    num_steps_trained: 699720\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.83221153846154\n",
      "    ram_util_percent: 55.45961538461539\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0459734404776583\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.72399397392256\n",
      "    mean_inference_ms: 2.8737874504965144\n",
      "    mean_raw_obs_processing_ms: 2.358826033353897\n",
      "  time_since_restore: 10174.246468782425\n",
      "  time_this_iter_s: 145.83030772209167\n",
      "  time_total_s: 10174.246468782425\n",
      "  timers:\n",
      "    learn_throughput: 932.266\n",
      "    learn_time_ms: 10722.264\n",
      "    load_throughput: 91980.754\n",
      "    load_time_ms: 108.675\n",
      "    sample_throughput: 71.535\n",
      "    sample_time_ms: 139735.821\n",
      "    update_time_ms: 10.342\n",
      "  timestamp: 1636304585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 699720\n",
      "  training_iteration: 70\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         10174.2</td><td style=\"text-align: right;\">699720</td><td style=\"text-align: right;\"> 1.75916</td><td style=\"text-align: right;\">                8.77</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           94.2336</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 709716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-05-34\n",
      "  done: false\n",
      "  episode_len_mean: 94.49056603773585\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.130000000000013\n",
      "  episode_reward_mean: 1.71660377358491\n",
      "  episode_reward_min: -1.9000000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 7568\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5306258757909137\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01386904838319247\n",
      "          policy_loss: -0.08397089938959505\n",
      "          total_loss: 0.06388328278469096\n",
      "          vf_explained_var: 0.8584480285644531\n",
      "          vf_loss: 0.141565014472884\n",
      "    num_agent_steps_sampled: 709716\n",
      "    num_agent_steps_trained: 709716\n",
      "    num_steps_sampled: 709716\n",
      "    num_steps_trained: 709716\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.29433962264152\n",
      "    ram_util_percent: 55.45896226415094\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04594831501429118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.72406832756425\n",
      "    mean_inference_ms: 2.8733678540807204\n",
      "    mean_raw_obs_processing_ms: 2.355362215272501\n",
      "  time_since_restore: 10322.729506492615\n",
      "  time_this_iter_s: 148.48303771018982\n",
      "  time_total_s: 10322.729506492615\n",
      "  timers:\n",
      "    learn_throughput: 932.388\n",
      "    learn_time_ms: 10720.855\n",
      "    load_throughput: 91815.199\n",
      "    load_time_ms: 108.871\n",
      "    sample_throughput: 72.452\n",
      "    sample_time_ms: 137967.013\n",
      "    update_time_ms: 10.249\n",
      "  timestamp: 1636304734\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 709716\n",
      "  training_iteration: 71\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         10322.7</td><td style=\"text-align: right;\">709716</td><td style=\"text-align: right;\">  1.7166</td><td style=\"text-align: right;\">                9.13</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           94.4906</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 719712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-08-03\n",
      "  done: false\n",
      "  episode_len_mean: 92.74766355140187\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.710000000000015\n",
      "  episode_reward_mean: 1.7808411214953312\n",
      "  episode_reward_min: -1.810000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 7675\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5413423642134054\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014785782154942233\n",
      "          policy_loss: -0.07929552043827935\n",
      "          total_loss: 0.06731085311780628\n",
      "          vf_explained_var: 0.8605018258094788\n",
      "          vf_loss: 0.13833593727750146\n",
      "    num_agent_steps_sampled: 719712\n",
      "    num_agent_steps_trained: 719712\n",
      "    num_steps_sampled: 719712\n",
      "    num_steps_trained: 719712\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.6622641509434\n",
      "    ram_util_percent: 55.47971698113207\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04594232199997967\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.719272426597705\n",
      "    mean_inference_ms: 2.8728878987384276\n",
      "    mean_raw_obs_processing_ms: 2.357506487815512\n",
      "  time_since_restore: 10471.527850151062\n",
      "  time_this_iter_s: 148.79834365844727\n",
      "  time_total_s: 10471.527850151062\n",
      "  timers:\n",
      "    learn_throughput: 932.289\n",
      "    learn_time_ms: 10722.001\n",
      "    load_throughput: 91715.477\n",
      "    load_time_ms: 108.989\n",
      "    sample_throughput: 71.807\n",
      "    sample_time_ms: 139207.308\n",
      "    update_time_ms: 9.442\n",
      "  timestamp: 1636304883\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 719712\n",
      "  training_iteration: 72\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         10471.5</td><td style=\"text-align: right;\">719712</td><td style=\"text-align: right;\"> 1.78084</td><td style=\"text-align: right;\">               10.71</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           92.7477</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 729708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-10-37\n",
      "  done: false\n",
      "  episode_len_mean: 93.03703703703704\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.78000000000001\n",
      "  episode_reward_mean: 1.7663888888888934\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 7783\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5265426352492764\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013440546279408579\n",
      "          policy_loss: -0.08088439668281976\n",
      "          total_loss: 0.0549425174577687\n",
      "          vf_explained_var: 0.8674768209457397\n",
      "          vf_loss: 0.13047309586794203\n",
      "    num_agent_steps_sampled: 729708\n",
      "    num_agent_steps_trained: 729708\n",
      "    num_steps_sampled: 729708\n",
      "    num_steps_trained: 729708\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.9218181818182\n",
      "    ram_util_percent: 55.48181818181818\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04598785315589777\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.71924873601126\n",
      "    mean_inference_ms: 2.873361949439835\n",
      "    mean_raw_obs_processing_ms: 2.362393082937832\n",
      "  time_since_restore: 10625.609754562378\n",
      "  time_this_iter_s: 154.08190441131592\n",
      "  time_total_s: 10625.609754562378\n",
      "  timers:\n",
      "    learn_throughput: 932.46\n",
      "    learn_time_ms: 10720.026\n",
      "    load_throughput: 91364.755\n",
      "    load_time_ms: 109.408\n",
      "    sample_throughput: 71.445\n",
      "    sample_time_ms: 139911.723\n",
      "    update_time_ms: 9.979\n",
      "  timestamp: 1636305037\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 729708\n",
      "  training_iteration: 73\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         10625.6</td><td style=\"text-align: right;\">729708</td><td style=\"text-align: right;\"> 1.76639</td><td style=\"text-align: right;\">                8.78</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">            93.037</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 739704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-13-47\n",
      "  done: false\n",
      "  episode_len_mean: 91.28703703703704\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.800000000000013\n",
      "  episode_reward_mean: 2.1212962962963013\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 7891\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.528597446384593\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014160518187238165\n",
      "          policy_loss: -0.07915605819728384\n",
      "          total_loss: 0.06300719374090306\n",
      "          vf_explained_var: 0.8916653394699097\n",
      "          vf_loss: 0.1351897936194944\n",
      "    num_agent_steps_sampled: 739704\n",
      "    num_agent_steps_trained: 739704\n",
      "    num_steps_sampled: 739704\n",
      "    num_steps_trained: 739704\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.05424354243543\n",
      "    ram_util_percent: 55.4940959409594\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04596892003567739\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.734345896157784\n",
      "    mean_inference_ms: 2.8734080920932588\n",
      "    mean_raw_obs_processing_ms: 2.4093848051847084\n",
      "  time_since_restore: 10815.428938388824\n",
      "  time_this_iter_s: 189.81918382644653\n",
      "  time_total_s: 10815.428938388824\n",
      "  timers:\n",
      "    learn_throughput: 933.139\n",
      "    learn_time_ms: 10712.226\n",
      "    load_throughput: 91327.837\n",
      "    load_time_ms: 109.452\n",
      "    sample_throughput: 70.021\n",
      "    sample_time_ms: 142756.974\n",
      "    update_time_ms: 9.648\n",
      "  timestamp: 1636305227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 739704\n",
      "  training_iteration: 74\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         10815.4</td><td style=\"text-align: right;\">739704</td><td style=\"text-align: right;\">  2.1213</td><td style=\"text-align: right;\">                 8.8</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">            91.287</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 749700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-16-19\n",
      "  done: false\n",
      "  episode_len_mean: 91.95454545454545\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.760000000000014\n",
      "  episode_reward_mean: 1.704909090909095\n",
      "  episode_reward_min: -1.860000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 8001\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.538535209191151\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014779410925070156\n",
      "          policy_loss: -0.08082136617272966\n",
      "          total_loss: 0.07033325833642584\n",
      "          vf_explained_var: 0.8665417432785034\n",
      "          vf_loss: 0.14287063036050296\n",
      "    num_agent_steps_sampled: 749700\n",
      "    num_agent_steps_trained: 749700\n",
      "    num_steps_sampled: 749700\n",
      "    num_steps_trained: 749700\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.51192660550458\n",
      "    ram_util_percent: 55.46926605504587\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045970227161255324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.74406565278462\n",
      "    mean_inference_ms: 2.8728191662325515\n",
      "    mean_raw_obs_processing_ms: 2.4070014647921103\n",
      "  time_since_restore: 10967.982999563217\n",
      "  time_this_iter_s: 152.5540611743927\n",
      "  time_total_s: 10967.982999563217\n",
      "  timers:\n",
      "    learn_throughput: 932.732\n",
      "    learn_time_ms: 10716.909\n",
      "    load_throughput: 91047.974\n",
      "    load_time_ms: 109.788\n",
      "    sample_throughput: 70.231\n",
      "    sample_time_ms: 142330.701\n",
      "    update_time_ms: 9.913\n",
      "  timestamp: 1636305379\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 749700\n",
      "  training_iteration: 75\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">           10968</td><td style=\"text-align: right;\">749700</td><td style=\"text-align: right;\"> 1.70491</td><td style=\"text-align: right;\">                6.76</td><td style=\"text-align: right;\">               -1.86</td><td style=\"text-align: right;\">           91.9545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 759696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-18-40\n",
      "  done: false\n",
      "  episode_len_mean: 91.66055045871559\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.99000000000001\n",
      "  episode_reward_mean: 2.1983486238532155\n",
      "  episode_reward_min: -1.5000000000000004\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 8110\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.511059343509185\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014435387863285234\n",
      "          policy_loss: -0.07876281150354025\n",
      "          total_loss: 0.08068958955984085\n",
      "          vf_explained_var: 0.8731030821800232\n",
      "          vf_loss: 0.15167737532343364\n",
      "    num_agent_steps_sampled: 759696\n",
      "    num_agent_steps_trained: 759696\n",
      "    num_steps_sampled: 759696\n",
      "    num_steps_trained: 759696\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.956\n",
      "    ram_util_percent: 55.376000000000005\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04597670296719814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.76141111000344\n",
      "    mean_inference_ms: 2.8729451635443413\n",
      "    mean_raw_obs_processing_ms: 2.3854440953276055\n",
      "  time_since_restore: 11108.205299377441\n",
      "  time_this_iter_s: 140.22229981422424\n",
      "  time_total_s: 11108.205299377441\n",
      "  timers:\n",
      "    learn_throughput: 932.428\n",
      "    learn_time_ms: 10720.404\n",
      "    load_throughput: 90341.464\n",
      "    load_time_ms: 110.647\n",
      "    sample_throughput: 70.266\n",
      "    sample_time_ms: 142258.533\n",
      "    update_time_ms: 9.939\n",
      "  timestamp: 1636305520\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 759696\n",
      "  training_iteration: 76\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         11108.2</td><td style=\"text-align: right;\">759696</td><td style=\"text-align: right;\"> 2.19835</td><td style=\"text-align: right;\">                8.99</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           91.6606</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 769692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-21-11\n",
      "  done: false\n",
      "  episode_len_mean: 92.58878504672897\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.870000000000012\n",
      "  episode_reward_mean: 1.958130841121499\n",
      "  episode_reward_min: -2.0300000000000002\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 8217\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.516046618192624\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013544636572014487\n",
      "          policy_loss: -0.08118102865484662\n",
      "          total_loss: 0.05955630886790335\n",
      "          vf_explained_var: 0.868785560131073\n",
      "          vf_loss: 0.1350414258101557\n",
      "    num_agent_steps_sampled: 769692\n",
      "    num_agent_steps_trained: 769692\n",
      "    num_steps_sampled: 769692\n",
      "    num_steps_trained: 769692\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.68465116279071\n",
      "    ram_util_percent: 55.35209302325582\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04599116104126135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.765026100637414\n",
      "    mean_inference_ms: 2.8727391090506935\n",
      "    mean_raw_obs_processing_ms: 2.3867147365112076\n",
      "  time_since_restore: 11259.22968673706\n",
      "  time_this_iter_s: 151.02438735961914\n",
      "  time_total_s: 11259.22968673706\n",
      "  timers:\n",
      "    learn_throughput: 931.84\n",
      "    learn_time_ms: 10727.166\n",
      "    load_throughput: 90367.595\n",
      "    load_time_ms: 110.615\n",
      "    sample_throughput: 70.75\n",
      "    sample_time_ms: 141286.698\n",
      "    update_time_ms: 10.112\n",
      "  timestamp: 1636305671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 769692\n",
      "  training_iteration: 77\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         11259.2</td><td style=\"text-align: right;\">769692</td><td style=\"text-align: right;\"> 1.95813</td><td style=\"text-align: right;\">                8.87</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">           92.5888</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 779688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-24-18\n",
      "  done: false\n",
      "  episode_len_mean: 88.69026548672566\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.400000000000015\n",
      "  episode_reward_mean: 2.132035398230093\n",
      "  episode_reward_min: -1.9200000000000008\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 8330\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.511643094282884\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014452935020588073\n",
      "          policy_loss: -0.07772132913367107\n",
      "          total_loss: 0.08762711850273558\n",
      "          vf_explained_var: 0.8858755230903625\n",
      "          vf_loss: 0.15753928490588043\n",
      "    num_agent_steps_sampled: 779688\n",
      "    num_agent_steps_trained: 779688\n",
      "    num_steps_sampled: 779688\n",
      "    num_steps_trained: 779688\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.16292134831461\n",
      "    ram_util_percent: 55.43033707865169\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04600582632929741\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.77280179206951\n",
      "    mean_inference_ms: 2.8721488146654006\n",
      "    mean_raw_obs_processing_ms: 2.4369817114433854\n",
      "  time_since_restore: 11446.569306135178\n",
      "  time_this_iter_s: 187.33961939811707\n",
      "  time_total_s: 11446.569306135178\n",
      "  timers:\n",
      "    learn_throughput: 931.337\n",
      "    learn_time_ms: 10732.961\n",
      "    load_throughput: 90336.578\n",
      "    load_time_ms: 110.653\n",
      "    sample_throughput: 69.158\n",
      "    sample_time_ms: 144539.372\n",
      "    update_time_ms: 10.384\n",
      "  timestamp: 1636305858\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 779688\n",
      "  training_iteration: 78\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         11446.6</td><td style=\"text-align: right;\">779688</td><td style=\"text-align: right;\"> 2.13204</td><td style=\"text-align: right;\">                10.4</td><td style=\"text-align: right;\">               -1.92</td><td style=\"text-align: right;\">           88.6903</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 789684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-26-51\n",
      "  done: false\n",
      "  episode_len_mean: 91.28181818181818\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.790000000000013\n",
      "  episode_reward_mean: 2.343636363636368\n",
      "  episode_reward_min: -1.4800000000000004\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 8440\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.504136856396993\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015220129895820035\n",
      "          policy_loss: -0.0800721113721275\n",
      "          total_loss: 0.06741134938584943\n",
      "          vf_explained_var: 0.8850389719009399\n",
      "          vf_loss: 0.13785147020338565\n",
      "    num_agent_steps_sampled: 789684\n",
      "    num_agent_steps_trained: 789684\n",
      "    num_steps_sampled: 789684\n",
      "    num_steps_trained: 789684\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.74449541284403\n",
      "    ram_util_percent: 55.46192660550459\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04599039640178228\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.7840700693425\n",
      "    mean_inference_ms: 2.8718650266083467\n",
      "    mean_raw_obs_processing_ms: 2.4393681493099337\n",
      "  time_since_restore: 11599.30577802658\n",
      "  time_this_iter_s: 152.7364718914032\n",
      "  time_total_s: 11599.30577802658\n",
      "  timers:\n",
      "    learn_throughput: 931.874\n",
      "    learn_time_ms: 10726.767\n",
      "    load_throughput: 90202.725\n",
      "    load_time_ms: 110.817\n",
      "    sample_throughput: 68.359\n",
      "    sample_time_ms: 146227.373\n",
      "    update_time_ms: 10.849\n",
      "  timestamp: 1636306011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 789684\n",
      "  training_iteration: 79\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         11599.3</td><td style=\"text-align: right;\">789684</td><td style=\"text-align: right;\"> 2.34364</td><td style=\"text-align: right;\">                7.79</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           91.2818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 799680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-29-15\n",
      "  done: false\n",
      "  episode_len_mean: 89.83928571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.360000000000005\n",
      "  episode_reward_mean: 1.7299107142857177\n",
      "  episode_reward_min: -1.7900000000000007\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 8552\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5105037446714875\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01329976110942247\n",
      "          policy_loss: -0.08170155062953122\n",
      "          total_loss: 0.04690433479049522\n",
      "          vf_explained_var: 0.8827595114707947\n",
      "          vf_loss: 0.12341240307188824\n",
      "    num_agent_steps_sampled: 799680\n",
      "    num_agent_steps_trained: 799680\n",
      "    num_steps_sampled: 799680\n",
      "    num_steps_trained: 799680\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.82850241545894\n",
      "    ram_util_percent: 55.474396135265685\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04598792990874897\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.814373165555416\n",
      "    mean_inference_ms: 2.8721348630420342\n",
      "    mean_raw_obs_processing_ms: 2.41448444987709\n",
      "  time_since_restore: 11743.797271490097\n",
      "  time_this_iter_s: 144.49149346351624\n",
      "  time_total_s: 11743.797271490097\n",
      "  timers:\n",
      "    learn_throughput: 932.11\n",
      "    learn_time_ms: 10724.051\n",
      "    load_throughput: 90239.322\n",
      "    load_time_ms: 110.772\n",
      "    sample_throughput: 68.421\n",
      "    sample_time_ms: 146095.971\n",
      "    update_time_ms: 11.233\n",
      "  timestamp: 1636306155\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 799680\n",
      "  training_iteration: 80\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         11743.8</td><td style=\"text-align: right;\">799680</td><td style=\"text-align: right;\"> 1.72991</td><td style=\"text-align: right;\">                9.36</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           89.8393</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 809676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-31-47\n",
      "  done: false\n",
      "  episode_len_mean: 90.58181818181818\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.810000000000015\n",
      "  episode_reward_mean: 1.8276363636363677\n",
      "  episode_reward_min: -1.8200000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 8662\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5048060117623745\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01499426429046237\n",
      "          policy_loss: -0.07754019424319267\n",
      "          total_loss: 0.07540600954149014\n",
      "          vf_explained_var: 0.8679239153862\n",
      "          vf_loss: 0.14383545508369422\n",
      "    num_agent_steps_sampled: 809676\n",
      "    num_agent_steps_trained: 809676\n",
      "    num_steps_sampled: 809676\n",
      "    num_steps_trained: 809676\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.74166666666669\n",
      "    ram_util_percent: 55.394444444444446\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04596447831030177\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.825920873841994\n",
      "    mean_inference_ms: 2.8719700102942953\n",
      "    mean_raw_obs_processing_ms: 2.409830609111753\n",
      "  time_since_restore: 11895.32329750061\n",
      "  time_this_iter_s: 151.5260260105133\n",
      "  time_total_s: 11895.32329750061\n",
      "  timers:\n",
      "    learn_throughput: 931.755\n",
      "    learn_time_ms: 10728.147\n",
      "    load_throughput: 90133.496\n",
      "    load_time_ms: 110.902\n",
      "    sample_throughput: 68.281\n",
      "    sample_time_ms: 146394.551\n",
      "    update_time_ms: 12.516\n",
      "  timestamp: 1636306307\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 809676\n",
      "  training_iteration: 81\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         11895.3</td><td style=\"text-align: right;\">809676</td><td style=\"text-align: right;\"> 1.82764</td><td style=\"text-align: right;\">                8.81</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           90.5818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 819672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-34-31\n",
      "  done: false\n",
      "  episode_len_mean: 89.90090090090091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.550000000000013\n",
      "  episode_reward_mean: 2.197927927927933\n",
      "  episode_reward_min: -1.4500000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 8773\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5131867832607693\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014758836643891283\n",
      "          policy_loss: -0.07846143445015973\n",
      "          total_loss: 0.0798892341227804\n",
      "          vf_explained_var: 0.8874314427375793\n",
      "          vf_loss: 0.1498600603105166\n",
      "    num_agent_steps_sampled: 819672\n",
      "    num_agent_steps_trained: 819672\n",
      "    num_steps_sampled: 819672\n",
      "    num_steps_trained: 819672\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.78197424892704\n",
      "    ram_util_percent: 55.494420600858355\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04595006964394439\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.824803399485475\n",
      "    mean_inference_ms: 2.8713831334067526\n",
      "    mean_raw_obs_processing_ms: 2.429761368990209\n",
      "  time_since_restore: 12059.021123409271\n",
      "  time_this_iter_s: 163.6978259086609\n",
      "  time_total_s: 12059.021123409271\n",
      "  timers:\n",
      "    learn_throughput: 931.769\n",
      "    learn_time_ms: 10727.976\n",
      "    load_throughput: 90183.536\n",
      "    load_time_ms: 110.841\n",
      "    sample_throughput: 67.593\n",
      "    sample_time_ms: 147884.73\n",
      "    update_time_ms: 12.647\n",
      "  timestamp: 1636306471\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 819672\n",
      "  training_iteration: 82\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">           12059</td><td style=\"text-align: right;\">819672</td><td style=\"text-align: right;\"> 2.19793</td><td style=\"text-align: right;\">                8.55</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           89.9009</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 829668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-37-10\n",
      "  done: false\n",
      "  episode_len_mean: 89.85454545454546\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.910000000000007\n",
      "  episode_reward_mean: 2.0070000000000037\n",
      "  episode_reward_min: -1.810000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 8883\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.504748384769146\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013905590404950147\n",
      "          policy_loss: -0.07973765624830356\n",
      "          total_loss: 0.06524901321778695\n",
      "          vf_explained_var: 0.8865697383880615\n",
      "          vf_loss: 0.13835547973489404\n",
      "    num_agent_steps_sampled: 829668\n",
      "    num_agent_steps_trained: 829668\n",
      "    num_steps_sampled: 829668\n",
      "    num_steps_trained: 829668\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.67192982456142\n",
      "    ram_util_percent: 55.6390350877193\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04596111219472092\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.82670390641284\n",
      "    mean_inference_ms: 2.8712913655399896\n",
      "    mean_raw_obs_processing_ms: 2.4495787552904416\n",
      "  time_since_restore: 12218.311991214752\n",
      "  time_this_iter_s: 159.29086780548096\n",
      "  time_total_s: 12218.311991214752\n",
      "  timers:\n",
      "    learn_throughput: 931.823\n",
      "    learn_time_ms: 10727.359\n",
      "    load_throughput: 90244.683\n",
      "    load_time_ms: 110.766\n",
      "    sample_throughput: 67.355\n",
      "    sample_time_ms: 148407.259\n",
      "    update_time_ms: 11.704\n",
      "  timestamp: 1636306630\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 829668\n",
      "  training_iteration: 83\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         12218.3</td><td style=\"text-align: right;\">829668</td><td style=\"text-align: right;\">   2.007</td><td style=\"text-align: right;\">               10.91</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           89.8545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 839664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-39-58\n",
      "  done: false\n",
      "  episode_len_mean: 89.56637168141593\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.410000000000013\n",
      "  episode_reward_mean: 2.303805309734518\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 8996\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4959365671516482\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014149598240842696\n",
      "          policy_loss: -0.07878890736585753\n",
      "          total_loss: 0.06795282521261237\n",
      "          vf_explained_var: 0.8906643390655518\n",
      "          vf_loss: 0.1394665445248859\n",
      "    num_agent_steps_sampled: 839664\n",
      "    num_agent_steps_trained: 839664\n",
      "    num_steps_sampled: 839664\n",
      "    num_steps_trained: 839664\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.28326359832634\n",
      "    ram_util_percent: 55.492050209205026\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045935495309643234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.82683186216059\n",
      "    mean_inference_ms: 2.8707845412683395\n",
      "    mean_raw_obs_processing_ms: 2.481451181809515\n",
      "  time_since_restore: 12386.189771413803\n",
      "  time_this_iter_s: 167.8777801990509\n",
      "  time_total_s: 12386.189771413803\n",
      "  timers:\n",
      "    learn_throughput: 931.751\n",
      "    learn_time_ms: 10728.188\n",
      "    load_throughput: 90351.549\n",
      "    load_time_ms: 110.635\n",
      "    sample_throughput: 68.366\n",
      "    sample_time_ms: 146212.131\n",
      "    update_time_ms: 11.687\n",
      "  timestamp: 1636306798\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 839664\n",
      "  training_iteration: 84\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         12386.2</td><td style=\"text-align: right;\">839664</td><td style=\"text-align: right;\"> 2.30381</td><td style=\"text-align: right;\">               10.41</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           89.5664</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 849660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-42-34\n",
      "  done: false\n",
      "  episode_len_mean: 90.56363636363636\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.990000000000013\n",
      "  episode_reward_mean: 2.132000000000004\n",
      "  episode_reward_min: -1.6700000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 9106\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.523839113243625\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014520280318996713\n",
      "          policy_loss: -0.08398791734829672\n",
      "          total_loss: 0.06642509409759799\n",
      "          vf_explained_var: 0.8882313966751099\n",
      "          vf_loss: 0.14257238845253348\n",
      "    num_agent_steps_sampled: 849660\n",
      "    num_agent_steps_trained: 849660\n",
      "    num_steps_sampled: 849660\n",
      "    num_steps_trained: 849660\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.91928251121077\n",
      "    ram_util_percent: 55.6170403587444\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045933360188323766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.835902224677305\n",
      "    mean_inference_ms: 2.8706546527528727\n",
      "    mean_raw_obs_processing_ms: 2.4811939931493923\n",
      "  time_since_restore: 12542.437821626663\n",
      "  time_this_iter_s: 156.2480502128601\n",
      "  time_total_s: 12542.437821626663\n",
      "  timers:\n",
      "    learn_throughput: 931.801\n",
      "    learn_time_ms: 10727.609\n",
      "    load_throughput: 90281.78\n",
      "    load_time_ms: 110.72\n",
      "    sample_throughput: 68.194\n",
      "    sample_time_ms: 146581.732\n",
      "    update_time_ms: 12.042\n",
      "  timestamp: 1636306954\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 849660\n",
      "  training_iteration: 85\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         12542.4</td><td style=\"text-align: right;\">849660</td><td style=\"text-align: right;\">   2.132</td><td style=\"text-align: right;\">                8.99</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           90.5636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 859656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-45-04\n",
      "  done: false\n",
      "  episode_len_mean: 90.07207207207207\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.14000000000001\n",
      "  episode_reward_mean: 2.270540540540545\n",
      "  episode_reward_min: -1.7000000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 9217\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.500977656372592\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014799948489868318\n",
      "          policy_loss: -0.08000117526588658\n",
      "          total_loss: 0.06659263322591527\n",
      "          vf_explained_var: 0.9002763032913208\n",
      "          vf_loss: 0.13788745069048472\n",
      "    num_agent_steps_sampled: 859656\n",
      "    num_agent_steps_trained: 859656\n",
      "    num_steps_sampled: 859656\n",
      "    num_steps_trained: 859656\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.46186046511627\n",
      "    ram_util_percent: 55.506976744186055\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045941539869162176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.83787754540369\n",
      "    mean_inference_ms: 2.870758027732293\n",
      "    mean_raw_obs_processing_ms: 2.485447370343253\n",
      "  time_since_restore: 12692.685426950455\n",
      "  time_this_iter_s: 150.2476053237915\n",
      "  time_total_s: 12692.685426950455\n",
      "  timers:\n",
      "    learn_throughput: 931.566\n",
      "    learn_time_ms: 10730.321\n",
      "    load_throughput: 90246.548\n",
      "    load_time_ms: 110.763\n",
      "    sample_throughput: 67.732\n",
      "    sample_time_ms: 147581.456\n",
      "    update_time_ms: 11.948\n",
      "  timestamp: 1636307104\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 859656\n",
      "  training_iteration: 86\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         12692.7</td><td style=\"text-align: right;\">859656</td><td style=\"text-align: right;\"> 2.27054</td><td style=\"text-align: right;\">                9.14</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           90.0721</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 869652\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-47-54\n",
      "  done: false\n",
      "  episode_len_mean: 90.18181818181819\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.540000000000017\n",
      "  episode_reward_mean: 2.156909090909096\n",
      "  episode_reward_min: -1.6400000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 9327\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4884441029312265\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014277404978349428\n",
      "          policy_loss: -0.08052562035970454\n",
      "          total_loss: 0.06143060956054773\n",
      "          vf_explained_var: 0.8992297053337097\n",
      "          vf_loss: 0.13431495724914547\n",
      "    num_agent_steps_sampled: 869652\n",
      "    num_agent_steps_trained: 869652\n",
      "    num_steps_sampled: 869652\n",
      "    num_steps_trained: 869652\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.79626556016596\n",
      "    ram_util_percent: 55.58879668049792\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0459117839847393\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.84700422764897\n",
      "    mean_inference_ms: 2.870386032848759\n",
      "    mean_raw_obs_processing_ms: 2.4984931568815383\n",
      "  time_since_restore: 12862.042485952377\n",
      "  time_this_iter_s: 169.3570590019226\n",
      "  time_total_s: 12862.042485952377\n",
      "  timers:\n",
      "    learn_throughput: 931.641\n",
      "    learn_time_ms: 10729.454\n",
      "    load_throughput: 90451.623\n",
      "    load_time_ms: 110.512\n",
      "    sample_throughput: 66.9\n",
      "    sample_time_ms: 149416.3\n",
      "    update_time_ms: 11.361\n",
      "  timestamp: 1636307274\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 869652\n",
      "  training_iteration: 87\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">           12862</td><td style=\"text-align: right;\">869652</td><td style=\"text-align: right;\"> 2.15691</td><td style=\"text-align: right;\">                8.54</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           90.1818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 879648\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-50-26\n",
      "  done: false\n",
      "  episode_len_mean: 89.6875\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.020000000000014\n",
      "  episode_reward_mean: 1.9443750000000044\n",
      "  episode_reward_min: -2.1300000000000003\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 9439\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5000275367345566\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014850368898322178\n",
      "          policy_loss: -0.0764203554767574\n",
      "          total_loss: 0.08190720317423598\n",
      "          vf_explained_var: 0.8865973949432373\n",
      "          vf_loss: 0.14949683621366563\n",
      "    num_agent_steps_sampled: 879648\n",
      "    num_agent_steps_trained: 879648\n",
      "    num_steps_sampled: 879648\n",
      "    num_steps_trained: 879648\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.82396313364055\n",
      "    ram_util_percent: 55.50092165898618\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045938882357180036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.857647125888874\n",
      "    mean_inference_ms: 2.870233685755996\n",
      "    mean_raw_obs_processing_ms: 2.50344373867629\n",
      "  time_since_restore: 13014.102447032928\n",
      "  time_this_iter_s: 152.05996108055115\n",
      "  time_total_s: 13014.102447032928\n",
      "  timers:\n",
      "    learn_throughput: 932.039\n",
      "    learn_time_ms: 10724.869\n",
      "    load_throughput: 90495.765\n",
      "    load_time_ms: 110.458\n",
      "    sample_throughput: 68.516\n",
      "    sample_time_ms: 145892.975\n",
      "    update_time_ms: 11.263\n",
      "  timestamp: 1636307426\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 879648\n",
      "  training_iteration: 88\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         13014.1</td><td style=\"text-align: right;\">879648</td><td style=\"text-align: right;\"> 1.94438</td><td style=\"text-align: right;\">                9.02</td><td style=\"text-align: right;\">               -2.13</td><td style=\"text-align: right;\">           89.6875</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 889644\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-53-11\n",
      "  done: false\n",
      "  episode_len_mean: 90.05405405405405\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.590000000000003\n",
      "  episode_reward_mean: 2.213243243243248\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 9550\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.501292507872622\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014363757640839511\n",
      "          policy_loss: -0.08175013891110817\n",
      "          total_loss: 0.06602619588852693\n",
      "          vf_explained_var: 0.8932087421417236\n",
      "          vf_loss: 0.1400668226612302\n",
      "    num_agent_steps_sampled: 889644\n",
      "    num_agent_steps_trained: 889644\n",
      "    num_steps_sampled: 889644\n",
      "    num_steps_trained: 889644\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.57966101694916\n",
      "    ram_util_percent: 55.47161016949152\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04590990063489778\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.86127069692489\n",
      "    mean_inference_ms: 2.8701148146725513\n",
      "    mean_raw_obs_processing_ms: 2.519112496794692\n",
      "  time_since_restore: 13179.24786233902\n",
      "  time_this_iter_s: 165.1454153060913\n",
      "  time_total_s: 13179.24786233902\n",
      "  timers:\n",
      "    learn_throughput: 931.446\n",
      "    learn_time_ms: 10731.699\n",
      "    load_throughput: 90527.635\n",
      "    load_time_ms: 110.419\n",
      "    sample_throughput: 67.941\n",
      "    sample_time_ms: 147127.689\n",
      "    update_time_ms: 10.317\n",
      "  timestamp: 1636307591\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 889644\n",
      "  training_iteration: 89\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         13179.2</td><td style=\"text-align: right;\">889644</td><td style=\"text-align: right;\"> 2.21324</td><td style=\"text-align: right;\">                9.59</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           90.0541</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 899640\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-55-29\n",
      "  done: false\n",
      "  episode_len_mean: 90.90990990990991\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.720000000000015\n",
      "  episode_reward_mean: 2.2272972972973024\n",
      "  episode_reward_min: -1.950000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 9661\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5081558902039487\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014677665447928128\n",
      "          policy_loss: -0.08146235699263903\n",
      "          total_loss: 0.07540261219613827\n",
      "          vf_explained_var: 0.8902168273925781\n",
      "          vf_loss: 0.14850896969119198\n",
      "    num_agent_steps_sampled: 899640\n",
      "    num_agent_steps_trained: 899640\n",
      "    num_steps_sampled: 899640\n",
      "    num_steps_trained: 899640\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03654822335024\n",
      "    ram_util_percent: 55.576142131979694\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04592162834517037\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.875796599231556\n",
      "    mean_inference_ms: 2.8703086988583397\n",
      "    mean_raw_obs_processing_ms: 2.500693723381406\n",
      "  time_since_restore: 13317.511820077896\n",
      "  time_this_iter_s: 138.26395773887634\n",
      "  time_total_s: 13317.511820077896\n",
      "  timers:\n",
      "    learn_throughput: 931.341\n",
      "    learn_time_ms: 10732.909\n",
      "    load_throughput: 90493.89\n",
      "    load_time_ms: 110.46\n",
      "    sample_throughput: 68.231\n",
      "    sample_time_ms: 146502.899\n",
      "    update_time_ms: 11.032\n",
      "  timestamp: 1636307729\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 899640\n",
      "  training_iteration: 90\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         13317.5</td><td style=\"text-align: right;\">899640</td><td style=\"text-align: right;\">  2.2273</td><td style=\"text-align: right;\">                8.72</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           90.9099</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 909636\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_17-58-03\n",
      "  done: false\n",
      "  episode_len_mean: 89.54954954954955\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.550000000000011\n",
      "  episode_reward_mean: 2.2577477477477523\n",
      "  episode_reward_min: -1.6700000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 9772\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.495304168595208\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01392611511662182\n",
      "          policy_loss: -0.08041942024396526\n",
      "          total_loss: 0.05561904059006618\n",
      "          vf_explained_var: 0.8987534046173096\n",
      "          vf_loss: 0.12926606999025642\n",
      "    num_agent_steps_sampled: 909636\n",
      "    num_agent_steps_trained: 909636\n",
      "    num_steps_sampled: 909636\n",
      "    num_steps_trained: 909636\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.46136363636364\n",
      "    ram_util_percent: 55.57727272727273\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04590672382383173\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.88612579975655\n",
      "    mean_inference_ms: 2.8702058425894283\n",
      "    mean_raw_obs_processing_ms: 2.500159594779338\n",
      "  time_since_restore: 13471.573074102402\n",
      "  time_this_iter_s: 154.06125402450562\n",
      "  time_total_s: 13471.573074102402\n",
      "  timers:\n",
      "    learn_throughput: 931.29\n",
      "    learn_time_ms: 10733.499\n",
      "    load_throughput: 90660.298\n",
      "    load_time_ms: 110.258\n",
      "    sample_throughput: 68.113\n",
      "    sample_time_ms: 146756.532\n",
      "    update_time_ms: 10.775\n",
      "  timestamp: 1636307883\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 909636\n",
      "  training_iteration: 91\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         13471.6</td><td style=\"text-align: right;\">909636</td><td style=\"text-align: right;\"> 2.25775</td><td style=\"text-align: right;\">                8.55</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           89.5495</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 919632\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-00-33\n",
      "  done: false\n",
      "  episode_len_mean: 91.8348623853211\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.930000000000012\n",
      "  episode_reward_mean: 2.1586238532110147\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 9881\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5080160894964494\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013502732182232326\n",
      "          policy_loss: -0.08341670059718383\n",
      "          total_loss: 0.039538293889859036\n",
      "          vf_explained_var: 0.9069659113883972\n",
      "          vf_loss: 0.1172742426666057\n",
      "    num_agent_steps_sampled: 919632\n",
      "    num_agent_steps_trained: 919632\n",
      "    num_steps_sampled: 919632\n",
      "    num_steps_trained: 919632\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.44319248826292\n",
      "    ram_util_percent: 55.469953051643195\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045911481282368154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.88038839068475\n",
      "    mean_inference_ms: 2.870159472050396\n",
      "    mean_raw_obs_processing_ms: 2.5205531919450577\n",
      "  time_since_restore: 13620.737632513046\n",
      "  time_this_iter_s: 149.16455841064453\n",
      "  time_total_s: 13620.737632513046\n",
      "  timers:\n",
      "    learn_throughput: 931.284\n",
      "    learn_time_ms: 10733.568\n",
      "    load_throughput: 90530.391\n",
      "    load_time_ms: 110.416\n",
      "    sample_throughput: 68.795\n",
      "    sample_time_ms: 145300.833\n",
      "    update_time_ms: 12.672\n",
      "  timestamp: 1636308033\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 919632\n",
      "  training_iteration: 92\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         13620.7</td><td style=\"text-align: right;\">919632</td><td style=\"text-align: right;\"> 2.15862</td><td style=\"text-align: right;\">                8.93</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           91.8349</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 929628\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-02-50\n",
      "  done: false\n",
      "  episode_len_mean: 92.02777777777777\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.550000000000015\n",
      "  episode_reward_mean: 2.399537037037042\n",
      "  episode_reward_min: -1.900000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 9989\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.507759531135233\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014646049938045675\n",
      "          policy_loss: -0.07890711293324955\n",
      "          total_loss: 0.0765524676690499\n",
      "          vf_explained_var: 0.8965805768966675\n",
      "          vf_loss: 0.1471716428016368\n",
      "    num_agent_steps_sampled: 929628\n",
      "    num_agent_steps_trained: 929628\n",
      "    num_steps_sampled: 929628\n",
      "    num_steps_trained: 929628\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96530612244898\n",
      "    ram_util_percent: 55.44744897959184\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04591869793243902\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.88807558267271\n",
      "    mean_inference_ms: 2.870286930543775\n",
      "    mean_raw_obs_processing_ms: 2.5001449347980245\n",
      "  time_since_restore: 13758.260817289352\n",
      "  time_this_iter_s: 137.52318477630615\n",
      "  time_total_s: 13758.260817289352\n",
      "  timers:\n",
      "    learn_throughput: 931.261\n",
      "    learn_time_ms: 10733.837\n",
      "    load_throughput: 90630.686\n",
      "    load_time_ms: 110.294\n",
      "    sample_throughput: 69.842\n",
      "    sample_time_ms: 143123.245\n",
      "    update_time_ms: 13.494\n",
      "  timestamp: 1636308170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 929628\n",
      "  training_iteration: 93\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         13758.3</td><td style=\"text-align: right;\">929628</td><td style=\"text-align: right;\"> 2.39954</td><td style=\"text-align: right;\">               12.55</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           92.0278</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 939624\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-05-24\n",
      "  done: false\n",
      "  episode_len_mean: 90.45454545454545\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.780000000000014\n",
      "  episode_reward_mean: 2.377818181818188\n",
      "  episode_reward_min: -2.1300000000000003\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 10099\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.501691791338798\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014712388239307548\n",
      "          policy_loss: -0.07973969169120249\n",
      "          total_loss: 0.07237978885825883\n",
      "          vf_explained_var: 0.9025144577026367\n",
      "          vf_loss: 0.1436197388304286\n",
      "    num_agent_steps_sampled: 939624\n",
      "    num_agent_steps_trained: 939624\n",
      "    num_steps_sampled: 939624\n",
      "    num_steps_trained: 939624\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.56849315068493\n",
      "    ram_util_percent: 55.52054794520548\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045908870539779933\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.90501498720239\n",
      "    mean_inference_ms: 2.87025396077256\n",
      "    mean_raw_obs_processing_ms: 2.4982823386194966\n",
      "  time_since_restore: 13911.77839255333\n",
      "  time_this_iter_s: 153.51757526397705\n",
      "  time_total_s: 13911.77839255333\n",
      "  timers:\n",
      "    learn_throughput: 931.015\n",
      "    learn_time_ms: 10736.665\n",
      "    load_throughput: 90686.379\n",
      "    load_time_ms: 110.226\n",
      "    sample_throughput: 70.551\n",
      "    sample_time_ms: 141684.583\n",
      "    update_time_ms: 13.503\n",
      "  timestamp: 1636308324\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 939624\n",
      "  training_iteration: 94\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         13911.8</td><td style=\"text-align: right;\">939624</td><td style=\"text-align: right;\"> 2.37782</td><td style=\"text-align: right;\">                8.78</td><td style=\"text-align: right;\">               -2.13</td><td style=\"text-align: right;\">           90.4545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 949620\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-07-57\n",
      "  done: false\n",
      "  episode_len_mean: 90.91891891891892\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.180000000000007\n",
      "  episode_reward_mean: 2.39504504504505\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 10210\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.506010322693067\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013799959852276538\n",
      "          policy_loss: -0.07800931309819477\n",
      "          total_loss: 0.07406979849577969\n",
      "          vf_explained_var: 0.9014742374420166\n",
      "          vf_loss: 0.14570118114829828\n",
      "    num_agent_steps_sampled: 949620\n",
      "    num_agent_steps_trained: 949620\n",
      "    num_steps_sampled: 949620\n",
      "    num_steps_trained: 949620\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.99770642201835\n",
      "    ram_util_percent: 55.44633027522936\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04588850977107339\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.91442767686817\n",
      "    mean_inference_ms: 2.870147667900787\n",
      "    mean_raw_obs_processing_ms: 2.494132088055827\n",
      "  time_since_restore: 14064.653007030487\n",
      "  time_this_iter_s: 152.8746144771576\n",
      "  time_total_s: 14064.653007030487\n",
      "  timers:\n",
      "    learn_throughput: 930.82\n",
      "    learn_time_ms: 10738.923\n",
      "    load_throughput: 91016.962\n",
      "    load_time_ms: 109.826\n",
      "    sample_throughput: 70.72\n",
      "    sample_time_ms: 141345.969\n",
      "    update_time_ms: 13.138\n",
      "  timestamp: 1636308477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 949620\n",
      "  training_iteration: 95\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         14064.7</td><td style=\"text-align: right;\">949620</td><td style=\"text-align: right;\"> 2.39505</td><td style=\"text-align: right;\">                9.18</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           90.9189</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 959616\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-10-27\n",
      "  done: false\n",
      "  episode_len_mean: 91.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.560000000000018\n",
      "  episode_reward_mean: 2.282129629629635\n",
      "  episode_reward_min: -2.100000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 10318\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5045605761373144\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013675275727268666\n",
      "          policy_loss: -0.08239337192036403\n",
      "          total_loss: 0.0562633636717995\n",
      "          vf_explained_var: 0.8955557942390442\n",
      "          vf_loss: 0.1325483526238519\n",
      "    num_agent_steps_sampled: 959616\n",
      "    num_agent_steps_trained: 959616\n",
      "    num_steps_sampled: 959616\n",
      "    num_steps_trained: 959616\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.49953488372094\n",
      "    ram_util_percent: 55.423255813953496\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04589618445806331\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.911962180085794\n",
      "    mean_inference_ms: 2.870118885409937\n",
      "    mean_raw_obs_processing_ms: 2.495244647963747\n",
      "  time_since_restore: 14214.658160448074\n",
      "  time_this_iter_s: 150.00515341758728\n",
      "  time_total_s: 14214.658160448074\n",
      "  timers:\n",
      "    learn_throughput: 931.083\n",
      "    learn_time_ms: 10735.88\n",
      "    load_throughput: 91483.014\n",
      "    load_time_ms: 109.266\n",
      "    sample_throughput: 70.731\n",
      "    sample_time_ms: 141325.163\n",
      "    update_time_ms: 12.805\n",
      "  timestamp: 1636308627\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 959616\n",
      "  training_iteration: 96\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         14214.7</td><td style=\"text-align: right;\">959616</td><td style=\"text-align: right;\"> 2.28213</td><td style=\"text-align: right;\">               10.56</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">             91.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 969612\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-13-08\n",
      "  done: false\n",
      "  episode_len_mean: 91.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.840000000000016\n",
      "  episode_reward_mean: 2.0868181818181863\n",
      "  episode_reward_min: -2.0900000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 10428\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5110848451272036\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013052004543741245\n",
      "          policy_loss: -0.08239030974606673\n",
      "          total_loss: 0.040776212995824145\n",
      "          vf_explained_var: 0.8906089067459106\n",
      "          vf_loss: 0.11854327104858353\n",
      "    num_agent_steps_sampled: 969612\n",
      "    num_agent_steps_trained: 969612\n",
      "    num_steps_sampled: 969612\n",
      "    num_steps_trained: 969612\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.27086956521741\n",
      "    ram_util_percent: 55.56956521739131\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04589334801671503\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.90451224552636\n",
      "    mean_inference_ms: 2.8696257183575002\n",
      "    mean_raw_obs_processing_ms: 2.510962955787235\n",
      "  time_since_restore: 14376.013761520386\n",
      "  time_this_iter_s: 161.3556010723114\n",
      "  time_total_s: 14376.013761520386\n",
      "  timers:\n",
      "    learn_throughput: 931.237\n",
      "    learn_time_ms: 10734.107\n",
      "    load_throughput: 91262.929\n",
      "    load_time_ms: 109.53\n",
      "    sample_throughput: 71.132\n",
      "    sample_time_ms: 140526.562\n",
      "    update_time_ms: 12.865\n",
      "  timestamp: 1636308788\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 969612\n",
      "  training_iteration: 97\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">           14376</td><td style=\"text-align: right;\">969612</td><td style=\"text-align: right;\"> 2.08682</td><td style=\"text-align: right;\">                8.84</td><td style=\"text-align: right;\">               -2.09</td><td style=\"text-align: right;\">              91.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 979608\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-15-40\n",
      "  done: false\n",
      "  episode_len_mean: 90.97272727272727\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.75000000000001\n",
      "  episode_reward_mean: 1.9983636363636403\n",
      "  episode_reward_min: -1.630000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 10538\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5119347706819193\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01456686091716934\n",
      "          policy_loss: -0.07986349296779968\n",
      "          total_loss: 0.05469885888453732\n",
      "          vf_explained_var: 0.9003019332885742\n",
      "          vf_loss: 0.1264965690736078\n",
      "    num_agent_steps_sampled: 979608\n",
      "    num_agent_steps_trained: 979608\n",
      "    num_steps_sampled: 979608\n",
      "    num_steps_trained: 979608\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.56574074074075\n",
      "    ram_util_percent: 55.44074074074074\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04589963293037739\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.90593509152044\n",
      "    mean_inference_ms: 2.869559604015491\n",
      "    mean_raw_obs_processing_ms: 2.513313265698337\n",
      "  time_since_restore: 14527.456972122192\n",
      "  time_this_iter_s: 151.44321060180664\n",
      "  time_total_s: 14527.456972122192\n",
      "  timers:\n",
      "    learn_throughput: 931.413\n",
      "    learn_time_ms: 10732.08\n",
      "    load_throughput: 91212.578\n",
      "    load_time_ms: 109.59\n",
      "    sample_throughput: 71.162\n",
      "    sample_time_ms: 140467.373\n",
      "    update_time_ms: 12.073\n",
      "  timestamp: 1636308940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 979608\n",
      "  training_iteration: 98\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         14527.5</td><td style=\"text-align: right;\">979608</td><td style=\"text-align: right;\"> 1.99836</td><td style=\"text-align: right;\">                6.75</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           90.9727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 989604\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-18-08\n",
      "  done: false\n",
      "  episode_len_mean: 91.21818181818182\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.990000000000016\n",
      "  episode_reward_mean: 1.817454545454549\n",
      "  episode_reward_min: -1.7900000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 10648\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.513296970139202\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013885175295228964\n",
      "          policy_loss: -0.08093450218757503\n",
      "          total_loss: 0.05467126411346034\n",
      "          vf_explained_var: 0.8807742595672607\n",
      "          vf_loss: 0.12910656973831036\n",
      "    num_agent_steps_sampled: 989604\n",
      "    num_agent_steps_trained: 989604\n",
      "    num_steps_sampled: 989604\n",
      "    num_steps_trained: 989604\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.04716981132076\n",
      "    ram_util_percent: 55.60566037735849\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04590399126434506\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.906307823174515\n",
      "    mean_inference_ms: 2.8695632142005065\n",
      "    mean_raw_obs_processing_ms: 2.5099553100382903\n",
      "  time_since_restore: 14676.346593141556\n",
      "  time_this_iter_s: 148.8896210193634\n",
      "  time_total_s: 14676.346593141556\n",
      "  timers:\n",
      "    learn_throughput: 931.535\n",
      "    learn_time_ms: 10730.673\n",
      "    load_throughput: 91395.247\n",
      "    load_time_ms: 109.371\n",
      "    sample_throughput: 71.995\n",
      "    sample_time_ms: 138843.364\n",
      "    update_time_ms: 12.325\n",
      "  timestamp: 1636309088\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 989604\n",
      "  training_iteration: 99\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         14676.3</td><td style=\"text-align: right;\">989604</td><td style=\"text-align: right;\"> 1.81745</td><td style=\"text-align: right;\">                6.99</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           91.2182</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 999600\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-20-36\n",
      "  done: false\n",
      "  episode_len_mean: 93.18691588785046\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.330000000000009\n",
      "  episode_reward_mean: 1.9801869158878556\n",
      "  episode_reward_min: -2.0500000000000003\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 10755\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5287940551073125\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014124087697128574\n",
      "          policy_loss: -0.08245388903678992\n",
      "          total_loss: 0.05278005235406578\n",
      "          vf_explained_var: 0.898181676864624\n",
      "          vf_loss: 0.12834544429778416\n",
      "    num_agent_steps_sampled: 999600\n",
      "    num_agent_steps_trained: 999600\n",
      "    num_steps_sampled: 999600\n",
      "    num_steps_trained: 999600\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.54739336492891\n",
      "    ram_util_percent: 55.50663507109005\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04591274225360581\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.899839741464255\n",
      "    mean_inference_ms: 2.8694807941130795\n",
      "    mean_raw_obs_processing_ms: 2.5095152213763\n",
      "  time_since_restore: 14823.978217840195\n",
      "  time_this_iter_s: 147.63162469863892\n",
      "  time_total_s: 14823.978217840195\n",
      "  timers:\n",
      "    learn_throughput: 931.169\n",
      "    learn_time_ms: 10734.892\n",
      "    load_throughput: 91030.894\n",
      "    load_time_ms: 109.809\n",
      "    sample_throughput: 71.514\n",
      "    sample_time_ms: 139776.849\n",
      "    update_time_ms: 11.217\n",
      "  timestamp: 1636309236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 999600\n",
      "  training_iteration: 100\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">           14824</td><td style=\"text-align: right;\">999600</td><td style=\"text-align: right;\"> 1.98019</td><td style=\"text-align: right;\">                7.33</td><td style=\"text-align: right;\">               -2.05</td><td style=\"text-align: right;\">           93.1869</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1009596\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-23-05\n",
      "  done: false\n",
      "  episode_len_mean: 92.45370370370371\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.97000000000001\n",
      "  episode_reward_mean: 2.2103703703703754\n",
      "  episode_reward_min: -1.9200000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 10863\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.525417670225486\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013716308105574107\n",
      "          policy_loss: -0.08257725580125792\n",
      "          total_loss: 0.04634810985089877\n",
      "          vf_explained_var: 0.8804720640182495\n",
      "          vf_loss: 0.12293207651147475\n",
      "    num_agent_steps_sampled: 1009596\n",
      "    num_agent_steps_trained: 1009596\n",
      "    num_steps_sampled: 1009596\n",
      "    num_steps_trained: 1009596\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.77558685446012\n",
      "    ram_util_percent: 55.57652582159624\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04596472948523109\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.89388943292349\n",
      "    mean_inference_ms: 2.869807247027095\n",
      "    mean_raw_obs_processing_ms: 2.5144987145641995\n",
      "  time_since_restore: 14972.824966907501\n",
      "  time_this_iter_s: 148.84674906730652\n",
      "  time_total_s: 14972.824966907501\n",
      "  timers:\n",
      "    learn_throughput: 931.109\n",
      "    learn_time_ms: 10735.59\n",
      "    load_throughput: 91063.083\n",
      "    load_time_ms: 109.77\n",
      "    sample_throughput: 71.782\n",
      "    sample_time_ms: 139255.24\n",
      "    update_time_ms: 10.446\n",
      "  timestamp: 1636309385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1009596\n",
      "  training_iteration: 101\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         14972.8</td><td style=\"text-align: right;\">1009596</td><td style=\"text-align: right;\"> 2.21037</td><td style=\"text-align: right;\">                8.97</td><td style=\"text-align: right;\">               -1.92</td><td style=\"text-align: right;\">           92.4537</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1019592\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-25-22\n",
      "  done: false\n",
      "  episode_len_mean: 92.69444444444444\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.710000000000013\n",
      "  episode_reward_mean: 2.540277777777783\n",
      "  episode_reward_min: -1.6300000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 10971\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.522090495753492\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01466584574940887\n",
      "          policy_loss: -0.07512675248181973\n",
      "          total_loss: 0.07971352907136464\n",
      "          vf_explained_var: 0.8866292238235474\n",
      "          vf_loss: 0.14665055528012477\n",
      "    num_agent_steps_sampled: 1019592\n",
      "    num_agent_steps_trained: 1019592\n",
      "    num_steps_sampled: 1019592\n",
      "    num_steps_trained: 1019592\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8139175257732\n",
      "    ram_util_percent: 55.60721649484536\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04592512705165627\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.89975838679353\n",
      "    mean_inference_ms: 2.869756272633288\n",
      "    mean_raw_obs_processing_ms: 2.4897909231929534\n",
      "  time_since_restore: 15109.400580406189\n",
      "  time_this_iter_s: 136.57561349868774\n",
      "  time_total_s: 15109.400580406189\n",
      "  timers:\n",
      "    learn_throughput: 931.366\n",
      "    learn_time_ms: 10732.622\n",
      "    load_throughput: 91250.336\n",
      "    load_time_ms: 109.545\n",
      "    sample_throughput: 72.434\n",
      "    sample_time_ms: 138000.997\n",
      "    update_time_ms: 9.22\n",
      "  timestamp: 1636309522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1019592\n",
      "  training_iteration: 102\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         15109.4</td><td style=\"text-align: right;\">1019592</td><td style=\"text-align: right;\"> 2.54028</td><td style=\"text-align: right;\">               10.71</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           92.6944</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1029588\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-28-03\n",
      "  done: false\n",
      "  episode_len_mean: 90.73636363636363\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.77000000000001\n",
      "  episode_reward_mean: 2.206818181818187\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 11081\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.520952227176764\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013418924079286059\n",
      "          policy_loss: -0.07970226787699339\n",
      "          total_loss: 0.04706716005188914\n",
      "          vf_explained_var: 0.9048892855644226\n",
      "          vf_loss: 0.12140896362531134\n",
      "    num_agent_steps_sampled: 1029588\n",
      "    num_agent_steps_trained: 1029588\n",
      "    num_steps_sampled: 1029588\n",
      "    num_steps_trained: 1029588\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.60130434782609\n",
      "    ram_util_percent: 55.47782608695651\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04594237467912692\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.891185210994756\n",
      "    mean_inference_ms: 2.86933330178569\n",
      "    mean_raw_obs_processing_ms: 2.509394848840582\n",
      "  time_since_restore: 15270.422822237015\n",
      "  time_this_iter_s: 161.0222418308258\n",
      "  time_total_s: 15270.422822237015\n",
      "  timers:\n",
      "    learn_throughput: 931.202\n",
      "    learn_time_ms: 10734.512\n",
      "    load_throughput: 91339.994\n",
      "    load_time_ms: 109.437\n",
      "    sample_throughput: 71.222\n",
      "    sample_time_ms: 140349.871\n",
      "    update_time_ms: 8.786\n",
      "  timestamp: 1636309683\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1029588\n",
      "  training_iteration: 103\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         15270.4</td><td style=\"text-align: right;\">1029588</td><td style=\"text-align: right;\"> 2.20682</td><td style=\"text-align: right;\">                8.77</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           90.7364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1039584\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-30-30\n",
      "  done: false\n",
      "  episode_len_mean: 91.19266055045871\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.21000000000001\n",
      "  episode_reward_mean: 2.3452293577981704\n",
      "  episode_reward_min: -1.8100000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 11190\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5186590946637666\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014342167081517138\n",
      "          policy_loss: -0.08033990991325715\n",
      "          total_loss: 0.05858766633189387\n",
      "          vf_explained_var: 0.9047171473503113\n",
      "          vf_loss: 0.13144091779254696\n",
      "    num_agent_steps_sampled: 1039584\n",
      "    num_agent_steps_trained: 1039584\n",
      "    num_steps_sampled: 1039584\n",
      "    num_steps_trained: 1039584\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.6478672985782\n",
      "    ram_util_percent: 55.54691943127961\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04591462297674401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.889633245629824\n",
      "    mean_inference_ms: 2.869352004807962\n",
      "    mean_raw_obs_processing_ms: 2.5060921101744267\n",
      "  time_since_restore: 15417.93773150444\n",
      "  time_this_iter_s: 147.51490926742554\n",
      "  time_total_s: 15417.93773150444\n",
      "  timers:\n",
      "    learn_throughput: 931.198\n",
      "    learn_time_ms: 10734.556\n",
      "    load_throughput: 91475.15\n",
      "    load_time_ms: 109.276\n",
      "    sample_throughput: 71.528\n",
      "    sample_time_ms: 139749.952\n",
      "    update_time_ms: 8.729\n",
      "  timestamp: 1636309830\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1039584\n",
      "  training_iteration: 104\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         15417.9</td><td style=\"text-align: right;\">1039584</td><td style=\"text-align: right;\"> 2.34523</td><td style=\"text-align: right;\">               11.21</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           91.1927</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1049580\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-32-45\n",
      "  done: false\n",
      "  episode_len_mean: 92.71296296296296\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.760000000000014\n",
      "  episode_reward_mean: 2.1763888888888934\n",
      "  episode_reward_min: -1.9100000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 11298\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.52011144242735\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014385978395988566\n",
      "          policy_loss: -0.07975049068928401\n",
      "          total_loss: 0.08540924940831386\n",
      "          vf_explained_var: 0.8695869445800781\n",
      "          vf_loss: 0.15758779623633268\n",
      "    num_agent_steps_sampled: 1049580\n",
      "    num_agent_steps_trained: 1049580\n",
      "    num_steps_sampled: 1049580\n",
      "    num_steps_trained: 1049580\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11510416666668\n",
      "    ram_util_percent: 55.61666666666667\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04591713569450499\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.890649819866944\n",
      "    mean_inference_ms: 2.8695937473520132\n",
      "    mean_raw_obs_processing_ms: 2.490718968519953\n",
      "  time_since_restore: 15552.426887512207\n",
      "  time_this_iter_s: 134.48915600776672\n",
      "  time_total_s: 15552.426887512207\n",
      "  timers:\n",
      "    learn_throughput: 931.243\n",
      "    learn_time_ms: 10734.035\n",
      "    load_throughput: 91306.337\n",
      "    load_time_ms: 109.478\n",
      "    sample_throughput: 72.481\n",
      "    sample_time_ms: 137911.138\n",
      "    update_time_ms: 8.825\n",
      "  timestamp: 1636309965\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1049580\n",
      "  training_iteration: 105\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         15552.4</td><td style=\"text-align: right;\">1049580</td><td style=\"text-align: right;\"> 2.17639</td><td style=\"text-align: right;\">                8.76</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">            92.713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1059576\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-35-28\n",
      "  done: false\n",
      "  episode_len_mean: 91.8256880733945\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.9500000000000135\n",
      "  episode_reward_mean: 1.5677064220183532\n",
      "  episode_reward_min: -2.3200000000000003\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 11407\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5314805081766893\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01343269074929759\n",
      "          policy_loss: -0.08242232748426688\n",
      "          total_loss: 0.03385962285579015\n",
      "          vf_explained_var: 0.8982226848602295\n",
      "          vf_loss: 0.11099540582324705\n",
      "    num_agent_steps_sampled: 1059576\n",
      "    num_agent_steps_trained: 1059576\n",
      "    num_steps_sampled: 1059576\n",
      "    num_steps_trained: 1059576\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.25301724137933\n",
      "    ram_util_percent: 55.58275862068966\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04590165616045727\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.88805017619962\n",
      "    mean_inference_ms: 2.86939536548967\n",
      "    mean_raw_obs_processing_ms: 2.502563436617956\n",
      "  time_since_restore: 15715.135256052017\n",
      "  time_this_iter_s: 162.70836853981018\n",
      "  time_total_s: 15715.135256052017\n",
      "  timers:\n",
      "    learn_throughput: 931.327\n",
      "    learn_time_ms: 10733.072\n",
      "    load_throughput: 91087.595\n",
      "    load_time_ms: 109.741\n",
      "    sample_throughput: 71.819\n",
      "    sample_time_ms: 139183.045\n",
      "    update_time_ms: 8.746\n",
      "  timestamp: 1636310128\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1059576\n",
      "  training_iteration: 106\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         15715.1</td><td style=\"text-align: right;\">1059576</td><td style=\"text-align: right;\"> 1.56771</td><td style=\"text-align: right;\">                6.95</td><td style=\"text-align: right;\">               -2.32</td><td style=\"text-align: right;\">           91.8257</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1069572\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-38-08\n",
      "  done: false\n",
      "  episode_len_mean: 92.1574074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.700000000000012\n",
      "  episode_reward_mean: 2.5025925925925976\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 11515\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5148282517734755\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014358388713944063\n",
      "          policy_loss: -0.07870137463681973\n",
      "          total_loss: 0.06394496190592519\n",
      "          vf_explained_var: 0.8966584205627441\n",
      "          vf_loss: 0.13508441373069063\n",
      "    num_agent_steps_sampled: 1069572\n",
      "    num_agent_steps_trained: 1069572\n",
      "    num_steps_sampled: 1069572\n",
      "    num_steps_trained: 1069572\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.19737991266375\n",
      "    ram_util_percent: 55.52794759825327\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04592920788861736\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.86745185285143\n",
      "    mean_inference_ms: 2.8693006411215882\n",
      "    mean_raw_obs_processing_ms: 2.5402168103677303\n",
      "  time_since_restore: 15875.643441438675\n",
      "  time_this_iter_s: 160.50818538665771\n",
      "  time_total_s: 15875.643441438675\n",
      "  timers:\n",
      "    learn_throughput: 931.499\n",
      "    learn_time_ms: 10731.088\n",
      "    load_throughput: 91268.909\n",
      "    load_time_ms: 109.523\n",
      "    sample_throughput: 71.862\n",
      "    sample_time_ms: 139100.273\n",
      "    update_time_ms: 8.9\n",
      "  timestamp: 1636310288\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1069572\n",
      "  training_iteration: 107\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         15875.6</td><td style=\"text-align: right;\">1069572</td><td style=\"text-align: right;\"> 2.50259</td><td style=\"text-align: right;\">                10.7</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           92.1574</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1079568\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-40-26\n",
      "  done: false\n",
      "  episode_len_mean: 92.45370370370371\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.900000000000013\n",
      "  episode_reward_mean: 2.4626851851851903\n",
      "  episode_reward_min: -1.860000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 11623\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5166496299270893\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014325235846354402\n",
      "          policy_loss: -0.07841948995159732\n",
      "          total_loss: 0.057436002970028384\n",
      "          vf_explained_var: 0.9113554358482361\n",
      "          vf_loss: 0.12838731078653892\n",
      "    num_agent_steps_sampled: 1079568\n",
      "    num_agent_steps_trained: 1079568\n",
      "    num_steps_sampled: 1079568\n",
      "    num_steps_trained: 1079568\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.98477157360406\n",
      "    ram_util_percent: 55.49441624365483\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04590391086130844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.871835535362074\n",
      "    mean_inference_ms: 2.869442743771905\n",
      "    mean_raw_obs_processing_ms: 2.5201114130550204\n",
      "  time_since_restore: 16013.52763557434\n",
      "  time_this_iter_s: 137.8841941356659\n",
      "  time_total_s: 16013.52763557434\n",
      "  timers:\n",
      "    learn_throughput: 931.205\n",
      "    learn_time_ms: 10734.479\n",
      "    load_throughput: 91229.647\n",
      "    load_time_ms: 109.57\n",
      "    sample_throughput: 72.571\n",
      "    sample_time_ms: 137740.47\n",
      "    update_time_ms: 9.691\n",
      "  timestamp: 1636310426\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1079568\n",
      "  training_iteration: 108\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         16013.5</td><td style=\"text-align: right;\">1079568</td><td style=\"text-align: right;\"> 2.46269</td><td style=\"text-align: right;\">                 8.9</td><td style=\"text-align: right;\">               -1.86</td><td style=\"text-align: right;\">           92.4537</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1089564\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-43-11\n",
      "  done: false\n",
      "  episode_len_mean: 91.32727272727273\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.020000000000012\n",
      "  episode_reward_mean: 2.3139090909090965\n",
      "  episode_reward_min: -1.5200000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 11733\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.523335959157373\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014636058855517685\n",
      "          policy_loss: -0.08014618202757377\n",
      "          total_loss: 0.06281705499650576\n",
      "          vf_explained_var: 0.8958575129508972\n",
      "          vf_loss: 0.13485382453371317\n",
      "    num_agent_steps_sampled: 1089564\n",
      "    num_agent_steps_trained: 1089564\n",
      "    num_steps_sampled: 1089564\n",
      "    num_steps_trained: 1089564\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.57702127659574\n",
      "    ram_util_percent: 55.55617021276594\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04590707534185197\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.84905743196069\n",
      "    mean_inference_ms: 2.868863363139396\n",
      "    mean_raw_obs_processing_ms: 2.546410161923832\n",
      "  time_since_restore: 16178.340594291687\n",
      "  time_this_iter_s: 164.8129587173462\n",
      "  time_total_s: 16178.340594291687\n",
      "  timers:\n",
      "    learn_throughput: 931.142\n",
      "    learn_time_ms: 10735.205\n",
      "    load_throughput: 90900.476\n",
      "    load_time_ms: 109.966\n",
      "    sample_throughput: 71.743\n",
      "    sample_time_ms: 139330.623\n",
      "    update_time_ms: 10.954\n",
      "  timestamp: 1636310591\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1089564\n",
      "  training_iteration: 109\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         16178.3</td><td style=\"text-align: right;\">1089564</td><td style=\"text-align: right;\"> 2.31391</td><td style=\"text-align: right;\">               11.02</td><td style=\"text-align: right;\">               -1.52</td><td style=\"text-align: right;\">           91.3273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1099560\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-45-42\n",
      "  done: false\n",
      "  episode_len_mean: 90.46846846846847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.130000000000006\n",
      "  episode_reward_mean: 2.414144144144149\n",
      "  episode_reward_min: -1.3000000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 11844\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.50868232820788\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014357509750954156\n",
      "          policy_loss: -0.07690263481126126\n",
      "          total_loss: 0.07283436700255952\n",
      "          vf_explained_var: 0.9075911045074463\n",
      "          vf_loss: 0.142115621553718\n",
      "    num_agent_steps_sampled: 1099560\n",
      "    num_agent_steps_trained: 1099560\n",
      "    num_steps_sampled: 1099560\n",
      "    num_steps_trained: 1099560\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.71674418604651\n",
      "    ram_util_percent: 55.520930232558136\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04588708746225023\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.85213454155079\n",
      "    mean_inference_ms: 2.8687222468042513\n",
      "    mean_raw_obs_processing_ms: 2.5437592981104866\n",
      "  time_since_restore: 16329.12442612648\n",
      "  time_this_iter_s: 150.7838318347931\n",
      "  time_total_s: 16329.12442612648\n",
      "  timers:\n",
      "    learn_throughput: 931.211\n",
      "    learn_time_ms: 10734.404\n",
      "    load_throughput: 90841.685\n",
      "    load_time_ms: 110.038\n",
      "    sample_throughput: 71.581\n",
      "    sample_time_ms: 139646.065\n",
      "    update_time_ms: 11.108\n",
      "  timestamp: 1636310742\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1099560\n",
      "  training_iteration: 110\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         16329.1</td><td style=\"text-align: right;\">1099560</td><td style=\"text-align: right;\"> 2.41414</td><td style=\"text-align: right;\">                9.13</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">           90.4685</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1109556\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-48-01\n",
      "  done: false\n",
      "  episode_len_mean: 91.41284403669725\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.270000000000007\n",
      "  episode_reward_mean: 2.181009174311931\n",
      "  episode_reward_min: -1.8200000000000012\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 11953\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.512505729789408\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013891259441643959\n",
      "          policy_loss: -0.07893491332204296\n",
      "          total_loss: 0.05453095465946274\n",
      "          vf_explained_var: 0.9038194417953491\n",
      "          vf_loss: 0.12694489868501058\n",
      "    num_agent_steps_sampled: 1109556\n",
      "    num_agent_steps_trained: 1109556\n",
      "    num_steps_sampled: 1109556\n",
      "    num_steps_trained: 1109556\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87336683417087\n",
      "    ram_util_percent: 55.39195979899498\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04590154920178228\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.86341701261279\n",
      "    mean_inference_ms: 2.868852242956988\n",
      "    mean_raw_obs_processing_ms: 2.529311579455153\n",
      "  time_since_restore: 16468.593272209167\n",
      "  time_this_iter_s: 139.46884608268738\n",
      "  time_total_s: 16468.593272209167\n",
      "  timers:\n",
      "    learn_throughput: 931.581\n",
      "    learn_time_ms: 10730.141\n",
      "    load_throughput: 90783.009\n",
      "    load_time_ms: 110.109\n",
      "    sample_throughput: 72.063\n",
      "    sample_time_ms: 138711.326\n",
      "    update_time_ms: 12.358\n",
      "  timestamp: 1636310881\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1109556\n",
      "  training_iteration: 111\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         16468.6</td><td style=\"text-align: right;\">1109556</td><td style=\"text-align: right;\"> 2.18101</td><td style=\"text-align: right;\">               11.27</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           91.4128</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1119552\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-50-41\n",
      "  done: false\n",
      "  episode_len_mean: 91.34545454545454\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.720000000000011\n",
      "  episode_reward_mean: 2.1945454545454597\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 12063\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.525234479781909\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01397112770146404\n",
      "          policy_loss: -0.07925234970947106\n",
      "          total_loss: 0.06911996066825003\n",
      "          vf_explained_var: 0.8871068954467773\n",
      "          vf_loss: 0.14179667936972318\n",
      "    num_agent_steps_sampled: 1119552\n",
      "    num_agent_steps_trained: 1119552\n",
      "    num_steps_sampled: 1119552\n",
      "    num_steps_trained: 1119552\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.18590308370042\n",
      "    ram_util_percent: 55.465638766519824\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045881155081240785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.85092580783479\n",
      "    mean_inference_ms: 2.8684349059257106\n",
      "    mean_raw_obs_processing_ms: 2.5389229851245805\n",
      "  time_since_restore: 16627.875855207443\n",
      "  time_this_iter_s: 159.28258299827576\n",
      "  time_total_s: 16627.875855207443\n",
      "  timers:\n",
      "    learn_throughput: 931.401\n",
      "    learn_time_ms: 10732.225\n",
      "    load_throughput: 90574.004\n",
      "    load_time_ms: 110.363\n",
      "    sample_throughput: 70.904\n",
      "    sample_time_ms: 140979.911\n",
      "    update_time_ms: 12.033\n",
      "  timestamp: 1636311041\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1119552\n",
      "  training_iteration: 112\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         16627.9</td><td style=\"text-align: right;\">1119552</td><td style=\"text-align: right;\"> 2.19455</td><td style=\"text-align: right;\">                8.72</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           91.3455</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1129548\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-53-11\n",
      "  done: false\n",
      "  episode_len_mean: 92.35514018691589\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.450000000000017\n",
      "  episode_reward_mean: 2.4461682242990714\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 12170\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.523615714423677\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014986794695587925\n",
      "          policy_loss: -0.07860761327016302\n",
      "          total_loss: 0.07395939325802346\n",
      "          vf_explained_var: 0.8966024518013\n",
      "          vf_loss: 0.14366137204835047\n",
      "    num_agent_steps_sampled: 1129548\n",
      "    num_agent_steps_trained: 1129548\n",
      "    num_steps_sampled: 1129548\n",
      "    num_steps_trained: 1129548\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.76558139534885\n",
      "    ram_util_percent: 55.473953488372096\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04587496210306108\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.850567522237036\n",
      "    mean_inference_ms: 2.868531859066968\n",
      "    mean_raw_obs_processing_ms: 2.538561050989762\n",
      "  time_since_restore: 16778.062982320786\n",
      "  time_this_iter_s: 150.18712711334229\n",
      "  time_total_s: 16778.062982320786\n",
      "  timers:\n",
      "    learn_throughput: 931.319\n",
      "    learn_time_ms: 10733.169\n",
      "    load_throughput: 90433.907\n",
      "    load_time_ms: 110.534\n",
      "    sample_throughput: 71.454\n",
      "    sample_time_ms: 139894.855\n",
      "    update_time_ms: 11.894\n",
      "  timestamp: 1636311191\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1129548\n",
      "  training_iteration: 113\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         16778.1</td><td style=\"text-align: right;\">1129548</td><td style=\"text-align: right;\"> 2.44617</td><td style=\"text-align: right;\">               12.45</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           92.3551</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1139544\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-55-41\n",
      "  done: false\n",
      "  episode_len_mean: 91.89908256880734\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.210000000000012\n",
      "  episode_reward_mean: 2.2211926605504644\n",
      "  episode_reward_min: -1.830000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 12279\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5060009811678503\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013123893039810436\n",
      "          policy_loss: -0.08086327488701313\n",
      "          total_loss: 0.03465338381819236\n",
      "          vf_explained_var: 0.9099036455154419\n",
      "          vf_loss: 0.11067879903090433\n",
      "    num_agent_steps_sampled: 1139544\n",
      "    num_agent_steps_trained: 1139544\n",
      "    num_steps_sampled: 1139544\n",
      "    num_steps_trained: 1139544\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.46121495327102\n",
      "    ram_util_percent: 55.29532710280374\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045874770951756516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.8457220643401\n",
      "    mean_inference_ms: 2.8682584454194946\n",
      "    mean_raw_obs_processing_ms: 2.554061626396996\n",
      "  time_since_restore: 16928.373678922653\n",
      "  time_this_iter_s: 150.31069660186768\n",
      "  time_total_s: 16928.373678922653\n",
      "  timers:\n",
      "    learn_throughput: 931.791\n",
      "    learn_time_ms: 10727.723\n",
      "    load_throughput: 90234.02\n",
      "    load_time_ms: 110.779\n",
      "    sample_throughput: 71.308\n",
      "    sample_time_ms: 140179.98\n",
      "    update_time_ms: 11.501\n",
      "  timestamp: 1636311341\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1139544\n",
      "  training_iteration: 114\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         16928.4</td><td style=\"text-align: right;\">1139544</td><td style=\"text-align: right;\"> 2.22119</td><td style=\"text-align: right;\">                8.21</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           91.8991</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1149540\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_18-58-09\n",
      "  done: false\n",
      "  episode_len_mean: 92.57407407407408\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.210000000000017\n",
      "  episode_reward_mean: 2.1409259259259312\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 12387\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5070309029685127\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01402945550235612\n",
      "          policy_loss: -0.07935358458556808\n",
      "          total_loss: 0.04489233230567004\n",
      "          vf_explained_var: 0.9064720273017883\n",
      "          vf_loss: 0.1173553717473888\n",
      "    num_agent_steps_sampled: 1149540\n",
      "    num_agent_steps_trained: 1149540\n",
      "    num_steps_sampled: 1149540\n",
      "    num_steps_trained: 1149540\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.560663507109\n",
      "    ram_util_percent: 55.41137440758293\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04588851421737995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.83599538769198\n",
      "    mean_inference_ms: 2.868296633384751\n",
      "    mean_raw_obs_processing_ms: 2.5562284777772883\n",
      "  time_since_restore: 17076.24130153656\n",
      "  time_this_iter_s: 147.86762261390686\n",
      "  time_total_s: 17076.24130153656\n",
      "  timers:\n",
      "    learn_throughput: 932.039\n",
      "    learn_time_ms: 10724.877\n",
      "    load_throughput: 90379.966\n",
      "    load_time_ms: 110.6\n",
      "    sample_throughput: 70.633\n",
      "    sample_time_ms: 141520.662\n",
      "    update_time_ms: 11.766\n",
      "  timestamp: 1636311489\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1149540\n",
      "  training_iteration: 115\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         17076.2</td><td style=\"text-align: right;\">1149540</td><td style=\"text-align: right;\"> 2.14093</td><td style=\"text-align: right;\">               10.21</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           92.5741</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1159536\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-00-51\n",
      "  done: false\n",
      "  episode_len_mean: 92.08333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.530000000000005\n",
      "  episode_reward_mean: 2.060370370370375\n",
      "  episode_reward_min: -1.8000000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 12495\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5087737841483873\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012695746109073086\n",
      "          policy_loss: -0.08611554581130672\n",
      "          total_loss: 0.022979749304552873\n",
      "          vf_explained_var: 0.908194899559021\n",
      "          vf_loss: 0.10526053556997297\n",
      "    num_agent_steps_sampled: 1159536\n",
      "    num_agent_steps_trained: 1159536\n",
      "    num_steps_sampled: 1159536\n",
      "    num_steps_trained: 1159536\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.3147186147186\n",
      "    ram_util_percent: 55.62467532467532\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04586384102837825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.81950708013456\n",
      "    mean_inference_ms: 2.867905806830323\n",
      "    mean_raw_obs_processing_ms: 2.5678525873771343\n",
      "  time_since_restore: 17237.813680887222\n",
      "  time_this_iter_s: 161.57237935066223\n",
      "  time_total_s: 17237.813680887222\n",
      "  timers:\n",
      "    learn_throughput: 932.095\n",
      "    learn_time_ms: 10724.226\n",
      "    load_throughput: 90935.057\n",
      "    load_time_ms: 109.925\n",
      "    sample_throughput: 70.689\n",
      "    sample_time_ms: 141407.248\n",
      "    update_time_ms: 12.655\n",
      "  timestamp: 1636311651\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1159536\n",
      "  training_iteration: 116\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         17237.8</td><td style=\"text-align: right;\">1159536</td><td style=\"text-align: right;\"> 2.06037</td><td style=\"text-align: right;\">                9.53</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           92.0833</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1169532\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-03-40\n",
      "  done: false\n",
      "  episode_len_mean: 91.8256880733945\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.680000000000016\n",
      "  episode_reward_mean: 2.538073394495418\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 12604\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5097839773210704\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015231431065808158\n",
      "          policy_loss: -0.07644215349911943\n",
      "          total_loss: 0.08671518789254065\n",
      "          vf_explained_var: 0.8950908184051514\n",
      "          vf_loss: 0.15355607533715984\n",
      "    num_agent_steps_sampled: 1169532\n",
      "    num_agent_steps_trained: 1169532\n",
      "    num_steps_sampled: 1169532\n",
      "    num_steps_trained: 1169532\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.8207468879668\n",
      "    ram_util_percent: 55.453112033195026\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045819452538302614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.797928645371925\n",
      "    mean_inference_ms: 2.867462991783292\n",
      "    mean_raw_obs_processing_ms: 2.6026131709884037\n",
      "  time_since_restore: 17406.73229575157\n",
      "  time_this_iter_s: 168.91861486434937\n",
      "  time_total_s: 17406.73229575157\n",
      "  timers:\n",
      "    learn_throughput: 932.044\n",
      "    learn_time_ms: 10724.821\n",
      "    load_throughput: 90999.617\n",
      "    load_time_ms: 109.847\n",
      "    sample_throughput: 70.272\n",
      "    sample_time_ms: 142248.117\n",
      "    update_time_ms: 12.118\n",
      "  timestamp: 1636311820\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1169532\n",
      "  training_iteration: 117\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         17406.7</td><td style=\"text-align: right;\">1169532</td><td style=\"text-align: right;\"> 2.53807</td><td style=\"text-align: right;\">               10.68</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           91.8257</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1179528\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-06-23\n",
      "  done: false\n",
      "  episode_len_mean: 90.82727272727273\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.00000000000001\n",
      "  episode_reward_mean: 2.0773636363636414\n",
      "  episode_reward_min: -1.7000000000000004\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 12714\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5010064461292365\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012926075054556696\n",
      "          policy_loss: -0.08155576274053664\n",
      "          total_loss: 0.041042282741166586\n",
      "          vf_explained_var: 0.898971676826477\n",
      "          vf_loss: 0.11816089402040482\n",
      "    num_agent_steps_sampled: 1179528\n",
      "    num_agent_steps_trained: 1179528\n",
      "    num_steps_sampled: 1179528\n",
      "    num_steps_trained: 1179528\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.48103448275862\n",
      "    ram_util_percent: 55.58189655172413\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045814956696922385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.787447404357344\n",
      "    mean_inference_ms: 2.8671644101575713\n",
      "    mean_raw_obs_processing_ms: 2.617870757705318\n",
      "  time_since_restore: 17569.771766901016\n",
      "  time_this_iter_s: 163.03947114944458\n",
      "  time_total_s: 17569.771766901016\n",
      "  timers:\n",
      "    learn_throughput: 932.401\n",
      "    learn_time_ms: 10720.704\n",
      "    load_throughput: 91149.023\n",
      "    load_time_ms: 109.667\n",
      "    sample_throughput: 69.048\n",
      "    sample_time_ms: 144768.603\n",
      "    update_time_ms: 11.333\n",
      "  timestamp: 1636311983\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1179528\n",
      "  training_iteration: 118\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         17569.8</td><td style=\"text-align: right;\">1179528</td><td style=\"text-align: right;\"> 2.07736</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           90.8273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1189524\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-09-09\n",
      "  done: false\n",
      "  episode_len_mean: 90.22522522522523\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.88\n",
      "  episode_reward_mean: 1.8671171171171212\n",
      "  episode_reward_min: -2.0699999999999994\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 12825\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.501251906615037\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012929444165230623\n",
      "          policy_loss: -0.08346219852280158\n",
      "          total_loss: 0.023793616576486418\n",
      "          vf_explained_var: 0.8934633135795593\n",
      "          vf_loss: 0.10281344397455199\n",
      "    num_agent_steps_sampled: 1189524\n",
      "    num_agent_steps_trained: 1189524\n",
      "    num_steps_sampled: 1189524\n",
      "    num_steps_trained: 1189524\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.92226890756302\n",
      "    ram_util_percent: 55.596638655462186\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578897653362969\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.77930001883897\n",
      "    mean_inference_ms: 2.8668134504895546\n",
      "    mean_raw_obs_processing_ms: 2.64502409869741\n",
      "  time_since_restore: 17736.21967792511\n",
      "  time_this_iter_s: 166.44791102409363\n",
      "  time_total_s: 17736.21967792511\n",
      "  timers:\n",
      "    learn_throughput: 932.585\n",
      "    learn_time_ms: 10718.591\n",
      "    load_throughput: 91121.289\n",
      "    load_time_ms: 109.7\n",
      "    sample_throughput: 68.969\n",
      "    sample_time_ms: 144934.557\n",
      "    update_time_ms: 10.833\n",
      "  timestamp: 1636312149\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1189524\n",
      "  training_iteration: 119\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         17736.2</td><td style=\"text-align: right;\">1189524</td><td style=\"text-align: right;\"> 1.86712</td><td style=\"text-align: right;\">                9.88</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           90.2252</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1199520\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-11-50\n",
      "  done: false\n",
      "  episode_len_mean: 89.74107142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.510000000000016\n",
      "  episode_reward_mean: 2.4444642857142918\n",
      "  episode_reward_min: -2.0699999999999994\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 12937\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4763449143140743\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013310621567230181\n",
      "          policy_loss: -0.08069694240091957\n",
      "          total_loss: 0.04991413564461036\n",
      "          vf_explained_var: 0.922523558139801\n",
      "          vf_loss: 0.1250512657352747\n",
      "    num_agent_steps_sampled: 1199520\n",
      "    num_agent_steps_trained: 1199520\n",
      "    num_steps_sampled: 1199520\n",
      "    num_steps_trained: 1199520\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.8943231441048\n",
      "    ram_util_percent: 55.426200873362454\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045805576564539915\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.77311363790779\n",
      "    mean_inference_ms: 2.8665141481988345\n",
      "    mean_raw_obs_processing_ms: 2.671607899302449\n",
      "  time_since_restore: 17897.185289144516\n",
      "  time_this_iter_s: 160.96561121940613\n",
      "  time_total_s: 17897.185289144516\n",
      "  timers:\n",
      "    learn_throughput: 932.779\n",
      "    learn_time_ms: 10716.37\n",
      "    load_throughput: 91649.156\n",
      "    load_time_ms: 109.068\n",
      "    sample_throughput: 68.487\n",
      "    sample_time_ms: 145955.736\n",
      "    update_time_ms: 10.781\n",
      "  timestamp: 1636312310\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1199520\n",
      "  training_iteration: 120\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         17897.2</td><td style=\"text-align: right;\">1199520</td><td style=\"text-align: right;\"> 2.44446</td><td style=\"text-align: right;\">                8.51</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           89.7411</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1209516\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-14-23\n",
      "  done: false\n",
      "  episode_len_mean: 92.42592592592592\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.600000000000016\n",
      "  episode_reward_mean: 2.3746296296296348\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 13045\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5034104114923723\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014258952483697403\n",
      "          policy_loss: -0.07806427923437112\n",
      "          total_loss: 0.0604373816257486\n",
      "          vf_explained_var: 0.8886040449142456\n",
      "          vf_loss: 0.1310520863558492\n",
      "    num_agent_steps_sampled: 1209516\n",
      "    num_agent_steps_trained: 1209516\n",
      "    num_steps_sampled: 1209516\n",
      "    num_steps_trained: 1209516\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.68767123287671\n",
      "    ram_util_percent: 55.40913242009133\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576265385010761\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.765060355113356\n",
      "    mean_inference_ms: 2.866208348371193\n",
      "    mean_raw_obs_processing_ms: 2.6709679533890096\n",
      "  time_since_restore: 18050.313002586365\n",
      "  time_this_iter_s: 153.12771344184875\n",
      "  time_total_s: 18050.313002586365\n",
      "  timers:\n",
      "    learn_throughput: 932.706\n",
      "    learn_time_ms: 10717.207\n",
      "    load_throughput: 91867.385\n",
      "    load_time_ms: 108.809\n",
      "    sample_throughput: 67.851\n",
      "    sample_time_ms: 147322.825\n",
      "    update_time_ms: 9.328\n",
      "  timestamp: 1636312463\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1209516\n",
      "  training_iteration: 121\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         18050.3</td><td style=\"text-align: right;\">1209516</td><td style=\"text-align: right;\"> 2.37463</td><td style=\"text-align: right;\">                10.6</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           92.4259</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1219512\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-16-40\n",
      "  done: false\n",
      "  episode_len_mean: 92.41284403669725\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.890000000000011\n",
      "  episode_reward_mean: 1.9433027522935822\n",
      "  episode_reward_min: -2.4599999999999995\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 13154\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.518586225183601\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01404099937477519\n",
      "          policy_loss: -0.08146773364761065\n",
      "          total_loss: 0.05522946181635444\n",
      "          vf_explained_var: 0.8927851319313049\n",
      "          vf_loss: 0.12989590593542044\n",
      "    num_agent_steps_sampled: 1219512\n",
      "    num_agent_steps_trained: 1219512\n",
      "    num_steps_sampled: 1219512\n",
      "    num_steps_trained: 1219512\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04205128205126\n",
      "    ram_util_percent: 55.513846153846146\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04580350252927302\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.76803633873536\n",
      "    mean_inference_ms: 2.8666016219874013\n",
      "    mean_raw_obs_processing_ms: 2.6610770280330063\n",
      "  time_since_restore: 18186.67786169052\n",
      "  time_this_iter_s: 136.3648591041565\n",
      "  time_total_s: 18186.67786169052\n",
      "  timers:\n",
      "    learn_throughput: 932.441\n",
      "    learn_time_ms: 10720.254\n",
      "    load_throughput: 91927.189\n",
      "    load_time_ms: 108.738\n",
      "    sample_throughput: 68.925\n",
      "    sample_time_ms: 145027.668\n",
      "    update_time_ms: 9.502\n",
      "  timestamp: 1636312600\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1219512\n",
      "  training_iteration: 122\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         18186.7</td><td style=\"text-align: right;\">1219512</td><td style=\"text-align: right;\">  1.9433</td><td style=\"text-align: right;\">               10.89</td><td style=\"text-align: right;\">               -2.46</td><td style=\"text-align: right;\">           92.4128</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1229508\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-19-09\n",
      "  done: false\n",
      "  episode_len_mean: 93.13207547169812\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.060000000000013\n",
      "  episode_reward_mean: 2.0558490566037784\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 13260\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5046601751930693\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01345825673824362\n",
      "          policy_loss: -0.08294781334857401\n",
      "          total_loss: 0.03578591674216028\n",
      "          vf_explained_var: 0.9072006940841675\n",
      "          vf_loss: 0.11312073982503806\n",
      "    num_agent_steps_sampled: 1229508\n",
      "    num_agent_steps_trained: 1229508\n",
      "    num_steps_sampled: 1229508\n",
      "    num_steps_trained: 1229508\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.67981220657278\n",
      "    ram_util_percent: 55.45446009389672\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04582129987458612\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.76210879073161\n",
      "    mean_inference_ms: 2.8665460940269747\n",
      "    mean_raw_obs_processing_ms: 2.6736726197481335\n",
      "  time_since_restore: 18335.970911026\n",
      "  time_this_iter_s: 149.29304933547974\n",
      "  time_total_s: 18335.970911026\n",
      "  timers:\n",
      "    learn_throughput: 932.136\n",
      "    learn_time_ms: 10723.759\n",
      "    load_throughput: 92050.082\n",
      "    load_time_ms: 108.593\n",
      "    sample_throughput: 68.969\n",
      "    sample_time_ms: 144934.771\n",
      "    update_time_ms: 9.855\n",
      "  timestamp: 1636312749\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1229508\n",
      "  training_iteration: 123\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">           18336</td><td style=\"text-align: right;\">1229508</td><td style=\"text-align: right;\"> 2.05585</td><td style=\"text-align: right;\">                9.06</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           93.1321</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1239504\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-21-38\n",
      "  done: false\n",
      "  episode_len_mean: 91.46363636363637\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.440000000000015\n",
      "  episode_reward_mean: 2.272090909090915\n",
      "  episode_reward_min: -1.4600000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 13370\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.500634270855504\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013746317402417295\n",
      "          policy_loss: -0.0813627652075683\n",
      "          total_loss: 0.04917512311496668\n",
      "          vf_explained_var: 0.9140698313713074\n",
      "          vf_loss: 0.12422840073545519\n",
      "    num_agent_steps_sampled: 1239504\n",
      "    num_agent_steps_trained: 1239504\n",
      "    num_steps_sampled: 1239504\n",
      "    num_steps_trained: 1239504\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.7737089201878\n",
      "    ram_util_percent: 55.376995305164314\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045788889151881146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.759611666305126\n",
      "    mean_inference_ms: 2.8665182642476155\n",
      "    mean_raw_obs_processing_ms: 2.667220924264669\n",
      "  time_since_restore: 18485.14214205742\n",
      "  time_this_iter_s: 149.17123103141785\n",
      "  time_total_s: 18485.14214205742\n",
      "  timers:\n",
      "    learn_throughput: 931.776\n",
      "    learn_time_ms: 10727.899\n",
      "    load_throughput: 92027.473\n",
      "    load_time_ms: 108.62\n",
      "    sample_throughput: 69.025\n",
      "    sample_time_ms: 144816.081\n",
      "    update_time_ms: 10.354\n",
      "  timestamp: 1636312898\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1239504\n",
      "  training_iteration: 124\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         18485.1</td><td style=\"text-align: right;\">1239504</td><td style=\"text-align: right;\"> 2.27209</td><td style=\"text-align: right;\">               10.44</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           91.4636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1249500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-23-54\n",
      "  done: false\n",
      "  episode_len_mean: 92.16822429906541\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.290000000000006\n",
      "  episode_reward_mean: 2.299065420560754\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 13477\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.514885278440948\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0140508476405776\n",
      "          policy_loss: -0.08324291240742318\n",
      "          total_loss: 0.047982333981010136\n",
      "          vf_explained_var: 0.901093602180481\n",
      "          vf_loss: 0.12436451087904792\n",
      "    num_agent_steps_sampled: 1249500\n",
      "    num_agent_steps_trained: 1249500\n",
      "    num_steps_sampled: 1249500\n",
      "    num_steps_trained: 1249500\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03056994818651\n",
      "    ram_util_percent: 55.42538860103628\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045825059034512484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.76088490307388\n",
      "    mean_inference_ms: 2.866653604697233\n",
      "    mean_raw_obs_processing_ms: 2.655151001848523\n",
      "  time_since_restore: 18620.618123054504\n",
      "  time_this_iter_s: 135.47598099708557\n",
      "  time_total_s: 18620.618123054504\n",
      "  timers:\n",
      "    learn_throughput: 931.759\n",
      "    learn_time_ms: 10728.1\n",
      "    load_throughput: 92043.939\n",
      "    load_time_ms: 108.6\n",
      "    sample_throughput: 69.621\n",
      "    sample_time_ms: 143576.807\n",
      "    update_time_ms: 10.123\n",
      "  timestamp: 1636313034\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1249500\n",
      "  training_iteration: 125\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         18620.6</td><td style=\"text-align: right;\">1249500</td><td style=\"text-align: right;\"> 2.29907</td><td style=\"text-align: right;\">                9.29</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           92.1682</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1259496\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-26-12\n",
      "  done: false\n",
      "  episode_len_mean: 94.35514018691589\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.430000000000017\n",
      "  episode_reward_mean: 2.399626168224305\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 13584\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.500425718177078\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012758639392001739\n",
      "          policy_loss: -0.0860444890979964\n",
      "          total_loss: 0.015013092960047925\n",
      "          vf_explained_var: 0.9142963290214539\n",
      "          vf_loss: 0.09699606259918621\n",
      "    num_agent_steps_sampled: 1259496\n",
      "    num_agent_steps_trained: 1259496\n",
      "    num_steps_sampled: 1259496\n",
      "    num_steps_trained: 1259496\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.61319796954317\n",
      "    ram_util_percent: 55.39543147208123\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04582223300437304\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.76855884295313\n",
      "    mean_inference_ms: 2.8667549692663594\n",
      "    mean_raw_obs_processing_ms: 2.6397649487143826\n",
      "  time_since_restore: 18758.945734739304\n",
      "  time_this_iter_s: 138.3276116847992\n",
      "  time_total_s: 18758.945734739304\n",
      "  timers:\n",
      "    learn_throughput: 931.642\n",
      "    learn_time_ms: 10729.439\n",
      "    load_throughput: 91471.358\n",
      "    load_time_ms: 109.28\n",
      "    sample_throughput: 70.768\n",
      "    sample_time_ms: 141250.053\n",
      "    update_time_ms: 10.631\n",
      "  timestamp: 1636313172\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1259496\n",
      "  training_iteration: 126\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         18758.9</td><td style=\"text-align: right;\">1259496</td><td style=\"text-align: right;\"> 2.39963</td><td style=\"text-align: right;\">               10.43</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           94.3551</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1269492\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-28-43\n",
      "  done: false\n",
      "  episode_len_mean: 91.30275229357798\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.690000000000015\n",
      "  episode_reward_mean: 2.47642201834863\n",
      "  episode_reward_min: -1.880000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 13693\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4900931015992778\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014026295217298927\n",
      "          policy_loss: -0.08115572390170434\n",
      "          total_loss: 0.07229705712972925\n",
      "          vf_explained_var: 0.9071541428565979\n",
      "          vf_loss: 0.14640005772662723\n",
      "    num_agent_steps_sampled: 1269492\n",
      "    num_agent_steps_trained: 1269492\n",
      "    num_steps_sampled: 1269492\n",
      "    num_steps_trained: 1269492\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.93981481481481\n",
      "    ram_util_percent: 55.161111111111104\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045818756634197454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.764534527131325\n",
      "    mean_inference_ms: 2.8664418057538636\n",
      "    mean_raw_obs_processing_ms: 2.662550564335342\n",
      "  time_since_restore: 18910.1165766716\n",
      "  time_this_iter_s: 151.17084193229675\n",
      "  time_total_s: 18910.1165766716\n",
      "  timers:\n",
      "    learn_throughput: 931.667\n",
      "    learn_time_ms: 10729.154\n",
      "    load_throughput: 91407.123\n",
      "    load_time_ms: 109.357\n",
      "    sample_throughput: 71.67\n",
      "    sample_time_ms: 139473.506\n",
      "    update_time_ms: 12.157\n",
      "  timestamp: 1636313323\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1269492\n",
      "  training_iteration: 127\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         18910.1</td><td style=\"text-align: right;\">1269492</td><td style=\"text-align: right;\"> 2.47642</td><td style=\"text-align: right;\">               10.69</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           91.3028</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1279488\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-31-08\n",
      "  done: false\n",
      "  episode_len_mean: 93.33333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.690000000000017\n",
      "  episode_reward_mean: 2.344907407407414\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 13801\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.499899204368265\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013446652821213066\n",
      "          policy_loss: -0.08651474219802607\n",
      "          total_loss: 0.02246232653259594\n",
      "          vf_explained_var: 0.9131360054016113\n",
      "          vf_loss: 0.10334290511842467\n",
      "    num_agent_steps_sampled: 1279488\n",
      "    num_agent_steps_trained: 1279488\n",
      "    num_steps_sampled: 1279488\n",
      "    num_steps_trained: 1279488\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.67536231884056\n",
      "    ram_util_percent: 55.581159420289836\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04581346198799403\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.7593442619174\n",
      "    mean_inference_ms: 2.86625481592791\n",
      "    mean_raw_obs_processing_ms: 2.6616293438608154\n",
      "  time_since_restore: 19054.914887189865\n",
      "  time_this_iter_s: 144.79831051826477\n",
      "  time_total_s: 19054.914887189865\n",
      "  timers:\n",
      "    learn_throughput: 931.015\n",
      "    learn_time_ms: 10736.673\n",
      "    load_throughput: 91386.681\n",
      "    load_time_ms: 109.381\n",
      "    sample_throughput: 72.624\n",
      "    sample_time_ms: 137640.533\n",
      "    update_time_ms: 13.483\n",
      "  timestamp: 1636313468\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1279488\n",
      "  training_iteration: 128\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         19054.9</td><td style=\"text-align: right;\">1279488</td><td style=\"text-align: right;\"> 2.34491</td><td style=\"text-align: right;\">                8.69</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           93.3333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1289484\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-33-58\n",
      "  done: false\n",
      "  episode_len_mean: 93.29906542056075\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.000000000000009\n",
      "  episode_reward_mean: 2.795140186915895\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 13908\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4843217611312864\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014241642459987582\n",
      "          policy_loss: -0.08193998758513958\n",
      "          total_loss: 0.049130447644294584\n",
      "          vf_explained_var: 0.908458948135376\n",
      "          vf_loss: 0.12346941063451207\n",
      "    num_agent_steps_sampled: 1289484\n",
      "    num_agent_steps_trained: 1289484\n",
      "    num_steps_sampled: 1289484\n",
      "    num_steps_trained: 1289484\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.60413223140495\n",
      "    ram_util_percent: 55.52727272727273\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045803551502943\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.74861676968089\n",
      "    mean_inference_ms: 2.8662921038779032\n",
      "    mean_raw_obs_processing_ms: 2.6912898530049967\n",
      "  time_since_restore: 19224.812975168228\n",
      "  time_this_iter_s: 169.89808797836304\n",
      "  time_total_s: 19224.812975168228\n",
      "  timers:\n",
      "    learn_throughput: 930.647\n",
      "    learn_time_ms: 10740.911\n",
      "    load_throughput: 91723.483\n",
      "    load_time_ms: 108.98\n",
      "    sample_throughput: 72.444\n",
      "    sample_time_ms: 137982.4\n",
      "    update_time_ms: 12.604\n",
      "  timestamp: 1636313638\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1289484\n",
      "  training_iteration: 129\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         19224.8</td><td style=\"text-align: right;\">1289484</td><td style=\"text-align: right;\"> 2.79514</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           93.2991</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1299480\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-36-28\n",
      "  done: false\n",
      "  episode_len_mean: 94.39047619047619\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.120000000000013\n",
      "  episode_reward_mean: 2.46780952380953\n",
      "  episode_reward_min: -1.8900000000000012\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 14013\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5040195259273563\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014964390928174129\n",
      "          policy_loss: -0.08056974953884243\n",
      "          total_loss: 0.05913820854332457\n",
      "          vf_explained_var: 0.9033365845680237\n",
      "          vf_loss: 0.13065739871345014\n",
      "    num_agent_steps_sampled: 1299480\n",
      "    num_agent_steps_trained: 1299480\n",
      "    num_steps_sampled: 1299480\n",
      "    num_steps_trained: 1299480\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.33785046728971\n",
      "    ram_util_percent: 55.55981308411216\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04581693343179762\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.746194713758\n",
      "    mean_inference_ms: 2.8660955475376015\n",
      "    mean_raw_obs_processing_ms: 2.6880012603113053\n",
      "  time_since_restore: 19374.75782608986\n",
      "  time_this_iter_s: 149.94485092163086\n",
      "  time_total_s: 19374.75782608986\n",
      "  timers:\n",
      "    learn_throughput: 930.317\n",
      "    learn_time_ms: 10744.723\n",
      "    load_throughput: 91761.706\n",
      "    load_time_ms: 108.934\n",
      "    sample_throughput: 73.03\n",
      "    sample_time_ms: 136875.787\n",
      "    update_time_ms: 13.543\n",
      "  timestamp: 1636313788\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1299480\n",
      "  training_iteration: 130\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         19374.8</td><td style=\"text-align: right;\">1299480</td><td style=\"text-align: right;\"> 2.46781</td><td style=\"text-align: right;\">                9.12</td><td style=\"text-align: right;\">               -1.89</td><td style=\"text-align: right;\">           94.3905</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1309476\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-38-53\n",
      "  done: false\n",
      "  episode_len_mean: 93.52777777777777\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.260000000000009\n",
      "  episode_reward_mean: 2.5129629629629693\n",
      "  episode_reward_min: -1.8200000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 14121\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4992141876465235\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01475456013245197\n",
      "          policy_loss: -0.07993803051037666\n",
      "          total_loss: 0.06915044648588722\n",
      "          vf_explained_var: 0.8963756561279297\n",
      "          vf_loss: 0.1404678841185175\n",
      "    num_agent_steps_sampled: 1309476\n",
      "    num_agent_steps_trained: 1309476\n",
      "    num_steps_sampled: 1309476\n",
      "    num_steps_trained: 1309476\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.60528846153846\n",
      "    ram_util_percent: 55.465865384615384\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457814672936466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.73673284623777\n",
      "    mean_inference_ms: 2.866069942387738\n",
      "    mean_raw_obs_processing_ms: 2.6854231233646395\n",
      "  time_since_restore: 19520.076770544052\n",
      "  time_this_iter_s: 145.31894445419312\n",
      "  time_total_s: 19520.076770544052\n",
      "  timers:\n",
      "    learn_throughput: 930.26\n",
      "    learn_time_ms: 10745.385\n",
      "    load_throughput: 91677.633\n",
      "    load_time_ms: 109.034\n",
      "    sample_throughput: 73.45\n",
      "    sample_time_ms: 136092.867\n",
      "    update_time_ms: 14.549\n",
      "  timestamp: 1636313933\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1309476\n",
      "  training_iteration: 131\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         19520.1</td><td style=\"text-align: right;\">1309476</td><td style=\"text-align: right;\"> 2.51296</td><td style=\"text-align: right;\">               11.26</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           93.5278</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1319472\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-41-21\n",
      "  done: false\n",
      "  episode_len_mean: 95.40384615384616\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.400000000000016\n",
      "  episode_reward_mean: 2.1100961538461593\n",
      "  episode_reward_min: -1.6200000000000008\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 14225\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.49353743862902\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013361837810790573\n",
      "          policy_loss: -0.08046111927455307\n",
      "          total_loss: 0.040719077363610266\n",
      "          vf_explained_var: 0.9043065905570984\n",
      "          vf_loss: 0.11567563363390727\n",
      "    num_agent_steps_sampled: 1319472\n",
      "    num_agent_steps_trained: 1319472\n",
      "    num_steps_sampled: 1319472\n",
      "    num_steps_trained: 1319472\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.69857142857141\n",
      "    ram_util_percent: 55.54\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04580693553104292\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.72916787772839\n",
      "    mean_inference_ms: 2.865954119203771\n",
      "    mean_raw_obs_processing_ms: 2.687813180046357\n",
      "  time_since_restore: 19667.814463615417\n",
      "  time_this_iter_s: 147.73769307136536\n",
      "  time_total_s: 19667.814463615417\n",
      "  timers:\n",
      "    learn_throughput: 930.639\n",
      "    learn_time_ms: 10741.006\n",
      "    load_throughput: 92005.622\n",
      "    load_time_ms: 108.646\n",
      "    sample_throughput: 72.838\n",
      "    sample_time_ms: 137235.29\n",
      "    update_time_ms: 14.432\n",
      "  timestamp: 1636314081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1319472\n",
      "  training_iteration: 132\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         19667.8</td><td style=\"text-align: right;\">1319472</td><td style=\"text-align: right;\">  2.1101</td><td style=\"text-align: right;\">                 8.4</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">           95.4038</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1329468\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-43-37\n",
      "  done: false\n",
      "  episode_len_mean: 93.30841121495327\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.760000000000018\n",
      "  episode_reward_mean: 2.404205607476642\n",
      "  episode_reward_min: -1.950000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 14332\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4733550801236404\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013591523559847758\n",
      "          policy_loss: -0.08160322504197685\n",
      "          total_loss: 0.03580214035434601\n",
      "          vf_explained_var: 0.9145292639732361\n",
      "          vf_loss: 0.11117572514738283\n",
      "    num_agent_steps_sampled: 1329468\n",
      "    num_agent_steps_trained: 1329468\n",
      "    num_steps_sampled: 1329468\n",
      "    num_steps_trained: 1329468\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.81597938144331\n",
      "    ram_util_percent: 55.58092783505154\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577343849009199\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.732254641438594\n",
      "    mean_inference_ms: 2.865870239821902\n",
      "    mean_raw_obs_processing_ms: 2.6661639392163115\n",
      "  time_since_restore: 19803.46444940567\n",
      "  time_this_iter_s: 135.64998579025269\n",
      "  time_total_s: 19803.46444940567\n",
      "  timers:\n",
      "    learn_throughput: 930.912\n",
      "    learn_time_ms: 10737.856\n",
      "    load_throughput: 92060.047\n",
      "    load_time_ms: 108.581\n",
      "    sample_throughput: 73.568\n",
      "    sample_time_ms: 135874.371\n",
      "    update_time_ms: 14.327\n",
      "  timestamp: 1636314217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1329468\n",
      "  training_iteration: 133\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         19803.5</td><td style=\"text-align: right;\">1329468</td><td style=\"text-align: right;\"> 2.40421</td><td style=\"text-align: right;\">                8.76</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           93.3084</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1339464\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-46-18\n",
      "  done: false\n",
      "  episode_len_mean: 91.61467889908256\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.740000000000016\n",
      "  episode_reward_mean: 2.5471559633027585\n",
      "  episode_reward_min: -2.3199999999999976\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 14441\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4840445675401606\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014338742352346194\n",
      "          policy_loss: -0.07858670271344037\n",
      "          total_loss: 0.07351409788601673\n",
      "          vf_explained_var: 0.9144460558891296\n",
      "          vf_loss: 0.1442757984647193\n",
      "    num_agent_steps_sampled: 1339464\n",
      "    num_agent_steps_trained: 1339464\n",
      "    num_steps_sampled: 1339464\n",
      "    num_steps_trained: 1339464\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.3421739130435\n",
      "    ram_util_percent: 55.50652173913043\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045764450584560995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.72392394810021\n",
      "    mean_inference_ms: 2.8656327592389235\n",
      "    mean_raw_obs_processing_ms: 2.6793012610298224\n",
      "  time_since_restore: 19964.4407453537\n",
      "  time_this_iter_s: 160.97629594802856\n",
      "  time_total_s: 19964.4407453537\n",
      "  timers:\n",
      "    learn_throughput: 930.553\n",
      "    learn_time_ms: 10741.996\n",
      "    load_throughput: 91784.064\n",
      "    load_time_ms: 108.908\n",
      "    sample_throughput: 72.937\n",
      "    sample_time_ms: 137049.649\n",
      "    update_time_ms: 15.199\n",
      "  timestamp: 1636314378\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1339464\n",
      "  training_iteration: 134\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         19964.4</td><td style=\"text-align: right;\">1339464</td><td style=\"text-align: right;\"> 2.54716</td><td style=\"text-align: right;\">               12.74</td><td style=\"text-align: right;\">               -2.32</td><td style=\"text-align: right;\">           91.6147</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1349460\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-48-47\n",
      "  done: false\n",
      "  episode_len_mean: 92.19266055045871\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.700000000000015\n",
      "  episode_reward_mean: 2.650183486238538\n",
      "  episode_reward_min: -1.7000000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 14550\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4836563884702505\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013231605002724939\n",
      "          policy_loss: -0.07980369379441453\n",
      "          total_loss: 0.0397089596463638\n",
      "          vf_explained_var: 0.9260602593421936\n",
      "          vf_loss: 0.11420596749800392\n",
      "    num_agent_steps_sampled: 1349460\n",
      "    num_agent_steps_trained: 1349460\n",
      "    num_steps_sampled: 1349460\n",
      "    num_steps_trained: 1349460\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.51084905660375\n",
      "    ram_util_percent: 55.50377358490566\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576312258156946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.7210850830005\n",
      "    mean_inference_ms: 2.865534637255213\n",
      "    mean_raw_obs_processing_ms: 2.6774406578644876\n",
      "  time_since_restore: 20113.064527750015\n",
      "  time_this_iter_s: 148.62378239631653\n",
      "  time_total_s: 20113.064527750015\n",
      "  timers:\n",
      "    learn_throughput: 929.929\n",
      "    learn_time_ms: 10749.207\n",
      "    load_throughput: 91882.868\n",
      "    load_time_ms: 108.791\n",
      "    sample_throughput: 72.247\n",
      "    sample_time_ms: 138357.959\n",
      "    update_time_ms: 14.798\n",
      "  timestamp: 1636314527\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1349460\n",
      "  training_iteration: 135\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         20113.1</td><td style=\"text-align: right;\">1349460</td><td style=\"text-align: right;\"> 2.65018</td><td style=\"text-align: right;\">                10.7</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           92.1927</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1359456\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-51-02\n",
      "  done: false\n",
      "  episode_len_mean: 94.47169811320755\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.450000000000012\n",
      "  episode_reward_mean: 2.6295283018867983\n",
      "  episode_reward_min: -2.17\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 14656\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.487950796754951\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013267317901245999\n",
      "          policy_loss: -0.08512308164778301\n",
      "          total_loss: 0.028191216457157563\n",
      "          vf_explained_var: 0.9113751649856567\n",
      "          vf_loss: 0.10796919675846385\n",
      "    num_agent_steps_sampled: 1359456\n",
      "    num_agent_steps_trained: 1359456\n",
      "    num_steps_sampled: 1359456\n",
      "    num_steps_trained: 1359456\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08082901554404\n",
      "    ram_util_percent: 55.54870466321243\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04579040583056311\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.72470562195425\n",
      "    mean_inference_ms: 2.86585862459497\n",
      "    mean_raw_obs_processing_ms: 2.6662756340448133\n",
      "  time_since_restore: 20248.426711559296\n",
      "  time_this_iter_s: 135.3621838092804\n",
      "  time_total_s: 20248.426711559296\n",
      "  timers:\n",
      "    learn_throughput: 929.751\n",
      "    learn_time_ms: 10751.261\n",
      "    load_throughput: 91922.916\n",
      "    load_time_ms: 108.743\n",
      "    sample_throughput: 72.404\n",
      "    sample_time_ms: 138059.468\n",
      "    update_time_ms: 14.392\n",
      "  timestamp: 1636314662\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1359456\n",
      "  training_iteration: 136\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         20248.4</td><td style=\"text-align: right;\">1359456</td><td style=\"text-align: right;\"> 2.62953</td><td style=\"text-align: right;\">               10.45</td><td style=\"text-align: right;\">               -2.17</td><td style=\"text-align: right;\">           94.4717</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1369452\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-53-31\n",
      "  done: false\n",
      "  episode_len_mean: 93.39622641509433\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.740000000000009\n",
      "  episode_reward_mean: 2.1699056603773634\n",
      "  episode_reward_min: -2.09\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 14762\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4930481588738598\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013458897937996999\n",
      "          policy_loss: -0.08117077029509168\n",
      "          total_loss: 0.03536067003559353\n",
      "          vf_explained_var: 0.9024460911750793\n",
      "          vf_loss: 0.11080086907117158\n",
      "    num_agent_steps_sampled: 1369452\n",
      "    num_agent_steps_trained: 1369452\n",
      "    num_steps_sampled: 1369452\n",
      "    num_steps_trained: 1369452\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.01737089201876\n",
      "    ram_util_percent: 55.55211267605633\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576854149050945\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.72224624554139\n",
      "    mean_inference_ms: 2.865782987430794\n",
      "    mean_raw_obs_processing_ms: 2.6615104209839915\n",
      "  time_since_restore: 20397.87549638748\n",
      "  time_this_iter_s: 149.44878482818604\n",
      "  time_total_s: 20397.87549638748\n",
      "  timers:\n",
      "    learn_throughput: 929.638\n",
      "    learn_time_ms: 10752.575\n",
      "    load_throughput: 92034.867\n",
      "    load_time_ms: 108.611\n",
      "    sample_throughput: 72.494\n",
      "    sample_time_ms: 137888.219\n",
      "    update_time_ms: 12.844\n",
      "  timestamp: 1636314811\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1369452\n",
      "  training_iteration: 137\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         20397.9</td><td style=\"text-align: right;\">1369452</td><td style=\"text-align: right;\"> 2.16991</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">               -2.09</td><td style=\"text-align: right;\">           93.3962</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1379448\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-56-39\n",
      "  done: false\n",
      "  episode_len_mean: 92.85321100917432\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.120000000000012\n",
      "  episode_reward_mean: 2.8492660550458786\n",
      "  episode_reward_min: -1.930000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 14871\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4995739828827035\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01366194098387174\n",
      "          policy_loss: -0.08060027715296317\n",
      "          total_loss: 0.048665314701059434\n",
      "          vf_explained_var: 0.923119068145752\n",
      "          vf_loss: 0.12313772107864547\n",
      "    num_agent_steps_sampled: 1379448\n",
      "    num_agent_steps_trained: 1379448\n",
      "    num_steps_sampled: 1379448\n",
      "    num_steps_trained: 1379448\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.27089552238807\n",
      "    ram_util_percent: 55.54589552238806\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576790090609073\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.71915794911598\n",
      "    mean_inference_ms: 2.865839562860737\n",
      "    mean_raw_obs_processing_ms: 2.690324110582504\n",
      "  time_since_restore: 20585.50050497055\n",
      "  time_this_iter_s: 187.62500858306885\n",
      "  time_total_s: 20585.50050497055\n",
      "  timers:\n",
      "    learn_throughput: 929.876\n",
      "    learn_time_ms: 10749.818\n",
      "    load_throughput: 91860.381\n",
      "    load_time_ms: 108.817\n",
      "    sample_throughput: 70.308\n",
      "    sample_time_ms: 142174.658\n",
      "    update_time_ms: 11.682\n",
      "  timestamp: 1636314999\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1379448\n",
      "  training_iteration: 138\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         20585.5</td><td style=\"text-align: right;\">1379448</td><td style=\"text-align: right;\"> 2.84927</td><td style=\"text-align: right;\">               11.12</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">           92.8532</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1389444\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_19-59-22\n",
      "  done: false\n",
      "  episode_len_mean: 91.34862385321101\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.610000000000012\n",
      "  episode_reward_mean: 2.142844036697253\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 14980\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.49713330024328\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012816549188123538\n",
      "          policy_loss: -0.0850025643602523\n",
      "          total_loss: 0.019741304371601497\n",
      "          vf_explained_var: 0.92364501953125\n",
      "          vf_loss: 0.10051750023650308\n",
      "    num_agent_steps_sampled: 1389444\n",
      "    num_agent_steps_trained: 1389444\n",
      "    num_steps_sampled: 1389444\n",
      "    num_steps_trained: 1389444\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.55818965517241\n",
      "    ram_util_percent: 55.466810344827586\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045791012086132725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.71199020393092\n",
      "    mean_inference_ms: 2.865337210331871\n",
      "    mean_raw_obs_processing_ms: 2.7141092833317786\n",
      "  time_since_restore: 20748.56908249855\n",
      "  time_this_iter_s: 163.06857752799988\n",
      "  time_total_s: 20748.56908249855\n",
      "  timers:\n",
      "    learn_throughput: 930.203\n",
      "    learn_time_ms: 10746.045\n",
      "    load_throughput: 91709.077\n",
      "    load_time_ms: 108.997\n",
      "    sample_throughput: 70.646\n",
      "    sample_time_ms: 141495.082\n",
      "    update_time_ms: 11.688\n",
      "  timestamp: 1636315162\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1389444\n",
      "  training_iteration: 139\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         20748.6</td><td style=\"text-align: right;\">1389444</td><td style=\"text-align: right;\"> 2.14284</td><td style=\"text-align: right;\">                8.61</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           91.3486</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1399440\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-01-37\n",
      "  done: false\n",
      "  episode_len_mean: 94.54285714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.13000000000001\n",
      "  episode_reward_mean: 2.4348571428571484\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 15085\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.515169446081178\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013762743440845573\n",
      "          policy_loss: -0.08365266160068349\n",
      "          total_loss: 0.03725298355277787\n",
      "          vf_explained_var: 0.9057474136352539\n",
      "          vf_loss: 0.11470408904581116\n",
      "    num_agent_steps_sampled: 1399440\n",
      "    num_agent_steps_trained: 1399440\n",
      "    num_steps_sampled: 1399440\n",
      "    num_steps_trained: 1399440\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94922279792745\n",
      "    ram_util_percent: 55.538341968911915\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575441320023891\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.71106256127321\n",
      "    mean_inference_ms: 2.865499438058818\n",
      "    mean_raw_obs_processing_ms: 2.69591457084881\n",
      "  time_since_restore: 20883.715568304062\n",
      "  time_this_iter_s: 135.14648580551147\n",
      "  time_total_s: 20883.715568304062\n",
      "  timers:\n",
      "    learn_throughput: 930.444\n",
      "    learn_time_ms: 10743.264\n",
      "    load_throughput: 91233.26\n",
      "    load_time_ms: 109.565\n",
      "    sample_throughput: 71.391\n",
      "    sample_time_ms: 140017.868\n",
      "    update_time_ms: 11.255\n",
      "  timestamp: 1636315297\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1399440\n",
      "  training_iteration: 140\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         20883.7</td><td style=\"text-align: right;\">1399440</td><td style=\"text-align: right;\"> 2.43486</td><td style=\"text-align: right;\">               13.13</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           94.5429</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1409436\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-04-03\n",
      "  done: false\n",
      "  episode_len_mean: 94.94339622641509\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000015\n",
      "  episode_reward_mean: 2.048962264150948\n",
      "  episode_reward_min: -2.189999999999997\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 15191\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.516207298458132\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013319692389660992\n",
      "          policy_loss: -0.08168262255210908\n",
      "          total_loss: 0.046163785684471714\n",
      "          vf_explained_var: 0.8952115178108215\n",
      "          vf_loss: 0.12266455605052985\n",
      "    num_agent_steps_sampled: 1409436\n",
      "    num_agent_steps_trained: 1409436\n",
      "    num_steps_sampled: 1409436\n",
      "    num_steps_trained: 1409436\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78221153846154\n",
      "    ram_util_percent: 55.50384615384615\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576219021356888\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.702090554866245\n",
      "    mean_inference_ms: 2.865516139879027\n",
      "    mean_raw_obs_processing_ms: 2.695728337499805\n",
      "  time_since_restore: 21029.104379415512\n",
      "  time_this_iter_s: 145.3888111114502\n",
      "  time_total_s: 21029.104379415512\n",
      "  timers:\n",
      "    learn_throughput: 930.112\n",
      "    learn_time_ms: 10747.095\n",
      "    load_throughput: 91176.853\n",
      "    load_time_ms: 109.633\n",
      "    sample_throughput: 71.389\n",
      "    sample_time_ms: 140020.758\n",
      "    update_time_ms: 11.446\n",
      "  timestamp: 1636315443\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1409436\n",
      "  training_iteration: 141\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         21029.1</td><td style=\"text-align: right;\">1409436</td><td style=\"text-align: right;\"> 2.04896</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">               -2.19</td><td style=\"text-align: right;\">           94.9434</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1419432\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-06-32\n",
      "  done: false\n",
      "  episode_len_mean: 93.30841121495327\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.790000000000015\n",
      "  episode_reward_mean: 2.4016822429906597\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 15298\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.499329665583423\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013086006725173576\n",
      "          policy_loss: -0.08364523139535489\n",
      "          total_loss: 0.040723531485463565\n",
      "          vf_explained_var: 0.9041531085968018\n",
      "          vf_loss: 0.11955049862114028\n",
      "    num_agent_steps_sampled: 1419432\n",
      "    num_agent_steps_trained: 1419432\n",
      "    num_steps_sampled: 1419432\n",
      "    num_steps_trained: 1419432\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.01886792452831\n",
      "    ram_util_percent: 55.39622641509434\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045764976715178686\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.69710648747263\n",
      "    mean_inference_ms: 2.8655730243124173\n",
      "    mean_raw_obs_processing_ms: 2.7070841290523715\n",
      "  time_since_restore: 21177.79001712799\n",
      "  time_this_iter_s: 148.68563771247864\n",
      "  time_total_s: 21177.79001712799\n",
      "  timers:\n",
      "    learn_throughput: 930.105\n",
      "    learn_time_ms: 10747.177\n",
      "    load_throughput: 90925.67\n",
      "    load_time_ms: 109.936\n",
      "    sample_throughput: 71.341\n",
      "    sample_time_ms: 140115.275\n",
      "    update_time_ms: 11.324\n",
      "  timestamp: 1636315592\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1419432\n",
      "  training_iteration: 142\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         21177.8</td><td style=\"text-align: right;\">1419432</td><td style=\"text-align: right;\"> 2.40168</td><td style=\"text-align: right;\">               10.79</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           93.3084</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1429428\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-08-49\n",
      "  done: false\n",
      "  episode_len_mean: 93.23148148148148\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.740000000000016\n",
      "  episode_reward_mean: 2.2029629629629683\n",
      "  episode_reward_min: -1.730000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 15406\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5046103404118463\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012885041351038799\n",
      "          policy_loss: -0.08330719826870367\n",
      "          total_loss: 0.01919776639765781\n",
      "          vf_explained_var: 0.9158593416213989\n",
      "          vf_loss: 0.09819733213362658\n",
      "    num_agent_steps_sampled: 1429428\n",
      "    num_agent_steps_trained: 1429428\n",
      "    num_steps_sampled: 1429428\n",
      "    num_steps_trained: 1429428\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92704081632655\n",
      "    ram_util_percent: 55.467346938775506\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577318528418776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.703903288932025\n",
      "    mean_inference_ms: 2.865765244271675\n",
      "    mean_raw_obs_processing_ms: 2.6925603758427465\n",
      "  time_since_restore: 21315.17098879814\n",
      "  time_this_iter_s: 137.38097167015076\n",
      "  time_total_s: 21315.17098879814\n",
      "  timers:\n",
      "    learn_throughput: 930.394\n",
      "    learn_time_ms: 10743.837\n",
      "    load_throughput: 90932.513\n",
      "    load_time_ms: 109.928\n",
      "    sample_throughput: 71.251\n",
      "    sample_time_ms: 140291.989\n",
      "    update_time_ms: 11.005\n",
      "  timestamp: 1636315729\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1429428\n",
      "  training_iteration: 143\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         21315.2</td><td style=\"text-align: right;\">1429428</td><td style=\"text-align: right;\"> 2.20296</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           93.2315</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1439424\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-11-19\n",
      "  done: false\n",
      "  episode_len_mean: 93.11111111111111\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.290000000000017\n",
      "  episode_reward_mean: 2.511759259259265\n",
      "  episode_reward_min: -1.7000000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 15514\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5039966037130763\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014304469593943388\n",
      "          policy_loss: -0.08523369189829398\n",
      "          total_loss: 0.05408409167495039\n",
      "          vf_explained_var: 0.9086123108863831\n",
      "          vf_loss: 0.13177037742068498\n",
      "    num_agent_steps_sampled: 1439424\n",
      "    num_agent_steps_trained: 1439424\n",
      "    num_steps_sampled: 1439424\n",
      "    num_steps_trained: 1439424\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.51549295774649\n",
      "    ram_util_percent: 55.640845070422536\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045775763947137636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.702038631007746\n",
      "    mean_inference_ms: 2.865676960208855\n",
      "    mean_raw_obs_processing_ms: 2.690961975572373\n",
      "  time_since_restore: 21464.69447040558\n",
      "  time_this_iter_s: 149.52348160743713\n",
      "  time_total_s: 21464.69447040558\n",
      "  timers:\n",
      "    learn_throughput: 930.399\n",
      "    learn_time_ms: 10743.773\n",
      "    load_throughput: 91274.711\n",
      "    load_time_ms: 109.516\n",
      "    sample_throughput: 71.837\n",
      "    sample_time_ms: 139148.178\n",
      "    update_time_ms: 9.73\n",
      "  timestamp: 1636315879\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1439424\n",
      "  training_iteration: 144\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         21464.7</td><td style=\"text-align: right;\">1439424</td><td style=\"text-align: right;\"> 2.51176</td><td style=\"text-align: right;\">               10.29</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           93.1111</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1449420\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-13-49\n",
      "  done: false\n",
      "  episode_len_mean: 92.10185185185185\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.450000000000017\n",
      "  episode_reward_mean: 2.2881481481481547\n",
      "  episode_reward_min: -1.8300000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 15622\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5045489062610855\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012683153689580541\n",
      "          policy_loss: -0.08433173545118836\n",
      "          total_loss: 0.0290465959522905\n",
      "          vf_explained_var: 0.9192653894424438\n",
      "          vf_loss: 0.10953000967796796\n",
      "    num_agent_steps_sampled: 1449420\n",
      "    num_agent_steps_trained: 1449420\n",
      "    num_steps_sampled: 1449420\n",
      "    num_steps_trained: 1449420\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.27757009345795\n",
      "    ram_util_percent: 55.43878504672898\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578767437189507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.69865988866545\n",
      "    mean_inference_ms: 2.865524908962437\n",
      "    mean_raw_obs_processing_ms: 2.700814144779781\n",
      "  time_since_restore: 21614.713577747345\n",
      "  time_this_iter_s: 150.01910734176636\n",
      "  time_total_s: 21614.713577747345\n",
      "  timers:\n",
      "    learn_throughput: 931.263\n",
      "    learn_time_ms: 10733.804\n",
      "    load_throughput: 91071.786\n",
      "    load_time_ms: 109.76\n",
      "    sample_throughput: 71.76\n",
      "    sample_time_ms: 139297.392\n",
      "    update_time_ms: 9.634\n",
      "  timestamp: 1636316029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1449420\n",
      "  training_iteration: 145\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         21614.7</td><td style=\"text-align: right;\">1449420</td><td style=\"text-align: right;\"> 2.28815</td><td style=\"text-align: right;\">               10.45</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           92.1019</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1459416\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-16-04\n",
      "  done: false\n",
      "  episode_len_mean: 93.73831775700934\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.670000000000016\n",
      "  episode_reward_mean: 2.7921495327102877\n",
      "  episode_reward_min: -1.7400000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 15729\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.503856944018959\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01364988594154093\n",
      "          policy_loss: -0.08426331508204214\n",
      "          total_loss: 0.031405988520281945\n",
      "          vf_explained_var: 0.9329918622970581\n",
      "          vf_loss: 0.10961172622509109\n",
      "    num_agent_steps_sampled: 1459416\n",
      "    num_agent_steps_trained: 1459416\n",
      "    num_steps_sampled: 1459416\n",
      "    num_steps_trained: 1459416\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12279792746115\n",
      "    ram_util_percent: 55.644041450777195\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045780862116445206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.70062827064656\n",
      "    mean_inference_ms: 2.8656623396910788\n",
      "    mean_raw_obs_processing_ms: 2.6880385567190417\n",
      "  time_since_restore: 21749.78629207611\n",
      "  time_this_iter_s: 135.07271432876587\n",
      "  time_total_s: 21749.78629207611\n",
      "  timers:\n",
      "    learn_throughput: 931.091\n",
      "    learn_time_ms: 10735.797\n",
      "    load_throughput: 91143.911\n",
      "    load_time_ms: 109.673\n",
      "    sample_throughput: 71.776\n",
      "    sample_time_ms: 139267.322\n",
      "    update_time_ms: 8.864\n",
      "  timestamp: 1636316164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1459416\n",
      "  training_iteration: 146\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         21749.8</td><td style=\"text-align: right;\">1459416</td><td style=\"text-align: right;\"> 2.79215</td><td style=\"text-align: right;\">               12.67</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           93.7383</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1469412\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-19-02\n",
      "  done: false\n",
      "  episode_len_mean: 91.93518518518519\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.820000000000013\n",
      "  episode_reward_mean: 2.475555555555561\n",
      "  episode_reward_min: -1.8200000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 15837\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.493053421811161\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013177542322150824\n",
      "          policy_loss: -0.0852029150686203\n",
      "          total_loss: 0.018763898856317004\n",
      "          vf_explained_var: 0.9279175996780396\n",
      "          vf_loss: 0.09887725947997891\n",
      "    num_agent_steps_sampled: 1469412\n",
      "    num_agent_steps_trained: 1469412\n",
      "    num_steps_sampled: 1469412\n",
      "    num_steps_trained: 1469412\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.6670588235294\n",
      "    ram_util_percent: 55.59607843137254\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577976105609332\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.703636206317185\n",
      "    mean_inference_ms: 2.865696396485032\n",
      "    mean_raw_obs_processing_ms: 2.7048706924395334\n",
      "  time_since_restore: 21928.412573575974\n",
      "  time_this_iter_s: 178.62628149986267\n",
      "  time_total_s: 21928.412573575974\n",
      "  timers:\n",
      "    learn_throughput: 930.082\n",
      "    learn_time_ms: 10747.443\n",
      "    load_throughput: 91169.954\n",
      "    load_time_ms: 109.641\n",
      "    sample_throughput: 70.309\n",
      "    sample_time_ms: 142172.295\n",
      "    update_time_ms: 9.855\n",
      "  timestamp: 1636316342\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1469412\n",
      "  training_iteration: 147\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         21928.4</td><td style=\"text-align: right;\">1469412</td><td style=\"text-align: right;\"> 2.47556</td><td style=\"text-align: right;\">                8.82</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           91.9352</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1479408\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-21-35\n",
      "  done: false\n",
      "  episode_len_mean: 91.35779816513761\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.30000000000001\n",
      "  episode_reward_mean: 2.2276146788990876\n",
      "  episode_reward_min: -2.12\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 15946\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.501949546683548\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014320820369194808\n",
      "          policy_loss: -0.08323524749049774\n",
      "          total_loss: 0.044371284697300346\n",
      "          vf_explained_var: 0.9120408296585083\n",
      "          vf_loss: 0.12000140766334584\n",
      "    num_agent_steps_sampled: 1479408\n",
      "    num_agent_steps_trained: 1479408\n",
      "    num_steps_sampled: 1479408\n",
      "    num_steps_trained: 1479408\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.23364055299541\n",
      "    ram_util_percent: 55.41658986175114\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576381756426433\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.70877188754044\n",
      "    mean_inference_ms: 2.865906684111137\n",
      "    mean_raw_obs_processing_ms: 2.7017973890060656\n",
      "  time_since_restore: 22080.680787324905\n",
      "  time_this_iter_s: 152.26821374893188\n",
      "  time_total_s: 22080.680787324905\n",
      "  timers:\n",
      "    learn_throughput: 929.896\n",
      "    learn_time_ms: 10749.59\n",
      "    load_throughput: 91312.939\n",
      "    load_time_ms: 109.47\n",
      "    sample_throughput: 72.104\n",
      "    sample_time_ms: 138632.732\n",
      "    update_time_ms: 11.769\n",
      "  timestamp: 1636316495\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1479408\n",
      "  training_iteration: 148\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         22080.7</td><td style=\"text-align: right;\">1479408</td><td style=\"text-align: right;\"> 2.22761</td><td style=\"text-align: right;\">                 9.3</td><td style=\"text-align: right;\">               -2.12</td><td style=\"text-align: right;\">           91.3578</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1489404\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-23-49\n",
      "  done: false\n",
      "  episode_len_mean: 93.4392523364486\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.270000000000012\n",
      "  episode_reward_mean: 2.272056074766361\n",
      "  episode_reward_min: -2.0099999999999993\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 16053\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5102897226301013\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013858118290875892\n",
      "          policy_loss: -0.08079682507066645\n",
      "          total_loss: 0.05169509374974375\n",
      "          vf_explained_var: 0.904965877532959\n",
      "          vf_loss: 0.12602428847159713\n",
      "    num_agent_steps_sampled: 1489404\n",
      "    num_agent_steps_trained: 1489404\n",
      "    num_steps_sampled: 1489404\n",
      "    num_steps_trained: 1489404\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.15781250000002\n",
      "    ram_util_percent: 55.56145833333333\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577668101460165\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.71116527202147\n",
      "    mean_inference_ms: 2.866118365577921\n",
      "    mean_raw_obs_processing_ms: 2.687605454307305\n",
      "  time_since_restore: 22215.139469623566\n",
      "  time_this_iter_s: 134.45868229866028\n",
      "  time_total_s: 22215.139469623566\n",
      "  timers:\n",
      "    learn_throughput: 929.366\n",
      "    learn_time_ms: 10755.721\n",
      "    load_throughput: 91410.87\n",
      "    load_time_ms: 109.352\n",
      "    sample_throughput: 73.627\n",
      "    sample_time_ms: 135764.653\n",
      "    update_time_ms: 13.268\n",
      "  timestamp: 1636316629\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1489404\n",
      "  training_iteration: 149\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         22215.1</td><td style=\"text-align: right;\">1489404</td><td style=\"text-align: right;\"> 2.27206</td><td style=\"text-align: right;\">                9.27</td><td style=\"text-align: right;\">               -2.01</td><td style=\"text-align: right;\">           93.4393</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1499400\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-26-18\n",
      "  done: false\n",
      "  episode_len_mean: 92.1574074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.590000000000018\n",
      "  episode_reward_mean: 2.251111111111117\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 16161\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.496755850213206\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013401686361693923\n",
      "          policy_loss: -0.08551507297043617\n",
      "          total_loss: 0.03254095756440845\n",
      "          vf_explained_var: 0.9145838618278503\n",
      "          vf_loss: 0.11249287160447775\n",
      "    num_agent_steps_sampled: 1499400\n",
      "    num_agent_steps_trained: 1499400\n",
      "    num_steps_sampled: 1499400\n",
      "    num_steps_trained: 1499400\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.80892018779342\n",
      "    ram_util_percent: 55.520657276995294\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045772997755765946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.709109141012085\n",
      "    mean_inference_ms: 2.8659352277974275\n",
      "    mean_raw_obs_processing_ms: 2.6856668846922966\n",
      "  time_since_restore: 22364.20312690735\n",
      "  time_this_iter_s: 149.06365728378296\n",
      "  time_total_s: 22364.20312690735\n",
      "  timers:\n",
      "    learn_throughput: 929.519\n",
      "    learn_time_ms: 10753.95\n",
      "    load_throughput: 91830.08\n",
      "    load_time_ms: 108.853\n",
      "    sample_throughput: 72.879\n",
      "    sample_time_ms: 137159.175\n",
      "    update_time_ms: 12.653\n",
      "  timestamp: 1636316778\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1499400\n",
      "  training_iteration: 150\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         22364.2</td><td style=\"text-align: right;\">1499400</td><td style=\"text-align: right;\"> 2.25111</td><td style=\"text-align: right;\">                8.59</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           92.1574</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1509396\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-29-00\n",
      "  done: false\n",
      "  episode_len_mean: 92.22935779816514\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.850000000000016\n",
      "  episode_reward_mean: 2.5500000000000056\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 16270\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5006105113233255\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013747328631685223\n",
      "          policy_loss: -0.08310312086827734\n",
      "          total_loss: 0.030398918519544807\n",
      "          vf_explained_var: 0.9092439413070679\n",
      "          vf_loss: 0.10719001206816134\n",
      "    num_agent_steps_sampled: 1509396\n",
      "    num_agent_steps_trained: 1509396\n",
      "    num_steps_sampled: 1509396\n",
      "    num_steps_trained: 1509396\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.44304347826088\n",
      "    ram_util_percent: 55.45565217391304\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577181676880753\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.69946535545309\n",
      "    mean_inference_ms: 2.865863432744305\n",
      "    mean_raw_obs_processing_ms: 2.697087626888854\n",
      "  time_since_restore: 22525.86762905121\n",
      "  time_this_iter_s: 161.66450214385986\n",
      "  time_total_s: 22525.86762905121\n",
      "  timers:\n",
      "    learn_throughput: 929.988\n",
      "    learn_time_ms: 10748.522\n",
      "    load_throughput: 91893.32\n",
      "    load_time_ms: 108.778\n",
      "    sample_throughput: 72.021\n",
      "    sample_time_ms: 138793.565\n",
      "    update_time_ms: 11.261\n",
      "  timestamp: 1636316940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1509396\n",
      "  training_iteration: 151\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         22525.9</td><td style=\"text-align: right;\">1509396</td><td style=\"text-align: right;\">    2.55</td><td style=\"text-align: right;\">               10.85</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           92.2294</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1519392\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-31-18\n",
      "  done: false\n",
      "  episode_len_mean: 93.83962264150944\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.920000000000014\n",
      "  episode_reward_mean: 2.5735849056603834\n",
      "  episode_reward_min: -2.3100000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 16376\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5027895134738367\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01389927465357827\n",
      "          policy_loss: -0.08141363270453408\n",
      "          total_loss: 0.0517153012765269\n",
      "          vf_explained_var: 0.9060806632041931\n",
      "          vf_loss: 0.1264925429549737\n",
      "    num_agent_steps_sampled: 1519392\n",
      "    num_agent_steps_trained: 1519392\n",
      "    num_steps_sampled: 1519392\n",
      "    num_steps_trained: 1519392\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79238578680203\n",
      "    ram_util_percent: 55.56091370558376\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457880733366051\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.70494763875867\n",
      "    mean_inference_ms: 2.8660385952244027\n",
      "    mean_raw_obs_processing_ms: 2.6865357008050683\n",
      "  time_since_restore: 22663.73676943779\n",
      "  time_this_iter_s: 137.86914038658142\n",
      "  time_total_s: 22663.73676943779\n",
      "  timers:\n",
      "    learn_throughput: 929.853\n",
      "    learn_time_ms: 10750.091\n",
      "    load_throughput: 91734.721\n",
      "    load_time_ms: 108.966\n",
      "    sample_throughput: 72.587\n",
      "    sample_time_ms: 137710.296\n",
      "    update_time_ms: 11.345\n",
      "  timestamp: 1636317078\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1519392\n",
      "  training_iteration: 152\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         22663.7</td><td style=\"text-align: right;\">1519392</td><td style=\"text-align: right;\"> 2.57358</td><td style=\"text-align: right;\">               12.92</td><td style=\"text-align: right;\">               -2.31</td><td style=\"text-align: right;\">           93.8396</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1529388\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-33-47\n",
      "  done: false\n",
      "  episode_len_mean: 94.20754716981132\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.780000000000014\n",
      "  episode_reward_mean: 3.0327358490566105\n",
      "  episode_reward_min: -1.9400000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 16482\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.494545528012463\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01491354715952469\n",
      "          policy_loss: -0.08309647862353704\n",
      "          total_loss: 0.05615915631413714\n",
      "          vf_explained_var: 0.9268737435340881\n",
      "          vf_loss: 0.1302261640644099\n",
      "    num_agent_steps_sampled: 1529388\n",
      "    num_agent_steps_trained: 1529388\n",
      "    num_steps_sampled: 1529388\n",
      "    num_steps_trained: 1529388\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.6507042253521\n",
      "    ram_util_percent: 55.51971830985915\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577422462049002\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.70472042200673\n",
      "    mean_inference_ms: 2.8658691870635518\n",
      "    mean_raw_obs_processing_ms: 2.6827390180108153\n",
      "  time_since_restore: 22812.87048101425\n",
      "  time_this_iter_s: 149.1337115764618\n",
      "  time_total_s: 22812.87048101425\n",
      "  timers:\n",
      "    learn_throughput: 929.812\n",
      "    learn_time_ms: 10750.562\n",
      "    load_throughput: 91799.538\n",
      "    load_time_ms: 108.889\n",
      "    sample_throughput: 71.974\n",
      "    sample_time_ms: 138884.396\n",
      "    update_time_ms: 12.182\n",
      "  timestamp: 1636317227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1529388\n",
      "  training_iteration: 153\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         22812.9</td><td style=\"text-align: right;\">1529388</td><td style=\"text-align: right;\"> 3.03274</td><td style=\"text-align: right;\">               12.78</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           94.2075</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1539384\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-36-17\n",
      "  done: false\n",
      "  episode_len_mean: 94.5377358490566\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.080000000000007\n",
      "  episode_reward_mean: 2.6899056603773652\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 16588\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5071878834667367\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0135145278118282\n",
      "          policy_loss: -0.08404081961633558\n",
      "          total_loss: 0.03176670105029375\n",
      "          vf_explained_var: 0.9178188443183899\n",
      "          vf_loss: 0.1100916147327576\n",
      "    num_agent_steps_sampled: 1539384\n",
      "    num_agent_steps_trained: 1539384\n",
      "    num_steps_sampled: 1539384\n",
      "    num_steps_trained: 1539384\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.93317757009345\n",
      "    ram_util_percent: 55.471495327102794\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04579436241890326\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.70749846595019\n",
      "    mean_inference_ms: 2.8659942881323817\n",
      "    mean_raw_obs_processing_ms: 2.6833612070477852\n",
      "  time_since_restore: 22962.99156475067\n",
      "  time_this_iter_s: 150.12108373641968\n",
      "  time_total_s: 22962.99156475067\n",
      "  timers:\n",
      "    learn_throughput: 930.162\n",
      "    learn_time_ms: 10746.515\n",
      "    load_throughput: 91524.693\n",
      "    load_time_ms: 109.216\n",
      "    sample_throughput: 71.941\n",
      "    sample_time_ms: 138946.406\n",
      "    update_time_ms: 13.97\n",
      "  timestamp: 1636317377\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1539384\n",
      "  training_iteration: 154\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">           22963</td><td style=\"text-align: right;\">1539384</td><td style=\"text-align: right;\"> 2.68991</td><td style=\"text-align: right;\">                9.08</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           94.5377</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1549380\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-38-46\n",
      "  done: false\n",
      "  episode_len_mean: 93.59813084112149\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.680000000000016\n",
      "  episode_reward_mean: 2.56971962616823\n",
      "  episode_reward_min: -1.6600000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 16695\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5012220521258492\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01424880438530368\n",
      "          policy_loss: -0.08385573502025033\n",
      "          total_loss: 0.0484775500674533\n",
      "          vf_explained_var: 0.9093213677406311\n",
      "          vf_loss: 0.12488494649067776\n",
      "    num_agent_steps_sampled: 1549380\n",
      "    num_agent_steps_trained: 1549380\n",
      "    num_steps_sampled: 1549380\n",
      "    num_steps_trained: 1549380\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.5377358490566\n",
      "    ram_util_percent: 55.55754716981131\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577114106643109\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.706323995978515\n",
      "    mean_inference_ms: 2.865774193714921\n",
      "    mean_raw_obs_processing_ms: 2.67834629840911\n",
      "  time_since_restore: 23111.59472131729\n",
      "  time_this_iter_s: 148.60315656661987\n",
      "  time_total_s: 23111.59472131729\n",
      "  timers:\n",
      "    learn_throughput: 929.445\n",
      "    learn_time_ms: 10754.81\n",
      "    load_throughput: 91546.716\n",
      "    load_time_ms: 109.19\n",
      "    sample_throughput: 72.019\n",
      "    sample_time_ms: 138795.879\n",
      "    update_time_ms: 14.82\n",
      "  timestamp: 1636317526\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1549380\n",
      "  training_iteration: 155\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         23111.6</td><td style=\"text-align: right;\">1549380</td><td style=\"text-align: right;\"> 2.56972</td><td style=\"text-align: right;\">               12.68</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           93.5981</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1559376\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-41-22\n",
      "  done: false\n",
      "  episode_len_mean: 92.77981651376147\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.520000000000016\n",
      "  episode_reward_mean: 2.758623853211015\n",
      "  episode_reward_min: -2.1\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 16804\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.50600140869108\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013402741524729027\n",
      "          policy_loss: -0.08904644814280109\n",
      "          total_loss: 0.02347909927400004\n",
      "          vf_explained_var: 0.9313921928405762\n",
      "          vf_loss: 0.10705243941221354\n",
      "    num_agent_steps_sampled: 1559376\n",
      "    num_agent_steps_trained: 1559376\n",
      "    num_steps_sampled: 1559376\n",
      "    num_steps_trained: 1559376\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.75401785714287\n",
      "    ram_util_percent: 55.51205357142856\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04579424972647503\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.709895345513516\n",
      "    mean_inference_ms: 2.8657117785682065\n",
      "    mean_raw_obs_processing_ms: 2.684410302932082\n",
      "  time_since_restore: 23268.060032129288\n",
      "  time_this_iter_s: 156.46531081199646\n",
      "  time_total_s: 23268.060032129288\n",
      "  timers:\n",
      "    learn_throughput: 929.501\n",
      "    learn_time_ms: 10754.161\n",
      "    load_throughput: 91334.621\n",
      "    load_time_ms: 109.444\n",
      "    sample_throughput: 70.926\n",
      "    sample_time_ms: 140934.936\n",
      "    update_time_ms: 15.487\n",
      "  timestamp: 1636317682\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1559376\n",
      "  training_iteration: 156\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         23268.1</td><td style=\"text-align: right;\">1559376</td><td style=\"text-align: right;\"> 2.75862</td><td style=\"text-align: right;\">               12.52</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">           92.7798</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1569372\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-44-31\n",
      "  done: false\n",
      "  episode_len_mean: 92.3177570093458\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.610000000000015\n",
      "  episode_reward_mean: 2.5803738317757063\n",
      "  episode_reward_min: -1.8200000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 16911\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5041604313076054\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014510981628238485\n",
      "          policy_loss: -0.0851977299198381\n",
      "          total_loss: 0.05241042495601707\n",
      "          vf_explained_var: 0.9089487195014954\n",
      "          vf_loss: 0.1295919283810589\n",
      "    num_agent_steps_sampled: 1569372\n",
      "    num_agent_steps_trained: 1569372\n",
      "    num_steps_sampled: 1569372\n",
      "    num_steps_trained: 1569372\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.55746268656716\n",
      "    ram_util_percent: 55.61865671641792\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045776949105705574\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.689230423306725\n",
      "    mean_inference_ms: 2.8651084596546195\n",
      "    mean_raw_obs_processing_ms: 2.726823813611849\n",
      "  time_since_restore: 23456.170826911926\n",
      "  time_this_iter_s: 188.11079478263855\n",
      "  time_total_s: 23456.170826911926\n",
      "  timers:\n",
      "    learn_throughput: 930.551\n",
      "    learn_time_ms: 10742.028\n",
      "    load_throughput: 91290.352\n",
      "    load_time_ms: 109.497\n",
      "    sample_throughput: 70.446\n",
      "    sample_time_ms: 141896.438\n",
      "    update_time_ms: 14.453\n",
      "  timestamp: 1636317871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1569372\n",
      "  training_iteration: 157\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         23456.2</td><td style=\"text-align: right;\">1569372</td><td style=\"text-align: right;\"> 2.58037</td><td style=\"text-align: right;\">               12.61</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           92.3178</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1579368\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-47-03\n",
      "  done: false\n",
      "  episode_len_mean: 93.08333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.700000000000003\n",
      "  episode_reward_mean: 2.3020370370370418\n",
      "  episode_reward_min: -2.369999999999995\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 17019\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.499976481943049\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013473195178533223\n",
      "          policy_loss: -0.08527443248332821\n",
      "          total_loss: 0.044042784351314236\n",
      "          vf_explained_var: 0.9201496243476868\n",
      "          vf_loss: 0.1236233591229424\n",
      "    num_agent_steps_sampled: 1579368\n",
      "    num_agent_steps_trained: 1579368\n",
      "    num_steps_sampled: 1579368\n",
      "    num_steps_trained: 1579368\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.66238532110093\n",
      "    ram_util_percent: 55.585321100917426\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045774682387960196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.692200443301125\n",
      "    mean_inference_ms: 2.865170734103342\n",
      "    mean_raw_obs_processing_ms: 2.726959818711756\n",
      "  time_since_restore: 23608.801973104477\n",
      "  time_this_iter_s: 152.63114619255066\n",
      "  time_total_s: 23608.801973104477\n",
      "  timers:\n",
      "    learn_throughput: 931.0\n",
      "    learn_time_ms: 10736.838\n",
      "    load_throughput: 91118.853\n",
      "    load_time_ms: 109.703\n",
      "    sample_throughput: 70.425\n",
      "    sample_time_ms: 141938.469\n",
      "    update_time_ms: 13.682\n",
      "  timestamp: 1636318023\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1579368\n",
      "  training_iteration: 158\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         23608.8</td><td style=\"text-align: right;\">1579368</td><td style=\"text-align: right;\"> 2.30204</td><td style=\"text-align: right;\">                 9.7</td><td style=\"text-align: right;\">               -2.37</td><td style=\"text-align: right;\">           93.0833</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1589364\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-49-35\n",
      "  done: false\n",
      "  episode_len_mean: 94.25471698113208\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.530000000000014\n",
      "  episode_reward_mean: 2.6404716981132137\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 17125\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5020227413911087\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014096735678353102\n",
      "          policy_loss: -0.08444628791612947\n",
      "          total_loss: 0.03773767793089406\n",
      "          vf_explained_var: 0.9226403832435608\n",
      "          vf_loss: 0.11509006553226048\n",
      "    num_agent_steps_sampled: 1589364\n",
      "    num_agent_steps_trained: 1589364\n",
      "    num_steps_sampled: 1589364\n",
      "    num_steps_trained: 1589364\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.54675925925925\n",
      "    ram_util_percent: 55.70509259259259\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575499855700902\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.691470158290926\n",
      "    mean_inference_ms: 2.8649476424647946\n",
      "    mean_raw_obs_processing_ms: 2.7223928575813545\n",
      "  time_since_restore: 23760.665544509888\n",
      "  time_this_iter_s: 151.86357140541077\n",
      "  time_total_s: 23760.665544509888\n",
      "  timers:\n",
      "    learn_throughput: 931.396\n",
      "    learn_time_ms: 10732.283\n",
      "    load_throughput: 91394.172\n",
      "    load_time_ms: 109.372\n",
      "    sample_throughput: 69.569\n",
      "    sample_time_ms: 143685.2\n",
      "    update_time_ms: 12.525\n",
      "  timestamp: 1636318175\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1589364\n",
      "  training_iteration: 159\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         23760.7</td><td style=\"text-align: right;\">1589364</td><td style=\"text-align: right;\"> 2.64047</td><td style=\"text-align: right;\">               10.53</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           94.2547</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1599360\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-52-02\n",
      "  done: false\n",
      "  episode_len_mean: 93.87735849056604\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.980000000000011\n",
      "  episode_reward_mean: 1.8694339622641554\n",
      "  episode_reward_min: -1.6800000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 17231\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.499167907747448\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012913764113949682\n",
      "          policy_loss: -0.08782014241044084\n",
      "          total_loss: 0.013898968742762367\n",
      "          vf_explained_var: 0.9110407829284668\n",
      "          vf_loss: 0.09729162003192254\n",
      "    num_agent_steps_sampled: 1599360\n",
      "    num_agent_steps_trained: 1599360\n",
      "    num_steps_sampled: 1599360\n",
      "    num_steps_trained: 1599360\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.33142857142856\n",
      "    ram_util_percent: 55.65238095238095\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575419837239041\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6903479845601\n",
      "    mean_inference_ms: 2.8651503980127018\n",
      "    mean_raw_obs_processing_ms: 2.7200319013720256\n",
      "  time_since_restore: 23907.77723789215\n",
      "  time_this_iter_s: 147.11169338226318\n",
      "  time_total_s: 23907.77723789215\n",
      "  timers:\n",
      "    learn_throughput: 931.632\n",
      "    learn_time_ms: 10729.561\n",
      "    load_throughput: 91202.697\n",
      "    load_time_ms: 109.602\n",
      "    sample_throughput: 69.662\n",
      "    sample_time_ms: 143492.289\n",
      "    update_time_ms: 12.914\n",
      "  timestamp: 1636318322\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1599360\n",
      "  training_iteration: 160\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         23907.8</td><td style=\"text-align: right;\">1599360</td><td style=\"text-align: right;\"> 1.86943</td><td style=\"text-align: right;\">                8.98</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           93.8774</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1609356\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-54-36\n",
      "  done: false\n",
      "  episode_len_mean: 92.03669724770643\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.790000000000003\n",
      "  episode_reward_mean: 2.1825688073394547\n",
      "  episode_reward_min: -1.810000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 17340\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4930569257491673\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013179955896844718\n",
      "          policy_loss: -0.08962078176550249\n",
      "          total_loss: 0.014709140023646447\n",
      "          vf_explained_var: 0.924996018409729\n",
      "          vf_loss: 0.09923490236123275\n",
      "    num_agent_steps_sampled: 1609356\n",
      "    num_agent_steps_trained: 1609356\n",
      "    num_steps_sampled: 1609356\n",
      "    num_steps_trained: 1609356\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.41278538812786\n",
      "    ram_util_percent: 55.403196347031965\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576914829230672\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6928133074427\n",
      "    mean_inference_ms: 2.864963983378465\n",
      "    mean_raw_obs_processing_ms: 2.7291312511738393\n",
      "  time_since_restore: 24061.15478014946\n",
      "  time_this_iter_s: 153.37754225730896\n",
      "  time_total_s: 24061.15478014946\n",
      "  timers:\n",
      "    learn_throughput: 931.292\n",
      "    learn_time_ms: 10733.472\n",
      "    load_throughput: 91167.396\n",
      "    load_time_ms: 109.644\n",
      "    sample_throughput: 70.07\n",
      "    sample_time_ms: 142658.157\n",
      "    update_time_ms: 14.428\n",
      "  timestamp: 1636318476\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1609356\n",
      "  training_iteration: 161\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         24061.2</td><td style=\"text-align: right;\">1609356</td><td style=\"text-align: right;\"> 2.18257</td><td style=\"text-align: right;\">                9.79</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           92.0367</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1619352\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-56-55\n",
      "  done: false\n",
      "  episode_len_mean: 92.35514018691589\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.910000000000011\n",
      "  episode_reward_mean: 2.569345794392529\n",
      "  episode_reward_min: -1.5400000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 17447\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4846686994927563\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014023711833313782\n",
      "          policy_loss: -0.08728433306703073\n",
      "          total_loss: 0.0330381511296663\n",
      "          vf_explained_var: 0.9236302971839905\n",
      "          vf_loss: 0.11322140129856192\n",
      "    num_agent_steps_sampled: 1619352\n",
      "    num_agent_steps_trained: 1619352\n",
      "    num_steps_sampled: 1619352\n",
      "    num_steps_trained: 1619352\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84472361809044\n",
      "    ram_util_percent: 55.66683417085427\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045760396959680545\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.700525561297944\n",
      "    mean_inference_ms: 2.865123164322045\n",
      "    mean_raw_obs_processing_ms: 2.7159869049584104\n",
      "  time_since_restore: 24200.4453060627\n",
      "  time_this_iter_s: 139.29052591323853\n",
      "  time_total_s: 24200.4453060627\n",
      "  timers:\n",
      "    learn_throughput: 931.376\n",
      "    learn_time_ms: 10732.507\n",
      "    load_throughput: 91182.941\n",
      "    load_time_ms: 109.626\n",
      "    sample_throughput: 70.0\n",
      "    sample_time_ms: 142800.786\n",
      "    update_time_ms: 14.669\n",
      "  timestamp: 1636318615\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1619352\n",
      "  training_iteration: 162\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         24200.4</td><td style=\"text-align: right;\">1619352</td><td style=\"text-align: right;\"> 2.56935</td><td style=\"text-align: right;\">                6.91</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           92.3551</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1629348\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_20-59-13\n",
      "  done: false\n",
      "  episode_len_mean: 92.57798165137615\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.140000000000013\n",
      "  episode_reward_mean: 2.709724770642208\n",
      "  episode_reward_min: -1.4700000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 17556\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4833494579690134\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014463564881911584\n",
      "          policy_loss: -0.08373361819574976\n",
      "          total_loss: 0.05238650601802983\n",
      "          vf_explained_var: 0.9030975699424744\n",
      "          vf_loss: 0.1280038090207829\n",
      "    num_agent_steps_sampled: 1629348\n",
      "    num_agent_steps_trained: 1629348\n",
      "    num_steps_sampled: 1629348\n",
      "    num_steps_trained: 1629348\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89030612244898\n",
      "    ram_util_percent: 55.63928571428571\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457766976241418\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.70719910700659\n",
      "    mean_inference_ms: 2.8651850291075167\n",
      "    mean_raw_obs_processing_ms: 2.7047196856217584\n",
      "  time_since_restore: 24338.129365682602\n",
      "  time_this_iter_s: 137.68405961990356\n",
      "  time_total_s: 24338.129365682602\n",
      "  timers:\n",
      "    learn_throughput: 931.276\n",
      "    learn_time_ms: 10733.663\n",
      "    load_throughput: 90978.627\n",
      "    load_time_ms: 109.872\n",
      "    sample_throughput: 70.566\n",
      "    sample_time_ms: 141654.234\n",
      "    update_time_ms: 14.807\n",
      "  timestamp: 1636318753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1629348\n",
      "  training_iteration: 163\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         24338.1</td><td style=\"text-align: right;\">1629348</td><td style=\"text-align: right;\"> 2.70972</td><td style=\"text-align: right;\">                9.14</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">            92.578</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1639344\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-02-10\n",
      "  done: false\n",
      "  episode_len_mean: 90.22522522522523\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.270000000000016\n",
      "  episode_reward_mean: 2.9801801801801866\n",
      "  episode_reward_min: -1.5700000000000007\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 17667\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4788466706235184\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013954577788268877\n",
      "          policy_loss: -0.08251342076855975\n",
      "          total_loss: 0.039585732403569496\n",
      "          vf_explained_var: 0.9387529492378235\n",
      "          vf_loss: 0.11509734574848643\n",
      "    num_agent_steps_sampled: 1639344\n",
      "    num_agent_steps_trained: 1639344\n",
      "    num_steps_sampled: 1639344\n",
      "    num_steps_trained: 1639344\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.96456692913385\n",
      "    ram_util_percent: 55.542125984251975\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577028218724938\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.69356553476308\n",
      "    mean_inference_ms: 2.8648196070105656\n",
      "    mean_raw_obs_processing_ms: 2.7378207669101013\n",
      "  time_since_restore: 24515.48794054985\n",
      "  time_this_iter_s: 177.35857486724854\n",
      "  time_total_s: 24515.48794054985\n",
      "  timers:\n",
      "    learn_throughput: 931.436\n",
      "    learn_time_ms: 10731.818\n",
      "    load_throughput: 91307.132\n",
      "    load_time_ms: 109.477\n",
      "    sample_throughput: 69.233\n",
      "    sample_time_ms: 144381.439\n",
      "    update_time_ms: 13.481\n",
      "  timestamp: 1636318930\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1639344\n",
      "  training_iteration: 164\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         24515.5</td><td style=\"text-align: right;\">1639344</td><td style=\"text-align: right;\"> 2.98018</td><td style=\"text-align: right;\">                8.27</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           90.2252</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1649340\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-04-39\n",
      "  done: false\n",
      "  episode_len_mean: 94.33018867924528\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.90000000000002\n",
      "  episode_reward_mean: 2.264622641509439\n",
      "  episode_reward_min: -1.830000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 17773\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5088911570035495\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013298022888964084\n",
      "          policy_loss: -0.08356824507857236\n",
      "          total_loss: 0.035172594488303885\n",
      "          vf_explained_var: 0.9182950854301453\n",
      "          vf_loss: 0.11353519152706633\n",
      "    num_agent_steps_sampled: 1649340\n",
      "    num_agent_steps_trained: 1649340\n",
      "    num_steps_sampled: 1649340\n",
      "    num_steps_trained: 1649340\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.59433962264151\n",
      "    ram_util_percent: 55.633962264150945\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578204936578067\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.687968433498455\n",
      "    mean_inference_ms: 2.864576617368864\n",
      "    mean_raw_obs_processing_ms: 2.7467320785620313\n",
      "  time_since_restore: 24664.533434152603\n",
      "  time_this_iter_s: 149.04549360275269\n",
      "  time_total_s: 24664.533434152603\n",
      "  timers:\n",
      "    learn_throughput: 931.956\n",
      "    learn_time_ms: 10725.826\n",
      "    load_throughput: 91259.215\n",
      "    load_time_ms: 109.534\n",
      "    sample_throughput: 69.209\n",
      "    sample_time_ms: 144432.922\n",
      "    update_time_ms: 12.344\n",
      "  timestamp: 1636319079\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1649340\n",
      "  training_iteration: 165\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         24664.5</td><td style=\"text-align: right;\">1649340</td><td style=\"text-align: right;\"> 2.26462</td><td style=\"text-align: right;\">                 8.9</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           94.3302</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1659336\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-07-16\n",
      "  done: false\n",
      "  episode_len_mean: 93.04672897196262\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.920000000000009\n",
      "  episode_reward_mean: 3.1047663551401943\n",
      "  episode_reward_min: -1.9200000000000008\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 17880\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.486359606237493\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014472812503618739\n",
      "          policy_loss: -0.08179042598582868\n",
      "          total_loss: 0.05887742303709826\n",
      "          vf_explained_var: 0.9274706244468689\n",
      "          vf_loss: 0.13256056902325178\n",
      "    num_agent_steps_sampled: 1659336\n",
      "    num_agent_steps_trained: 1659336\n",
      "    num_steps_sampled: 1659336\n",
      "    num_steps_trained: 1659336\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.16696428571429\n",
      "    ram_util_percent: 55.70312500000001\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045769204718950185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.67526740789008\n",
      "    mean_inference_ms: 2.864451038987336\n",
      "    mean_raw_obs_processing_ms: 2.7632924188493297\n",
      "  time_since_restore: 24821.573991060257\n",
      "  time_this_iter_s: 157.0405569076538\n",
      "  time_total_s: 24821.573991060257\n",
      "  timers:\n",
      "    learn_throughput: 932.077\n",
      "    learn_time_ms: 10724.435\n",
      "    load_throughput: 91146.071\n",
      "    load_time_ms: 109.67\n",
      "    sample_throughput: 69.18\n",
      "    sample_time_ms: 144492.174\n",
      "    update_time_ms: 11.808\n",
      "  timestamp: 1636319236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1659336\n",
      "  training_iteration: 166\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         24821.6</td><td style=\"text-align: right;\">1659336</td><td style=\"text-align: right;\"> 3.10477</td><td style=\"text-align: right;\">               10.92</td><td style=\"text-align: right;\">               -1.92</td><td style=\"text-align: right;\">           93.0467</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1669332\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-09-44\n",
      "  done: false\n",
      "  episode_len_mean: 92.6822429906542\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000018\n",
      "  episode_reward_mean: 2.570093457943932\n",
      "  episode_reward_min: -1.6800000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 17987\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.486037085810278\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013299104922459296\n",
      "          policy_loss: -0.08553980101600417\n",
      "          total_loss: 0.02961656991392374\n",
      "          vf_explained_var: 0.9282262325286865\n",
      "          vf_loss: 0.10971971694220845\n",
      "    num_agent_steps_sampled: 1669332\n",
      "    num_agent_steps_trained: 1669332\n",
      "    num_steps_sampled: 1669332\n",
      "    num_steps_trained: 1669332\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.46066350710899\n",
      "    ram_util_percent: 55.59620853080568\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574397860695658\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.67269538629173\n",
      "    mean_inference_ms: 2.864228516788554\n",
      "    mean_raw_obs_processing_ms: 2.7677355970274693\n",
      "  time_since_restore: 24969.577520608902\n",
      "  time_this_iter_s: 148.00352954864502\n",
      "  time_total_s: 24969.577520608902\n",
      "  timers:\n",
      "    learn_throughput: 931.909\n",
      "    learn_time_ms: 10726.373\n",
      "    load_throughput: 90870.293\n",
      "    load_time_ms: 110.003\n",
      "    sample_throughput: 71.157\n",
      "    sample_time_ms: 140477.879\n",
      "    update_time_ms: 13.043\n",
      "  timestamp: 1636319384\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1669332\n",
      "  training_iteration: 167\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         24969.6</td><td style=\"text-align: right;\">1669332</td><td style=\"text-align: right;\"> 2.57009</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           92.6822</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1679328\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-12-04\n",
      "  done: false\n",
      "  episode_len_mean: 93.00925925925925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.990000000000011\n",
      "  episode_reward_mean: 2.2958333333333383\n",
      "  episode_reward_min: -1.6200000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 18095\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.493429479435978\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013355876216310946\n",
      "          policy_loss: -0.08454160479048634\n",
      "          total_loss: 0.02791673527377793\n",
      "          vf_explained_var: 0.9333418607711792\n",
      "          vf_loss: 0.10696627735279692\n",
      "    num_agent_steps_sampled: 1679328\n",
      "    num_agent_steps_trained: 1679328\n",
      "    num_steps_sampled: 1679328\n",
      "    num_steps_trained: 1679328\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.02150000000002\n",
      "    ram_util_percent: 55.571\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045754366583276106\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.68283637998499\n",
      "    mean_inference_ms: 2.864383445966552\n",
      "    mean_raw_obs_processing_ms: 2.7570046540908817\n",
      "  time_since_restore: 25109.611332416534\n",
      "  time_this_iter_s: 140.03381180763245\n",
      "  time_total_s: 25109.611332416534\n",
      "  timers:\n",
      "    learn_throughput: 931.706\n",
      "    learn_time_ms: 10728.709\n",
      "    load_throughput: 90869.485\n",
      "    load_time_ms: 110.004\n",
      "    sample_throughput: 71.802\n",
      "    sample_time_ms: 139216.208\n",
      "    update_time_ms: 12.656\n",
      "  timestamp: 1636319524\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1679328\n",
      "  training_iteration: 168\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         25109.6</td><td style=\"text-align: right;\">1679328</td><td style=\"text-align: right;\"> 2.29583</td><td style=\"text-align: right;\">                6.99</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">           93.0093</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1689324\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-14-34\n",
      "  done: false\n",
      "  episode_len_mean: 95.11428571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.790000000000012\n",
      "  episode_reward_mean: 2.551619047619054\n",
      "  episode_reward_min: -1.2900000000000005\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 18200\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4857177204555936\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013899246683043402\n",
      "          policy_loss: -0.08370506766164659\n",
      "          total_loss: 0.04731809511924019\n",
      "          vf_explained_var: 0.916820228099823\n",
      "          vf_loss: 0.12421611771783513\n",
      "    num_agent_steps_sampled: 1689324\n",
      "    num_agent_steps_trained: 1689324\n",
      "    num_steps_sampled: 1689324\n",
      "    num_steps_trained: 1689324\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.29018691588784\n",
      "    ram_util_percent: 55.664485981308395\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045751500243466456\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.68047776389298\n",
      "    mean_inference_ms: 2.864369767274545\n",
      "    mean_raw_obs_processing_ms: 2.7553025307647854\n",
      "  time_since_restore: 25259.527307510376\n",
      "  time_this_iter_s: 149.91597509384155\n",
      "  time_total_s: 25259.527307510376\n",
      "  timers:\n",
      "    learn_throughput: 931.708\n",
      "    learn_time_ms: 10728.689\n",
      "    load_throughput: 90592.068\n",
      "    load_time_ms: 110.341\n",
      "    sample_throughput: 71.903\n",
      "    sample_time_ms: 139020.332\n",
      "    update_time_ms: 13.323\n",
      "  timestamp: 1636319674\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1689324\n",
      "  training_iteration: 169\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         25259.5</td><td style=\"text-align: right;\">1689324</td><td style=\"text-align: right;\"> 2.55162</td><td style=\"text-align: right;\">                8.79</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           95.1143</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1699320\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-17-05\n",
      "  done: false\n",
      "  episode_len_mean: 94.06603773584905\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.800000000000015\n",
      "  episode_reward_mean: 2.7833018867924597\n",
      "  episode_reward_min: -2.190000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 18306\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4752386747262416\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013857001297918703\n",
      "          policy_loss: -0.08190970837703755\n",
      "          total_loss: 0.0506371114960211\n",
      "          vf_explained_var: 0.9190250039100647\n",
      "          vf_loss: 0.1257312230296178\n",
      "    num_agent_steps_sampled: 1699320\n",
      "    num_agent_steps_trained: 1699320\n",
      "    num_steps_sampled: 1699320\n",
      "    num_steps_trained: 1699320\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.56697674418605\n",
      "    ram_util_percent: 55.65302325581394\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575557083913266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.68397825095511\n",
      "    mean_inference_ms: 2.864522975989916\n",
      "    mean_raw_obs_processing_ms: 2.7517136640032405\n",
      "  time_since_restore: 25410.192055940628\n",
      "  time_this_iter_s: 150.66474843025208\n",
      "  time_total_s: 25410.192055940628\n",
      "  timers:\n",
      "    learn_throughput: 931.63\n",
      "    learn_time_ms: 10729.585\n",
      "    load_throughput: 90617.934\n",
      "    load_time_ms: 110.309\n",
      "    sample_throughput: 71.721\n",
      "    sample_time_ms: 139374.24\n",
      "    update_time_ms: 13.769\n",
      "  timestamp: 1636319825\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1699320\n",
      "  training_iteration: 170\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         25410.2</td><td style=\"text-align: right;\">1699320</td><td style=\"text-align: right;\">  2.7833</td><td style=\"text-align: right;\">                10.8</td><td style=\"text-align: right;\">               -2.19</td><td style=\"text-align: right;\">            94.066</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1709316\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-19-34\n",
      "  done: false\n",
      "  episode_len_mean: 94.61320754716981\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.010000000000014\n",
      "  episode_reward_mean: 2.913490566037743\n",
      "  episode_reward_min: -1.4200000000000006\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 18412\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4938581140632303\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013303552829098607\n",
      "          policy_loss: -0.08260646380611464\n",
      "          total_loss: 0.03762702969277007\n",
      "          vf_explained_var: 0.9238666296005249\n",
      "          vf_loss: 0.11486491666804267\n",
      "    num_agent_steps_sampled: 1709316\n",
      "    num_agent_steps_trained: 1709316\n",
      "    num_steps_sampled: 1709316\n",
      "    num_steps_trained: 1709316\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.80281690140845\n",
      "    ram_util_percent: 55.47464788732394\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045771363980561086\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.685775976077196\n",
      "    mean_inference_ms: 2.864373654462036\n",
      "    mean_raw_obs_processing_ms: 2.751749163569171\n",
      "  time_since_restore: 25559.480701446533\n",
      "  time_this_iter_s: 149.28864550590515\n",
      "  time_total_s: 25559.480701446533\n",
      "  timers:\n",
      "    learn_throughput: 931.665\n",
      "    learn_time_ms: 10729.183\n",
      "    load_throughput: 90285.007\n",
      "    load_time_ms: 110.716\n",
      "    sample_throughput: 71.931\n",
      "    sample_time_ms: 138966.644\n",
      "    update_time_ms: 12.794\n",
      "  timestamp: 1636319974\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1709316\n",
      "  training_iteration: 171\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         25559.5</td><td style=\"text-align: right;\">1709316</td><td style=\"text-align: right;\"> 2.91349</td><td style=\"text-align: right;\">                9.01</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           94.6132</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1719312\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-22-13\n",
      "  done: false\n",
      "  episode_len_mean: 93.90566037735849\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.510000000000018\n",
      "  episode_reward_mean: 2.494716981132081\n",
      "  episode_reward_min: -1.8800000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 18518\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.491127127663702\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012997578199604905\n",
      "          policy_loss: -0.0838358285303554\n",
      "          total_loss: 0.038345688320377956\n",
      "          vf_explained_var: 0.911868155002594\n",
      "          vf_loss: 0.11748267979735239\n",
      "    num_agent_steps_sampled: 1719312\n",
      "    num_agent_steps_trained: 1719312\n",
      "    num_steps_sampled: 1719312\n",
      "    num_steps_trained: 1719312\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.49691629955949\n",
      "    ram_util_percent: 55.62158590308369\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576175784550521\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.675351593866736\n",
      "    mean_inference_ms: 2.8640783742323106\n",
      "    mean_raw_obs_processing_ms: 2.7700777135299153\n",
      "  time_since_restore: 25718.117990255356\n",
      "  time_this_iter_s: 158.63728880882263\n",
      "  time_total_s: 25718.117990255356\n",
      "  timers:\n",
      "    learn_throughput: 931.55\n",
      "    learn_time_ms: 10730.508\n",
      "    load_throughput: 90259.74\n",
      "    load_time_ms: 110.747\n",
      "    sample_throughput: 70.944\n",
      "    sample_time_ms: 140900.658\n",
      "    update_time_ms: 12.252\n",
      "  timestamp: 1636320133\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1719312\n",
      "  training_iteration: 172\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         25718.1</td><td style=\"text-align: right;\">1719312</td><td style=\"text-align: right;\"> 2.49472</td><td style=\"text-align: right;\">               12.51</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           93.9057</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1729308\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-24-52\n",
      "  done: false\n",
      "  episode_len_mean: 94.23584905660377\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.550000000000015\n",
      "  episode_reward_mean: 2.16462264150944\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 18624\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5054053553149234\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012531929930903192\n",
      "          policy_loss: -0.08476313841807791\n",
      "          total_loss: 0.019460496987001252\n",
      "          vf_explained_var: 0.9213221073150635\n",
      "          vf_loss: 0.10072838632453583\n",
      "    num_agent_steps_sampled: 1729308\n",
      "    num_agent_steps_trained: 1729308\n",
      "    num_steps_sampled: 1729308\n",
      "    num_steps_trained: 1729308\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.55265486725665\n",
      "    ram_util_percent: 55.70840707964603\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045750908601676556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.661244006957695\n",
      "    mean_inference_ms: 2.8639789961736244\n",
      "    mean_raw_obs_processing_ms: 2.7779372772718083\n",
      "  time_since_restore: 25876.598753213882\n",
      "  time_this_iter_s: 158.4807629585266\n",
      "  time_total_s: 25876.598753213882\n",
      "  timers:\n",
      "    learn_throughput: 931.507\n",
      "    learn_time_ms: 10730.993\n",
      "    load_throughput: 90367.946\n",
      "    load_time_ms: 110.614\n",
      "    sample_throughput: 69.912\n",
      "    sample_time_ms: 142980.353\n",
      "    update_time_ms: 11.782\n",
      "  timestamp: 1636320292\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1729308\n",
      "  training_iteration: 173\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         25876.6</td><td style=\"text-align: right;\">1729308</td><td style=\"text-align: right;\"> 2.16462</td><td style=\"text-align: right;\">                8.55</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           94.2358</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1739304\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-27-09\n",
      "  done: false\n",
      "  episode_len_mean: 95.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.310000000000018\n",
      "  episode_reward_mean: 2.4759047619047676\n",
      "  episode_reward_min: -1.7500000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 18729\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.496442183877668\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013701890332941034\n",
      "          policy_loss: -0.08445279306262476\n",
      "          total_loss: 0.03757826785246531\n",
      "          vf_explained_var: 0.9124161005020142\n",
      "          vf_loss: 0.11578086371589293\n",
      "    num_agent_steps_sampled: 1739304\n",
      "    num_agent_steps_trained: 1739304\n",
      "    num_steps_sampled: 1739304\n",
      "    num_steps_trained: 1739304\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90051020408163\n",
      "    ram_util_percent: 55.652040816326526\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045759542929599245\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.66522431993048\n",
      "    mean_inference_ms: 2.8639931545642625\n",
      "    mean_raw_obs_processing_ms: 2.7657406248568916\n",
      "  time_since_restore: 26013.767728567123\n",
      "  time_this_iter_s: 137.16897535324097\n",
      "  time_total_s: 26013.767728567123\n",
      "  timers:\n",
      "    learn_throughput: 931.506\n",
      "    learn_time_ms: 10731.005\n",
      "    load_throughput: 90347.324\n",
      "    load_time_ms: 110.64\n",
      "    sample_throughput: 71.934\n",
      "    sample_time_ms: 138960.813\n",
      "    update_time_ms: 11.97\n",
      "  timestamp: 1636320429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1739304\n",
      "  training_iteration: 174\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">         26013.8</td><td style=\"text-align: right;\">1739304</td><td style=\"text-align: right;\">  2.4759</td><td style=\"text-align: right;\">               12.31</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">              95.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1749300\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-29-38\n",
      "  done: false\n",
      "  episode_len_mean: 94.5754716981132\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.920000000000016\n",
      "  episode_reward_mean: 2.405000000000006\n",
      "  episode_reward_min: -1.770000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 18835\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.497209001198793\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012401346041311077\n",
      "          policy_loss: -0.08944979542468348\n",
      "          total_loss: 0.0033139200053281252\n",
      "          vf_explained_var: 0.9298809170722961\n",
      "          vf_loss: 0.08948398683076868\n",
      "    num_agent_steps_sampled: 1749300\n",
      "    num_agent_steps_trained: 1749300\n",
      "    num_steps_sampled: 1749300\n",
      "    num_steps_trained: 1749300\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.72877358490567\n",
      "    ram_util_percent: 55.548113207547175\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578050490300936\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.66340157821462\n",
      "    mean_inference_ms: 2.8641990126302153\n",
      "    mean_raw_obs_processing_ms: 2.7666068499933787\n",
      "  time_since_restore: 26162.625004529953\n",
      "  time_this_iter_s: 148.8572759628296\n",
      "  time_total_s: 26162.625004529953\n",
      "  timers:\n",
      "    learn_throughput: 931.505\n",
      "    learn_time_ms: 10731.019\n",
      "    load_throughput: 90300.758\n",
      "    load_time_ms: 110.697\n",
      "    sample_throughput: 71.944\n",
      "    sample_time_ms: 138941.766\n",
      "    update_time_ms: 12.018\n",
      "  timestamp: 1636320578\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1749300\n",
      "  training_iteration: 175\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         26162.6</td><td style=\"text-align: right;\">1749300</td><td style=\"text-align: right;\">   2.405</td><td style=\"text-align: right;\">                8.92</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           94.5755</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1759296\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-32-19\n",
      "  done: false\n",
      "  episode_len_mean: 95.26666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.750000000000007\n",
      "  episode_reward_mean: 2.6709523809523867\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 18940\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5009829095286182\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014246555622618656\n",
      "          policy_loss: -0.08409645569184397\n",
      "          total_loss: 0.06032980394302907\n",
      "          vf_explained_var: 0.9122642874717712\n",
      "          vf_loss: 0.1369806547418364\n",
      "    num_agent_steps_sampled: 1759296\n",
      "    num_agent_steps_trained: 1759296\n",
      "    num_steps_sampled: 1759296\n",
      "    num_steps_trained: 1759296\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.71565217391304\n",
      "    ram_util_percent: 55.54130434782608\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576473301013884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.65711537608029\n",
      "    mean_inference_ms: 2.8639460911320853\n",
      "    mean_raw_obs_processing_ms: 2.772679438886769\n",
      "  time_since_restore: 26323.71077299118\n",
      "  time_this_iter_s: 161.08576846122742\n",
      "  time_total_s: 26323.71077299118\n",
      "  timers:\n",
      "    learn_throughput: 931.367\n",
      "    learn_time_ms: 10732.615\n",
      "    load_throughput: 90231.437\n",
      "    load_time_ms: 110.782\n",
      "    sample_throughput: 71.736\n",
      "    sample_time_ms: 139343.78\n",
      "    update_time_ms: 12.572\n",
      "  timestamp: 1636320739\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1759296\n",
      "  training_iteration: 176\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         26323.7</td><td style=\"text-align: right;\">1759296</td><td style=\"text-align: right;\"> 2.67095</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           95.2667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1769292\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-35-40\n",
      "  done: false\n",
      "  episode_len_mean: 92.83333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.410000000000013\n",
      "  episode_reward_mean: 2.4714814814814865\n",
      "  episode_reward_min: -1.7700000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 19048\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5049342055606028\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013253675265920186\n",
      "          policy_loss: -0.08043152732758695\n",
      "          total_loss: 0.04346637849926821\n",
      "          vf_explained_var: 0.9096168279647827\n",
      "          vf_loss: 0.1187537181055826\n",
      "    num_agent_steps_sampled: 1769292\n",
      "    num_agent_steps_trained: 1769292\n",
      "    num_steps_sampled: 1769292\n",
      "    num_steps_trained: 1769292\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.6574912891986\n",
      "    ram_util_percent: 55.77038327526131\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575540009199931\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.633631565725004\n",
      "    mean_inference_ms: 2.863614529440239\n",
      "    mean_raw_obs_processing_ms: 2.8101496937020536\n",
      "  time_since_restore: 26524.567566156387\n",
      "  time_this_iter_s: 200.8567931652069\n",
      "  time_total_s: 26524.567566156387\n",
      "  timers:\n",
      "    learn_throughput: 931.267\n",
      "    learn_time_ms: 10733.765\n",
      "    load_throughput: 90153.226\n",
      "    load_time_ms: 110.878\n",
      "    sample_throughput: 69.115\n",
      "    sample_time_ms: 144628.275\n",
      "    update_time_ms: 12.539\n",
      "  timestamp: 1636320940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1769292\n",
      "  training_iteration: 177\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         26524.6</td><td style=\"text-align: right;\">1769292</td><td style=\"text-align: right;\"> 2.47148</td><td style=\"text-align: right;\">               10.41</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           92.8333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1779288\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-38-07\n",
      "  done: false\n",
      "  episode_len_mean: 94.82075471698113\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.850000000000014\n",
      "  episode_reward_mean: 2.5637735849056673\n",
      "  episode_reward_min: -1.9900000000000009\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 19154\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.497721405314584\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01336934220276464\n",
      "          policy_loss: -0.08569312230325662\n",
      "          total_loss: 0.04093616109771224\n",
      "          vf_explained_var: 0.9175637364387512\n",
      "          vf_loss: 0.12114946283400059\n",
      "    num_agent_steps_sampled: 1779288\n",
      "    num_agent_steps_trained: 1779288\n",
      "    num_steps_sampled: 1779288\n",
      "    num_steps_trained: 1779288\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.63000000000001\n",
      "    ram_util_percent: 55.67095238095238\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457344935328521\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6276946175151\n",
      "    mean_inference_ms: 2.8636614338378577\n",
      "    mean_raw_obs_processing_ms: 2.8073897841754274\n",
      "  time_since_restore: 26671.96392226219\n",
      "  time_this_iter_s: 147.39635610580444\n",
      "  time_total_s: 26671.96392226219\n",
      "  timers:\n",
      "    learn_throughput: 931.264\n",
      "    learn_time_ms: 10733.804\n",
      "    load_throughput: 90311.32\n",
      "    load_time_ms: 110.684\n",
      "    sample_throughput: 68.765\n",
      "    sample_time_ms: 145365.282\n",
      "    update_time_ms: 11.77\n",
      "  timestamp: 1636321087\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1779288\n",
      "  training_iteration: 178\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">           26672</td><td style=\"text-align: right;\">1779288</td><td style=\"text-align: right;\"> 2.56377</td><td style=\"text-align: right;\">                8.85</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           94.8208</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1789284\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-40-52\n",
      "  done: false\n",
      "  episode_len_mean: 92.22429906542057\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000013\n",
      "  episode_reward_mean: 2.3332710280373883\n",
      "  episode_reward_min: -1.7700000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 19261\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4998962671328813\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013103294923987846\n",
      "          policy_loss: -0.08159870983173068\n",
      "          total_loss: 0.031305365673162874\n",
      "          vf_explained_var: 0.9058298468589783\n",
      "          vf_loss: 0.10805209430141581\n",
      "    num_agent_steps_sampled: 1789284\n",
      "    num_agent_steps_trained: 1789284\n",
      "    num_steps_sampled: 1789284\n",
      "    num_steps_trained: 1789284\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.06991525423729\n",
      "    ram_util_percent: 55.67966101694914\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045752541723927516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.62871533041394\n",
      "    mean_inference_ms: 2.8635486205273075\n",
      "    mean_raw_obs_processing_ms: 2.8155817607660643\n",
      "  time_since_restore: 26837.163452625275\n",
      "  time_this_iter_s: 165.19953036308289\n",
      "  time_total_s: 26837.163452625275\n",
      "  timers:\n",
      "    learn_throughput: 931.281\n",
      "    learn_time_ms: 10733.601\n",
      "    load_throughput: 90112.555\n",
      "    load_time_ms: 110.928\n",
      "    sample_throughput: 68.049\n",
      "    sample_time_ms: 146894.609\n",
      "    update_time_ms: 10.644\n",
      "  timestamp: 1636321252\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1789284\n",
      "  training_iteration: 179\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         26837.2</td><td style=\"text-align: right;\">1789284</td><td style=\"text-align: right;\"> 2.33327</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           92.2243</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1799280\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-43-26\n",
      "  done: false\n",
      "  episode_len_mean: 93.86915887850468\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.360000000000019\n",
      "  episode_reward_mean: 2.6966355140186975\n",
      "  episode_reward_min: -2.0699999999999994\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 19368\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4980415060988856\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012931673592034513\n",
      "          policy_loss: -0.08210908189479611\n",
      "          total_loss: 0.048171719099180055\n",
      "          vf_explained_var: 0.9185910224914551\n",
      "          vf_loss: 0.12580124679475257\n",
      "    num_agent_steps_sampled: 1799280\n",
      "    num_agent_steps_trained: 1799280\n",
      "    num_steps_sampled: 1799280\n",
      "    num_steps_trained: 1799280\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.70779816513763\n",
      "    ram_util_percent: 55.61009174311926\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457696142585646\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.630165442984094\n",
      "    mean_inference_ms: 2.8634627712909286\n",
      "    mean_raw_obs_processing_ms: 2.823198804828838\n",
      "  time_since_restore: 26990.42547726631\n",
      "  time_this_iter_s: 153.262024641037\n",
      "  time_total_s: 26990.42547726631\n",
      "  timers:\n",
      "    learn_throughput: 930.365\n",
      "    learn_time_ms: 10744.175\n",
      "    load_throughput: 90268.076\n",
      "    load_time_ms: 110.737\n",
      "    sample_throughput: 67.933\n",
      "    sample_time_ms: 147144.469\n",
      "    update_time_ms: 9.905\n",
      "  timestamp: 1636321406\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1799280\n",
      "  training_iteration: 180\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         26990.4</td><td style=\"text-align: right;\">1799280</td><td style=\"text-align: right;\"> 2.69664</td><td style=\"text-align: right;\">               12.36</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           93.8692</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1809276\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-45-58\n",
      "  done: false\n",
      "  episode_len_mean: 92.62037037037037\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.730000000000004\n",
      "  episode_reward_mean: 2.27694444444445\n",
      "  episode_reward_min: -1.850000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 19476\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4965605517737885\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013242299555575677\n",
      "          policy_loss: -0.08351266875258113\n",
      "          total_loss: 0.03198098014626238\n",
      "          vf_explained_var: 0.9281731247901917\n",
      "          vf_loss: 0.11029163941374828\n",
      "    num_agent_steps_sampled: 1809276\n",
      "    num_agent_steps_trained: 1809276\n",
      "    num_steps_sampled: 1809276\n",
      "    num_steps_trained: 1809276\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.5594470046083\n",
      "    ram_util_percent: 55.683410138248846\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457480152279602\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.631600158724\n",
      "    mean_inference_ms: 2.863159305594417\n",
      "    mean_raw_obs_processing_ms: 2.81926066775895\n",
      "  time_since_restore: 27142.228836774826\n",
      "  time_this_iter_s: 151.8033595085144\n",
      "  time_total_s: 27142.228836774826\n",
      "  timers:\n",
      "    learn_throughput: 930.324\n",
      "    learn_time_ms: 10744.648\n",
      "    load_throughput: 90413.742\n",
      "    load_time_ms: 110.558\n",
      "    sample_throughput: 67.818\n",
      "    sample_time_ms: 147395.136\n",
      "    update_time_ms: 9.896\n",
      "  timestamp: 1636321558\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1809276\n",
      "  training_iteration: 181\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         27142.2</td><td style=\"text-align: right;\">1809276</td><td style=\"text-align: right;\"> 2.27694</td><td style=\"text-align: right;\">                9.73</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           92.6204</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1819272\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-48-50\n",
      "  done: false\n",
      "  episode_len_mean: 92.68518518518519\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.510000000000014\n",
      "  episode_reward_mean: 2.3831481481481527\n",
      "  episode_reward_min: -1.7500000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 19584\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4994335684001956\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012983884315811203\n",
      "          policy_loss: -0.08197500161094289\n",
      "          total_loss: 0.04365232595935082\n",
      "          vf_explained_var: 0.9064947962760925\n",
      "          vf_loss: 0.1210427506126336\n",
      "    num_agent_steps_sampled: 1819272\n",
      "    num_agent_steps_trained: 1819272\n",
      "    num_steps_sampled: 1819272\n",
      "    num_steps_trained: 1819272\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.85447154471545\n",
      "    ram_util_percent: 55.62357723577235\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576568835665942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.63367533089129\n",
      "    mean_inference_ms: 2.863525896886114\n",
      "    mean_raw_obs_processing_ms: 2.8286717331751885\n",
      "  time_since_restore: 27314.876193523407\n",
      "  time_this_iter_s: 172.64735674858093\n",
      "  time_total_s: 27314.876193523407\n",
      "  timers:\n",
      "    learn_throughput: 930.355\n",
      "    learn_time_ms: 10744.291\n",
      "    load_throughput: 90425.364\n",
      "    load_time_ms: 110.544\n",
      "    sample_throughput: 67.179\n",
      "    sample_time_ms: 148795.64\n",
      "    update_time_ms: 10.418\n",
      "  timestamp: 1636321730\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1819272\n",
      "  training_iteration: 182\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         27314.9</td><td style=\"text-align: right;\">1819272</td><td style=\"text-align: right;\"> 2.38315</td><td style=\"text-align: right;\">               12.51</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           92.6852</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1829268\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-51-05\n",
      "  done: false\n",
      "  episode_len_mean: 92.92592592592592\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 2.6925000000000066\n",
      "  episode_reward_min: -1.7600000000000011\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 19692\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4823880929213304\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013765939347947618\n",
      "          policy_loss: -0.0804736979624145\n",
      "          total_loss: 0.05068903497269011\n",
      "          vf_explained_var: 0.9318801760673523\n",
      "          vf_loss: 0.12462608156025283\n",
      "    num_agent_steps_sampled: 1829268\n",
      "    num_agent_steps_trained: 1829268\n",
      "    num_steps_sampled: 1829268\n",
      "    num_steps_trained: 1829268\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96113989637306\n",
      "    ram_util_percent: 55.56580310880828\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575229022860884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.63714358501141\n",
      "    mean_inference_ms: 2.863386929628289\n",
      "    mean_raw_obs_processing_ms: 2.815405670337467\n",
      "  time_since_restore: 27450.03183245659\n",
      "  time_this_iter_s: 135.15563893318176\n",
      "  time_total_s: 27450.03183245659\n",
      "  timers:\n",
      "    learn_throughput: 929.953\n",
      "    learn_time_ms: 10748.926\n",
      "    load_throughput: 90322.624\n",
      "    load_time_ms: 110.67\n",
      "    sample_throughput: 68.251\n",
      "    sample_time_ms: 146458.466\n",
      "    update_time_ms: 10.427\n",
      "  timestamp: 1636321865\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1829268\n",
      "  training_iteration: 183\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">           27450</td><td style=\"text-align: right;\">1829268</td><td style=\"text-align: right;\">  2.6925</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           92.9259</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1839264\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-53-35\n",
      "  done: false\n",
      "  episode_len_mean: 91.50925925925925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.960000000000013\n",
      "  episode_reward_mean: 2.3322222222222275\n",
      "  episode_reward_min: -1.97\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 19800\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.478398217706599\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014325292298760669\n",
      "          policy_loss: -0.08288297479351361\n",
      "          total_loss: 0.0658843132476203\n",
      "          vf_explained_var: 0.9184994697570801\n",
      "          vf_loss: 0.14091646270587657\n",
      "    num_agent_steps_sampled: 1839264\n",
      "    num_agent_steps_trained: 1839264\n",
      "    num_steps_sampled: 1839264\n",
      "    num_steps_trained: 1839264\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.83644859813084\n",
      "    ram_util_percent: 55.564953271028045\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045790923131410595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.63678758161797\n",
      "    mean_inference_ms: 2.863536507607039\n",
      "    mean_raw_obs_processing_ms: 2.8244834605233304\n",
      "  time_since_restore: 27599.79137992859\n",
      "  time_this_iter_s: 149.75954747200012\n",
      "  time_total_s: 27599.79137992859\n",
      "  timers:\n",
      "    learn_throughput: 929.955\n",
      "    learn_time_ms: 10748.911\n",
      "    load_throughput: 90431.489\n",
      "    load_time_ms: 110.537\n",
      "    sample_throughput: 67.67\n",
      "    sample_time_ms: 147717.58\n",
      "    update_time_ms: 10.968\n",
      "  timestamp: 1636322015\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1839264\n",
      "  training_iteration: 184\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">         27599.8</td><td style=\"text-align: right;\">1839264</td><td style=\"text-align: right;\"> 2.33222</td><td style=\"text-align: right;\">                8.96</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           91.5093</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1849260\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-56-04\n",
      "  done: false\n",
      "  episode_len_mean: 94.13207547169812\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.120000000000017\n",
      "  episode_reward_mean: 2.9200943396226484\n",
      "  episode_reward_min: -1.5400000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 19906\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.48120036369715\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013362941080297898\n",
      "          policy_loss: -0.07989111063189995\n",
      "          total_loss: 0.05719672395155216\n",
      "          vf_explained_var: 0.923953652381897\n",
      "          vf_loss: 0.13145738732165252\n",
      "    num_agent_steps_sampled: 1849260\n",
      "    num_agent_steps_trained: 1849260\n",
      "    num_steps_sampled: 1849260\n",
      "    num_steps_trained: 1849260\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.6244131455399\n",
      "    ram_util_percent: 55.56103286384975\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045794231719748384\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.63714126370139\n",
      "    mean_inference_ms: 2.863374450551275\n",
      "    mean_raw_obs_processing_ms: 2.8217094180923157\n",
      "  time_since_restore: 27748.829203128815\n",
      "  time_this_iter_s: 149.03782320022583\n",
      "  time_total_s: 27748.829203128815\n",
      "  timers:\n",
      "    learn_throughput: 929.802\n",
      "    learn_time_ms: 10750.678\n",
      "    load_throughput: 90495.922\n",
      "    load_time_ms: 110.458\n",
      "    sample_throughput: 67.663\n",
      "    sample_time_ms: 147732.921\n",
      "    update_time_ms: 11.775\n",
      "  timestamp: 1636322164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1849260\n",
      "  training_iteration: 185\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         27748.8</td><td style=\"text-align: right;\">1849260</td><td style=\"text-align: right;\"> 2.92009</td><td style=\"text-align: right;\">               10.12</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           94.1321</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1859256\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_21-58-53\n",
      "  done: false\n",
      "  episode_len_mean: 91.97272727272727\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.810000000000002\n",
      "  episode_reward_mean: 2.463636363636369\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 20016\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4869230885790965\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013659398920073595\n",
      "          policy_loss: -0.08259317028200906\n",
      "          total_loss: 0.04225643621996427\n",
      "          vf_explained_var: 0.9240238666534424\n",
      "          vf_loss: 0.11860101799456738\n",
      "    num_agent_steps_sampled: 1859256\n",
      "    num_agent_steps_trained: 1859256\n",
      "    num_steps_sampled: 1859256\n",
      "    num_steps_trained: 1859256\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.7475\n",
      "    ram_util_percent: 55.62166666666666\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045779531808325204\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.635499890522176\n",
      "    mean_inference_ms: 2.8630225641342744\n",
      "    mean_raw_obs_processing_ms: 2.837570960025783\n",
      "  time_since_restore: 27917.203766822815\n",
      "  time_this_iter_s: 168.37456369400024\n",
      "  time_total_s: 27917.203766822815\n",
      "  timers:\n",
      "    learn_throughput: 930.073\n",
      "    learn_time_ms: 10747.544\n",
      "    load_throughput: 90943.006\n",
      "    load_time_ms: 109.915\n",
      "    sample_throughput: 67.329\n",
      "    sample_time_ms: 148465.644\n",
      "    update_time_ms: 11.97\n",
      "  timestamp: 1636322333\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1859256\n",
      "  training_iteration: 186\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         27917.2</td><td style=\"text-align: right;\">1859256</td><td style=\"text-align: right;\"> 2.46364</td><td style=\"text-align: right;\">                9.81</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           91.9727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1869252\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-01-09\n",
      "  done: false\n",
      "  episode_len_mean: 93.23584905660377\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.780000000000014\n",
      "  episode_reward_mean: 2.4973584905660435\n",
      "  episode_reward_min: -1.6900000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 20122\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.478222561493898\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01349381159703376\n",
      "          policy_loss: -0.0814872259282085\n",
      "          total_loss: 0.03785077033277887\n",
      "          vf_explained_var: 0.9361218810081482\n",
      "          vf_loss: 0.11337963186729795\n",
      "    num_agent_steps_sampled: 1869252\n",
      "    num_agent_steps_trained: 1869252\n",
      "    num_steps_sampled: 1869252\n",
      "    num_steps_trained: 1869252\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14512820512822\n",
      "    ram_util_percent: 55.59897435897435\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577768525972555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.64014256819119\n",
      "    mean_inference_ms: 2.8632719271959566\n",
      "    mean_raw_obs_processing_ms: 2.8265125253138983\n",
      "  time_since_restore: 28053.840095043182\n",
      "  time_this_iter_s: 136.63632822036743\n",
      "  time_total_s: 28053.840095043182\n",
      "  timers:\n",
      "    learn_throughput: 929.854\n",
      "    learn_time_ms: 10750.076\n",
      "    load_throughput: 91139.73\n",
      "    load_time_ms: 109.678\n",
      "    sample_throughput: 70.373\n",
      "    sample_time_ms: 142042.314\n",
      "    update_time_ms: 11.031\n",
      "  timestamp: 1636322469\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1869252\n",
      "  training_iteration: 187\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         28053.8</td><td style=\"text-align: right;\">1869252</td><td style=\"text-align: right;\"> 2.49736</td><td style=\"text-align: right;\">                8.78</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           93.2358</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1879248\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-03-28\n",
      "  done: false\n",
      "  episode_len_mean: 92.91666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.750000000000018\n",
      "  episode_reward_mean: 2.3060185185185245\n",
      "  episode_reward_min: -1.6400000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 20230\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.490180923999884\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014074030814375391\n",
      "          policy_loss: -0.08216667233401129\n",
      "          total_loss: 0.04854108222051818\n",
      "          vf_explained_var: 0.9192240834236145\n",
      "          vf_loss: 0.12354716164036057\n",
      "    num_agent_steps_sampled: 1879248\n",
      "    num_agent_steps_trained: 1879248\n",
      "    num_steps_sampled: 1879248\n",
      "    num_steps_trained: 1879248\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99393939393941\n",
      "    ram_util_percent: 55.58838383838385\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577279165783358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6481386234451\n",
      "    mean_inference_ms: 2.8633344871386073\n",
      "    mean_raw_obs_processing_ms: 2.814833708135436\n",
      "  time_since_restore: 28192.90435743332\n",
      "  time_this_iter_s: 139.06426239013672\n",
      "  time_total_s: 28192.90435743332\n",
      "  timers:\n",
      "    learn_throughput: 929.146\n",
      "    learn_time_ms: 10758.269\n",
      "    load_throughput: 91121.982\n",
      "    load_time_ms: 109.699\n",
      "    sample_throughput: 70.793\n",
      "    sample_time_ms: 141200.325\n",
      "    update_time_ms: 11.7\n",
      "  timestamp: 1636322608\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1879248\n",
      "  training_iteration: 188\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">         28192.9</td><td style=\"text-align: right;\">1879248</td><td style=\"text-align: right;\"> 2.30602</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           92.9167</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1889244\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-06-13\n",
      "  done: false\n",
      "  episode_len_mean: 92.97196261682242\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.830000000000016\n",
      "  episode_reward_mean: 1.9543925233644914\n",
      "  episode_reward_min: -2.15\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 20337\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4875909611710116\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01322862519366267\n",
      "          policy_loss: -0.07967934562291346\n",
      "          total_loss: 0.04060463142286763\n",
      "          vf_explained_var: 0.9192461967468262\n",
      "          vf_loss: 0.11502342146590479\n",
      "    num_agent_steps_sampled: 1889244\n",
      "    num_agent_steps_trained: 1889244\n",
      "    num_steps_sampled: 1889244\n",
      "    num_steps_trained: 1889244\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.40851063829787\n",
      "    ram_util_percent: 55.50042553191489\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045785919949324155\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6410050685238\n",
      "    mean_inference_ms: 2.8632804864751837\n",
      "    mean_raw_obs_processing_ms: 2.832282977280244\n",
      "  time_since_restore: 28357.150688171387\n",
      "  time_this_iter_s: 164.24633073806763\n",
      "  time_total_s: 28357.150688171387\n",
      "  timers:\n",
      "    learn_throughput: 929.06\n",
      "    learn_time_ms: 10759.266\n",
      "    load_throughput: 91136.382\n",
      "    load_time_ms: 109.682\n",
      "    sample_throughput: 70.842\n",
      "    sample_time_ms: 141103.413\n",
      "    update_time_ms: 12.079\n",
      "  timestamp: 1636322773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1889244\n",
      "  training_iteration: 189\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         28357.2</td><td style=\"text-align: right;\">1889244</td><td style=\"text-align: right;\"> 1.95439</td><td style=\"text-align: right;\">                8.83</td><td style=\"text-align: right;\">               -2.15</td><td style=\"text-align: right;\">            92.972</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1899240\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-08-42\n",
      "  done: false\n",
      "  episode_len_mean: 93.1574074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.860000000000001\n",
      "  episode_reward_mean: 2.7580555555555617\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 20445\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4732870468726524\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013631111715916274\n",
      "          policy_loss: -0.08354456674976227\n",
      "          total_loss: 0.03970547450754123\n",
      "          vf_explained_var: 0.9167192578315735\n",
      "          vf_loss: 0.11692953433156905\n",
      "    num_agent_steps_sampled: 1899240\n",
      "    num_agent_steps_trained: 1899240\n",
      "    num_steps_sampled: 1899240\n",
      "    num_steps_trained: 1899240\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.40283018867925\n",
      "    ram_util_percent: 55.633018867924534\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578391702192577\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.64221704279802\n",
      "    mean_inference_ms: 2.8633168259747235\n",
      "    mean_raw_obs_processing_ms: 2.8299994003770705\n",
      "  time_since_restore: 28505.9838013649\n",
      "  time_this_iter_s: 148.83311319351196\n",
      "  time_total_s: 28505.9838013649\n",
      "  timers:\n",
      "    learn_throughput: 929.533\n",
      "    learn_time_ms: 10753.789\n",
      "    load_throughput: 91096.283\n",
      "    load_time_ms: 109.73\n",
      "    sample_throughput: 71.062\n",
      "    sample_time_ms: 140665.866\n",
      "    update_time_ms: 12.58\n",
      "  timestamp: 1636322922\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1899240\n",
      "  training_iteration: 190\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   190</td><td style=\"text-align: right;\">           28506</td><td style=\"text-align: right;\">1899240</td><td style=\"text-align: right;\"> 2.75806</td><td style=\"text-align: right;\">                9.86</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           93.1574</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1909236\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-11-09\n",
      "  done: false\n",
      "  episode_len_mean: 92.45871559633028\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.780000000000014\n",
      "  episode_reward_mean: 2.540642201834868\n",
      "  episode_reward_min: -1.5600000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 20554\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4872780164082844\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013190809415554498\n",
      "          policy_loss: -0.08455597335297582\n",
      "          total_loss: 0.03859925648977614\n",
      "          vf_explained_var: 0.9229960441589355\n",
      "          vf_loss: 0.11797769426758219\n",
      "    num_agent_steps_sampled: 1909236\n",
      "    num_agent_steps_trained: 1909236\n",
      "    num_steps_sampled: 1909236\n",
      "    num_steps_trained: 1909236\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.67345971563982\n",
      "    ram_util_percent: 55.675829383886246\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578785152330108\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.64040784621595\n",
      "    mean_inference_ms: 2.8632092594676264\n",
      "    mean_raw_obs_processing_ms: 2.8273713467577717\n",
      "  time_since_restore: 28653.738080263138\n",
      "  time_this_iter_s: 147.75427889823914\n",
      "  time_total_s: 28653.738080263138\n",
      "  timers:\n",
      "    learn_throughput: 929.761\n",
      "    learn_time_ms: 10751.149\n",
      "    load_throughput: 91152.788\n",
      "    load_time_ms: 109.662\n",
      "    sample_throughput: 71.266\n",
      "    sample_time_ms: 140264.004\n",
      "    update_time_ms: 12.133\n",
      "  timestamp: 1636323069\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1909236\n",
      "  training_iteration: 191\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">         28653.7</td><td style=\"text-align: right;\">1909236</td><td style=\"text-align: right;\"> 2.54064</td><td style=\"text-align: right;\">               10.78</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           92.4587</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1919232\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-13-39\n",
      "  done: false\n",
      "  episode_len_mean: 94.33962264150944\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.660000000000016\n",
      "  episode_reward_mean: 2.5474528301886847\n",
      "  episode_reward_min: -1.6000000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 20660\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.480414307423127\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013445245636274368\n",
      "          policy_loss: -0.08378128657101566\n",
      "          total_loss: 0.038911850695522165\n",
      "          vf_explained_var: 0.9119445085525513\n",
      "          vf_loss: 0.11686732991733867\n",
      "    num_agent_steps_sampled: 1919232\n",
      "    num_agent_steps_trained: 1919232\n",
      "    num_steps_sampled: 1919232\n",
      "    num_steps_trained: 1919232\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.73317757009346\n",
      "    ram_util_percent: 55.63177570093459\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04580220407957838\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.63963143160689\n",
      "    mean_inference_ms: 2.8633351388568355\n",
      "    mean_raw_obs_processing_ms: 2.8255286887758584\n",
      "  time_since_restore: 28803.7090010643\n",
      "  time_this_iter_s: 149.97092080116272\n",
      "  time_total_s: 28803.7090010643\n",
      "  timers:\n",
      "    learn_throughput: 929.448\n",
      "    learn_time_ms: 10754.774\n",
      "    load_throughput: 91396.044\n",
      "    load_time_ms: 109.37\n",
      "    sample_throughput: 72.439\n",
      "    sample_time_ms: 137992.485\n",
      "    update_time_ms: 13.12\n",
      "  timestamp: 1636323219\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1919232\n",
      "  training_iteration: 192\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">         28803.7</td><td style=\"text-align: right;\">1919232</td><td style=\"text-align: right;\"> 2.54745</td><td style=\"text-align: right;\">               12.66</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           94.3396</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1929228\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-15-57\n",
      "  done: false\n",
      "  episode_len_mean: 91.79629629629629\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.010000000000012\n",
      "  episode_reward_mean: 2.637407407407414\n",
      "  episode_reward_min: -1.4400000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 20768\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4651941242381037\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014258591140239479\n",
      "          policy_loss: -0.08329790932022862\n",
      "          total_loss: 0.05314183897442288\n",
      "          vf_explained_var: 0.922923743724823\n",
      "          vf_loss: 0.12860883705031415\n",
      "    num_agent_steps_sampled: 1929228\n",
      "    num_agent_steps_trained: 1929228\n",
      "    num_steps_sampled: 1929228\n",
      "    num_steps_trained: 1929228\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.91725888324875\n",
      "    ram_util_percent: 55.53451776649746\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04580082311292084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.645641544302165\n",
      "    mean_inference_ms: 2.863586842783127\n",
      "    mean_raw_obs_processing_ms: 2.8148144658048886\n",
      "  time_since_restore: 28941.6673746109\n",
      "  time_this_iter_s: 137.95837354660034\n",
      "  time_total_s: 28941.6673746109\n",
      "  timers:\n",
      "    learn_throughput: 930.257\n",
      "    learn_time_ms: 10745.423\n",
      "    load_throughput: 91594.916\n",
      "    load_time_ms: 109.133\n",
      "    sample_throughput: 72.287\n",
      "    sample_time_ms: 138283.004\n",
      "    update_time_ms: 12.503\n",
      "  timestamp: 1636323357\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1929228\n",
      "  training_iteration: 193\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">         28941.7</td><td style=\"text-align: right;\">1929228</td><td style=\"text-align: right;\"> 2.63741</td><td style=\"text-align: right;\">               11.01</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           91.7963</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1939224\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-18-25\n",
      "  done: false\n",
      "  episode_len_mean: 93.52830188679245\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.88\n",
      "  episode_reward_mean: 2.4334905660377415\n",
      "  episode_reward_min: -2.1800000000000006\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 20874\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.48040058938866\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012918982393857662\n",
      "          policy_loss: -0.08560438685628594\n",
      "          total_loss: 0.018435121876880144\n",
      "          vf_explained_var: 0.9241398572921753\n",
      "          vf_loss: 0.09941245616994734\n",
      "    num_agent_steps_sampled: 1939224\n",
      "    num_agent_steps_trained: 1939224\n",
      "    num_steps_sampled: 1939224\n",
      "    num_steps_trained: 1939224\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.5308056872038\n",
      "    ram_util_percent: 55.53270142180094\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578642945108644\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.64100792702475\n",
      "    mean_inference_ms: 2.8633904693034955\n",
      "    mean_raw_obs_processing_ms: 2.820356453889242\n",
      "  time_since_restore: 29089.46457505226\n",
      "  time_this_iter_s: 147.79720044136047\n",
      "  time_total_s: 29089.46457505226\n",
      "  timers:\n",
      "    learn_throughput: 930.497\n",
      "    learn_time_ms: 10742.646\n",
      "    load_throughput: 91304.03\n",
      "    load_time_ms: 109.48\n",
      "    sample_throughput: 72.387\n",
      "    sample_time_ms: 138090.422\n",
      "    update_time_ms: 11.409\n",
      "  timestamp: 1636323505\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1939224\n",
      "  training_iteration: 194\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">         29089.5</td><td style=\"text-align: right;\">1939224</td><td style=\"text-align: right;\"> 2.43349</td><td style=\"text-align: right;\">                9.88</td><td style=\"text-align: right;\">               -2.18</td><td style=\"text-align: right;\">           93.5283</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1949220\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-20-43\n",
      "  done: false\n",
      "  episode_len_mean: 93.55555555555556\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.830000000000016\n",
      "  episode_reward_mean: 2.4630555555555618\n",
      "  episode_reward_min: -1.6800000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 20982\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.470492130263239\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01281378116875914\n",
      "          policy_loss: -0.08264486321494875\n",
      "          total_loss: 0.023150325953387296\n",
      "          vf_explained_var: 0.9178274869918823\n",
      "          vf_loss: 0.10130871435802462\n",
      "    num_agent_steps_sampled: 1949220\n",
      "    num_agent_steps_trained: 1949220\n",
      "    num_steps_sampled: 1949220\n",
      "    num_steps_trained: 1949220\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95459183673469\n",
      "    ram_util_percent: 55.65765306122448\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045826838636212834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.64369301664667\n",
      "    mean_inference_ms: 2.863604713669988\n",
      "    mean_raw_obs_processing_ms: 2.8121552760597264\n",
      "  time_since_restore: 29226.794946193695\n",
      "  time_this_iter_s: 137.33037114143372\n",
      "  time_total_s: 29226.794946193695\n",
      "  timers:\n",
      "    learn_throughput: 930.553\n",
      "    learn_time_ms: 10742.002\n",
      "    load_throughput: 91502.68\n",
      "    load_time_ms: 109.243\n",
      "    sample_throughput: 73.005\n",
      "    sample_time_ms: 136921.457\n",
      "    update_time_ms: 10.743\n",
      "  timestamp: 1636323643\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1949220\n",
      "  training_iteration: 195\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         29226.8</td><td style=\"text-align: right;\">1949220</td><td style=\"text-align: right;\"> 2.46306</td><td style=\"text-align: right;\">               12.83</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           93.5556</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1959216\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-23-11\n",
      "  done: false\n",
      "  episode_len_mean: 92.29357798165138\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.520000000000014\n",
      "  episode_reward_mean: 2.48247706422019\n",
      "  episode_reward_min: -1.5700000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 21091\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4725735945579332\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01331884161502398\n",
      "          policy_loss: -0.08060906767670033\n",
      "          total_loss: 0.05388967698662836\n",
      "          vf_explained_var: 0.9079403877258301\n",
      "          vf_loss: 0.1288824937083464\n",
      "    num_agent_steps_sampled: 1959216\n",
      "    num_agent_steps_trained: 1959216\n",
      "    num_steps_sampled: 1959216\n",
      "    num_steps_trained: 1959216\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.66872037914692\n",
      "    ram_util_percent: 55.62843601895734\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04579374624949643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6431837044322\n",
      "    mean_inference_ms: 2.8632454919116626\n",
      "    mean_raw_obs_processing_ms: 2.807562032666804\n",
      "  time_since_restore: 29374.965883493423\n",
      "  time_this_iter_s: 148.1709372997284\n",
      "  time_total_s: 29374.965883493423\n",
      "  timers:\n",
      "    learn_throughput: 930.842\n",
      "    learn_time_ms: 10738.664\n",
      "    load_throughput: 91365.97\n",
      "    load_time_ms: 109.406\n",
      "    sample_throughput: 74.097\n",
      "    sample_time_ms: 134904.36\n",
      "    update_time_ms: 10.324\n",
      "  timestamp: 1636323791\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1959216\n",
      "  training_iteration: 196\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   196</td><td style=\"text-align: right;\">           29375</td><td style=\"text-align: right;\">1959216</td><td style=\"text-align: right;\"> 2.48248</td><td style=\"text-align: right;\">                8.52</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           92.2936</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1969212\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-25-54\n",
      "  done: false\n",
      "  episode_len_mean: 91.98165137614679\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.980000000000013\n",
      "  episode_reward_mean: 3.0389908256880807\n",
      "  episode_reward_min: -1.4100000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 21200\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.453698437234275\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013798074797966667\n",
      "          policy_loss: -0.0777343698283737\n",
      "          total_loss: 0.08057953836794338\n",
      "          vf_explained_var: 0.916746973991394\n",
      "          vf_loss: 0.15141715286617988\n",
      "    num_agent_steps_sampled: 1969212\n",
      "    num_agent_steps_trained: 1969212\n",
      "    num_steps_sampled: 1969212\n",
      "    num_steps_trained: 1969212\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.01802575107297\n",
      "    ram_util_percent: 55.62145922746781\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578341038488369\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.63867830909547\n",
      "    mean_inference_ms: 2.863314886153999\n",
      "    mean_raw_obs_processing_ms: 2.8150867139073754\n",
      "  time_since_restore: 29538.341490507126\n",
      "  time_this_iter_s: 163.3756070137024\n",
      "  time_total_s: 29538.341490507126\n",
      "  timers:\n",
      "    learn_throughput: 931.716\n",
      "    learn_time_ms: 10728.594\n",
      "    load_throughput: 91298.264\n",
      "    load_time_ms: 109.487\n",
      "    sample_throughput: 72.652\n",
      "    sample_time_ms: 137587.481\n",
      "    update_time_ms: 10.792\n",
      "  timestamp: 1636323954\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1969212\n",
      "  training_iteration: 197\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">         29538.3</td><td style=\"text-align: right;\">1969212</td><td style=\"text-align: right;\"> 3.03899</td><td style=\"text-align: right;\">               10.98</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           91.9817</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1979208\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-28-37\n",
      "  done: false\n",
      "  episode_len_mean: 90.95412844036697\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.830000000000002\n",
      "  episode_reward_mean: 2.5399082568807394\n",
      "  episode_reward_min: -1.6300000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 21309\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4666767776521863\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014066397543278193\n",
      "          policy_loss: -0.08369048654905752\n",
      "          total_loss: 0.0642306826610723\n",
      "          vf_explained_var: 0.9032118320465088\n",
      "          vf_loss: 0.14054292289890413\n",
      "    num_agent_steps_sampled: 1979208\n",
      "    num_agent_steps_trained: 1979208\n",
      "    num_steps_sampled: 1979208\n",
      "    num_steps_trained: 1979208\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.37167381974248\n",
      "    ram_util_percent: 55.77510729613734\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045791190875488844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.63669210870279\n",
      "    mean_inference_ms: 2.863014702116908\n",
      "    mean_raw_obs_processing_ms: 2.8227191204852433\n",
      "  time_since_restore: 29701.342252731323\n",
      "  time_this_iter_s: 163.0007622241974\n",
      "  time_total_s: 29701.342252731323\n",
      "  timers:\n",
      "    learn_throughput: 932.659\n",
      "    learn_time_ms: 10717.743\n",
      "    load_throughput: 90848.378\n",
      "    load_time_ms: 110.029\n",
      "    sample_throughput: 71.404\n",
      "    sample_time_ms: 139991.869\n",
      "    update_time_ms: 10.574\n",
      "  timestamp: 1636324117\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1979208\n",
      "  training_iteration: 198\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   198</td><td style=\"text-align: right;\">         29701.3</td><td style=\"text-align: right;\">1979208</td><td style=\"text-align: right;\"> 2.53991</td><td style=\"text-align: right;\">                9.83</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           90.9541</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1989204\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-30-53\n",
      "  done: false\n",
      "  episode_len_mean: 92.88785046728972\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.520000000000017\n",
      "  episode_reward_mean: 2.1661682242990707\n",
      "  episode_reward_min: -1.890000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 21416\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4556996129516864\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012551111875629859\n",
      "          policy_loss: -0.08711492885700148\n",
      "          total_loss: 0.025057463669496724\n",
      "          vf_explained_var: 0.9135725498199463\n",
      "          vf_loss: 0.10813638626669463\n",
      "    num_agent_steps_sampled: 1989204\n",
      "    num_agent_steps_trained: 1989204\n",
      "    num_steps_sampled: 1989204\n",
      "    num_steps_trained: 1989204\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03041237113403\n",
      "    ram_util_percent: 55.658762886597934\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045803070448439856\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.640587407188086\n",
      "    mean_inference_ms: 2.8632492018648823\n",
      "    mean_raw_obs_processing_ms: 2.812682627229551\n",
      "  time_since_restore: 29837.51995921135\n",
      "  time_this_iter_s: 136.17770648002625\n",
      "  time_total_s: 29837.51995921135\n",
      "  timers:\n",
      "    learn_throughput: 932.347\n",
      "    learn_time_ms: 10721.33\n",
      "    load_throughput: 90859.639\n",
      "    load_time_ms: 110.016\n",
      "    sample_throughput: 72.867\n",
      "    sample_time_ms: 137180.784\n",
      "    update_time_ms: 11.273\n",
      "  timestamp: 1636324253\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1989204\n",
      "  training_iteration: 199\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">         29837.5</td><td style=\"text-align: right;\">1989204</td><td style=\"text-align: right;\"> 2.16617</td><td style=\"text-align: right;\">               10.52</td><td style=\"text-align: right;\">               -1.89</td><td style=\"text-align: right;\">           92.8879</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 1999200\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-33-25\n",
      "  done: false\n",
      "  episode_len_mean: 90.33035714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.840000000000016\n",
      "  episode_reward_mean: 2.679375000000006\n",
      "  episode_reward_min: -1.6800000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 21528\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4412955080342087\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014237558111562975\n",
      "          policy_loss: -0.08323672758972543\n",
      "          total_loss: 0.06368961046871721\n",
      "          vf_explained_var: 0.9057791233062744\n",
      "          vf_loss: 0.1389043561803798\n",
      "    num_agent_steps_sampled: 1999200\n",
      "    num_agent_steps_trained: 1999200\n",
      "    num_steps_sampled: 1999200\n",
      "    num_steps_trained: 1999200\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.57777777777777\n",
      "    ram_util_percent: 55.59861111111112\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578349920386656\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6426523340317\n",
      "    mean_inference_ms: 2.863082490087435\n",
      "    mean_raw_obs_processing_ms: 2.8183732730972304\n",
      "  time_since_restore: 29988.988538742065\n",
      "  time_this_iter_s: 151.46857953071594\n",
      "  time_total_s: 29988.988538742065\n",
      "  timers:\n",
      "    learn_throughput: 932.46\n",
      "    learn_time_ms: 10720.026\n",
      "    load_throughput: 90877.837\n",
      "    load_time_ms: 109.994\n",
      "    sample_throughput: 72.727\n",
      "    sample_time_ms: 137446.191\n",
      "    update_time_ms: 10.825\n",
      "  timestamp: 1636324405\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1999200\n",
      "  training_iteration: 200\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">           29989</td><td style=\"text-align: right;\">1999200</td><td style=\"text-align: right;\"> 2.67938</td><td style=\"text-align: right;\">                8.84</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           90.3304</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2009196\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-36-07\n",
      "  done: false\n",
      "  episode_len_mean: 89.13636363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.820000000000013\n",
      "  episode_reward_mean: 2.893181818181824\n",
      "  episode_reward_min: -1.3900000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 21638\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.432646731026152\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013266861386720891\n",
      "          policy_loss: -0.08389140463346599\n",
      "          total_loss: 0.04296384808472079\n",
      "          vf_explained_var: 0.9189626574516296\n",
      "          vf_loss: 0.12095815040823868\n",
      "    num_agent_steps_sampled: 2009196\n",
      "    num_agent_steps_trained: 2009196\n",
      "    num_steps_sampled: 2009196\n",
      "    num_steps_trained: 2009196\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.00735930735931\n",
      "    ram_util_percent: 55.65541125541125\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045798949690215064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.660294404222796\n",
      "    mean_inference_ms: 2.8629356062523033\n",
      "    mean_raw_obs_processing_ms: 2.816881149753357\n",
      "  time_since_restore: 30150.590317487717\n",
      "  time_this_iter_s: 161.60177874565125\n",
      "  time_total_s: 30150.590317487717\n",
      "  timers:\n",
      "    learn_throughput: 932.631\n",
      "    learn_time_ms: 10718.065\n",
      "    load_throughput: 90892.869\n",
      "    load_time_ms: 109.976\n",
      "    sample_throughput: 72.0\n",
      "    sample_time_ms: 138832.755\n",
      "    update_time_ms: 11.455\n",
      "  timestamp: 1636324567\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2009196\n",
      "  training_iteration: 201\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         30150.6</td><td style=\"text-align: right;\">2009196</td><td style=\"text-align: right;\"> 2.89318</td><td style=\"text-align: right;\">               12.82</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">           89.1364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2019192\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-38-55\n",
      "  done: false\n",
      "  episode_len_mean: 91.34234234234235\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.710000000000019\n",
      "  episode_reward_mean: 2.8685585585585653\n",
      "  episode_reward_min: -1.900000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 21749\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4340811167007836\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013145745956753928\n",
      "          policy_loss: -0.08470721060298701\n",
      "          total_loss: 0.0386413853830443\n",
      "          vf_explained_var: 0.9280899167060852\n",
      "          vf_loss: 0.1177417530813533\n",
      "    num_agent_steps_sampled: 2019192\n",
      "    num_agent_steps_trained: 2019192\n",
      "    num_steps_sampled: 2019192\n",
      "    num_steps_trained: 2019192\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.92208333333335\n",
      "    ram_util_percent: 55.56541666666666\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045815788231421524\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.666591749785056\n",
      "    mean_inference_ms: 2.8631403844132493\n",
      "    mean_raw_obs_processing_ms: 2.822146519004341\n",
      "  time_since_restore: 30319.087686538696\n",
      "  time_this_iter_s: 168.49736905097961\n",
      "  time_total_s: 30319.087686538696\n",
      "  timers:\n",
      "    learn_throughput: 933.307\n",
      "    learn_time_ms: 10710.307\n",
      "    load_throughput: 90829.838\n",
      "    load_time_ms: 110.052\n",
      "    sample_throughput: 71.048\n",
      "    sample_time_ms: 140694.129\n",
      "    update_time_ms: 10.395\n",
      "  timestamp: 1636324735\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2019192\n",
      "  training_iteration: 202\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   202</td><td style=\"text-align: right;\">         30319.1</td><td style=\"text-align: right;\">2019192</td><td style=\"text-align: right;\"> 2.86856</td><td style=\"text-align: right;\">               12.71</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           91.3423</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2029188\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-41-30\n",
      "  done: false\n",
      "  episode_len_mean: 89.04504504504504\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.640000000000017\n",
      "  episode_reward_mean: 2.88360360360361\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 21860\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4249969724915985\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013204541109564791\n",
      "          policy_loss: -0.08600559530572759\n",
      "          total_loss: 0.035291551359188864\n",
      "          vf_explained_var: 0.9352210164070129\n",
      "          vf_loss: 0.11546552089783244\n",
      "    num_agent_steps_sampled: 2029188\n",
      "    num_agent_steps_trained: 2029188\n",
      "    num_steps_sampled: 2029188\n",
      "    num_steps_trained: 2029188\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.79954954954955\n",
      "    ram_util_percent: 55.5927927927928\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457924615418371\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.669189504545294\n",
      "    mean_inference_ms: 2.8632758661696185\n",
      "    mean_raw_obs_processing_ms: 2.8271366168277767\n",
      "  time_since_restore: 30474.213067770004\n",
      "  time_this_iter_s: 155.12538123130798\n",
      "  time_total_s: 30474.213067770004\n",
      "  timers:\n",
      "    learn_throughput: 932.914\n",
      "    learn_time_ms: 10714.819\n",
      "    load_throughput: 90841.901\n",
      "    load_time_ms: 110.037\n",
      "    sample_throughput: 70.194\n",
      "    sample_time_ms: 142405.562\n",
      "    update_time_ms: 10.916\n",
      "  timestamp: 1636324890\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2029188\n",
      "  training_iteration: 203\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   203</td><td style=\"text-align: right;\">         30474.2</td><td style=\"text-align: right;\">2029188</td><td style=\"text-align: right;\">  2.8836</td><td style=\"text-align: right;\">               10.64</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">            89.045</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2039184\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-44-03\n",
      "  done: false\n",
      "  episode_len_mean: 90.83783783783784\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.080000000000013\n",
      "  episode_reward_mean: 2.583603603603609\n",
      "  episode_reward_min: -1.5500000000000007\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 21971\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4271342412019385\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013669024650101167\n",
      "          policy_loss: -0.08379512170059049\n",
      "          total_loss: 0.04042321679333591\n",
      "          vf_explained_var: 0.9259775876998901\n",
      "          vf_loss: 0.11734993286335316\n",
      "    num_agent_steps_sampled: 2039184\n",
      "    num_agent_steps_trained: 2039184\n",
      "    num_steps_sampled: 2039184\n",
      "    num_steps_trained: 2039184\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.54700460829491\n",
      "    ram_util_percent: 55.62672811059908\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04580285669873933\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.672627734984985\n",
      "    mean_inference_ms: 2.863132821882554\n",
      "    mean_raw_obs_processing_ms: 2.826598255290193\n",
      "  time_since_restore: 30626.646195173264\n",
      "  time_this_iter_s: 152.43312740325928\n",
      "  time_total_s: 30626.646195173264\n",
      "  timers:\n",
      "    learn_throughput: 932.483\n",
      "    learn_time_ms: 10719.764\n",
      "    load_throughput: 90917.783\n",
      "    load_time_ms: 109.945\n",
      "    sample_throughput: 69.968\n",
      "    sample_time_ms: 142864.41\n",
      "    update_time_ms: 10.71\n",
      "  timestamp: 1636325043\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2039184\n",
      "  training_iteration: 204\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">         30626.6</td><td style=\"text-align: right;\">2039184</td><td style=\"text-align: right;\">  2.5836</td><td style=\"text-align: right;\">                9.08</td><td style=\"text-align: right;\">               -1.55</td><td style=\"text-align: right;\">           90.8378</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2049180\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-46-31\n",
      "  done: false\n",
      "  episode_len_mean: 91.92660550458716\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.830000000000013\n",
      "  episode_reward_mean: 2.8189908256880782\n",
      "  episode_reward_min: -2.04\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 22080\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4393403691104334\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01420109201575802\n",
      "          policy_loss: -0.07825294896068737\n",
      "          total_loss: 0.07698127779966364\n",
      "          vf_explained_var: 0.9042829871177673\n",
      "          vf_loss: 0.14727576605291065\n",
      "    num_agent_steps_sampled: 2049180\n",
      "    num_agent_steps_trained: 2049180\n",
      "    num_steps_sampled: 2049180\n",
      "    num_steps_trained: 2049180\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.6222748815166\n",
      "    ram_util_percent: 55.84786729857821\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04581943675547691\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.67233829972107\n",
      "    mean_inference_ms: 2.863025715540464\n",
      "    mean_raw_obs_processing_ms: 2.826112514815873\n",
      "  time_since_restore: 30774.45161652565\n",
      "  time_this_iter_s: 147.80542135238647\n",
      "  time_total_s: 30774.45161652565\n",
      "  timers:\n",
      "    learn_throughput: 933.069\n",
      "    learn_time_ms: 10713.033\n",
      "    load_throughput: 90781.181\n",
      "    load_time_ms: 110.111\n",
      "    sample_throughput: 69.456\n",
      "    sample_time_ms: 143918.521\n",
      "    update_time_ms: 10.477\n",
      "  timestamp: 1636325191\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2049180\n",
      "  training_iteration: 205\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   205</td><td style=\"text-align: right;\">         30774.5</td><td style=\"text-align: right;\">2049180</td><td style=\"text-align: right;\"> 2.81899</td><td style=\"text-align: right;\">               10.83</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           91.9266</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2059176\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-48-49\n",
      "  done: false\n",
      "  episode_len_mean: 91.6697247706422\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.830000000000014\n",
      "  episode_reward_mean: 2.591834862385328\n",
      "  episode_reward_min: -1.990000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 22189\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4383618919258443\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014206329791655944\n",
      "          policy_loss: -0.08034616080232156\n",
      "          total_loss: 0.06386735250488815\n",
      "          vf_explained_var: 0.898929238319397\n",
      "          vf_loss: 0.13623333629857526\n",
      "    num_agent_steps_sampled: 2059176\n",
      "    num_agent_steps_trained: 2059176\n",
      "    num_steps_sampled: 2059176\n",
      "    num_steps_trained: 2059176\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.18172588832486\n",
      "    ram_util_percent: 55.77411167512691\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578067233846918\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.6773667455841\n",
      "    mean_inference_ms: 2.863159745818473\n",
      "    mean_raw_obs_processing_ms: 2.8138841620881623\n",
      "  time_since_restore: 30912.341354370117\n",
      "  time_this_iter_s: 137.88973784446716\n",
      "  time_total_s: 30912.341354370117\n",
      "  timers:\n",
      "    learn_throughput: 933.064\n",
      "    learn_time_ms: 10713.091\n",
      "    load_throughput: 90827.85\n",
      "    load_time_ms: 110.054\n",
      "    sample_throughput: 69.956\n",
      "    sample_time_ms: 142890.283\n",
      "    update_time_ms: 10.798\n",
      "  timestamp: 1636325329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2059176\n",
      "  training_iteration: 206\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">         30912.3</td><td style=\"text-align: right;\">2059176</td><td style=\"text-align: right;\"> 2.59183</td><td style=\"text-align: right;\">                8.83</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           91.6697</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2069172\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-52-20\n",
      "  done: false\n",
      "  episode_len_mean: 87.30701754385964\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.850000000000001\n",
      "  episode_reward_mean: 2.7931578947368476\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 22303\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4289880351123645\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01321778632280097\n",
      "          policy_loss: -0.08177710978839642\n",
      "          total_loss: 0.05385889108491759\n",
      "          vf_explained_var: 0.9164316058158875\n",
      "          vf_loss: 0.12981411098128456\n",
      "    num_agent_steps_sampled: 2069172\n",
      "    num_agent_steps_trained: 2069172\n",
      "    num_steps_sampled: 2069172\n",
      "    num_steps_trained: 2069172\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.8671096345515\n",
      "    ram_util_percent: 55.75016611295682\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575117448609765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.674179338655314\n",
      "    mean_inference_ms: 2.862799913797779\n",
      "    mean_raw_obs_processing_ms: 2.850847368216409\n",
      "  time_since_restore: 31123.60234260559\n",
      "  time_this_iter_s: 211.26098823547363\n",
      "  time_total_s: 31123.60234260559\n",
      "  timers:\n",
      "    learn_throughput: 933.012\n",
      "    learn_time_ms: 10713.693\n",
      "    load_throughput: 90944.565\n",
      "    load_time_ms: 109.913\n",
      "    sample_throughput: 67.687\n",
      "    sample_time_ms: 147679.235\n",
      "    update_time_ms: 10.218\n",
      "  timestamp: 1636325540\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2069172\n",
      "  training_iteration: 207\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   207</td><td style=\"text-align: right;\">         31123.6</td><td style=\"text-align: right;\">2069172</td><td style=\"text-align: right;\"> 2.79316</td><td style=\"text-align: right;\">                9.85</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">            87.307</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2079168\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-55-31\n",
      "  done: false\n",
      "  episode_len_mean: 89.13392857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.08000000000001\n",
      "  episode_reward_mean: 2.7214285714285773\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 22415\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.421975537854382\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01324625999713596\n",
      "          policy_loss: -0.07952383758229578\n",
      "          total_loss: 0.04261264558045719\n",
      "          vf_explained_var: 0.9257248044013977\n",
      "          vf_loss: 0.1161796016463389\n",
      "    num_agent_steps_sampled: 2079168\n",
      "    num_agent_steps_trained: 2079168\n",
      "    num_steps_sampled: 2079168\n",
      "    num_steps_trained: 2079168\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.15970695970695\n",
      "    ram_util_percent: 55.79010989010989\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575392792125726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.66398159876424\n",
      "    mean_inference_ms: 2.862197734102047\n",
      "    mean_raw_obs_processing_ms: 2.88219939750121\n",
      "  time_since_restore: 31314.301139116287\n",
      "  time_this_iter_s: 190.6987965106964\n",
      "  time_total_s: 31314.301139116287\n",
      "  timers:\n",
      "    learn_throughput: 933.307\n",
      "    learn_time_ms: 10710.3\n",
      "    load_throughput: 91336.332\n",
      "    load_time_ms: 109.442\n",
      "    sample_throughput: 66.44\n",
      "    sample_time_ms: 150451.998\n",
      "    update_time_ms: 10.934\n",
      "  timestamp: 1636325731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2079168\n",
      "  training_iteration: 208\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">         31314.3</td><td style=\"text-align: right;\">2079168</td><td style=\"text-align: right;\"> 2.72143</td><td style=\"text-align: right;\">               11.08</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           89.1339</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2089164\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_22-58-36\n",
      "  done: false\n",
      "  episode_len_mean: 90.04504504504504\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.830000000000014\n",
      "  episode_reward_mean: 2.5021621621621675\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 22526\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.425171137263632\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013114875562490327\n",
      "          policy_loss: -0.08692511398440753\n",
      "          total_loss: 0.02457035875552867\n",
      "          vf_explained_var: 0.9296663403511047\n",
      "          vf_loss: 0.10586985778222736\n",
      "    num_agent_steps_sampled: 2089164\n",
      "    num_agent_steps_trained: 2089164\n",
      "    num_steps_sampled: 2089164\n",
      "    num_steps_trained: 2089164\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.51666666666667\n",
      "    ram_util_percent: 55.75871212121213\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577712699209239\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.664122986509305\n",
      "    mean_inference_ms: 2.8620813301203625\n",
      "    mean_raw_obs_processing_ms: 2.897613506984738\n",
      "  time_since_restore: 31499.92241501808\n",
      "  time_this_iter_s: 185.62127590179443\n",
      "  time_total_s: 31499.92241501808\n",
      "  timers:\n",
      "    learn_throughput: 933.979\n",
      "    learn_time_ms: 10702.596\n",
      "    load_throughput: 91537.262\n",
      "    load_time_ms: 109.201\n",
      "    sample_throughput: 64.322\n",
      "    sample_time_ms: 155405.629\n",
      "    update_time_ms: 9.761\n",
      "  timestamp: 1636325916\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2089164\n",
      "  training_iteration: 209\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">         31499.9</td><td style=\"text-align: right;\">2089164</td><td style=\"text-align: right;\"> 2.50216</td><td style=\"text-align: right;\">               12.83</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">            90.045</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2099160\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-01-12\n",
      "  done: false\n",
      "  episode_len_mean: 90.33333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.010000000000018\n",
      "  episode_reward_mean: 2.897297297297304\n",
      "  episode_reward_min: -1.7300000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 22637\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4199124965912255\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0132829875829255\n",
      "          policy_loss: -0.08556915233787309\n",
      "          total_loss: 0.03331526176462698\n",
      "          vf_explained_var: 0.9272594451904297\n",
      "          vf_loss: 0.1128232328253042\n",
      "    num_agent_steps_sampled: 2099160\n",
      "    num_agent_steps_trained: 2099160\n",
      "    num_steps_sampled: 2099160\n",
      "    num_steps_trained: 2099160\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.51351351351352\n",
      "    ram_util_percent: 55.647297297297285\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04573495793438109\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.66982287594887\n",
      "    mean_inference_ms: 2.8620379617328564\n",
      "    mean_raw_obs_processing_ms: 2.89448640379025\n",
      "  time_since_restore: 31655.21754026413\n",
      "  time_this_iter_s: 155.29512524604797\n",
      "  time_total_s: 31655.21754026413\n",
      "  timers:\n",
      "    learn_throughput: 934.61\n",
      "    learn_time_ms: 10695.371\n",
      "    load_throughput: 91615.831\n",
      "    load_time_ms: 109.108\n",
      "    sample_throughput: 64.161\n",
      "    sample_time_ms: 155795.189\n",
      "    update_time_ms: 9.811\n",
      "  timestamp: 1636326072\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2099160\n",
      "  training_iteration: 210\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   210</td><td style=\"text-align: right;\">         31655.2</td><td style=\"text-align: right;\">2099160</td><td style=\"text-align: right;\">  2.8973</td><td style=\"text-align: right;\">               11.01</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           90.3333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2109156\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-03-55\n",
      "  done: false\n",
      "  episode_len_mean: 88.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.290000000000013\n",
      "  episode_reward_mean: 2.7593805309734574\n",
      "  episode_reward_min: -1.5300000000000005\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 22750\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4219688484811375\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013384187758276362\n",
      "          policy_loss: -0.08047838811086029\n",
      "          total_loss: 0.04059246451331255\n",
      "          vf_explained_var: 0.9223693609237671\n",
      "          vf_loss: 0.114799687338786\n",
      "    num_agent_steps_sampled: 2109156\n",
      "    num_agent_steps_trained: 2109156\n",
      "    num_steps_sampled: 2109156\n",
      "    num_steps_trained: 2109156\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.57008547008547\n",
      "    ram_util_percent: 55.47222222222222\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045751908946127524\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.68481282773856\n",
      "    mean_inference_ms: 2.862151919372454\n",
      "    mean_raw_obs_processing_ms: 2.9011240228476054\n",
      "  time_since_restore: 31818.970937252045\n",
      "  time_this_iter_s: 163.75339698791504\n",
      "  time_total_s: 31818.970937252045\n",
      "  timers:\n",
      "    learn_throughput: 934.801\n",
      "    learn_time_ms: 10693.179\n",
      "    load_throughput: 91755.621\n",
      "    load_time_ms: 108.942\n",
      "    sample_throughput: 64.072\n",
      "    sample_time_ms: 156012.493\n",
      "    update_time_ms: 9.742\n",
      "  timestamp: 1636326235\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2109156\n",
      "  training_iteration: 211\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   211</td><td style=\"text-align: right;\">           31819</td><td style=\"text-align: right;\">2109156</td><td style=\"text-align: right;\"> 2.75938</td><td style=\"text-align: right;\">               13.29</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">                88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2119152\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-06-31\n",
      "  done: false\n",
      "  episode_len_mean: 89.33628318584071\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000017\n",
      "  episode_reward_mean: 2.5025663716814206\n",
      "  episode_reward_min: -1.8200000000000007\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 22863\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.431667758868291\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012448573443212225\n",
      "          policy_loss: -0.08492764939959997\n",
      "          total_loss: 0.02323770373263675\n",
      "          vf_explained_var: 0.9244449734687805\n",
      "          vf_loss: 0.10412262301876123\n",
      "    num_agent_steps_sampled: 2119152\n",
      "    num_agent_steps_trained: 2119152\n",
      "    num_steps_sampled: 2119152\n",
      "    num_steps_trained: 2119152\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.68333333333334\n",
      "    ram_util_percent: 55.822072072072054\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045774515965760015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.69259494417616\n",
      "    mean_inference_ms: 2.8622299345804096\n",
      "    mean_raw_obs_processing_ms: 2.8999847163943437\n",
      "  time_since_restore: 31974.432628154755\n",
      "  time_this_iter_s: 155.46169090270996\n",
      "  time_total_s: 31974.432628154755\n",
      "  timers:\n",
      "    learn_throughput: 935.214\n",
      "    learn_time_ms: 10688.46\n",
      "    load_throughput: 91731.289\n",
      "    load_time_ms: 108.97\n",
      "    sample_throughput: 64.61\n",
      "    sample_time_ms: 154712.701\n",
      "    update_time_ms: 10.063\n",
      "  timestamp: 1636326391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2119152\n",
      "  training_iteration: 212\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">         31974.4</td><td style=\"text-align: right;\">2119152</td><td style=\"text-align: right;\"> 2.50257</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           89.3363</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2129148\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-08-53\n",
      "  done: false\n",
      "  episode_len_mean: 88.72321428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.240000000000013\n",
      "  episode_reward_mean: 2.7633035714285774\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 22975\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4159343322118123\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012885501794904256\n",
      "          policy_loss: -0.08312856007335533\n",
      "          total_loss: 0.03227042329823996\n",
      "          vf_explained_var: 0.9275467991828918\n",
      "          vf_loss: 0.11020354198403338\n",
      "    num_agent_steps_sampled: 2129148\n",
      "    num_agent_steps_trained: 2129148\n",
      "    num_steps_sampled: 2129148\n",
      "    num_steps_trained: 2129148\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95742574257424\n",
      "    ram_util_percent: 55.71683168316832\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04579543902918775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.703391673022914\n",
      "    mean_inference_ms: 2.8626776682891415\n",
      "    mean_raw_obs_processing_ms: 2.888505128616719\n",
      "  time_since_restore: 32116.431163072586\n",
      "  time_this_iter_s: 141.99853491783142\n",
      "  time_total_s: 32116.431163072586\n",
      "  timers:\n",
      "    learn_throughput: 935.56\n",
      "    learn_time_ms: 10684.512\n",
      "    load_throughput: 91747.609\n",
      "    load_time_ms: 108.951\n",
      "    sample_throughput: 65.161\n",
      "    sample_time_ms: 153404.513\n",
      "    update_time_ms: 9.727\n",
      "  timestamp: 1636326533\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2129148\n",
      "  training_iteration: 213\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   213</td><td style=\"text-align: right;\">         32116.4</td><td style=\"text-align: right;\">2129148</td><td style=\"text-align: right;\">  2.7633</td><td style=\"text-align: right;\">               11.24</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           88.7232</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2139144\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-11-29\n",
      "  done: false\n",
      "  episode_len_mean: 88.60176991150442\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.930000000000012\n",
      "  episode_reward_mean: 2.756371681415936\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 23088\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.421661371247381\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012866189527687111\n",
      "          policy_loss: -0.08258165072999958\n",
      "          total_loss: 0.033234769221331575\n",
      "          vf_explained_var: 0.9276599884033203\n",
      "          vf_loss: 0.11072224428017552\n",
      "    num_agent_steps_sampled: 2139144\n",
      "    num_agent_steps_trained: 2139144\n",
      "    num_steps_sampled: 2139144\n",
      "    num_steps_trained: 2139144\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.79820627802691\n",
      "    ram_util_percent: 55.630941704035884\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457981774035563\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.71015992189225\n",
      "    mean_inference_ms: 2.8625400550555953\n",
      "    mean_raw_obs_processing_ms: 2.894757505427084\n",
      "  time_since_restore: 32272.412789583206\n",
      "  time_this_iter_s: 155.98162651062012\n",
      "  time_total_s: 32272.412789583206\n",
      "  timers:\n",
      "    learn_throughput: 936.196\n",
      "    learn_time_ms: 10677.256\n",
      "    load_throughput: 91786.154\n",
      "    load_time_ms: 108.905\n",
      "    sample_throughput: 65.008\n",
      "    sample_time_ms: 153765.619\n",
      "    update_time_ms: 10.679\n",
      "  timestamp: 1636326689\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2139144\n",
      "  training_iteration: 214\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   214</td><td style=\"text-align: right;\">         32272.4</td><td style=\"text-align: right;\">2139144</td><td style=\"text-align: right;\"> 2.75637</td><td style=\"text-align: right;\">               14.93</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           88.6018</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2149140\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-14-02\n",
      "  done: false\n",
      "  episode_len_mean: 89.98198198198199\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.790000000000003\n",
      "  episode_reward_mean: 2.8933333333333398\n",
      "  episode_reward_min: -1.6400000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 23199\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.423554398259546\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012771939072397091\n",
      "          policy_loss: -0.0805169635046369\n",
      "          total_loss: 0.038291788715709985\n",
      "          vf_explained_var: 0.9208767414093018\n",
      "          vf_loss: 0.11394822071823808\n",
      "    num_agent_steps_sampled: 2149140\n",
      "    num_agent_steps_trained: 2149140\n",
      "    num_steps_sampled: 2149140\n",
      "    num_steps_trained: 2149140\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.47385321100916\n",
      "    ram_util_percent: 55.749541284403676\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577201495648789\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.7143125724759\n",
      "    mean_inference_ms: 2.8625411811512556\n",
      "    mean_raw_obs_processing_ms: 2.891614214494898\n",
      "  time_since_restore: 32425.13389825821\n",
      "  time_this_iter_s: 152.72110867500305\n",
      "  time_total_s: 32425.13389825821\n",
      "  timers:\n",
      "    learn_throughput: 935.876\n",
      "    learn_time_ms: 10680.897\n",
      "    load_throughput: 91613.269\n",
      "    load_time_ms: 109.111\n",
      "    sample_throughput: 64.803\n",
      "    sample_time_ms: 154252.924\n",
      "    update_time_ms: 11.167\n",
      "  timestamp: 1636326842\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2149140\n",
      "  training_iteration: 215\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   215</td><td style=\"text-align: right;\">         32425.1</td><td style=\"text-align: right;\">2149140</td><td style=\"text-align: right;\"> 2.89333</td><td style=\"text-align: right;\">                9.79</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">            89.982</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2159136\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-16-47\n",
      "  done: false\n",
      "  episode_len_mean: 87.96460176991151\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.650000000000016\n",
      "  episode_reward_mean: 3.0870796460177052\n",
      "  episode_reward_min: -1.3700000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 23312\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4122575578526555\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013264917714080279\n",
      "          policy_loss: -0.08296794991176097\n",
      "          total_loss: 0.04605525458215648\n",
      "          vf_explained_var: 0.9286439418792725\n",
      "          vf_loss: 0.12292663884611849\n",
      "    num_agent_steps_sampled: 2159136\n",
      "    num_agent_steps_trained: 2159136\n",
      "    num_steps_sampled: 2159136\n",
      "    num_steps_trained: 2159136\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.70084745762712\n",
      "    ram_util_percent: 55.775000000000006\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04579351437553182\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.7175935272556\n",
      "    mean_inference_ms: 2.862306389999834\n",
      "    mean_raw_obs_processing_ms: 2.89901013056763\n",
      "  time_since_restore: 32590.74328494072\n",
      "  time_this_iter_s: 165.60938668251038\n",
      "  time_total_s: 32590.74328494072\n",
      "  timers:\n",
      "    learn_throughput: 936.136\n",
      "    learn_time_ms: 10677.932\n",
      "    load_throughput: 91587.112\n",
      "    load_time_ms: 109.142\n",
      "    sample_throughput: 63.657\n",
      "    sample_time_ms: 157028.646\n",
      "    update_time_ms: 10.447\n",
      "  timestamp: 1636327007\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2159136\n",
      "  training_iteration: 216\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   216</td><td style=\"text-align: right;\">         32590.7</td><td style=\"text-align: right;\">2159136</td><td style=\"text-align: right;\"> 3.08708</td><td style=\"text-align: right;\">               12.65</td><td style=\"text-align: right;\">               -1.37</td><td style=\"text-align: right;\">           87.9646</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2169132\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-19-25\n",
      "  done: false\n",
      "  episode_len_mean: 88.21929824561404\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.050000000000013\n",
      "  episode_reward_mean: 2.868245614035094\n",
      "  episode_reward_min: -1.2900000000000005\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 23426\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.399631421178834\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013619638698423205\n",
      "          policy_loss: -0.08246253994492511\n",
      "          total_loss: 0.047397060025260486\n",
      "          vf_explained_var: 0.9287212491035461\n",
      "          vf_loss: 0.12282867308260284\n",
      "    num_agent_steps_sampled: 2169132\n",
      "    num_agent_steps_trained: 2169132\n",
      "    num_steps_sampled: 2169132\n",
      "    num_steps_trained: 2169132\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.58977777777778\n",
      "    ram_util_percent: 55.71555555555555\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575600969417881\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.72603147923619\n",
      "    mean_inference_ms: 2.8621220728208496\n",
      "    mean_raw_obs_processing_ms: 2.896417812159927\n",
      "  time_since_restore: 32748.398188591003\n",
      "  time_this_iter_s: 157.6549036502838\n",
      "  time_total_s: 32748.398188591003\n",
      "  timers:\n",
      "    learn_throughput: 935.746\n",
      "    learn_time_ms: 10682.392\n",
      "    load_throughput: 91460.204\n",
      "    load_time_ms: 109.293\n",
      "    sample_throughput: 65.91\n",
      "    sample_time_ms: 151662.476\n",
      "    update_time_ms: 11.322\n",
      "  timestamp: 1636327165\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2169132\n",
      "  training_iteration: 217\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   217</td><td style=\"text-align: right;\">         32748.4</td><td style=\"text-align: right;\">2169132</td><td style=\"text-align: right;\"> 2.86825</td><td style=\"text-align: right;\">                9.05</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           88.2193</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2179128\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-22-20\n",
      "  done: false\n",
      "  episode_len_mean: 88.90090090090091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.170000000000012\n",
      "  episode_reward_mean: 3.2219819819819886\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 23537\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3896371168968007\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014100093666240885\n",
      "          policy_loss: -0.08305644752760219\n",
      "          total_loss: 0.05995728182248198\n",
      "          vf_explained_var: 0.9278818964958191\n",
      "          vf_loss: 0.13478832351218942\n",
      "    num_agent_steps_sampled: 2179128\n",
      "    num_agent_steps_trained: 2179128\n",
      "    num_steps_sampled: 2179128\n",
      "    num_steps_trained: 2179128\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.4752\n",
      "    ram_util_percent: 55.6844\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04578660087229911\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.724809672898544\n",
      "    mean_inference_ms: 2.861865866956976\n",
      "    mean_raw_obs_processing_ms: 2.9090257140615803\n",
      "  time_since_restore: 32923.38484239578\n",
      "  time_this_iter_s: 174.98665380477905\n",
      "  time_total_s: 32923.38484239578\n",
      "  timers:\n",
      "    learn_throughput: 935.219\n",
      "    learn_time_ms: 10688.402\n",
      "    load_throughput: 91554.632\n",
      "    load_time_ms: 109.181\n",
      "    sample_throughput: 66.601\n",
      "    sample_time_ms: 150086.722\n",
      "    update_time_ms: 10.135\n",
      "  timestamp: 1636327340\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2179128\n",
      "  training_iteration: 218\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">         32923.4</td><td style=\"text-align: right;\">2179128</td><td style=\"text-align: right;\"> 3.22198</td><td style=\"text-align: right;\">               11.17</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           88.9009</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2189124\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-25-10\n",
      "  done: false\n",
      "  episode_len_mean: 88.04347826086956\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.100000000000016\n",
      "  episode_reward_mean: 2.9966956521739183\n",
      "  episode_reward_min: -1.6300000000000006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 23652\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.394678037798303\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01410589935626363\n",
      "          policy_loss: -0.07725582011044026\n",
      "          total_loss: 0.07793006231196416\n",
      "          vf_explained_var: 0.9190701246261597\n",
      "          vf_loss: 0.14699766056723573\n",
      "    num_agent_steps_sampled: 2189124\n",
      "    num_agent_steps_trained: 2189124\n",
      "    num_steps_sampled: 2189124\n",
      "    num_steps_trained: 2189124\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.89094650205762\n",
      "    ram_util_percent: 55.67160493827161\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045780006093352664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.732992634687236\n",
      "    mean_inference_ms: 2.861963277560965\n",
      "    mean_raw_obs_processing_ms: 2.914433704220216\n",
      "  time_since_restore: 33093.75122523308\n",
      "  time_this_iter_s: 170.36638283729553\n",
      "  time_total_s: 33093.75122523308\n",
      "  timers:\n",
      "    learn_throughput: 935.322\n",
      "    learn_time_ms: 10687.225\n",
      "    load_throughput: 91589.893\n",
      "    load_time_ms: 109.139\n",
      "    sample_throughput: 67.285\n",
      "    sample_time_ms: 148561.36\n",
      "    update_time_ms: 11.272\n",
      "  timestamp: 1636327510\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2189124\n",
      "  training_iteration: 219\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   219</td><td style=\"text-align: right;\">         33093.8</td><td style=\"text-align: right;\">2189124</td><td style=\"text-align: right;\">  2.9967</td><td style=\"text-align: right;\">                15.1</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           88.0435</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2199120\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-27-48\n",
      "  done: false\n",
      "  episode_len_mean: 87.31304347826087\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.670000000000016\n",
      "  episode_reward_mean: 3.0933913043478327\n",
      "  episode_reward_min: -1.6200000000000008\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 23767\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3846114637505296\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014280239277918662\n",
      "          policy_loss: -0.08118791078519809\n",
      "          total_loss: 0.06543801742661585\n",
      "          vf_explained_var: 0.9241780638694763\n",
      "          vf_loss: 0.13793987111212352\n",
      "    num_agent_steps_sampled: 2199120\n",
      "    num_agent_steps_trained: 2199120\n",
      "    num_steps_sampled: 2199120\n",
      "    num_steps_trained: 2199120\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.93526785714286\n",
      "    ram_util_percent: 55.59196428571429\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457519388985068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.73841484529788\n",
      "    mean_inference_ms: 2.861747215667431\n",
      "    mean_raw_obs_processing_ms: 2.9201076678038853\n",
      "  time_since_restore: 33250.83600473404\n",
      "  time_this_iter_s: 157.0847795009613\n",
      "  time_total_s: 33250.83600473404\n",
      "  timers:\n",
      "    learn_throughput: 935.069\n",
      "    learn_time_ms: 10690.122\n",
      "    load_throughput: 91373.198\n",
      "    load_time_ms: 109.398\n",
      "    sample_throughput: 67.206\n",
      "    sample_time_ms: 148736.701\n",
      "    update_time_ms: 11.628\n",
      "  timestamp: 1636327668\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2199120\n",
      "  training_iteration: 220\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   220</td><td style=\"text-align: right;\">         33250.8</td><td style=\"text-align: right;\">2199120</td><td style=\"text-align: right;\"> 3.09339</td><td style=\"text-align: right;\">               10.67</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">            87.313</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2209116\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-30-10\n",
      "  done: false\n",
      "  episode_len_mean: 90.44954128440367\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.310000000000016\n",
      "  episode_reward_mean: 3.0260550458715665\n",
      "  episode_reward_min: -1.5600000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 23876\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4041725077180782\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013387728774380415\n",
      "          policy_loss: -0.08432606907927583\n",
      "          total_loss: 0.046416815558177796\n",
      "          vf_explained_var: 0.9218944311141968\n",
      "          vf_loss: 0.1242856886731381\n",
      "    num_agent_steps_sampled: 2209116\n",
      "    num_agent_steps_trained: 2209116\n",
      "    num_steps_sampled: 2209116\n",
      "    num_steps_trained: 2209116\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08128078817734\n",
      "    ram_util_percent: 55.55467980295566\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577347155007086\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.74992823123769\n",
      "    mean_inference_ms: 2.861944560782075\n",
      "    mean_raw_obs_processing_ms: 2.911052455395239\n",
      "  time_since_restore: 33393.13650202751\n",
      "  time_this_iter_s: 142.3004972934723\n",
      "  time_total_s: 33393.13650202751\n",
      "  timers:\n",
      "    learn_throughput: 934.648\n",
      "    learn_time_ms: 10694.94\n",
      "    load_throughput: 91337.088\n",
      "    load_time_ms: 109.441\n",
      "    sample_throughput: 68.192\n",
      "    sample_time_ms: 146586.236\n",
      "    update_time_ms: 11.983\n",
      "  timestamp: 1636327810\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2209116\n",
      "  training_iteration: 221\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   221</td><td style=\"text-align: right;\">         33393.1</td><td style=\"text-align: right;\">2209116</td><td style=\"text-align: right;\"> 3.02606</td><td style=\"text-align: right;\">               12.31</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           90.4495</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2219112\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-32-46\n",
      "  done: false\n",
      "  episode_len_mean: 90.10714285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.390000000000017\n",
      "  episode_reward_mean: 3.044196428571435\n",
      "  episode_reward_min: -2.060000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 23988\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.394341374054933\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012726435035454632\n",
      "          policy_loss: -0.0853504970876707\n",
      "          total_loss: 0.030381765313701244\n",
      "          vf_explained_var: 0.9268773794174194\n",
      "          vf_loss: 0.11068326431111647\n",
      "    num_agent_steps_sampled: 2219112\n",
      "    num_agent_steps_trained: 2219112\n",
      "    num_steps_sampled: 2219112\n",
      "    num_steps_trained: 2219112\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.42657657657658\n",
      "    ram_util_percent: 55.709459459459445\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04580057760772583\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.75368212923174\n",
      "    mean_inference_ms: 2.862102817266209\n",
      "    mean_raw_obs_processing_ms: 2.9094888528987033\n",
      "  time_since_restore: 33548.76115846634\n",
      "  time_this_iter_s: 155.62465643882751\n",
      "  time_total_s: 33548.76115846634\n",
      "  timers:\n",
      "    learn_throughput: 933.698\n",
      "    learn_time_ms: 10705.813\n",
      "    load_throughput: 91355.876\n",
      "    load_time_ms: 109.418\n",
      "    sample_throughput: 68.189\n",
      "    sample_time_ms: 146592.225\n",
      "    update_time_ms: 11.805\n",
      "  timestamp: 1636327966\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2219112\n",
      "  training_iteration: 222\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   222</td><td style=\"text-align: right;\">         33548.8</td><td style=\"text-align: right;\">2219112</td><td style=\"text-align: right;\">  3.0442</td><td style=\"text-align: right;\">               10.39</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           90.1071</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2229108\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-35-19\n",
      "  done: false\n",
      "  episode_len_mean: 90.34234234234235\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.810000000000016\n",
      "  episode_reward_mean: 2.853333333333339\n",
      "  episode_reward_min: -1.990000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 24099\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.407589753265055\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013830805523344319\n",
      "          policy_loss: -0.08537161463043756\n",
      "          total_loss: 0.04543645109535537\n",
      "          vf_explained_var: 0.9230453372001648\n",
      "          vf_loss: 0.12337565811541983\n",
      "    num_agent_steps_sampled: 2229108\n",
      "    num_agent_steps_trained: 2229108\n",
      "    num_steps_sampled: 2229108\n",
      "    num_steps_trained: 2229108\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.81461187214613\n",
      "    ram_util_percent: 55.71872146118721\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045743414586629665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.759889567798574\n",
      "    mean_inference_ms: 2.8618945744474873\n",
      "    mean_raw_obs_processing_ms: 2.9053206344912685\n",
      "  time_since_restore: 33702.09896349907\n",
      "  time_this_iter_s: 153.3378050327301\n",
      "  time_total_s: 33702.09896349907\n",
      "  timers:\n",
      "    learn_throughput: 933.209\n",
      "    learn_time_ms: 10711.429\n",
      "    load_throughput: 91282.163\n",
      "    load_time_ms: 109.507\n",
      "    sample_throughput: 67.669\n",
      "    sample_time_ms: 147719.161\n",
      "    update_time_ms: 12.557\n",
      "  timestamp: 1636328119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2229108\n",
      "  training_iteration: 223\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   223</td><td style=\"text-align: right;\">         33702.1</td><td style=\"text-align: right;\">2229108</td><td style=\"text-align: right;\"> 2.85333</td><td style=\"text-align: right;\">               12.81</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           90.3423</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2239104\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-37-51\n",
      "  done: false\n",
      "  episode_len_mean: 90.63302752293578\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.310000000000016\n",
      "  episode_reward_mean: 2.45550458715597\n",
      "  episode_reward_min: -1.7099999999999942\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 24208\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.40388445263235\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013458997171704064\n",
      "          policy_loss: -0.08324952856120137\n",
      "          total_loss: 0.03628784605405397\n",
      "          vf_explained_var: 0.9250745177268982\n",
      "          vf_loss: 0.11291494032479504\n",
      "    num_agent_steps_sampled: 2239104\n",
      "    num_agent_steps_trained: 2239104\n",
      "    num_steps_sampled: 2239104\n",
      "    num_steps_trained: 2239104\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.85115207373273\n",
      "    ram_util_percent: 55.65161290322581\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574441076793766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.76352645875394\n",
      "    mean_inference_ms: 2.8619173654842123\n",
      "    mean_raw_obs_processing_ms: 2.903644546502757\n",
      "  time_since_restore: 33853.82333731651\n",
      "  time_this_iter_s: 151.72437381744385\n",
      "  time_total_s: 33853.82333731651\n",
      "  timers:\n",
      "    learn_throughput: 932.282\n",
      "    learn_time_ms: 10722.079\n",
      "    load_throughput: 91207.816\n",
      "    load_time_ms: 109.596\n",
      "    sample_throughput: 67.869\n",
      "    sample_time_ms: 147282.823\n",
      "    update_time_ms: 12.384\n",
      "  timestamp: 1636328271\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2239104\n",
      "  training_iteration: 224\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">         33853.8</td><td style=\"text-align: right;\">2239104</td><td style=\"text-align: right;\">  2.4555</td><td style=\"text-align: right;\">               10.31</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">            90.633</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2249100\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-40-23\n",
      "  done: false\n",
      "  episode_len_mean: 89.45535714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.160000000000013\n",
      "  episode_reward_mean: 3.201428571428579\n",
      "  episode_reward_min: -1.960000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 24320\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3820755532664113\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013474978417220604\n",
      "          policy_loss: -0.08287762166916306\n",
      "          total_loss: 0.04309471701072831\n",
      "          vf_explained_var: 0.9399086236953735\n",
      "          vf_loss: 0.11909540862354458\n",
      "    num_agent_steps_sampled: 2249100\n",
      "    num_agent_steps_trained: 2249100\n",
      "    num_steps_sampled: 2249100\n",
      "    num_steps_trained: 2249100\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.57870370370371\n",
      "    ram_util_percent: 55.7287037037037\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576535424202487\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.767388425968626\n",
      "    mean_inference_ms: 2.861997390755415\n",
      "    mean_raw_obs_processing_ms: 2.902896459687961\n",
      "  time_since_restore: 34005.717302560806\n",
      "  time_this_iter_s: 151.8939652442932\n",
      "  time_total_s: 34005.717302560806\n",
      "  timers:\n",
      "    learn_throughput: 932.147\n",
      "    learn_time_ms: 10723.625\n",
      "    load_throughput: 91253.216\n",
      "    load_time_ms: 109.541\n",
      "    sample_throughput: 67.908\n",
      "    sample_time_ms: 147198.672\n",
      "    update_time_ms: 12.416\n",
      "  timestamp: 1636328423\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2249100\n",
      "  training_iteration: 225\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   225</td><td style=\"text-align: right;\">         34005.7</td><td style=\"text-align: right;\">2249100</td><td style=\"text-align: right;\"> 3.20143</td><td style=\"text-align: right;\">                9.16</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">           89.4554</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2259096\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-42-58\n",
      "  done: false\n",
      "  episode_len_mean: 89.14159292035399\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.790000000000013\n",
      "  episode_reward_mean: 2.9366371681416\n",
      "  episode_reward_min: -1.640000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 24433\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3876679583492444\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013503344914972834\n",
      "          policy_loss: -0.08464182576435245\n",
      "          total_loss: 0.040586585677268666\n",
      "          vf_explained_var: 0.936714768409729\n",
      "          vf_loss: 0.11834278514799781\n",
      "    num_agent_steps_sampled: 2259096\n",
      "    num_agent_steps_trained: 2259096\n",
      "    num_steps_sampled: 2259096\n",
      "    num_steps_trained: 2259096\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.6099547511312\n",
      "    ram_util_percent: 55.719004524886884\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045763295089996964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.77344399466506\n",
      "    mean_inference_ms: 2.8619403654154656\n",
      "    mean_raw_obs_processing_ms: 2.901476138128881\n",
      "  time_since_restore: 34160.4965801239\n",
      "  time_this_iter_s: 154.7792775630951\n",
      "  time_total_s: 34160.4965801239\n",
      "  timers:\n",
      "    learn_throughput: 931.436\n",
      "    learn_time_ms: 10731.813\n",
      "    load_throughput: 91272.843\n",
      "    load_time_ms: 109.518\n",
      "    sample_throughput: 68.416\n",
      "    sample_time_ms: 146107.199\n",
      "    update_time_ms: 12.666\n",
      "  timestamp: 1636328578\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2259096\n",
      "  training_iteration: 226\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   226</td><td style=\"text-align: right;\">         34160.5</td><td style=\"text-align: right;\">2259096</td><td style=\"text-align: right;\"> 2.93664</td><td style=\"text-align: right;\">               10.79</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           89.1416</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2269092\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-46-06\n",
      "  done: false\n",
      "  episode_len_mean: 86.56896551724138\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.070000000000007\n",
      "  episode_reward_mean: 3.248620689655179\n",
      "  episode_reward_min: -1.9700000000000009\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 24549\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.377033751235049\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01370186157619514\n",
      "          policy_loss: -0.08108604382245968\n",
      "          total_loss: 0.06488989037580979\n",
      "          vf_explained_var: 0.9226114153862\n",
      "          vf_loss: 0.13853171796848376\n",
      "    num_agent_steps_sampled: 2269092\n",
      "    num_agent_steps_trained: 2269092\n",
      "    num_steps_sampled: 2269092\n",
      "    num_steps_trained: 2269092\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.10777777777777\n",
      "    ram_util_percent: 55.7037037037037\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045755605973846085\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.780625837751145\n",
      "    mean_inference_ms: 2.8619236442099\n",
      "    mean_raw_obs_processing_ms: 2.920816571841748\n",
      "  time_since_restore: 34349.206139564514\n",
      "  time_this_iter_s: 188.7095594406128\n",
      "  time_total_s: 34349.206139564514\n",
      "  timers:\n",
      "    learn_throughput: 931.955\n",
      "    learn_time_ms: 10725.836\n",
      "    load_throughput: 91271.612\n",
      "    load_time_ms: 109.519\n",
      "    sample_throughput: 66.988\n",
      "    sample_time_ms: 149219.659\n",
      "    update_time_ms: 11.786\n",
      "  timestamp: 1636328766\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2269092\n",
      "  training_iteration: 227\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   227</td><td style=\"text-align: right;\">         34349.2</td><td style=\"text-align: right;\">2269092</td><td style=\"text-align: right;\"> 3.24862</td><td style=\"text-align: right;\">               11.07</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">            86.569</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2279088\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-48-44\n",
      "  done: false\n",
      "  episode_len_mean: 88.00884955752213\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.650000000000016\n",
      "  episode_reward_mean: 3.343274336283193\n",
      "  episode_reward_min: -1.4700000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 24662\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.384485812880035\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013746053110921173\n",
      "          policy_loss: -0.0839869175854529\n",
      "          total_loss: 0.04936821626610736\n",
      "          vf_explained_var: 0.9346886277198792\n",
      "          vf_loss: 0.1258847642594423\n",
      "    num_agent_steps_sampled: 2279088\n",
      "    num_agent_steps_trained: 2279088\n",
      "    num_steps_sampled: 2279088\n",
      "    num_steps_trained: 2279088\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.75357142857145\n",
      "    ram_util_percent: 55.83571428571429\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045741488920722946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.790182234046014\n",
      "    mean_inference_ms: 2.8617746998833775\n",
      "    mean_raw_obs_processing_ms: 2.918751749079035\n",
      "  time_since_restore: 34506.60665893555\n",
      "  time_this_iter_s: 157.40051937103271\n",
      "  time_total_s: 34506.60665893555\n",
      "  timers:\n",
      "    learn_throughput: 932.125\n",
      "    learn_time_ms: 10723.885\n",
      "    load_throughput: 91125.963\n",
      "    load_time_ms: 109.694\n",
      "    sample_throughput: 67.787\n",
      "    sample_time_ms: 147462.118\n",
      "    update_time_ms: 12.304\n",
      "  timestamp: 1636328924\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2279088\n",
      "  training_iteration: 228\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   228</td><td style=\"text-align: right;\">         34506.6</td><td style=\"text-align: right;\">2279088</td><td style=\"text-align: right;\"> 3.34327</td><td style=\"text-align: right;\">               10.65</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           88.0088</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2289084\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-51-52\n",
      "  done: false\n",
      "  episode_len_mean: 88.40707964601769\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.020000000000014\n",
      "  episode_reward_mean: 3.6395575221239023\n",
      "  episode_reward_min: -1.4200000000000004\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 24775\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3576839330868844\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0136889501531214\n",
      "          policy_loss: -0.08305489772882982\n",
      "          total_loss: 0.048104871669386186\n",
      "          vf_explained_var: 0.943844735622406\n",
      "          vf_loss: 0.12355146749725199\n",
      "    num_agent_steps_sampled: 2289084\n",
      "    num_agent_steps_trained: 2289084\n",
      "    num_steps_sampled: 2289084\n",
      "    num_steps_trained: 2289084\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.40557620817843\n",
      "    ram_util_percent: 55.87100371747213\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045757234377824973\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.7956986934161\n",
      "    mean_inference_ms: 2.8617182034651516\n",
      "    mean_raw_obs_processing_ms: 2.933269742364326\n",
      "  time_since_restore: 34694.68785762787\n",
      "  time_this_iter_s: 188.08119869232178\n",
      "  time_total_s: 34694.68785762787\n",
      "  timers:\n",
      "    learn_throughput: 931.877\n",
      "    learn_time_ms: 10726.743\n",
      "    load_throughput: 91172.551\n",
      "    load_time_ms: 109.638\n",
      "    sample_throughput: 66.983\n",
      "    sample_time_ms: 149231.769\n",
      "    update_time_ms: 11.319\n",
      "  timestamp: 1636329112\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2289084\n",
      "  training_iteration: 229\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   229</td><td style=\"text-align: right;\">         34694.7</td><td style=\"text-align: right;\">2289084</td><td style=\"text-align: right;\"> 3.63956</td><td style=\"text-align: right;\">               11.02</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           88.4071</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2299080\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-54-14\n",
      "  done: false\n",
      "  episode_len_mean: 89.50892857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 3.15785714285715\n",
      "  episode_reward_min: -1.9400000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 24887\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3759879605382936\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013375503554459019\n",
      "          policy_loss: -0.08223243140352843\n",
      "          total_loss: 0.04723051572138937\n",
      "          vf_explained_var: 0.934721827507019\n",
      "          vf_loss: 0.12275175644228091\n",
      "    num_agent_steps_sampled: 2299080\n",
      "    num_agent_steps_trained: 2299080\n",
      "    num_steps_sampled: 2299080\n",
      "    num_steps_trained: 2299080\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0509900990099\n",
      "    ram_util_percent: 55.68316831683168\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576576356678576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.80447894617139\n",
      "    mean_inference_ms: 2.8620486635051035\n",
      "    mean_raw_obs_processing_ms: 2.9227493409356566\n",
      "  time_since_restore: 34836.74809408188\n",
      "  time_this_iter_s: 142.06023645401\n",
      "  time_total_s: 34836.74809408188\n",
      "  timers:\n",
      "    learn_throughput: 931.979\n",
      "    learn_time_ms: 10725.559\n",
      "    load_throughput: 91344.372\n",
      "    load_time_ms: 109.432\n",
      "    sample_throughput: 67.663\n",
      "    sample_time_ms: 147731.063\n",
      "    update_time_ms: 10.82\n",
      "  timestamp: 1636329254\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2299080\n",
      "  training_iteration: 230\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">         34836.7</td><td style=\"text-align: right;\">2299080</td><td style=\"text-align: right;\"> 3.15786</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           89.5089</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2309076\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-56-52\n",
      "  done: false\n",
      "  episode_len_mean: 87.58407079646018\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.570000000000016\n",
      "  episode_reward_mean: 2.8202654867256705\n",
      "  episode_reward_min: -1.7500000000000009\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 25000\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.381718896800636\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01319412683721822\n",
      "          policy_loss: -0.0828968358783322\n",
      "          total_loss: 0.032349580610728165\n",
      "          vf_explained_var: 0.924372136592865\n",
      "          vf_loss: 0.10900573260509051\n",
      "    num_agent_steps_sampled: 2309076\n",
      "    num_agent_steps_trained: 2309076\n",
      "    num_steps_sampled: 2309076\n",
      "    num_steps_trained: 2309076\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.85707964601772\n",
      "    ram_util_percent: 55.74690265486726\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045753163677545276\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.81162734479757\n",
      "    mean_inference_ms: 2.8620238280777985\n",
      "    mean_raw_obs_processing_ms: 2.9274046577565858\n",
      "  time_since_restore: 34994.8672618866\n",
      "  time_this_iter_s: 158.11916780471802\n",
      "  time_total_s: 34994.8672618866\n",
      "  timers:\n",
      "    learn_throughput: 932.415\n",
      "    learn_time_ms: 10720.548\n",
      "    load_throughput: 91087.417\n",
      "    load_time_ms: 109.741\n",
      "    sample_throughput: 66.945\n",
      "    sample_time_ms: 149317.234\n",
      "    update_time_ms: 10.667\n",
      "  timestamp: 1636329412\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2309076\n",
      "  training_iteration: 231\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   231</td><td style=\"text-align: right;\">         34994.9</td><td style=\"text-align: right;\">2309076</td><td style=\"text-align: right;\"> 2.82027</td><td style=\"text-align: right;\">               10.57</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           87.5841</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2319072\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-07_23-59-43\n",
      "  done: false\n",
      "  episode_len_mean: 89.0625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.860000000000001\n",
      "  episode_reward_mean: 2.983035714285721\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 25112\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.393980205568493\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013574260351931305\n",
      "          policy_loss: -0.08300689376381218\n",
      "          total_loss: 0.04918343280083858\n",
      "          vf_explained_var: 0.9224579334259033\n",
      "          vf_loss: 0.1252062648662135\n",
      "    num_agent_steps_sampled: 2319072\n",
      "    num_agent_steps_trained: 2319072\n",
      "    num_steps_sampled: 2319072\n",
      "    num_steps_trained: 2319072\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.7872950819672\n",
      "    ram_util_percent: 55.932377049180346\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574476721973597\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.8115339732325\n",
      "    mean_inference_ms: 2.8618537141764477\n",
      "    mean_raw_obs_processing_ms: 2.9344305659327192\n",
      "  time_since_restore: 35165.75548553467\n",
      "  time_this_iter_s: 170.8882236480713\n",
      "  time_total_s: 35165.75548553467\n",
      "  timers:\n",
      "    learn_throughput: 932.874\n",
      "    learn_time_ms: 10715.271\n",
      "    load_throughput: 91012.576\n",
      "    load_time_ms: 109.831\n",
      "    sample_throughput: 66.265\n",
      "    sample_time_ms: 150848.647\n",
      "    update_time_ms: 11.032\n",
      "  timestamp: 1636329583\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2319072\n",
      "  training_iteration: 232\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   232</td><td style=\"text-align: right;\">         35165.8</td><td style=\"text-align: right;\">2319072</td><td style=\"text-align: right;\"> 2.98304</td><td style=\"text-align: right;\">                9.86</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           89.0625</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2329068\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-02-26\n",
      "  done: false\n",
      "  episode_len_mean: 88.93805309734513\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.700000000000014\n",
      "  episode_reward_mean: 3.009911504424786\n",
      "  episode_reward_min: -1.6100000000000008\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 25225\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3923714242429814\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014613870444713599\n",
      "          policy_loss: -0.07793599477547229\n",
      "          total_loss: 0.05117720916994616\n",
      "          vf_explained_var: 0.9286001324653625\n",
      "          vf_loss: 0.11974469303416135\n",
      "    num_agent_steps_sampled: 2329068\n",
      "    num_agent_steps_trained: 2329068\n",
      "    num_steps_sampled: 2329068\n",
      "    num_steps_trained: 2329068\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.56551724137931\n",
      "    ram_util_percent: 55.72025862068965\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576551592308724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.81704785941496\n",
      "    mean_inference_ms: 2.8617084809592392\n",
      "    mean_raw_obs_processing_ms: 2.9436404309478266\n",
      "  time_since_restore: 35328.64393186569\n",
      "  time_this_iter_s: 162.88844633102417\n",
      "  time_total_s: 35328.64393186569\n",
      "  timers:\n",
      "    learn_throughput: 933.367\n",
      "    learn_time_ms: 10709.609\n",
      "    load_throughput: 90892.12\n",
      "    load_time_ms: 109.977\n",
      "    sample_throughput: 65.845\n",
      "    sample_time_ms: 151809.978\n",
      "    update_time_ms: 10.55\n",
      "  timestamp: 1636329746\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2329068\n",
      "  training_iteration: 233\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   233</td><td style=\"text-align: right;\">         35328.6</td><td style=\"text-align: right;\">2329068</td><td style=\"text-align: right;\"> 3.00991</td><td style=\"text-align: right;\">                10.7</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           88.9381</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2339064\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-05-19\n",
      "  done: false\n",
      "  episode_len_mean: 91.26363636363637\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.190000000000012\n",
      "  episode_reward_mean: 2.7405454545454613\n",
      "  episode_reward_min: -1.7500000000000009\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 25335\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3998292503193914\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013362683813476281\n",
      "          policy_loss: -0.08489182373811292\n",
      "          total_loss: 0.032122795240810284\n",
      "          vf_explained_var: 0.9247320890426636\n",
      "          vf_loss: 0.11057104621257664\n",
      "    num_agent_steps_sampled: 2339064\n",
      "    num_agent_steps_trained: 2339064\n",
      "    num_steps_sampled: 2339064\n",
      "    num_steps_trained: 2339064\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.10564516129033\n",
      "    ram_util_percent: 55.979838709677416\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576769910003457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.82601504996347\n",
      "    mean_inference_ms: 2.86171676309617\n",
      "    mean_raw_obs_processing_ms: 2.9470529072146125\n",
      "  time_since_restore: 35502.06164979935\n",
      "  time_this_iter_s: 173.41771793365479\n",
      "  time_total_s: 35502.06164979935\n",
      "  timers:\n",
      "    learn_throughput: 933.98\n",
      "    learn_time_ms: 10702.588\n",
      "    load_throughput: 90909.168\n",
      "    load_time_ms: 109.956\n",
      "    sample_throughput: 64.914\n",
      "    sample_time_ms: 153987.271\n",
      "    update_time_ms: 9.828\n",
      "  timestamp: 1636329919\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2339064\n",
      "  training_iteration: 234\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   234</td><td style=\"text-align: right;\">         35502.1</td><td style=\"text-align: right;\">2339064</td><td style=\"text-align: right;\"> 2.74055</td><td style=\"text-align: right;\">                9.19</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           91.2636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2349060\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-07-56\n",
      "  done: false\n",
      "  episode_len_mean: 90.38532110091744\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.430000000000009\n",
      "  episode_reward_mean: 3.0370642201834923\n",
      "  episode_reward_min: -1.3200000000000003\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 25444\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3913690444750664\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013217811902140393\n",
      "          policy_loss: -0.083203156470743\n",
      "          total_loss: 0.04064760210040288\n",
      "          vf_explained_var: 0.9220372438430786\n",
      "          vf_loss: 0.11765261951069801\n",
      "    num_agent_steps_sampled: 2349060\n",
      "    num_agent_steps_trained: 2349060\n",
      "    num_steps_sampled: 2349060\n",
      "    num_steps_trained: 2349060\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.78834080717489\n",
      "    ram_util_percent: 55.726008968609875\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045752036593689475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.83429988901348\n",
      "    mean_inference_ms: 2.861802091035686\n",
      "    mean_raw_obs_processing_ms: 2.9434587333097206\n",
      "  time_since_restore: 35658.408719062805\n",
      "  time_this_iter_s: 156.34706926345825\n",
      "  time_total_s: 35658.408719062805\n",
      "  timers:\n",
      "    learn_throughput: 933.963\n",
      "    learn_time_ms: 10702.779\n",
      "    load_throughput: 91000.802\n",
      "    load_time_ms: 109.845\n",
      "    sample_throughput: 64.727\n",
      "    sample_time_ms: 154432.053\n",
      "    update_time_ms: 9.981\n",
      "  timestamp: 1636330076\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2349060\n",
      "  training_iteration: 235\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   235</td><td style=\"text-align: right;\">         35658.4</td><td style=\"text-align: right;\">2349060</td><td style=\"text-align: right;\"> 3.03706</td><td style=\"text-align: right;\">                9.43</td><td style=\"text-align: right;\">               -1.32</td><td style=\"text-align: right;\">           90.3853</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2359056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-10-34\n",
      "  done: false\n",
      "  episode_len_mean: 90.16814159292035\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.710000000000013\n",
      "  episode_reward_mean: 3.0458407079646093\n",
      "  episode_reward_min: -2.0699999999999994\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 25557\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.382973528927208\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013054754264458762\n",
      "          policy_loss: -0.08221659087695372\n",
      "          total_loss: 0.04272654817487376\n",
      "          vf_explained_var: 0.9286047220230103\n",
      "          vf_loss: 0.1190325113108907\n",
      "    num_agent_steps_sampled: 2359056\n",
      "    num_agent_steps_trained: 2359056\n",
      "    num_steps_sampled: 2359056\n",
      "    num_steps_trained: 2359056\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.05265486725662\n",
      "    ram_util_percent: 55.79690265486726\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0457624592220207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.84557785664209\n",
      "    mean_inference_ms: 2.8617913290677026\n",
      "    mean_raw_obs_processing_ms: 2.941424713550513\n",
      "  time_since_restore: 35816.85854554176\n",
      "  time_this_iter_s: 158.44982647895813\n",
      "  time_total_s: 35816.85854554176\n",
      "  timers:\n",
      "    learn_throughput: 934.409\n",
      "    learn_time_ms: 10697.666\n",
      "    load_throughput: 91021.665\n",
      "    load_time_ms: 109.82\n",
      "    sample_throughput: 64.572\n",
      "    sample_time_ms: 154803.603\n",
      "    update_time_ms: 10.834\n",
      "  timestamp: 1636330234\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2359056\n",
      "  training_iteration: 236\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">         35816.9</td><td style=\"text-align: right;\">2359056</td><td style=\"text-align: right;\"> 3.04584</td><td style=\"text-align: right;\">               10.71</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           90.1681</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2369052\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-13-20\n",
      "  done: false\n",
      "  episode_len_mean: 89.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.640000000000013\n",
      "  episode_reward_mean: 3.095181818181825\n",
      "  episode_reward_min: -2.5300000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 25667\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.389985664278014\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013867084654004306\n",
      "          policy_loss: -0.08293770703717938\n",
      "          total_loss: 0.051845049852521245\n",
      "          vf_explained_var: 0.9222933650016785\n",
      "          vf_loss: 0.12709165998997216\n",
      "    num_agent_steps_sampled: 2369052\n",
      "    num_agent_steps_trained: 2369052\n",
      "    num_steps_sampled: 2369052\n",
      "    num_steps_trained: 2369052\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.03417721518987\n",
      "    ram_util_percent: 55.84978902953587\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576364406072772\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.84891647316905\n",
      "    mean_inference_ms: 2.861438453629184\n",
      "    mean_raw_obs_processing_ms: 2.946360397668451\n",
      "  time_since_restore: 35982.86308383942\n",
      "  time_this_iter_s: 166.0045382976532\n",
      "  time_total_s: 35982.86308383942\n",
      "  timers:\n",
      "    learn_throughput: 933.78\n",
      "    learn_time_ms: 10704.873\n",
      "    load_throughput: 91303.056\n",
      "    load_time_ms: 109.482\n",
      "    sample_throughput: 65.536\n",
      "    sample_time_ms: 152525.818\n",
      "    update_time_ms: 11.078\n",
      "  timestamp: 1636330400\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2369052\n",
      "  training_iteration: 237\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   237</td><td style=\"text-align: right;\">         35982.9</td><td style=\"text-align: right;\">2369052</td><td style=\"text-align: right;\"> 3.09518</td><td style=\"text-align: right;\">               12.64</td><td style=\"text-align: right;\">               -2.53</td><td style=\"text-align: right;\">              89.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2379048\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-16-05\n",
      "  done: false\n",
      "  episode_len_mean: 91.05454545454545\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.190000000000014\n",
      "  episode_reward_mean: 3.2118181818181903\n",
      "  episode_reward_min: -1.8000000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 25777\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3533908118549576\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013074791845927271\n",
      "          policy_loss: -0.08161853054602049\n",
      "          total_loss: 0.034925814548459576\n",
      "          vf_explained_var: 0.9384793639183044\n",
      "          vf_loss: 0.1102922436216066\n",
      "    num_agent_steps_sampled: 2379048\n",
      "    num_agent_steps_trained: 2379048\n",
      "    num_steps_sampled: 2379048\n",
      "    num_steps_trained: 2379048\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.54401709401711\n",
      "    ram_util_percent: 55.824786324786324\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045749502584086214\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.846811037151\n",
      "    mean_inference_ms: 2.861413179682292\n",
      "    mean_raw_obs_processing_ms: 2.949828918100288\n",
      "  time_since_restore: 36147.33508348465\n",
      "  time_this_iter_s: 164.47199964523315\n",
      "  time_total_s: 36147.33508348465\n",
      "  timers:\n",
      "    learn_throughput: 934.046\n",
      "    learn_time_ms: 10701.826\n",
      "    load_throughput: 91397.519\n",
      "    load_time_ms: 109.368\n",
      "    sample_throughput: 65.233\n",
      "    sample_time_ms: 153236.483\n",
      "    update_time_ms: 10.636\n",
      "  timestamp: 1636330565\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2379048\n",
      "  training_iteration: 238\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   238</td><td style=\"text-align: right;\">         36147.3</td><td style=\"text-align: right;\">2379048</td><td style=\"text-align: right;\"> 3.21182</td><td style=\"text-align: right;\">               12.19</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           91.0545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2389044\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-18-40\n",
      "  done: false\n",
      "  episode_len_mean: 89.17857142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.210000000000013\n",
      "  episode_reward_mean: 3.3482142857142927\n",
      "  episode_reward_min: -1.4600000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 25889\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3583160681602284\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012927454168654267\n",
      "          policy_loss: -0.08027090525302367\n",
      "          total_loss: 0.033822774115758826\n",
      "          vf_explained_var: 0.9432406425476074\n",
      "          vf_loss: 0.10822648257415136\n",
      "    num_agent_steps_sampled: 2389044\n",
      "    num_agent_steps_trained: 2389044\n",
      "    num_steps_sampled: 2389044\n",
      "    num_steps_trained: 2389044\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.59411764705882\n",
      "    ram_util_percent: 55.778280542986444\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576862147963166\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.852057244167305\n",
      "    mean_inference_ms: 2.8615379347875347\n",
      "    mean_raw_obs_processing_ms: 2.9475155122681893\n",
      "  time_since_restore: 36302.01285195351\n",
      "  time_this_iter_s: 154.6777684688568\n",
      "  time_total_s: 36302.01285195351\n",
      "  timers:\n",
      "    learn_throughput: 933.983\n",
      "    learn_time_ms: 10702.546\n",
      "    load_throughput: 91373.656\n",
      "    load_time_ms: 109.397\n",
      "    sample_throughput: 66.687\n",
      "    sample_time_ms: 149895.011\n",
      "    update_time_ms: 11.037\n",
      "  timestamp: 1636330720\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2389044\n",
      "  training_iteration: 239\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   239</td><td style=\"text-align: right;\">           36302</td><td style=\"text-align: right;\">2389044</td><td style=\"text-align: right;\"> 3.34821</td><td style=\"text-align: right;\">               11.21</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           89.1786</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2399040\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-21-26\n",
      "  done: false\n",
      "  episode_len_mean: 89.05357142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.060000000000013\n",
      "  episode_reward_mean: 3.2462500000000074\n",
      "  episode_reward_min: -1.690000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 26001\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.367945357876965\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013828114818054993\n",
      "          policy_loss: -0.0822649980075339\n",
      "          total_loss: 0.04144268870098978\n",
      "          vf_explained_var: 0.9394233822822571\n",
      "          vf_loss: 0.11588496625598552\n",
      "    num_agent_steps_sampled: 2399040\n",
      "    num_agent_steps_trained: 2399040\n",
      "    num_steps_sampled: 2399040\n",
      "    num_steps_trained: 2399040\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.62605042016807\n",
      "    ram_util_percent: 55.96974789915965\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045749327348730065\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.851047000668515\n",
      "    mean_inference_ms: 2.861452569574034\n",
      "    mean_raw_obs_processing_ms: 2.95886381237059\n",
      "  time_since_restore: 36468.846994161606\n",
      "  time_this_iter_s: 166.83414220809937\n",
      "  time_total_s: 36468.846994161606\n",
      "  timers:\n",
      "    learn_throughput: 934.143\n",
      "    learn_time_ms: 10700.714\n",
      "    load_throughput: 91489.781\n",
      "    load_time_ms: 109.258\n",
      "    sample_throughput: 65.602\n",
      "    sample_time_ms: 152374.025\n",
      "    update_time_ms: 11.962\n",
      "  timestamp: 1636330886\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2399040\n",
      "  training_iteration: 240\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   240</td><td style=\"text-align: right;\">         36468.8</td><td style=\"text-align: right;\">2399040</td><td style=\"text-align: right;\"> 3.24625</td><td style=\"text-align: right;\">               11.06</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           89.0536</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2409036\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-24-14\n",
      "  done: false\n",
      "  episode_len_mean: 89.61607142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.120000000000012\n",
      "  episode_reward_mean: 3.4716964285714362\n",
      "  episode_reward_min: -1.3600000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 26113\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3684270090527004\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014107696066816484\n",
      "          policy_loss: -0.07750006488436817\n",
      "          total_loss: 0.062364077193933165\n",
      "          vf_explained_var: 0.9225014448165894\n",
      "          vf_loss: 0.1314093169923394\n",
      "    num_agent_steps_sampled: 2409036\n",
      "    num_agent_steps_trained: 2409036\n",
      "    num_steps_sampled: 2409036\n",
      "    num_steps_trained: 2409036\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.17999999999999\n",
      "    ram_util_percent: 56.02666666666666\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577404500332089\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.851655886362046\n",
      "    mean_inference_ms: 2.8612605271802534\n",
      "    mean_raw_obs_processing_ms: 2.9736236269379854\n",
      "  time_since_restore: 36636.57147717476\n",
      "  time_this_iter_s: 167.72448301315308\n",
      "  time_total_s: 36636.57147717476\n",
      "  timers:\n",
      "    learn_throughput: 933.646\n",
      "    learn_time_ms: 10706.414\n",
      "    load_throughput: 91804.764\n",
      "    load_time_ms: 108.883\n",
      "    sample_throughput: 65.192\n",
      "    sample_time_ms: 153330.808\n",
      "    update_time_ms: 11.184\n",
      "  timestamp: 1636331054\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2409036\n",
      "  training_iteration: 241\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   241</td><td style=\"text-align: right;\">         36636.6</td><td style=\"text-align: right;\">2409036</td><td style=\"text-align: right;\">  3.4717</td><td style=\"text-align: right;\">               13.12</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           89.6161</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2419032\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-26-31\n",
      "  done: false\n",
      "  episode_len_mean: 92.32407407407408\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.150000000000016\n",
      "  episode_reward_mean: 2.815462962962971\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 26221\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3851566361565877\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012720692789492938\n",
      "          policy_loss: -0.08382953648320121\n",
      "          total_loss: 0.036500998248911315\n",
      "          vf_explained_var: 0.9358655214309692\n",
      "          vf_loss: 0.11520277216600684\n",
      "    num_agent_steps_sampled: 2419032\n",
      "    num_agent_steps_trained: 2419032\n",
      "    num_steps_sampled: 2419032\n",
      "    num_steps_trained: 2419032\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90666666666668\n",
      "    ram_util_percent: 55.94615384615385\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577592917868388\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.85524998753813\n",
      "    mean_inference_ms: 2.861461530109069\n",
      "    mean_raw_obs_processing_ms: 2.9639182982687675\n",
      "  time_since_restore: 36773.524003744125\n",
      "  time_this_iter_s: 136.95252656936646\n",
      "  time_total_s: 36773.524003744125\n",
      "  timers:\n",
      "    learn_throughput: 933.865\n",
      "    learn_time_ms: 10703.908\n",
      "    load_throughput: 92006.591\n",
      "    load_time_ms: 108.644\n",
      "    sample_throughput: 66.667\n",
      "    sample_time_ms: 149939.73\n",
      "    update_time_ms: 10.938\n",
      "  timestamp: 1636331191\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2419032\n",
      "  training_iteration: 242\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">         36773.5</td><td style=\"text-align: right;\">2419032</td><td style=\"text-align: right;\"> 2.81546</td><td style=\"text-align: right;\">               12.15</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           92.3241</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2429028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-29-16\n",
      "  done: false\n",
      "  episode_len_mean: 89.125\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.710000000000003\n",
      "  episode_reward_mean: 2.9535714285714363\n",
      "  episode_reward_min: -2.289999999999998\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 26333\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3737765418158636\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01298311577786199\n",
      "          policy_loss: -0.08139312729303144\n",
      "          total_loss: 0.04335817000072481\n",
      "          vf_explained_var: 0.9199544191360474\n",
      "          vf_loss: 0.11891190130183966\n",
      "    num_agent_steps_sampled: 2429028\n",
      "    num_agent_steps_trained: 2429028\n",
      "    num_steps_sampled: 2429028\n",
      "    num_steps_trained: 2429028\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.30808510638299\n",
      "    ram_util_percent: 56.02851063829787\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045763532818943055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.85484331234003\n",
      "    mean_inference_ms: 2.8613922108555494\n",
      "    mean_raw_obs_processing_ms: 2.968485598905881\n",
      "  time_since_restore: 36938.33048892021\n",
      "  time_this_iter_s: 164.80648517608643\n",
      "  time_total_s: 36938.33048892021\n",
      "  timers:\n",
      "    learn_throughput: 933.776\n",
      "    learn_time_ms: 10704.925\n",
      "    load_throughput: 92137.998\n",
      "    load_time_ms: 108.489\n",
      "    sample_throughput: 66.582\n",
      "    sample_time_ms: 150129.827\n",
      "    update_time_ms: 12.017\n",
      "  timestamp: 1636331356\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2429028\n",
      "  training_iteration: 243\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   243</td><td style=\"text-align: right;\">         36938.3</td><td style=\"text-align: right;\">2429028</td><td style=\"text-align: right;\"> 2.95357</td><td style=\"text-align: right;\">                9.71</td><td style=\"text-align: right;\">               -2.29</td><td style=\"text-align: right;\">            89.125</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2439024\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-31-51\n",
      "  done: false\n",
      "  episode_len_mean: 89.36607142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.920000000000012\n",
      "  episode_reward_mean: 3.275625000000008\n",
      "  episode_reward_min: -1.830000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 26445\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.348641552273025\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01424710801949066\n",
      "          policy_loss: -0.07917197962474619\n",
      "          total_loss: 0.0608507546588269\n",
      "          vf_explained_var: 0.9259290099143982\n",
      "          vf_loss: 0.13105245629070789\n",
      "    num_agent_steps_sampled: 2439024\n",
      "    num_agent_steps_trained: 2439024\n",
      "    num_steps_sampled: 2439024\n",
      "    num_steps_trained: 2439024\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.9371040723982\n",
      "    ram_util_percent: 55.88461538461539\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574197764670369\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.86116780502646\n",
      "    mean_inference_ms: 2.8613024486400422\n",
      "    mean_raw_obs_processing_ms: 2.9650083301271244\n",
      "  time_since_restore: 37093.31469964981\n",
      "  time_this_iter_s: 154.984210729599\n",
      "  time_total_s: 37093.31469964981\n",
      "  timers:\n",
      "    learn_throughput: 933.573\n",
      "    learn_time_ms: 10707.251\n",
      "    load_throughput: 92242.132\n",
      "    load_time_ms: 108.367\n",
      "    sample_throughput: 67.412\n",
      "    sample_time_ms: 148283.255\n",
      "    update_time_ms: 12.755\n",
      "  timestamp: 1636331511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2439024\n",
      "  training_iteration: 244\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   244</td><td style=\"text-align: right;\">         37093.3</td><td style=\"text-align: right;\">2439024</td><td style=\"text-align: right;\"> 3.27563</td><td style=\"text-align: right;\">               10.92</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           89.3661</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2449020\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-34-31\n",
      "  done: false\n",
      "  episode_len_mean: 89.54464285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.570000000000016\n",
      "  episode_reward_mean: 3.546875000000008\n",
      "  episode_reward_min: -1.589999999999997\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 26557\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3575934966405234\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01408624194781229\n",
      "          policy_loss: -0.07879312064530503\n",
      "          total_loss: 0.06505100436062894\n",
      "          vf_explained_var: 0.9357138276100159\n",
      "          vf_loss: 0.13532983924970668\n",
      "    num_agent_steps_sampled: 2449020\n",
      "    num_agent_steps_trained: 2449020\n",
      "    num_steps_sampled: 2449020\n",
      "    num_steps_trained: 2449020\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.87192982456142\n",
      "    ram_util_percent: 56.00526315789473\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04572074312590179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.86981389494796\n",
      "    mean_inference_ms: 2.8613548057281255\n",
      "    mean_raw_obs_processing_ms: 2.9616845490036545\n",
      "  time_since_restore: 37253.06988453865\n",
      "  time_this_iter_s: 159.75518488883972\n",
      "  time_total_s: 37253.06988453865\n",
      "  timers:\n",
      "    learn_throughput: 933.485\n",
      "    learn_time_ms: 10708.255\n",
      "    load_throughput: 92286.049\n",
      "    load_time_ms: 108.315\n",
      "    sample_throughput: 67.257\n",
      "    sample_time_ms: 148623.082\n",
      "    update_time_ms: 13.153\n",
      "  timestamp: 1636331671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2449020\n",
      "  training_iteration: 245\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   245</td><td style=\"text-align: right;\">         37253.1</td><td style=\"text-align: right;\">2449020</td><td style=\"text-align: right;\"> 3.54688</td><td style=\"text-align: right;\">               12.57</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           89.5446</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2459016\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-37-35\n",
      "  done: false\n",
      "  episode_len_mean: 89.33928571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.040000000000012\n",
      "  episode_reward_mean: 3.25910714285715\n",
      "  episode_reward_min: -1.7300000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 26669\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.362684541889745\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013514046320907087\n",
      "          policy_loss: -0.07995144757322777\n",
      "          total_loss: 0.05054726894053384\n",
      "          vf_explained_var: 0.932756781578064\n",
      "          vf_loss: 0.12333887472716916\n",
      "    num_agent_steps_sampled: 2459016\n",
      "    num_agent_steps_trained: 2459016\n",
      "    num_steps_sampled: 2459016\n",
      "    num_steps_trained: 2459016\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.08441064638784\n",
      "    ram_util_percent: 56.04600760456273\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04577795340744543\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.8702606915823\n",
      "    mean_inference_ms: 2.8613434169785554\n",
      "    mean_raw_obs_processing_ms: 2.9777421690496055\n",
      "  time_since_restore: 37436.957802295685\n",
      "  time_this_iter_s: 183.8879177570343\n",
      "  time_total_s: 37436.957802295685\n",
      "  timers:\n",
      "    learn_throughput: 933.517\n",
      "    learn_time_ms: 10707.891\n",
      "    load_throughput: 92223.932\n",
      "    load_time_ms: 108.388\n",
      "    sample_throughput: 66.125\n",
      "    sample_time_ms: 151168.266\n",
      "    update_time_ms: 11.962\n",
      "  timestamp: 1636331855\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2459016\n",
      "  training_iteration: 246\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">           37437</td><td style=\"text-align: right;\">2459016</td><td style=\"text-align: right;\"> 3.25911</td><td style=\"text-align: right;\">                9.04</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           89.3393</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2469012\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-40-18\n",
      "  done: false\n",
      "  episode_len_mean: 89.16964285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.820000000000013\n",
      "  episode_reward_mean: 3.2065178571428636\n",
      "  episode_reward_min: -1.9200000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 26781\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3528144559289657\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013422110053437266\n",
      "          policy_loss: -0.07871367628288128\n",
      "          total_loss: 0.06638657708899078\n",
      "          vf_explained_var: 0.9108462333679199\n",
      "          vf_loss: 0.13805115392160977\n",
      "    num_agent_steps_sampled: 2469012\n",
      "    num_agent_steps_trained: 2469012\n",
      "    num_steps_sampled: 2469012\n",
      "    num_steps_trained: 2469012\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.7008620689655\n",
      "    ram_util_percent: 55.956896551724135\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045756219636343735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.87166087813676\n",
      "    mean_inference_ms: 2.86088201160232\n",
      "    mean_raw_obs_processing_ms: 2.981013876495318\n",
      "  time_since_restore: 37599.86088180542\n",
      "  time_this_iter_s: 162.9030795097351\n",
      "  time_total_s: 37599.86088180542\n",
      "  timers:\n",
      "    learn_throughput: 933.868\n",
      "    learn_time_ms: 10703.874\n",
      "    load_throughput: 91944.486\n",
      "    load_time_ms: 108.718\n",
      "    sample_throughput: 66.259\n",
      "    sample_time_ms: 150861.418\n",
      "    update_time_ms: 12.564\n",
      "  timestamp: 1636332018\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2469012\n",
      "  training_iteration: 247\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   247</td><td style=\"text-align: right;\">         37599.9</td><td style=\"text-align: right;\">2469012</td><td style=\"text-align: right;\"> 3.20652</td><td style=\"text-align: right;\">               10.82</td><td style=\"text-align: right;\">               -1.92</td><td style=\"text-align: right;\">           89.1696</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2479008\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-42-39\n",
      "  done: false\n",
      "  episode_len_mean: 90.09909909909909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.460000000000017\n",
      "  episode_reward_mean: 3.5922522522522606\n",
      "  episode_reward_min: -1.3600000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 26892\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3450595969827766\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013501083833265176\n",
      "          policy_loss: -0.07931246595600476\n",
      "          total_loss: 0.06485062800905006\n",
      "          vf_explained_var: 0.9258711934089661\n",
      "          vf_loss: 0.13685653187637017\n",
      "    num_agent_steps_sampled: 2479008\n",
      "    num_agent_steps_trained: 2479008\n",
      "    num_steps_sampled: 2479008\n",
      "    num_steps_trained: 2479008\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11633663366337\n",
      "    ram_util_percent: 55.90198019801981\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045746831978812554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.87964721045374\n",
      "    mean_inference_ms: 2.86115630059124\n",
      "    mean_raw_obs_processing_ms: 2.970471881225252\n",
      "  time_since_restore: 37741.37526226044\n",
      "  time_this_iter_s: 141.5143804550171\n",
      "  time_total_s: 37741.37526226044\n",
      "  timers:\n",
      "    learn_throughput: 934.01\n",
      "    learn_time_ms: 10702.246\n",
      "    load_throughput: 92054.832\n",
      "    load_time_ms: 108.587\n",
      "    sample_throughput: 67.283\n",
      "    sample_time_ms: 148567.165\n",
      "    update_time_ms: 12.641\n",
      "  timestamp: 1636332159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2479008\n",
      "  training_iteration: 248\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">         37741.4</td><td style=\"text-align: right;\">2479008</td><td style=\"text-align: right;\"> 3.59225</td><td style=\"text-align: right;\">               10.46</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           90.0991</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2489004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-45-15\n",
      "  done: false\n",
      "  episode_len_mean: 88.4424778761062\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000017\n",
      "  episode_reward_mean: 3.2928318584070873\n",
      "  episode_reward_min: -1.5300000000000005\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 27005\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3393336340912385\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01295707716910926\n",
      "          policy_loss: -0.08188570034491201\n",
      "          total_loss: 0.03556880132159871\n",
      "          vf_explained_var: 0.9380015134811401\n",
      "          vf_loss: 0.11132999621172492\n",
      "    num_agent_steps_sampled: 2489004\n",
      "    num_agent_steps_trained: 2489004\n",
      "    num_steps_sampled: 2489004\n",
      "    num_steps_trained: 2489004\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.95\n",
      "    ram_util_percent: 55.92702702702702\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576586703840638\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.88563538074443\n",
      "    mean_inference_ms: 2.8611889178140495\n",
      "    mean_raw_obs_processing_ms: 2.969406125937393\n",
      "  time_since_restore: 37897.01671695709\n",
      "  time_this_iter_s: 155.64145469665527\n",
      "  time_total_s: 37897.01671695709\n",
      "  timers:\n",
      "    learn_throughput: 934.142\n",
      "    learn_time_ms: 10700.724\n",
      "    load_throughput: 91945.091\n",
      "    load_time_ms: 108.717\n",
      "    sample_throughput: 67.238\n",
      "    sample_time_ms: 148665.263\n",
      "    update_time_ms: 12.419\n",
      "  timestamp: 1636332315\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2489004\n",
      "  training_iteration: 249\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   249</td><td style=\"text-align: right;\">           37897</td><td style=\"text-align: right;\">2489004</td><td style=\"text-align: right;\"> 3.29283</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">           88.4425</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2499000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-48-07\n",
      "  done: false\n",
      "  episode_len_mean: 88.41071428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000017\n",
      "  episode_reward_mean: 2.9547321428571505\n",
      "  episode_reward_min: -1.6800000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 27117\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.353748286483634\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013120730145106197\n",
      "          policy_loss: -0.07741196746818531\n",
      "          total_loss: 0.060774256072492684\n",
      "          vf_explained_var: 0.928286612033844\n",
      "          vf_loss: 0.13183304283162978\n",
      "    num_agent_steps_sampled: 2499000\n",
      "    num_agent_steps_trained: 2499000\n",
      "    num_steps_sampled: 2499000\n",
      "    num_steps_trained: 2499000\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.10938775510203\n",
      "    ram_util_percent: 55.94367346938776\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04573367001726151\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.88949631014971\n",
      "    mean_inference_ms: 2.861069934269\n",
      "    mean_raw_obs_processing_ms: 2.9718279936080045\n",
      "  time_since_restore: 38068.832845926285\n",
      "  time_this_iter_s: 171.8161289691925\n",
      "  time_total_s: 38068.832845926285\n",
      "  timers:\n",
      "    learn_throughput: 933.965\n",
      "    learn_time_ms: 10702.751\n",
      "    load_throughput: 91911.088\n",
      "    load_time_ms: 108.757\n",
      "    sample_throughput: 67.014\n",
      "    sample_time_ms: 149162.103\n",
      "    update_time_ms: 11.477\n",
      "  timestamp: 1636332487\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2499000\n",
      "  training_iteration: 250\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         38068.8</td><td style=\"text-align: right;\">2499000</td><td style=\"text-align: right;\"> 2.95473</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           88.4107</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2508996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-50-29\n",
      "  done: false\n",
      "  episode_len_mean: 90.29464285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.890000000000015\n",
      "  episode_reward_mean: 3.3594642857142945\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 27229\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3500593311766274\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013375323385929994\n",
      "          policy_loss: -0.07903031372489074\n",
      "          total_loss: 0.047069967907463386\n",
      "          vf_explained_var: 0.936002790927887\n",
      "          vf_loss: 0.11913021498192579\n",
      "    num_agent_steps_sampled: 2508996\n",
      "    num_agent_steps_trained: 2508996\n",
      "    num_steps_sampled: 2508996\n",
      "    num_steps_trained: 2508996\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14187192118226\n",
      "    ram_util_percent: 55.835467980295576\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045757519758096346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.89850854146352\n",
      "    mean_inference_ms: 2.861181371685148\n",
      "    mean_raw_obs_processing_ms: 2.9645565438475825\n",
      "  time_since_restore: 38210.657358407974\n",
      "  time_this_iter_s: 141.82451248168945\n",
      "  time_total_s: 38210.657358407974\n",
      "  timers:\n",
      "    learn_throughput: 934.254\n",
      "    learn_time_ms: 10699.451\n",
      "    load_throughput: 91864.567\n",
      "    load_time_ms: 108.812\n",
      "    sample_throughput: 68.198\n",
      "    sample_time_ms: 146573.68\n",
      "    update_time_ms: 12.899\n",
      "  timestamp: 1636332629\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2508996\n",
      "  training_iteration: 251\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   251</td><td style=\"text-align: right;\">         38210.7</td><td style=\"text-align: right;\">2508996</td><td style=\"text-align: right;\"> 3.35946</td><td style=\"text-align: right;\">               12.89</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           90.2946</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2518992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-53-07\n",
      "  done: false\n",
      "  episode_len_mean: 88.57142857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.780000000000015\n",
      "  episode_reward_mean: 2.970000000000007\n",
      "  episode_reward_min: -2.0600000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 27341\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3383243701396843\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013404003164280821\n",
      "          policy_loss: -0.07970200954403123\n",
      "          total_loss: 0.0563889261526175\n",
      "          vf_explained_var: 0.9154801964759827\n",
      "          vf_loss: 0.12893818378066405\n",
      "    num_agent_steps_sampled: 2518992\n",
      "    num_agent_steps_trained: 2518992\n",
      "    num_steps_sampled: 2518992\n",
      "    num_steps_trained: 2518992\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.17920353982302\n",
      "    ram_util_percent: 55.872123893805316\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574698069225068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.90504083507646\n",
      "    mean_inference_ms: 2.86126761956696\n",
      "    mean_raw_obs_processing_ms: 2.9612115856370926\n",
      "  time_since_restore: 38369.2071056366\n",
      "  time_this_iter_s: 158.54974722862244\n",
      "  time_total_s: 38369.2071056366\n",
      "  timers:\n",
      "    learn_throughput: 934.035\n",
      "    learn_time_ms: 10701.957\n",
      "    load_throughput: 91713.551\n",
      "    load_time_ms: 108.992\n",
      "    sample_throughput: 67.209\n",
      "    sample_time_ms: 148730.795\n",
      "    update_time_ms: 13.051\n",
      "  timestamp: 1636332787\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2518992\n",
      "  training_iteration: 252\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   252</td><td style=\"text-align: right;\">         38369.2</td><td style=\"text-align: right;\">2518992</td><td style=\"text-align: right;\">    2.97</td><td style=\"text-align: right;\">               12.78</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           88.5714</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2528988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-55-44\n",
      "  done: false\n",
      "  episode_len_mean: 88.19469026548673\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.110000000000017\n",
      "  episode_reward_mean: 3.3274336283185915\n",
      "  episode_reward_min: -1.7100000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 27454\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.348838087839958\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013577138966144417\n",
      "          policy_loss: -0.08062504519286573\n",
      "          total_loss: 0.06345655775159342\n",
      "          vf_explained_var: 0.9250807762145996\n",
      "          vf_loss: 0.13663956318369025\n",
      "    num_agent_steps_sampled: 2528988\n",
      "    num_agent_steps_trained: 2528988\n",
      "    num_steps_sampled: 2528988\n",
      "    num_steps_trained: 2528988\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.76771300448429\n",
      "    ram_util_percent: 55.84215246636773\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04573124049857839\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.909400255089935\n",
      "    mean_inference_ms: 2.861312509634807\n",
      "    mean_raw_obs_processing_ms: 2.95856631675997\n",
      "  time_since_restore: 38525.600512742996\n",
      "  time_this_iter_s: 156.39340710639954\n",
      "  time_total_s: 38525.600512742996\n",
      "  timers:\n",
      "    learn_throughput: 934.006\n",
      "    learn_time_ms: 10702.29\n",
      "    load_throughput: 91645.049\n",
      "    load_time_ms: 109.073\n",
      "    sample_throughput: 67.59\n",
      "    sample_time_ms: 147890.651\n",
      "    update_time_ms: 11.445\n",
      "  timestamp: 1636332944\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2528988\n",
      "  training_iteration: 253\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   253</td><td style=\"text-align: right;\">         38525.6</td><td style=\"text-align: right;\">2528988</td><td style=\"text-align: right;\"> 3.32743</td><td style=\"text-align: right;\">               12.11</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           88.1947</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2538984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_00-58-17\n",
      "  done: false\n",
      "  episode_len_mean: 89.54867256637168\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.820000000000014\n",
      "  episode_reward_mean: 3.438407079646025\n",
      "  episode_reward_min: -1.680000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 27567\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3399653864721968\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014361058626608646\n",
      "          policy_loss: -0.08000292105711679\n",
      "          total_loss: 0.05655276878681193\n",
      "          vf_explained_var: 0.931330144405365\n",
      "          vf_loss: 0.12723905466910865\n",
      "    num_agent_steps_sampled: 2538984\n",
      "    num_agent_steps_trained: 2538984\n",
      "    num_steps_sampled: 2538984\n",
      "    num_steps_trained: 2538984\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.83013698630138\n",
      "    ram_util_percent: 55.820091324200924\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045751749404759345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.91445134363281\n",
      "    mean_inference_ms: 2.861352846602366\n",
      "    mean_raw_obs_processing_ms: 2.9577585302463922\n",
      "  time_since_restore: 38679.20573782921\n",
      "  time_this_iter_s: 153.60522508621216\n",
      "  time_total_s: 38679.20573782921\n",
      "  timers:\n",
      "    learn_throughput: 933.994\n",
      "    learn_time_ms: 10702.423\n",
      "    load_throughput: 91607.184\n",
      "    load_time_ms: 109.118\n",
      "    sample_throughput: 67.653\n",
      "    sample_time_ms: 147753.403\n",
      "    update_time_ms: 10.804\n",
      "  timestamp: 1636333097\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2538984\n",
      "  training_iteration: 254\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">         38679.2</td><td style=\"text-align: right;\">2538984</td><td style=\"text-align: right;\"> 3.43841</td><td style=\"text-align: right;\">               12.82</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           89.5487</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2548980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-00-48\n",
      "  done: false\n",
      "  episode_len_mean: 90.91743119266054\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.77000000000001\n",
      "  episode_reward_mean: 3.39366972477065\n",
      "  episode_reward_min: -1.5800000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 27676\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.344546906560914\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01332099729446033\n",
      "          policy_loss: -0.07787542131164263\n",
      "          total_loss: 0.04258472363217774\n",
      "          vf_explained_var: 0.9422920346260071\n",
      "          vf_loss: 0.11355871740712696\n",
      "    num_agent_steps_sampled: 2548980\n",
      "    num_agent_steps_trained: 2548980\n",
      "    num_steps_sampled: 2548980\n",
      "    num_steps_trained: 2548980\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.35648148148148\n",
      "    ram_util_percent: 55.90601851851852\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575021746403938\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.918550322545634\n",
      "    mean_inference_ms: 2.861339285918051\n",
      "    mean_raw_obs_processing_ms: 2.9550736233252923\n",
      "  time_since_restore: 38830.242094278336\n",
      "  time_this_iter_s: 151.0363564491272\n",
      "  time_total_s: 38830.242094278336\n",
      "  timers:\n",
      "    learn_throughput: 934.176\n",
      "    learn_time_ms: 10700.336\n",
      "    load_throughput: 91688.801\n",
      "    load_time_ms: 109.021\n",
      "    sample_throughput: 68.053\n",
      "    sample_time_ms: 146884.527\n",
      "    update_time_ms: 9.881\n",
      "  timestamp: 1636333248\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2548980\n",
      "  training_iteration: 255\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   255</td><td style=\"text-align: right;\">         38830.2</td><td style=\"text-align: right;\">2548980</td><td style=\"text-align: right;\"> 3.39367</td><td style=\"text-align: right;\">               12.77</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           90.9174</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2558976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-03-38\n",
      "  done: false\n",
      "  episode_len_mean: 87.7304347826087\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.640000000000013\n",
      "  episode_reward_mean: 3.3660869565217473\n",
      "  episode_reward_min: -1.6899999999999995\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 27791\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3306805573976956\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013272419148033314\n",
      "          policy_loss: -0.07972523186785671\n",
      "          total_loss: 0.06013835148854006\n",
      "          vf_explained_var: 0.9273483157157898\n",
      "          vf_loss: 0.13293415853817367\n",
      "    num_agent_steps_sampled: 2558976\n",
      "    num_agent_steps_trained: 2558976\n",
      "    num_steps_sampled: 2558976\n",
      "    num_steps_trained: 2558976\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.26652892561985\n",
      "    ram_util_percent: 55.828925619834706\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575635875726219\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.92099452171737\n",
      "    mean_inference_ms: 2.861100688045736\n",
      "    mean_raw_obs_processing_ms: 2.961237263022262\n",
      "  time_since_restore: 38999.85591697693\n",
      "  time_this_iter_s: 169.61382269859314\n",
      "  time_total_s: 38999.85591697693\n",
      "  timers:\n",
      "    learn_throughput: 934.755\n",
      "    learn_time_ms: 10693.706\n",
      "    load_throughput: 91818.597\n",
      "    load_time_ms: 108.867\n",
      "    sample_throughput: 68.719\n",
      "    sample_time_ms: 145462.873\n",
      "    update_time_ms: 10.626\n",
      "  timestamp: 1636333418\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2558976\n",
      "  training_iteration: 256\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   256</td><td style=\"text-align: right;\">         38999.9</td><td style=\"text-align: right;\">2558976</td><td style=\"text-align: right;\"> 3.36609</td><td style=\"text-align: right;\">               10.64</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           87.7304</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2568972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-05-58\n",
      "  done: false\n",
      "  episode_len_mean: 90.32727272727273\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.82999999999999\n",
      "  episode_reward_mean: 3.816909090909099\n",
      "  episode_reward_min: -1.890000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 27901\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.35510842942784\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013143986099123296\n",
      "          policy_loss: -0.07819413240266661\n",
      "          total_loss: 0.05457863764534903\n",
      "          vf_explained_var: 0.9404085874557495\n",
      "          vf_loss: 0.12638020970038752\n",
      "    num_agent_steps_sampled: 2568972\n",
      "    num_agent_steps_trained: 2568972\n",
      "    num_steps_sampled: 2568972\n",
      "    num_steps_trained: 2568972\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00201005025126\n",
      "    ram_util_percent: 55.81708542713567\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574859281229054\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.925344225552166\n",
      "    mean_inference_ms: 2.8612728731042285\n",
      "    mean_raw_obs_processing_ms: 2.951643350940428\n",
      "  time_since_restore: 39139.41605472565\n",
      "  time_this_iter_s: 139.56013774871826\n",
      "  time_total_s: 39139.41605472565\n",
      "  timers:\n",
      "    learn_throughput: 934.694\n",
      "    learn_time_ms: 10694.405\n",
      "    load_throughput: 92117.734\n",
      "    load_time_ms: 108.513\n",
      "    sample_throughput: 69.84\n",
      "    sample_time_ms: 143127.448\n",
      "    update_time_ms: 11.055\n",
      "  timestamp: 1636333558\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2568972\n",
      "  training_iteration: 257\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   257</td><td style=\"text-align: right;\">         39139.4</td><td style=\"text-align: right;\">2568972</td><td style=\"text-align: right;\"> 3.81691</td><td style=\"text-align: right;\">               17.83</td><td style=\"text-align: right;\">               -1.89</td><td style=\"text-align: right;\">           90.3273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2578968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-08-30\n",
      "  done: false\n",
      "  episode_len_mean: 88.70796460176992\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.610000000000015\n",
      "  episode_reward_mean: 3.1307964601769975\n",
      "  episode_reward_min: -1.770000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 28014\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3300176290365364\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012979053469094066\n",
      "          policy_loss: -0.07869649688657532\n",
      "          total_loss: 0.044675831229258806\n",
      "          vf_explained_var: 0.9439103603363037\n",
      "          vf_loss: 0.11710459750432234\n",
      "    num_agent_steps_sampled: 2578968\n",
      "    num_agent_steps_trained: 2578968\n",
      "    num_steps_sampled: 2578968\n",
      "    num_steps_trained: 2578968\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.798623853211\n",
      "    ram_util_percent: 55.89357798165138\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04576114200934342\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93126085129392\n",
      "    mean_inference_ms: 2.861160853367544\n",
      "    mean_raw_obs_processing_ms: 2.9507828765841166\n",
      "  time_since_restore: 39292.170749902725\n",
      "  time_this_iter_s: 152.75469517707825\n",
      "  time_total_s: 39292.170749902725\n",
      "  timers:\n",
      "    learn_throughput: 934.599\n",
      "    learn_time_ms: 10695.494\n",
      "    load_throughput: 92127.652\n",
      "    load_time_ms: 108.502\n",
      "    sample_throughput: 69.296\n",
      "    sample_time_ms: 144250.154\n",
      "    update_time_ms: 11.466\n",
      "  timestamp: 1636333710\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2578968\n",
      "  training_iteration: 258\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   258</td><td style=\"text-align: right;\">         39292.2</td><td style=\"text-align: right;\">2578968</td><td style=\"text-align: right;\">  3.1308</td><td style=\"text-align: right;\">               12.61</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">            88.708</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2588964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-11-22\n",
      "  done: false\n",
      "  episode_len_mean: 86.65217391304348\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.670000000000018\n",
      "  episode_reward_mean: 3.7263478260869647\n",
      "  episode_reward_min: -1.830000000000001\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 28129\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3342390223446055\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014677873852633024\n",
      "          policy_loss: -0.07775660125681987\n",
      "          total_loss: 0.08915218182672292\n",
      "          vf_explained_var: 0.9308323264122009\n",
      "          vf_loss: 0.1568131406019386\n",
      "    num_agent_steps_sampled: 2588964\n",
      "    num_agent_steps_trained: 2588964\n",
      "    num_steps_sampled: 2588964\n",
      "    num_steps_trained: 2588964\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.89303278688526\n",
      "    ram_util_percent: 55.91434426229508\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045734949841399315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93466533203956\n",
      "    mean_inference_ms: 2.8610481597469564\n",
      "    mean_raw_obs_processing_ms: 2.9602369181531403\n",
      "  time_since_restore: 39463.19656634331\n",
      "  time_this_iter_s: 171.02581644058228\n",
      "  time_total_s: 39463.19656634331\n",
      "  timers:\n",
      "    learn_throughput: 934.736\n",
      "    learn_time_ms: 10693.933\n",
      "    load_throughput: 92163.863\n",
      "    load_time_ms: 108.459\n",
      "    sample_throughput: 68.564\n",
      "    sample_time_ms: 145790.115\n",
      "    update_time_ms: 11.273\n",
      "  timestamp: 1636333882\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2588964\n",
      "  training_iteration: 259\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   259</td><td style=\"text-align: right;\">         39463.2</td><td style=\"text-align: right;\">2588964</td><td style=\"text-align: right;\"> 3.72635</td><td style=\"text-align: right;\">               12.67</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           86.6522</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2598960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-13-46\n",
      "  done: false\n",
      "  episode_len_mean: 88.91071428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.320000000000013\n",
      "  episode_reward_mean: 3.4479464285714365\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 28241\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.334736793061607\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013348438191310414\n",
      "          policy_loss: -0.07509671387971084\n",
      "          total_loss: 0.08247017533335294\n",
      "          vf_explained_var: 0.9294275045394897\n",
      "          vf_loss: 0.15050484566097586\n",
      "    num_agent_steps_sampled: 2598960\n",
      "    num_agent_steps_trained: 2598960\n",
      "    num_steps_sampled: 2598960\n",
      "    num_steps_trained: 2598960\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6734299516908\n",
      "    ram_util_percent: 55.829951690821254\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045756564515519724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94398826855558\n",
      "    mean_inference_ms: 2.8612002344358225\n",
      "    mean_raw_obs_processing_ms: 2.953263766440479\n",
      "  time_since_restore: 39607.97006893158\n",
      "  time_this_iter_s: 144.7735025882721\n",
      "  time_total_s: 39607.97006893158\n",
      "  timers:\n",
      "    learn_throughput: 934.911\n",
      "    learn_time_ms: 10691.93\n",
      "    load_throughput: 92140.874\n",
      "    load_time_ms: 108.486\n",
      "    sample_throughput: 69.859\n",
      "    sample_time_ms: 143087.407\n",
      "    update_time_ms: 11.738\n",
      "  timestamp: 1636334026\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2598960\n",
      "  training_iteration: 260\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   260</td><td style=\"text-align: right;\">           39608</td><td style=\"text-align: right;\">2598960</td><td style=\"text-align: right;\"> 3.44795</td><td style=\"text-align: right;\">               12.32</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           88.9107</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2608956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-16-31\n",
      "  done: false\n",
      "  episode_len_mean: 87.66956521739131\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.200000000000012\n",
      "  episode_reward_mean: 3.2908695652174\n",
      "  episode_reward_min: -2.18\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 28356\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3355947649377025\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012793875829869277\n",
      "          policy_loss: -0.07626374440633843\n",
      "          total_loss: 0.06174295794011818\n",
      "          vf_explained_var: 0.9361783266067505\n",
      "          vf_loss: 0.1322166012568224\n",
      "    num_agent_steps_sampled: 2608956\n",
      "    num_agent_steps_trained: 2608956\n",
      "    num_steps_sampled: 2608956\n",
      "    num_steps_trained: 2608956\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.96808510638297\n",
      "    ram_util_percent: 55.924680851063826\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574030741649807\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94638759692064\n",
      "    mean_inference_ms: 2.8612813728951307\n",
      "    mean_raw_obs_processing_ms: 2.96119346104237\n",
      "  time_since_restore: 39772.80770611763\n",
      "  time_this_iter_s: 164.83763718605042\n",
      "  time_total_s: 39772.80770611763\n",
      "  timers:\n",
      "    learn_throughput: 934.65\n",
      "    learn_time_ms: 10694.908\n",
      "    load_throughput: 92187.553\n",
      "    load_time_ms: 108.431\n",
      "    sample_throughput: 68.755\n",
      "    sample_time_ms: 145386.234\n",
      "    update_time_ms: 10.981\n",
      "  timestamp: 1636334191\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2608956\n",
      "  training_iteration: 261\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   261</td><td style=\"text-align: right;\">         39772.8</td><td style=\"text-align: right;\">2608956</td><td style=\"text-align: right;\"> 3.29087</td><td style=\"text-align: right;\">                11.2</td><td style=\"text-align: right;\">               -2.18</td><td style=\"text-align: right;\">           87.6696</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2618952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-19-13\n",
      "  done: false\n",
      "  episode_len_mean: 89.88288288288288\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.010000000000014\n",
      "  episode_reward_mean: 3.5694594594594675\n",
      "  episode_reward_min: -1.4800000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 28467\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3434153395840247\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014035957644635203\n",
      "          policy_loss: -0.07705185031279539\n",
      "          total_loss: 0.0730914755951231\n",
      "          vf_explained_var: 0.9307616949081421\n",
      "          vf_loss: 0.1416018136912304\n",
      "    num_agent_steps_sampled: 2618952\n",
      "    num_agent_steps_trained: 2618952\n",
      "    num_steps_sampled: 2618952\n",
      "    num_steps_trained: 2618952\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.16406926406927\n",
      "    ram_util_percent: 56.019047619047626\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574372649504837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94356583464257\n",
      "    mean_inference_ms: 2.8611842388360635\n",
      "    mean_raw_obs_processing_ms: 2.9664740405156462\n",
      "  time_since_restore: 39934.78973078728\n",
      "  time_this_iter_s: 161.98202466964722\n",
      "  time_total_s: 39934.78973078728\n",
      "  timers:\n",
      "    learn_throughput: 934.692\n",
      "    learn_time_ms: 10694.435\n",
      "    load_throughput: 92263.832\n",
      "    load_time_ms: 108.341\n",
      "    sample_throughput: 68.592\n",
      "    sample_time_ms: 145730.7\n",
      "    update_time_ms: 10.182\n",
      "  timestamp: 1636334353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2618952\n",
      "  training_iteration: 262\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   262</td><td style=\"text-align: right;\">         39934.8</td><td style=\"text-align: right;\">2618952</td><td style=\"text-align: right;\"> 3.56946</td><td style=\"text-align: right;\">               13.01</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           89.8829</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2628948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-21-47\n",
      "  done: false\n",
      "  episode_len_mean: 88.67857142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.980000000000015\n",
      "  episode_reward_mean: 3.7261607142857227\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 28579\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3369773561119014\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013376007629009059\n",
      "          policy_loss: -0.0762607682074428\n",
      "          total_loss: 0.05738064178830793\n",
      "          vf_explained_var: 0.9419529438018799\n",
      "          vf_loss: 0.12653896452652083\n",
      "    num_agent_steps_sampled: 2628948\n",
      "    num_agent_steps_trained: 2628948\n",
      "    num_steps_sampled: 2628948\n",
      "    num_steps_trained: 2628948\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.89680365296805\n",
      "    ram_util_percent: 56.009132420091326\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575048693468927\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.946459962866584\n",
      "    mean_inference_ms: 2.8612422654584253\n",
      "    mean_raw_obs_processing_ms: 2.9652844380451393\n",
      "  time_since_restore: 40088.3886756897\n",
      "  time_this_iter_s: 153.59894490242004\n",
      "  time_total_s: 40088.3886756897\n",
      "  timers:\n",
      "    learn_throughput: 934.841\n",
      "    learn_time_ms: 10692.725\n",
      "    load_throughput: 92243.147\n",
      "    load_time_ms: 108.366\n",
      "    sample_throughput: 68.724\n",
      "    sample_time_ms: 145451.862\n",
      "    update_time_ms: 11.189\n",
      "  timestamp: 1636334507\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2628948\n",
      "  training_iteration: 263\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   263</td><td style=\"text-align: right;\">         40088.4</td><td style=\"text-align: right;\">2628948</td><td style=\"text-align: right;\"> 3.72616</td><td style=\"text-align: right;\">               14.98</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           88.6786</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2638944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-24-43\n",
      "  done: false\n",
      "  episode_len_mean: 89.32743362831859\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.920000000000014\n",
      "  episode_reward_mean: 3.456371681415937\n",
      "  episode_reward_min: -2.0999999999999988\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 28692\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.34367320130014\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013513748302436613\n",
      "          policy_loss: -0.07806098547994963\n",
      "          total_loss: 0.07385659182730775\n",
      "          vf_explained_var: 0.9373729228973389\n",
      "          vf_loss: 0.14456830100817047\n",
      "    num_agent_steps_sampled: 2638944\n",
      "    num_agent_steps_trained: 2638944\n",
      "    num_steps_sampled: 2638944\n",
      "    num_steps_trained: 2638944\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.40438247011951\n",
      "    ram_util_percent: 56.1410358565737\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045742060242265764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95019065913001\n",
      "    mean_inference_ms: 2.8612600462198454\n",
      "    mean_raw_obs_processing_ms: 2.970013328270726\n",
      "  time_since_restore: 40264.20955324173\n",
      "  time_this_iter_s: 175.82087755203247\n",
      "  time_total_s: 40264.20955324173\n",
      "  timers:\n",
      "    learn_throughput: 934.523\n",
      "    learn_time_ms: 10696.365\n",
      "    load_throughput: 91422.869\n",
      "    load_time_ms: 109.338\n",
      "    sample_throughput: 67.692\n",
      "    sample_time_ms: 147668.947\n",
      "    update_time_ms: 11.015\n",
      "  timestamp: 1636334683\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2638944\n",
      "  training_iteration: 264\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   264</td><td style=\"text-align: right;\">         40264.2</td><td style=\"text-align: right;\">2638944</td><td style=\"text-align: right;\"> 3.45637</td><td style=\"text-align: right;\">               10.92</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">           89.3274</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2648940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-27-32\n",
      "  done: false\n",
      "  episode_len_mean: 88.39285714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.920000000000012\n",
      "  episode_reward_mean: 3.604642857142865\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 28804\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3236286020686485\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01295968227417844\n",
      "          policy_loss: -0.07880269026335998\n",
      "          total_loss: 0.04831588962553149\n",
      "          vf_explained_var: 0.9447145462036133\n",
      "          vf_loss: 0.1208310880817664\n",
      "    num_agent_steps_sampled: 2648940\n",
      "    num_agent_steps_trained: 2648940\n",
      "    num_steps_sampled: 2648940\n",
      "    num_steps_trained: 2648940\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19504132231405\n",
      "    ram_util_percent: 55.791735537190085\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045752254449049894\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95556049993518\n",
      "    mean_inference_ms: 2.861166219092771\n",
      "    mean_raw_obs_processing_ms: 2.98741355033702\n",
      "  time_since_restore: 40433.46974444389\n",
      "  time_this_iter_s: 169.2601912021637\n",
      "  time_total_s: 40433.46974444389\n",
      "  timers:\n",
      "    learn_throughput: 934.413\n",
      "    learn_time_ms: 10697.624\n",
      "    load_throughput: 91422.072\n",
      "    load_time_ms: 109.339\n",
      "    sample_throughput: 66.867\n",
      "    sample_time_ms: 149490.21\n",
      "    update_time_ms: 10.907\n",
      "  timestamp: 1636334852\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2648940\n",
      "  training_iteration: 265\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   265</td><td style=\"text-align: right;\">         40433.5</td><td style=\"text-align: right;\">2648940</td><td style=\"text-align: right;\"> 3.60464</td><td style=\"text-align: right;\">               10.92</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           88.3929</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2658936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-30-00\n",
      "  done: false\n",
      "  episode_len_mean: 90.21621621621621\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.930000000000014\n",
      "  episode_reward_mean: 3.3099099099099174\n",
      "  episode_reward_min: -1.3800000000000003\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 28915\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3646230025169177\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012928427927730121\n",
      "          policy_loss: -0.07980219410875669\n",
      "          total_loss: 0.04974684279778192\n",
      "          vf_explained_var: 0.9299294352531433\n",
      "          vf_loss: 0.12374269170447802\n",
      "    num_agent_steps_sampled: 2658936\n",
      "    num_agent_steps_trained: 2658936\n",
      "    num_steps_sampled: 2658936\n",
      "    num_steps_trained: 2658936\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.36113744075831\n",
      "    ram_util_percent: 56.00663507109004\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574336361427348\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.967757989227024\n",
      "    mean_inference_ms: 2.861153875135914\n",
      "    mean_raw_obs_processing_ms: 2.978474673432436\n",
      "  time_since_restore: 40581.545402526855\n",
      "  time_this_iter_s: 148.07565808296204\n",
      "  time_total_s: 40581.545402526855\n",
      "  timers:\n",
      "    learn_throughput: 933.527\n",
      "    learn_time_ms: 10707.783\n",
      "    load_throughput: 91380.825\n",
      "    load_time_ms: 109.388\n",
      "    sample_throughput: 67.849\n",
      "    sample_time_ms: 147326.738\n",
      "    update_time_ms: 10.191\n",
      "  timestamp: 1636335000\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2658936\n",
      "  training_iteration: 266\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   266</td><td style=\"text-align: right;\">         40581.5</td><td style=\"text-align: right;\">2658936</td><td style=\"text-align: right;\"> 3.30991</td><td style=\"text-align: right;\">               12.93</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           90.2162</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2668932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-32-43\n",
      "  done: false\n",
      "  episode_len_mean: 89.61261261261261\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.689999999999973\n",
      "  episode_reward_mean: 3.3919819819819894\n",
      "  episode_reward_min: -1.8600000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 29026\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.35138480459523\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014261683336800206\n",
      "          policy_loss: -0.07360491472590938\n",
      "          total_loss: 0.07496083345200516\n",
      "          vf_explained_var: 0.9378887414932251\n",
      "          vf_loss: 0.13958969846861358\n",
      "    num_agent_steps_sampled: 2668932\n",
      "    num_agent_steps_trained: 2668932\n",
      "    num_steps_sampled: 2668932\n",
      "    num_steps_trained: 2668932\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.98491379310344\n",
      "    ram_util_percent: 56.13836206896551\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045749347917169454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97667029211028\n",
      "    mean_inference_ms: 2.861310111295376\n",
      "    mean_raw_obs_processing_ms: 2.977019751812218\n",
      "  time_since_restore: 40743.99842405319\n",
      "  time_this_iter_s: 162.45302152633667\n",
      "  time_total_s: 40743.99842405319\n",
      "  timers:\n",
      "    learn_throughput: 933.509\n",
      "    learn_time_ms: 10707.987\n",
      "    load_throughput: 91121.586\n",
      "    load_time_ms: 109.7\n",
      "    sample_throughput: 66.811\n",
      "    sample_time_ms: 149615.761\n",
      "    update_time_ms: 9.865\n",
      "  timestamp: 1636335163\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2668932\n",
      "  training_iteration: 267\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   267</td><td style=\"text-align: right;\">           40744</td><td style=\"text-align: right;\">2668932</td><td style=\"text-align: right;\"> 3.39198</td><td style=\"text-align: right;\">               18.69</td><td style=\"text-align: right;\">               -1.86</td><td style=\"text-align: right;\">           89.6126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2678928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-35-22\n",
      "  done: false\n",
      "  episode_len_mean: 87.19827586206897\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.660000000000014\n",
      "  episode_reward_mean: 3.0040517241379376\n",
      "  episode_reward_min: -1.9000000000000008\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 29142\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3430225237821922\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013015928661369814\n",
      "          policy_loss: -0.07670604099845911\n",
      "          total_loss: 0.05982554777183084\n",
      "          vf_explained_var: 0.9280214905738831\n",
      "          vf_loss: 0.13030990052840905\n",
      "    num_agent_steps_sampled: 2678928\n",
      "    num_agent_steps_trained: 2678928\n",
      "    num_steps_sampled: 2678928\n",
      "    num_steps_trained: 2678928\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.42643171806166\n",
      "    ram_util_percent: 55.96651982378855\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04571181484080472\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98427174238559\n",
      "    mean_inference_ms: 2.8609956657344857\n",
      "    mean_raw_obs_processing_ms: 2.9790069621121704\n",
      "  time_since_restore: 40903.220455408096\n",
      "  time_this_iter_s: 159.22203135490417\n",
      "  time_total_s: 40903.220455408096\n",
      "  timers:\n",
      "    learn_throughput: 933.4\n",
      "    learn_time_ms: 10709.231\n",
      "    load_throughput: 91115.071\n",
      "    load_time_ms: 109.707\n",
      "    sample_throughput: 66.524\n",
      "    sample_time_ms: 150261.675\n",
      "    update_time_ms: 9.228\n",
      "  timestamp: 1636335322\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2678928\n",
      "  training_iteration: 268\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   268</td><td style=\"text-align: right;\">         40903.2</td><td style=\"text-align: right;\">2678928</td><td style=\"text-align: right;\"> 3.00405</td><td style=\"text-align: right;\">               10.66</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           87.1983</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2688924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-37-46\n",
      "  done: false\n",
      "  episode_len_mean: 88.72321428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.980000000000011\n",
      "  episode_reward_mean: 3.4491071428571507\n",
      "  episode_reward_min: -1.1800000000000004\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 29254\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3394033409591413\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013551301082980752\n",
      "          policy_loss: -0.0814849111259493\n",
      "          total_loss: 0.0622666869376205\n",
      "          vf_explained_var: 0.9208278059959412\n",
      "          vf_loss: 0.1362740721497844\n",
      "    num_agent_steps_sampled: 2688924\n",
      "    num_agent_steps_trained: 2688924\n",
      "    num_steps_sampled: 2688924\n",
      "    num_steps_trained: 2688924\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.80436893203883\n",
      "    ram_util_percent: 55.943203883495144\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574755683296457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99476720391223\n",
      "    mean_inference_ms: 2.8611804279877395\n",
      "    mean_raw_obs_processing_ms: 2.972804819129267\n",
      "  time_since_restore: 41047.36948490143\n",
      "  time_this_iter_s: 144.1490294933319\n",
      "  time_total_s: 41047.36948490143\n",
      "  timers:\n",
      "    learn_throughput: 933.242\n",
      "    learn_time_ms: 10711.046\n",
      "    load_throughput: 91013.03\n",
      "    load_time_ms: 109.83\n",
      "    sample_throughput: 67.737\n",
      "    sample_time_ms: 147571.341\n",
      "    update_time_ms: 9.877\n",
      "  timestamp: 1636335466\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2688924\n",
      "  training_iteration: 269\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   269</td><td style=\"text-align: right;\">         41047.4</td><td style=\"text-align: right;\">2688924</td><td style=\"text-align: right;\"> 3.44911</td><td style=\"text-align: right;\">               10.98</td><td style=\"text-align: right;\">               -1.18</td><td style=\"text-align: right;\">           88.7232</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2698920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-40-28\n",
      "  done: false\n",
      "  episode_len_mean: 88.6875\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.55000000000001\n",
      "  episode_reward_mean: 3.6522321428571516\n",
      "  episode_reward_min: -1.4400000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 29366\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3271913061794054\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013284144643602964\n",
      "          policy_loss: -0.07972003694177948\n",
      "          total_loss: 0.052993119036794725\n",
      "          vf_explained_var: 0.9310900568962097\n",
      "          vf_loss: 0.12572212645975062\n",
      "    num_agent_steps_sampled: 2698920\n",
      "    num_agent_steps_trained: 2698920\n",
      "    num_steps_sampled: 2698920\n",
      "    num_steps_trained: 2698920\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.91913043478262\n",
      "    ram_util_percent: 56.14434782608694\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04575388161892654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99626451472755\n",
      "    mean_inference_ms: 2.8613536644178823\n",
      "    mean_raw_obs_processing_ms: 2.975317452131034\n",
      "  time_since_restore: 41208.96442747116\n",
      "  time_this_iter_s: 161.59494256973267\n",
      "  time_total_s: 41208.96442747116\n",
      "  timers:\n",
      "    learn_throughput: 932.798\n",
      "    learn_time_ms: 10716.143\n",
      "    load_throughput: 90931.389\n",
      "    load_time_ms: 109.929\n",
      "    sample_throughput: 66.976\n",
      "    sample_time_ms: 149247.9\n",
      "    update_time_ms: 10.287\n",
      "  timestamp: 1636335628\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2698920\n",
      "  training_iteration: 270\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   270</td><td style=\"text-align: right;\">           41209</td><td style=\"text-align: right;\">2698920</td><td style=\"text-align: right;\"> 3.65223</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           88.6875</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2708916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-43-04\n",
      "  done: false\n",
      "  episode_len_mean: 88.30434782608695\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.050000000000013\n",
      "  episode_reward_mean: 3.491304347826095\n",
      "  episode_reward_min: -2.0699999999999994\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 29481\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.332050629151173\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014084952367522673\n",
      "          policy_loss: -0.0777442912833813\n",
      "          total_loss: 0.06753177712074457\n",
      "          vf_explained_var: 0.910218358039856\n",
      "          vf_loss: 0.13650929138112144\n",
      "    num_agent_steps_sampled: 2708916\n",
      "    num_agent_steps_trained: 2708916\n",
      "    num_steps_sampled: 2708916\n",
      "    num_steps_trained: 2708916\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.02286995515695\n",
      "    ram_util_percent: 56.13004484304933\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04572373603204749\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.000114727675744\n",
      "    mean_inference_ms: 2.8611045095828285\n",
      "    mean_raw_obs_processing_ms: 2.9778699206465364\n",
      "  time_since_restore: 41365.31644463539\n",
      "  time_this_iter_s: 156.35201716423035\n",
      "  time_total_s: 41365.31644463539\n",
      "  timers:\n",
      "    learn_throughput: 933.033\n",
      "    learn_time_ms: 10713.443\n",
      "    load_throughput: 90770.47\n",
      "    load_time_ms: 110.124\n",
      "    sample_throughput: 67.357\n",
      "    sample_time_ms: 148403.253\n",
      "    update_time_ms: 9.494\n",
      "  timestamp: 1636335784\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2708916\n",
      "  training_iteration: 271\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   271</td><td style=\"text-align: right;\">         41365.3</td><td style=\"text-align: right;\">2708916</td><td style=\"text-align: right;\">  3.4913</td><td style=\"text-align: right;\">               13.05</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           88.3043</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2718912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-45-38\n",
      "  done: false\n",
      "  episode_len_mean: 89.16071428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.28000000000001\n",
      "  episode_reward_mean: 3.1620535714285785\n",
      "  episode_reward_min: -1.8500000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 29593\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3438013086971057\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01347845577969753\n",
      "          policy_loss: -0.07913110814988614\n",
      "          total_loss: 0.06234211160076989\n",
      "          vf_explained_var: 0.9254655241966248\n",
      "          vf_loss: 0.13420562431948563\n",
      "    num_agent_steps_sampled: 2718912\n",
      "    num_agent_steps_trained: 2718912\n",
      "    num_steps_sampled: 2718912\n",
      "    num_steps_trained: 2718912\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.94409090909089\n",
      "    ram_util_percent: 56.03863636363635\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574099042738896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00389112131543\n",
      "    mean_inference_ms: 2.8611961249545845\n",
      "    mean_raw_obs_processing_ms: 2.9775499257587725\n",
      "  time_since_restore: 41519.154849529266\n",
      "  time_this_iter_s: 153.83840489387512\n",
      "  time_total_s: 41519.154849529266\n",
      "  timers:\n",
      "    learn_throughput: 933.352\n",
      "    learn_time_ms: 10709.781\n",
      "    load_throughput: 90518.723\n",
      "    load_time_ms: 110.43\n",
      "    sample_throughput: 67.728\n",
      "    sample_time_ms: 147591.171\n",
      "    update_time_ms: 10.727\n",
      "  timestamp: 1636335938\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2718912\n",
      "  training_iteration: 272\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   272</td><td style=\"text-align: right;\">         41519.2</td><td style=\"text-align: right;\">2718912</td><td style=\"text-align: right;\"> 3.16205</td><td style=\"text-align: right;\">                9.28</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           89.1607</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2728908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-48-13\n",
      "  done: false\n",
      "  episode_len_mean: 89.72072072072072\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.560000000000013\n",
      "  episode_reward_mean: 3.909369369369378\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 29704\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3189012011911116\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013237689126356589\n",
      "          policy_loss: -0.0742702613465297\n",
      "          total_loss: 0.0713982396846653\n",
      "          vf_explained_var: 0.9430211186408997\n",
      "          vf_loss: 0.13870040316325732\n",
      "    num_agent_steps_sampled: 2728908\n",
      "    num_agent_steps_trained: 2728908\n",
      "    num_steps_sampled: 2728908\n",
      "    num_steps_trained: 2728908\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.58693693693695\n",
      "    ram_util_percent: 56.18513513513513\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04571362457900108\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00668089908749\n",
      "    mean_inference_ms: 2.8612217419105286\n",
      "    mean_raw_obs_processing_ms: 2.9803907381865704\n",
      "  time_since_restore: 41674.42572426796\n",
      "  time_this_iter_s: 155.27087473869324\n",
      "  time_total_s: 41674.42572426796\n",
      "  timers:\n",
      "    learn_throughput: 933.502\n",
      "    learn_time_ms: 10708.06\n",
      "    load_throughput: 90654.104\n",
      "    load_time_ms: 110.265\n",
      "    sample_throughput: 67.65\n",
      "    sample_time_ms: 147760.621\n",
      "    update_time_ms: 10.188\n",
      "  timestamp: 1636336093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2728908\n",
      "  training_iteration: 273\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   273</td><td style=\"text-align: right;\">         41674.4</td><td style=\"text-align: right;\">2728908</td><td style=\"text-align: right;\"> 3.90937</td><td style=\"text-align: right;\">               12.56</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           89.7207</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2738904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-50-39\n",
      "  done: false\n",
      "  episode_len_mean: 90.13636363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.810000000000013\n",
      "  episode_reward_mean: 3.8169090909090992\n",
      "  episode_reward_min: -1.6000000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 29814\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.320848163376507\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013410258156379931\n",
      "          policy_loss: -0.07993370618384618\n",
      "          total_loss: 0.05444901380369551\n",
      "          vf_explained_var: 0.9301467537879944\n",
      "          vf_loss: 0.12704095710387342\n",
      "    num_agent_steps_sampled: 2738904\n",
      "    num_agent_steps_trained: 2738904\n",
      "    num_steps_sampled: 2738904\n",
      "    num_steps_trained: 2738904\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16778846153846\n",
      "    ram_util_percent: 56.16057692307691\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04572343108136562\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01840971298775\n",
      "    mean_inference_ms: 2.861310459109455\n",
      "    mean_raw_obs_processing_ms: 2.9731845834949366\n",
      "  time_since_restore: 41820.514256715775\n",
      "  time_this_iter_s: 146.08853244781494\n",
      "  time_total_s: 41820.514256715775\n",
      "  timers:\n",
      "    learn_throughput: 934.214\n",
      "    learn_time_ms: 10699.909\n",
      "    load_throughput: 91574.529\n",
      "    load_time_ms: 109.157\n",
      "    sample_throughput: 69.035\n",
      "    sample_time_ms: 144795.757\n",
      "    update_time_ms: 11.022\n",
      "  timestamp: 1636336239\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2738904\n",
      "  training_iteration: 274\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   274</td><td style=\"text-align: right;\">         41820.5</td><td style=\"text-align: right;\">2738904</td><td style=\"text-align: right;\"> 3.81691</td><td style=\"text-align: right;\">               14.81</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           90.1364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2748900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-53-17\n",
      "  done: false\n",
      "  episode_len_mean: 90.71818181818182\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000016\n",
      "  episode_reward_mean: 3.3574545454545537\n",
      "  episode_reward_min: -1.850000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 29924\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3349648917842116\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013527185042516595\n",
      "          policy_loss: -0.077975686518555\n",
      "          total_loss: 0.05163266173420617\n",
      "          vf_explained_var: 0.9400271773338318\n",
      "          vf_loss: 0.12214137855996815\n",
      "    num_agent_steps_sampled: 2748900\n",
      "    num_agent_steps_trained: 2748900\n",
      "    num_steps_sampled: 2748900\n",
      "    num_steps_trained: 2748900\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.76622222222223\n",
      "    ram_util_percent: 56.202222222222204\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574111859798353\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02462620775192\n",
      "    mean_inference_ms: 2.8612509791524205\n",
      "    mean_raw_obs_processing_ms: 2.972950786569998\n",
      "  time_since_restore: 41977.879264593124\n",
      "  time_this_iter_s: 157.36500787734985\n",
      "  time_total_s: 41977.879264593124\n",
      "  timers:\n",
      "    learn_throughput: 934.108\n",
      "    learn_time_ms: 10701.117\n",
      "    load_throughput: 91297.151\n",
      "    load_time_ms: 109.489\n",
      "    sample_throughput: 69.608\n",
      "    sample_time_ms: 143603.874\n",
      "    update_time_ms: 11.793\n",
      "  timestamp: 1636336397\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2748900\n",
      "  training_iteration: 275\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   275</td><td style=\"text-align: right;\">         41977.9</td><td style=\"text-align: right;\">2748900</td><td style=\"text-align: right;\"> 3.35745</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           90.7182</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2758896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-56-16\n",
      "  done: false\n",
      "  episode_len_mean: 87.84210526315789\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.040000000000013\n",
      "  episode_reward_mean: 3.5164035087719374\n",
      "  episode_reward_min: -1.5300000000000005\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 30038\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3224769284582547\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014328083114676371\n",
      "          policy_loss: -0.07114215790429432\n",
      "          total_loss: 0.08568321576931029\n",
      "          vf_explained_var: 0.9231038689613342\n",
      "          vf_loss: 0.14740897753697813\n",
      "    num_agent_steps_sampled: 2758896\n",
      "    num_agent_steps_trained: 2758896\n",
      "    num_steps_sampled: 2758896\n",
      "    num_steps_trained: 2758896\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.977734375\n",
      "    ram_util_percent: 56.07460937500001\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045709490524633335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02634265674066\n",
      "    mean_inference_ms: 2.8612688358722695\n",
      "    mean_raw_obs_processing_ms: 2.9912879559361736\n",
      "  time_since_restore: 42157.38730216026\n",
      "  time_this_iter_s: 179.50803756713867\n",
      "  time_total_s: 42157.38730216026\n",
      "  timers:\n",
      "    learn_throughput: 934.384\n",
      "    learn_time_ms: 10697.956\n",
      "    load_throughput: 91271.87\n",
      "    load_time_ms: 109.519\n",
      "    sample_throughput: 68.116\n",
      "    sample_time_ms: 146750.09\n",
      "    update_time_ms: 12.32\n",
      "  timestamp: 1636336576\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2758896\n",
      "  training_iteration: 276\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   276</td><td style=\"text-align: right;\">         42157.4</td><td style=\"text-align: right;\">2758896</td><td style=\"text-align: right;\">  3.5164</td><td style=\"text-align: right;\">               13.04</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">           87.8421</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2768892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_01-58-52\n",
      "  done: false\n",
      "  episode_len_mean: 89.65178571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.99000000000001\n",
      "  episode_reward_mean: 3.1990178571428642\n",
      "  episode_reward_min: -1.4500000000000004\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 30150\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.33144281501444\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013174911522529746\n",
      "          policy_loss: -0.07667715726181483\n",
      "          total_loss: 0.06899293252290824\n",
      "          vf_explained_var: 0.9229164719581604\n",
      "          vf_loss: 0.13897042182616443\n",
      "    num_agent_steps_sampled: 2768892\n",
      "    num_agent_steps_trained: 2768892\n",
      "    num_steps_sampled: 2768892\n",
      "    num_steps_trained: 2768892\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.25090090090092\n",
      "    ram_util_percent: 56.166666666666664\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045722843448023305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02839014404595\n",
      "    mean_inference_ms: 2.8610672162392796\n",
      "    mean_raw_obs_processing_ms: 2.997595424426813\n",
      "  time_since_restore: 42313.31399297714\n",
      "  time_this_iter_s: 155.92669081687927\n",
      "  time_total_s: 42313.31399297714\n",
      "  timers:\n",
      "    learn_throughput: 934.609\n",
      "    learn_time_ms: 10695.379\n",
      "    load_throughput: 91346.72\n",
      "    load_time_ms: 109.429\n",
      "    sample_throughput: 68.419\n",
      "    sample_time_ms: 146100.6\n",
      "    update_time_ms: 11.754\n",
      "  timestamp: 1636336732\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2768892\n",
      "  training_iteration: 277\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   277</td><td style=\"text-align: right;\">         42313.3</td><td style=\"text-align: right;\">2768892</td><td style=\"text-align: right;\"> 3.19902</td><td style=\"text-align: right;\">               10.99</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           89.6518</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2778888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-02-01\n",
      "  done: false\n",
      "  episode_len_mean: 91.55045871559633\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.560000000000015\n",
      "  episode_reward_mean: 3.9258715596330367\n",
      "  episode_reward_min: -1.470000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 30259\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3032152966556385\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013659935739768566\n",
      "          policy_loss: -0.07859779928739254\n",
      "          total_loss: 0.06456980355497864\n",
      "          vf_explained_var: 0.9392614364624023\n",
      "          vf_loss: 0.13508071293815588\n",
      "    num_agent_steps_sampled: 2778888\n",
      "    num_agent_steps_trained: 2778888\n",
      "    num_steps_sampled: 2778888\n",
      "    num_steps_trained: 2778888\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.64832713754647\n",
      "    ram_util_percent: 56.3081784386617\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04571637733364906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01870888769601\n",
      "    mean_inference_ms: 2.8608557066464115\n",
      "    mean_raw_obs_processing_ms: 3.014063418491132\n",
      "  time_since_restore: 42501.50398373604\n",
      "  time_this_iter_s: 188.18999075889587\n",
      "  time_total_s: 42501.50398373604\n",
      "  timers:\n",
      "    learn_throughput: 934.919\n",
      "    learn_time_ms: 10691.833\n",
      "    load_throughput: 91348.611\n",
      "    load_time_ms: 109.427\n",
      "    sample_throughput: 67.087\n",
      "    sample_time_ms: 149000.294\n",
      "    update_time_ms: 12.997\n",
      "  timestamp: 1636336921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2778888\n",
      "  training_iteration: 278\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   278</td><td style=\"text-align: right;\">         42501.5</td><td style=\"text-align: right;\">2778888</td><td style=\"text-align: right;\"> 3.92587</td><td style=\"text-align: right;\">               12.56</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           91.5505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2788884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-04-22\n",
      "  done: false\n",
      "  episode_len_mean: 91.32727272727273\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.570000000000014\n",
      "  episode_reward_mean: 3.0541818181818257\n",
      "  episode_reward_min: -2.0999999999999988\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 30369\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.314923475135086\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013589715104510238\n",
      "          policy_loss: -0.07763693289688\n",
      "          total_loss: 0.05993893175011771\n",
      "          vf_explained_var: 0.9229065179824829\n",
      "          vf_loss: 0.12976603011529034\n",
      "    num_agent_steps_sampled: 2788884\n",
      "    num_agent_steps_trained: 2788884\n",
      "    num_steps_sampled: 2788884\n",
      "    num_steps_trained: 2788884\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11831683168316\n",
      "    ram_util_percent: 56.10990099009899\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04574257971747319\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02595625145275\n",
      "    mean_inference_ms: 2.8608955353996843\n",
      "    mean_raw_obs_processing_ms: 3.0081656841545894\n",
      "  time_since_restore: 42642.967549324036\n",
      "  time_this_iter_s: 141.46356558799744\n",
      "  time_total_s: 42642.967549324036\n",
      "  timers:\n",
      "    learn_throughput: 934.803\n",
      "    learn_time_ms: 10693.16\n",
      "    load_throughput: 91509.451\n",
      "    load_time_ms: 109.235\n",
      "    sample_throughput: 67.208\n",
      "    sample_time_ms: 148731.289\n",
      "    update_time_ms: 12.624\n",
      "  timestamp: 1636337062\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2788884\n",
      "  training_iteration: 279\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   279</td><td style=\"text-align: right;\">           42643</td><td style=\"text-align: right;\">2788884</td><td style=\"text-align: right;\"> 3.05418</td><td style=\"text-align: right;\">               12.57</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">           91.3273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2798880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-07-06\n",
      "  done: false\n",
      "  episode_len_mean: 90.23636363636363\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.190000000000014\n",
      "  episode_reward_mean: 3.3672727272727347\n",
      "  episode_reward_min: -1.4900000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 30479\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3208967991364307\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013871348219527938\n",
      "          policy_loss: -0.07680904206175071\n",
      "          total_loss: 0.07836487381997653\n",
      "          vf_explained_var: 0.9212888479232788\n",
      "          vf_loss: 0.14678221771764194\n",
      "    num_agent_steps_sampled: 2798880\n",
      "    num_agent_steps_trained: 2798880\n",
      "    num_steps_sampled: 2798880\n",
      "    num_steps_trained: 2798880\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.17939914163088\n",
      "    ram_util_percent: 56.16952789699571\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04570846053301899\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0229624037127\n",
      "    mean_inference_ms: 2.8610035331526755\n",
      "    mean_raw_obs_processing_ms: 3.0087367280406916\n",
      "  time_since_restore: 42806.41139340401\n",
      "  time_this_iter_s: 163.4438440799713\n",
      "  time_total_s: 42806.41139340401\n",
      "  timers:\n",
      "    learn_throughput: 935.089\n",
      "    learn_time_ms: 10689.89\n",
      "    load_throughput: 91534.204\n",
      "    load_time_ms: 109.205\n",
      "    sample_throughput: 67.124\n",
      "    sample_time_ms: 148918.399\n",
      "    update_time_ms: 13.472\n",
      "  timestamp: 1636337226\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2798880\n",
      "  training_iteration: 280\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   280</td><td style=\"text-align: right;\">         42806.4</td><td style=\"text-align: right;\">2798880</td><td style=\"text-align: right;\"> 3.36727</td><td style=\"text-align: right;\">               13.19</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">           90.2364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2808876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-09-50\n",
      "  done: false\n",
      "  episode_len_mean: 90.71171171171171\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.810000000000015\n",
      "  episode_reward_mean: 3.489369369369378\n",
      "  episode_reward_min: -1.7700000000000007\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 30590\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.32667614985735\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012997319046317426\n",
      "          policy_loss: -0.08106255146682771\n",
      "          total_loss: 0.03797994579833287\n",
      "          vf_explained_var: 0.9397525787353516\n",
      "          vf_loss: 0.11269973964693072\n",
      "    num_agent_steps_sampled: 2808876\n",
      "    num_agent_steps_trained: 2808876\n",
      "    num_steps_sampled: 2808876\n",
      "    num_steps_trained: 2808876\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.78170212765957\n",
      "    ram_util_percent: 56.136595744680854\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04570017211942268\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01692962544186\n",
      "    mean_inference_ms: 2.8606266269180725\n",
      "    mean_raw_obs_processing_ms: 3.0164225397388122\n",
      "  time_since_restore: 42971.13841676712\n",
      "  time_this_iter_s: 164.7270233631134\n",
      "  time_total_s: 42971.13841676712\n",
      "  timers:\n",
      "    learn_throughput: 935.05\n",
      "    learn_time_ms: 10690.334\n",
      "    load_throughput: 91765.321\n",
      "    load_time_ms: 108.93\n",
      "    sample_throughput: 66.749\n",
      "    sample_time_ms: 149754.513\n",
      "    update_time_ms: 14.658\n",
      "  timestamp: 1636337390\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2808876\n",
      "  training_iteration: 281\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   281</td><td style=\"text-align: right;\">         42971.1</td><td style=\"text-align: right;\">2808876</td><td style=\"text-align: right;\"> 3.48937</td><td style=\"text-align: right;\">               12.81</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           90.7117</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2818872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-12-11\n",
      "  done: false\n",
      "  episode_len_mean: 91.4074074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.780000000000017\n",
      "  episode_reward_mean: 3.566388888888898\n",
      "  episode_reward_min: -1.9700000000000009\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 30698\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.319905108264369\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014076506946302103\n",
      "          policy_loss: -0.07935386745768608\n",
      "          total_loss: 0.052155013719939775\n",
      "          vf_explained_var: 0.9365021586418152\n",
      "          vf_loss: 0.12263988929633529\n",
      "    num_agent_steps_sampled: 2818872\n",
      "    num_agent_steps_trained: 2818872\n",
      "    num_steps_sampled: 2818872\n",
      "    num_steps_trained: 2818872\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.2845\n",
      "    ram_util_percent: 56.194500000000005\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04571335160606985\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.022954744994735\n",
      "    mean_inference_ms: 2.8608264032475272\n",
      "    mean_raw_obs_processing_ms: 3.007849987422984\n",
      "  time_since_restore: 43111.555430173874\n",
      "  time_this_iter_s: 140.41701340675354\n",
      "  time_total_s: 43111.555430173874\n",
      "  timers:\n",
      "    learn_throughput: 934.709\n",
      "    learn_time_ms: 10694.238\n",
      "    load_throughput: 92107.959\n",
      "    load_time_ms: 108.525\n",
      "    sample_throughput: 67.354\n",
      "    sample_time_ms: 148409.194\n",
      "    update_time_ms: 14.204\n",
      "  timestamp: 1636337531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2818872\n",
      "  training_iteration: 282\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   282</td><td style=\"text-align: right;\">         43111.6</td><td style=\"text-align: right;\">2818872</td><td style=\"text-align: right;\"> 3.56639</td><td style=\"text-align: right;\">               10.78</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           91.4074</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2828868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-14-41\n",
      "  done: false\n",
      "  episode_len_mean: 91.60909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.930000000000016\n",
      "  episode_reward_mean: 3.757454545454554\n",
      "  episode_reward_min: -1.780000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 30808\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.291002618553292\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01380849179580544\n",
      "          policy_loss: -0.0766258130948513\n",
      "          total_loss: 0.07293860380314927\n",
      "          vf_explained_var: 0.9327720403671265\n",
      "          vf_loss: 0.1410169718747274\n",
      "    num_agent_steps_sampled: 2828868\n",
      "    num_agent_steps_trained: 2828868\n",
      "    num_steps_sampled: 2828868\n",
      "    num_steps_trained: 2828868\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78325581395349\n",
      "    ram_util_percent: 56.23860465116279\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045722554483229476\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02378513926128\n",
      "    mean_inference_ms: 2.860778266737318\n",
      "    mean_raw_obs_processing_ms: 3.0073713735982683\n",
      "  time_since_restore: 43261.761850595474\n",
      "  time_this_iter_s: 150.20642042160034\n",
      "  time_total_s: 43261.761850595474\n",
      "  timers:\n",
      "    learn_throughput: 934.145\n",
      "    learn_time_ms: 10700.694\n",
      "    load_throughput: 92092.017\n",
      "    load_time_ms: 108.544\n",
      "    sample_throughput: 67.588\n",
      "    sample_time_ms: 147896.928\n",
      "    update_time_ms: 13.838\n",
      "  timestamp: 1636337681\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2828868\n",
      "  training_iteration: 283\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   283</td><td style=\"text-align: right;\">         43261.8</td><td style=\"text-align: right;\">2828868</td><td style=\"text-align: right;\"> 3.75745</td><td style=\"text-align: right;\">               12.93</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           91.6091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2838864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-17-43\n",
      "  done: false\n",
      "  episode_len_mean: 88.92035398230088\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.050000000000015\n",
      "  episode_reward_mean: 3.786902654867265\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 30921\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3019890648686987\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01395030385030329\n",
      "          policy_loss: -0.07778726247194995\n",
      "          total_loss: 0.0702640461600107\n",
      "          vf_explained_var: 0.9425718784332275\n",
      "          vf_loss: 0.13929066244894878\n",
      "    num_agent_steps_sampled: 2838864\n",
      "    num_agent_steps_trained: 2838864\n",
      "    num_steps_sampled: 2838864\n",
      "    num_steps_trained: 2838864\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.07683397683398\n",
      "    ram_util_percent: 56.22355212355213\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04570832773909232\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.019775419048145\n",
      "    mean_inference_ms: 2.8603847990009332\n",
      "    mean_raw_obs_processing_ms: 3.024458039217912\n",
      "  time_since_restore: 43443.350509643555\n",
      "  time_this_iter_s: 181.58865904808044\n",
      "  time_total_s: 43443.350509643555\n",
      "  timers:\n",
      "    learn_throughput: 933.861\n",
      "    learn_time_ms: 10703.949\n",
      "    load_throughput: 91863.44\n",
      "    load_time_ms: 108.814\n",
      "    sample_throughput: 66.005\n",
      "    sample_time_ms: 151443.718\n",
      "    update_time_ms: 13.64\n",
      "  timestamp: 1636337863\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2838864\n",
      "  training_iteration: 284\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   284</td><td style=\"text-align: right;\">         43443.4</td><td style=\"text-align: right;\">2838864</td><td style=\"text-align: right;\">  3.7869</td><td style=\"text-align: right;\">               14.05</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           88.9204</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2848860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-20-03\n",
      "  done: false\n",
      "  episode_len_mean: 90.9090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.450000000000014\n",
      "  episode_reward_mean: 3.0096363636363708\n",
      "  episode_reward_min: -1.5100000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 31031\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.340269427625542\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01300035808255347\n",
      "          policy_loss: -0.0803151280603284\n",
      "          total_loss: 0.04763845411949178\n",
      "          vf_explained_var: 0.9245647192001343\n",
      "          vf_loss: 0.12173983491320386\n",
      "    num_agent_steps_sampled: 2848860\n",
      "    num_agent_steps_trained: 2848860\n",
      "    num_steps_sampled: 2848860\n",
      "    num_steps_trained: 2848860\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00450000000001\n",
      "    ram_util_percent: 56.32400000000001\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045693130475331904\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0246841493123\n",
      "    mean_inference_ms: 2.860533277440255\n",
      "    mean_raw_obs_processing_ms: 3.0144688540253743\n",
      "  time_since_restore: 43583.95775437355\n",
      "  time_this_iter_s: 140.60724472999573\n",
      "  time_total_s: 43583.95775437355\n",
      "  timers:\n",
      "    learn_throughput: 934.263\n",
      "    learn_time_ms: 10699.339\n",
      "    load_throughput: 92279.488\n",
      "    load_time_ms: 108.323\n",
      "    sample_throughput: 66.741\n",
      "    sample_time_ms: 149773.466\n",
      "    update_time_ms: 13.02\n",
      "  timestamp: 1636338003\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2848860\n",
      "  training_iteration: 285\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   285</td><td style=\"text-align: right;\">           43584</td><td style=\"text-align: right;\">2848860</td><td style=\"text-align: right;\"> 3.00964</td><td style=\"text-align: right;\">               12.45</td><td style=\"text-align: right;\">               -1.51</td><td style=\"text-align: right;\">           90.9091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2858856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-23-12\n",
      "  done: false\n",
      "  episode_len_mean: 91.40366972477064\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.130000000000011\n",
      "  episode_reward_mean: 4.128440366972486\n",
      "  episode_reward_min: -1.6900000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 31140\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3085732682138427\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015089328728082198\n",
      "          policy_loss: -0.07131462623643824\n",
      "          total_loss: 0.10336641076410938\n",
      "          vf_explained_var: 0.8873404860496521\n",
      "          vf_loss: 0.16339139203803663\n",
      "    num_agent_steps_sampled: 2858856\n",
      "    num_agent_steps_trained: 2858856\n",
      "    num_steps_sampled: 2858856\n",
      "    num_steps_trained: 2858856\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.4267657992565\n",
      "    ram_util_percent: 56.33271375464683\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04570882176890486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.028429061414194\n",
      "    mean_inference_ms: 2.860550630299041\n",
      "    mean_raw_obs_processing_ms: 3.0304171532924267\n",
      "  time_since_restore: 43772.31961750984\n",
      "  time_this_iter_s: 188.3618631362915\n",
      "  time_total_s: 43772.31961750984\n",
      "  timers:\n",
      "    learn_throughput: 933.644\n",
      "    learn_time_ms: 10706.435\n",
      "    load_throughput: 92153.916\n",
      "    load_time_ms: 108.471\n",
      "    sample_throughput: 66.352\n",
      "    sample_time_ms: 150651.04\n",
      "    update_time_ms: 13.565\n",
      "  timestamp: 1636338192\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2858856\n",
      "  training_iteration: 286\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   286</td><td style=\"text-align: right;\">         43772.3</td><td style=\"text-align: right;\">2858856</td><td style=\"text-align: right;\"> 4.12844</td><td style=\"text-align: right;\">               13.13</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           91.4037</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2868852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-25-45\n",
      "  done: false\n",
      "  episode_len_mean: 91.20183486238533\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.830000000000013\n",
      "  episode_reward_mean: 3.5050458715596404\n",
      "  episode_reward_min: -1.5400000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 31249\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3221048147250443\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013948505794442251\n",
      "          policy_loss: -0.07437153935400594\n",
      "          total_loss: 0.08954332673874421\n",
      "          vf_explained_var: 0.9224669933319092\n",
      "          vf_loss: 0.1553594740258896\n",
      "    num_agent_steps_sampled: 2868852\n",
      "    num_agent_steps_trained: 2868852\n",
      "    num_steps_sampled: 2868852\n",
      "    num_steps_trained: 2868852\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.00273972602739\n",
      "    ram_util_percent: 56.22237442922375\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04568411985907174\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02872355556234\n",
      "    mean_inference_ms: 2.860402327489639\n",
      "    mean_raw_obs_processing_ms: 3.0385747155716945\n",
      "  time_since_restore: 43925.77926874161\n",
      "  time_this_iter_s: 153.45965123176575\n",
      "  time_total_s: 43925.77926874161\n",
      "  timers:\n",
      "    learn_throughput: 933.655\n",
      "    learn_time_ms: 10706.309\n",
      "    load_throughput: 92215.777\n",
      "    load_time_ms: 108.398\n",
      "    sample_throughput: 66.461\n",
      "    sample_time_ms: 150404.607\n",
      "    update_time_ms: 13.569\n",
      "  timestamp: 1636338345\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2868852\n",
      "  training_iteration: 287\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   287</td><td style=\"text-align: right;\">         43925.8</td><td style=\"text-align: right;\">2868852</td><td style=\"text-align: right;\"> 3.50505</td><td style=\"text-align: right;\">               12.83</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           91.2018</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2878848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-28-37\n",
      "  done: false\n",
      "  episode_len_mean: 92.70642201834862\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.530000000000017\n",
      "  episode_reward_mean: 3.0774311926605575\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 31358\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.340431830006787\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014320166693772398\n",
      "          policy_loss: -0.07534126649554979\n",
      "          total_loss: 0.0835668415734624\n",
      "          vf_explained_var: 0.9094942808151245\n",
      "          vf_loss: 0.1496892956762105\n",
      "    num_agent_steps_sampled: 2878848\n",
      "    num_agent_steps_trained: 2878848\n",
      "    num_steps_sampled: 2878848\n",
      "    num_steps_trained: 2878848\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.30447154471545\n",
      "    ram_util_percent: 56.420731707317074\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04569347468117543\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02276578795399\n",
      "    mean_inference_ms: 2.860102838781409\n",
      "    mean_raw_obs_processing_ms: 3.0496684199129014\n",
      "  time_since_restore: 44097.63119006157\n",
      "  time_this_iter_s: 171.85192131996155\n",
      "  time_total_s: 44097.63119006157\n",
      "  timers:\n",
      "    learn_throughput: 933.11\n",
      "    learn_time_ms: 10712.566\n",
      "    load_throughput: 92190.33\n",
      "    load_time_ms: 108.428\n",
      "    sample_throughput: 67.193\n",
      "    sample_time_ms: 148765.312\n",
      "    update_time_ms: 12.683\n",
      "  timestamp: 1636338517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2878848\n",
      "  training_iteration: 288\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   288</td><td style=\"text-align: right;\">         44097.6</td><td style=\"text-align: right;\">2878848</td><td style=\"text-align: right;\"> 3.07743</td><td style=\"text-align: right;\">               12.53</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           92.7064</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2888844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-31-16\n",
      "  done: false\n",
      "  episode_len_mean: 91.22018348623853\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.200000000000014\n",
      "  episode_reward_mean: 3.9807339449541366\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 31467\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.30450394092462\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014032927468433834\n",
      "          policy_loss: -0.07877176730997032\n",
      "          total_loss: 0.07283785111692725\n",
      "          vf_explained_var: 0.9283273816108704\n",
      "          vf_loss: 0.1426858951807277\n",
      "    num_agent_steps_sampled: 2888844\n",
      "    num_agent_steps_trained: 2888844\n",
      "    num_steps_sampled: 2888844\n",
      "    num_steps_trained: 2888844\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.50132743362833\n",
      "    ram_util_percent: 56.2849557522124\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045690279804514185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01954330017231\n",
      "    mean_inference_ms: 2.859991968187438\n",
      "    mean_raw_obs_processing_ms: 3.0517995988733038\n",
      "  time_since_restore: 44255.99902009964\n",
      "  time_this_iter_s: 158.36783003807068\n",
      "  time_total_s: 44255.99902009964\n",
      "  timers:\n",
      "    learn_throughput: 933.848\n",
      "    learn_time_ms: 10704.1\n",
      "    load_throughput: 92008.691\n",
      "    load_time_ms: 108.642\n",
      "    sample_throughput: 66.435\n",
      "    sample_time_ms: 150463.687\n",
      "    update_time_ms: 12.921\n",
      "  timestamp: 1636338676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2888844\n",
      "  training_iteration: 289\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   289</td><td style=\"text-align: right;\">           44256</td><td style=\"text-align: right;\">2888844</td><td style=\"text-align: right;\"> 3.98073</td><td style=\"text-align: right;\">                14.2</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           91.2202</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2898840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-34-01\n",
      "  done: false\n",
      "  episode_len_mean: 90.06363636363636\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.880000000000011\n",
      "  episode_reward_mean: 3.1631818181818243\n",
      "  episode_reward_min: -1.2799999999999998\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 31577\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.32152987728771\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012838104857929569\n",
      "          policy_loss: -0.0775048727527834\n",
      "          total_loss: 0.06258308177447727\n",
      "          vf_explained_var: 0.9299209713935852\n",
      "          vf_loss: 0.1340564454563408\n",
      "    num_agent_steps_sampled: 2898840\n",
      "    num_agent_steps_trained: 2898840\n",
      "    num_steps_sampled: 2898840\n",
      "    num_steps_trained: 2898840\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.26\n",
      "    ram_util_percent: 56.16085106382978\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045672114014783105\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01929341730038\n",
      "    mean_inference_ms: 2.8599307278557853\n",
      "    mean_raw_obs_processing_ms: 3.0539806438707244\n",
      "  time_since_restore: 44421.03382587433\n",
      "  time_this_iter_s: 165.03480577468872\n",
      "  time_total_s: 44421.03382587433\n",
      "  timers:\n",
      "    learn_throughput: 934.191\n",
      "    learn_time_ms: 10700.171\n",
      "    load_throughput: 91990.401\n",
      "    load_time_ms: 108.664\n",
      "    sample_throughput: 66.362\n",
      "    sample_time_ms: 150627.797\n",
      "    update_time_ms: 11.744\n",
      "  timestamp: 1636338841\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2898840\n",
      "  training_iteration: 290\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   290</td><td style=\"text-align: right;\">           44421</td><td style=\"text-align: right;\">2898840</td><td style=\"text-align: right;\"> 3.16318</td><td style=\"text-align: right;\">               10.88</td><td style=\"text-align: right;\">               -1.28</td><td style=\"text-align: right;\">           90.0636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2908836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-36-32\n",
      "  done: false\n",
      "  episode_len_mean: 90.74107142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.730000000000013\n",
      "  episode_reward_mean: 3.825982142857151\n",
      "  episode_reward_min: -1.0400000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 31689\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3025948856630896\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014093008983669412\n",
      "          policy_loss: -0.07741713155952529\n",
      "          total_loss: 0.0789498971361253\n",
      "          vf_explained_var: 0.9205562472343445\n",
      "          vf_loss: 0.14728734085543288\n",
      "    num_agent_steps_sampled: 2908836\n",
      "    num_agent_steps_trained: 2908836\n",
      "    num_steps_sampled: 2908836\n",
      "    num_steps_trained: 2908836\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.75529953917051\n",
      "    ram_util_percent: 56.13870967741936\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045688215482313964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02114496614189\n",
      "    mean_inference_ms: 2.8600624072412892\n",
      "    mean_raw_obs_processing_ms: 3.052513037607376\n",
      "  time_since_restore: 44572.79427242279\n",
      "  time_this_iter_s: 151.7604465484619\n",
      "  time_total_s: 44572.79427242279\n",
      "  timers:\n",
      "    learn_throughput: 934.296\n",
      "    learn_time_ms: 10698.966\n",
      "    load_throughput: 91906.252\n",
      "    load_time_ms: 108.763\n",
      "    sample_throughput: 66.938\n",
      "    sample_time_ms: 149332.818\n",
      "    update_time_ms: 11.115\n",
      "  timestamp: 1636338992\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2908836\n",
      "  training_iteration: 291\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   291</td><td style=\"text-align: right;\">         44572.8</td><td style=\"text-align: right;\">2908836</td><td style=\"text-align: right;\"> 3.82598</td><td style=\"text-align: right;\">               12.73</td><td style=\"text-align: right;\">               -1.04</td><td style=\"text-align: right;\">           90.7411</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2918832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-39-20\n",
      "  done: false\n",
      "  episode_len_mean: 89.73873873873873\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.200000000000017\n",
      "  episode_reward_mean: 3.6695495495495583\n",
      "  episode_reward_min: -1.4700000000000004\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 31800\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3118348327457396\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013351603444698578\n",
      "          policy_loss: -0.07399737469247009\n",
      "          total_loss: 0.06332457484279433\n",
      "          vf_explained_var: 0.9381957054138184\n",
      "          vf_loss: 0.1300236753323394\n",
      "    num_agent_steps_sampled: 2918832\n",
      "    num_agent_steps_trained: 2918832\n",
      "    num_steps_sampled: 2918832\n",
      "    num_steps_trained: 2918832\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.64602510460251\n",
      "    ram_util_percent: 56.3589958158996\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567559701124465\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.022543039287555\n",
      "    mean_inference_ms: 2.8598833982862155\n",
      "    mean_raw_obs_processing_ms: 3.055765283512967\n",
      "  time_since_restore: 44740.430032253265\n",
      "  time_this_iter_s: 167.63575983047485\n",
      "  time_total_s: 44740.430032253265\n",
      "  timers:\n",
      "    learn_throughput: 934.079\n",
      "    learn_time_ms: 10701.448\n",
      "    load_throughput: 91819.642\n",
      "    load_time_ms: 108.866\n",
      "    sample_throughput: 65.741\n",
      "    sample_time_ms: 152052.204\n",
      "    update_time_ms: 10.865\n",
      "  timestamp: 1636339160\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2918832\n",
      "  training_iteration: 292\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   292</td><td style=\"text-align: right;\">         44740.4</td><td style=\"text-align: right;\">2918832</td><td style=\"text-align: right;\"> 3.66955</td><td style=\"text-align: right;\">                14.2</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           89.7387</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2928828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-41-52\n",
      "  done: false\n",
      "  episode_len_mean: 92.08333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.850000000000016\n",
      "  episode_reward_mean: 2.937870370370378\n",
      "  episode_reward_min: -1.680000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 31908\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.333870546838157\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012968821566463593\n",
      "          policy_loss: -0.08042227674562197\n",
      "          total_loss: 0.04624432006484678\n",
      "          vf_explained_var: 0.9150016903877258\n",
      "          vf_loss: 0.12046070441078299\n",
      "    num_agent_steps_sampled: 2928828\n",
      "    num_agent_steps_trained: 2928828\n",
      "    num_steps_sampled: 2928828\n",
      "    num_steps_trained: 2928828\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.45529953917053\n",
      "    ram_util_percent: 56.35115207373273\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567802373933062\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02244145960182\n",
      "    mean_inference_ms: 2.8599088162894732\n",
      "    mean_raw_obs_processing_ms: 3.053933591904007\n",
      "  time_since_restore: 44892.189655542374\n",
      "  time_this_iter_s: 151.75962328910828\n",
      "  time_total_s: 44892.189655542374\n",
      "  timers:\n",
      "    learn_throughput: 934.211\n",
      "    learn_time_ms: 10699.935\n",
      "    load_throughput: 91799.377\n",
      "    load_time_ms: 108.89\n",
      "    sample_throughput: 65.673\n",
      "    sample_time_ms: 152208.811\n",
      "    update_time_ms: 10.772\n",
      "  timestamp: 1636339312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2928828\n",
      "  training_iteration: 293\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   293</td><td style=\"text-align: right;\">         44892.2</td><td style=\"text-align: right;\">2928828</td><td style=\"text-align: right;\"> 2.93787</td><td style=\"text-align: right;\">               12.85</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           92.0833</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2938824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-44-26\n",
      "  done: false\n",
      "  episode_len_mean: 90.60909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.980000000000015\n",
      "  episode_reward_mean: 3.1244545454545527\n",
      "  episode_reward_min: -1.3000000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 32018\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3368676625765286\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013508710730205714\n",
      "          policy_loss: -0.07794395602570894\n",
      "          total_loss: 0.053616719038631674\n",
      "          vf_explained_var: 0.9216579794883728\n",
      "          vf_loss: 0.12415481833900269\n",
      "    num_agent_steps_sampled: 2938824\n",
      "    num_agent_steps_trained: 2938824\n",
      "    num_steps_sampled: 2938824\n",
      "    num_steps_trained: 2938824\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.29132420091325\n",
      "    ram_util_percent: 56.29178082191782\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045694162435363755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02585855875282\n",
      "    mean_inference_ms: 2.8601120913625024\n",
      "    mean_raw_obs_processing_ms: 3.0522057725915728\n",
      "  time_since_restore: 45045.969489336014\n",
      "  time_this_iter_s: 153.77983379364014\n",
      "  time_total_s: 45045.969489336014\n",
      "  timers:\n",
      "    learn_throughput: 934.611\n",
      "    learn_time_ms: 10695.362\n",
      "    load_throughput: 91946.442\n",
      "    load_time_ms: 108.715\n",
      "    sample_throughput: 66.893\n",
      "    sample_time_ms: 149432.561\n",
      "    update_time_ms: 10.899\n",
      "  timestamp: 1636339466\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2938824\n",
      "  training_iteration: 294\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   294</td><td style=\"text-align: right;\">           45046</td><td style=\"text-align: right;\">2938824</td><td style=\"text-align: right;\"> 3.12445</td><td style=\"text-align: right;\">               12.98</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">           90.6091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2948820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-47-10\n",
      "  done: false\n",
      "  episode_len_mean: 90.56756756756756\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.830000000000013\n",
      "  episode_reward_mean: 3.4536936936937024\n",
      "  episode_reward_min: -1.5300000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 32129\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3002869964664816\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01308071714492305\n",
      "          policy_loss: -0.08066574098526412\n",
      "          total_loss: 0.048067369951237726\n",
      "          vf_explained_var: 0.9323979020118713\n",
      "          vf_loss: 0.12193647166793672\n",
      "    num_agent_steps_sampled: 2948820\n",
      "    num_agent_steps_trained: 2948820\n",
      "    num_steps_sampled: 2948820\n",
      "    num_steps_trained: 2948820\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.54615384615386\n",
      "    ram_util_percent: 56.182051282051276\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04565752807280648\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.021513540198264\n",
      "    mean_inference_ms: 2.8599027458444675\n",
      "    mean_raw_obs_processing_ms: 3.060368604312323\n",
      "  time_since_restore: 45210.33830857277\n",
      "  time_this_iter_s: 164.36881923675537\n",
      "  time_total_s: 45210.33830857277\n",
      "  timers:\n",
      "    learn_throughput: 934.933\n",
      "    learn_time_ms: 10691.673\n",
      "    load_throughput: 91812.384\n",
      "    load_time_ms: 108.874\n",
      "    sample_throughput: 65.844\n",
      "    sample_time_ms: 151812.543\n",
      "    update_time_ms: 10.783\n",
      "  timestamp: 1636339630\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2948820\n",
      "  training_iteration: 295\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   295</td><td style=\"text-align: right;\">         45210.3</td><td style=\"text-align: right;\">2948820</td><td style=\"text-align: right;\"> 3.45369</td><td style=\"text-align: right;\">               10.83</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">           90.5676</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2958816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-49-50\n",
      "  done: false\n",
      "  episode_len_mean: 90.4090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.860000000000015\n",
      "  episode_reward_mean: 4.3267272727272825\n",
      "  episode_reward_min: -1.0500000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 32239\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2930141835131197\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014273285762268792\n",
      "          policy_loss: -0.07641386196303826\n",
      "          total_loss: 0.07475103665557173\n",
      "          vf_explained_var: 0.9393163323402405\n",
      "          vf_loss: 0.14157870966049596\n",
      "    num_agent_steps_sampled: 2958816\n",
      "    num_agent_steps_trained: 2958816\n",
      "    num_steps_sampled: 2958816\n",
      "    num_steps_trained: 2958816\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.73464912280701\n",
      "    ram_util_percent: 56.33596491228071\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567270683520005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03219084524427\n",
      "    mean_inference_ms: 2.859641308779323\n",
      "    mean_raw_obs_processing_ms: 3.0612955371906025\n",
      "  time_since_restore: 45369.80323123932\n",
      "  time_this_iter_s: 159.46492266654968\n",
      "  time_total_s: 45369.80323123932\n",
      "  timers:\n",
      "    learn_throughput: 935.335\n",
      "    learn_time_ms: 10687.077\n",
      "    load_throughput: 91985.033\n",
      "    load_time_ms: 108.67\n",
      "    sample_throughput: 67.12\n",
      "    sample_time_ms: 148927.882\n",
      "    update_time_ms: 10.623\n",
      "  timestamp: 1636339790\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2958816\n",
      "  training_iteration: 296\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   296</td><td style=\"text-align: right;\">         45369.8</td><td style=\"text-align: right;\">2958816</td><td style=\"text-align: right;\"> 4.32673</td><td style=\"text-align: right;\">               14.86</td><td style=\"text-align: right;\">               -1.05</td><td style=\"text-align: right;\">           90.4091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2968812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-52-18\n",
      "  done: false\n",
      "  episode_len_mean: 92.86111111111111\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.920000000000016\n",
      "  episode_reward_mean: 3.587777777777786\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 32347\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3121811245241735\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013794658056032085\n",
      "          policy_loss: -0.07607949097664693\n",
      "          total_loss: 0.05996192949386234\n",
      "          vf_explained_var: 0.9224866032600403\n",
      "          vf_loss: 0.12773727532635387\n",
      "    num_agent_steps_sampled: 2968812\n",
      "    num_agent_steps_trained: 2968812\n",
      "    num_steps_sampled: 2968812\n",
      "    num_steps_trained: 2968812\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.73632075471697\n",
      "    ram_util_percent: 56.2877358490566\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045678827246331266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03062297123629\n",
      "    mean_inference_ms: 2.859734868949945\n",
      "    mean_raw_obs_processing_ms: 3.059615136937243\n",
      "  time_since_restore: 45518.41156578064\n",
      "  time_this_iter_s: 148.6083345413208\n",
      "  time_total_s: 45518.41156578064\n",
      "  timers:\n",
      "    learn_throughput: 934.985\n",
      "    learn_time_ms: 10691.076\n",
      "    load_throughput: 91983.257\n",
      "    load_time_ms: 108.672\n",
      "    sample_throughput: 67.341\n",
      "    sample_time_ms: 148438.6\n",
      "    update_time_ms: 11.065\n",
      "  timestamp: 1636339938\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2968812\n",
      "  training_iteration: 297\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   297</td><td style=\"text-align: right;\">         45518.4</td><td style=\"text-align: right;\">2968812</td><td style=\"text-align: right;\"> 3.58778</td><td style=\"text-align: right;\">               12.92</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           92.8611</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2978808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-54-54\n",
      "  done: false\n",
      "  episode_len_mean: 89.54054054054055\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.810000000000013\n",
      "  episode_reward_mean: 3.366216216216224\n",
      "  episode_reward_min: -1.8900000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 32458\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3105558118249614\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014729702139811337\n",
      "          policy_loss: -0.07619124489287153\n",
      "          total_loss: 0.09487720592520558\n",
      "          vf_explained_var: 0.9294339418411255\n",
      "          vf_loss: 0.1606179057341865\n",
      "    num_agent_steps_sampled: 2978808\n",
      "    num_agent_steps_trained: 2978808\n",
      "    num_steps_sampled: 2978808\n",
      "    num_steps_trained: 2978808\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.11306306306305\n",
      "    ram_util_percent: 56.30810810810811\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045638230379739735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03073475430958\n",
      "    mean_inference_ms: 2.8597893660916185\n",
      "    mean_raw_obs_processing_ms: 3.0604400821991953\n",
      "  time_since_restore: 45673.86745715141\n",
      "  time_this_iter_s: 155.45589137077332\n",
      "  time_total_s: 45673.86745715141\n",
      "  timers:\n",
      "    learn_throughput: 935.269\n",
      "    learn_time_ms: 10687.838\n",
      "    load_throughput: 91890.399\n",
      "    load_time_ms: 108.782\n",
      "    sample_throughput: 68.092\n",
      "    sample_time_ms: 146801.486\n",
      "    update_time_ms: 11.252\n",
      "  timestamp: 1636340094\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2978808\n",
      "  training_iteration: 298\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   298</td><td style=\"text-align: right;\">         45673.9</td><td style=\"text-align: right;\">2978808</td><td style=\"text-align: right;\"> 3.36622</td><td style=\"text-align: right;\">               12.81</td><td style=\"text-align: right;\">               -1.89</td><td style=\"text-align: right;\">           89.5405</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2988804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_02-57-46\n",
      "  done: false\n",
      "  episode_len_mean: 90.05357142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.94999999999999\n",
      "  episode_reward_mean: 3.745446428571436\n",
      "  episode_reward_min: -2.04\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 32570\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.291561312145657\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01414886684614145\n",
      "          policy_loss: -0.07341664472005816\n",
      "          total_loss: 0.09050329676391478\n",
      "          vf_explained_var: 0.9228647351264954\n",
      "          vf_loss: 0.15460266643880397\n",
      "    num_agent_steps_sampled: 2988804\n",
      "    num_agent_steps_trained: 2988804\n",
      "    num_steps_sampled: 2988804\n",
      "    num_steps_trained: 2988804\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.19551020408164\n",
      "    ram_util_percent: 56.38857142857142\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045641242519872775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03418840864987\n",
      "    mean_inference_ms: 2.859685147064019\n",
      "    mean_raw_obs_processing_ms: 3.065097502788767\n",
      "  time_since_restore: 45845.73872423172\n",
      "  time_this_iter_s: 171.871267080307\n",
      "  time_total_s: 45845.73872423172\n",
      "  timers:\n",
      "    learn_throughput: 934.545\n",
      "    learn_time_ms: 10696.11\n",
      "    load_throughput: 92003.442\n",
      "    load_time_ms: 108.648\n",
      "    sample_throughput: 67.475\n",
      "    sample_time_ms: 148143.93\n",
      "    update_time_ms: 11.007\n",
      "  timestamp: 1636340266\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2988804\n",
      "  training_iteration: 299\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   299</td><td style=\"text-align: right;\">         45845.7</td><td style=\"text-align: right;\">2988804</td><td style=\"text-align: right;\"> 3.74545</td><td style=\"text-align: right;\">               16.95</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           90.0536</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 2998800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-00-54\n",
      "  done: false\n",
      "  episode_len_mean: 91.19266055045871\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.690000000000014\n",
      "  episode_reward_mean: 3.6282568807339546\n",
      "  episode_reward_min: -1.6900000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 32679\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.3146348794301352\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01352763806854723\n",
      "          policy_loss: -0.07601152987370634\n",
      "          total_loss: 0.07774508781412728\n",
      "          vf_explained_var: 0.9215949773788452\n",
      "          vf_loss: 0.14608531476786504\n",
      "    num_agent_steps_sampled: 2998800\n",
      "    num_agent_steps_trained: 2998800\n",
      "    num_steps_sampled: 2998800\n",
      "    num_steps_trained: 2998800\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.95018587360595\n",
      "    ram_util_percent: 56.343122676579924\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04570729950601927\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03214799269609\n",
      "    mean_inference_ms: 2.859794368380957\n",
      "    mean_raw_obs_processing_ms: 3.0903458716531667\n",
      "  time_since_restore: 46034.32147192955\n",
      "  time_this_iter_s: 188.5827476978302\n",
      "  time_total_s: 46034.32147192955\n",
      "  timers:\n",
      "    learn_throughput: 933.836\n",
      "    learn_time_ms: 10704.239\n",
      "    load_throughput: 91944.708\n",
      "    load_time_ms: 108.718\n",
      "    sample_throughput: 66.423\n",
      "    sample_time_ms: 150491.067\n",
      "    update_time_ms: 10.498\n",
      "  timestamp: 1636340454\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2998800\n",
      "  training_iteration: 300\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   300</td><td style=\"text-align: right;\">         46034.3</td><td style=\"text-align: right;\">2998800</td><td style=\"text-align: right;\"> 3.62826</td><td style=\"text-align: right;\">               12.69</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           91.1927</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3008796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-03-15\n",
      "  done: false\n",
      "  episode_len_mean: 91.26605504587155\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.150000000000013\n",
      "  episode_reward_mean: 3.653119266055054\n",
      "  episode_reward_min: -1.990000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 32788\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.30558620538467\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013904272899989065\n",
      "          policy_loss: -0.07510018111803593\n",
      "          total_loss: 0.09181024745409178\n",
      "          vf_explained_var: 0.9253290891647339\n",
      "          vf_loss: 0.15829061745610248\n",
      "    num_agent_steps_sampled: 3008796\n",
      "    num_agent_steps_trained: 3008796\n",
      "    num_steps_sampled: 3008796\n",
      "    num_steps_trained: 3008796\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7905472636816\n",
      "    ram_util_percent: 56.316417910447775\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04566865182408679\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.036619022772896\n",
      "    mean_inference_ms: 2.859757802561351\n",
      "    mean_raw_obs_processing_ms: 3.079952713473503\n",
      "  time_since_restore: 46174.790028333664\n",
      "  time_this_iter_s: 140.46855640411377\n",
      "  time_total_s: 46174.790028333664\n",
      "  timers:\n",
      "    learn_throughput: 934.046\n",
      "    learn_time_ms: 10701.832\n",
      "    load_throughput: 92038.201\n",
      "    load_time_ms: 108.607\n",
      "    sample_throughput: 66.924\n",
      "    sample_time_ms: 149364.395\n",
      "    update_time_ms: 10.342\n",
      "  timestamp: 1636340595\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3008796\n",
      "  training_iteration: 301\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   301</td><td style=\"text-align: right;\">         46174.8</td><td style=\"text-align: right;\">3008796</td><td style=\"text-align: right;\"> 3.65312</td><td style=\"text-align: right;\">               11.15</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           91.2661</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3018792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-05-51\n",
      "  done: false\n",
      "  episode_len_mean: 89.69642857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.480000000000016\n",
      "  episode_reward_mean: 4.006160714285723\n",
      "  episode_reward_min: -1.5600000000000007\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 32900\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2599156927858663\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014731068288079683\n",
      "          policy_loss: -0.0762932083903788\n",
      "          total_loss: 0.09180384700576592\n",
      "          vf_explained_var: 0.9364080429077148\n",
      "          vf_loss: 0.15713699656323746\n",
      "    num_agent_steps_sampled: 3018792\n",
      "    num_agent_steps_trained: 3018792\n",
      "    num_steps_sampled: 3018792\n",
      "    num_steps_trained: 3018792\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.65067264573992\n",
      "    ram_util_percent: 56.253363228699534\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04566815536745077\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03921693895342\n",
      "    mean_inference_ms: 2.859676591097661\n",
      "    mean_raw_obs_processing_ms: 3.0838409206048545\n",
      "  time_since_restore: 46331.082693099976\n",
      "  time_this_iter_s: 156.29266476631165\n",
      "  time_total_s: 46331.082693099976\n",
      "  timers:\n",
      "    learn_throughput: 934.044\n",
      "    learn_time_ms: 10701.848\n",
      "    load_throughput: 91824.207\n",
      "    load_time_ms: 108.86\n",
      "    sample_throughput: 67.435\n",
      "    sample_time_ms: 148230.665\n",
      "    update_time_ms: 9.88\n",
      "  timestamp: 1636340751\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3018792\n",
      "  training_iteration: 302\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   302</td><td style=\"text-align: right;\">         46331.1</td><td style=\"text-align: right;\">3018792</td><td style=\"text-align: right;\"> 4.00616</td><td style=\"text-align: right;\">               14.48</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           89.6964</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3028788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-08-25\n",
      "  done: false\n",
      "  episode_len_mean: 89.75892857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.810000000000013\n",
      "  episode_reward_mean: 3.6880357142857227\n",
      "  episode_reward_min: -1.870000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 33012\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.287842667612255\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013424222039778225\n",
      "          policy_loss: -0.07897596758368433\n",
      "          total_loss: 0.07609384566481807\n",
      "          vf_explained_var: 0.9320546388626099\n",
      "          vf_loss: 0.14736618235325202\n",
      "    num_agent_steps_sampled: 3028788\n",
      "    num_agent_steps_trained: 3028788\n",
      "    num_steps_sampled: 3028788\n",
      "    num_steps_trained: 3028788\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.84794520547948\n",
      "    ram_util_percent: 56.24657534246575\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567533456642635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.042620596615194\n",
      "    mean_inference_ms: 2.859797997891641\n",
      "    mean_raw_obs_processing_ms: 3.0807173325887254\n",
      "  time_since_restore: 46484.349373579025\n",
      "  time_this_iter_s: 153.26668047904968\n",
      "  time_total_s: 46484.349373579025\n",
      "  timers:\n",
      "    learn_throughput: 934.555\n",
      "    learn_time_ms: 10696.005\n",
      "    load_throughput: 91878.78\n",
      "    load_time_ms: 108.796\n",
      "    sample_throughput: 67.364\n",
      "    sample_time_ms: 148387.016\n",
      "    update_time_ms: 10.281\n",
      "  timestamp: 1636340905\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3028788\n",
      "  training_iteration: 303\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   303</td><td style=\"text-align: right;\">         46484.3</td><td style=\"text-align: right;\">3028788</td><td style=\"text-align: right;\"> 3.68804</td><td style=\"text-align: right;\">               12.81</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">           89.7589</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3038784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-11-10\n",
      "  done: false\n",
      "  episode_len_mean: 89.01801801801801\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.980000000000015\n",
      "  episode_reward_mean: 4.179639639639649\n",
      "  episode_reward_min: -1.1500000000000004\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 33123\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2663751411641764\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014850025736966458\n",
      "          policy_loss: -0.07677815055203999\n",
      "          total_loss: 0.0991389229766324\n",
      "          vf_explained_var: 0.9334408044815063\n",
      "          vf_loss: 0.16475060880502573\n",
      "    num_agent_steps_sampled: 3038784\n",
      "    num_agent_steps_trained: 3038784\n",
      "    num_steps_sampled: 3038784\n",
      "    num_steps_trained: 3038784\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.54322033898305\n",
      "    ram_util_percent: 56.440677966101696\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04565335161780156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04144859193579\n",
      "    mean_inference_ms: 2.8596761759073903\n",
      "    mean_raw_obs_processing_ms: 3.0830365154634856\n",
      "  time_since_restore: 46649.741770744324\n",
      "  time_this_iter_s: 165.39239716529846\n",
      "  time_total_s: 46649.741770744324\n",
      "  timers:\n",
      "    learn_throughput: 933.952\n",
      "    learn_time_ms: 10702.904\n",
      "    load_throughput: 91738.234\n",
      "    load_time_ms: 108.962\n",
      "    sample_throughput: 66.845\n",
      "    sample_time_ms: 149541.024\n",
      "    update_time_ms: 10.431\n",
      "  timestamp: 1636341070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3038784\n",
      "  training_iteration: 304\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   304</td><td style=\"text-align: right;\">         46649.7</td><td style=\"text-align: right;\">3038784</td><td style=\"text-align: right;\"> 4.17964</td><td style=\"text-align: right;\">               10.98</td><td style=\"text-align: right;\">               -1.15</td><td style=\"text-align: right;\">            89.018</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3048780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-13-29\n",
      "  done: false\n",
      "  episode_len_mean: 91.73636363636363\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.960000000000013\n",
      "  episode_reward_mean: 3.747363636363646\n",
      "  episode_reward_min: -1.2000000000000004\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 33233\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.281994484632443\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013100208095922009\n",
      "          policy_loss: -0.07689594034678661\n",
      "          total_loss: 0.06970502359187629\n",
      "          vf_explained_var: 0.9314793348312378\n",
      "          vf_loss: 0.13957699646090724\n",
      "    num_agent_steps_sampled: 3048780\n",
      "    num_agent_steps_trained: 3048780\n",
      "    num_steps_sampled: 3048780\n",
      "    num_steps_trained: 3048780\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85909090909092\n",
      "    ram_util_percent: 56.38838383838385\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04566539636904103\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04497725350762\n",
      "    mean_inference_ms: 2.8598089779830356\n",
      "    mean_raw_obs_processing_ms: 3.0762156640898453\n",
      "  time_since_restore: 46788.83675098419\n",
      "  time_this_iter_s: 139.09498023986816\n",
      "  time_total_s: 46788.83675098419\n",
      "  timers:\n",
      "    learn_throughput: 932.641\n",
      "    learn_time_ms: 10717.955\n",
      "    load_throughput: 91689.081\n",
      "    load_time_ms: 109.021\n",
      "    sample_throughput: 68.001\n",
      "    sample_time_ms: 146997.576\n",
      "    update_time_ms: 11.52\n",
      "  timestamp: 1636341209\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3048780\n",
      "  training_iteration: 305\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   305</td><td style=\"text-align: right;\">         46788.8</td><td style=\"text-align: right;\">3048780</td><td style=\"text-align: right;\"> 3.74736</td><td style=\"text-align: right;\">               10.96</td><td style=\"text-align: right;\">                -1.2</td><td style=\"text-align: right;\">           91.7364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3058776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-16-16\n",
      "  done: false\n",
      "  episode_len_mean: 90.46363636363637\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.050000000000013\n",
      "  episode_reward_mean: 3.590090909090918\n",
      "  episode_reward_min: -1.6200000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 33343\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.285744542341966\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014225853104995082\n",
      "          policy_loss: -0.07215627933748894\n",
      "          total_loss: 0.08405771514830682\n",
      "          vf_explained_var: 0.9334003925323486\n",
      "          vf_loss: 0.14666316681820105\n",
      "    num_agent_steps_sampled: 3058776\n",
      "    num_agent_steps_trained: 3058776\n",
      "    num_steps_sampled: 3058776\n",
      "    num_steps_trained: 3058776\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.39581589958158\n",
      "    ram_util_percent: 56.25230125523012\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567724290706412\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04635409371853\n",
      "    mean_inference_ms: 2.85964607507142\n",
      "    mean_raw_obs_processing_ms: 3.081604883296415\n",
      "  time_since_restore: 46956.10451436043\n",
      "  time_this_iter_s: 167.26776337623596\n",
      "  time_total_s: 46956.10451436043\n",
      "  timers:\n",
      "    learn_throughput: 932.942\n",
      "    learn_time_ms: 10714.498\n",
      "    load_throughput: 91476.108\n",
      "    load_time_ms: 109.274\n",
      "    sample_throughput: 67.64\n",
      "    sample_time_ms: 147781.362\n",
      "    update_time_ms: 11.419\n",
      "  timestamp: 1636341376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3058776\n",
      "  training_iteration: 306\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   306</td><td style=\"text-align: right;\">         46956.1</td><td style=\"text-align: right;\">3058776</td><td style=\"text-align: right;\"> 3.59009</td><td style=\"text-align: right;\">               13.05</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">           90.4636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3068772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-19-11\n",
      "  done: false\n",
      "  episode_len_mean: 90.86363636363636\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.760000000000018\n",
      "  episode_reward_mean: 4.01881818181819\n",
      "  episode_reward_min: -1.4800000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 33453\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.284923804519523\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01374788412219921\n",
      "          policy_loss: -0.07118433981847305\n",
      "          total_loss: 0.09003026024717041\n",
      "          vf_explained_var: 0.9300100803375244\n",
      "          vf_loss: 0.15274443813384725\n",
      "    num_agent_steps_sampled: 3068772\n",
      "    num_agent_steps_trained: 3068772\n",
      "    num_steps_sampled: 3068772\n",
      "    num_steps_trained: 3068772\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.15903614457831\n",
      "    ram_util_percent: 56.33212851405623\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567113474092899\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.045234694465414\n",
      "    mean_inference_ms: 2.8593348867784574\n",
      "    mean_raw_obs_processing_ms: 3.093243103472816\n",
      "  time_since_restore: 47130.510800123215\n",
      "  time_this_iter_s: 174.40628576278687\n",
      "  time_total_s: 47130.510800123215\n",
      "  timers:\n",
      "    learn_throughput: 933.342\n",
      "    learn_time_ms: 10709.9\n",
      "    load_throughput: 91490.281\n",
      "    load_time_ms: 109.258\n",
      "    sample_throughput: 66.478\n",
      "    sample_time_ms: 150366.069\n",
      "    update_time_ms: 11.109\n",
      "  timestamp: 1636341551\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3068772\n",
      "  training_iteration: 307\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   307</td><td style=\"text-align: right;\">         47130.5</td><td style=\"text-align: right;\">3068772</td><td style=\"text-align: right;\"> 4.01882</td><td style=\"text-align: right;\">               12.76</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           90.8636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3078768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-21-44\n",
      "  done: false\n",
      "  episode_len_mean: 91.78899082568807\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.00000000000001\n",
      "  episode_reward_mean: 3.627431192660558\n",
      "  episode_reward_min: -1.8400000000000012\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 33562\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2887985579987875\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01396530446981555\n",
      "          policy_loss: -0.07679112601356629\n",
      "          total_loss: 0.08304288830194208\n",
      "          vf_explained_var: 0.9109708070755005\n",
      "          vf_loss: 0.15090729041168324\n",
      "    num_agent_steps_sampled: 3078768\n",
      "    num_agent_steps_trained: 3078768\n",
      "    num_steps_sampled: 3078768\n",
      "    num_steps_trained: 3078768\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78486238532109\n",
      "    ram_util_percent: 56.454587155963296\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04564645060589015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04544714621953\n",
      "    mean_inference_ms: 2.8593727374553413\n",
      "    mean_raw_obs_processing_ms: 3.089629762212888\n",
      "  time_since_restore: 47283.42603182793\n",
      "  time_this_iter_s: 152.9152317047119\n",
      "  time_total_s: 47283.42603182793\n",
      "  timers:\n",
      "    learn_throughput: 933.613\n",
      "    learn_time_ms: 10706.79\n",
      "    load_throughput: 91457.949\n",
      "    load_time_ms: 109.296\n",
      "    sample_throughput: 66.589\n",
      "    sample_time_ms: 150115.285\n",
      "    update_time_ms: 11.224\n",
      "  timestamp: 1636341704\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3078768\n",
      "  training_iteration: 308\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   308</td><td style=\"text-align: right;\">         47283.4</td><td style=\"text-align: right;\">3078768</td><td style=\"text-align: right;\"> 3.62743</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">            91.789</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3088764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-24-15\n",
      "  done: false\n",
      "  episode_len_mean: 91.44036697247707\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.910000000000016\n",
      "  episode_reward_mean: 3.8462385321101005\n",
      "  episode_reward_min: -1.4700000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 33671\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.280952625396924\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014600913969998764\n",
      "          policy_loss: -0.07480576055713443\n",
      "          total_loss: 0.11316714617781914\n",
      "          vf_explained_var: 0.915919840335846\n",
      "          vf_loss: 0.1775197255735596\n",
      "    num_agent_steps_sampled: 3088764\n",
      "    num_agent_steps_trained: 3088764\n",
      "    num_steps_sampled: 3088764\n",
      "    num_steps_trained: 3088764\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.5537037037037\n",
      "    ram_util_percent: 56.39490740740741\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567648419445168\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0463070279336\n",
      "    mean_inference_ms: 2.859550397867065\n",
      "    mean_raw_obs_processing_ms: 3.088034269881313\n",
      "  time_since_restore: 47434.79155635834\n",
      "  time_this_iter_s: 151.36552453041077\n",
      "  time_total_s: 47434.79155635834\n",
      "  timers:\n",
      "    learn_throughput: 933.924\n",
      "    learn_time_ms: 10703.223\n",
      "    load_throughput: 91484.631\n",
      "    load_time_ms: 109.264\n",
      "    sample_throughput: 67.51\n",
      "    sample_time_ms: 148067.362\n",
      "    update_time_ms: 12.012\n",
      "  timestamp: 1636341855\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3088764\n",
      "  training_iteration: 309\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   309</td><td style=\"text-align: right;\">         47434.8</td><td style=\"text-align: right;\">3088764</td><td style=\"text-align: right;\"> 3.84624</td><td style=\"text-align: right;\">               12.91</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           91.4404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3098760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-27-02\n",
      "  done: false\n",
      "  episode_len_mean: 90.14414414414415\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.820000000000014\n",
      "  episode_reward_mean: 3.309549549549558\n",
      "  episode_reward_min: -1.7200000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 33782\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2972291950486663\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01256793070260167\n",
      "          policy_loss: -0.07781468053372242\n",
      "          total_loss: 0.06346588053254999\n",
      "          vf_explained_var: 0.9301301836967468\n",
      "          vf_loss: 0.13562153515079592\n",
      "    num_agent_steps_sampled: 3098760\n",
      "    num_agent_steps_trained: 3098760\n",
      "    num_steps_sampled: 3098760\n",
      "    num_steps_trained: 3098760\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.42268907563025\n",
      "    ram_util_percent: 56.50084033613445\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567867484231653\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0459244579788\n",
      "    mean_inference_ms: 2.8592887390277872\n",
      "    mean_raw_obs_processing_ms: 3.0929689992033564\n",
      "  time_since_restore: 47601.50412392616\n",
      "  time_this_iter_s: 166.71256756782532\n",
      "  time_total_s: 47601.50412392616\n",
      "  timers:\n",
      "    learn_throughput: 934.176\n",
      "    learn_time_ms: 10700.335\n",
      "    load_throughput: 91584.351\n",
      "    load_time_ms: 109.145\n",
      "    sample_throughput: 68.521\n",
      "    sample_time_ms: 145882.581\n",
      "    update_time_ms: 12.709\n",
      "  timestamp: 1636342022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3098760\n",
      "  training_iteration: 310\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   310</td><td style=\"text-align: right;\">         47601.5</td><td style=\"text-align: right;\">3098760</td><td style=\"text-align: right;\"> 3.30955</td><td style=\"text-align: right;\">               10.82</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           90.1441</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3108756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-29-43\n",
      "  done: false\n",
      "  episode_len_mean: 89.47321428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.910000000000014\n",
      "  episode_reward_mean: 3.75517857142858\n",
      "  episode_reward_min: -1.7300000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 33894\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.290946831051101\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01303914766673555\n",
      "          policy_loss: -0.07572113300681624\n",
      "          total_loss: 0.06706725331182536\n",
      "          vf_explained_var: 0.9332742691040039\n",
      "          vf_loss: 0.13599304688903383\n",
      "    num_agent_steps_sampled: 3108756\n",
      "    num_agent_steps_trained: 3108756\n",
      "    num_steps_sampled: 3108756\n",
      "    num_steps_trained: 3108756\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.03362445414848\n",
      "    ram_util_percent: 56.44061135371179\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045677471730685655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05010451735708\n",
      "    mean_inference_ms: 2.8594820836125714\n",
      "    mean_raw_obs_processing_ms: 3.0917679439454537\n",
      "  time_since_restore: 47762.31071519852\n",
      "  time_this_iter_s: 160.80659127235413\n",
      "  time_total_s: 47762.31071519852\n",
      "  timers:\n",
      "    learn_throughput: 933.846\n",
      "    learn_time_ms: 10704.124\n",
      "    load_throughput: 91477.705\n",
      "    load_time_ms: 109.273\n",
      "    sample_throughput: 67.581\n",
      "    sample_time_ms: 147912.376\n",
      "    update_time_ms: 12.835\n",
      "  timestamp: 1636342183\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3108756\n",
      "  training_iteration: 311\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   311</td><td style=\"text-align: right;\">         47762.3</td><td style=\"text-align: right;\">3108756</td><td style=\"text-align: right;\"> 3.75518</td><td style=\"text-align: right;\">               12.91</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           89.4732</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3118752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-32-16\n",
      "  done: false\n",
      "  episode_len_mean: 90.42727272727272\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.040000000000013\n",
      "  episode_reward_mean: 3.613545454545462\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 34004\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.297121034320603\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013502955056141934\n",
      "          policy_loss: -0.07788110995649272\n",
      "          total_loss: 0.07886505857683145\n",
      "          vf_explained_var: 0.9058569669723511\n",
      "          vf_loss: 0.14895595845042003\n",
      "    num_agent_steps_sampled: 3118752\n",
      "    num_agent_steps_trained: 3118752\n",
      "    num_steps_sampled: 3118752\n",
      "    num_steps_trained: 3118752\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.76940639269407\n",
      "    ram_util_percent: 56.45616438356164\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045645405318215634\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05181666087792\n",
      "    mean_inference_ms: 2.8593692447489842\n",
      "    mean_raw_obs_processing_ms: 3.087772486586757\n",
      "  time_since_restore: 47915.3328294754\n",
      "  time_this_iter_s: 153.022114276886\n",
      "  time_total_s: 47915.3328294754\n",
      "  timers:\n",
      "    learn_throughput: 933.616\n",
      "    learn_time_ms: 10706.762\n",
      "    load_throughput: 91791.68\n",
      "    load_time_ms: 108.899\n",
      "    sample_throughput: 67.731\n",
      "    sample_time_ms: 147583.067\n",
      "    update_time_ms: 12.46\n",
      "  timestamp: 1636342336\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3118752\n",
      "  training_iteration: 312\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   312</td><td style=\"text-align: right;\">         47915.3</td><td style=\"text-align: right;\">3118752</td><td style=\"text-align: right;\"> 3.61355</td><td style=\"text-align: right;\">               13.04</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           90.4273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3128748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-34-58\n",
      "  done: false\n",
      "  episode_len_mean: 90.49549549549549\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.720000000000017\n",
      "  episode_reward_mean: 3.7445945945946035\n",
      "  episode_reward_min: -1.7900000000000011\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 34115\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2678800847795273\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014236405219396585\n",
      "          policy_loss: -0.0746441928924531\n",
      "          total_loss: 0.08729449518056762\n",
      "          vf_explained_var: 0.9239442348480225\n",
      "          vf_loss: 0.1521851779256239\n",
      "    num_agent_steps_sampled: 3128748\n",
      "    num_agent_steps_trained: 3128748\n",
      "    num_steps_sampled: 3128748\n",
      "    num_steps_trained: 3128748\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.2978354978355\n",
      "    ram_util_percent: 56.435930735930754\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0456648722177037\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04984902942259\n",
      "    mean_inference_ms: 2.8592263326165255\n",
      "    mean_raw_obs_processing_ms: 3.0925457358063526\n",
      "  time_since_restore: 48077.75730419159\n",
      "  time_this_iter_s: 162.42447471618652\n",
      "  time_total_s: 48077.75730419159\n",
      "  timers:\n",
      "    learn_throughput: 933.296\n",
      "    learn_time_ms: 10710.432\n",
      "    load_throughput: 91745.401\n",
      "    load_time_ms: 108.954\n",
      "    sample_throughput: 67.315\n",
      "    sample_time_ms: 148495.334\n",
      "    update_time_ms: 12.135\n",
      "  timestamp: 1636342498\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3128748\n",
      "  training_iteration: 313\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   313</td><td style=\"text-align: right;\">         48077.8</td><td style=\"text-align: right;\">3128748</td><td style=\"text-align: right;\"> 3.74459</td><td style=\"text-align: right;\">               12.72</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           90.4955</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3138744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-37-33\n",
      "  done: false\n",
      "  episode_len_mean: 89.63063063063063\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.670000000000012\n",
      "  episode_reward_mean: 3.546846846846855\n",
      "  episode_reward_min: -1.6000000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 34226\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2740612873664268\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013128001422645199\n",
      "          policy_loss: -0.07927137994740763\n",
      "          total_loss: 0.041883302139293435\n",
      "          vf_explained_var: 0.938593327999115\n",
      "          vf_loss: 0.11398806595999715\n",
      "    num_agent_steps_sampled: 3138744\n",
      "    num_agent_steps_trained: 3138744\n",
      "    num_steps_sampled: 3138744\n",
      "    num_steps_trained: 3138744\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.85701357466064\n",
      "    ram_util_percent: 56.40723981900453\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567161000138625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05156738960056\n",
      "    mean_inference_ms: 2.859384737985723\n",
      "    mean_raw_obs_processing_ms: 3.090304829671489\n",
      "  time_since_restore: 48232.13709139824\n",
      "  time_this_iter_s: 154.37978720664978\n",
      "  time_total_s: 48232.13709139824\n",
      "  timers:\n",
      "    learn_throughput: 933.182\n",
      "    learn_time_ms: 10711.732\n",
      "    load_throughput: 91898.577\n",
      "    load_time_ms: 108.772\n",
      "    sample_throughput: 67.819\n",
      "    sample_time_ms: 147392.991\n",
      "    update_time_ms: 11.921\n",
      "  timestamp: 1636342653\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3138744\n",
      "  training_iteration: 314\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   314</td><td style=\"text-align: right;\">         48232.1</td><td style=\"text-align: right;\">3138744</td><td style=\"text-align: right;\"> 3.54685</td><td style=\"text-align: right;\">               12.67</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           89.6306</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3148740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-40-51\n",
      "  done: false\n",
      "  episode_len_mean: 90.31531531531532\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.300000000000017\n",
      "  episode_reward_mean: 3.8023423423423517\n",
      "  episode_reward_min: -1.3900000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 34337\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2907290059277137\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013333596729805141\n",
      "          policy_loss: -0.0763426824624085\n",
      "          total_loss: 0.060668563592828746\n",
      "          vf_explained_var: 0.9384514093399048\n",
      "          vf_loss: 0.12954293513495443\n",
      "    num_agent_steps_sampled: 3148740\n",
      "    num_agent_steps_trained: 3148740\n",
      "    num_steps_sampled: 3148740\n",
      "    num_steps_trained: 3148740\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.31696113074204\n",
      "    ram_util_percent: 56.53462897526502\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04568452212907585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04982700886238\n",
      "    mean_inference_ms: 2.859176255186998\n",
      "    mean_raw_obs_processing_ms: 3.1122808134794013\n",
      "  time_since_restore: 48430.63149809837\n",
      "  time_this_iter_s: 198.49440670013428\n",
      "  time_total_s: 48430.63149809837\n",
      "  timers:\n",
      "    learn_throughput: 934.161\n",
      "    learn_time_ms: 10700.507\n",
      "    load_throughput: 92016.971\n",
      "    load_time_ms: 108.632\n",
      "    sample_throughput: 65.187\n",
      "    sample_time_ms: 153344.579\n",
      "    update_time_ms: 11.777\n",
      "  timestamp: 1636342851\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3148740\n",
      "  training_iteration: 315\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   315</td><td style=\"text-align: right;\">         48430.6</td><td style=\"text-align: right;\">3148740</td><td style=\"text-align: right;\"> 3.80234</td><td style=\"text-align: right;\">                14.3</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">           90.3153</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3158736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-43-31\n",
      "  done: false\n",
      "  episode_len_mean: 89.53571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.630000000000015\n",
      "  episode_reward_mean: 3.4510714285714363\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 34449\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.276303341246059\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013932581506874502\n",
      "          policy_loss: -0.0770833728914587\n",
      "          total_loss: 0.07546050351622523\n",
      "          vf_explained_var: 0.9285145998001099\n",
      "          vf_loss: 0.14356674721671475\n",
      "    num_agent_steps_sampled: 3158736\n",
      "    num_agent_steps_trained: 3158736\n",
      "    num_steps_sampled: 3158736\n",
      "    num_steps_trained: 3158736\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.79647577092513\n",
      "    ram_util_percent: 56.42114537444933\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04565136168205713\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.056879746432614\n",
      "    mean_inference_ms: 2.8590571118555994\n",
      "    mean_raw_obs_processing_ms: 3.1079935201239235\n",
      "  time_since_restore: 48589.95608520508\n",
      "  time_this_iter_s: 159.3245871067047\n",
      "  time_total_s: 48589.95608520508\n",
      "  timers:\n",
      "    learn_throughput: 933.662\n",
      "    learn_time_ms: 10706.228\n",
      "    load_throughput: 92098.733\n",
      "    load_time_ms: 108.536\n",
      "    sample_throughput: 65.528\n",
      "    sample_time_ms: 152544.649\n",
      "    update_time_ms: 11.695\n",
      "  timestamp: 1636343011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3158736\n",
      "  training_iteration: 316\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   316</td><td style=\"text-align: right;\">           48590</td><td style=\"text-align: right;\">3158736</td><td style=\"text-align: right;\"> 3.45107</td><td style=\"text-align: right;\">               12.63</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           89.5357</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3168732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 89.70270270270271\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.600000000000016\n",
      "  episode_reward_mean: 3.814594594594603\n",
      "  episode_reward_min: -1.7200000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 34560\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2679415747650666\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014242918059189327\n",
      "          policy_loss: -0.07670866087333769\n",
      "          total_loss: 0.08233193575651344\n",
      "          vf_explained_var: 0.9261979460716248\n",
      "          vf_loss: 0.149272863765876\n",
      "    num_agent_steps_sampled: 3168732\n",
      "    num_agent_steps_trained: 3168732\n",
      "    num_steps_sampled: 3168732\n",
      "    num_steps_trained: 3168732\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.56730038022815\n",
      "    ram_util_percent: 56.61026615969581\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045692858784403545\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.058597705061146\n",
      "    mean_inference_ms: 2.8588389584433815\n",
      "    mean_raw_obs_processing_ms: 3.120663755805017\n",
      "  time_since_restore: 48773.82730650902\n",
      "  time_this_iter_s: 183.87122130393982\n",
      "  time_total_s: 48773.82730650902\n",
      "  timers:\n",
      "    learn_throughput: 932.988\n",
      "    learn_time_ms: 10713.966\n",
      "    load_throughput: 92150.068\n",
      "    load_time_ms: 108.475\n",
      "    sample_throughput: 65.127\n",
      "    sample_time_ms: 153483.701\n",
      "    update_time_ms: 11.127\n",
      "  timestamp: 1636343195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3168732\n",
      "  training_iteration: 317\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   317</td><td style=\"text-align: right;\">         48773.8</td><td style=\"text-align: right;\">3168732</td><td style=\"text-align: right;\"> 3.81459</td><td style=\"text-align: right;\">                10.6</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           89.7027</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3178728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-49-11\n",
      "  done: false\n",
      "  episode_len_mean: 91.5229357798165\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.780000000000012\n",
      "  episode_reward_mean: 3.8151376146789078\n",
      "  episode_reward_min: -2.0999999999999988\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 34669\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2731873722157925\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013089692153971934\n",
      "          policy_loss: -0.0771182718471839\n",
      "          total_loss: 0.06669757341583953\n",
      "          vf_explained_var: 0.9316648244857788\n",
      "          vf_loss: 0.13672776437467998\n",
      "    num_agent_steps_sampled: 3178728\n",
      "    num_agent_steps_trained: 3178728\n",
      "    num_steps_sampled: 3178728\n",
      "    num_steps_trained: 3178728\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.75201793721973\n",
      "    ram_util_percent: 56.443497757847524\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04563011696814873\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06209339637641\n",
      "    mean_inference_ms: 2.858833464476333\n",
      "    mean_raw_obs_processing_ms: 3.1132469913838023\n",
      "  time_since_restore: 48930.581657886505\n",
      "  time_this_iter_s: 156.75435137748718\n",
      "  time_total_s: 48930.581657886505\n",
      "  timers:\n",
      "    learn_throughput: 933.02\n",
      "    learn_time_ms: 10713.595\n",
      "    load_throughput: 92287.329\n",
      "    load_time_ms: 108.314\n",
      "    sample_throughput: 64.965\n",
      "    sample_time_ms: 153868.354\n",
      "    update_time_ms: 11.149\n",
      "  timestamp: 1636343351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3178728\n",
      "  training_iteration: 318\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   318</td><td style=\"text-align: right;\">         48930.6</td><td style=\"text-align: right;\">3178728</td><td style=\"text-align: right;\"> 3.81514</td><td style=\"text-align: right;\">               10.78</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">           91.5229</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3188724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-51-55\n",
      "  done: false\n",
      "  episode_len_mean: 92.83177570093459\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.760000000000018\n",
      "  episode_reward_mean: 3.447757009345802\n",
      "  episode_reward_min: -1.4300000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 34776\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2932657015629303\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01343983427002958\n",
      "          policy_loss: -0.07572020979948406\n",
      "          total_loss: 0.07260781872508108\n",
      "          vf_explained_var: 0.9288674592971802\n",
      "          vf_loss: 0.14064306238602498\n",
      "    num_agent_steps_sampled: 3188724\n",
      "    num_agent_steps_trained: 3188724\n",
      "    num_steps_sampled: 3188724\n",
      "    num_steps_trained: 3188724\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.49017094017094\n",
      "    ram_util_percent: 56.40512820512821\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567738939320153\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06311515929308\n",
      "    mean_inference_ms: 2.858842873813849\n",
      "    mean_raw_obs_processing_ms: 3.11808925417816\n",
      "  time_since_restore: 49094.54432845116\n",
      "  time_this_iter_s: 163.9626705646515\n",
      "  time_total_s: 49094.54432845116\n",
      "  timers:\n",
      "    learn_throughput: 933.077\n",
      "    learn_time_ms: 10712.94\n",
      "    load_throughput: 92269.7\n",
      "    load_time_ms: 108.335\n",
      "    sample_throughput: 64.436\n",
      "    sample_time_ms: 155129.598\n",
      "    update_time_ms: 10.745\n",
      "  timestamp: 1636343515\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3188724\n",
      "  training_iteration: 319\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   319</td><td style=\"text-align: right;\">         49094.5</td><td style=\"text-align: right;\">3188724</td><td style=\"text-align: right;\"> 3.44776</td><td style=\"text-align: right;\">               10.76</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           92.8318</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3198720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-54-33\n",
      "  done: false\n",
      "  episode_len_mean: 90.15315315315316\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.789999999999964\n",
      "  episode_reward_mean: 3.7576576576576657\n",
      "  episode_reward_min: -1.4800000000000009\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 34887\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2991710247137607\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015282795142004531\n",
      "          policy_loss: -0.07281927071973426\n",
      "          total_loss: 0.11397586659743236\n",
      "          vf_explained_var: 0.9160694479942322\n",
      "          vf_loss: 0.17497073030019672\n",
      "    num_agent_steps_sampled: 3198720\n",
      "    num_agent_steps_trained: 3198720\n",
      "    num_steps_sampled: 3198720\n",
      "    num_steps_trained: 3198720\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.90400000000001\n",
      "    ram_util_percent: 56.51022222222222\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04564624189767367\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06892216393649\n",
      "    mean_inference_ms: 2.8588159972642946\n",
      "    mean_raw_obs_processing_ms: 3.11351742818339\n",
      "  time_since_restore: 49252.05058336258\n",
      "  time_this_iter_s: 157.50625491142273\n",
      "  time_total_s: 49252.05058336258\n",
      "  timers:\n",
      "    learn_throughput: 933.029\n",
      "    learn_time_ms: 10713.496\n",
      "    load_throughput: 92313.481\n",
      "    load_time_ms: 108.283\n",
      "    sample_throughput: 64.821\n",
      "    sample_time_ms: 154208.779\n",
      "    update_time_ms: 10.826\n",
      "  timestamp: 1636343673\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3198720\n",
      "  training_iteration: 320\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   320</td><td style=\"text-align: right;\">         49252.1</td><td style=\"text-align: right;\">3198720</td><td style=\"text-align: right;\"> 3.75766</td><td style=\"text-align: right;\">               18.79</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           90.1532</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3208716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-57-17\n",
      "  done: false\n",
      "  episode_len_mean: 91.06363636363636\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.80999999999997\n",
      "  episode_reward_mean: 3.7151818181818257\n",
      "  episode_reward_min: -1.330000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 34997\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.26000243557824\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013631245583280788\n",
      "          policy_loss: -0.07614770699531222\n",
      "          total_loss: 0.08049227439631254\n",
      "          vf_explained_var: 0.9289596676826477\n",
      "          vf_loss: 0.14818632270121931\n",
      "    num_agent_steps_sampled: 3208716\n",
      "    num_agent_steps_trained: 3208716\n",
      "    num_steps_sampled: 3208716\n",
      "    num_steps_trained: 3208716\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.53034188034188\n",
      "    ram_util_percent: 56.344444444444456\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04569510637973671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06730333360549\n",
      "    mean_inference_ms: 2.8588113706351637\n",
      "    mean_raw_obs_processing_ms: 3.120972245335713\n",
      "  time_since_restore: 49416.02379369736\n",
      "  time_this_iter_s: 163.97321033477783\n",
      "  time_total_s: 49416.02379369736\n",
      "  timers:\n",
      "    learn_throughput: 933.468\n",
      "    learn_time_ms: 10708.459\n",
      "    load_throughput: 92209.368\n",
      "    load_time_ms: 108.405\n",
      "    sample_throughput: 64.686\n",
      "    sample_time_ms: 154530.545\n",
      "    update_time_ms: 10.794\n",
      "  timestamp: 1636343837\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3208716\n",
      "  training_iteration: 321\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   321</td><td style=\"text-align: right;\">           49416</td><td style=\"text-align: right;\">3208716</td><td style=\"text-align: right;\"> 3.71518</td><td style=\"text-align: right;\">               16.81</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">           91.0636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3218712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_03-59-38\n",
      "  done: false\n",
      "  episode_len_mean: 91.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.830000000000013\n",
      "  episode_reward_mean: 3.8554545454545543\n",
      "  episode_reward_min: -0.9600000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 35107\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2457307173655585\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013947001417969986\n",
      "          policy_loss: -0.07674821579797018\n",
      "          total_loss: 0.08741023278691702\n",
      "          vf_explained_var: 0.9404701590538025\n",
      "          vf_loss: 0.15484274277447635\n",
      "    num_agent_steps_sampled: 3218712\n",
      "    num_agent_steps_trained: 3218712\n",
      "    num_steps_sampled: 3218712\n",
      "    num_steps_trained: 3218712\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79353233830845\n",
      "    ram_util_percent: 56.443781094527345\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04567927417006672\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.069647770460826\n",
      "    mean_inference_ms: 2.8590270127605204\n",
      "    mean_raw_obs_processing_ms: 3.1121738909736294\n",
      "  time_since_restore: 49556.86650967598\n",
      "  time_this_iter_s: 140.84271597862244\n",
      "  time_total_s: 49556.86650967598\n",
      "  timers:\n",
      "    learn_throughput: 934.319\n",
      "    learn_time_ms: 10698.699\n",
      "    load_throughput: 92084.007\n",
      "    load_time_ms: 108.553\n",
      "    sample_throughput: 65.196\n",
      "    sample_time_ms: 153322.317\n",
      "    update_time_ms: 10.907\n",
      "  timestamp: 1636343978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3218712\n",
      "  training_iteration: 322\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   322</td><td style=\"text-align: right;\">         49556.9</td><td style=\"text-align: right;\">3218712</td><td style=\"text-align: right;\"> 3.85545</td><td style=\"text-align: right;\">               12.83</td><td style=\"text-align: right;\">               -0.96</td><td style=\"text-align: right;\">              91.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3228708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-02-27\n",
      "  done: false\n",
      "  episode_len_mean: 89.66666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.200000000000014\n",
      "  episode_reward_mean: 3.853333333333341\n",
      "  episode_reward_min: -1.5600000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 35218\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2550803098923122\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01383104390054708\n",
      "          policy_loss: -0.0773248737407291\n",
      "          total_loss: 0.07352836860550774\n",
      "          vf_explained_var: 0.9392185807228088\n",
      "          vf_loss: 0.1418951977060264\n",
      "    num_agent_steps_sampled: 3228708\n",
      "    num_agent_steps_trained: 3228708\n",
      "    num_steps_sampled: 3228708\n",
      "    num_steps_trained: 3228708\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.4599173553719\n",
      "    ram_util_percent: 56.466528925619826\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04563715015865956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06977185019624\n",
      "    mean_inference_ms: 2.8588169114808717\n",
      "    mean_raw_obs_processing_ms: 3.1131382669209926\n",
      "  time_since_restore: 49726.37597966194\n",
      "  time_this_iter_s: 169.5094699859619\n",
      "  time_total_s: 49726.37597966194\n",
      "  timers:\n",
      "    learn_throughput: 934.407\n",
      "    learn_time_ms: 10697.697\n",
      "    load_throughput: 91938.841\n",
      "    load_time_ms: 108.724\n",
      "    sample_throughput: 64.896\n",
      "    sample_time_ms: 154030.595\n",
      "    update_time_ms: 12.43\n",
      "  timestamp: 1636344147\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3228708\n",
      "  training_iteration: 323\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   323</td><td style=\"text-align: right;\">         49726.4</td><td style=\"text-align: right;\">3228708</td><td style=\"text-align: right;\"> 3.85333</td><td style=\"text-align: right;\">                11.2</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           89.6667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3238704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-05-16\n",
      "  done: false\n",
      "  episode_len_mean: 89.58928571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.020000000000014\n",
      "  episode_reward_mean: 3.4274107142857226\n",
      "  episode_reward_min: -1.8500000000000014\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 35330\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2662578833408844\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01485846218358801\n",
      "          policy_loss: -0.07502348394825673\n",
      "          total_loss: 0.0824170348385715\n",
      "          vf_explained_var: 0.9279797673225403\n",
      "          vf_loss: 0.14625366222845693\n",
      "    num_agent_steps_sampled: 3238704\n",
      "    num_agent_steps_trained: 3238704\n",
      "    num_steps_sampled: 3238704\n",
      "    num_steps_trained: 3238704\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.52157676348547\n",
      "    ram_util_percent: 56.27717842323652\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045666716210834166\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07027027691912\n",
      "    mean_inference_ms: 2.858611668457411\n",
      "    mean_raw_obs_processing_ms: 3.1247056109154565\n",
      "  time_since_restore: 49894.93174791336\n",
      "  time_this_iter_s: 168.55576825141907\n",
      "  time_total_s: 49894.93174791336\n",
      "  timers:\n",
      "    learn_throughput: 934.618\n",
      "    learn_time_ms: 10695.281\n",
      "    load_throughput: 91916.508\n",
      "    load_time_ms: 108.751\n",
      "    sample_throughput: 64.303\n",
      "    sample_time_ms: 155450.626\n",
      "    update_time_ms: 12.634\n",
      "  timestamp: 1636344316\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3238704\n",
      "  training_iteration: 324\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   324</td><td style=\"text-align: right;\">         49894.9</td><td style=\"text-align: right;\">3238704</td><td style=\"text-align: right;\"> 3.42741</td><td style=\"text-align: right;\">               11.02</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           89.5893</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3248700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-07-35\n",
      "  done: false\n",
      "  episode_len_mean: 92.34862385321101\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.880000000000015\n",
      "  episode_reward_mean: 3.7699082568807425\n",
      "  episode_reward_min: -1.970000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 35439\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2790074994421414\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013657404845905987\n",
      "          policy_loss: -0.07633908048081092\n",
      "          total_loss: 0.06611541195685028\n",
      "          vf_explained_var: 0.9357666969299316\n",
      "          vf_loss: 0.13413129039267954\n",
      "    num_agent_steps_sampled: 3248700\n",
      "    num_agent_steps_trained: 3248700\n",
      "    num_steps_sampled: 3248700\n",
      "    num_steps_trained: 3248700\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.31859296482413\n",
      "    ram_util_percent: 56.34522613065327\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045639542738748\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07282073429332\n",
      "    mean_inference_ms: 2.8588487013344115\n",
      "    mean_raw_obs_processing_ms: 3.1145770333507063\n",
      "  time_since_restore: 50034.43133020401\n",
      "  time_this_iter_s: 139.4995822906494\n",
      "  time_total_s: 50034.43133020401\n",
      "  timers:\n",
      "    learn_throughput: 934.181\n",
      "    learn_time_ms: 10700.284\n",
      "    load_throughput: 91667.471\n",
      "    load_time_ms: 109.046\n",
      "    sample_throughput: 66.842\n",
      "    sample_time_ms: 149546.324\n",
      "    update_time_ms: 11.975\n",
      "  timestamp: 1636344455\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3248700\n",
      "  training_iteration: 325\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   325</td><td style=\"text-align: right;\">         50034.4</td><td style=\"text-align: right;\">3248700</td><td style=\"text-align: right;\"> 3.76991</td><td style=\"text-align: right;\">               12.88</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           92.3486</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3258696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-11-02\n",
      "  done: false\n",
      "  episode_len_mean: 92.3425925925926\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.240000000000007\n",
      "  episode_reward_mean: 3.807037037037045\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 35547\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2522569035872433\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015181848361892932\n",
      "          policy_loss: -0.07024558474047062\n",
      "          total_loss: 0.11883553065136712\n",
      "          vf_explained_var: 0.9140962958335876\n",
      "          vf_loss: 0.17701753510687596\n",
      "    num_agent_steps_sampled: 3258696\n",
      "    num_agent_steps_trained: 3258696\n",
      "    num_steps_sampled: 3258696\n",
      "    num_steps_trained: 3258696\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.10034013605443\n",
      "    ram_util_percent: 56.50850340136054\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045606225128760516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.074526726782146\n",
      "    mean_inference_ms: 2.858676902693323\n",
      "    mean_raw_obs_processing_ms: 3.1269539849212045\n",
      "  time_since_restore: 50240.751371860504\n",
      "  time_this_iter_s: 206.32004165649414\n",
      "  time_total_s: 50240.751371860504\n",
      "  timers:\n",
      "    learn_throughput: 934.405\n",
      "    learn_time_ms: 10697.716\n",
      "    load_throughput: 91313.635\n",
      "    load_time_ms: 109.469\n",
      "    sample_throughput: 64.805\n",
      "    sample_time_ms: 154248.473\n",
      "    update_time_ms: 11.373\n",
      "  timestamp: 1636344662\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3258696\n",
      "  training_iteration: 326\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   326</td><td style=\"text-align: right;\">         50240.8</td><td style=\"text-align: right;\">3258696</td><td style=\"text-align: right;\"> 3.80704</td><td style=\"text-align: right;\">               15.24</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           92.3426</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3268692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-13-23\n",
      "  done: false\n",
      "  episode_len_mean: 92.31481481481481\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.910000000000016\n",
      "  episode_reward_mean: 4.154351851851861\n",
      "  episode_reward_min: -2.0300000000000002\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 35655\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.253525491861197\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013922393516242346\n",
      "          policy_loss: -0.07165008771718823\n",
      "          total_loss: 0.09354561330575464\n",
      "          vf_explained_var: 0.931423008441925\n",
      "          vf_loss: 0.15601400246955135\n",
      "    num_agent_steps_sampled: 3268692\n",
      "    num_agent_steps_trained: 3268692\n",
      "    num_steps_sampled: 3268692\n",
      "    num_steps_trained: 3268692\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04875621890547\n",
      "    ram_util_percent: 56.25870646766169\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04565193550410832\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.08055240675818\n",
      "    mean_inference_ms: 2.8588332511264167\n",
      "    mean_raw_obs_processing_ms: 3.1214989977896987\n",
      "  time_since_restore: 50381.44222807884\n",
      "  time_this_iter_s: 140.690856218338\n",
      "  time_total_s: 50381.44222807884\n",
      "  timers:\n",
      "    learn_throughput: 934.117\n",
      "    learn_time_ms: 10701.017\n",
      "    load_throughput: 91413.341\n",
      "    load_time_ms: 109.349\n",
      "    sample_throughput: 66.672\n",
      "    sample_time_ms: 149926.894\n",
      "    update_time_ms: 12.202\n",
      "  timestamp: 1636344803\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3268692\n",
      "  training_iteration: 327\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   327</td><td style=\"text-align: right;\">         50381.4</td><td style=\"text-align: right;\">3268692</td><td style=\"text-align: right;\"> 4.15435</td><td style=\"text-align: right;\">               12.91</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">           92.3148</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3278688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-16-42\n",
      "  done: false\n",
      "  episode_len_mean: 89.7927927927928\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.710000000000006\n",
      "  episode_reward_mean: 3.4775675675675757\n",
      "  episode_reward_min: -2.169999999999999\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 35766\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.252226863661383\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013458504860437183\n",
      "          policy_loss: -0.07373666662054185\n",
      "          total_loss: 0.07138166663945358\n",
      "          vf_explained_var: 0.9339299201965332\n",
      "          vf_loss: 0.1369804450016246\n",
      "    num_agent_steps_sampled: 3278688\n",
      "    num_agent_steps_trained: 3278688\n",
      "    num_steps_sampled: 3278688\n",
      "    num_steps_trained: 3278688\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.75508771929825\n",
      "    ram_util_percent: 56.47859649122807\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04566250761767133\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07871451171456\n",
      "    mean_inference_ms: 2.858619850606762\n",
      "    mean_raw_obs_processing_ms: 3.1421268692938966\n",
      "  time_since_restore: 50581.054720401764\n",
      "  time_this_iter_s: 199.61249232292175\n",
      "  time_total_s: 50581.054720401764\n",
      "  timers:\n",
      "    learn_throughput: 933.918\n",
      "    learn_time_ms: 10703.29\n",
      "    load_throughput: 91841.687\n",
      "    load_time_ms: 108.839\n",
      "    sample_throughput: 64.821\n",
      "    sample_time_ms: 154209.964\n",
      "    update_time_ms: 12.846\n",
      "  timestamp: 1636345002\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3278688\n",
      "  training_iteration: 328\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   328</td><td style=\"text-align: right;\">         50581.1</td><td style=\"text-align: right;\">3278688</td><td style=\"text-align: right;\"> 3.47757</td><td style=\"text-align: right;\">               12.71</td><td style=\"text-align: right;\">               -2.17</td><td style=\"text-align: right;\">           89.7928</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3288684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-19-03\n",
      "  done: false\n",
      "  episode_len_mean: 92.43119266055047\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.750000000000014\n",
      "  episode_reward_mean: 3.0718348623853284\n",
      "  episode_reward_min: -2.0500000000000003\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 35875\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2640748327613895\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013992209450282827\n",
      "          policy_loss: -0.0763209345869911\n",
      "          total_loss: 0.08380611196048876\n",
      "          vf_explained_var: 0.909416913986206\n",
      "          vf_loss: 0.15089179233719524\n",
      "    num_agent_steps_sampled: 3288684\n",
      "    num_agent_steps_trained: 3288684\n",
      "    num_steps_sampled: 3288684\n",
      "    num_steps_trained: 3288684\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.30547263681592\n",
      "    ram_util_percent: 56.343283582089555\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04563993008832358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.082440481262786\n",
      "    mean_inference_ms: 2.858788375671309\n",
      "    mean_raw_obs_processing_ms: 3.132623028885\n",
      "  time_since_restore: 50722.23514842987\n",
      "  time_this_iter_s: 141.1804280281067\n",
      "  time_total_s: 50722.23514842987\n",
      "  timers:\n",
      "    learn_throughput: 934.492\n",
      "    learn_time_ms: 10696.718\n",
      "    load_throughput: 91747.75\n",
      "    load_time_ms: 108.951\n",
      "    sample_throughput: 65.79\n",
      "    sample_time_ms: 151937.348\n",
      "    update_time_ms: 13.267\n",
      "  timestamp: 1636345143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3288684\n",
      "  training_iteration: 329\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   329</td><td style=\"text-align: right;\">         50722.2</td><td style=\"text-align: right;\">3288684</td><td style=\"text-align: right;\"> 3.07183</td><td style=\"text-align: right;\">               12.75</td><td style=\"text-align: right;\">               -2.05</td><td style=\"text-align: right;\">           92.4312</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3298680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-22-09\n",
      "  done: false\n",
      "  episode_len_mean: 88.53097345132744\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.770000000000016\n",
      "  episode_reward_mean: 3.8531858407079724\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 35988\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2343690144710053\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014473775831268403\n",
      "          policy_loss: -0.07305499990032906\n",
      "          total_loss: 0.08108648521881391\n",
      "          vf_explained_var: 0.9356955289840698\n",
      "          vf_loss: 0.14351210335954132\n",
      "    num_agent_steps_sampled: 3298680\n",
      "    num_agent_steps_trained: 3298680\n",
      "    num_steps_sampled: 3298680\n",
      "    num_steps_trained: 3298680\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.13863636363635\n",
      "    ram_util_percent: 56.375757575757575\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04562362847389324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.08258658499665\n",
      "    mean_inference_ms: 2.858717908374819\n",
      "    mean_raw_obs_processing_ms: 3.1409352030426443\n",
      "  time_since_restore: 50907.35931015015\n",
      "  time_this_iter_s: 185.12416172027588\n",
      "  time_total_s: 50907.35931015015\n",
      "  timers:\n",
      "    learn_throughput: 934.676\n",
      "    learn_time_ms: 10694.615\n",
      "    load_throughput: 91510.469\n",
      "    load_time_ms: 109.233\n",
      "    sample_throughput: 64.615\n",
      "    sample_time_ms: 154701.319\n",
      "    update_time_ms: 12.836\n",
      "  timestamp: 1636345329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3298680\n",
      "  training_iteration: 330\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   330</td><td style=\"text-align: right;\">         50907.4</td><td style=\"text-align: right;\">3298680</td><td style=\"text-align: right;\"> 3.85319</td><td style=\"text-align: right;\">               10.77</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">            88.531</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3308676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-25-03\n",
      "  done: false\n",
      "  episode_len_mean: 89.38392857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.890000000000015\n",
      "  episode_reward_mean: 3.734642857142865\n",
      "  episode_reward_min: -1.8700000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 36100\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.232542047031924\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014222499178490217\n",
      "          policy_loss: -0.07305457670018714\n",
      "          total_loss: 0.10267128603628431\n",
      "          vf_explained_var: 0.9333191514015198\n",
      "          vf_loss: 0.165650651552993\n",
      "    num_agent_steps_sampled: 3308676\n",
      "    num_agent_steps_trained: 3308676\n",
      "    num_steps_sampled: 3308676\n",
      "    num_steps_trained: 3308676\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.79079999999999\n",
      "    ram_util_percent: 56.336800000000004\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045659160029694064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.08552648780749\n",
      "    mean_inference_ms: 2.8587209406135705\n",
      "    mean_raw_obs_processing_ms: 3.151299925573728\n",
      "  time_since_restore: 51081.97889304161\n",
      "  time_this_iter_s: 174.61958289146423\n",
      "  time_total_s: 51081.97889304161\n",
      "  timers:\n",
      "    learn_throughput: 934.34\n",
      "    learn_time_ms: 10698.456\n",
      "    load_throughput: 91635.735\n",
      "    load_time_ms: 109.084\n",
      "    sample_throughput: 64.175\n",
      "    sample_time_ms: 155761.344\n",
      "    update_time_ms: 13.445\n",
      "  timestamp: 1636345503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3308676\n",
      "  training_iteration: 331\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   331</td><td style=\"text-align: right;\">           51082</td><td style=\"text-align: right;\">3308676</td><td style=\"text-align: right;\"> 3.73464</td><td style=\"text-align: right;\">               14.89</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">           89.3839</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3318672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-27-56\n",
      "  done: false\n",
      "  episode_len_mean: 88.22321428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.160000000000013\n",
      "  episode_reward_mean: 3.2481250000000066\n",
      "  episode_reward_min: -2.259999999999996\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 36212\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2501306020296536\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013096010688332311\n",
      "          policy_loss: -0.07537526061646958\n",
      "          total_loss: 0.07138223890851961\n",
      "          vf_explained_var: 0.915462851524353\n",
      "          vf_loss: 0.13942445534416753\n",
      "    num_agent_steps_sampled: 3318672\n",
      "    num_agent_steps_trained: 3318672\n",
      "    num_steps_sampled: 3318672\n",
      "    num_steps_trained: 3318672\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.34146341463415\n",
      "    ram_util_percent: 56.46707317073172\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04564968197879227\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.088096150172916\n",
      "    mean_inference_ms: 2.858493411979694\n",
      "    mean_raw_obs_processing_ms: 3.1598998277650407\n",
      "  time_since_restore: 51254.8993935585\n",
      "  time_this_iter_s: 172.92050051689148\n",
      "  time_total_s: 51254.8993935585\n",
      "  timers:\n",
      "    learn_throughput: 934.299\n",
      "    learn_time_ms: 10698.935\n",
      "    load_throughput: 91552.493\n",
      "    load_time_ms: 109.183\n",
      "    sample_throughput: 62.881\n",
      "    sample_time_ms: 158967.69\n",
      "    update_time_ms: 14.106\n",
      "  timestamp: 1636345676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3318672\n",
      "  training_iteration: 332\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   332</td><td style=\"text-align: right;\">         51254.9</td><td style=\"text-align: right;\">3318672</td><td style=\"text-align: right;\"> 3.24813</td><td style=\"text-align: right;\">               11.16</td><td style=\"text-align: right;\">               -2.26</td><td style=\"text-align: right;\">           88.2232</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3328668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-30-48\n",
      "  done: false\n",
      "  episode_len_mean: 90.22321428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.950000000000014\n",
      "  episode_reward_mean: 3.585000000000008\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 36324\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2562202938601503\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013195319750160705\n",
      "          policy_loss: -0.07154013545324023\n",
      "          total_loss: 0.08359736031056661\n",
      "          vf_explained_var: 0.9307571053504944\n",
      "          vf_loss: 0.14763910983585649\n",
      "    num_agent_steps_sampled: 3328668\n",
      "    num_agent_steps_trained: 3328668\n",
      "    num_steps_sampled: 3328668\n",
      "    num_steps_trained: 3328668\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.38285714285715\n",
      "    ram_util_percent: 56.45836734693877\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04564063118828906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.089753385839444\n",
      "    mean_inference_ms: 2.8586908551727084\n",
      "    mean_raw_obs_processing_ms: 3.1661972202959476\n",
      "  time_since_restore: 51426.26507949829\n",
      "  time_this_iter_s: 171.36568593978882\n",
      "  time_total_s: 51426.26507949829\n",
      "  timers:\n",
      "    learn_throughput: 934.046\n",
      "    learn_time_ms: 10701.831\n",
      "    load_throughput: 91674.145\n",
      "    load_time_ms: 109.038\n",
      "    sample_throughput: 62.808\n",
      "    sample_time_ms: 159152.031\n",
      "    update_time_ms: 12.705\n",
      "  timestamp: 1636345848\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3328668\n",
      "  training_iteration: 333\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   333</td><td style=\"text-align: right;\">         51426.3</td><td style=\"text-align: right;\">3328668</td><td style=\"text-align: right;\">   3.585</td><td style=\"text-align: right;\">               12.95</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           90.2232</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3338664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-33-39\n",
      "  done: false\n",
      "  episode_len_mean: 89.38738738738739\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000016\n",
      "  episode_reward_mean: 3.6994594594594674\n",
      "  episode_reward_min: -1.3900000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 36435\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2495338327864296\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013905552555137606\n",
      "          policy_loss: -0.07486971310124947\n",
      "          total_loss: 0.06907785080978249\n",
      "          vf_explained_var: 0.9280301332473755\n",
      "          vf_loss: 0.13476431482813805\n",
      "    num_agent_steps_sampled: 3338664\n",
      "    num_agent_steps_trained: 3338664\n",
      "    num_steps_sampled: 3338664\n",
      "    num_steps_trained: 3338664\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.37500000000001\n",
      "    ram_util_percent: 56.58729508196721\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04563723238944177\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09236851061423\n",
      "    mean_inference_ms: 2.858358860566211\n",
      "    mean_raw_obs_processing_ms: 3.174667936941823\n",
      "  time_since_restore: 51597.54653644562\n",
      "  time_this_iter_s: 171.28145694732666\n",
      "  time_total_s: 51597.54653644562\n",
      "  timers:\n",
      "    learn_throughput: 934.346\n",
      "    learn_time_ms: 10698.39\n",
      "    load_throughput: 91441.134\n",
      "    load_time_ms: 109.316\n",
      "    sample_throughput: 62.699\n",
      "    sample_time_ms: 159427.962\n",
      "    update_time_ms: 12.465\n",
      "  timestamp: 1636346019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3338664\n",
      "  training_iteration: 334\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   334</td><td style=\"text-align: right;\">         51597.5</td><td style=\"text-align: right;\">3338664</td><td style=\"text-align: right;\"> 3.69946</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">           89.3874</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3348660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-36-44\n",
      "  done: false\n",
      "  episode_len_mean: 87.86842105263158\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 3.870087719298253\n",
      "  episode_reward_min: -1.2300000000000006\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 36549\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.255609434995896\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014276525115381565\n",
      "          policy_loss: -0.06978669793337074\n",
      "          total_loss: 0.10596141854746856\n",
      "          vf_explained_var: 0.9299802780151367\n",
      "          vf_loss: 0.16578050036238046\n",
      "    num_agent_steps_sampled: 3348660\n",
      "    num_agent_steps_trained: 3348660\n",
      "    num_steps_sampled: 3348660\n",
      "    num_steps_trained: 3348660\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.11132075471698\n",
      "    ram_util_percent: 56.50226415094339\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04563069244926368\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.087716667358066\n",
      "    mean_inference_ms: 2.858375601463753\n",
      "    mean_raw_obs_processing_ms: 3.193350947078466\n",
      "  time_since_restore: 51782.96460580826\n",
      "  time_this_iter_s: 185.41806936264038\n",
      "  time_total_s: 51782.96460580826\n",
      "  timers:\n",
      "    learn_throughput: 934.903\n",
      "    learn_time_ms: 10692.018\n",
      "    load_throughput: 91575.27\n",
      "    load_time_ms: 109.156\n",
      "    sample_throughput: 60.942\n",
      "    sample_time_ms: 164025.23\n",
      "    update_time_ms: 13.212\n",
      "  timestamp: 1636346204\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3348660\n",
      "  training_iteration: 335\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   335</td><td style=\"text-align: right;\">           51783</td><td style=\"text-align: right;\">3348660</td><td style=\"text-align: right;\"> 3.87009</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">               -1.23</td><td style=\"text-align: right;\">           87.8684</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3358656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-39-34\n",
      "  done: false\n",
      "  episode_len_mean: 87.47368421052632\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.050000000000013\n",
      "  episode_reward_mean: 4.184912280701763\n",
      "  episode_reward_min: -1.5600000000000005\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 36663\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2320980255420393\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013730207654299173\n",
      "          policy_loss: -0.07271702786127472\n",
      "          total_loss: 0.09022141946877679\n",
      "          vf_explained_var: 0.9366027116775513\n",
      "          vf_loss: 0.15398029644742736\n",
      "    num_agent_steps_sampled: 3358656\n",
      "    num_agent_steps_trained: 3358656\n",
      "    num_steps_sampled: 3358656\n",
      "    num_steps_trained: 3358656\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.22190082644627\n",
      "    ram_util_percent: 56.5607438016529\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045644702616511455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09069318440131\n",
      "    mean_inference_ms: 2.8581788058749535\n",
      "    mean_raw_obs_processing_ms: 3.1970840926414485\n",
      "  time_since_restore: 51952.35874223709\n",
      "  time_this_iter_s: 169.394136428833\n",
      "  time_total_s: 51952.35874223709\n",
      "  timers:\n",
      "    learn_throughput: 934.933\n",
      "    learn_time_ms: 10691.68\n",
      "    load_throughput: 91678.435\n",
      "    load_time_ms: 109.033\n",
      "    sample_throughput: 62.346\n",
      "    sample_time_ms: 160332.171\n",
      "    update_time_ms: 13.884\n",
      "  timestamp: 1636346374\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3358656\n",
      "  training_iteration: 336\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   336</td><td style=\"text-align: right;\">         51952.4</td><td style=\"text-align: right;\">3358656</td><td style=\"text-align: right;\"> 4.18491</td><td style=\"text-align: right;\">               13.05</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           87.4737</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3368652\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-43-02\n",
      "  done: false\n",
      "  episode_len_mean: 89.80357142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.570000000000013\n",
      "  episode_reward_mean: 4.0216964285714365\n",
      "  episode_reward_min: -0.9600000000000009\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 36775\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2454314005680573\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013865022893170716\n",
      "          policy_loss: -0.07458895579553568\n",
      "          total_loss: 0.09464355071958823\n",
      "          vf_explained_var: 0.9256706833839417\n",
      "          vf_loss: 0.16010056439086667\n",
      "    num_agent_steps_sampled: 3368652\n",
      "    num_agent_steps_trained: 3368652\n",
      "    num_steps_sampled: 3368652\n",
      "    num_steps_trained: 3368652\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.55371621621622\n",
      "    ram_util_percent: 56.58175675675675\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04566636236711202\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09469471496383\n",
      "    mean_inference_ms: 2.8581559155025604\n",
      "    mean_raw_obs_processing_ms: 3.2121592677578144\n",
      "  time_since_restore: 52160.2345290184\n",
      "  time_this_iter_s: 207.87578678131104\n",
      "  time_total_s: 52160.2345290184\n",
      "  timers:\n",
      "    learn_throughput: 935.623\n",
      "    learn_time_ms: 10683.788\n",
      "    load_throughput: 91486.927\n",
      "    load_time_ms: 109.262\n",
      "    sample_throughput: 59.835\n",
      "    sample_time_ms: 167058.121\n",
      "    update_time_ms: 14.022\n",
      "  timestamp: 1636346582\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3368652\n",
      "  training_iteration: 337\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   337</td><td style=\"text-align: right;\">         52160.2</td><td style=\"text-align: right;\">3368652</td><td style=\"text-align: right;\">  4.0217</td><td style=\"text-align: right;\">               12.57</td><td style=\"text-align: right;\">               -0.96</td><td style=\"text-align: right;\">           89.8036</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3378648\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-45-36\n",
      "  done: false\n",
      "  episode_len_mean: 90.43243243243244\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.760000000000012\n",
      "  episode_reward_mean: 4.05207207207208\n",
      "  episode_reward_min: -1.1400000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 36886\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2372478362841486\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013550791104758927\n",
      "          policy_loss: -0.07415636490361813\n",
      "          total_loss: 0.07491222801658078\n",
      "          vf_explained_var: 0.9370580315589905\n",
      "          vf_loss: 0.1405706743709743\n",
      "    num_agent_steps_sampled: 3378648\n",
      "    num_agent_steps_trained: 3378648\n",
      "    num_steps_sampled: 3378648\n",
      "    num_steps_trained: 3378648\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.86636363636364\n",
      "    ram_util_percent: 56.49681818181818\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04561979187274879\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09711995738688\n",
      "    mean_inference_ms: 2.858072057335222\n",
      "    mean_raw_obs_processing_ms: 3.207198335430128\n",
      "  time_since_restore: 52314.44095206261\n",
      "  time_this_iter_s: 154.2064230442047\n",
      "  time_total_s: 52314.44095206261\n",
      "  timers:\n",
      "    learn_throughput: 935.746\n",
      "    learn_time_ms: 10682.382\n",
      "    load_throughput: 91200.852\n",
      "    load_time_ms: 109.604\n",
      "    sample_throughput: 61.507\n",
      "    sample_time_ms: 162519.211\n",
      "    update_time_ms: 13.472\n",
      "  timestamp: 1636346736\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3378648\n",
      "  training_iteration: 338\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   338</td><td style=\"text-align: right;\">         52314.4</td><td style=\"text-align: right;\">3378648</td><td style=\"text-align: right;\"> 4.05207</td><td style=\"text-align: right;\">               12.76</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           90.4324</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3388644\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-48-39\n",
      "  done: false\n",
      "  episode_len_mean: 88.83783783783784\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.830000000000014\n",
      "  episode_reward_mean: 3.978468468468477\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 36997\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2373445804302508\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014170427849310255\n",
      "          policy_loss: -0.07549467953399588\n",
      "          total_loss: 0.0938503842195894\n",
      "          vf_explained_var: 0.9370816349983215\n",
      "          vf_loss: 0.1594365029810713\n",
      "    num_agent_steps_sampled: 3388644\n",
      "    num_agent_steps_trained: 3388644\n",
      "    num_steps_sampled: 3388644\n",
      "    num_steps_trained: 3388644\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.49080459770114\n",
      "    ram_util_percent: 56.55517241379311\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045656676547185485\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09795401611239\n",
      "    mean_inference_ms: 2.857984388621114\n",
      "    mean_raw_obs_processing_ms: 3.2224429837694712\n",
      "  time_since_restore: 52497.01522397995\n",
      "  time_this_iter_s: 182.57427191734314\n",
      "  time_total_s: 52497.01522397995\n",
      "  timers:\n",
      "    learn_throughput: 935.032\n",
      "    learn_time_ms: 10690.548\n",
      "    load_throughput: 91108.676\n",
      "    load_time_ms: 109.715\n",
      "    sample_throughput: 59.981\n",
      "    sample_time_ms: 166651.678\n",
      "    update_time_ms: 12.245\n",
      "  timestamp: 1636346919\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3388644\n",
      "  training_iteration: 339\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   339</td><td style=\"text-align: right;\">           52497</td><td style=\"text-align: right;\">3388644</td><td style=\"text-align: right;\"> 3.97847</td><td style=\"text-align: right;\">               12.83</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           88.8378</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3398640\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-51-01\n",
      "  done: false\n",
      "  episode_len_mean: 91.03636363636363\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.08000000000001\n",
      "  episode_reward_mean: 3.62972727272728\n",
      "  episode_reward_min: -1.3300000000000003\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 37107\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2434215708675547\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014149978707341769\n",
      "          policy_loss: -0.0734064681463453\n",
      "          total_loss: 0.0957532468976246\n",
      "          vf_explained_var: 0.9275050759315491\n",
      "          vf_loss: 0.15935851017920635\n",
      "    num_agent_steps_sampled: 3398640\n",
      "    num_agent_steps_trained: 3398640\n",
      "    num_steps_sampled: 3398640\n",
      "    num_steps_trained: 3398640\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.32079207920792\n",
      "    ram_util_percent: 56.46485148514851\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04563784752497005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10295243774171\n",
      "    mean_inference_ms: 2.8581912795251676\n",
      "    mean_raw_obs_processing_ms: 3.2140516580768774\n",
      "  time_since_restore: 52639.03893995285\n",
      "  time_this_iter_s: 142.0237159729004\n",
      "  time_total_s: 52639.03893995285\n",
      "  timers:\n",
      "    learn_throughput: 935.071\n",
      "    learn_time_ms: 10690.101\n",
      "    load_throughput: 91106.577\n",
      "    load_time_ms: 109.718\n",
      "    sample_throughput: 61.574\n",
      "    sample_time_ms: 162342.263\n",
      "    update_time_ms: 12.05\n",
      "  timestamp: 1636347061\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3398640\n",
      "  training_iteration: 340\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   340</td><td style=\"text-align: right;\">           52639</td><td style=\"text-align: right;\">3398640</td><td style=\"text-align: right;\"> 3.62973</td><td style=\"text-align: right;\">               13.08</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">           91.0364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3408636\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-54-18\n",
      "  done: false\n",
      "  episode_len_mean: 89.27678571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.890000000000013\n",
      "  episode_reward_mean: 3.6683035714285794\n",
      "  episode_reward_min: -1.6500000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 37219\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2352333527344923\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013798220867827348\n",
      "          policy_loss: -0.07260048294949353\n",
      "          total_loss: 0.11722193813890729\n",
      "          vf_explained_var: 0.9051232933998108\n",
      "          vf_loss: 0.18074068075412103\n",
      "    num_agent_steps_sampled: 3408636\n",
      "    num_agent_steps_trained: 3408636\n",
      "    num_steps_sampled: 3408636\n",
      "    num_steps_trained: 3408636\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.02553191489363\n",
      "    ram_util_percent: 56.44078014184398\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04563609568089425\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10568575363795\n",
      "    mean_inference_ms: 2.857829768670618\n",
      "    mean_raw_obs_processing_ms: 3.228309611485779\n",
      "  time_since_restore: 52835.980009794235\n",
      "  time_this_iter_s: 196.9410698413849\n",
      "  time_total_s: 52835.980009794235\n",
      "  timers:\n",
      "    learn_throughput: 935.293\n",
      "    learn_time_ms: 10687.557\n",
      "    load_throughput: 90945.117\n",
      "    load_time_ms: 109.912\n",
      "    sample_throughput: 60.737\n",
      "    sample_time_ms: 164577.578\n",
      "    update_time_ms: 11.224\n",
      "  timestamp: 1636347258\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3408636\n",
      "  training_iteration: 341\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   341</td><td style=\"text-align: right;\">           52836</td><td style=\"text-align: right;\">3408636</td><td style=\"text-align: right;\">  3.6683</td><td style=\"text-align: right;\">               14.89</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           89.2768</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3418632\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-57-24\n",
      "  done: false\n",
      "  episode_len_mean: 87.97368421052632\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.770000000000016\n",
      "  episode_reward_mean: 3.4905263157894817\n",
      "  episode_reward_min: -1.6400000000000008\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 37333\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.233782192784497\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014002884676449133\n",
      "          policy_loss: -0.06933212568028232\n",
      "          total_loss: 0.09364019586808152\n",
      "          vf_explained_var: 0.9228399991989136\n",
      "          vf_loss: 0.15340982081575527\n",
      "    num_agent_steps_sampled: 3418632\n",
      "    num_agent_steps_trained: 3418632\n",
      "    num_steps_sampled: 3418632\n",
      "    num_steps_trained: 3418632\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.103007518797\n",
      "    ram_util_percent: 56.36578947368421\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045614047836100735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10427250460096\n",
      "    mean_inference_ms: 2.857839948691133\n",
      "    mean_raw_obs_processing_ms: 3.2397649695121524\n",
      "  time_since_restore: 53022.673948049545\n",
      "  time_this_iter_s: 186.69393825531006\n",
      "  time_total_s: 53022.673948049545\n",
      "  timers:\n",
      "    learn_throughput: 934.862\n",
      "    learn_time_ms: 10692.486\n",
      "    load_throughput: 91307.689\n",
      "    load_time_ms: 109.476\n",
      "    sample_throughput: 60.235\n",
      "    sample_time_ms: 165950.729\n",
      "    update_time_ms: 11.211\n",
      "  timestamp: 1636347444\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3418632\n",
      "  training_iteration: 342\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   342</td><td style=\"text-align: right;\">         53022.7</td><td style=\"text-align: right;\">3418632</td><td style=\"text-align: right;\"> 3.49053</td><td style=\"text-align: right;\">               12.77</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           87.9737</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3428628\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_04-59-58\n",
      "  done: false\n",
      "  episode_len_mean: 89.9375\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.990000000000013\n",
      "  episode_reward_mean: 3.2680357142857224\n",
      "  episode_reward_min: -1.6700000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 37445\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2529360919936092\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013658910739881354\n",
      "          policy_loss: -0.07228654913731619\n",
      "          total_loss: 0.09598119093630558\n",
      "          vf_explained_var: 0.9176378846168518\n",
      "          vf_loss: 0.15968039474553533\n",
      "    num_agent_steps_sampled: 3428628\n",
      "    num_agent_steps_trained: 3428628\n",
      "    num_steps_sampled: 3428628\n",
      "    num_steps_trained: 3428628\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.7440909090909\n",
      "    ram_util_percent: 56.436818181818175\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04563970687014144\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10728902717235\n",
      "    mean_inference_ms: 2.8579864889578945\n",
      "    mean_raw_obs_processing_ms: 3.239414515278279\n",
      "  time_since_restore: 53176.627308130264\n",
      "  time_this_iter_s: 153.953360080719\n",
      "  time_total_s: 53176.627308130264\n",
      "  timers:\n",
      "    learn_throughput: 934.95\n",
      "    learn_time_ms: 10691.483\n",
      "    load_throughput: 91190.319\n",
      "    load_time_ms: 109.617\n",
      "    sample_throughput: 60.873\n",
      "    sample_time_ms: 164210.232\n",
      "    update_time_ms: 11.086\n",
      "  timestamp: 1636347598\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3428628\n",
      "  training_iteration: 343\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   343</td><td style=\"text-align: right;\">         53176.6</td><td style=\"text-align: right;\">3428628</td><td style=\"text-align: right;\"> 3.26804</td><td style=\"text-align: right;\">               14.99</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           89.9375</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3438624\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-02-31\n",
      "  done: false\n",
      "  episode_len_mean: 91.19266055045871\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.640000000000015\n",
      "  episode_reward_mean: 3.922201834862394\n",
      "  episode_reward_min: -2.0600000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 37554\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2242654339880006\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014217291696684306\n",
      "          policy_loss: -0.07131992530427937\n",
      "          total_loss: 0.09648177240234919\n",
      "          vf_explained_var: 0.9283559918403625\n",
      "          vf_loss: 0.1576555834685126\n",
      "    num_agent_steps_sampled: 3438624\n",
      "    num_agent_steps_trained: 3438624\n",
      "    num_steps_sampled: 3438624\n",
      "    num_steps_trained: 3438624\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.7442396313364\n",
      "    ram_util_percent: 56.525345622119815\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0456383695556425\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10661695978656\n",
      "    mean_inference_ms: 2.857950570457373\n",
      "    mean_raw_obs_processing_ms: 3.2420657612313537\n",
      "  time_since_restore: 53328.85582923889\n",
      "  time_this_iter_s: 152.22852110862732\n",
      "  time_total_s: 53328.85582923889\n",
      "  timers:\n",
      "    learn_throughput: 935.029\n",
      "    learn_time_ms: 10690.578\n",
      "    load_throughput: 91762.489\n",
      "    load_time_ms: 108.933\n",
      "    sample_throughput: 61.587\n",
      "    sample_time_ms: 162306.975\n",
      "    update_time_ms: 10.482\n",
      "  timestamp: 1636347751\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3438624\n",
      "  training_iteration: 344\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   344</td><td style=\"text-align: right;\">         53328.9</td><td style=\"text-align: right;\">3438624</td><td style=\"text-align: right;\">  3.9222</td><td style=\"text-align: right;\">               12.64</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           91.1927</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3448620\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-05-03\n",
      "  done: false\n",
      "  episode_len_mean: 92.83177570093459\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.210000000000012\n",
      "  episode_reward_mean: 3.7204672897196343\n",
      "  episode_reward_min: -1.5200000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 37661\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.245342842534057\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013742611822342725\n",
      "          policy_loss: -0.07400520229154928\n",
      "          total_loss: 0.0952505141027017\n",
      "          vf_explained_var: 0.9297173619270325\n",
      "          vf_loss: 0.16040175639283963\n",
      "    num_agent_steps_sampled: 3448620\n",
      "    num_agent_steps_trained: 3448620\n",
      "    num_steps_sampled: 3448620\n",
      "    num_steps_trained: 3448620\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.91382488479265\n",
      "    ram_util_percent: 56.506451612903234\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045622236244893054\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.105999075217376\n",
      "    mean_inference_ms: 2.85777375856283\n",
      "    mean_raw_obs_processing_ms: 3.2437498568845946\n",
      "  time_since_restore: 53481.118191957474\n",
      "  time_this_iter_s: 152.26236271858215\n",
      "  time_total_s: 53481.118191957474\n",
      "  timers:\n",
      "    learn_throughput: 935.029\n",
      "    learn_time_ms: 10690.573\n",
      "    load_throughput: 91716.681\n",
      "    load_time_ms: 108.988\n",
      "    sample_throughput: 62.871\n",
      "    sample_time_ms: 158991.949\n",
      "    update_time_ms: 9.953\n",
      "  timestamp: 1636347903\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3448620\n",
      "  training_iteration: 345\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   345</td><td style=\"text-align: right;\">         53481.1</td><td style=\"text-align: right;\">3448620</td><td style=\"text-align: right;\"> 3.72047</td><td style=\"text-align: right;\">               13.21</td><td style=\"text-align: right;\">               -1.52</td><td style=\"text-align: right;\">           92.8318</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3458616\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-07-53\n",
      "  done: false\n",
      "  episode_len_mean: 92.79629629629629\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.92000000000001\n",
      "  episode_reward_mean: 3.611018518518527\n",
      "  episode_reward_min: -1.0100000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 37769\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2484480501240136\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013678052848185516\n",
      "          policy_loss: -0.07230657456904395\n",
      "          total_loss: 0.08383475301516616\n",
      "          vf_explained_var: 0.9226611256599426\n",
      "          vf_loss: 0.14746549187116642\n",
      "    num_agent_steps_sampled: 3458616\n",
      "    num_agent_steps_trained: 3458616\n",
      "    num_steps_sampled: 3458616\n",
      "    num_steps_trained: 3458616\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.32438016528926\n",
      "    ram_util_percent: 56.58429752066115\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045613041525242204\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.099667453713785\n",
      "    mean_inference_ms: 2.857814681267916\n",
      "    mean_raw_obs_processing_ms: 3.2481058262670257\n",
      "  time_since_restore: 53650.71100950241\n",
      "  time_this_iter_s: 169.59281754493713\n",
      "  time_total_s: 53650.71100950241\n",
      "  timers:\n",
      "    learn_throughput: 935.545\n",
      "    learn_time_ms: 10684.678\n",
      "    load_throughput: 92406.829\n",
      "    load_time_ms: 108.174\n",
      "    sample_throughput: 62.86\n",
      "    sample_time_ms: 159019.32\n",
      "    update_time_ms: 9.504\n",
      "  timestamp: 1636348073\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3458616\n",
      "  training_iteration: 346\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   346</td><td style=\"text-align: right;\">         53650.7</td><td style=\"text-align: right;\">3458616</td><td style=\"text-align: right;\"> 3.61102</td><td style=\"text-align: right;\">               14.92</td><td style=\"text-align: right;\">               -1.01</td><td style=\"text-align: right;\">           92.7963</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3468612\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-10-25\n",
      "  done: false\n",
      "  episode_len_mean: 92.36111111111111\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.730000000000018\n",
      "  episode_reward_mean: 3.34546296296297\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 37877\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.241486157209445\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013418731519082296\n",
      "          policy_loss: -0.07145958872209503\n",
      "          total_loss: 0.07375239224817891\n",
      "          vf_explained_var: 0.9285520315170288\n",
      "          vf_loss: 0.13705729361400645\n",
      "    num_agent_steps_sampled: 3468612\n",
      "    num_agent_steps_trained: 3468612\n",
      "    num_steps_sampled: 3468612\n",
      "    num_steps_trained: 3468612\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.17649769585253\n",
      "    ram_util_percent: 56.62672811059908\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0456136078710669\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0993459361721\n",
      "    mean_inference_ms: 2.857821999418743\n",
      "    mean_raw_obs_processing_ms: 3.246096432973446\n",
      "  time_since_restore: 53802.59827184677\n",
      "  time_this_iter_s: 151.88726234436035\n",
      "  time_total_s: 53802.59827184677\n",
      "  timers:\n",
      "    learn_throughput: 935.56\n",
      "    learn_time_ms: 10684.508\n",
      "    load_throughput: 92798.567\n",
      "    load_time_ms: 107.717\n",
      "    sample_throughput: 65.154\n",
      "    sample_time_ms: 153421.83\n",
      "    update_time_ms: 8.508\n",
      "  timestamp: 1636348225\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3468612\n",
      "  training_iteration: 347\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   347</td><td style=\"text-align: right;\">         53802.6</td><td style=\"text-align: right;\">3468612</td><td style=\"text-align: right;\"> 3.34546</td><td style=\"text-align: right;\">               12.73</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           92.3611</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3478608\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-13-12\n",
      "  done: false\n",
      "  episode_len_mean: 91.89908256880734\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.650000000000016\n",
      "  episode_reward_mean: 3.556697247706431\n",
      "  episode_reward_min: -1.0800000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 37986\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.242501612402435\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013464355084053482\n",
      "          policy_loss: -0.06985651512558644\n",
      "          total_loss: 0.07007750964476767\n",
      "          vf_explained_var: 0.9289230704307556\n",
      "          vf_loss: 0.13168555674358057\n",
      "    num_agent_steps_sampled: 3478608\n",
      "    num_agent_steps_trained: 3478608\n",
      "    num_steps_sampled: 3478608\n",
      "    num_steps_trained: 3478608\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.76317991631801\n",
      "    ram_util_percent: 56.56192468619246\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04564281153276946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10029745092226\n",
      "    mean_inference_ms: 2.8576273557928613\n",
      "    mean_raw_obs_processing_ms: 3.2514457435313853\n",
      "  time_since_restore: 53969.874069452286\n",
      "  time_this_iter_s: 167.27579760551453\n",
      "  time_total_s: 53969.874069452286\n",
      "  timers:\n",
      "    learn_throughput: 935.46\n",
      "    learn_time_ms: 10685.654\n",
      "    load_throughput: 92646.187\n",
      "    load_time_ms: 107.894\n",
      "    sample_throughput: 64.604\n",
      "    sample_time_ms: 154728.305\n",
      "    update_time_ms: 7.664\n",
      "  timestamp: 1636348392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3478608\n",
      "  training_iteration: 348\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   348</td><td style=\"text-align: right;\">         53969.9</td><td style=\"text-align: right;\">3478608</td><td style=\"text-align: right;\">  3.5567</td><td style=\"text-align: right;\">               12.65</td><td style=\"text-align: right;\">               -1.08</td><td style=\"text-align: right;\">           91.8991</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3488604\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-16-01\n",
      "  done: false\n",
      "  episode_len_mean: 91.55045871559633\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.230000000000013\n",
      "  episode_reward_mean: 3.859266055045881\n",
      "  episode_reward_min: -1.1300000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 38095\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2468109513959313\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014308046681599889\n",
      "          policy_loss: -0.07078834888803907\n",
      "          total_loss: 0.11179647179017974\n",
      "          vf_explained_var: 0.9267479181289673\n",
      "          vf_loss: 0.1724574104206175\n",
      "    num_agent_steps_sampled: 3488604\n",
      "    num_agent_steps_trained: 3488604\n",
      "    num_steps_sampled: 3488604\n",
      "    num_steps_trained: 3488604\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.22821576763485\n",
      "    ram_util_percent: 56.489626556016596\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045625353593982426\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.092637492800435\n",
      "    mean_inference_ms: 2.8575475081591826\n",
      "    mean_raw_obs_processing_ms: 3.2568659499695394\n",
      "  time_since_restore: 54138.7570669651\n",
      "  time_this_iter_s: 168.88299751281738\n",
      "  time_total_s: 54138.7570669651\n",
      "  timers:\n",
      "    learn_throughput: 935.579\n",
      "    learn_time_ms: 10684.29\n",
      "    load_throughput: 92843.53\n",
      "    load_time_ms: 107.665\n",
      "    sample_throughput: 65.18\n",
      "    sample_time_ms: 153360.696\n",
      "    update_time_ms: 7.918\n",
      "  timestamp: 1636348561\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3488604\n",
      "  training_iteration: 349\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   349</td><td style=\"text-align: right;\">         54138.8</td><td style=\"text-align: right;\">3488604</td><td style=\"text-align: right;\"> 3.85927</td><td style=\"text-align: right;\">               11.23</td><td style=\"text-align: right;\">               -1.13</td><td style=\"text-align: right;\">           91.5505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3498600\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-18-34\n",
      "  done: false\n",
      "  episode_len_mean: 92.68518518518519\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.070000000000014\n",
      "  episode_reward_mean: 3.622407407407415\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 38203\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.225293137273218\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01455541058540669\n",
      "          policy_loss: -0.06935402600842919\n",
      "          total_loss: 0.09201014508357924\n",
      "          vf_explained_var: 0.9307939410209656\n",
      "          vf_loss: 0.1504580564987965\n",
      "    num_agent_steps_sampled: 3498600\n",
      "    num_agent_steps_trained: 3498600\n",
      "    num_steps_sampled: 3498600\n",
      "    num_steps_trained: 3498600\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.87064220183487\n",
      "    ram_util_percent: 56.54587155963302\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0456245364704551\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09529122769433\n",
      "    mean_inference_ms: 2.8576960081358918\n",
      "    mean_raw_obs_processing_ms: 3.253922048620165\n",
      "  time_since_restore: 54291.952459812164\n",
      "  time_this_iter_s: 153.19539284706116\n",
      "  time_total_s: 54291.952459812164\n",
      "  timers:\n",
      "    learn_throughput: 935.674\n",
      "    learn_time_ms: 10683.21\n",
      "    load_throughput: 92896.749\n",
      "    load_time_ms: 107.603\n",
      "    sample_throughput: 64.708\n",
      "    sample_time_ms: 154477.851\n",
      "    update_time_ms: 8.812\n",
      "  timestamp: 1636348714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3498600\n",
      "  training_iteration: 350\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   350</td><td style=\"text-align: right;\">           54292</td><td style=\"text-align: right;\">3498600</td><td style=\"text-align: right;\"> 3.62241</td><td style=\"text-align: right;\">               13.07</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           92.6852</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3508596\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-21-04\n",
      "  done: false\n",
      "  episode_len_mean: 92.58715596330275\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.920000000000014\n",
      "  episode_reward_mean: 3.4973394495412924\n",
      "  episode_reward_min: -1.5800000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 38312\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2357284567294977\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014656060381935055\n",
      "          policy_loss: -0.06932840124091022\n",
      "          total_loss: 0.11255107653987968\n",
      "          vf_explained_var: 0.9173742532730103\n",
      "          vf_loss: 0.17084842371459827\n",
      "    num_agent_steps_sampled: 3508596\n",
      "    num_agent_steps_trained: 3508596\n",
      "    num_steps_sampled: 3508596\n",
      "    num_steps_trained: 3508596\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.79813084112148\n",
      "    ram_util_percent: 56.35093457943925\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045632457134577295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.094047019084584\n",
      "    mean_inference_ms: 2.8577566140022284\n",
      "    mean_raw_obs_processing_ms: 3.2568659943985927\n",
      "  time_since_restore: 54441.55342745781\n",
      "  time_this_iter_s: 149.60096764564514\n",
      "  time_total_s: 54441.55342745781\n",
      "  timers:\n",
      "    learn_throughput: 935.817\n",
      "    learn_time_ms: 10681.572\n",
      "    load_throughput: 93096.692\n",
      "    load_time_ms: 107.372\n",
      "    sample_throughput: 66.753\n",
      "    sample_time_ms: 149745.129\n",
      "    update_time_ms: 9.609\n",
      "  timestamp: 1636348864\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3508596\n",
      "  training_iteration: 351\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   351</td><td style=\"text-align: right;\">         54441.6</td><td style=\"text-align: right;\">3508596</td><td style=\"text-align: right;\"> 3.49734</td><td style=\"text-align: right;\">               12.92</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           92.5872</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3518592\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-23-56\n",
      "  done: false\n",
      "  episode_len_mean: 91.56481481481481\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.010000000000016\n",
      "  episode_reward_mean: 3.719907407407416\n",
      "  episode_reward_min: -1.3300000000000003\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 38420\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.238563604028816\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014708764170796819\n",
      "          policy_loss: -0.0670214005252426\n",
      "          total_loss: 0.1172587055951739\n",
      "          vf_explained_var: 0.9212980270385742\n",
      "          vf_loss: 0.17315733840800504\n",
      "    num_agent_steps_sampled: 3518592\n",
      "    num_agent_steps_trained: 3518592\n",
      "    num_steps_sampled: 3518592\n",
      "    num_steps_trained: 3518592\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.13265306122449\n",
      "    ram_util_percent: 56.55714285714285\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045621593697522805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.092062580956956\n",
      "    mean_inference_ms: 2.8576248816602376\n",
      "    mean_raw_obs_processing_ms: 3.265734235769379\n",
      "  time_since_restore: 54613.51136922836\n",
      "  time_this_iter_s: 171.9579417705536\n",
      "  time_total_s: 54613.51136922836\n",
      "  timers:\n",
      "    learn_throughput: 935.623\n",
      "    learn_time_ms: 10683.793\n",
      "    load_throughput: 93280.207\n",
      "    load_time_ms: 107.161\n",
      "    sample_throughput: 67.418\n",
      "    sample_time_ms: 148269.953\n",
      "    update_time_ms: 9.283\n",
      "  timestamp: 1636349036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3518592\n",
      "  training_iteration: 352\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   352</td><td style=\"text-align: right;\">         54613.5</td><td style=\"text-align: right;\">3518592</td><td style=\"text-align: right;\"> 3.71991</td><td style=\"text-align: right;\">               12.01</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">           91.5648</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3528588\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-26-24\n",
      "  done: false\n",
      "  episode_len_mean: 94.48113207547169\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.14000000000001\n",
      "  episode_reward_mean: 3.5118867924528394\n",
      "  episode_reward_min: -1.3000000000000003\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 38526\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2523372081609874\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013249710335648283\n",
      "          policy_loss: -0.07291444290079113\n",
      "          total_loss: 0.06302080356285103\n",
      "          vf_explained_var: 0.937316358089447\n",
      "          vf_loss: 0.12827412088871257\n",
      "    num_agent_steps_sampled: 3528588\n",
      "    num_agent_steps_trained: 3528588\n",
      "    num_steps_sampled: 3528588\n",
      "    num_steps_trained: 3528588\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.40330188679245\n",
      "    ram_util_percent: 56.62405660377358\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045588855984654064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.08895748935064\n",
      "    mean_inference_ms: 2.857479701667051\n",
      "    mean_raw_obs_processing_ms: 3.262035314315661\n",
      "  time_since_restore: 54761.76804804802\n",
      "  time_this_iter_s: 148.25667881965637\n",
      "  time_total_s: 54761.76804804802\n",
      "  timers:\n",
      "    learn_throughput: 935.727\n",
      "    learn_time_ms: 10682.602\n",
      "    load_throughput: 93438.555\n",
      "    load_time_ms: 106.979\n",
      "    sample_throughput: 67.677\n",
      "    sample_time_ms: 147700.903\n",
      "    update_time_ms: 9.854\n",
      "  timestamp: 1636349184\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3528588\n",
      "  training_iteration: 353\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   353</td><td style=\"text-align: right;\">         54761.8</td><td style=\"text-align: right;\">3528588</td><td style=\"text-align: right;\"> 3.51189</td><td style=\"text-align: right;\">               13.14</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">           94.4811</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3538584\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-29-15\n",
      "  done: false\n",
      "  episode_len_mean: 94.01886792452831\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.180000000000014\n",
      "  episode_reward_mean: 3.9870754716981223\n",
      "  episode_reward_min: -1.6400000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 38632\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2398057254970585\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014767240124584526\n",
      "          policy_loss: -0.06819615016221746\n",
      "          total_loss: 0.09200278982106182\n",
      "          vf_explained_var: 0.9232621192932129\n",
      "          vf_loss: 0.14895537621699848\n",
      "    num_agent_steps_sampled: 3538584\n",
      "    num_agent_steps_trained: 3538584\n",
      "    num_steps_sampled: 3538584\n",
      "    num_steps_trained: 3538584\n",
      "  iterations_since_restore: 354\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.38483606557377\n",
      "    ram_util_percent: 56.55901639344261\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04561756582474567\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.08148581034352\n",
      "    mean_inference_ms: 2.857247446327288\n",
      "    mean_raw_obs_processing_ms: 3.275362009658257\n",
      "  time_since_restore: 54932.67426991463\n",
      "  time_this_iter_s: 170.90622186660767\n",
      "  time_total_s: 54932.67426991463\n",
      "  timers:\n",
      "    learn_throughput: 935.238\n",
      "    learn_time_ms: 10688.192\n",
      "    load_throughput: 93068.69\n",
      "    load_time_ms: 107.405\n",
      "    sample_throughput: 66.835\n",
      "    sample_time_ms: 149562.996\n",
      "    update_time_ms: 9.836\n",
      "  timestamp: 1636349355\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3538584\n",
      "  training_iteration: 354\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   354</td><td style=\"text-align: right;\">         54932.7</td><td style=\"text-align: right;\">3538584</td><td style=\"text-align: right;\"> 3.98708</td><td style=\"text-align: right;\">               11.18</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           94.0189</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3548580\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-31-47\n",
      "  done: false\n",
      "  episode_len_mean: 93.8411214953271\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.140000000000011\n",
      "  episode_reward_mean: 3.600841121495336\n",
      "  episode_reward_min: -1.6200000000000008\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 38739\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2300586346887115\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014551115972451241\n",
      "          policy_loss: -0.06903870027337192\n",
      "          total_loss: 0.10638914453502521\n",
      "          vf_explained_var: 0.9359985589981079\n",
      "          vf_loss: 0.16457916888543683\n",
      "    num_agent_steps_sampled: 3548580\n",
      "    num_agent_steps_trained: 3548580\n",
      "    num_steps_sampled: 3548580\n",
      "    num_steps_trained: 3548580\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.63842592592593\n",
      "    ram_util_percent: 56.53703703703704\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559775540985228\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07871078502736\n",
      "    mean_inference_ms: 2.8574709858404033\n",
      "    mean_raw_obs_processing_ms: 3.2752169525825874\n",
      "  time_since_restore: 55084.70670962334\n",
      "  time_this_iter_s: 152.03243970870972\n",
      "  time_total_s: 55084.70670962334\n",
      "  timers:\n",
      "    learn_throughput: 935.481\n",
      "    learn_time_ms: 10685.413\n",
      "    load_throughput: 93028.896\n",
      "    load_time_ms: 107.45\n",
      "    sample_throughput: 66.844\n",
      "    sample_time_ms: 149543.124\n",
      "    update_time_ms: 9.506\n",
      "  timestamp: 1636349507\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3548580\n",
      "  training_iteration: 355\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   355</td><td style=\"text-align: right;\">         55084.7</td><td style=\"text-align: right;\">3548580</td><td style=\"text-align: right;\"> 3.60084</td><td style=\"text-align: right;\">               13.14</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">           93.8411</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3558576\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-34-30\n",
      "  done: false\n",
      "  episode_len_mean: 92.73148148148148\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.970000000000015\n",
      "  episode_reward_mean: 4.209907407407417\n",
      "  episode_reward_min: -1.4500000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 38847\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2337730994591345\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013822436178079416\n",
      "          policy_loss: -0.0730097367372523\n",
      "          total_loss: 0.09360877120883292\n",
      "          vf_explained_var: 0.9356511235237122\n",
      "          vf_loss: 0.15746700097448552\n",
      "    num_agent_steps_sampled: 3558576\n",
      "    num_agent_steps_trained: 3558576\n",
      "    num_steps_sampled: 3558576\n",
      "    num_steps_trained: 3558576\n",
      "  iterations_since_restore: 356\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.53290598290597\n",
      "    ram_util_percent: 56.68846153846154\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045583602651573636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.073727933207934\n",
      "    mean_inference_ms: 2.8573344834673793\n",
      "    mean_raw_obs_processing_ms: 3.28246173920172\n",
      "  time_since_restore: 55248.1126408577\n",
      "  time_this_iter_s: 163.40593123435974\n",
      "  time_total_s: 55248.1126408577\n",
      "  timers:\n",
      "    learn_throughput: 935.263\n",
      "    learn_time_ms: 10687.898\n",
      "    load_throughput: 92641.151\n",
      "    load_time_ms: 107.9\n",
      "    sample_throughput: 67.123\n",
      "    sample_time_ms: 148921.189\n",
      "    update_time_ms: 9.375\n",
      "  timestamp: 1636349670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3558576\n",
      "  training_iteration: 356\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   356</td><td style=\"text-align: right;\">         55248.1</td><td style=\"text-align: right;\">3558576</td><td style=\"text-align: right;\"> 4.20991</td><td style=\"text-align: right;\">               12.97</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           92.7315</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3568572\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-37-11\n",
      "  done: false\n",
      "  episode_len_mean: 94.9245283018868\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.510000000000012\n",
      "  episode_reward_mean: 3.4497169811320836\n",
      "  episode_reward_min: -1.6800000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 38953\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2383927078328583\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013921541881304532\n",
      "          policy_loss: -0.06946550017366042\n",
      "          total_loss: 0.08440158755446855\n",
      "          vf_explained_var: 0.9315767884254456\n",
      "          vf_loss: 0.14453600166827185\n",
      "    num_agent_steps_sampled: 3568572\n",
      "    num_agent_steps_trained: 3568572\n",
      "    num_steps_sampled: 3568572\n",
      "    num_steps_trained: 3568572\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.30263157894737\n",
      "    ram_util_percent: 56.53421052631579\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04562657355562964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07180065324946\n",
      "    mean_inference_ms: 2.8569172366202786\n",
      "    mean_raw_obs_processing_ms: 3.2881998908889107\n",
      "  time_since_restore: 55408.352059841156\n",
      "  time_this_iter_s: 160.23941898345947\n",
      "  time_total_s: 55408.352059841156\n",
      "  timers:\n",
      "    learn_throughput: 935.374\n",
      "    learn_time_ms: 10686.631\n",
      "    load_throughput: 92354.557\n",
      "    load_time_ms: 108.235\n",
      "    sample_throughput: 66.749\n",
      "    sample_time_ms: 149755.763\n",
      "    update_time_ms: 10.198\n",
      "  timestamp: 1636349831\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3568572\n",
      "  training_iteration: 357\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   357</td><td style=\"text-align: right;\">         55408.4</td><td style=\"text-align: right;\">3568572</td><td style=\"text-align: right;\"> 3.44972</td><td style=\"text-align: right;\">               10.51</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           94.9245</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3578568\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-40-28\n",
      "  done: false\n",
      "  episode_len_mean: 93.29245283018868\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.980000000000011\n",
      "  episode_reward_mean: 3.948301886792461\n",
      "  episode_reward_min: -1.5000000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 39059\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2278693086061723\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013268942996712645\n",
      "          policy_loss: -0.0731553165632117\n",
      "          total_loss: 0.07966884378598542\n",
      "          vf_explained_var: 0.9345712661743164\n",
      "          vf_loss: 0.1448745423490102\n",
      "    num_agent_steps_sampled: 3578568\n",
      "    num_agent_steps_trained: 3578568\n",
      "    num_steps_sampled: 3578568\n",
      "    num_steps_trained: 3578568\n",
      "  iterations_since_restore: 358\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.35212765957446\n",
      "    ram_util_percent: 56.58156028368794\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045613507214782356\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06364049425926\n",
      "    mean_inference_ms: 2.8570419164289125\n",
      "    mean_raw_obs_processing_ms: 3.315243598473861\n",
      "  time_since_restore: 55605.66695690155\n",
      "  time_this_iter_s: 197.3148970603943\n",
      "  time_total_s: 55605.66695690155\n",
      "  timers:\n",
      "    learn_throughput: 935.169\n",
      "    learn_time_ms: 10688.978\n",
      "    load_throughput: 92199.98\n",
      "    load_time_ms: 108.417\n",
      "    sample_throughput: 65.438\n",
      "    sample_time_ms: 152756.434\n",
      "    update_time_ms: 10.471\n",
      "  timestamp: 1636350028\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3578568\n",
      "  training_iteration: 358\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   358</td><td style=\"text-align: right;\">         55605.7</td><td style=\"text-align: right;\">3578568</td><td style=\"text-align: right;\">  3.9483</td><td style=\"text-align: right;\">               12.98</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           93.2925</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3588564\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-43-13\n",
      "  done: false\n",
      "  episode_len_mean: 94.26415094339623\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.830000000000016\n",
      "  episode_reward_mean: 3.6489622641509523\n",
      "  episode_reward_min: -1.6500000000000006\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 39165\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2273643157421015\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013430212778234953\n",
      "          policy_loss: -0.07079231958103994\n",
      "          total_loss: 0.07046961164595479\n",
      "          vf_explained_var: 0.9294625520706177\n",
      "          vf_loss: 0.1329398697337661\n",
      "    num_agent_steps_sampled: 3588564\n",
      "    num_agent_steps_trained: 3588564\n",
      "    num_steps_sampled: 3588564\n",
      "    num_steps_trained: 3588564\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.9927659574468\n",
      "    ram_util_percent: 56.72680851063829\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556765810587033\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.059536467038114\n",
      "    mean_inference_ms: 2.856881479425886\n",
      "    mean_raw_obs_processing_ms: 3.3160655627477365\n",
      "  time_since_restore: 55770.44390249252\n",
      "  time_this_iter_s: 164.7769455909729\n",
      "  time_total_s: 55770.44390249252\n",
      "  timers:\n",
      "    learn_throughput: 934.894\n",
      "    learn_time_ms: 10692.116\n",
      "    load_throughput: 92167.023\n",
      "    load_time_ms: 108.455\n",
      "    sample_throughput: 65.616\n",
      "    sample_time_ms: 152342.043\n",
      "    update_time_ms: 10.607\n",
      "  timestamp: 1636350193\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3588564\n",
      "  training_iteration: 359\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   359</td><td style=\"text-align: right;\">         55770.4</td><td style=\"text-align: right;\">3588564</td><td style=\"text-align: right;\"> 3.64896</td><td style=\"text-align: right;\">               10.83</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           94.2642</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3598560\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-45-28\n",
      "  done: false\n",
      "  episode_len_mean: 95.95238095238095\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.950000000000012\n",
      "  episode_reward_mean: 3.136476190476198\n",
      "  episode_reward_min: -1.6900000000000008\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 39270\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.236630449947129\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014018558101995154\n",
      "          policy_loss: -0.07398003312782982\n",
      "          total_loss: 0.07371509950130414\n",
      "          vf_explained_var: 0.9301438331604004\n",
      "          vf_loss: 0.13812540844719634\n",
      "    num_agent_steps_sampled: 3598560\n",
      "    num_agent_steps_trained: 3598560\n",
      "    num_steps_sampled: 3598560\n",
      "    num_steps_trained: 3598560\n",
      "  iterations_since_restore: 360\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.83160621761658\n",
      "    ram_util_percent: 56.526424870466336\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560706453697887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.061217238203085\n",
      "    mean_inference_ms: 2.857039467672566\n",
      "    mean_raw_obs_processing_ms: 3.309940483664747\n",
      "  time_since_restore: 55905.80075478554\n",
      "  time_this_iter_s: 135.35685229301453\n",
      "  time_total_s: 55905.80075478554\n",
      "  timers:\n",
      "    learn_throughput: 935.193\n",
      "    learn_time_ms: 10688.706\n",
      "    load_throughput: 92194.242\n",
      "    load_time_ms: 108.423\n",
      "    sample_throughput: 66.391\n",
      "    sample_time_ms: 150562.625\n",
      "    update_time_ms: 9.614\n",
      "  timestamp: 1636350328\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3598560\n",
      "  training_iteration: 360\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   360</td><td style=\"text-align: right;\">         55905.8</td><td style=\"text-align: right;\">3598560</td><td style=\"text-align: right;\"> 3.13648</td><td style=\"text-align: right;\">               10.95</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           95.9524</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3608556\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-47-59\n",
      "  done: false\n",
      "  episode_len_mean: 95.83653846153847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.960000000000013\n",
      "  episode_reward_mean: 4.12125000000001\n",
      "  episode_reward_min: -1.4600000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 39374\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2119285273755716\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013933339799318052\n",
      "          policy_loss: -0.07228747834889297\n",
      "          total_loss: 0.09369607929808971\n",
      "          vf_explained_var: 0.9349416494369507\n",
      "          vf_loss: 0.15636095257682933\n",
      "    num_agent_steps_sampled: 3608556\n",
      "    num_agent_steps_trained: 3608556\n",
      "    num_steps_sampled: 3608556\n",
      "    num_steps_trained: 3608556\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.40511627906977\n",
      "    ram_util_percent: 56.45953488372093\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045592278211146454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0592788274986\n",
      "    mean_inference_ms: 2.8569139754489563\n",
      "    mean_raw_obs_processing_ms: 3.3073152319810313\n",
      "  time_since_restore: 56056.219613313675\n",
      "  time_this_iter_s: 150.4188585281372\n",
      "  time_total_s: 56056.219613313675\n",
      "  timers:\n",
      "    learn_throughput: 935.052\n",
      "    learn_time_ms: 10690.317\n",
      "    load_throughput: 92206.996\n",
      "    load_time_ms: 108.408\n",
      "    sample_throughput: 66.355\n",
      "    sample_time_ms: 150643.587\n",
      "    update_time_ms: 8.753\n",
      "  timestamp: 1636350479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3608556\n",
      "  training_iteration: 361\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   361</td><td style=\"text-align: right;\">         56056.2</td><td style=\"text-align: right;\">3608556</td><td style=\"text-align: right;\"> 4.12125</td><td style=\"text-align: right;\">               12.96</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           95.8365</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3618552\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-50-44\n",
      "  done: false\n",
      "  episode_len_mean: 91.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.150000000000011\n",
      "  episode_reward_mean: 4.094074074074083\n",
      "  episode_reward_min: -1.750000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 39482\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.19566532750415\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013330398772573979\n",
      "          policy_loss: -0.07201183079463294\n",
      "          total_loss: 0.10627883282593555\n",
      "          vf_explained_var: 0.9211147427558899\n",
      "          vf_loss: 0.16987900198238273\n",
      "    num_agent_steps_sampled: 3618552\n",
      "    num_agent_steps_trained: 3618552\n",
      "    num_steps_sampled: 3618552\n",
      "    num_steps_trained: 3618552\n",
      "  iterations_since_restore: 362\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.56186440677965\n",
      "    ram_util_percent: 56.35889830508475\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04564423880746394\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05615998551621\n",
      "    mean_inference_ms: 2.8570477865721937\n",
      "    mean_raw_obs_processing_ms: 3.3211567420752233\n",
      "  time_since_restore: 56221.7086224556\n",
      "  time_this_iter_s: 165.489009141922\n",
      "  time_total_s: 56221.7086224556\n",
      "  timers:\n",
      "    learn_throughput: 935.363\n",
      "    learn_time_ms: 10686.756\n",
      "    load_throughput: 91856.557\n",
      "    load_time_ms: 108.822\n",
      "    sample_throughput: 66.64\n",
      "    sample_time_ms: 149999.178\n",
      "    update_time_ms: 9.408\n",
      "  timestamp: 1636350644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3618552\n",
      "  training_iteration: 362\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   362</td><td style=\"text-align: right;\">         56221.7</td><td style=\"text-align: right;\">3618552</td><td style=\"text-align: right;\"> 4.09407</td><td style=\"text-align: right;\">               11.15</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">             91.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3628548\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-53-17\n",
      "  done: false\n",
      "  episode_len_mean: 96.52884615384616\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.840000000000012\n",
      "  episode_reward_mean: 3.714903846153855\n",
      "  episode_reward_min: -1.9000000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 39586\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.235807717152131\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014040543590248604\n",
      "          policy_loss: -0.06750000798676768\n",
      "          total_loss: 0.10675893277089056\n",
      "          vf_explained_var: 0.929010272026062\n",
      "          vf_loss: 0.16463090382898465\n",
      "    num_agent_steps_sampled: 3628548\n",
      "    num_agent_steps_trained: 3628548\n",
      "    num_steps_sampled: 3628548\n",
      "    num_steps_trained: 3628548\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.26912442396313\n",
      "    ram_util_percent: 56.602764976958525\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558717227794946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05295422861114\n",
      "    mean_inference_ms: 2.856729620588981\n",
      "    mean_raw_obs_processing_ms: 3.3167442973929755\n",
      "  time_since_restore: 56374.05311846733\n",
      "  time_this_iter_s: 152.344496011734\n",
      "  time_total_s: 56374.05311846733\n",
      "  timers:\n",
      "    learn_throughput: 935.281\n",
      "    learn_time_ms: 10687.702\n",
      "    load_throughput: 91873.223\n",
      "    load_time_ms: 108.802\n",
      "    sample_throughput: 66.46\n",
      "    sample_time_ms: 150407.142\n",
      "    update_time_ms: 9.449\n",
      "  timestamp: 1636350797\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3628548\n",
      "  training_iteration: 363\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   363</td><td style=\"text-align: right;\">         56374.1</td><td style=\"text-align: right;\">3628548</td><td style=\"text-align: right;\">  3.7149</td><td style=\"text-align: right;\">               14.84</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           96.5288</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3638544\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-56-15\n",
      "  done: false\n",
      "  episode_len_mean: 93.1214953271028\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.940000000000017\n",
      "  episode_reward_mean: 3.4078504672897267\n",
      "  episode_reward_min: -1.3200000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 39693\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2336977163950604\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014147902421439899\n",
      "          policy_loss: -0.0691674546760499\n",
      "          total_loss: 0.09847209720561902\n",
      "          vf_explained_var: 0.920369029045105\n",
      "          vf_loss: 0.1577458389899415\n",
      "    num_agent_steps_sampled: 3638544\n",
      "    num_agent_steps_trained: 3638544\n",
      "    num_steps_sampled: 3638544\n",
      "    num_steps_trained: 3638544\n",
      "  iterations_since_restore: 364\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.43828124999999\n",
      "    ram_util_percent: 56.619140625\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559460365169687\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05489408880702\n",
      "    mean_inference_ms: 2.8568697930891047\n",
      "    mean_raw_obs_processing_ms: 3.3223919706672405\n",
      "  time_since_restore: 56552.824402570724\n",
      "  time_this_iter_s: 178.77128410339355\n",
      "  time_total_s: 56552.824402570724\n",
      "  timers:\n",
      "    learn_throughput: 935.298\n",
      "    learn_time_ms: 10687.504\n",
      "    load_throughput: 91870.183\n",
      "    load_time_ms: 108.806\n",
      "    sample_throughput: 66.114\n",
      "    sample_time_ms: 151192.626\n",
      "    update_time_ms: 10.349\n",
      "  timestamp: 1636350975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3638544\n",
      "  training_iteration: 364\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   364</td><td style=\"text-align: right;\">         56552.8</td><td style=\"text-align: right;\">3638544</td><td style=\"text-align: right;\"> 3.40785</td><td style=\"text-align: right;\">               10.94</td><td style=\"text-align: right;\">               -1.32</td><td style=\"text-align: right;\">           93.1215</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3648540\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_05-59-07\n",
      "  done: false\n",
      "  episode_len_mean: 94.25233644859813\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.570000000000014\n",
      "  episode_reward_mean: 3.5583177570093545\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 39800\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2107077786046214\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012700260202466247\n",
      "          policy_loss: -0.07040331567295341\n",
      "          total_loss: 0.0737897862552896\n",
      "          vf_explained_var: 0.9267804622650146\n",
      "          vf_loss: 0.13736739804586157\n",
      "    num_agent_steps_sampled: 3648540\n",
      "    num_agent_steps_trained: 3648540\n",
      "    num_steps_sampled: 3648540\n",
      "    num_steps_trained: 3648540\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.87581967213113\n",
      "    ram_util_percent: 56.55163934426229\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045576001231974264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04624542555499\n",
      "    mean_inference_ms: 2.8567997104416754\n",
      "    mean_raw_obs_processing_ms: 3.3289304214855986\n",
      "  time_since_restore: 56724.41419315338\n",
      "  time_this_iter_s: 171.58979058265686\n",
      "  time_total_s: 56724.41419315338\n",
      "  timers:\n",
      "    learn_throughput: 934.569\n",
      "    learn_time_ms: 10695.834\n",
      "    load_throughput: 91916.044\n",
      "    load_time_ms: 108.751\n",
      "    sample_throughput: 65.274\n",
      "    sample_time_ms: 153139.491\n",
      "    update_time_ms: 11.019\n",
      "  timestamp: 1636351147\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3648540\n",
      "  training_iteration: 365\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   365</td><td style=\"text-align: right;\">         56724.4</td><td style=\"text-align: right;\">3648540</td><td style=\"text-align: right;\"> 3.55832</td><td style=\"text-align: right;\">               12.57</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           94.2523</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3658536\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-02-07\n",
      "  done: false\n",
      "  episode_len_mean: 92.67592592592592\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.540000000000015\n",
      "  episode_reward_mean: 3.495740740740749\n",
      "  episode_reward_min: -2.079999999999999\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 39908\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.220704848745949\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014166747174139294\n",
      "          policy_loss: -0.06679148473737077\n",
      "          total_loss: 0.08825509241646809\n",
      "          vf_explained_var: 0.9356070756912231\n",
      "          vf_loss: 0.14498000379460743\n",
      "    num_agent_steps_sampled: 3658536\n",
      "    num_agent_steps_trained: 3658536\n",
      "    num_steps_sampled: 3658536\n",
      "    num_steps_trained: 3658536\n",
      "  iterations_since_restore: 366\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.34591439688715\n",
      "    ram_util_percent: 56.30817120622568\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557279539152837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0420675477697\n",
      "    mean_inference_ms: 2.856452132176551\n",
      "    mean_raw_obs_processing_ms: 3.340031037215827\n",
      "  time_since_restore: 56904.373453855515\n",
      "  time_this_iter_s: 179.95926070213318\n",
      "  time_total_s: 56904.373453855515\n",
      "  timers:\n",
      "    learn_throughput: 934.39\n",
      "    learn_time_ms: 10697.891\n",
      "    load_throughput: 92025.009\n",
      "    load_time_ms: 108.623\n",
      "    sample_throughput: 64.576\n",
      "    sample_time_ms: 154793.265\n",
      "    update_time_ms: 10.947\n",
      "  timestamp: 1636351327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3658536\n",
      "  training_iteration: 366\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   366</td><td style=\"text-align: right;\">         56904.4</td><td style=\"text-align: right;\">3658536</td><td style=\"text-align: right;\"> 3.49574</td><td style=\"text-align: right;\">               10.54</td><td style=\"text-align: right;\">               -2.08</td><td style=\"text-align: right;\">           92.6759</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3668532\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-04-35\n",
      "  done: false\n",
      "  episode_len_mean: 94.78846153846153\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.730000000000013\n",
      "  episode_reward_mean: 3.471442307692317\n",
      "  episode_reward_min: -1.3400000000000005\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 40012\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.234641471479693\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01413010730973793\n",
      "          policy_loss: -0.06767548601755984\n",
      "          total_loss: 0.09966858668953307\n",
      "          vf_explained_var: 0.9319909811019897\n",
      "          vf_loss: 0.15750033546270978\n",
      "    num_agent_steps_sampled: 3668532\n",
      "    num_agent_steps_trained: 3668532\n",
      "    num_steps_sampled: 3668532\n",
      "    num_steps_trained: 3668532\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.63459715639812\n",
      "    ram_util_percent: 56.424170616113756\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559263922295519\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03997043942467\n",
      "    mean_inference_ms: 2.8566076113765866\n",
      "    mean_raw_obs_processing_ms: 3.3378517040438966\n",
      "  time_since_restore: 57052.35815548897\n",
      "  time_this_iter_s: 147.98470163345337\n",
      "  time_total_s: 57052.35815548897\n",
      "  timers:\n",
      "    learn_throughput: 933.307\n",
      "    learn_time_ms: 10710.305\n",
      "    load_throughput: 91938.438\n",
      "    load_time_ms: 108.725\n",
      "    sample_throughput: 65.097\n",
      "    sample_time_ms: 153556.286\n",
      "    update_time_ms: 10.749\n",
      "  timestamp: 1636351475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3668532\n",
      "  training_iteration: 367\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   367</td><td style=\"text-align: right;\">         57052.4</td><td style=\"text-align: right;\">3668532</td><td style=\"text-align: right;\"> 3.47144</td><td style=\"text-align: right;\">               12.73</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           94.7885</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3678528\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-06-46\n",
      "  done: false\n",
      "  episode_len_mean: 98.80392156862744\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.619999999999948\n",
      "  episode_reward_mean: 3.884313725490206\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 40114\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.226301493705847\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015022534574558176\n",
      "          policy_loss: -0.06454387955272045\n",
      "          total_loss: 0.1415173411090723\n",
      "          vf_explained_var: 0.9209212064743042\n",
      "          vf_loss: 0.19410102202310267\n",
      "    num_agent_steps_sampled: 3678528\n",
      "    num_agent_steps_trained: 3678528\n",
      "    num_steps_sampled: 3678528\n",
      "    num_steps_trained: 3678528\n",
      "  iterations_since_restore: 368\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95478723404256\n",
      "    ram_util_percent: 56.55585106382978\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455944726822992\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03666371132974\n",
      "    mean_inference_ms: 2.8566154985836056\n",
      "    mean_raw_obs_processing_ms: 3.3305668267829955\n",
      "  time_since_restore: 57183.54481124878\n",
      "  time_this_iter_s: 131.1866557598114\n",
      "  time_total_s: 57183.54481124878\n",
      "  timers:\n",
      "    learn_throughput: 933.34\n",
      "    learn_time_ms: 10709.922\n",
      "    load_throughput: 91902.747\n",
      "    load_time_ms: 108.767\n",
      "    sample_throughput: 68.026\n",
      "    sample_time_ms: 146944.306\n",
      "    update_time_ms: 10.664\n",
      "  timestamp: 1636351606\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3678528\n",
      "  training_iteration: 368\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   368</td><td style=\"text-align: right;\">         57183.5</td><td style=\"text-align: right;\">3678528</td><td style=\"text-align: right;\"> 3.88431</td><td style=\"text-align: right;\">               16.62</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           98.8039</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3688524\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-09-29\n",
      "  done: false\n",
      "  episode_len_mean: 93.75700934579439\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.580000000000018\n",
      "  episode_reward_mean: 3.606542056074776\n",
      "  episode_reward_min: -1.5000000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 40221\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2362976432865502\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012622544179343003\n",
      "          policy_loss: -0.06828990484245567\n",
      "          total_loss: 0.07848822119781095\n",
      "          vf_explained_var: 0.9293187856674194\n",
      "          vf_loss: 0.14038536829284878\n",
      "    num_agent_steps_sampled: 3688524\n",
      "    num_agent_steps_trained: 3688524\n",
      "    num_steps_sampled: 3688524\n",
      "    num_steps_trained: 3688524\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.45991379310344\n",
      "    ram_util_percent: 56.537068965517236\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045566598351765894\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03075116228308\n",
      "    mean_inference_ms: 2.8565387919818095\n",
      "    mean_raw_obs_processing_ms: 3.3377273457546335\n",
      "  time_since_restore: 57346.44135212898\n",
      "  time_this_iter_s: 162.89654088020325\n",
      "  time_total_s: 57346.44135212898\n",
      "  timers:\n",
      "    learn_throughput: 933.258\n",
      "    learn_time_ms: 10710.865\n",
      "    load_throughput: 91943.76\n",
      "    load_time_ms: 108.719\n",
      "    sample_throughput: 68.113\n",
      "    sample_time_ms: 146755.128\n",
      "    update_time_ms: 11.194\n",
      "  timestamp: 1636351769\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3688524\n",
      "  training_iteration: 369\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   369</td><td style=\"text-align: right;\">         57346.4</td><td style=\"text-align: right;\">3688524</td><td style=\"text-align: right;\"> 3.60654</td><td style=\"text-align: right;\">               12.58</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">            93.757</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3698520\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-11-39\n",
      "  done: false\n",
      "  episode_len_mean: 98.56862745098039\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.370000000000019\n",
      "  episode_reward_mean: 4.05000000000001\n",
      "  episode_reward_min: -1.5000000000000009\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 40323\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.238207125256204\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012677900531704018\n",
      "          policy_loss: -0.07205587157135845\n",
      "          total_loss: 0.07745514533872533\n",
      "          vf_explained_var: 0.9374738931655884\n",
      "          vf_loss: 0.143011244544043\n",
      "    num_agent_steps_sampled: 3698520\n",
      "    num_agent_steps_trained: 3698520\n",
      "    num_steps_sampled: 3698520\n",
      "    num_steps_trained: 3698520\n",
      "  iterations_since_restore: 370\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.82365591397848\n",
      "    ram_util_percent: 56.51559139784945\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558322971412845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02822954351696\n",
      "    mean_inference_ms: 2.8564974404558043\n",
      "    mean_raw_obs_processing_ms: 3.330299185018383\n",
      "  time_since_restore: 57476.52854967117\n",
      "  time_this_iter_s: 130.08719754219055\n",
      "  time_total_s: 57476.52854967117\n",
      "  timers:\n",
      "    learn_throughput: 933.169\n",
      "    learn_time_ms: 10711.886\n",
      "    load_throughput: 92032.503\n",
      "    load_time_ms: 108.614\n",
      "    sample_throughput: 68.36\n",
      "    sample_time_ms: 146226.632\n",
      "    update_time_ms: 11.889\n",
      "  timestamp: 1636351899\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3698520\n",
      "  training_iteration: 370\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   370</td><td style=\"text-align: right;\">         57476.5</td><td style=\"text-align: right;\">3698520</td><td style=\"text-align: right;\">    4.05</td><td style=\"text-align: right;\">               12.37</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           98.5686</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3708516\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-14-05\n",
      "  done: false\n",
      "  episode_len_mean: 97.38613861386139\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.820000000000016\n",
      "  episode_reward_mean: 3.8142574257425834\n",
      "  episode_reward_min: -1.9000000000000012\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 40424\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2394329064931626\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013888254862634106\n",
      "          policy_loss: -0.0664838989193623\n",
      "          total_loss: 0.12576477407501677\n",
      "          vf_explained_var: 0.919617235660553\n",
      "          vf_loss: 0.1830038193629211\n",
      "    num_agent_steps_sampled: 3708516\n",
      "    num_agent_steps_trained: 3708516\n",
      "    num_steps_sampled: 3708516\n",
      "    num_steps_trained: 3708516\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.12125603864733\n",
      "    ram_util_percent: 56.58840579710143\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045604799992451116\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02229747462401\n",
      "    mean_inference_ms: 2.8566237172668156\n",
      "    mean_raw_obs_processing_ms: 3.3327338303621064\n",
      "  time_since_restore: 57621.7612080574\n",
      "  time_this_iter_s: 145.23265838623047\n",
      "  time_total_s: 57621.7612080574\n",
      "  timers:\n",
      "    learn_throughput: 932.733\n",
      "    learn_time_ms: 10716.895\n",
      "    load_throughput: 91872.217\n",
      "    load_time_ms: 108.803\n",
      "    sample_throughput: 68.606\n",
      "    sample_time_ms: 145702.423\n",
      "    update_time_ms: 12.17\n",
      "  timestamp: 1636352045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3708516\n",
      "  training_iteration: 371\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   371</td><td style=\"text-align: right;\">         57621.8</td><td style=\"text-align: right;\">3708516</td><td style=\"text-align: right;\"> 3.81426</td><td style=\"text-align: right;\">               10.82</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           97.3861</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3718512\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-16-17\n",
      "  done: false\n",
      "  episode_len_mean: 97.9126213592233\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.450000000000015\n",
      "  episode_reward_mean: 3.824271844660204\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 40527\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.247414851392436\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013623647688335886\n",
      "          policy_loss: -0.06997730423752059\n",
      "          total_loss: 0.08947391278850726\n",
      "          vf_explained_var: 0.9304954409599304\n",
      "          vf_loss: 0.150888991354304\n",
      "    num_agent_steps_sampled: 3718512\n",
      "    num_agent_steps_trained: 3718512\n",
      "    num_steps_sampled: 3718512\n",
      "    num_steps_trained: 3718512\n",
      "  iterations_since_restore: 372\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96702127659576\n",
      "    ram_util_percent: 56.63244680851063\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045601110595719634\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.019126354302415\n",
      "    mean_inference_ms: 2.8567852044806314\n",
      "    mean_raw_obs_processing_ms: 3.3258263271954442\n",
      "  time_since_restore: 57753.900993824005\n",
      "  time_this_iter_s: 132.13978576660156\n",
      "  time_total_s: 57753.900993824005\n",
      "  timers:\n",
      "    learn_throughput: 932.602\n",
      "    learn_time_ms: 10718.396\n",
      "    load_throughput: 91816.566\n",
      "    load_time_ms: 108.869\n",
      "    sample_throughput: 70.213\n",
      "    sample_time_ms: 142366.876\n",
      "    update_time_ms: 11.262\n",
      "  timestamp: 1636352177\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3718512\n",
      "  training_iteration: 372\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   372</td><td style=\"text-align: right;\">         57753.9</td><td style=\"text-align: right;\">3718512</td><td style=\"text-align: right;\"> 3.82427</td><td style=\"text-align: right;\">               12.45</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           97.9126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3728508\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-18-41\n",
      "  done: false\n",
      "  episode_len_mean: 96.81553398058253\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.470000000000017\n",
      "  episode_reward_mean: 3.763203883495155\n",
      "  episode_reward_min: -1.4100000000000006\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 40630\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2489467230617493\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013078006388281948\n",
      "          policy_loss: -0.0702554737830646\n",
      "          total_loss: 0.09771888824418569\n",
      "          vf_explained_var: 0.893979012966156\n",
      "          vf_loss: 0.16067049610945913\n",
      "    num_agent_steps_sampled: 3728508\n",
      "    num_agent_steps_trained: 3728508\n",
      "    num_steps_sampled: 3728508\n",
      "    num_steps_trained: 3728508\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.55242718446604\n",
      "    ram_util_percent: 56.605825242718446\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558447894057714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01324518418933\n",
      "    mean_inference_ms: 2.856870920862943\n",
      "    mean_raw_obs_processing_ms: 3.3234632154060963\n",
      "  time_since_restore: 57897.96369552612\n",
      "  time_this_iter_s: 144.06270170211792\n",
      "  time_total_s: 57897.96369552612\n",
      "  timers:\n",
      "    learn_throughput: 932.25\n",
      "    learn_time_ms: 10722.444\n",
      "    load_throughput: 91634.013\n",
      "    load_time_ms: 109.086\n",
      "    sample_throughput: 70.626\n",
      "    sample_time_ms: 141534.364\n",
      "    update_time_ms: 11.459\n",
      "  timestamp: 1636352321\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3728508\n",
      "  training_iteration: 373\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   373</td><td style=\"text-align: right;\">           57898</td><td style=\"text-align: right;\">3728508</td><td style=\"text-align: right;\">  3.7632</td><td style=\"text-align: right;\">               10.47</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           96.8155</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3738504\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-21-19\n",
      "  done: false\n",
      "  episode_len_mean: 94.05660377358491\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.000000000000014\n",
      "  episode_reward_mean: 3.7894339622641606\n",
      "  episode_reward_min: -0.9400000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 40736\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2324062679567906\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012721285991649428\n",
      "          policy_loss: -0.07082268186072763\n",
      "          total_loss: 0.08105720846165512\n",
      "          vf_explained_var: 0.934346616268158\n",
      "          vf_loss: 0.14522327163025864\n",
      "    num_agent_steps_sampled: 3738504\n",
      "    num_agent_steps_trained: 3738504\n",
      "    num_steps_sampled: 3738504\n",
      "    num_steps_trained: 3738504\n",
      "  iterations_since_restore: 374\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.60355555555557\n",
      "    ram_util_percent: 56.528\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045585344819316885\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00811466430735\n",
      "    mean_inference_ms: 2.8564945253218283\n",
      "    mean_raw_obs_processing_ms: 3.3301041881199973\n",
      "  time_since_restore: 58055.75740170479\n",
      "  time_this_iter_s: 157.79370617866516\n",
      "  time_total_s: 58055.75740170479\n",
      "  timers:\n",
      "    learn_throughput: 932.523\n",
      "    learn_time_ms: 10719.307\n",
      "    load_throughput: 91413.541\n",
      "    load_time_ms: 109.349\n",
      "    sample_throughput: 71.688\n",
      "    sample_time_ms: 139438.45\n",
      "    update_time_ms: 10.892\n",
      "  timestamp: 1636352479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3738504\n",
      "  training_iteration: 374\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   374</td><td style=\"text-align: right;\">         58055.8</td><td style=\"text-align: right;\">3738504</td><td style=\"text-align: right;\"> 3.78943</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">               -0.94</td><td style=\"text-align: right;\">           94.0566</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3748500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-23-46\n",
      "  done: false\n",
      "  episode_len_mean: 96.625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.16000000000001\n",
      "  episode_reward_mean: 3.7062500000000105\n",
      "  episode_reward_min: -1.4800000000000004\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 40840\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2564092515880225\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012565801188769788\n",
      "          policy_loss: -0.06968104060197998\n",
      "          total_loss: 0.07381220032166466\n",
      "          vf_explained_var: 0.9363589882850647\n",
      "          vf_loss: 0.13743086681725122\n",
      "    num_agent_steps_sampled: 3748500\n",
      "    num_agent_steps_trained: 3748500\n",
      "    num_steps_sampled: 3748500\n",
      "    num_steps_trained: 3748500\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.70142180094787\n",
      "    ram_util_percent: 56.494312796208526\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557218779923826\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00436704996358\n",
      "    mean_inference_ms: 2.856446171661178\n",
      "    mean_raw_obs_processing_ms: 3.3277052334527806\n",
      "  time_since_restore: 58203.32942509651\n",
      "  time_this_iter_s: 147.57202339172363\n",
      "  time_total_s: 58203.32942509651\n",
      "  timers:\n",
      "    learn_throughput: 932.91\n",
      "    learn_time_ms: 10714.865\n",
      "    load_throughput: 91272.049\n",
      "    load_time_ms: 109.519\n",
      "    sample_throughput: 72.942\n",
      "    sample_time_ms: 137040.815\n",
      "    update_time_ms: 11.22\n",
      "  timestamp: 1636352626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3748500\n",
      "  training_iteration: 375\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   375</td><td style=\"text-align: right;\">         58203.3</td><td style=\"text-align: right;\">3748500</td><td style=\"text-align: right;\"> 3.70625</td><td style=\"text-align: right;\">               11.16</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">            96.625</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3758496\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-26-03\n",
      "  done: false\n",
      "  episode_len_mean: 96.17307692307692\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.590000000000016\n",
      "  episode_reward_mean: 3.7372115384615485\n",
      "  episode_reward_min: -1.850000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 40944\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2583661501224226\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013789447921124715\n",
      "          policy_loss: -0.06912503890438466\n",
      "          total_loss: 0.08712639709950512\n",
      "          vf_explained_var: 0.930955171585083\n",
      "          vf_loss: 0.1474210114703856\n",
      "    num_agent_steps_sampled: 3758496\n",
      "    num_agent_steps_trained: 3758496\n",
      "    num_steps_sampled: 3758496\n",
      "    num_steps_trained: 3758496\n",
      "  iterations_since_restore: 376\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.98666666666668\n",
      "    ram_util_percent: 56.64974358974357\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045580882425330024\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00630361501532\n",
      "    mean_inference_ms: 2.856655994076228\n",
      "    mean_raw_obs_processing_ms: 3.321023619193374\n",
      "  time_since_restore: 58340.176491737366\n",
      "  time_this_iter_s: 136.84706664085388\n",
      "  time_total_s: 58340.176491737366\n",
      "  timers:\n",
      "    learn_throughput: 932.91\n",
      "    learn_time_ms: 10714.856\n",
      "    load_throughput: 91242.711\n",
      "    load_time_ms: 109.554\n",
      "    sample_throughput: 75.312\n",
      "    sample_time_ms: 132728.632\n",
      "    update_time_ms: 12.046\n",
      "  timestamp: 1636352763\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3758496\n",
      "  training_iteration: 376\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   376</td><td style=\"text-align: right;\">         58340.2</td><td style=\"text-align: right;\">3758496</td><td style=\"text-align: right;\"> 3.73721</td><td style=\"text-align: right;\">               10.59</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           96.1731</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3768492\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-28-21\n",
      "  done: false\n",
      "  episode_len_mean: 95.54285714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.920000000000016\n",
      "  episode_reward_mean: 4.296952380952391\n",
      "  episode_reward_min: -1.6900000000000008\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 41049\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2538351578590197\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01513491722292738\n",
      "          policy_loss: -0.06709078225092246\n",
      "          total_loss: 0.11566301948653582\n",
      "          vf_explained_var: 0.9343904256820679\n",
      "          vf_loss: 0.1708129190147305\n",
      "    num_agent_steps_sampled: 3768492\n",
      "    num_agent_steps_trained: 3768492\n",
      "    num_steps_sampled: 3768492\n",
      "    num_steps_trained: 3768492\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.27806122448979\n",
      "    ram_util_percent: 56.60459183673469\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558360609394783\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.008730967885334\n",
      "    mean_inference_ms: 2.8564725622157154\n",
      "    mean_raw_obs_processing_ms: 3.3137569780356895\n",
      "  time_since_restore: 58477.79980826378\n",
      "  time_this_iter_s: 137.62331652641296\n",
      "  time_total_s: 58477.79980826378\n",
      "  timers:\n",
      "    learn_throughput: 933.857\n",
      "    learn_time_ms: 10703.993\n",
      "    load_throughput: 91313.237\n",
      "    load_time_ms: 109.469\n",
      "    sample_throughput: 75.898\n",
      "    sample_time_ms: 131702.883\n",
      "    update_time_ms: 12.587\n",
      "  timestamp: 1636352901\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3768492\n",
      "  training_iteration: 377\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   377</td><td style=\"text-align: right;\">         58477.8</td><td style=\"text-align: right;\">3768492</td><td style=\"text-align: right;\"> 4.29695</td><td style=\"text-align: right;\">               12.92</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           95.5429</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3778488\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-31-26\n",
      "  done: false\n",
      "  episode_len_mean: 92.48598130841121\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.97\n",
      "  episode_reward_mean: 4.012803738317767\n",
      "  episode_reward_min: -2.559999999999998\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 41156\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2337244692011775\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013768713760788283\n",
      "          policy_loss: -0.06714112068502567\n",
      "          total_loss: 0.08787266410982762\n",
      "          vf_explained_var: 0.9472403526306152\n",
      "          vf_loss: 0.14598417822112386\n",
      "    num_agent_steps_sampled: 3778488\n",
      "    num_agent_steps_trained: 3778488\n",
      "    num_steps_sampled: 3778488\n",
      "    num_steps_trained: 3778488\n",
      "  iterations_since_restore: 378\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.54528301886792\n",
      "    ram_util_percent: 56.49773584905661\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045608811731026565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00101210807025\n",
      "    mean_inference_ms: 2.8565733689906776\n",
      "    mean_raw_obs_processing_ms: 3.338625721117077\n",
      "  time_since_restore: 58663.07739806175\n",
      "  time_this_iter_s: 185.27758979797363\n",
      "  time_total_s: 58663.07739806175\n",
      "  timers:\n",
      "    learn_throughput: 933.847\n",
      "    learn_time_ms: 10704.107\n",
      "    load_throughput: 91474.591\n",
      "    load_time_ms: 109.276\n",
      "    sample_throughput: 72.904\n",
      "    sample_time_ms: 137111.001\n",
      "    update_time_ms: 13.08\n",
      "  timestamp: 1636353086\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3778488\n",
      "  training_iteration: 378\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   378</td><td style=\"text-align: right;\">         58663.1</td><td style=\"text-align: right;\">3778488</td><td style=\"text-align: right;\">  4.0128</td><td style=\"text-align: right;\">               18.97</td><td style=\"text-align: right;\">               -2.56</td><td style=\"text-align: right;\">            92.486</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3788484\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-33-55\n",
      "  done: false\n",
      "  episode_len_mean: 97.01941747572816\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.830000000000016\n",
      "  episode_reward_mean: 3.3467961165048634\n",
      "  episode_reward_min: -1.3400000000000007\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 41259\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.256286431173993\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012408910666304415\n",
      "          policy_loss: -0.07150985047889825\n",
      "          total_loss: 0.04905219681115232\n",
      "          vf_explained_var: 0.9375060796737671\n",
      "          vf_loss: 0.11485586146959383\n",
      "    num_agent_steps_sampled: 3788484\n",
      "    num_agent_steps_trained: 3788484\n",
      "    num_steps_sampled: 3788484\n",
      "    num_steps_trained: 3788484\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.06886792452829\n",
      "    ram_util_percent: 56.63537735849056\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558331799058725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99523466861308\n",
      "    mean_inference_ms: 2.856506014787226\n",
      "    mean_raw_obs_processing_ms: 3.3375709634636563\n",
      "  time_since_restore: 58811.97056221962\n",
      "  time_this_iter_s: 148.89316415786743\n",
      "  time_total_s: 58811.97056221962\n",
      "  timers:\n",
      "    learn_throughput: 933.785\n",
      "    learn_time_ms: 10704.814\n",
      "    load_throughput: 91517.121\n",
      "    load_time_ms: 109.225\n",
      "    sample_throughput: 73.657\n",
      "    sample_time_ms: 135710.943\n",
      "    update_time_ms: 12.31\n",
      "  timestamp: 1636353235\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3788484\n",
      "  training_iteration: 379\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   379</td><td style=\"text-align: right;\">           58812</td><td style=\"text-align: right;\">3788484</td><td style=\"text-align: right;\">  3.3468</td><td style=\"text-align: right;\">               10.83</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           97.0194</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3798480\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-36-39\n",
      "  done: false\n",
      "  episode_len_mean: 95.47169811320755\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.810000000000015\n",
      "  episode_reward_mean: 4.195849056603784\n",
      "  episode_reward_min: -1.4000000000000006\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 41365\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.250670980795836\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013094687487013269\n",
      "          policy_loss: -0.06866807002956286\n",
      "          total_loss: 0.08699897091167096\n",
      "          vf_explained_var: 0.9219944477081299\n",
      "          vf_loss: 0.14834241415891383\n",
      "    num_agent_steps_sampled: 3798480\n",
      "    num_agent_steps_trained: 3798480\n",
      "    num_steps_sampled: 3798480\n",
      "    num_steps_trained: 3798480\n",
      "  iterations_since_restore: 380\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.9974358974359\n",
      "    ram_util_percent: 56.61068376068377\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045597358578130374\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99052009984692\n",
      "    mean_inference_ms: 2.8563396575400883\n",
      "    mean_raw_obs_processing_ms: 3.3460140491089057\n",
      "  time_since_restore: 58975.986701250076\n",
      "  time_this_iter_s: 164.01613903045654\n",
      "  time_total_s: 58975.986701250076\n",
      "  timers:\n",
      "    learn_throughput: 932.754\n",
      "    learn_time_ms: 10716.654\n",
      "    load_throughput: 91264.856\n",
      "    load_time_ms: 109.527\n",
      "    sample_throughput: 71.866\n",
      "    sample_time_ms: 139092.551\n",
      "    update_time_ms: 11.567\n",
      "  timestamp: 1636353399\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3798480\n",
      "  training_iteration: 380\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   380</td><td style=\"text-align: right;\">           58976</td><td style=\"text-align: right;\">3798480</td><td style=\"text-align: right;\"> 4.19585</td><td style=\"text-align: right;\">               12.81</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           95.4717</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3808476\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-39-22\n",
      "  done: false\n",
      "  episode_len_mean: 95.82692307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.640000000000017\n",
      "  episode_reward_mean: 3.6253846153846245\n",
      "  episode_reward_min: -1.9900000000000009\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 41469\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.227399496543102\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012922092405845879\n",
      "          policy_loss: -0.07036707929343494\n",
      "          total_loss: 0.07047558340490756\n",
      "          vf_explained_var: 0.932105541229248\n",
      "          vf_loss: 0.13367851593523708\n",
      "    num_agent_steps_sampled: 3808476\n",
      "    num_agent_steps_trained: 3808476\n",
      "    num_steps_sampled: 3808476\n",
      "    num_steps_trained: 3808476\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.67038626609443\n",
      "    ram_util_percent: 56.66523605150214\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557309562082837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98510149862016\n",
      "    mean_inference_ms: 2.856144331086365\n",
      "    mean_raw_obs_processing_ms: 3.3478196184686198\n",
      "  time_since_restore: 59139.04401254654\n",
      "  time_this_iter_s: 163.057311296463\n",
      "  time_total_s: 59139.04401254654\n",
      "  timers:\n",
      "    learn_throughput: 932.959\n",
      "    learn_time_ms: 10714.297\n",
      "    load_throughput: 91299.457\n",
      "    load_time_ms: 109.486\n",
      "    sample_throughput: 70.955\n",
      "    sample_time_ms: 140877.304\n",
      "    update_time_ms: 12.233\n",
      "  timestamp: 1636353562\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3808476\n",
      "  training_iteration: 381\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   381</td><td style=\"text-align: right;\">           59139</td><td style=\"text-align: right;\">3808476</td><td style=\"text-align: right;\"> 3.62538</td><td style=\"text-align: right;\">               12.64</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           95.8269</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3818472\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-41-47\n",
      "  done: false\n",
      "  episode_len_mean: 94.8952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.800000000000011\n",
      "  episode_reward_mean: 4.115047619047628\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 41574\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.211767719545935\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014122279062020753\n",
      "          policy_loss: -0.06946911651832172\n",
      "          total_loss: 0.09791905064549711\n",
      "          vf_explained_var: 0.939019501209259\n",
      "          vf_loss: 0.15733352485630248\n",
      "    num_agent_steps_sampled: 3818472\n",
      "    num_agent_steps_trained: 3818472\n",
      "    num_steps_sampled: 3818472\n",
      "    num_steps_trained: 3818472\n",
      "  iterations_since_restore: 382\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.57536231884058\n",
      "    ram_util_percent: 56.65507246376811\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560025173039735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98329192414557\n",
      "    mean_inference_ms: 2.8561763199236454\n",
      "    mean_raw_obs_processing_ms: 3.3453527297268697\n",
      "  time_since_restore: 59283.992020606995\n",
      "  time_this_iter_s: 144.94800806045532\n",
      "  time_total_s: 59283.992020606995\n",
      "  timers:\n",
      "    learn_throughput: 933.174\n",
      "    learn_time_ms: 10711.824\n",
      "    load_throughput: 91193.115\n",
      "    load_time_ms: 109.614\n",
      "    sample_throughput: 70.315\n",
      "    sample_time_ms: 142160.257\n",
      "    update_time_ms: 12.278\n",
      "  timestamp: 1636353707\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3818472\n",
      "  training_iteration: 382\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   382</td><td style=\"text-align: right;\">           59284</td><td style=\"text-align: right;\">3818472</td><td style=\"text-align: right;\"> 4.11505</td><td style=\"text-align: right;\">                14.8</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           94.8952</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3828468\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-44-51\n",
      "  done: false\n",
      "  episode_len_mean: 93.4766355140187\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.490000000000013\n",
      "  episode_reward_mean: 3.8120560747663648\n",
      "  episode_reward_min: -1.880000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 41681\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.219113216848455\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01424862148572979\n",
      "          policy_loss: -0.064075380938653\n",
      "          total_loss: 0.12426802726207763\n",
      "          vf_explained_var: 0.9313440918922424\n",
      "          vf_loss: 0.17807439875462625\n",
      "    num_agent_steps_sampled: 3828468\n",
      "    num_agent_steps_trained: 3828468\n",
      "    num_steps_sampled: 3828468\n",
      "    num_steps_trained: 3828468\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.26374045801526\n",
      "    ram_util_percent: 56.73664122137404\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554841101576042\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97889411543458\n",
      "    mean_inference_ms: 2.8563654205823648\n",
      "    mean_raw_obs_processing_ms: 3.3534911588210305\n",
      "  time_since_restore: 59467.8763897419\n",
      "  time_this_iter_s: 183.88436913490295\n",
      "  time_total_s: 59467.8763897419\n",
      "  timers:\n",
      "    learn_throughput: 933.603\n",
      "    learn_time_ms: 10706.909\n",
      "    load_throughput: 90985.794\n",
      "    load_time_ms: 109.863\n",
      "    sample_throughput: 68.397\n",
      "    sample_time_ms: 146146.622\n",
      "    update_time_ms: 12.578\n",
      "  timestamp: 1636353891\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3828468\n",
      "  training_iteration: 383\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   383</td><td style=\"text-align: right;\">         59467.9</td><td style=\"text-align: right;\">3828468</td><td style=\"text-align: right;\"> 3.81206</td><td style=\"text-align: right;\">               12.49</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           93.4766</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3838464\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-47-24\n",
      "  done: false\n",
      "  episode_len_mean: 97.22330097087378\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.05000000000001\n",
      "  episode_reward_mean: 3.665825242718458\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 41784\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.248081186082628\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012927719041634495\n",
      "          policy_loss: -0.07048216066920222\n",
      "          total_loss: 0.08881303899738396\n",
      "          vf_explained_var: 0.9237533211708069\n",
      "          vf_loss: 0.15232505227924667\n",
      "    num_agent_steps_sampled: 3838464\n",
      "    num_agent_steps_trained: 3838464\n",
      "    num_steps_sampled: 3838464\n",
      "    num_steps_trained: 3838464\n",
      "  iterations_since_restore: 384\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.11330275229356\n",
      "    ram_util_percent: 56.58348623853211\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559199549497539\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98039372947186\n",
      "    mean_inference_ms: 2.856309917536194\n",
      "    mean_raw_obs_processing_ms: 3.35009746979463\n",
      "  time_since_restore: 59620.330201625824\n",
      "  time_this_iter_s: 152.4538118839264\n",
      "  time_total_s: 59620.330201625824\n",
      "  timers:\n",
      "    learn_throughput: 933.746\n",
      "    learn_time_ms: 10705.261\n",
      "    load_throughput: 90749.153\n",
      "    load_time_ms: 110.15\n",
      "    sample_throughput: 68.646\n",
      "    sample_time_ms: 145615.745\n",
      "    update_time_ms: 12.656\n",
      "  timestamp: 1636354044\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3838464\n",
      "  training_iteration: 384\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   384</td><td style=\"text-align: right;\">         59620.3</td><td style=\"text-align: right;\">3838464</td><td style=\"text-align: right;\"> 3.66583</td><td style=\"text-align: right;\">                9.05</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           97.2233</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3848460\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-50-18\n",
      "  done: false\n",
      "  episode_len_mean: 94.90384615384616\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.920000000000009\n",
      "  episode_reward_mean: 3.9915384615384712\n",
      "  episode_reward_min: -1.4300000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 41888\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2160945737463797\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012994820926729385\n",
      "          policy_loss: -0.06954847783900989\n",
      "          total_loss: 0.07918810572984636\n",
      "          vf_explained_var: 0.9276885986328125\n",
      "          vf_loss: 0.1412937019044199\n",
      "    num_agent_steps_sampled: 3848460\n",
      "    num_agent_steps_trained: 3848460\n",
      "    num_steps_sampled: 3848460\n",
      "    num_steps_trained: 3848460\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1459677419355\n",
      "    ram_util_percent: 56.613306451612914\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455907643915534\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97510291850253\n",
      "    mean_inference_ms: 2.8561351000977746\n",
      "    mean_raw_obs_processing_ms: 3.360087967591465\n",
      "  time_since_restore: 59794.14780497551\n",
      "  time_this_iter_s: 173.81760334968567\n",
      "  time_total_s: 59794.14780497551\n",
      "  timers:\n",
      "    learn_throughput: 933.264\n",
      "    learn_time_ms: 10710.798\n",
      "    load_throughput: 90874.468\n",
      "    load_time_ms: 109.998\n",
      "    sample_throughput: 67.433\n",
      "    sample_time_ms: 148236.078\n",
      "    update_time_ms: 11.526\n",
      "  timestamp: 1636354218\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3848460\n",
      "  training_iteration: 385\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   385</td><td style=\"text-align: right;\">         59794.1</td><td style=\"text-align: right;\">3848460</td><td style=\"text-align: right;\"> 3.99154</td><td style=\"text-align: right;\">               10.92</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           94.9038</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3858456\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-53-21\n",
      "  done: false\n",
      "  episode_len_mean: 96.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.590000000000016\n",
      "  episode_reward_mean: 3.481153846153856\n",
      "  episode_reward_min: -1.500000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 41992\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2657763790880514\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01235143307680307\n",
      "          policy_loss: -0.07325817870023923\n",
      "          total_loss: 0.05797068032189312\n",
      "          vf_explained_var: 0.9346731901168823\n",
      "          vf_loss: 0.12574851361668518\n",
      "    num_agent_steps_sampled: 3858456\n",
      "    num_agent_steps_trained: 3858456\n",
      "    num_steps_sampled: 3858456\n",
      "    num_steps_trained: 3858456\n",
      "  iterations_since_restore: 386\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.95555555555555\n",
      "    ram_util_percent: 56.65670498084292\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559124401894639\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97245147672192\n",
      "    mean_inference_ms: 2.8561152311649183\n",
      "    mean_raw_obs_processing_ms: 3.3672154514823465\n",
      "  time_since_restore: 59977.21145319939\n",
      "  time_this_iter_s: 183.06364822387695\n",
      "  time_total_s: 59977.21145319939\n",
      "  timers:\n",
      "    learn_throughput: 933.633\n",
      "    learn_time_ms: 10706.557\n",
      "    load_throughput: 90568.839\n",
      "    load_time_ms: 110.369\n",
      "    sample_throughput: 65.392\n",
      "    sample_time_ms: 152862.283\n",
      "    update_time_ms: 10.945\n",
      "  timestamp: 1636354401\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3858456\n",
      "  training_iteration: 386\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   386</td><td style=\"text-align: right;\">         59977.2</td><td style=\"text-align: right;\">3858456</td><td style=\"text-align: right;\"> 3.48115</td><td style=\"text-align: right;\">               10.59</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">             96.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3868452\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-55-46\n",
      "  done: false\n",
      "  episode_len_mean: 96.99038461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.980000000000018\n",
      "  episode_reward_mean: 3.7560576923077016\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 42096\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.229100269639594\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014521874604028616\n",
      "          policy_loss: -0.06723871528147123\n",
      "          total_loss: 0.0929638184622949\n",
      "          vf_explained_var: 0.9363389611244202\n",
      "          vf_loss: 0.14941089062227142\n",
      "    num_agent_steps_sampled: 3868452\n",
      "    num_agent_steps_trained: 3868452\n",
      "    num_steps_sampled: 3868452\n",
      "    num_steps_trained: 3868452\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.10531400966185\n",
      "    ram_util_percent: 56.59323671497583\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558526095844592\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96693541795589\n",
      "    mean_inference_ms: 2.8563744821203936\n",
      "    mean_raw_obs_processing_ms: 3.365022906224129\n",
      "  time_since_restore: 60122.34916138649\n",
      "  time_this_iter_s: 145.13770818710327\n",
      "  time_total_s: 60122.34916138649\n",
      "  timers:\n",
      "    learn_throughput: 933.756\n",
      "    learn_time_ms: 10705.148\n",
      "    load_throughput: 90395.886\n",
      "    load_time_ms: 110.58\n",
      "    sample_throughput: 65.071\n",
      "    sample_time_ms: 153616.299\n",
      "    update_time_ms: 9.7\n",
      "  timestamp: 1636354546\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3868452\n",
      "  training_iteration: 387\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   387</td><td style=\"text-align: right;\">         60122.3</td><td style=\"text-align: right;\">3868452</td><td style=\"text-align: right;\"> 3.75606</td><td style=\"text-align: right;\">               10.98</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           96.9904</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3878448\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_06-58-16\n",
      "  done: false\n",
      "  episode_len_mean: 94.40566037735849\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.820000000000014\n",
      "  episode_reward_mean: 3.1568867924528377\n",
      "  episode_reward_min: -2.0399999999999996\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 42202\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2436540733035812\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012928781149853642\n",
      "          policy_loss: -0.06627599454174439\n",
      "          total_loss: 0.08543121557619072\n",
      "          vf_explained_var: 0.9216033220291138\n",
      "          vf_loss: 0.14469037048009217\n",
      "    num_agent_steps_sampled: 3878448\n",
      "    num_agent_steps_trained: 3878448\n",
      "    num_steps_sampled: 3878448\n",
      "    num_steps_trained: 3878448\n",
      "  iterations_since_restore: 388\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.18604651162791\n",
      "    ram_util_percent: 56.796744186046524\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04561754017928448\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96661361441493\n",
      "    mean_inference_ms: 2.856504776565978\n",
      "    mean_raw_obs_processing_ms: 3.362843878200583\n",
      "  time_since_restore: 60272.85259819031\n",
      "  time_this_iter_s: 150.50343680381775\n",
      "  time_total_s: 60272.85259819031\n",
      "  timers:\n",
      "    learn_throughput: 933.54\n",
      "    learn_time_ms: 10707.627\n",
      "    load_throughput: 90353.983\n",
      "    load_time_ms: 110.632\n",
      "    sample_throughput: 66.579\n",
      "    sample_time_ms: 150136.731\n",
      "    update_time_ms: 9.744\n",
      "  timestamp: 1636354696\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3878448\n",
      "  training_iteration: 388\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   388</td><td style=\"text-align: right;\">         60272.9</td><td style=\"text-align: right;\">3878448</td><td style=\"text-align: right;\"> 3.15689</td><td style=\"text-align: right;\">               10.82</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           94.4057</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3888444\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-00-46\n",
      "  done: false\n",
      "  episode_len_mean: 94.13333333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.860000000000015\n",
      "  episode_reward_mean: 3.6407619047619137\n",
      "  episode_reward_min: -1.3700000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 42307\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.212661032187633\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01379081725615208\n",
      "          policy_loss: -0.06785711103843318\n",
      "          total_loss: 0.0983018597910324\n",
      "          vf_explained_var: 0.923886775970459\n",
      "          vf_loss: 0.15686837566745843\n",
      "    num_agent_steps_sampled: 3888444\n",
      "    num_agent_steps_trained: 3888444\n",
      "    num_steps_sampled: 3888444\n",
      "    num_steps_trained: 3888444\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.97183098591549\n",
      "    ram_util_percent: 56.80469483568075\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557578170775444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96463146462646\n",
      "    mean_inference_ms: 2.856229905406545\n",
      "    mean_raw_obs_processing_ms: 3.359994250453715\n",
      "  time_since_restore: 60422.07158470154\n",
      "  time_this_iter_s: 149.21898651123047\n",
      "  time_total_s: 60422.07158470154\n",
      "  timers:\n",
      "    learn_throughput: 933.881\n",
      "    learn_time_ms: 10703.715\n",
      "    load_throughput: 90337.084\n",
      "    load_time_ms: 110.652\n",
      "    sample_throughput: 66.563\n",
      "    sample_time_ms: 150173.277\n",
      "    update_time_ms: 9.576\n",
      "  timestamp: 1636354846\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3888444\n",
      "  training_iteration: 389\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   389</td><td style=\"text-align: right;\">         60422.1</td><td style=\"text-align: right;\">3888444</td><td style=\"text-align: right;\"> 3.64076</td><td style=\"text-align: right;\">               11.86</td><td style=\"text-align: right;\">               -1.37</td><td style=\"text-align: right;\">           94.1333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3898440\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-03-49\n",
      "  done: false\n",
      "  episode_len_mean: 93.55140186915888\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.480000000000015\n",
      "  episode_reward_mean: 4.397009345794402\n",
      "  episode_reward_min: -1.9500000000000013\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 42414\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.196883244901641\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01430998918907244\n",
      "          policy_loss: -0.06368057767613831\n",
      "          total_loss: 0.11762873544954719\n",
      "          vf_explained_var: 0.9359781742095947\n",
      "          vf_loss: 0.17067819939544185\n",
      "    num_agent_steps_sampled: 3898440\n",
      "    num_agent_steps_trained: 3898440\n",
      "    num_steps_sampled: 3898440\n",
      "    num_steps_trained: 3898440\n",
      "  iterations_since_restore: 390\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.32413793103447\n",
      "    ram_util_percent: 56.61877394636015\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559212221718912\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95716232489877\n",
      "    mean_inference_ms: 2.85626765613548\n",
      "    mean_raw_obs_processing_ms: 3.3693095506036945\n",
      "  time_since_restore: 60605.3085167408\n",
      "  time_this_iter_s: 183.23693203926086\n",
      "  time_total_s: 60605.3085167408\n",
      "  timers:\n",
      "    learn_throughput: 934.895\n",
      "    learn_time_ms: 10692.11\n",
      "    load_throughput: 90563.205\n",
      "    load_time_ms: 110.376\n",
      "    sample_throughput: 65.717\n",
      "    sample_time_ms: 152107.488\n",
      "    update_time_ms: 9.603\n",
      "  timestamp: 1636355029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3898440\n",
      "  training_iteration: 390\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   390</td><td style=\"text-align: right;\">         60605.3</td><td style=\"text-align: right;\">3898440</td><td style=\"text-align: right;\"> 4.39701</td><td style=\"text-align: right;\">               14.48</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           93.5514</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3908436\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-06-17\n",
      "  done: false\n",
      "  episode_len_mean: 95.01886792452831\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.730000000000013\n",
      "  episode_reward_mean: 3.6762264150943476\n",
      "  episode_reward_min: -1.9699999999999993\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 42520\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2476426330387085\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013949306849474182\n",
      "          policy_loss: -0.07045767569484619\n",
      "          total_loss: 0.11838753355953556\n",
      "          vf_explained_var: 0.9221041202545166\n",
      "          vf_loss: 0.17954337022816524\n",
      "    num_agent_steps_sampled: 3908436\n",
      "    num_agent_steps_trained: 3908436\n",
      "    num_steps_sampled: 3908436\n",
      "    num_steps_trained: 3908436\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.4829383886256\n",
      "    ram_util_percent: 56.56919431279621\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555252836964055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95327613888494\n",
      "    mean_inference_ms: 2.856317675659566\n",
      "    mean_raw_obs_processing_ms: 3.3672752056353588\n",
      "  time_since_restore: 60753.11707901955\n",
      "  time_this_iter_s: 147.80856227874756\n",
      "  time_total_s: 60753.11707901955\n",
      "  timers:\n",
      "    learn_throughput: 934.546\n",
      "    learn_time_ms: 10696.108\n",
      "    load_throughput: 90621.067\n",
      "    load_time_ms: 110.305\n",
      "    sample_throughput: 66.384\n",
      "    sample_time_ms: 150578.591\n",
      "    update_time_ms: 9.525\n",
      "  timestamp: 1636355177\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3908436\n",
      "  training_iteration: 391\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   391</td><td style=\"text-align: right;\">         60753.1</td><td style=\"text-align: right;\">3908436</td><td style=\"text-align: right;\"> 3.67623</td><td style=\"text-align: right;\">               12.73</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           95.0189</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3918432\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-08-47\n",
      "  done: false\n",
      "  episode_len_mean: 94.23584905660377\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.820000000000011\n",
      "  episode_reward_mean: 3.619339622641518\n",
      "  episode_reward_min: -1.9000000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 42626\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.23437088493608\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013125569054304705\n",
      "          policy_loss: -0.06602280397827809\n",
      "          total_loss: 0.11197909401236182\n",
      "          vf_explained_var: 0.9152719378471375\n",
      "          vf_loss: 0.17044391862602315\n",
      "    num_agent_steps_sampled: 3918432\n",
      "    num_agent_steps_trained: 3918432\n",
      "    num_steps_sampled: 3918432\n",
      "    num_steps_trained: 3918432\n",
      "  iterations_since_restore: 392\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.42790697674417\n",
      "    ram_util_percent: 56.602790697674415\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559091457204238\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95378420711672\n",
      "    mean_inference_ms: 2.8563754026494856\n",
      "    mean_raw_obs_processing_ms: 3.3645935796205486\n",
      "  time_since_restore: 60903.641924619675\n",
      "  time_this_iter_s: 150.52484560012817\n",
      "  time_total_s: 60903.641924619675\n",
      "  timers:\n",
      "    learn_throughput: 934.399\n",
      "    learn_time_ms: 10697.79\n",
      "    load_throughput: 90662.435\n",
      "    load_time_ms: 110.255\n",
      "    sample_throughput: 66.14\n",
      "    sample_time_ms: 151133.745\n",
      "    update_time_ms: 10.1\n",
      "  timestamp: 1636355327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3918432\n",
      "  training_iteration: 392\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   392</td><td style=\"text-align: right;\">         60903.6</td><td style=\"text-align: right;\">3918432</td><td style=\"text-align: right;\"> 3.61934</td><td style=\"text-align: right;\">               10.82</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           94.2358</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3928428\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-11-19\n",
      "  done: false\n",
      "  episode_len_mean: 93.93396226415095\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.94000000000001\n",
      "  episode_reward_mean: 3.925471698113217\n",
      "  episode_reward_min: -1.2600000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 42732\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2283788717710054\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01415129706827545\n",
      "          policy_loss: -0.06742266878390159\n",
      "          total_loss: 0.1145417887940366\n",
      "          vf_explained_var: 0.9380373954772949\n",
      "          vf_loss: 0.1720098214956303\n",
      "    num_agent_steps_sampled: 3928428\n",
      "    num_agent_steps_trained: 3928428\n",
      "    num_steps_sampled: 3928428\n",
      "    num_steps_trained: 3928428\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.24814814814815\n",
      "    ram_util_percent: 56.61944444444444\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045587480800348495\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.951967550665266\n",
      "    mean_inference_ms: 2.856231612222046\n",
      "    mean_raw_obs_processing_ms: 3.3665322772068818\n",
      "  time_since_restore: 61055.01237344742\n",
      "  time_this_iter_s: 151.37044882774353\n",
      "  time_total_s: 61055.01237344742\n",
      "  timers:\n",
      "    learn_throughput: 934.257\n",
      "    learn_time_ms: 10699.416\n",
      "    load_throughput: 90901.855\n",
      "    load_time_ms: 109.965\n",
      "    sample_throughput: 67.595\n",
      "    sample_time_ms: 147880.815\n",
      "    update_time_ms: 10.244\n",
      "  timestamp: 1636355479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3928428\n",
      "  training_iteration: 393\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   393</td><td style=\"text-align: right;\">           61055</td><td style=\"text-align: right;\">3928428</td><td style=\"text-align: right;\"> 3.92547</td><td style=\"text-align: right;\">               10.94</td><td style=\"text-align: right;\">               -1.26</td><td style=\"text-align: right;\">            93.934</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3938424\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-13-38\n",
      "  done: false\n",
      "  episode_len_mean: 93.38888888888889\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.820000000000014\n",
      "  episode_reward_mean: 3.101759259259267\n",
      "  episode_reward_min: -1.6100000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 42840\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2534369236383682\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011992995901379202\n",
      "          policy_loss: -0.0708500837477354\n",
      "          total_loss: 0.05730162461917115\n",
      "          vf_explained_var: 0.9329063892364502\n",
      "          vf_loss: 0.12336453301115678\n",
      "    num_agent_steps_sampled: 3938424\n",
      "    num_agent_steps_trained: 3938424\n",
      "    num_steps_sampled: 3938424\n",
      "    num_steps_trained: 3938424\n",
      "  iterations_since_restore: 394\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11212121212121\n",
      "    ram_util_percent: 56.6090909090909\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560305443850582\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.954195522116294\n",
      "    mean_inference_ms: 2.8563349943108736\n",
      "    mean_raw_obs_processing_ms: 3.359806858847278\n",
      "  time_since_restore: 61193.729410648346\n",
      "  time_this_iter_s: 138.71703720092773\n",
      "  time_total_s: 61193.729410648346\n",
      "  timers:\n",
      "    learn_throughput: 934.175\n",
      "    learn_time_ms: 10700.354\n",
      "    load_throughput: 91307.251\n",
      "    load_time_ms: 109.477\n",
      "    sample_throughput: 68.23\n",
      "    sample_time_ms: 146504.219\n",
      "    update_time_ms: 12.395\n",
      "  timestamp: 1636355618\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3938424\n",
      "  training_iteration: 394\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   394</td><td style=\"text-align: right;\">         61193.7</td><td style=\"text-align: right;\">3938424</td><td style=\"text-align: right;\"> 3.10176</td><td style=\"text-align: right;\">               10.82</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           93.3889</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3948420\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-16-16\n",
      "  done: false\n",
      "  episode_len_mean: 90.06363636363636\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000014\n",
      "  episode_reward_mean: 3.4374545454545538\n",
      "  episode_reward_min: -1.6000000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 42950\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2157852096435353\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013116380780730673\n",
      "          policy_loss: -0.06800684282699457\n",
      "          total_loss: 0.0974797846064863\n",
      "          vf_explained_var: 0.9329434633255005\n",
      "          vf_loss: 0.15776372364539112\n",
      "    num_agent_steps_sampled: 3948420\n",
      "    num_agent_steps_trained: 3948420\n",
      "    num_steps_sampled: 3948420\n",
      "    num_steps_trained: 3948420\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.13938053097345\n",
      "    ram_util_percent: 56.627876106194684\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559633483271845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.9580566868503\n",
      "    mean_inference_ms: 2.8567278298418812\n",
      "    mean_raw_obs_processing_ms: 3.3574617195282372\n",
      "  time_since_restore: 61352.042692661285\n",
      "  time_this_iter_s: 158.31328201293945\n",
      "  time_total_s: 61352.042692661285\n",
      "  timers:\n",
      "    learn_throughput: 934.218\n",
      "    learn_time_ms: 10699.854\n",
      "    load_throughput: 91323.003\n",
      "    load_time_ms: 109.458\n",
      "    sample_throughput: 68.96\n",
      "    sample_time_ms: 144953.4\n",
      "    update_time_ms: 13.137\n",
      "  timestamp: 1636355776\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3948420\n",
      "  training_iteration: 395\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   395</td><td style=\"text-align: right;\">           61352</td><td style=\"text-align: right;\">3948420</td><td style=\"text-align: right;\"> 3.43745</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           90.0636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3958416\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-19-01\n",
      "  done: false\n",
      "  episode_len_mean: 92.03636363636363\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.64000000000001\n",
      "  episode_reward_mean: 4.101636363636373\n",
      "  episode_reward_min: -1.5100000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 43060\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.208857988088559\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014001514407959633\n",
      "          policy_loss: -0.06969778502566946\n",
      "          total_loss: 0.1174898368298498\n",
      "          vf_explained_var: 0.9274449348449707\n",
      "          vf_loss: 0.17737900058890127\n",
      "    num_agent_steps_sampled: 3958416\n",
      "    num_agent_steps_trained: 3958416\n",
      "    num_steps_sampled: 3958416\n",
      "    num_steps_trained: 3958416\n",
      "  iterations_since_restore: 396\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.13744680851063\n",
      "    ram_util_percent: 56.58\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045590566997415094\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95923992107139\n",
      "    mean_inference_ms: 2.8563417018965973\n",
      "    mean_raw_obs_processing_ms: 3.359165926603408\n",
      "  time_since_restore: 61516.73965001106\n",
      "  time_this_iter_s: 164.69695734977722\n",
      "  time_total_s: 61516.73965001106\n",
      "  timers:\n",
      "    learn_throughput: 933.944\n",
      "    learn_time_ms: 10702.997\n",
      "    load_throughput: 91462.019\n",
      "    load_time_ms: 109.291\n",
      "    sample_throughput: 69.847\n",
      "    sample_time_ms: 143112.746\n",
      "    update_time_ms: 13.911\n",
      "  timestamp: 1636355941\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3958416\n",
      "  training_iteration: 396\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   396</td><td style=\"text-align: right;\">         61516.7</td><td style=\"text-align: right;\">3958416</td><td style=\"text-align: right;\"> 4.10164</td><td style=\"text-align: right;\">               12.64</td><td style=\"text-align: right;\">               -1.51</td><td style=\"text-align: right;\">           92.0364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3968412\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-21-32\n",
      "  done: false\n",
      "  episode_len_mean: 93.27102803738318\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.870000000000015\n",
      "  episode_reward_mean: 3.508224299065429\n",
      "  episode_reward_min: -1.5500000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 43167\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.20878486918588\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013215014294412672\n",
      "          policy_loss: -0.06458808361019334\n",
      "          total_loss: 0.1020493204295476\n",
      "          vf_explained_var: 0.9300735592842102\n",
      "          vf_loss: 0.15861979875013105\n",
      "    num_agent_steps_sampled: 3968412\n",
      "    num_agent_steps_trained: 3968412\n",
      "    num_steps_sampled: 3968412\n",
      "    num_steps_trained: 3968412\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.50976744186048\n",
      "    ram_util_percent: 56.683720930232575\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559955163700466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95957818501742\n",
      "    mean_inference_ms: 2.8565341278503595\n",
      "    mean_raw_obs_processing_ms: 3.356791129520332\n",
      "  time_since_restore: 61667.85959601402\n",
      "  time_this_iter_s: 151.1199460029602\n",
      "  time_total_s: 61667.85959601402\n",
      "  timers:\n",
      "    learn_throughput: 934.009\n",
      "    learn_time_ms: 10702.257\n",
      "    load_throughput: 91706.991\n",
      "    load_time_ms: 108.999\n",
      "    sample_throughput: 69.556\n",
      "    sample_time_ms: 143710.892\n",
      "    update_time_ms: 15.037\n",
      "  timestamp: 1636356092\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3968412\n",
      "  training_iteration: 397\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   397</td><td style=\"text-align: right;\">         61667.9</td><td style=\"text-align: right;\">3968412</td><td style=\"text-align: right;\"> 3.50822</td><td style=\"text-align: right;\">               12.87</td><td style=\"text-align: right;\">               -1.55</td><td style=\"text-align: right;\">            93.271</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3978408\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-23-52\n",
      "  done: false\n",
      "  episode_len_mean: 93.0754716981132\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.980000000000013\n",
      "  episode_reward_mean: 3.7286792452830277\n",
      "  episode_reward_min: -1.269999999999993\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 43273\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1982595331648476\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012591814792039423\n",
      "          policy_loss: -0.07132035033761436\n",
      "          total_loss: 0.07406749107007288\n",
      "          vf_explained_var: 0.9333450198173523\n",
      "          vf_loss: 0.13868470801215652\n",
      "    num_agent_steps_sampled: 3978408\n",
      "    num_agent_steps_trained: 3978408\n",
      "    num_steps_sampled: 3978408\n",
      "    num_steps_trained: 3978408\n",
      "  iterations_since_restore: 398\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.31800000000001\n",
      "    ram_util_percent: 56.78800000000001\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560181057787947\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.963303830591684\n",
      "    mean_inference_ms: 2.8566967813726745\n",
      "    mean_raw_obs_processing_ms: 3.350225085476374\n",
      "  time_since_restore: 61807.9159450531\n",
      "  time_this_iter_s: 140.05634903907776\n",
      "  time_total_s: 61807.9159450531\n",
      "  timers:\n",
      "    learn_throughput: 934.103\n",
      "    learn_time_ms: 10701.173\n",
      "    load_throughput: 91510.409\n",
      "    load_time_ms: 109.233\n",
      "    sample_throughput: 70.065\n",
      "    sample_time_ms: 142667.421\n",
      "    update_time_ms: 14.815\n",
      "  timestamp: 1636356232\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3978408\n",
      "  training_iteration: 398\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   398</td><td style=\"text-align: right;\">         61807.9</td><td style=\"text-align: right;\">3978408</td><td style=\"text-align: right;\"> 3.72868</td><td style=\"text-align: right;\">               12.98</td><td style=\"text-align: right;\">               -1.27</td><td style=\"text-align: right;\">           93.0755</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3988404\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-26-31\n",
      "  done: false\n",
      "  episode_len_mean: 90.85454545454546\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.950000000000014\n",
      "  episode_reward_mean: 4.20081818181819\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 43383\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2034991076868824\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014028993280339836\n",
      "          policy_loss: -0.07103951104208191\n",
      "          total_loss: 0.07948943059732262\n",
      "          vf_explained_var: 0.9440323114395142\n",
      "          vf_loss: 0.1406041318264145\n",
      "    num_agent_steps_sampled: 3988404\n",
      "    num_agent_steps_trained: 3988404\n",
      "    num_steps_sampled: 3988404\n",
      "    num_steps_trained: 3988404\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.79515418502203\n",
      "    ram_util_percent: 56.495154185022024\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560162466997252\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96604017816216\n",
      "    mean_inference_ms: 2.85664311440669\n",
      "    mean_raw_obs_processing_ms: 3.35670546077633\n",
      "  time_since_restore: 61967.12404704094\n",
      "  time_this_iter_s: 159.20810198783875\n",
      "  time_total_s: 61967.12404704094\n",
      "  timers:\n",
      "    learn_throughput: 933.851\n",
      "    learn_time_ms: 10704.061\n",
      "    load_throughput: 91536.982\n",
      "    load_time_ms: 109.202\n",
      "    sample_throughput: 69.58\n",
      "    sample_time_ms: 143662.623\n",
      "    update_time_ms: 15.614\n",
      "  timestamp: 1636356391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3988404\n",
      "  training_iteration: 399\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   399</td><td style=\"text-align: right;\">         61967.1</td><td style=\"text-align: right;\">3988404</td><td style=\"text-align: right;\"> 4.20082</td><td style=\"text-align: right;\">               12.95</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           90.8545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 3998400\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-29-18\n",
      "  done: false\n",
      "  episode_len_mean: 90.99090909090908\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.800000000000017\n",
      "  episode_reward_mean: 3.3724545454545547\n",
      "  episode_reward_min: -2.5899999999999985\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 43493\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2218818134731717\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01363299596966418\n",
      "          policy_loss: -0.0664840464758822\n",
      "          total_loss: 0.10241083956013124\n",
      "          vf_explained_var: 0.9242337942123413\n",
      "          vf_loss: 0.16005603519196693\n",
      "    num_agent_steps_sampled: 3998400\n",
      "    num_agent_steps_trained: 3998400\n",
      "    num_steps_sampled: 3998400\n",
      "    num_steps_trained: 3998400\n",
      "  iterations_since_restore: 400\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.14267782426778\n",
      "    ram_util_percent: 56.68828451882846\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455877253479133\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96604922513915\n",
      "    mean_inference_ms: 2.856700982951798\n",
      "    mean_raw_obs_processing_ms: 3.3586859844879386\n",
      "  time_since_restore: 62134.017914533615\n",
      "  time_this_iter_s: 166.89386749267578\n",
      "  time_total_s: 62134.017914533615\n",
      "  timers:\n",
      "    learn_throughput: 933.526\n",
      "    learn_time_ms: 10707.785\n",
      "    load_throughput: 91558.731\n",
      "    load_time_ms: 109.176\n",
      "    sample_throughput: 70.383\n",
      "    sample_time_ms: 142023.606\n",
      "    update_time_ms: 16.213\n",
      "  timestamp: 1636356558\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3998400\n",
      "  training_iteration: 400\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   400</td><td style=\"text-align: right;\">           62134</td><td style=\"text-align: right;\">3998400</td><td style=\"text-align: right;\"> 3.37245</td><td style=\"text-align: right;\">                10.8</td><td style=\"text-align: right;\">               -2.59</td><td style=\"text-align: right;\">           90.9909</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4008396\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-33-01\n",
      "  done: false\n",
      "  episode_len_mean: 88.78761061946902\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.30000000000001\n",
      "  episode_reward_mean: 3.7380530973451407\n",
      "  episode_reward_min: -1.6000000000000005\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 43606\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1876680590148663\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012291638847195528\n",
      "          policy_loss: -0.06935772543024812\n",
      "          total_loss: 0.06601713622928175\n",
      "          vf_explained_var: 0.9478688836097717\n",
      "          vf_loss: 0.1292496522808941\n",
      "    num_agent_steps_sampled: 4008396\n",
      "    num_agent_steps_trained: 4008396\n",
      "    num_steps_sampled: 4008396\n",
      "    num_steps_trained: 4008396\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.83880126182966\n",
      "    ram_util_percent: 56.752050473186124\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558379474759652\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96063395948276\n",
      "    mean_inference_ms: 2.856433548954864\n",
      "    mean_raw_obs_processing_ms: 3.3952938104529062\n",
      "  time_since_restore: 62356.54581236839\n",
      "  time_this_iter_s: 222.52789783477783\n",
      "  time_total_s: 62356.54581236839\n",
      "  timers:\n",
      "    learn_throughput: 933.861\n",
      "    learn_time_ms: 10703.948\n",
      "    load_throughput: 91507.593\n",
      "    load_time_ms: 109.237\n",
      "    sample_throughput: 66.863\n",
      "    sample_time_ms: 149500.036\n",
      "    update_time_ms: 15.37\n",
      "  timestamp: 1636356781\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4008396\n",
      "  training_iteration: 401\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   401</td><td style=\"text-align: right;\">         62356.5</td><td style=\"text-align: right;\">4008396</td><td style=\"text-align: right;\"> 3.73805</td><td style=\"text-align: right;\">                11.3</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           88.7876</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4018392\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-35-49\n",
      "  done: false\n",
      "  episode_len_mean: 91.86238532110092\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000016\n",
      "  episode_reward_mean: 3.250825688073402\n",
      "  episode_reward_min: -1.6400000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 43715\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.221913212384933\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012750560753761794\n",
      "          policy_loss: -0.06956644825255259\n",
      "          total_loss: 0.06507340675442774\n",
      "          vf_explained_var: 0.9347043633460999\n",
      "          vf_loss: 0.12781161550655323\n",
      "    num_agent_steps_sampled: 4018392\n",
      "    num_agent_steps_trained: 4018392\n",
      "    num_steps_sampled: 4018392\n",
      "    num_steps_trained: 4018392\n",
      "  iterations_since_restore: 402\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.12323651452282\n",
      "    ram_util_percent: 56.77053941908714\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560394240502673\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96309897877491\n",
      "    mean_inference_ms: 2.856212499828176\n",
      "    mean_raw_obs_processing_ms: 3.396728653130968\n",
      "  time_since_restore: 62525.16759777069\n",
      "  time_this_iter_s: 168.62178540229797\n",
      "  time_total_s: 62525.16759777069\n",
      "  timers:\n",
      "    learn_throughput: 934.233\n",
      "    learn_time_ms: 10699.685\n",
      "    load_throughput: 91116.695\n",
      "    load_time_ms: 109.705\n",
      "    sample_throughput: 66.061\n",
      "    sample_time_ms: 151314.077\n",
      "    update_time_ms: 15.156\n",
      "  timestamp: 1636356949\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4018392\n",
      "  training_iteration: 402\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   402</td><td style=\"text-align: right;\">         62525.2</td><td style=\"text-align: right;\">4018392</td><td style=\"text-align: right;\"> 3.25083</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           91.8624</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4028388\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-38-59\n",
      "  done: false\n",
      "  episode_len_mean: 89.69369369369369\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.830000000000016\n",
      "  episode_reward_mean: 3.893153153153161\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 43826\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2079218385565995\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013855331953859936\n",
      "          policy_loss: -0.06639200581285434\n",
      "          total_loss: 0.09638425107472218\n",
      "          vf_explained_var: 0.9353910088539124\n",
      "          vf_loss: 0.15329129722797208\n",
      "    num_agent_steps_sampled: 4028388\n",
      "    num_agent_steps_trained: 4028388\n",
      "    num_steps_sampled: 4028388\n",
      "    num_steps_trained: 4028388\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.64037037037038\n",
      "    ram_util_percent: 56.70333333333333\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045634973376205513\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.962890697970856\n",
      "    mean_inference_ms: 2.856568638303202\n",
      "    mean_raw_obs_processing_ms: 3.4093355374642074\n",
      "  time_since_restore: 62714.38056731224\n",
      "  time_this_iter_s: 189.21296954154968\n",
      "  time_total_s: 62714.38056731224\n",
      "  timers:\n",
      "    learn_throughput: 934.884\n",
      "    learn_time_ms: 10692.23\n",
      "    load_throughput: 91070.203\n",
      "    load_time_ms: 109.761\n",
      "    sample_throughput: 64.446\n",
      "    sample_time_ms: 155106.056\n",
      "    update_time_ms: 14.895\n",
      "  timestamp: 1636357139\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4028388\n",
      "  training_iteration: 403\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   403</td><td style=\"text-align: right;\">         62714.4</td><td style=\"text-align: right;\">4028388</td><td style=\"text-align: right;\"> 3.89315</td><td style=\"text-align: right;\">               14.83</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           89.6937</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4038384\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-41-55\n",
      "  done: false\n",
      "  episode_len_mean: 90.24107142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.680000000000017\n",
      "  episode_reward_mean: 3.8155357142857227\n",
      "  episode_reward_min: -1.4900000000000007\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 43938\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1917909011881576\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012936848775514615\n",
      "          policy_loss: -0.06542718691162319\n",
      "          total_loss: 0.08786120169525409\n",
      "          vf_explained_var: 0.9272052049636841\n",
      "          vf_loss: 0.14573453832338126\n",
      "    num_agent_steps_sampled: 4038384\n",
      "    num_agent_steps_trained: 4038384\n",
      "    num_steps_sampled: 4038384\n",
      "    num_steps_trained: 4038384\n",
      "  iterations_since_restore: 404\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.47370517928287\n",
      "    ram_util_percent: 56.713944223107575\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045559451374555394\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95509855036464\n",
      "    mean_inference_ms: 2.8559307056845324\n",
      "    mean_raw_obs_processing_ms: 3.4146298252369016\n",
      "  time_since_restore: 62890.47219967842\n",
      "  time_this_iter_s: 176.09163236618042\n",
      "  time_total_s: 62890.47219967842\n",
      "  timers:\n",
      "    learn_throughput: 935.023\n",
      "    learn_time_ms: 10690.645\n",
      "    load_throughput: 91088.268\n",
      "    load_time_ms: 109.74\n",
      "    sample_throughput: 62.928\n",
      "    sample_time_ms: 158847.452\n",
      "    update_time_ms: 12.873\n",
      "  timestamp: 1636357315\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4038384\n",
      "  training_iteration: 404\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   404</td><td style=\"text-align: right;\">         62890.5</td><td style=\"text-align: right;\">4038384</td><td style=\"text-align: right;\"> 3.81554</td><td style=\"text-align: right;\">               12.68</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">           90.2411</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4048380\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-44-38\n",
      "  done: false\n",
      "  episode_len_mean: 90.57272727272728\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.010000000000014\n",
      "  episode_reward_mean: 4.008181818181828\n",
      "  episode_reward_min: -1.5400000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 44048\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1868989461507553\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014123312283008421\n",
      "          policy_loss: -0.06589136902386179\n",
      "          total_loss: 0.11136655296939306\n",
      "          vf_explained_var: 0.9309718608856201\n",
      "          vf_loss: 0.16695223877158685\n",
      "    num_agent_steps_sampled: 4048380\n",
      "    num_agent_steps_trained: 4048380\n",
      "    num_steps_sampled: 4048380\n",
      "    num_steps_trained: 4048380\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.56051502145922\n",
      "    ram_util_percent: 56.786266094420604\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558285304568549\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95477774650631\n",
      "    mean_inference_ms: 2.855874673376662\n",
      "    mean_raw_obs_processing_ms: 3.4175131570145063\n",
      "  time_since_restore: 63053.53534054756\n",
      "  time_this_iter_s: 163.06314086914062\n",
      "  time_total_s: 63053.53534054756\n",
      "  timers:\n",
      "    learn_throughput: 935.45\n",
      "    learn_time_ms: 10685.769\n",
      "    load_throughput: 91191.211\n",
      "    load_time_ms: 109.616\n",
      "    sample_throughput: 62.739\n",
      "    sample_time_ms: 159327.658\n",
      "    update_time_ms: 12.845\n",
      "  timestamp: 1636357478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4048380\n",
      "  training_iteration: 405\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   405</td><td style=\"text-align: right;\">         63053.5</td><td style=\"text-align: right;\">4048380</td><td style=\"text-align: right;\"> 4.00818</td><td style=\"text-align: right;\">               11.01</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           90.5727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4058376\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-47-08\n",
      "  done: false\n",
      "  episode_len_mean: 93.15094339622641\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000011\n",
      "  episode_reward_mean: 3.8217924528301968\n",
      "  episode_reward_min: -1.2500000000000004\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 44154\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.232552194595337\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012784750380639932\n",
      "          policy_loss: -0.06861677286493727\n",
      "          total_loss: 0.08518904607711185\n",
      "          vf_explained_var: 0.9308537244796753\n",
      "          vf_loss: 0.14700608054000852\n",
      "    num_agent_steps_sampled: 4058376\n",
      "    num_agent_steps_trained: 4058376\n",
      "    num_steps_sampled: 4058376\n",
      "    num_steps_trained: 4058376\n",
      "  iterations_since_restore: 406\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.6177570093458\n",
      "    ram_util_percent: 56.746261682242995\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558728048932881\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95309557665495\n",
      "    mean_inference_ms: 2.856058384863667\n",
      "    mean_raw_obs_processing_ms: 3.4191370355108126\n",
      "  time_since_restore: 63203.65586519241\n",
      "  time_this_iter_s: 150.12052464485168\n",
      "  time_total_s: 63203.65586519241\n",
      "  timers:\n",
      "    learn_throughput: 935.527\n",
      "    learn_time_ms: 10684.888\n",
      "    load_throughput: 91315.087\n",
      "    load_time_ms: 109.467\n",
      "    sample_throughput: 63.317\n",
      "    sample_time_ms: 157871.35\n",
      "    update_time_ms: 12.726\n",
      "  timestamp: 1636357628\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4058376\n",
      "  training_iteration: 406\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   406</td><td style=\"text-align: right;\">         63203.7</td><td style=\"text-align: right;\">4058376</td><td style=\"text-align: right;\"> 3.82179</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -1.25</td><td style=\"text-align: right;\">           93.1509</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4068372\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-49-55\n",
      "  done: false\n",
      "  episode_len_mean: 93.8785046728972\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.710000000000004\n",
      "  episode_reward_mean: 3.465981308411223\n",
      "  episode_reward_min: -1.6900000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 44261\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.202144443275582\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012450788204305833\n",
      "          policy_loss: -0.0709234733086748\n",
      "          total_loss: 0.06766416175752624\n",
      "          vf_explained_var: 0.9314371943473816\n",
      "          vf_loss: 0.13224462740059592\n",
      "    num_agent_steps_sampled: 4068372\n",
      "    num_agent_steps_trained: 4068372\n",
      "    num_steps_sampled: 4068372\n",
      "    num_steps_trained: 4068372\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.13991596638655\n",
      "    ram_util_percent: 56.83781512605043\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559622512562338\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95254852256855\n",
      "    mean_inference_ms: 2.856150404269122\n",
      "    mean_raw_obs_processing_ms: 3.4253893641548503\n",
      "  time_since_restore: 63370.67124938965\n",
      "  time_this_iter_s: 167.0153841972351\n",
      "  time_total_s: 63370.67124938965\n",
      "  timers:\n",
      "    learn_throughput: 935.075\n",
      "    learn_time_ms: 10690.055\n",
      "    load_throughput: 90985.359\n",
      "    load_time_ms: 109.864\n",
      "    sample_throughput: 62.688\n",
      "    sample_time_ms: 159455.772\n",
      "    update_time_ms: 12.222\n",
      "  timestamp: 1636357795\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4068372\n",
      "  training_iteration: 407\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   407</td><td style=\"text-align: right;\">         63370.7</td><td style=\"text-align: right;\">4068372</td><td style=\"text-align: right;\"> 3.46598</td><td style=\"text-align: right;\">                9.71</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           93.8785</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4078368\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-52-49\n",
      "  done: false\n",
      "  episode_len_mean: 91.68807339449542\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.090000000000014\n",
      "  episode_reward_mean: 3.8311009174312014\n",
      "  episode_reward_min: -1.5600000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 44370\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1916560302432786\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013526449872505035\n",
      "          policy_loss: -0.0699057763784678\n",
      "          total_loss: 0.08845773365579418\n",
      "          vf_explained_var: 0.9385538697242737\n",
      "          vf_loss: 0.1494651260292237\n",
      "    num_agent_steps_sampled: 4078368\n",
      "    num_agent_steps_trained: 4078368\n",
      "    num_steps_sampled: 4078368\n",
      "    num_steps_trained: 4078368\n",
      "  iterations_since_restore: 408\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.00963855421686\n",
      "    ram_util_percent: 56.89919678714861\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045588715923550134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95089238566131\n",
      "    mean_inference_ms: 2.8560523213600186\n",
      "    mean_raw_obs_processing_ms: 3.429572665377634\n",
      "  time_since_restore: 63544.66635298729\n",
      "  time_this_iter_s: 173.995103597641\n",
      "  time_total_s: 63544.66635298729\n",
      "  timers:\n",
      "    learn_throughput: 935.211\n",
      "    learn_time_ms: 10688.493\n",
      "    load_throughput: 91029.985\n",
      "    load_time_ms: 109.81\n",
      "    sample_throughput: 61.381\n",
      "    sample_time_ms: 162851.688\n",
      "    update_time_ms: 11.791\n",
      "  timestamp: 1636357969\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4078368\n",
      "  training_iteration: 408\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   408</td><td style=\"text-align: right;\">         63544.7</td><td style=\"text-align: right;\">4078368</td><td style=\"text-align: right;\">  3.8311</td><td style=\"text-align: right;\">               11.09</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           91.6881</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4088364\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-55-21\n",
      "  done: false\n",
      "  episode_len_mean: 92.66055045871559\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.86000000000001\n",
      "  episode_reward_mean: 4.1094495412844125\n",
      "  episode_reward_min: -1.3400000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 44479\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1882740583175266\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01307853468379205\n",
      "          policy_loss: -0.06898505410864057\n",
      "          total_loss: 0.08749736473282688\n",
      "          vf_explained_var: 0.942684531211853\n",
      "          vf_loss: 0.148570620526488\n",
      "    num_agent_steps_sampled: 4088364\n",
      "    num_agent_steps_trained: 4088364\n",
      "    num_steps_sampled: 4088364\n",
      "    num_steps_trained: 4088364\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.05115207373271\n",
      "    ram_util_percent: 56.84423963133641\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045585292704543756\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.951694311412126\n",
      "    mean_inference_ms: 2.855904601848938\n",
      "    mean_raw_obs_processing_ms: 3.426953891179562\n",
      "  time_since_restore: 63696.99642729759\n",
      "  time_this_iter_s: 152.33007431030273\n",
      "  time_total_s: 63696.99642729759\n",
      "  timers:\n",
      "    learn_throughput: 934.952\n",
      "    learn_time_ms: 10691.456\n",
      "    load_throughput: 90749.703\n",
      "    load_time_ms: 110.149\n",
      "    sample_throughput: 61.642\n",
      "    sample_time_ms: 162161.315\n",
      "    update_time_ms: 10.981\n",
      "  timestamp: 1636358121\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4088364\n",
      "  training_iteration: 409\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   409</td><td style=\"text-align: right;\">           63697</td><td style=\"text-align: right;\">4088364</td><td style=\"text-align: right;\"> 4.10945</td><td style=\"text-align: right;\">               14.86</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           92.6606</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4098360\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_07-57-59\n",
      "  done: false\n",
      "  episode_len_mean: 94.28571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.750000000000014\n",
      "  episode_reward_mean: 3.713333333333342\n",
      "  episode_reward_min: -1.5300000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 44584\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.198503725956648\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013424545706457854\n",
      "          policy_loss: -0.06806675498174806\n",
      "          total_loss: 0.07748502867582899\n",
      "          vf_explained_var: 0.9369170069694519\n",
      "          vf_loss: 0.1369540260404221\n",
      "    num_agent_steps_sampled: 4098360\n",
      "    num_agent_steps_trained: 4098360\n",
      "    num_steps_sampled: 4098360\n",
      "    num_steps_trained: 4098360\n",
      "  iterations_since_restore: 410\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.588\n",
      "    ram_util_percent: 56.808000000000014\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557428903291222\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95118661502954\n",
      "    mean_inference_ms: 2.855896381308214\n",
      "    mean_raw_obs_processing_ms: 3.4257717540381427\n",
      "  time_since_restore: 63854.94254279137\n",
      "  time_this_iter_s: 157.9461154937744\n",
      "  time_total_s: 63854.94254279137\n",
      "  timers:\n",
      "    learn_throughput: 935.13\n",
      "    learn_time_ms: 10689.424\n",
      "    load_throughput: 90442.12\n",
      "    load_time_ms: 110.524\n",
      "    sample_throughput: 61.984\n",
      "    sample_time_ms: 161266.184\n",
      "    update_time_ms: 12.91\n",
      "  timestamp: 1636358279\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4098360\n",
      "  training_iteration: 410\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   410</td><td style=\"text-align: right;\">         63854.9</td><td style=\"text-align: right;\">4098360</td><td style=\"text-align: right;\"> 3.71333</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">           94.2857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4108356\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-00-49\n",
      "  done: false\n",
      "  episode_len_mean: 93.7196261682243\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.040000000000015\n",
      "  episode_reward_mean: 3.611588785046739\n",
      "  episode_reward_min: -1.4900000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 44691\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.194233762504708\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013665323156686084\n",
      "          policy_loss: -0.06517342779084913\n",
      "          total_loss: 0.10240440792205115\n",
      "          vf_explained_var: 0.9161876440048218\n",
      "          vf_loss: 0.15838885811818207\n",
      "    num_agent_steps_sampled: 4108356\n",
      "    num_agent_steps_trained: 4108356\n",
      "    num_steps_sampled: 4108356\n",
      "    num_steps_trained: 4108356\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.76131687242798\n",
      "    ram_util_percent: 56.84691358024693\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559413085293559\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94790856111856\n",
      "    mean_inference_ms: 2.8560051753135967\n",
      "    mean_raw_obs_processing_ms: 3.429881726947915\n",
      "  time_since_restore: 64024.714926958084\n",
      "  time_this_iter_s: 169.77238416671753\n",
      "  time_total_s: 64024.714926958084\n",
      "  timers:\n",
      "    learn_throughput: 935.044\n",
      "    learn_time_ms: 10690.409\n",
      "    load_throughput: 90432.113\n",
      "    load_time_ms: 110.536\n",
      "    sample_throughput: 64.082\n",
      "    sample_time_ms: 155988.572\n",
      "    update_time_ms: 14.044\n",
      "  timestamp: 1636358449\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4108356\n",
      "  training_iteration: 411\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   411</td><td style=\"text-align: right;\">         64024.7</td><td style=\"text-align: right;\">4108356</td><td style=\"text-align: right;\"> 3.61159</td><td style=\"text-align: right;\">               12.04</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">           93.7196</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4118352\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-03-30\n",
      "  done: false\n",
      "  episode_len_mean: 93.59433962264151\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.720000000000017\n",
      "  episode_reward_mean: 3.5166037735849143\n",
      "  episode_reward_min: -2.2899999999999947\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 44797\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1956536144272896\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013307960121577466\n",
      "          policy_loss: -0.07015460631372328\n",
      "          total_loss: 0.07269108425825835\n",
      "          vf_explained_var: 0.9313903450965881\n",
      "          vf_loss: 0.13448502980013433\n",
      "    num_agent_steps_sampled: 4118352\n",
      "    num_agent_steps_trained: 4118352\n",
      "    num_steps_sampled: 4118352\n",
      "    num_steps_trained: 4118352\n",
      "  iterations_since_restore: 412\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.25938864628822\n",
      "    ram_util_percent: 56.851091703056774\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557450495696058\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94262969137465\n",
      "    mean_inference_ms: 2.856105791619321\n",
      "    mean_raw_obs_processing_ms: 3.4312439588258727\n",
      "  time_since_restore: 64185.319024562836\n",
      "  time_this_iter_s: 160.6040976047516\n",
      "  time_total_s: 64185.319024562836\n",
      "  timers:\n",
      "    learn_throughput: 933.819\n",
      "    learn_time_ms: 10704.432\n",
      "    load_throughput: 90548.477\n",
      "    load_time_ms: 110.394\n",
      "    sample_throughput: 64.419\n",
      "    sample_time_ms: 155172.237\n",
      "    update_time_ms: 14.49\n",
      "  timestamp: 1636358610\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4118352\n",
      "  training_iteration: 412\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   412</td><td style=\"text-align: right;\">         64185.3</td><td style=\"text-align: right;\">4118352</td><td style=\"text-align: right;\">  3.5166</td><td style=\"text-align: right;\">               10.72</td><td style=\"text-align: right;\">               -2.29</td><td style=\"text-align: right;\">           93.5943</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4128348\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-06-02\n",
      "  done: false\n",
      "  episode_len_mean: 92.9074074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.75000000000001\n",
      "  episode_reward_mean: 3.976388888888899\n",
      "  episode_reward_min: -1.5800000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 44905\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1907410770399958\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013353501079196495\n",
      "          policy_loss: -0.06639163381555396\n",
      "          total_loss: 0.07844294292502041\n",
      "          vf_explained_var: 0.9420851469039917\n",
      "          vf_loss: 0.13632104246375654\n",
      "    num_agent_steps_sampled: 4128348\n",
      "    num_agent_steps_trained: 4128348\n",
      "    num_steps_sampled: 4128348\n",
      "    num_steps_trained: 4128348\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.63686635944701\n",
      "    ram_util_percent: 56.85944700460829\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045561342132211795\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94138386742472\n",
      "    mean_inference_ms: 2.856036342616741\n",
      "    mean_raw_obs_processing_ms: 3.4328111837851623\n",
      "  time_since_restore: 64337.78113627434\n",
      "  time_this_iter_s: 152.46211171150208\n",
      "  time_total_s: 64337.78113627434\n",
      "  timers:\n",
      "    learn_throughput: 932.998\n",
      "    learn_time_ms: 10713.848\n",
      "    load_throughput: 90604.578\n",
      "    load_time_ms: 110.326\n",
      "    sample_throughput: 65.986\n",
      "    sample_time_ms: 151487.567\n",
      "    update_time_ms: 14.73\n",
      "  timestamp: 1636358762\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4128348\n",
      "  training_iteration: 413\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   413</td><td style=\"text-align: right;\">         64337.8</td><td style=\"text-align: right;\">4128348</td><td style=\"text-align: right;\"> 3.97639</td><td style=\"text-align: right;\">               12.75</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           92.9074</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4138344\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-08-33\n",
      "  done: false\n",
      "  episode_len_mean: 94.05607476635514\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.940000000000012\n",
      "  episode_reward_mean: 3.646915887850477\n",
      "  episode_reward_min: -1.3100000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 45012\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2084657475479648\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013570634059755216\n",
      "          policy_loss: -0.06465512636300717\n",
      "          total_loss: 0.09137675691173118\n",
      "          vf_explained_var: 0.9383723139762878\n",
      "          vf_loss: 0.14720094071573808\n",
      "    num_agent_steps_sampled: 4138344\n",
      "    num_agent_steps_trained: 4138344\n",
      "    num_steps_sampled: 4138344\n",
      "    num_steps_trained: 4138344\n",
      "  iterations_since_restore: 414\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.56093023255814\n",
      "    ram_util_percent: 56.92093023255814\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560986642492507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94263995545871\n",
      "    mean_inference_ms: 2.856008602802436\n",
      "    mean_raw_obs_processing_ms: 3.431523675527388\n",
      "  time_since_restore: 64487.99637055397\n",
      "  time_this_iter_s: 150.21523427963257\n",
      "  time_total_s: 64487.99637055397\n",
      "  timers:\n",
      "    learn_throughput: 932.363\n",
      "    learn_time_ms: 10721.152\n",
      "    load_throughput: 90619.461\n",
      "    load_time_ms: 110.307\n",
      "    sample_throughput: 67.136\n",
      "    sample_time_ms: 148891.513\n",
      "    update_time_ms: 15.827\n",
      "  timestamp: 1636358913\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4138344\n",
      "  training_iteration: 414\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   414</td><td style=\"text-align: right;\">           64488</td><td style=\"text-align: right;\">4138344</td><td style=\"text-align: right;\"> 3.64692</td><td style=\"text-align: right;\">               12.94</td><td style=\"text-align: right;\">               -1.31</td><td style=\"text-align: right;\">           94.0561</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4148340\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-10-53\n",
      "  done: false\n",
      "  episode_len_mean: 92.42592592592592\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.360000000000017\n",
      "  episode_reward_mean: 3.5975000000000077\n",
      "  episode_reward_min: -1.6700000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 45120\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1871672168756144\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012946654925794788\n",
      "          policy_loss: -0.06790018582509624\n",
      "          total_loss: 0.09808046225394704\n",
      "          vf_explained_var: 0.9238619208335876\n",
      "          vf_loss: 0.15835822000462785\n",
      "    num_agent_steps_sampled: 4148340\n",
      "    num_agent_steps_trained: 4148340\n",
      "    num_steps_sampled: 4148340\n",
      "    num_steps_trained: 4148340\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.104\n",
      "    ram_util_percent: 56.965\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556984957374815\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94463827006201\n",
      "    mean_inference_ms: 2.8558393980918164\n",
      "    mean_raw_obs_processing_ms: 3.4237656504298792\n",
      "  time_since_restore: 64628.14252829552\n",
      "  time_this_iter_s: 140.14615774154663\n",
      "  time_total_s: 64628.14252829552\n",
      "  timers:\n",
      "    learn_throughput: 932.08\n",
      "    learn_time_ms: 10724.405\n",
      "    load_throughput: 90343.196\n",
      "    load_time_ms: 110.645\n",
      "    sample_throughput: 68.187\n",
      "    sample_time_ms: 146596.239\n",
      "    update_time_ms: 15.523\n",
      "  timestamp: 1636359053\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4148340\n",
      "  training_iteration: 415\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   415</td><td style=\"text-align: right;\">         64628.1</td><td style=\"text-align: right;\">4148340</td><td style=\"text-align: right;\">  3.5975</td><td style=\"text-align: right;\">               14.36</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           92.4259</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4158336\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-13-26\n",
      "  done: false\n",
      "  episode_len_mean: 94.74528301886792\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.000000000000014\n",
      "  episode_reward_mean: 3.2172641509434046\n",
      "  episode_reward_min: -1.6100000000000003\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 45226\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1997144984383867\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013251135794876084\n",
      "          policy_loss: -0.06919593505847912\n",
      "          total_loss: 0.07824794278105991\n",
      "          vf_explained_var: 0.9258736968040466\n",
      "          vf_loss: 0.13925327802888857\n",
      "    num_agent_steps_sampled: 4158336\n",
      "    num_agent_steps_trained: 4158336\n",
      "    num_steps_sampled: 4158336\n",
      "    num_steps_trained: 4158336\n",
      "  iterations_since_restore: 416\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.22201834862386\n",
      "    ram_util_percent: 56.91376146788991\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557559833934054\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94448932698072\n",
      "    mean_inference_ms: 2.8561389878824404\n",
      "    mean_raw_obs_processing_ms: 3.421872555577077\n",
      "  time_since_restore: 64781.237891197205\n",
      "  time_this_iter_s: 153.09536290168762\n",
      "  time_total_s: 64781.237891197205\n",
      "  timers:\n",
      "    learn_throughput: 931.035\n",
      "    learn_time_ms: 10736.433\n",
      "    load_throughput: 90132.082\n",
      "    load_time_ms: 110.904\n",
      "    sample_throughput: 68.055\n",
      "    sample_time_ms: 146882.01\n",
      "    update_time_ms: 14.772\n",
      "  timestamp: 1636359206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4158336\n",
      "  training_iteration: 416\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   416</td><td style=\"text-align: right;\">         64781.2</td><td style=\"text-align: right;\">4158336</td><td style=\"text-align: right;\"> 3.21726</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           94.7453</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4168332\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-16-14\n",
      "  done: false\n",
      "  episode_len_mean: 91.25688073394495\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.05000000000001\n",
      "  episode_reward_mean: 3.8876146788990917\n",
      "  episode_reward_min: -1.4300000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 45335\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.199414829107431\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013460099118370037\n",
      "          policy_loss: -0.07145873848189656\n",
      "          total_loss: 0.08314912877021692\n",
      "          vf_explained_var: 0.9354813694953918\n",
      "          vf_loss: 0.14593822598202616\n",
      "    num_agent_steps_sampled: 4168332\n",
      "    num_agent_steps_trained: 4168332\n",
      "    num_steps_sampled: 4168332\n",
      "    num_steps_trained: 4168332\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.12175732217572\n",
      "    ram_util_percent: 56.80627615062763\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560613317128092\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.946582100279834\n",
      "    mean_inference_ms: 2.8559485157578406\n",
      "    mean_raw_obs_processing_ms: 3.428101030997759\n",
      "  time_since_restore: 64948.723537921906\n",
      "  time_this_iter_s: 167.48564672470093\n",
      "  time_total_s: 64948.723537921906\n",
      "  timers:\n",
      "    learn_throughput: 931.565\n",
      "    learn_time_ms: 10730.335\n",
      "    load_throughput: 89986.298\n",
      "    load_time_ms: 111.084\n",
      "    sample_throughput: 68.03\n",
      "    sample_time_ms: 146934.22\n",
      "    update_time_ms: 15.19\n",
      "  timestamp: 1636359374\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4168332\n",
      "  training_iteration: 417\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   417</td><td style=\"text-align: right;\">         64948.7</td><td style=\"text-align: right;\">4168332</td><td style=\"text-align: right;\"> 3.88761</td><td style=\"text-align: right;\">               15.05</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           91.2569</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4178328\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-18-58\n",
      "  done: false\n",
      "  episode_len_mean: 95.18867924528301\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.710000000000012\n",
      "  episode_reward_mean: 3.97745283018869\n",
      "  episode_reward_min: -1.6700000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 45441\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.190525872483213\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013485541751588245\n",
      "          policy_loss: -0.06617835932371453\n",
      "          total_loss: 0.09396520340735587\n",
      "          vf_explained_var: 0.9334796071052551\n",
      "          vf_loss: 0.15132707053731775\n",
      "    num_agent_steps_sampled: 4178328\n",
      "    num_agent_steps_trained: 4178328\n",
      "    num_steps_sampled: 4178328\n",
      "    num_steps_trained: 4178328\n",
      "  iterations_since_restore: 418\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.81872340425532\n",
      "    ram_util_percent: 57.02297872340424\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045554005588930975\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94021435704935\n",
      "    mean_inference_ms: 2.8559978944376265\n",
      "    mean_raw_obs_processing_ms: 3.4294987424450456\n",
      "  time_since_restore: 65112.91786336899\n",
      "  time_this_iter_s: 164.19432544708252\n",
      "  time_total_s: 65112.91786336899\n",
      "  timers:\n",
      "    learn_throughput: 931.028\n",
      "    learn_time_ms: 10736.519\n",
      "    load_throughput: 90272.216\n",
      "    load_time_ms: 110.732\n",
      "    sample_throughput: 68.49\n",
      "    sample_time_ms: 145947.588\n",
      "    update_time_ms: 16.149\n",
      "  timestamp: 1636359538\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4178328\n",
      "  training_iteration: 418\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   418</td><td style=\"text-align: right;\">         65112.9</td><td style=\"text-align: right;\">4178328</td><td style=\"text-align: right;\"> 3.97745</td><td style=\"text-align: right;\">               12.71</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           95.1887</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4188324\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-22-01\n",
      "  done: false\n",
      "  episode_len_mean: 91.36697247706422\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.180000000000012\n",
      "  episode_reward_mean: 3.976605504587165\n",
      "  episode_reward_min: -1.8500000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 45550\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1879957081925157\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013948500864663486\n",
      "          policy_loss: -0.06796718035052475\n",
      "          total_loss: 0.08606065941226279\n",
      "          vf_explained_var: 0.943539023399353\n",
      "          vf_loss: 0.14413136748644786\n",
      "    num_agent_steps_sampled: 4188324\n",
      "    num_agent_steps_trained: 4188324\n",
      "    num_steps_sampled: 4188324\n",
      "    num_steps_trained: 4188324\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.15916030534352\n",
      "    ram_util_percent: 56.94656488549618\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560213382881999\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94338384684822\n",
      "    mean_inference_ms: 2.8559385519523928\n",
      "    mean_raw_obs_processing_ms: 3.440048173814668\n",
      "  time_since_restore: 65296.53790092468\n",
      "  time_this_iter_s: 183.62003755569458\n",
      "  time_total_s: 65296.53790092468\n",
      "  timers:\n",
      "    learn_throughput: 931.842\n",
      "    learn_time_ms: 10727.144\n",
      "    load_throughput: 90507.702\n",
      "    load_time_ms: 110.444\n",
      "    sample_throughput: 67.049\n",
      "    sample_time_ms: 149085.364\n",
      "    update_time_ms: 16.894\n",
      "  timestamp: 1636359721\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4188324\n",
      "  training_iteration: 419\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   419</td><td style=\"text-align: right;\">         65296.5</td><td style=\"text-align: right;\">4188324</td><td style=\"text-align: right;\"> 3.97661</td><td style=\"text-align: right;\">               11.18</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">            91.367</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4198320\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-24-40\n",
      "  done: false\n",
      "  episode_len_mean: 93.81132075471699\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.790000000000013\n",
      "  episode_reward_mean: 4.126792452830199\n",
      "  episode_reward_min: -1.1900000000000004\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 45656\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1586471838828847\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012925330623064253\n",
      "          policy_loss: -0.0651422929432657\n",
      "          total_loss: 0.06910212974772494\n",
      "          vf_explained_var: 0.9559566974639893\n",
      "          vf_loss: 0.12638537367153116\n",
      "    num_agent_steps_sampled: 4198320\n",
      "    num_agent_steps_trained: 4198320\n",
      "    num_steps_sampled: 4198320\n",
      "    num_steps_trained: 4198320\n",
      "  iterations_since_restore: 420\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.71150442477875\n",
      "    ram_util_percent: 56.656637168141586\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556762906493325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.943222860268094\n",
      "    mean_inference_ms: 2.8559859992108176\n",
      "    mean_raw_obs_processing_ms: 3.4378039166787184\n",
      "  time_since_restore: 65455.10248708725\n",
      "  time_this_iter_s: 158.56458616256714\n",
      "  time_total_s: 65455.10248708725\n",
      "  timers:\n",
      "    learn_throughput: 931.322\n",
      "    learn_time_ms: 10733.127\n",
      "    load_throughput: 90837.631\n",
      "    load_time_ms: 110.043\n",
      "    sample_throughput: 67.022\n",
      "    sample_time_ms: 149143.956\n",
      "    update_time_ms: 14.82\n",
      "  timestamp: 1636359880\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4198320\n",
      "  training_iteration: 420\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   420</td><td style=\"text-align: right;\">         65455.1</td><td style=\"text-align: right;\">4198320</td><td style=\"text-align: right;\"> 4.12679</td><td style=\"text-align: right;\">               12.79</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           93.8113</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4208316\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-27-10\n",
      "  done: false\n",
      "  episode_len_mean: 95.73076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.570000000000018\n",
      "  episode_reward_mean: 3.352307692307701\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 45760\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1915318433036153\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012852036380932142\n",
      "          policy_loss: -0.07010253447657212\n",
      "          total_loss: 0.06983439184836725\n",
      "          vf_explained_var: 0.9370538592338562\n",
      "          vf_loss: 0.1325736988479128\n",
      "    num_agent_steps_sampled: 4208316\n",
      "    num_agent_steps_trained: 4208316\n",
      "    num_steps_sampled: 4208316\n",
      "    num_steps_trained: 4208316\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.8769953051643\n",
      "    ram_util_percent: 56.89906103286388\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045575762894943445\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94341273709988\n",
      "    mean_inference_ms: 2.8561134432431228\n",
      "    mean_raw_obs_processing_ms: 3.4357362207170046\n",
      "  time_since_restore: 65604.52269220352\n",
      "  time_this_iter_s: 149.42020511627197\n",
      "  time_total_s: 65604.52269220352\n",
      "  timers:\n",
      "    learn_throughput: 931.604\n",
      "    learn_time_ms: 10729.88\n",
      "    load_throughput: 90892.554\n",
      "    load_time_ms: 109.976\n",
      "    sample_throughput: 67.948\n",
      "    sample_time_ms: 147113.173\n",
      "    update_time_ms: 13.699\n",
      "  timestamp: 1636360030\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4208316\n",
      "  training_iteration: 421\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   421</td><td style=\"text-align: right;\">         65604.5</td><td style=\"text-align: right;\">4208316</td><td style=\"text-align: right;\"> 3.35231</td><td style=\"text-align: right;\">               10.57</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           95.7308</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4218312\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-29-54\n",
      "  done: false\n",
      "  episode_len_mean: 94.33018867924528\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.580000000000016\n",
      "  episode_reward_mean: 4.160849056603784\n",
      "  episode_reward_min: -2.1399999999999997\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 45866\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.150744915721763\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014163084036750534\n",
      "          policy_loss: -0.06440481930258724\n",
      "          total_loss: 0.11673047612222213\n",
      "          vf_explained_var: 0.9324191808700562\n",
      "          vf_loss: 0.1703774684896836\n",
      "    num_agent_steps_sampled: 4218312\n",
      "    num_agent_steps_trained: 4218312\n",
      "    num_steps_sampled: 4218312\n",
      "    num_steps_trained: 4218312\n",
      "  iterations_since_restore: 422\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.34510638297871\n",
      "    ram_util_percent: 56.89106382978724\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045586179232259015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94321755606872\n",
      "    mean_inference_ms: 2.856119256720299\n",
      "    mean_raw_obs_processing_ms: 3.4378254185274364\n",
      "  time_since_restore: 65769.13204193115\n",
      "  time_this_iter_s: 164.60934972763062\n",
      "  time_total_s: 65769.13204193115\n",
      "  timers:\n",
      "    learn_throughput: 932.233\n",
      "    learn_time_ms: 10722.646\n",
      "    load_throughput: 91013.919\n",
      "    load_time_ms: 109.829\n",
      "    sample_throughput: 67.76\n",
      "    sample_time_ms: 147521.535\n",
      "    update_time_ms: 13.3\n",
      "  timestamp: 1636360194\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4218312\n",
      "  training_iteration: 422\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   422</td><td style=\"text-align: right;\">         65769.1</td><td style=\"text-align: right;\">4218312</td><td style=\"text-align: right;\"> 4.16085</td><td style=\"text-align: right;\">               12.58</td><td style=\"text-align: right;\">               -2.14</td><td style=\"text-align: right;\">           94.3302</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4228308\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-32-29\n",
      "  done: false\n",
      "  episode_len_mean: 92.63888888888889\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.230000000000015\n",
      "  episode_reward_mean: 3.583888888888898\n",
      "  episode_reward_min: -1.4000000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 45974\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.191594819941072\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013013488735916368\n",
      "          policy_loss: -0.06511404713114294\n",
      "          total_loss: 0.10745197597604532\n",
      "          vf_explained_var: 0.9338178634643555\n",
      "          vf_loss: 0.16483561669070368\n",
      "    num_agent_steps_sampled: 4228308\n",
      "    num_agent_steps_trained: 4228308\n",
      "    num_steps_sampled: 4228308\n",
      "    num_steps_trained: 4228308\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.44545454545455\n",
      "    ram_util_percent: 56.65636363636364\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555241128861636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94262228283272\n",
      "    mean_inference_ms: 2.8559151042828432\n",
      "    mean_raw_obs_processing_ms: 3.438827309139922\n",
      "  time_since_restore: 65923.46377539635\n",
      "  time_this_iter_s: 154.3317334651947\n",
      "  time_total_s: 65923.46377539635\n",
      "  timers:\n",
      "    learn_throughput: 932.582\n",
      "    learn_time_ms: 10718.633\n",
      "    load_throughput: 91052.047\n",
      "    load_time_ms: 109.783\n",
      "    sample_throughput: 67.672\n",
      "    sample_time_ms: 147713.146\n",
      "    update_time_ms: 12.775\n",
      "  timestamp: 1636360349\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4228308\n",
      "  training_iteration: 423\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   423</td><td style=\"text-align: right;\">         65923.5</td><td style=\"text-align: right;\">4228308</td><td style=\"text-align: right;\"> 3.58389</td><td style=\"text-align: right;\">               12.23</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           92.6389</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4238304\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-35-37\n",
      "  done: false\n",
      "  episode_len_mean: 92.78703703703704\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.940000000000014\n",
      "  episode_reward_mean: 4.0065740740740825\n",
      "  episode_reward_min: -0.9200000000000004\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 46082\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.193988230900887\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013536761462499032\n",
      "          policy_loss: -0.06544336928134291\n",
      "          total_loss: 0.09669108684532918\n",
      "          vf_explained_var: 0.9377652406692505\n",
      "          vf_loss: 0.15323590281236377\n",
      "    num_agent_steps_sampled: 4238304\n",
      "    num_agent_steps_trained: 4238304\n",
      "    num_steps_sampled: 4238304\n",
      "    num_steps_trained: 4238304\n",
      "  iterations_since_restore: 424\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.853531598513\n",
      "    ram_util_percent: 56.93308550185873\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555939101607088\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94099986223328\n",
      "    mean_inference_ms: 2.8560597508373498\n",
      "    mean_raw_obs_processing_ms: 3.4471899052486994\n",
      "  time_since_restore: 66111.80825734138\n",
      "  time_this_iter_s: 188.34448194503784\n",
      "  time_total_s: 66111.80825734138\n",
      "  timers:\n",
      "    learn_throughput: 932.716\n",
      "    learn_time_ms: 10717.093\n",
      "    load_throughput: 91027.139\n",
      "    load_time_ms: 109.813\n",
      "    sample_throughput: 65.968\n",
      "    sample_time_ms: 151528.416\n",
      "    update_time_ms: 11.943\n",
      "  timestamp: 1636360537\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4238304\n",
      "  training_iteration: 424\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   424</td><td style=\"text-align: right;\">         66111.8</td><td style=\"text-align: right;\">4238304</td><td style=\"text-align: right;\"> 4.00657</td><td style=\"text-align: right;\">               12.94</td><td style=\"text-align: right;\">               -0.92</td><td style=\"text-align: right;\">            92.787</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4248300\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-38-18\n",
      "  done: false\n",
      "  episode_len_mean: 92.67289719626169\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.610000000000014\n",
      "  episode_reward_mean: 3.7762616822429997\n",
      "  episode_reward_min: -1.2400000000000004\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 46189\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1627939925234543\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012694999339967313\n",
      "          policy_loss: -0.0695162040523739\n",
      "          total_loss: 0.07764866601707589\n",
      "          vf_explained_var: 0.9401608109474182\n",
      "          vf_loss: 0.13987201389530277\n",
      "    num_agent_steps_sampled: 4248300\n",
      "    num_agent_steps_trained: 4248300\n",
      "    num_steps_sampled: 4248300\n",
      "    num_steps_trained: 4248300\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.61391304347826\n",
      "    ram_util_percent: 56.95869565217393\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556080106374178\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93932163167083\n",
      "    mean_inference_ms: 2.855841387759001\n",
      "    mean_raw_obs_processing_ms: 3.4485417842693358\n",
      "  time_since_restore: 66273.25715899467\n",
      "  time_this_iter_s: 161.4489016532898\n",
      "  time_total_s: 66273.25715899467\n",
      "  timers:\n",
      "    learn_throughput: 932.716\n",
      "    learn_time_ms: 10717.093\n",
      "    load_throughput: 91014.058\n",
      "    load_time_ms: 109.829\n",
      "    sample_throughput: 65.053\n",
      "    sample_time_ms: 153659.299\n",
      "    update_time_ms: 11.463\n",
      "  timestamp: 1636360698\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4248300\n",
      "  training_iteration: 425\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   425</td><td style=\"text-align: right;\">         66273.3</td><td style=\"text-align: right;\">4248300</td><td style=\"text-align: right;\"> 3.77626</td><td style=\"text-align: right;\">               12.61</td><td style=\"text-align: right;\">               -1.24</td><td style=\"text-align: right;\">           92.6729</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4258296\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-41-02\n",
      "  done: false\n",
      "  episode_len_mean: 91.53636363636363\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.800000000000011\n",
      "  episode_reward_mean: 3.771636363636373\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 46299\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1946246431424066\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013049858573776057\n",
      "          policy_loss: -0.0685580959973427\n",
      "          total_loss: 0.09332723398175505\n",
      "          vf_explained_var: 0.9384799003601074\n",
      "          vf_loss: 0.154102366632567\n",
      "    num_agent_steps_sampled: 4258296\n",
      "    num_agent_steps_trained: 4258296\n",
      "    num_steps_sampled: 4258296\n",
      "    num_steps_trained: 4258296\n",
      "  iterations_since_restore: 426\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.05256410256412\n",
      "    ram_util_percent: 56.81709401709402\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556541970750729\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93757638002094\n",
      "    mean_inference_ms: 2.8558965233856806\n",
      "    mean_raw_obs_processing_ms: 3.45471825210212\n",
      "  time_since_restore: 66437.09151649475\n",
      "  time_this_iter_s: 163.8343575000763\n",
      "  time_total_s: 66437.09151649475\n",
      "  timers:\n",
      "    learn_throughput: 933.506\n",
      "    learn_time_ms: 10708.02\n",
      "    load_throughput: 91408.977\n",
      "    load_time_ms: 109.355\n",
      "    sample_throughput: 64.597\n",
      "    sample_time_ms: 154743.036\n",
      "    update_time_ms: 11.312\n",
      "  timestamp: 1636360862\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4258296\n",
      "  training_iteration: 426\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   426</td><td style=\"text-align: right;\">         66437.1</td><td style=\"text-align: right;\">4258296</td><td style=\"text-align: right;\"> 3.77164</td><td style=\"text-align: right;\">                10.8</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           91.5364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4268292\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-43-33\n",
      "  done: false\n",
      "  episode_len_mean: 93.06542056074767\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.870000000000017\n",
      "  episode_reward_mean: 4.191495327102813\n",
      "  episode_reward_min: -1.7900000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 46406\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.174702736047598\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012752620625056494\n",
      "          policy_loss: -0.06958157820467893\n",
      "          total_loss: 0.08406782608845423\n",
      "          vf_explained_var: 0.9382973313331604\n",
      "          vf_loss: 0.1463443668702474\n",
      "    num_agent_steps_sampled: 4268292\n",
      "    num_agent_steps_trained: 4268292\n",
      "    num_steps_sampled: 4268292\n",
      "    num_steps_trained: 4268292\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.92976744186048\n",
      "    ram_util_percent: 56.90883720930234\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555774949102806\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.938776018114375\n",
      "    mean_inference_ms: 2.855770122905571\n",
      "    mean_raw_obs_processing_ms: 3.4515829310904067\n",
      "  time_since_restore: 66587.96495866776\n",
      "  time_this_iter_s: 150.87344217300415\n",
      "  time_total_s: 66587.96495866776\n",
      "  timers:\n",
      "    learn_throughput: 932.576\n",
      "    learn_time_ms: 10718.701\n",
      "    load_throughput: 91644.328\n",
      "    load_time_ms: 109.074\n",
      "    sample_throughput: 65.302\n",
      "    sample_time_ms: 153072.552\n",
      "    update_time_ms: 10.409\n",
      "  timestamp: 1636361013\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4268292\n",
      "  training_iteration: 427\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   427</td><td style=\"text-align: right;\">           66588</td><td style=\"text-align: right;\">4268292</td><td style=\"text-align: right;\">  4.1915</td><td style=\"text-align: right;\">               14.87</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           93.0654</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4278288\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-46-01\n",
      "  done: false\n",
      "  episode_len_mean: 94.42056074766356\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.570000000000023\n",
      "  episode_reward_mean: 3.5600000000000076\n",
      "  episode_reward_min: -1.780000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 46513\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.211117487381666\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013170536175733126\n",
      "          policy_loss: -0.06289148626323694\n",
      "          total_loss: 0.0973399846137971\n",
      "          vf_explained_var: 0.9308083653450012\n",
      "          vf_loss: 0.15233851672492477\n",
      "    num_agent_steps_sampled: 4278288\n",
      "    num_agent_steps_trained: 4278288\n",
      "    num_steps_sampled: 4278288\n",
      "    num_steps_trained: 4278288\n",
      "  iterations_since_restore: 428\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.38679245283019\n",
      "    ram_util_percent: 56.92735849056603\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558387755739773\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93753190038735\n",
      "    mean_inference_ms: 2.8558476073358805\n",
      "    mean_raw_obs_processing_ms: 3.4498489602509697\n",
      "  time_since_restore: 66736.10049247742\n",
      "  time_this_iter_s: 148.13553380966187\n",
      "  time_total_s: 66736.10049247742\n",
      "  timers:\n",
      "    learn_throughput: 933.391\n",
      "    learn_time_ms: 10709.339\n",
      "    load_throughput: 91369.195\n",
      "    load_time_ms: 109.402\n",
      "    sample_throughput: 65.991\n",
      "    sample_time_ms: 151475.483\n",
      "    update_time_ms: 10.163\n",
      "  timestamp: 1636361161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4278288\n",
      "  training_iteration: 428\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   428</td><td style=\"text-align: right;\">         66736.1</td><td style=\"text-align: right;\">4278288</td><td style=\"text-align: right;\">    3.56</td><td style=\"text-align: right;\">               12.57</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           94.4206</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4288284\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-48-32\n",
      "  done: false\n",
      "  episode_len_mean: 93.33018867924528\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000014\n",
      "  episode_reward_mean: 3.6414150943396315\n",
      "  episode_reward_min: -1.520000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 46619\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.193110685267\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013701907926352957\n",
      "          policy_loss: -0.06866432583898816\n",
      "          total_loss: 0.09365027222830133\n",
      "          vf_explained_var: 0.9367602467536926\n",
      "          vf_loss: 0.15303104614886717\n",
      "    num_agent_steps_sampled: 4288284\n",
      "    num_agent_steps_trained: 4288284\n",
      "    num_steps_sampled: 4288284\n",
      "    num_steps_trained: 4288284\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.57023255813952\n",
      "    ram_util_percent: 56.93534883720931\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556907275452252\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.937771322296825\n",
      "    mean_inference_ms: 2.8556416774340785\n",
      "    mean_raw_obs_processing_ms: 3.4462981431077906\n",
      "  time_since_restore: 66887.00014042854\n",
      "  time_this_iter_s: 150.8996479511261\n",
      "  time_total_s: 66887.00014042854\n",
      "  timers:\n",
      "    learn_throughput: 932.976\n",
      "    learn_time_ms: 10714.102\n",
      "    load_throughput: 91014.67\n",
      "    load_time_ms: 109.828\n",
      "    sample_throughput: 67.451\n",
      "    sample_time_ms: 148196.626\n",
      "    update_time_ms: 11.788\n",
      "  timestamp: 1636361312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4288284\n",
      "  training_iteration: 429\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   429</td><td style=\"text-align: right;\">           66887</td><td style=\"text-align: right;\">4288284</td><td style=\"text-align: right;\"> 3.64142</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">               -1.52</td><td style=\"text-align: right;\">           93.3302</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4298280\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-51-02\n",
      "  done: false\n",
      "  episode_len_mean: 93.06542056074767\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.23000000000001\n",
      "  episode_reward_mean: 3.7883177570093554\n",
      "  episode_reward_min: -1.4600000000000004\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 46726\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.187019762524173\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013534239433635464\n",
      "          policy_loss: -0.06821232407202578\n",
      "          total_loss: 0.0950972365700982\n",
      "          vf_explained_var: 0.9169899821281433\n",
      "          vf_loss: 0.154347067940821\n",
      "    num_agent_steps_sampled: 4298280\n",
      "    num_agent_steps_trained: 4298280\n",
      "    num_steps_sampled: 4298280\n",
      "    num_steps_trained: 4298280\n",
      "  iterations_since_restore: 430\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.7658878504673\n",
      "    ram_util_percent: 56.92056074766355\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559632679124841\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.937358776193975\n",
      "    mean_inference_ms: 2.8560420586676525\n",
      "    mean_raw_obs_processing_ms: 3.4459060754871955\n",
      "  time_since_restore: 67036.67847299576\n",
      "  time_this_iter_s: 149.67833256721497\n",
      "  time_total_s: 67036.67847299576\n",
      "  timers:\n",
      "    learn_throughput: 933.24\n",
      "    learn_time_ms: 10711.067\n",
      "    load_throughput: 91024.333\n",
      "    load_time_ms: 109.817\n",
      "    sample_throughput: 67.856\n",
      "    sample_time_ms: 147311.181\n",
      "    update_time_ms: 11.865\n",
      "  timestamp: 1636361462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4298280\n",
      "  training_iteration: 430\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   430</td><td style=\"text-align: right;\">         67036.7</td><td style=\"text-align: right;\">4298280</td><td style=\"text-align: right;\"> 3.78832</td><td style=\"text-align: right;\">               13.23</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           93.0654</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4308276\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-53-35\n",
      "  done: false\n",
      "  episode_len_mean: 95.51428571428572\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.750000000000018\n",
      "  episode_reward_mean: 4.0635238095238195\n",
      "  episode_reward_min: -1.590000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 46831\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.175864988310724\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01391946306409495\n",
      "          policy_loss: -0.06533067736010521\n",
      "          total_loss: 0.0901479318865344\n",
      "          vf_explained_var: 0.9427686333656311\n",
      "          vf_loss: 0.145526980721734\n",
      "    num_agent_steps_sampled: 4308276\n",
      "    num_agent_steps_trained: 4308276\n",
      "    num_steps_sampled: 4308276\n",
      "    num_steps_trained: 4308276\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.18532110091743\n",
      "    ram_util_percent: 56.90871559633028\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558818981532042\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93967100621403\n",
      "    mean_inference_ms: 2.8558107835489115\n",
      "    mean_raw_obs_processing_ms: 3.442355452479467\n",
      "  time_since_restore: 67189.3673093319\n",
      "  time_this_iter_s: 152.68883633613586\n",
      "  time_total_s: 67189.3673093319\n",
      "  timers:\n",
      "    learn_throughput: 933.046\n",
      "    learn_time_ms: 10713.298\n",
      "    load_throughput: 90788.376\n",
      "    load_time_ms: 110.102\n",
      "    sample_throughput: 67.707\n",
      "    sample_time_ms: 147635.138\n",
      "    update_time_ms: 12.333\n",
      "  timestamp: 1636361615\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4308276\n",
      "  training_iteration: 431\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   431</td><td style=\"text-align: right;\">         67189.4</td><td style=\"text-align: right;\">4308276</td><td style=\"text-align: right;\"> 4.06352</td><td style=\"text-align: right;\">               12.75</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           95.5143</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4318272\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-56-06\n",
      "  done: false\n",
      "  episode_len_mean: 94.81132075471699\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.480000000000016\n",
      "  episode_reward_mean: 4.067358490566049\n",
      "  episode_reward_min: -1.7000000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 46937\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.166742431811797\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01387244432253061\n",
      "          policy_loss: -0.06366099279660445\n",
      "          total_loss: 0.11707050474838186\n",
      "          vf_explained_var: 0.9281685948371887\n",
      "          vf_loss: 0.1707957598595665\n",
      "    num_agent_steps_sampled: 4318272\n",
      "    num_agent_steps_trained: 4318272\n",
      "    num_steps_sampled: 4318272\n",
      "    num_steps_trained: 4318272\n",
      "  iterations_since_restore: 432\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.84325581395349\n",
      "    ram_util_percent: 56.800000000000026\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045599092950974474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94131031517361\n",
      "    mean_inference_ms: 2.8558957516189616\n",
      "    mean_raw_obs_processing_ms: 3.4406558551905597\n",
      "  time_since_restore: 67340.23470067978\n",
      "  time_this_iter_s: 150.86739134788513\n",
      "  time_total_s: 67340.23470067978\n",
      "  timers:\n",
      "    learn_throughput: 932.786\n",
      "    learn_time_ms: 10716.281\n",
      "    load_throughput: 90807.371\n",
      "    load_time_ms: 110.079\n",
      "    sample_throughput: 68.345\n",
      "    sample_time_ms: 146257.568\n",
      "    update_time_ms: 13.01\n",
      "  timestamp: 1636361766\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4318272\n",
      "  training_iteration: 432\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   432</td><td style=\"text-align: right;\">         67340.2</td><td style=\"text-align: right;\">4318272</td><td style=\"text-align: right;\"> 4.06736</td><td style=\"text-align: right;\">               12.48</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           94.8113</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4328268\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_08-59-08\n",
      "  done: false\n",
      "  episode_len_mean: 93.1214953271028\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.59000000000002\n",
      "  episode_reward_mean: 3.4900934579439338\n",
      "  episode_reward_min: -2.130000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 47044\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.192212865087721\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012734463898041486\n",
      "          policy_loss: -0.0646487179506793\n",
      "          total_loss: 0.08126350987909568\n",
      "          vf_explained_var: 0.9369053244590759\n",
      "          vf_loss: 0.13882365578260178\n",
      "    num_agent_steps_sampled: 4328268\n",
      "    num_agent_steps_trained: 4328268\n",
      "    num_steps_sampled: 4328268\n",
      "    num_steps_trained: 4328268\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.39846153846155\n",
      "    ram_util_percent: 56.925\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559965747919558\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94237773229058\n",
      "    mean_inference_ms: 2.855757518317211\n",
      "    mean_raw_obs_processing_ms: 3.44654262509805\n",
      "  time_since_restore: 67522.48666524887\n",
      "  time_this_iter_s: 182.2519645690918\n",
      "  time_total_s: 67522.48666524887\n",
      "  timers:\n",
      "    learn_throughput: 931.76\n",
      "    learn_time_ms: 10728.082\n",
      "    load_throughput: 90740.589\n",
      "    load_time_ms: 110.16\n",
      "    sample_throughput: 67.07\n",
      "    sample_time_ms: 149037.782\n",
      "    update_time_ms: 12.895\n",
      "  timestamp: 1636361948\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4328268\n",
      "  training_iteration: 433\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   433</td><td style=\"text-align: right;\">         67522.5</td><td style=\"text-align: right;\">4328268</td><td style=\"text-align: right;\"> 3.49009</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">               -2.13</td><td style=\"text-align: right;\">           93.1215</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4338264\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-01-45\n",
      "  done: false\n",
      "  episode_len_mean: 93.18867924528301\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.820000000000014\n",
      "  episode_reward_mean: 3.932641509433972\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 47150\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1783532872159257\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012967397919042454\n",
      "          policy_loss: -0.06720937876524324\n",
      "          total_loss: 0.08648040374884239\n",
      "          vf_explained_var: 0.9349953532218933\n",
      "          vf_loss: 0.14593196065825784\n",
      "    num_agent_steps_sampled: 4338264\n",
      "    num_agent_steps_trained: 4338264\n",
      "    num_steps_sampled: 4338264\n",
      "    num_steps_trained: 4338264\n",
      "  iterations_since_restore: 434\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.31562499999998\n",
      "    ram_util_percent: 56.87901785714286\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554620455605453\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94064841550645\n",
      "    mean_inference_ms: 2.8558601294812593\n",
      "    mean_raw_obs_processing_ms: 3.443844086148411\n",
      "  time_since_restore: 67679.20213508606\n",
      "  time_this_iter_s: 156.71546983718872\n",
      "  time_total_s: 67679.20213508606\n",
      "  timers:\n",
      "    learn_throughput: 932.078\n",
      "    learn_time_ms: 10724.427\n",
      "    load_throughput: 90870.332\n",
      "    load_time_ms: 110.003\n",
      "    sample_throughput: 68.522\n",
      "    sample_time_ms: 145879.538\n",
      "    update_time_ms: 12.156\n",
      "  timestamp: 1636362105\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4338264\n",
      "  training_iteration: 434\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   434</td><td style=\"text-align: right;\">         67679.2</td><td style=\"text-align: right;\">4338264</td><td style=\"text-align: right;\"> 3.93264</td><td style=\"text-align: right;\">               12.82</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           93.1887</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4348260\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-04-47\n",
      "  done: false\n",
      "  episode_len_mean: 92.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.60000000000002\n",
      "  episode_reward_mean: 4.148545454545463\n",
      "  episode_reward_min: -1.4900000000000004\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 47260\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1753786580175416\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013980059869402768\n",
      "          policy_loss: -0.06712413228984572\n",
      "          total_loss: 0.09887256717197915\n",
      "          vf_explained_var: 0.9383128881454468\n",
      "          vf_loss: 0.15590216202231555\n",
      "    num_agent_steps_sampled: 4348260\n",
      "    num_agent_steps_trained: 4348260\n",
      "    num_steps_sampled: 4348260\n",
      "    num_steps_trained: 4348260\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.03653846153846\n",
      "    ram_util_percent: 56.92115384615385\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554907114636062\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93791992645185\n",
      "    mean_inference_ms: 2.855676042570076\n",
      "    mean_raw_obs_processing_ms: 3.4537093831812276\n",
      "  time_since_restore: 67861.70037388802\n",
      "  time_this_iter_s: 182.49823880195618\n",
      "  time_total_s: 67861.70037388802\n",
      "  timers:\n",
      "    learn_throughput: 932.104\n",
      "    learn_time_ms: 10724.126\n",
      "    load_throughput: 91025.637\n",
      "    load_time_ms: 109.815\n",
      "    sample_throughput: 67.548\n",
      "    sample_time_ms: 147984.22\n",
      "    update_time_ms: 13.056\n",
      "  timestamp: 1636362287\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4348260\n",
      "  training_iteration: 435\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   435</td><td style=\"text-align: right;\">         67861.7</td><td style=\"text-align: right;\">4348260</td><td style=\"text-align: right;\"> 4.14855</td><td style=\"text-align: right;\">                12.6</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">              92.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4358256\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-07-06\n",
      "  done: false\n",
      "  episode_len_mean: 95.1923076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.369999999999987\n",
      "  episode_reward_mean: 4.49576923076924\n",
      "  episode_reward_min: -1.6900000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 47364\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1567796422885013\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01296700605030532\n",
      "          policy_loss: -0.06770500835094952\n",
      "          total_loss: 0.08779809705944908\n",
      "          vf_explained_var: 0.9462521076202393\n",
      "          vf_loss: 0.14753044120903708\n",
      "    num_agent_steps_sampled: 4358256\n",
      "    num_agent_steps_trained: 4358256\n",
      "    num_steps_sampled: 4358256\n",
      "    num_steps_trained: 4358256\n",
      "  iterations_since_restore: 436\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96497461928935\n",
      "    ram_util_percent: 56.83756345177667\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455713211487683\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94029243111528\n",
      "    mean_inference_ms: 2.8558257068502564\n",
      "    mean_raw_obs_processing_ms: 3.4477410545570453\n",
      "  time_since_restore: 67999.94000768661\n",
      "  time_this_iter_s: 138.23963379859924\n",
      "  time_total_s: 67999.94000768661\n",
      "  timers:\n",
      "    learn_throughput: 932.001\n",
      "    learn_time_ms: 10725.313\n",
      "    load_throughput: 90807.135\n",
      "    load_time_ms: 110.079\n",
      "    sample_throughput: 68.737\n",
      "    sample_time_ms: 145422.916\n",
      "    update_time_ms: 13.727\n",
      "  timestamp: 1636362426\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4358256\n",
      "  training_iteration: 436\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   436</td><td style=\"text-align: right;\">         67999.9</td><td style=\"text-align: right;\">4358256</td><td style=\"text-align: right;\"> 4.49577</td><td style=\"text-align: right;\">               16.37</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           95.1923</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4368252\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-09-32\n",
      "  done: false\n",
      "  episode_len_mean: 96.03809523809524\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.19000000000001\n",
      "  episode_reward_mean: 4.060476190476201\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 47469\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.17539571248568\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013667290171904245\n",
      "          policy_loss: -0.06857536891156919\n",
      "          total_loss: 0.08989419804121822\n",
      "          vf_explained_var: 0.9333586096763611\n",
      "          vf_loss: 0.14908772806485748\n",
      "    num_agent_steps_sampled: 4368252\n",
      "    num_agent_steps_trained: 4368252\n",
      "    num_steps_sampled: 4368252\n",
      "    num_steps_trained: 4368252\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.76124401913874\n",
      "    ram_util_percent: 56.74928229665072\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555964422631847\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.938496710382005\n",
      "    mean_inference_ms: 2.8558424392011283\n",
      "    mean_raw_obs_processing_ms: 3.4452674733150457\n",
      "  time_since_restore: 68146.44939041138\n",
      "  time_this_iter_s: 146.50938272476196\n",
      "  time_total_s: 68146.44939041138\n",
      "  timers:\n",
      "    learn_throughput: 932.983\n",
      "    learn_time_ms: 10714.02\n",
      "    load_throughput: 90938.055\n",
      "    load_time_ms: 109.921\n",
      "    sample_throughput: 68.939\n",
      "    sample_time_ms: 144997.374\n",
      "    update_time_ms: 14.376\n",
      "  timestamp: 1636362572\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4368252\n",
      "  training_iteration: 437\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   437</td><td style=\"text-align: right;\">         68146.4</td><td style=\"text-align: right;\">4368252</td><td style=\"text-align: right;\"> 4.06048</td><td style=\"text-align: right;\">               11.19</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           96.0381</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4378248\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-12-20\n",
      "  done: false\n",
      "  episode_len_mean: 93.82242990654206\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.150000000000015\n",
      "  episode_reward_mean: 3.749813084112158\n",
      "  episode_reward_min: -1.4400000000000004\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 47576\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1619676767251432\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014028678336347569\n",
      "          policy_loss: -0.06591576064785576\n",
      "          total_loss: 0.10617317923018312\n",
      "          vf_explained_var: 0.9226055145263672\n",
      "          vf_loss: 0.1617495328761064\n",
      "    num_agent_steps_sampled: 4378248\n",
      "    num_agent_steps_trained: 4378248\n",
      "    num_steps_sampled: 4378248\n",
      "    num_steps_trained: 4378248\n",
      "  iterations_since_restore: 438\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.95666666666666\n",
      "    ram_util_percent: 56.96291666666668\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560593191034207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94044908078529\n",
      "    mean_inference_ms: 2.8558460103726344\n",
      "    mean_raw_obs_processing_ms: 3.44709973617962\n",
      "  time_since_restore: 68314.25021505356\n",
      "  time_this_iter_s: 167.8008246421814\n",
      "  time_total_s: 68314.25021505356\n",
      "  timers:\n",
      "    learn_throughput: 932.145\n",
      "    learn_time_ms: 10723.652\n",
      "    load_throughput: 90981.864\n",
      "    load_time_ms: 109.868\n",
      "    sample_throughput: 68.021\n",
      "    sample_time_ms: 146954.22\n",
      "    update_time_ms: 14.493\n",
      "  timestamp: 1636362740\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4378248\n",
      "  training_iteration: 438\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   438</td><td style=\"text-align: right;\">         68314.3</td><td style=\"text-align: right;\">4378248</td><td style=\"text-align: right;\"> 3.74981</td><td style=\"text-align: right;\">               12.15</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           93.8224</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4388244\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-14-50\n",
      "  done: false\n",
      "  episode_len_mean: 93.77142857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.450000000000019\n",
      "  episode_reward_mean: 3.970095238095247\n",
      "  episode_reward_min: -1.4700000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 47681\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.2031607874438293\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012837058459041222\n",
      "          policy_loss: -0.06792928827687716\n",
      "          total_loss: 0.11450096062647226\n",
      "          vf_explained_var: 0.9222427606582642\n",
      "          vf_loss: 0.17521743195720463\n",
      "    num_agent_steps_sampled: 4388244\n",
      "    num_agent_steps_trained: 4388244\n",
      "    num_steps_sampled: 4388244\n",
      "    num_steps_trained: 4388244\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.86244131455399\n",
      "    ram_util_percent: 56.9995305164319\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045554625873573125\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93879190273244\n",
      "    mean_inference_ms: 2.855861333390112\n",
      "    mean_raw_obs_processing_ms: 3.444997651086724\n",
      "  time_since_restore: 68463.90953612328\n",
      "  time_this_iter_s: 149.6593210697174\n",
      "  time_total_s: 68463.90953612328\n",
      "  timers:\n",
      "    learn_throughput: 932.28\n",
      "    learn_time_ms: 10722.096\n",
      "    load_throughput: 91268.87\n",
      "    load_time_ms: 109.523\n",
      "    sample_throughput: 68.077\n",
      "    sample_time_ms: 146833.877\n",
      "    update_time_ms: 12.346\n",
      "  timestamp: 1636362890\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4388244\n",
      "  training_iteration: 439\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   439</td><td style=\"text-align: right;\">         68463.9</td><td style=\"text-align: right;\">4388244</td><td style=\"text-align: right;\">  3.9701</td><td style=\"text-align: right;\">               12.45</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           93.7714</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4398240\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-17-22\n",
      "  done: false\n",
      "  episode_len_mean: 92.77064220183486\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.680000000000017\n",
      "  episode_reward_mean: 3.2693577981651463\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 47790\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.179918657714485\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012866413815329943\n",
      "          policy_loss: -0.06753905803984046\n",
      "          total_loss: 0.08321171440860718\n",
      "          vf_explained_var: 0.9243295788764954\n",
      "          vf_loss: 0.1432386591274323\n",
      "    num_agent_steps_sampled: 4398240\n",
      "    num_agent_steps_trained: 4398240\n",
      "    num_steps_sampled: 4398240\n",
      "    num_steps_trained: 4398240\n",
      "  iterations_since_restore: 440\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78709677419354\n",
      "    ram_util_percent: 56.9442396313364\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045577234144428894\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.940934181343074\n",
      "    mean_inference_ms: 2.855826280215569\n",
      "    mean_raw_obs_processing_ms: 3.4427535437618837\n",
      "  time_since_restore: 68615.91639375687\n",
      "  time_this_iter_s: 152.0068576335907\n",
      "  time_total_s: 68615.91639375687\n",
      "  timers:\n",
      "    learn_throughput: 932.759\n",
      "    learn_time_ms: 10716.59\n",
      "    load_throughput: 91266.605\n",
      "    load_time_ms: 109.525\n",
      "    sample_throughput: 67.967\n",
      "    sample_time_ms: 147070.524\n",
      "    update_time_ms: 13.225\n",
      "  timestamp: 1636363042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4398240\n",
      "  training_iteration: 440\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   440</td><td style=\"text-align: right;\">         68615.9</td><td style=\"text-align: right;\">4398240</td><td style=\"text-align: right;\"> 3.26936</td><td style=\"text-align: right;\">               12.68</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           92.7706</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4408236\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-20-06\n",
      "  done: false\n",
      "  episode_len_mean: 91.71296296296296\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.01000000000001\n",
      "  episode_reward_mean: 3.537037037037046\n",
      "  episode_reward_min: -1.620000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 47898\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1878037719645054\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013297375787935757\n",
      "          policy_loss: -0.06639728294446683\n",
      "          total_loss: 0.10310752287220497\n",
      "          vf_explained_var: 0.9300084114074707\n",
      "          vf_loss: 0.16108975840302614\n",
      "    num_agent_steps_sampled: 4408236\n",
      "    num_agent_steps_trained: 4408236\n",
      "    num_steps_sampled: 4408236\n",
      "    num_steps_trained: 4408236\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.74170212765956\n",
      "    ram_util_percent: 56.969787234042556\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558470413977659\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.940894013088894\n",
      "    mean_inference_ms: 2.855754181081906\n",
      "    mean_raw_obs_processing_ms: 3.4443901995965547\n",
      "  time_since_restore: 68780.27906823158\n",
      "  time_this_iter_s: 164.3626744747162\n",
      "  time_total_s: 68780.27906823158\n",
      "  timers:\n",
      "    learn_throughput: 932.633\n",
      "    learn_time_ms: 10718.045\n",
      "    load_throughput: 91373.198\n",
      "    load_time_ms: 109.398\n",
      "    sample_throughput: 67.433\n",
      "    sample_time_ms: 148236.253\n",
      "    update_time_ms: 13.385\n",
      "  timestamp: 1636363206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4408236\n",
      "  training_iteration: 441\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   441</td><td style=\"text-align: right;\">         68780.3</td><td style=\"text-align: right;\">4408236</td><td style=\"text-align: right;\"> 3.53704</td><td style=\"text-align: right;\">               11.01</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">            91.713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4418232\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-22-38\n",
      "  done: false\n",
      "  episode_len_mean: 92.35779816513761\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.77000000000002\n",
      "  episode_reward_mean: 3.9921100917431285\n",
      "  episode_reward_min: -1.2900000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 48007\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.164072797441075\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013408065369454042\n",
      "          policy_loss: -0.06746377328044584\n",
      "          total_loss: 0.09260771785759264\n",
      "          vf_explained_var: 0.9308831691741943\n",
      "          vf_loss: 0.1511669698656879\n",
      "    num_agent_steps_sampled: 4418232\n",
      "    num_agent_steps_trained: 4418232\n",
      "    num_steps_sampled: 4418232\n",
      "    num_steps_trained: 4418232\n",
      "  iterations_since_restore: 442\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.53824884792627\n",
      "    ram_util_percent: 57.00829493087557\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556238409853906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94102930276975\n",
      "    mean_inference_ms: 2.8555895126570063\n",
      "    mean_raw_obs_processing_ms: 3.4414274466835457\n",
      "  time_since_restore: 68932.35593008995\n",
      "  time_this_iter_s: 152.07686185836792\n",
      "  time_total_s: 68932.35593008995\n",
      "  timers:\n",
      "    learn_throughput: 933.295\n",
      "    learn_time_ms: 10710.444\n",
      "    load_throughput: 91550.794\n",
      "    load_time_ms: 109.185\n",
      "    sample_throughput: 67.374\n",
      "    sample_time_ms: 148364.916\n",
      "    update_time_ms: 13.182\n",
      "  timestamp: 1636363358\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4418232\n",
      "  training_iteration: 442\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   442</td><td style=\"text-align: right;\">         68932.4</td><td style=\"text-align: right;\">4418232</td><td style=\"text-align: right;\"> 3.99211</td><td style=\"text-align: right;\">               12.77</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           92.3578</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4428228\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 91.25688073394495\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.580000000000021\n",
      "  episode_reward_mean: 3.555688073394504\n",
      "  episode_reward_min: -1.4100000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 48116\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.177999690047696\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013288486839599222\n",
      "          policy_loss: -0.06265606842457484\n",
      "          total_loss: 0.10291515037210451\n",
      "          vf_explained_var: 0.9228453040122986\n",
      "          vf_loss: 0.1570783812775571\n",
      "    num_agent_steps_sampled: 4428228\n",
      "    num_agent_steps_trained: 4428228\n",
      "    num_steps_sampled: 4428228\n",
      "    num_steps_trained: 4428228\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.04170403587445\n",
      "    ram_util_percent: 57.00717488789237\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554662942289295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94374062231975\n",
      "    mean_inference_ms: 2.8555975678774645\n",
      "    mean_raw_obs_processing_ms: 3.4387836337195443\n",
      "  time_since_restore: 69089.03948807716\n",
      "  time_this_iter_s: 156.68355798721313\n",
      "  time_total_s: 69089.03948807716\n",
      "  timers:\n",
      "    learn_throughput: 934.09\n",
      "    learn_time_ms: 10701.33\n",
      "    load_throughput: 91562.47\n",
      "    load_time_ms: 109.171\n",
      "    sample_throughput: 68.551\n",
      "    sample_time_ms: 145817.63\n",
      "    update_time_ms: 12.793\n",
      "  timestamp: 1636363515\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4428228\n",
      "  training_iteration: 443\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   443</td><td style=\"text-align: right;\">           69089</td><td style=\"text-align: right;\">4428228</td><td style=\"text-align: right;\"> 3.55569</td><td style=\"text-align: right;\">               12.58</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           91.2569</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4438224\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-27-35\n",
      "  done: false\n",
      "  episode_len_mean: 94.97169811320755\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.740000000000016\n",
      "  episode_reward_mean: 3.5666981132075564\n",
      "  episode_reward_min: -1.880000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 48222\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.193759940832089\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013342025256412742\n",
      "          policy_loss: -0.06720376779269586\n",
      "          total_loss: 0.09824209016405491\n",
      "          vf_explained_var: 0.9239227771759033\n",
      "          vf_loss: 0.15698865495431116\n",
      "    num_agent_steps_sampled: 4438224\n",
      "    num_agent_steps_trained: 4438224\n",
      "    num_steps_sampled: 4438224\n",
      "    num_steps_trained: 4438224\n",
      "  iterations_since_restore: 444\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8825\n",
      "    ram_util_percent: 56.95199999999999\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556508525716243\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94691942566352\n",
      "    mean_inference_ms: 2.8560084971507202\n",
      "    mean_raw_obs_processing_ms: 3.434036577808807\n",
      "  time_since_restore: 69228.91135239601\n",
      "  time_this_iter_s: 139.87186431884766\n",
      "  time_total_s: 69228.91135239601\n",
      "  timers:\n",
      "    learn_throughput: 933.971\n",
      "    learn_time_ms: 10702.686\n",
      "    load_throughput: 91467.906\n",
      "    load_time_ms: 109.284\n",
      "    sample_throughput: 69.354\n",
      "    sample_time_ms: 144131.085\n",
      "    update_time_ms: 13.279\n",
      "  timestamp: 1636363655\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4438224\n",
      "  training_iteration: 444\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   444</td><td style=\"text-align: right;\">         69228.9</td><td style=\"text-align: right;\">4438224</td><td style=\"text-align: right;\">  3.5667</td><td style=\"text-align: right;\">               12.74</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           94.9717</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4448220\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-30-09\n",
      "  done: false\n",
      "  episode_len_mean: 90.59633027522936\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.010000000000018\n",
      "  episode_reward_mean: 3.7007339449541377\n",
      "  episode_reward_min: -1.3600000000000003\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 48331\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.171982989148197\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012791097308694967\n",
      "          policy_loss: -0.0684396517667999\n",
      "          total_loss: 0.08727104985115365\n",
      "          vf_explained_var: 0.9311335682868958\n",
      "          vf_loss: 0.14829081223529372\n",
      "    num_agent_steps_sampled: 4448220\n",
      "    num_agent_steps_trained: 4448220\n",
      "    num_steps_sampled: 4448220\n",
      "    num_steps_trained: 4448220\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.67214611872144\n",
      "    ram_util_percent: 56.81917808219179\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559260112164653\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94942493527351\n",
      "    mean_inference_ms: 2.855844550930167\n",
      "    mean_raw_obs_processing_ms: 3.435113973396888\n",
      "  time_since_restore: 69382.67568850517\n",
      "  time_this_iter_s: 153.76433610916138\n",
      "  time_total_s: 69382.67568850517\n",
      "  timers:\n",
      "    learn_throughput: 934.061\n",
      "    learn_time_ms: 10701.656\n",
      "    load_throughput: 91595.636\n",
      "    load_time_ms: 109.132\n",
      "    sample_throughput: 70.764\n",
      "    sample_time_ms: 141258.658\n",
      "    update_time_ms: 13.609\n",
      "  timestamp: 1636363809\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4448220\n",
      "  training_iteration: 445\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   445</td><td style=\"text-align: right;\">         69382.7</td><td style=\"text-align: right;\">4448220</td><td style=\"text-align: right;\"> 3.70073</td><td style=\"text-align: right;\">               12.01</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           90.5963</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4458216\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-33-00\n",
      "  done: false\n",
      "  episode_len_mean: 92.89814814814815\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.77000000000002\n",
      "  episode_reward_mean: 3.4184259259259346\n",
      "  episode_reward_min: -1.4500000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 48439\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.178596302892408\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013638855822247541\n",
      "          policy_loss: -0.06427897508136737\n",
      "          total_loss: 0.10580647760190261\n",
      "          vf_explained_var: 0.9163147211074829\n",
      "          vf_loss: 0.16080039736265556\n",
      "    num_agent_steps_sampled: 4458216\n",
      "    num_agent_steps_trained: 4458216\n",
      "    num_steps_sampled: 4458216\n",
      "    num_steps_trained: 4458216\n",
      "  iterations_since_restore: 446\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.00081967213113\n",
      "    ram_util_percent: 57.04672131147541\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045531476885765546\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.945111847195776\n",
      "    mean_inference_ms: 2.8558608513395436\n",
      "    mean_raw_obs_processing_ms: 3.438255017170878\n",
      "  time_since_restore: 69553.52702069283\n",
      "  time_this_iter_s: 170.8513321876526\n",
      "  time_total_s: 69553.52702069283\n",
      "  timers:\n",
      "    learn_throughput: 933.937\n",
      "    learn_time_ms: 10703.072\n",
      "    load_throughput: 91674.506\n",
      "    load_time_ms: 109.038\n",
      "    sample_throughput: 69.167\n",
      "    sample_time_ms: 144519.11\n",
      "    update_time_ms: 12.661\n",
      "  timestamp: 1636363980\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4458216\n",
      "  training_iteration: 446\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   446</td><td style=\"text-align: right;\">         69553.5</td><td style=\"text-align: right;\">4458216</td><td style=\"text-align: right;\"> 3.41843</td><td style=\"text-align: right;\">               10.77</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           92.8981</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4468212\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-35-30\n",
      "  done: false\n",
      "  episode_len_mean: 94.80188679245283\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.450000000000019\n",
      "  episode_reward_mean: 3.753962264150953\n",
      "  episode_reward_min: -1.639999999999999\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 48545\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.195798749393887\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01272178198987024\n",
      "          policy_loss: -0.06857214570403672\n",
      "          total_loss: 0.08040440315898094\n",
      "          vf_explained_var: 0.9299439787864685\n",
      "          vf_loss: 0.14195272574981307\n",
      "    num_agent_steps_sampled: 4468212\n",
      "    num_agent_steps_trained: 4468212\n",
      "    num_steps_sampled: 4468212\n",
      "    num_steps_trained: 4468212\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.8353488372093\n",
      "    ram_util_percent: 57.017209302325575\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557454405149523\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.946966940828055\n",
      "    mean_inference_ms: 2.8558478292412826\n",
      "    mean_raw_obs_processing_ms: 3.4353070854707366\n",
      "  time_since_restore: 69703.76356983185\n",
      "  time_this_iter_s: 150.23654913902283\n",
      "  time_total_s: 69703.76356983185\n",
      "  timers:\n",
      "    learn_throughput: 933.66\n",
      "    learn_time_ms: 10706.25\n",
      "    load_throughput: 91621.757\n",
      "    load_time_ms: 109.101\n",
      "    sample_throughput: 68.991\n",
      "    sample_time_ms: 144888.538\n",
      "    update_time_ms: 12.326\n",
      "  timestamp: 1636364130\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4468212\n",
      "  training_iteration: 447\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   447</td><td style=\"text-align: right;\">         69703.8</td><td style=\"text-align: right;\">4468212</td><td style=\"text-align: right;\"> 3.75396</td><td style=\"text-align: right;\">               14.45</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           94.8019</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4478208\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-38-17\n",
      "  done: false\n",
      "  episode_len_mean: 93.95283018867924\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000016\n",
      "  episode_reward_mean: 3.7257547169811396\n",
      "  episode_reward_min: -1.5200000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 48651\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1919232963496804\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01374582481210189\n",
      "          policy_loss: -0.06469867906700343\n",
      "          total_loss: 0.1198623973931958\n",
      "          vf_explained_var: 0.916352391242981\n",
      "          vf_loss: 0.17516560105877554\n",
      "    num_agent_steps_sampled: 4478208\n",
      "    num_agent_steps_trained: 4478208\n",
      "    num_steps_sampled: 4478208\n",
      "    num_steps_trained: 4478208\n",
      "  iterations_since_restore: 448\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.84243697478992\n",
      "    ram_util_percent: 57.04579831932774\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558219310775183\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.946033517024425\n",
      "    mean_inference_ms: 2.855984713954057\n",
      "    mean_raw_obs_processing_ms: 3.4374904561683826\n",
      "  time_since_restore: 69870.74655413628\n",
      "  time_this_iter_s: 166.9829843044281\n",
      "  time_total_s: 69870.74655413628\n",
      "  timers:\n",
      "    learn_throughput: 934.354\n",
      "    learn_time_ms: 10698.298\n",
      "    load_throughput: 91610.486\n",
      "    load_time_ms: 109.114\n",
      "    sample_throughput: 69.026\n",
      "    sample_time_ms: 144815.346\n",
      "    update_time_ms: 12.149\n",
      "  timestamp: 1636364297\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4478208\n",
      "  training_iteration: 448\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   448</td><td style=\"text-align: right;\">         69870.7</td><td style=\"text-align: right;\">4478208</td><td style=\"text-align: right;\"> 3.72575</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -1.52</td><td style=\"text-align: right;\">           93.9528</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4488204\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-40-36\n",
      "  done: false\n",
      "  episode_len_mean: 94.0377358490566\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.230000000000013\n",
      "  episode_reward_mean: 3.5731132075471788\n",
      "  episode_reward_min: -1.6100000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 48757\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.156036737637642\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01230572815979861\n",
      "          policy_loss: -0.0665735333489302\n",
      "          total_loss: 0.09751481816777562\n",
      "          vf_explained_var: 0.9201086163520813\n",
      "          vf_loss: 0.1576147316214748\n",
      "    num_agent_steps_sampled: 4488204\n",
      "    num_agent_steps_trained: 4488204\n",
      "    num_steps_sampled: 4488204\n",
      "    num_steps_trained: 4488204\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.91616161616162\n",
      "    ram_util_percent: 57.063131313131315\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045569021170631184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.9473970899643\n",
      "    mean_inference_ms: 2.856120675519174\n",
      "    mean_raw_obs_processing_ms: 3.431895095543483\n",
      "  time_since_restore: 70009.58456707001\n",
      "  time_this_iter_s: 138.83801293373108\n",
      "  time_total_s: 70009.58456707001\n",
      "  timers:\n",
      "    learn_throughput: 934.194\n",
      "    learn_time_ms: 10700.138\n",
      "    load_throughput: 91534.944\n",
      "    load_time_ms: 109.204\n",
      "    sample_throughput: 69.546\n",
      "    sample_time_ms: 143732.074\n",
      "    update_time_ms: 11.935\n",
      "  timestamp: 1636364436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4488204\n",
      "  training_iteration: 449\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   449</td><td style=\"text-align: right;\">         70009.6</td><td style=\"text-align: right;\">4488204</td><td style=\"text-align: right;\"> 3.57311</td><td style=\"text-align: right;\">               13.23</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           94.0377</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4498200\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-43-23\n",
      "  done: false\n",
      "  episode_len_mean: 91.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.370000000000019\n",
      "  episode_reward_mean: 3.6761818181818264\n",
      "  episode_reward_min: -1.4500000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 48867\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1816313391057855\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013009433533141709\n",
      "          policy_loss: -0.06878777051933556\n",
      "          total_loss: 0.07551064561320166\n",
      "          vf_explained_var: 0.9302858710289001\n",
      "          vf_loss: 0.1364776137850096\n",
      "    num_agent_steps_sampled: 4498200\n",
      "    num_agent_steps_trained: 4498200\n",
      "    num_steps_sampled: 4498200\n",
      "    num_steps_trained: 4498200\n",
      "  iterations_since_restore: 450\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.55355648535566\n",
      "    ram_util_percent: 56.96736401673639\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045583481604578036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.947648683093796\n",
      "    mean_inference_ms: 2.8558612699804002\n",
      "    mean_raw_obs_processing_ms: 3.4365027373597306\n",
      "  time_since_restore: 70176.95479154587\n",
      "  time_this_iter_s: 167.3702244758606\n",
      "  time_total_s: 70176.95479154587\n",
      "  timers:\n",
      "    learn_throughput: 933.129\n",
      "    learn_time_ms: 10712.349\n",
      "    load_throughput: 91531.886\n",
      "    load_time_ms: 109.208\n",
      "    sample_throughput: 68.816\n",
      "    sample_time_ms: 145257.726\n",
      "    update_time_ms: 10.836\n",
      "  timestamp: 1636364603\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4498200\n",
      "  training_iteration: 450\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   450</td><td style=\"text-align: right;\">           70177</td><td style=\"text-align: right;\">4498200</td><td style=\"text-align: right;\"> 3.67618</td><td style=\"text-align: right;\">               12.37</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">              91.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4508196\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-46-00\n",
      "  done: false\n",
      "  episode_len_mean: 91.64814814814815\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.18\n",
      "  episode_reward_mean: 3.6889814814814894\n",
      "  episode_reward_min: -0.9200000000000003\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 48975\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1795067383692817\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013161393425455291\n",
      "          policy_loss: -0.0657170192967368\n",
      "          total_loss: 0.10039707554233634\n",
      "          vf_explained_var: 0.9258984923362732\n",
      "          vf_loss: 0.15792586186056973\n",
      "    num_agent_steps_sampled: 4508196\n",
      "    num_agent_steps_trained: 4508196\n",
      "    num_steps_sampled: 4508196\n",
      "    num_steps_trained: 4508196\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.19375000000001\n",
      "    ram_util_percent: 56.950892857142854\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556933253262511\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94995656883004\n",
      "    mean_inference_ms: 2.8558603907019995\n",
      "    mean_raw_obs_processing_ms: 3.4383491981168484\n",
      "  time_since_restore: 70334.28758788109\n",
      "  time_this_iter_s: 157.33279633522034\n",
      "  time_total_s: 70334.28758788109\n",
      "  timers:\n",
      "    learn_throughput: 933.198\n",
      "    learn_time_ms: 10711.554\n",
      "    load_throughput: 91664.284\n",
      "    load_time_ms: 109.05\n",
      "    sample_throughput: 69.15\n",
      "    sample_time_ms: 144555.75\n",
      "    update_time_ms: 10.637\n",
      "  timestamp: 1636364760\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4508196\n",
      "  training_iteration: 451\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   451</td><td style=\"text-align: right;\">         70334.3</td><td style=\"text-align: right;\">4508196</td><td style=\"text-align: right;\"> 3.68898</td><td style=\"text-align: right;\">               16.18</td><td style=\"text-align: right;\">               -0.92</td><td style=\"text-align: right;\">           91.6481</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4518192\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-48-33\n",
      "  done: false\n",
      "  episode_len_mean: 92.89814814814815\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.610000000000015\n",
      "  episode_reward_mean: 4.281111111111121\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 49083\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.177280055763375\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013954038008514627\n",
      "          policy_loss: -0.06335406661925153\n",
      "          total_loss: 0.10593405546318008\n",
      "          vf_explained_var: 0.9407122135162354\n",
      "          vf_loss: 0.15927187871092405\n",
      "    num_agent_steps_sampled: 4518192\n",
      "    num_agent_steps_trained: 4518192\n",
      "    num_steps_sampled: 4518192\n",
      "    num_steps_trained: 4518192\n",
      "  iterations_since_restore: 452\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.0770642201835\n",
      "    ram_util_percent: 57.054128440366966\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558787720368767\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95330311509925\n",
      "    mean_inference_ms: 2.8558519186918576\n",
      "    mean_raw_obs_processing_ms: 3.4357950963998\n",
      "  time_since_restore: 70487.15053868294\n",
      "  time_this_iter_s: 152.86295080184937\n",
      "  time_total_s: 70487.15053868294\n",
      "  timers:\n",
      "    learn_throughput: 932.821\n",
      "    learn_time_ms: 10715.882\n",
      "    load_throughput: 91626.743\n",
      "    load_time_ms: 109.095\n",
      "    sample_throughput: 69.114\n",
      "    sample_time_ms: 144630.814\n",
      "    update_time_ms: 10.158\n",
      "  timestamp: 1636364913\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4518192\n",
      "  training_iteration: 452\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   452</td><td style=\"text-align: right;\">         70487.2</td><td style=\"text-align: right;\">4518192</td><td style=\"text-align: right;\"> 4.28111</td><td style=\"text-align: right;\">               12.61</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           92.8981</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4528188\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-51-41\n",
      "  done: false\n",
      "  episode_len_mean: 90.1891891891892\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.56999999999996\n",
      "  episode_reward_mean: 3.9883783783783864\n",
      "  episode_reward_min: -1.6400000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 49194\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1568512096364274\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013826834398871212\n",
      "          policy_loss: -0.06245097577189788\n",
      "          total_loss: 0.1225730956890262\n",
      "          vf_explained_var: 0.9323893189430237\n",
      "          vf_loss: 0.17509332531983526\n",
      "    num_agent_steps_sampled: 4528188\n",
      "    num_agent_steps_trained: 4528188\n",
      "    num_steps_sampled: 4528188\n",
      "    num_steps_trained: 4528188\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1134328358209\n",
      "    ram_util_percent: 57.02686567164179\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558298318653658\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94582449351715\n",
      "    mean_inference_ms: 2.8556352570799133\n",
      "    mean_raw_obs_processing_ms: 3.455444853733032\n",
      "  time_since_restore: 70674.31466603279\n",
      "  time_this_iter_s: 187.16412734985352\n",
      "  time_total_s: 70674.31466603279\n",
      "  timers:\n",
      "    learn_throughput: 932.986\n",
      "    learn_time_ms: 10713.984\n",
      "    load_throughput: 91662.761\n",
      "    load_time_ms: 109.052\n",
      "    sample_throughput: 67.687\n",
      "    sample_time_ms: 147680.663\n",
      "    update_time_ms: 9.99\n",
      "  timestamp: 1636365101\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4528188\n",
      "  training_iteration: 453\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   453</td><td style=\"text-align: right;\">         70674.3</td><td style=\"text-align: right;\">4528188</td><td style=\"text-align: right;\"> 3.98838</td><td style=\"text-align: right;\">               16.57</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           90.1892</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4538184\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-54-27\n",
      "  done: false\n",
      "  episode_len_mean: 93.06481481481481\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.52000000000002\n",
      "  episode_reward_mean: 4.058703703703713\n",
      "  episode_reward_min: -1.0500000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 49302\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1676534544708383\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013367489535963659\n",
      "          policy_loss: -0.06925862719838181\n",
      "          total_loss: 0.10015893798305565\n",
      "          vf_explained_var: 0.9446707367897034\n",
      "          vf_loss: 0.16064128613529297\n",
      "    num_agent_steps_sampled: 4538184\n",
      "    num_agent_steps_trained: 4538184\n",
      "    num_steps_sampled: 4538184\n",
      "    num_steps_trained: 4538184\n",
      "  iterations_since_restore: 454\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.37257383966242\n",
      "    ram_util_percent: 57.083122362869176\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557609047320463\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94475533095845\n",
      "    mean_inference_ms: 2.8558346509137724\n",
      "    mean_raw_obs_processing_ms: 3.4580889465431977\n",
      "  time_since_restore: 70840.73880839348\n",
      "  time_this_iter_s: 166.42414236068726\n",
      "  time_total_s: 70840.73880839348\n",
      "  timers:\n",
      "    learn_throughput: 933.114\n",
      "    learn_time_ms: 10712.521\n",
      "    load_throughput: 91604.421\n",
      "    load_time_ms: 109.121\n",
      "    sample_throughput: 66.49\n",
      "    sample_time_ms: 150337.868\n",
      "    update_time_ms: 9.737\n",
      "  timestamp: 1636365267\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4538184\n",
      "  training_iteration: 454\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   454</td><td style=\"text-align: right;\">         70840.7</td><td style=\"text-align: right;\">4538184</td><td style=\"text-align: right;\">  4.0587</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">               -1.05</td><td style=\"text-align: right;\">           93.0648</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4548180\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-57-01\n",
      "  done: false\n",
      "  episode_len_mean: 95.10576923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.270000000000016\n",
      "  episode_reward_mean: 3.4782692307692398\n",
      "  episode_reward_min: -1.6900000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 49406\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1642304462245385\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013612241328718752\n",
      "          policy_loss: -0.06779810783063245\n",
      "          total_loss: 0.10466771228796141\n",
      "          vf_explained_var: 0.9256669282913208\n",
      "          vf_loss: 0.16309773615664905\n",
      "    num_agent_steps_sampled: 4548180\n",
      "    num_agent_steps_trained: 4548180\n",
      "    num_steps_sampled: 4548180\n",
      "    num_steps_trained: 4548180\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.13863636363637\n",
      "    ram_util_percent: 57.17545454545455\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045565739534909534\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94514730183619\n",
      "    mean_inference_ms: 2.8558117510845373\n",
      "    mean_raw_obs_processing_ms: 3.4553137105324576\n",
      "  time_since_restore: 70995.1324133873\n",
      "  time_this_iter_s: 154.3936049938202\n",
      "  time_total_s: 70995.1324133873\n",
      "  timers:\n",
      "    learn_throughput: 932.896\n",
      "    learn_time_ms: 10715.017\n",
      "    load_throughput: 91449.511\n",
      "    load_time_ms: 109.306\n",
      "    sample_throughput: 66.463\n",
      "    sample_time_ms: 150399.153\n",
      "    update_time_ms: 8.481\n",
      "  timestamp: 1636365421\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4548180\n",
      "  training_iteration: 455\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   455</td><td style=\"text-align: right;\">         70995.1</td><td style=\"text-align: right;\">4548180</td><td style=\"text-align: right;\"> 3.47827</td><td style=\"text-align: right;\">               10.27</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           95.1058</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4558176\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_09-59-53\n",
      "  done: false\n",
      "  episode_len_mean: 90.46846846846847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.140000000000011\n",
      "  episode_reward_mean: 3.7809009009009085\n",
      "  episode_reward_min: -1.4700000000000009\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 49517\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.160636700014783\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013003329377736258\n",
      "          policy_loss: -0.0630716513364743\n",
      "          total_loss: 0.11079963290960425\n",
      "          vf_explained_var: 0.9098851084709167\n",
      "          vf_loss: 0.16585444221034265\n",
      "    num_agent_steps_sampled: 4558176\n",
      "    num_agent_steps_trained: 4558176\n",
      "    num_steps_sampled: 4558176\n",
      "    num_steps_trained: 4558176\n",
      "  iterations_since_restore: 456\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.77673469387756\n",
      "    ram_util_percent: 57.03877551020408\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556638207194536\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94738544452445\n",
      "    mean_inference_ms: 2.8557539669788783\n",
      "    mean_raw_obs_processing_ms: 3.4569743618702846\n",
      "  time_since_restore: 71166.89345002174\n",
      "  time_this_iter_s: 171.7610366344452\n",
      "  time_total_s: 71166.89345002174\n",
      "  timers:\n",
      "    learn_throughput: 933.067\n",
      "    learn_time_ms: 10713.057\n",
      "    load_throughput: 91249.165\n",
      "    load_time_ms: 109.546\n",
      "    sample_throughput: 66.422\n",
      "    sample_time_ms: 150491.937\n",
      "    update_time_ms: 8.674\n",
      "  timestamp: 1636365593\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4558176\n",
      "  training_iteration: 456\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   456</td><td style=\"text-align: right;\">         71166.9</td><td style=\"text-align: right;\">4558176</td><td style=\"text-align: right;\">  3.7809</td><td style=\"text-align: right;\">               13.14</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           90.4685</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4568172\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-02-39\n",
      "  done: false\n",
      "  episode_len_mean: 93.69158878504673\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 3.837570093457953\n",
      "  episode_reward_min: -1.3600000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 49624\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1655809645978814\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012969227266634624\n",
      "          policy_loss: -0.06960869274205632\n",
      "          total_loss: 0.09564008401531694\n",
      "          vf_explained_var: 0.9252680540084839\n",
      "          vf_loss: 0.1573590646044184\n",
      "    num_agent_steps_sampled: 4568172\n",
      "    num_agent_steps_trained: 4568172\n",
      "    num_steps_sampled: 4568172\n",
      "    num_steps_trained: 4568172\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.82658227848101\n",
      "    ram_util_percent: 56.937552742616035\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554121066484671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.944238026399525\n",
      "    mean_inference_ms: 2.8556304787252227\n",
      "    mean_raw_obs_processing_ms: 3.4619785395555103\n",
      "  time_since_restore: 71332.34196543694\n",
      "  time_this_iter_s: 165.44851541519165\n",
      "  time_total_s: 71332.34196543694\n",
      "  timers:\n",
      "    learn_throughput: 932.381\n",
      "    learn_time_ms: 10720.943\n",
      "    load_throughput: 91381.463\n",
      "    load_time_ms: 109.388\n",
      "    sample_throughput: 65.761\n",
      "    sample_time_ms: 152005.046\n",
      "    update_time_ms: 9.439\n",
      "  timestamp: 1636365759\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4568172\n",
      "  training_iteration: 457\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   457</td><td style=\"text-align: right;\">         71332.3</td><td style=\"text-align: right;\">4568172</td><td style=\"text-align: right;\"> 3.83757</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           93.6916</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4578168\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-05-18\n",
      "  done: false\n",
      "  episode_len_mean: 91.5229357798165\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.31000000000002\n",
      "  episode_reward_mean: 4.455137614678908\n",
      "  episode_reward_min: -1.4700000000000009\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 49733\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.146037627387251\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013476896330187187\n",
      "          policy_loss: -0.06610189945651934\n",
      "          total_loss: 0.09178093649669845\n",
      "          vf_explained_var: 0.9404269456863403\n",
      "          vf_loss: 0.14864115693216395\n",
      "    num_agent_steps_sampled: 4578168\n",
      "    num_agent_steps_trained: 4578168\n",
      "    num_steps_sampled: 4578168\n",
      "    num_steps_trained: 4578168\n",
      "  iterations_since_restore: 458\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.52466960352422\n",
      "    ram_util_percent: 57.081497797356825\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555212574384433\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94603654104976\n",
      "    mean_inference_ms: 2.855646154810228\n",
      "    mean_raw_obs_processing_ms: 3.461799151502263\n",
      "  time_since_restore: 71491.52818346024\n",
      "  time_this_iter_s: 159.18621802330017\n",
      "  time_total_s: 71491.52818346024\n",
      "  timers:\n",
      "    learn_throughput: 932.255\n",
      "    learn_time_ms: 10722.393\n",
      "    load_throughput: 91278.149\n",
      "    load_time_ms: 109.511\n",
      "    sample_throughput: 66.1\n",
      "    sample_time_ms: 151224.433\n",
      "    update_time_ms: 8.806\n",
      "  timestamp: 1636365918\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4578168\n",
      "  training_iteration: 458\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   458</td><td style=\"text-align: right;\">         71491.5</td><td style=\"text-align: right;\">4578168</td><td style=\"text-align: right;\"> 4.45514</td><td style=\"text-align: right;\">               12.31</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           91.5229</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4588164\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-07-48\n",
      "  done: false\n",
      "  episode_len_mean: 94.37142857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.920000000000012\n",
      "  episode_reward_mean: 3.9053333333333433\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 49838\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.160908337230356\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013554106554332906\n",
      "          policy_loss: -0.06868847772224336\n",
      "          total_loss: 0.0996706241972617\n",
      "          vf_explained_var: 0.9295716881752014\n",
      "          vf_loss: 0.15909023398422023\n",
      "    num_agent_steps_sampled: 4588164\n",
      "    num_agent_steps_trained: 4588164\n",
      "    num_steps_sampled: 4588164\n",
      "    num_steps_trained: 4588164\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.86028037383177\n",
      "    ram_util_percent: 57.09859813084113\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555928292729707\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94721696738232\n",
      "    mean_inference_ms: 2.8554942235250294\n",
      "    mean_raw_obs_processing_ms: 3.4590948253215865\n",
      "  time_since_restore: 71641.87707567215\n",
      "  time_this_iter_s: 150.34889221191406\n",
      "  time_total_s: 71641.87707567215\n",
      "  timers:\n",
      "    learn_throughput: 932.542\n",
      "    learn_time_ms: 10719.091\n",
      "    load_throughput: 91429.967\n",
      "    load_time_ms: 109.33\n",
      "    sample_throughput: 65.6\n",
      "    sample_time_ms: 152378.337\n",
      "    update_time_ms: 9.497\n",
      "  timestamp: 1636366068\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4588164\n",
      "  training_iteration: 459\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   459</td><td style=\"text-align: right;\">         71641.9</td><td style=\"text-align: right;\">4588164</td><td style=\"text-align: right;\"> 3.90533</td><td style=\"text-align: right;\">               10.92</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           94.3714</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4598160\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-10-38\n",
      "  done: false\n",
      "  episode_len_mean: 91.37272727272727\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.710000000000015\n",
      "  episode_reward_mean: 3.656545454545463\n",
      "  episode_reward_min: -1.4400000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 49948\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.16886640410138\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01280255129410899\n",
      "          policy_loss: -0.06778527485827605\n",
      "          total_loss: 0.09991732478125864\n",
      "          vf_explained_var: 0.9254178404808044\n",
      "          vf_loss: 0.16022545163177399\n",
      "    num_agent_steps_sampled: 4598160\n",
      "    num_agent_steps_trained: 4598160\n",
      "    num_steps_sampled: 4598160\n",
      "    num_steps_trained: 4598160\n",
      "  iterations_since_restore: 460\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.51404958677685\n",
      "    ram_util_percent: 57.075206611570245\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045609017190103775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94974757085921\n",
      "    mean_inference_ms: 2.8558567041540837\n",
      "    mean_raw_obs_processing_ms: 3.4626276042804163\n",
      "  time_since_restore: 71811.2223148346\n",
      "  time_this_iter_s: 169.34523916244507\n",
      "  time_total_s: 71811.2223148346\n",
      "  timers:\n",
      "    learn_throughput: 933.202\n",
      "    learn_time_ms: 10711.509\n",
      "    load_throughput: 91213.471\n",
      "    load_time_ms: 109.589\n",
      "    sample_throughput: 65.512\n",
      "    sample_time_ms: 152583.659\n",
      "    update_time_ms: 9.303\n",
      "  timestamp: 1636366238\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4598160\n",
      "  training_iteration: 460\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   460</td><td style=\"text-align: right;\">         71811.2</td><td style=\"text-align: right;\">4598160</td><td style=\"text-align: right;\"> 3.65655</td><td style=\"text-align: right;\">               12.71</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           91.3727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4608156\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-13-43\n",
      "  done: false\n",
      "  episode_len_mean: 89.45132743362832\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.43000000000001\n",
      "  episode_reward_mean: 3.653716814159301\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 50061\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.140358300698109\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013291239887731109\n",
      "          policy_loss: -0.06492210039072949\n",
      "          total_loss: 0.10723746806606013\n",
      "          vf_explained_var: 0.9310703277587891\n",
      "          vf_loss: 0.16328404530500754\n",
      "    num_agent_steps_sampled: 4608156\n",
      "    num_agent_steps_trained: 4608156\n",
      "    num_steps_sampled: 4608156\n",
      "    num_steps_trained: 4608156\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.42651515151516\n",
      "    ram_util_percent: 57.03522727272727\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555689039525876\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.9474602086808\n",
      "    mean_inference_ms: 2.855482011475246\n",
      "    mean_raw_obs_processing_ms: 3.470377129279977\n",
      "  time_since_restore: 71996.53817915916\n",
      "  time_this_iter_s: 185.3158643245697\n",
      "  time_total_s: 71996.53817915916\n",
      "  timers:\n",
      "    learn_throughput: 933.279\n",
      "    learn_time_ms: 10710.626\n",
      "    load_throughput: 91198.808\n",
      "    load_time_ms: 109.607\n",
      "    sample_throughput: 64.331\n",
      "    sample_time_ms: 155383.104\n",
      "    update_time_ms: 9.307\n",
      "  timestamp: 1636366423\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4608156\n",
      "  training_iteration: 461\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   461</td><td style=\"text-align: right;\">         71996.5</td><td style=\"text-align: right;\">4608156</td><td style=\"text-align: right;\"> 3.65372</td><td style=\"text-align: right;\">                9.43</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           89.4513</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4618152\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-16-04\n",
      "  done: false\n",
      "  episode_len_mean: 92.06542056074767\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.870000000000015\n",
      "  episode_reward_mean: 3.859813084112158\n",
      "  episode_reward_min: -1.4800000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 50168\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.164970399885096\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013840736585796569\n",
      "          policy_loss: -0.06550184281495137\n",
      "          total_loss: 0.11042094755058106\n",
      "          vf_explained_var: 0.9245805740356445\n",
      "          vf_loss: 0.16604156686454757\n",
      "    num_agent_steps_sampled: 4618152\n",
      "    num_agent_steps_trained: 4618152\n",
      "    num_steps_sampled: 4618152\n",
      "    num_steps_trained: 4618152\n",
      "  iterations_since_restore: 462\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.68656716417911\n",
      "    ram_util_percent: 57.07611940298507\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559219199589015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.951455285019414\n",
      "    mean_inference_ms: 2.8555501644329877\n",
      "    mean_raw_obs_processing_ms: 3.465217729462222\n",
      "  time_since_restore: 72137.52285385132\n",
      "  time_this_iter_s: 140.98467469215393\n",
      "  time_total_s: 72137.52285385132\n",
      "  timers:\n",
      "    learn_throughput: 933.398\n",
      "    learn_time_ms: 10709.261\n",
      "    load_throughput: 91077.721\n",
      "    load_time_ms: 109.752\n",
      "    sample_throughput: 64.826\n",
      "    sample_time_ms: 154197.028\n",
      "    update_time_ms: 8.679\n",
      "  timestamp: 1636366564\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4618152\n",
      "  training_iteration: 462\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   462</td><td style=\"text-align: right;\">         72137.5</td><td style=\"text-align: right;\">4618152</td><td style=\"text-align: right;\"> 3.85981</td><td style=\"text-align: right;\">               12.87</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           92.0654</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4628148\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-18-41\n",
      "  done: false\n",
      "  episode_len_mean: 92.53703703703704\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.040000000000012\n",
      "  episode_reward_mean: 3.894629629629639\n",
      "  episode_reward_min: -1.6300000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 50276\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1662290099339607\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013350180508105217\n",
      "          policy_loss: -0.06013648437065446\n",
      "          total_loss: 0.11678770604169267\n",
      "          vf_explained_var: 0.9293761849403381\n",
      "          vf_loss: 0.16817309990779966\n",
      "    num_agent_steps_sampled: 4628148\n",
      "    num_agent_steps_trained: 4628148\n",
      "    num_steps_sampled: 4628148\n",
      "    num_steps_trained: 4628148\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.31333333333333\n",
      "    ram_util_percent: 57.10355555555555\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554373278056141\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95168261261461\n",
      "    mean_inference_ms: 2.8555815544091225\n",
      "    mean_raw_obs_processing_ms: 3.4620107773617463\n",
      "  time_since_restore: 72294.60976624489\n",
      "  time_this_iter_s: 157.08691239356995\n",
      "  time_total_s: 72294.60976624489\n",
      "  timers:\n",
      "    learn_throughput: 932.771\n",
      "    learn_time_ms: 10716.457\n",
      "    load_throughput: 91151.639\n",
      "    load_time_ms: 109.663\n",
      "    sample_throughput: 66.119\n",
      "    sample_time_ms: 151182.143\n",
      "    update_time_ms: 8.803\n",
      "  timestamp: 1636366721\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4628148\n",
      "  training_iteration: 463\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   463</td><td style=\"text-align: right;\">         72294.6</td><td style=\"text-align: right;\">4628148</td><td style=\"text-align: right;\"> 3.89463</td><td style=\"text-align: right;\">               11.04</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">            92.537</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4638144\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-21-36\n",
      "  done: false\n",
      "  episode_len_mean: 90.64864864864865\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.040000000000024\n",
      "  episode_reward_mean: 3.874684684684693\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 50387\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1584084670767827\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012262471012156492\n",
      "          policy_loss: -0.06137523013843685\n",
      "          total_loss: 0.10451589904717591\n",
      "          vf_explained_var: 0.9095877408981323\n",
      "          vf_loss: 0.15953977034769506\n",
      "    num_agent_steps_sampled: 4638144\n",
      "    num_agent_steps_trained: 4638144\n",
      "    num_steps_sampled: 4638144\n",
      "    num_steps_trained: 4638144\n",
      "  iterations_since_restore: 464\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.34016064257028\n",
      "    ram_util_percent: 56.86746987951808\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04560203544910179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.954332545546194\n",
      "    mean_inference_ms: 2.8556033966699377\n",
      "    mean_raw_obs_processing_ms: 3.4669499583956607\n",
      "  time_since_restore: 72469.58299660683\n",
      "  time_this_iter_s: 174.97323036193848\n",
      "  time_total_s: 72469.58299660683\n",
      "  timers:\n",
      "    learn_throughput: 933.166\n",
      "    learn_time_ms: 10711.916\n",
      "    load_throughput: 91215.694\n",
      "    load_time_ms: 109.586\n",
      "    sample_throughput: 65.745\n",
      "    sample_time_ms: 152041.515\n",
      "    update_time_ms: 8.582\n",
      "  timestamp: 1636366896\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4638144\n",
      "  training_iteration: 464\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   464</td><td style=\"text-align: right;\">         72469.6</td><td style=\"text-align: right;\">4638144</td><td style=\"text-align: right;\"> 3.87468</td><td style=\"text-align: right;\">               12.04</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           90.6486</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4648140\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-24-23\n",
      "  done: false\n",
      "  episode_len_mean: 90.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.800000000000017\n",
      "  episode_reward_mean: 4.096727272727282\n",
      "  episode_reward_min: -1.4900000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 50497\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1338452131320267\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011843527935854848\n",
      "          policy_loss: -0.06517703703039476\n",
      "          total_loss: 0.0817809243981018\n",
      "          vf_explained_var: 0.9311550855636597\n",
      "          vf_loss: 0.1413153757221806\n",
      "    num_agent_steps_sampled: 4648140\n",
      "    num_agent_steps_trained: 4648140\n",
      "    num_steps_sampled: 4648140\n",
      "    num_steps_trained: 4648140\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.44999999999999\n",
      "    ram_util_percent: 57.163025210084015\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455525042191827\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95081479392938\n",
      "    mean_inference_ms: 2.855436648244963\n",
      "    mean_raw_obs_processing_ms: 3.4708085471962926\n",
      "  time_since_restore: 72636.30503726006\n",
      "  time_this_iter_s: 166.72204065322876\n",
      "  time_total_s: 72636.30503726006\n",
      "  timers:\n",
      "    learn_throughput: 933.195\n",
      "    learn_time_ms: 10711.582\n",
      "    load_throughput: 90975.152\n",
      "    load_time_ms: 109.876\n",
      "    sample_throughput: 65.217\n",
      "    sample_time_ms: 153273.74\n",
      "    update_time_ms: 9.127\n",
      "  timestamp: 1636367063\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4648140\n",
      "  training_iteration: 465\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   465</td><td style=\"text-align: right;\">         72636.3</td><td style=\"text-align: right;\">4648140</td><td style=\"text-align: right;\"> 4.09673</td><td style=\"text-align: right;\">                14.8</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">              90.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4658136\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-27-00\n",
      "  done: false\n",
      "  episode_len_mean: 89.28571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.15000000000001\n",
      "  episode_reward_mean: 4.0410714285714375\n",
      "  episode_reward_min: -1.3500000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 50609\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.143673924299387\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013211516966026765\n",
      "          policy_loss: -0.06277374599574723\n",
      "          total_loss: 0.08753540336003161\n",
      "          vf_explained_var: 0.9341976046562195\n",
      "          vf_loss: 0.1416484016001734\n",
      "    num_agent_steps_sampled: 4658136\n",
      "    num_agent_steps_trained: 4658136\n",
      "    num_steps_sampled: 4658136\n",
      "    num_steps_trained: 4658136\n",
      "  iterations_since_restore: 466\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.48755555555556\n",
      "    ram_util_percent: 57.09644444444445\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555453396276902\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95433043121034\n",
      "    mean_inference_ms: 2.8555640761500514\n",
      "    mean_raw_obs_processing_ms: 3.4689022221462738\n",
      "  time_since_restore: 72793.63423991203\n",
      "  time_this_iter_s: 157.32920265197754\n",
      "  time_total_s: 72793.63423991203\n",
      "  timers:\n",
      "    learn_throughput: 932.776\n",
      "    learn_time_ms: 10716.401\n",
      "    load_throughput: 91118.992\n",
      "    load_time_ms: 109.703\n",
      "    sample_throughput: 65.839\n",
      "    sample_time_ms: 151824.858\n",
      "    update_time_ms: 9.996\n",
      "  timestamp: 1636367220\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4658136\n",
      "  training_iteration: 466\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   466</td><td style=\"text-align: right;\">         72793.6</td><td style=\"text-align: right;\">4658136</td><td style=\"text-align: right;\"> 4.04107</td><td style=\"text-align: right;\">               13.15</td><td style=\"text-align: right;\">               -1.35</td><td style=\"text-align: right;\">           89.2857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4668132\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-29-46\n",
      "  done: false\n",
      "  episode_len_mean: 88.84955752212389\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.810000000000013\n",
      "  episode_reward_mean: 4.08654867256638\n",
      "  episode_reward_min: -1.4000000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 50722\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1077513232190386\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013103184825175397\n",
      "          policy_loss: -0.06451088701311149\n",
      "          total_loss: 0.1310163989328803\n",
      "          vf_explained_var: 0.9260838031768799\n",
      "          vf_loss: 0.1867541063242616\n",
      "    num_agent_steps_sampled: 4668132\n",
      "    num_agent_steps_trained: 4668132\n",
      "    num_steps_sampled: 4668132\n",
      "    num_steps_trained: 4668132\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.7902953586498\n",
      "    ram_util_percent: 57.00801687763712\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455774108689249\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95518079630357\n",
      "    mean_inference_ms: 2.8554945285950932\n",
      "    mean_raw_obs_processing_ms: 3.4746962070318155\n",
      "  time_since_restore: 72959.64255928993\n",
      "  time_this_iter_s: 166.00831937789917\n",
      "  time_total_s: 72959.64255928993\n",
      "  timers:\n",
      "    learn_throughput: 933.372\n",
      "    learn_time_ms: 10709.56\n",
      "    load_throughput: 91194.246\n",
      "    load_time_ms: 109.612\n",
      "    sample_throughput: 65.811\n",
      "    sample_time_ms: 151888.838\n",
      "    update_time_ms: 8.938\n",
      "  timestamp: 1636367386\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4668132\n",
      "  training_iteration: 467\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   467</td><td style=\"text-align: right;\">         72959.6</td><td style=\"text-align: right;\">4668132</td><td style=\"text-align: right;\"> 4.08655</td><td style=\"text-align: right;\">               14.81</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           88.8496</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4678128\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-32-22\n",
      "  done: false\n",
      "  episode_len_mean: 90.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.940000000000015\n",
      "  episode_reward_mean: 4.0310000000000095\n",
      "  episode_reward_min: -1.3700000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 50832\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1428655000833365\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012975541616002102\n",
      "          policy_loss: -0.06455867163932476\n",
      "          total_loss: 0.09301891850832945\n",
      "          vf_explained_var: 0.93223637342453\n",
      "          vf_loss: 0.1494463397221815\n",
      "    num_agent_steps_sampled: 4678128\n",
      "    num_agent_steps_trained: 4678128\n",
      "    num_steps_sampled: 4678128\n",
      "    num_steps_trained: 4678128\n",
      "  iterations_since_restore: 468\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.03153153153153\n",
      "    ram_util_percent: 57.07477477477476\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045560143374016995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95776440004467\n",
      "    mean_inference_ms: 2.855448428857993\n",
      "    mean_raw_obs_processing_ms: 3.4717681215533287\n",
      "  time_since_restore: 73115.55053567886\n",
      "  time_this_iter_s: 155.90797638893127\n",
      "  time_total_s: 73115.55053567886\n",
      "  timers:\n",
      "    learn_throughput: 933.085\n",
      "    learn_time_ms: 10712.849\n",
      "    load_throughput: 91457.351\n",
      "    load_time_ms: 109.297\n",
      "    sample_throughput: 65.955\n",
      "    sample_time_ms: 151556.814\n",
      "    update_time_ms: 10.053\n",
      "  timestamp: 1636367542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4678128\n",
      "  training_iteration: 468\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   468</td><td style=\"text-align: right;\">         73115.6</td><td style=\"text-align: right;\">4678128</td><td style=\"text-align: right;\">   4.031</td><td style=\"text-align: right;\">               12.94</td><td style=\"text-align: right;\">               -1.37</td><td style=\"text-align: right;\">              90.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4688124\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-34-43\n",
      "  done: false\n",
      "  episode_len_mean: 91.14678899082568\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.470000000000015\n",
      "  episode_reward_mean: 3.367339449541292\n",
      "  episode_reward_min: -1.4500000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 50941\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1379743695259092\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012795286065115291\n",
      "          policy_loss: -0.06510438378581888\n",
      "          total_loss: 0.10391335004510788\n",
      "          vf_explained_var: 0.9272468090057373\n",
      "          vf_loss: 0.16124821599397776\n",
      "    num_agent_steps_sampled: 4688124\n",
      "    num_agent_steps_trained: 4688124\n",
      "    num_steps_sampled: 4688124\n",
      "    num_steps_trained: 4688124\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88009950248757\n",
      "    ram_util_percent: 57.06268656716417\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558158526569083\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96231327255442\n",
      "    mean_inference_ms: 2.8556573508730247\n",
      "    mean_raw_obs_processing_ms: 3.466897849146398\n",
      "  time_since_restore: 73256.07808065414\n",
      "  time_this_iter_s: 140.52754497528076\n",
      "  time_total_s: 73256.07808065414\n",
      "  timers:\n",
      "    learn_throughput: 933.054\n",
      "    learn_time_ms: 10713.212\n",
      "    load_throughput: 91406.047\n",
      "    load_time_ms: 109.358\n",
      "    sample_throughput: 66.386\n",
      "    sample_time_ms: 150574.823\n",
      "    update_time_ms: 9.439\n",
      "  timestamp: 1636367683\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4688124\n",
      "  training_iteration: 469\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   469</td><td style=\"text-align: right;\">         73256.1</td><td style=\"text-align: right;\">4688124</td><td style=\"text-align: right;\"> 3.36734</td><td style=\"text-align: right;\">               10.47</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           91.1468</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4698120\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-37-22\n",
      "  done: false\n",
      "  episode_len_mean: 87.3913043478261\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.830000000000014\n",
      "  episode_reward_mean: 3.882695652173922\n",
      "  episode_reward_min: -1.5200000000000005\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 51056\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.120785379817343\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012595667414883086\n",
      "          policy_loss: -0.06361818275231326\n",
      "          total_loss: 0.11376962268597678\n",
      "          vf_explained_var: 0.93763667345047\n",
      "          vf_loss: 0.16990115309659487\n",
      "    num_agent_steps_sampled: 4698120\n",
      "    num_agent_steps_trained: 4698120\n",
      "    num_steps_sampled: 4698120\n",
      "    num_steps_trained: 4698120\n",
      "  iterations_since_restore: 470\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.73039647577092\n",
      "    ram_util_percent: 56.87180616740088\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554692572582943\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.964800540878464\n",
      "    mean_inference_ms: 2.8556197439448794\n",
      "    mean_raw_obs_processing_ms: 3.467788298814167\n",
      "  time_since_restore: 73415.4854722023\n",
      "  time_this_iter_s: 159.40739154815674\n",
      "  time_total_s: 73415.4854722023\n",
      "  timers:\n",
      "    learn_throughput: 933.083\n",
      "    learn_time_ms: 10712.872\n",
      "    load_throughput: 91613.689\n",
      "    load_time_ms: 109.11\n",
      "    sample_throughput: 66.827\n",
      "    sample_time_ms: 149581.048\n",
      "    update_time_ms: 9.746\n",
      "  timestamp: 1636367842\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4698120\n",
      "  training_iteration: 470\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   470</td><td style=\"text-align: right;\">         73415.5</td><td style=\"text-align: right;\">4698120</td><td style=\"text-align: right;\">  3.8827</td><td style=\"text-align: right;\">               10.83</td><td style=\"text-align: right;\">               -1.52</td><td style=\"text-align: right;\">           87.3913</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4708116\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-40-32\n",
      "  done: false\n",
      "  episode_len_mean: 86.91228070175438\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.78\n",
      "  episode_reward_mean: 4.490438596491238\n",
      "  episode_reward_min: -1.4200000000000004\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 51170\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1235311553009555\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013517456139090741\n",
      "          policy_loss: -0.06447497509801998\n",
      "          total_loss: 0.08833596034882925\n",
      "          vf_explained_var: 0.9453569650650024\n",
      "          vf_loss: 0.1432517914977084\n",
      "    num_agent_steps_sampled: 4708116\n",
      "    num_agent_steps_trained: 4708116\n",
      "    num_steps_sampled: 4708116\n",
      "    num_steps_trained: 4708116\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13616236162362\n",
      "    ram_util_percent: 56.87859778597785\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455763652257267\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.964185123430525\n",
      "    mean_inference_ms: 2.8555594859931612\n",
      "    mean_raw_obs_processing_ms: 3.4814595706307996\n",
      "  time_since_restore: 73605.17203569412\n",
      "  time_this_iter_s: 189.6865634918213\n",
      "  time_total_s: 73605.17203569412\n",
      "  timers:\n",
      "    learn_throughput: 933.254\n",
      "    learn_time_ms: 10710.912\n",
      "    load_throughput: 91509.071\n",
      "    load_time_ms: 109.235\n",
      "    sample_throughput: 66.632\n",
      "    sample_time_ms: 150018.982\n",
      "    update_time_ms: 10.077\n",
      "  timestamp: 1636368032\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4708116\n",
      "  training_iteration: 471\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   471</td><td style=\"text-align: right;\">         73605.2</td><td style=\"text-align: right;\">4708116</td><td style=\"text-align: right;\"> 4.49044</td><td style=\"text-align: right;\">               16.78</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           86.9123</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4718112\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 89.6283185840708\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000017\n",
      "  episode_reward_mean: 4.155309734513283\n",
      "  episode_reward_min: -1.2900000000000003\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 51283\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.133701386105301\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013777094876546875\n",
      "          policy_loss: -0.061777785427581805\n",
      "          total_loss: 0.12930268774557319\n",
      "          vf_explained_var: 0.9169219732284546\n",
      "          vf_loss: 0.18103154168392604\n",
      "    num_agent_steps_sampled: 4718112\n",
      "    num_agent_steps_trained: 4718112\n",
      "    num_steps_sampled: 4718112\n",
      "    num_steps_trained: 4718112\n",
      "  iterations_since_restore: 472\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.23365853658537\n",
      "    ram_util_percent: 57.034146341463405\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555989791498706\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.969157281914306\n",
      "    mean_inference_ms: 2.8554341432140404\n",
      "    mean_raw_obs_processing_ms: 3.474719067086911\n",
      "  time_since_restore: 73749.25443434715\n",
      "  time_this_iter_s: 144.0823986530304\n",
      "  time_total_s: 73749.25443434715\n",
      "  timers:\n",
      "    learn_throughput: 933.609\n",
      "    learn_time_ms: 10706.836\n",
      "    load_throughput: 91653.884\n",
      "    load_time_ms: 109.062\n",
      "    sample_throughput: 66.493\n",
      "    sample_time_ms: 150332.31\n",
      "    update_time_ms: 10.487\n",
      "  timestamp: 1636368176\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4718112\n",
      "  training_iteration: 472\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   472</td><td style=\"text-align: right;\">         73749.3</td><td style=\"text-align: right;\">4718112</td><td style=\"text-align: right;\"> 4.15531</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           89.6283</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4728108\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-45-34\n",
      "  done: false\n",
      "  episode_len_mean: 89.04464285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.030000000000012\n",
      "  episode_reward_mean: 4.1781250000000085\n",
      "  episode_reward_min: -1.5800000000000007\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 51395\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1305832088503065\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013296706005031212\n",
      "          policy_loss: -0.066083055951943\n",
      "          total_loss: 0.12839534296375563\n",
      "          vf_explained_var: 0.9249223470687866\n",
      "          vf_loss: 0.18549267247510262\n",
      "    num_agent_steps_sampled: 4728108\n",
      "    num_agent_steps_trained: 4728108\n",
      "    num_steps_sampled: 4728108\n",
      "    num_steps_trained: 4728108\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.39333333333333\n",
      "    ram_util_percent: 57.079555555555565\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559333633166162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97349781147137\n",
      "    mean_inference_ms: 2.855504806814537\n",
      "    mean_raw_obs_processing_ms: 3.473502231138714\n",
      "  time_since_restore: 73906.94612622261\n",
      "  time_this_iter_s: 157.69169187545776\n",
      "  time_total_s: 73906.94612622261\n",
      "  timers:\n",
      "    learn_throughput: 934.583\n",
      "    learn_time_ms: 10695.683\n",
      "    load_throughput: 91505.057\n",
      "    load_time_ms: 109.24\n",
      "    sample_throughput: 66.461\n",
      "    sample_time_ms: 150403.036\n",
      "    update_time_ms: 11.246\n",
      "  timestamp: 1636368334\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4728108\n",
      "  training_iteration: 473\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   473</td><td style=\"text-align: right;\">         73906.9</td><td style=\"text-align: right;\">4728108</td><td style=\"text-align: right;\"> 4.17813</td><td style=\"text-align: right;\">               13.03</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           89.0446</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4738104\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-48-22\n",
      "  done: false\n",
      "  episode_len_mean: 90.68181818181819\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.090000000000012\n",
      "  episode_reward_mean: 4.081818181818192\n",
      "  episode_reward_min: -1.3300000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 51505\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.132609485866677\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014075651427993744\n",
      "          policy_loss: -0.06134442587215931\n",
      "          total_loss: 0.15628946418197365\n",
      "          vf_explained_var: 0.9149696826934814\n",
      "          vf_loss: 0.20689389033036099\n",
      "    num_agent_steps_sampled: 4738104\n",
      "    num_agent_steps_trained: 4738104\n",
      "    num_steps_sampled: 4738104\n",
      "    num_steps_trained: 4738104\n",
      "  iterations_since_restore: 474\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.55208333333333\n",
      "    ram_util_percent: 56.935833333333335\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556712502169965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97453827789586\n",
      "    mean_inference_ms: 2.855546056406124\n",
      "    mean_raw_obs_processing_ms: 3.474462122904654\n",
      "  time_since_restore: 74074.85113763809\n",
      "  time_this_iter_s: 167.90501141548157\n",
      "  time_total_s: 74074.85113763809\n",
      "  timers:\n",
      "    learn_throughput: 933.896\n",
      "    learn_time_ms: 10703.547\n",
      "    load_throughput: 91495.472\n",
      "    load_time_ms: 109.251\n",
      "    sample_throughput: 66.779\n",
      "    sample_time_ms: 149688.408\n",
      "    update_time_ms: 11.308\n",
      "  timestamp: 1636368502\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4738104\n",
      "  training_iteration: 474\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   474</td><td style=\"text-align: right;\">         74074.9</td><td style=\"text-align: right;\">4738104</td><td style=\"text-align: right;\"> 4.08182</td><td style=\"text-align: right;\">               11.09</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">           90.6818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4748100\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-50-54\n",
      "  done: false\n",
      "  episode_len_mean: 90.17117117117117\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.110000000000014\n",
      "  episode_reward_mean: 3.9070270270270364\n",
      "  episode_reward_min: -1.3200000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 51616\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1529773223094453\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011825928042510314\n",
      "          policy_loss: -0.06845026857291277\n",
      "          total_loss: 0.07869347001497562\n",
      "          vf_explained_var: 0.9398617148399353\n",
      "          vf_loss: 0.1417325693429408\n",
      "    num_agent_steps_sampled: 4748100\n",
      "    num_agent_steps_trained: 4748100\n",
      "    num_steps_sampled: 4748100\n",
      "    num_steps_trained: 4748100\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.87926267281108\n",
      "    ram_util_percent: 57.136866359447\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455764621272691\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97707767571118\n",
      "    mean_inference_ms: 2.8556314367061604\n",
      "    mean_raw_obs_processing_ms: 3.4727639472189247\n",
      "  time_since_restore: 74227.21803092957\n",
      "  time_this_iter_s: 152.3668932914734\n",
      "  time_total_s: 74227.21803092957\n",
      "  timers:\n",
      "    learn_throughput: 934.51\n",
      "    learn_time_ms: 10696.519\n",
      "    load_throughput: 91653.624\n",
      "    load_time_ms: 109.063\n",
      "    sample_throughput: 67.422\n",
      "    sample_time_ms: 148260.609\n",
      "    update_time_ms: 10.911\n",
      "  timestamp: 1636368654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4748100\n",
      "  training_iteration: 475\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   475</td><td style=\"text-align: right;\">         74227.2</td><td style=\"text-align: right;\">4748100</td><td style=\"text-align: right;\"> 3.90703</td><td style=\"text-align: right;\">               13.11</td><td style=\"text-align: right;\">               -1.32</td><td style=\"text-align: right;\">           90.1712</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4758096\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-53-32\n",
      "  done: false\n",
      "  episode_len_mean: 88.64035087719299\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.580000000000013\n",
      "  episode_reward_mean: 3.7858771929824644\n",
      "  episode_reward_min: -1.7900000000000007\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 51730\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1270130341888493\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012846018203173538\n",
      "          policy_loss: -0.06326687233442935\n",
      "          total_loss: 0.10926288186898853\n",
      "          vf_explained_var: 0.9253146648406982\n",
      "          vf_loss: 0.164535049130965\n",
      "    num_agent_steps_sampled: 4758096\n",
      "    num_agent_steps_trained: 4758096\n",
      "    num_steps_sampled: 4758096\n",
      "    num_steps_trained: 4758096\n",
      "  iterations_since_restore: 476\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.32133333333333\n",
      "    ram_util_percent: 57.05599999999999\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556846214421503\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98080850769122\n",
      "    mean_inference_ms: 2.8555248750262763\n",
      "    mean_raw_obs_processing_ms: 3.473417100000581\n",
      "  time_since_restore: 74384.61801099777\n",
      "  time_this_iter_s: 157.3999800682068\n",
      "  time_total_s: 74384.61801099777\n",
      "  timers:\n",
      "    learn_throughput: 934.434\n",
      "    learn_time_ms: 10697.388\n",
      "    load_throughput: 91759.316\n",
      "    load_time_ms: 108.937\n",
      "    sample_throughput: 67.419\n",
      "    sample_time_ms: 148267.523\n",
      "    update_time_ms: 10.538\n",
      "  timestamp: 1636368812\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4758096\n",
      "  training_iteration: 476\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   476</td><td style=\"text-align: right;\">         74384.6</td><td style=\"text-align: right;\">4758096</td><td style=\"text-align: right;\"> 3.78588</td><td style=\"text-align: right;\">               10.58</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           88.6404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4768092\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-56-21\n",
      "  done: false\n",
      "  episode_len_mean: 89.67272727272727\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.000000000000012\n",
      "  episode_reward_mean: 4.1999090909091\n",
      "  episode_reward_min: -1.7000000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 51840\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1106501101428625\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012841942657539376\n",
      "          policy_loss: -0.06360638247022772\n",
      "          total_loss: 0.10444477772196899\n",
      "          vf_explained_var: 0.9305068254470825\n",
      "          vf_loss: 0.15990211044271022\n",
      "    num_agent_steps_sampled: 4768092\n",
      "    num_agent_steps_trained: 4768092\n",
      "    num_steps_sampled: 4768092\n",
      "    num_steps_trained: 4768092\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.24398340248963\n",
      "    ram_util_percent: 56.93236514522822\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045556526525981834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.982849247850574\n",
      "    mean_inference_ms: 2.855415264534568\n",
      "    mean_raw_obs_processing_ms: 3.4743487640965762\n",
      "  time_since_restore: 74553.35854530334\n",
      "  time_this_iter_s: 168.7405343055725\n",
      "  time_total_s: 74553.35854530334\n",
      "  timers:\n",
      "    learn_throughput: 934.856\n",
      "    learn_time_ms: 10692.553\n",
      "    load_throughput: 91543.218\n",
      "    load_time_ms: 109.194\n",
      "    sample_throughput: 67.293\n",
      "    sample_time_ms: 148544.573\n",
      "    update_time_ms: 11.491\n",
      "  timestamp: 1636368981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4768092\n",
      "  training_iteration: 477\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   477</td><td style=\"text-align: right;\">         74553.4</td><td style=\"text-align: right;\">4768092</td><td style=\"text-align: right;\"> 4.19991</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           89.6727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4778088\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_10-58-43\n",
      "  done: false\n",
      "  episode_len_mean: 89.78571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.900000000000013\n",
      "  episode_reward_mean: 3.9608035714285803\n",
      "  episode_reward_min: -0.9900000000000003\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 51952\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.124086292177184\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013272330863105957\n",
      "          policy_loss: -0.06476323477064187\n",
      "          total_loss: 0.10886911360037504\n",
      "          vf_explained_var: 0.9256473779678345\n",
      "          vf_loss: 0.1646371808492093\n",
      "    num_agent_steps_sampled: 4778088\n",
      "    num_agent_steps_trained: 4778088\n",
      "    num_steps_sampled: 4778088\n",
      "    num_steps_trained: 4778088\n",
      "  iterations_since_restore: 478\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.83578431372548\n",
      "    ram_util_percent: 57.093627450980385\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455741913590025\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98796284175926\n",
      "    mean_inference_ms: 2.855615347455875\n",
      "    mean_raw_obs_processing_ms: 3.469730932961336\n",
      "  time_since_restore: 74696.19326019287\n",
      "  time_this_iter_s: 142.83471488952637\n",
      "  time_total_s: 74696.19326019287\n",
      "  timers:\n",
      "    learn_throughput: 935.473\n",
      "    learn_time_ms: 10685.499\n",
      "    load_throughput: 91593.435\n",
      "    load_time_ms: 109.134\n",
      "    sample_throughput: 67.887\n",
      "    sample_time_ms: 147244.66\n",
      "    update_time_ms: 11.162\n",
      "  timestamp: 1636369123\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4778088\n",
      "  training_iteration: 478\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   478</td><td style=\"text-align: right;\">         74696.2</td><td style=\"text-align: right;\">4778088</td><td style=\"text-align: right;\">  3.9608</td><td style=\"text-align: right;\">                12.9</td><td style=\"text-align: right;\">               -0.99</td><td style=\"text-align: right;\">           89.7857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4788084\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-01-11\n",
      "  done: false\n",
      "  episode_len_mean: 89.35135135135135\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.890000000000011\n",
      "  episode_reward_mean: 4.010090090090098\n",
      "  episode_reward_min: -1.3700000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 52063\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.130750102365119\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012663499350057688\n",
      "          policy_loss: -0.06289129646606426\n",
      "          total_loss: 0.11546034041441913\n",
      "          vf_explained_var: 0.9413130879402161\n",
      "          vf_loss: 0.17081010264909674\n",
      "    num_agent_steps_sampled: 4788084\n",
      "    num_agent_steps_trained: 4788084\n",
      "    num_steps_sampled: 4788084\n",
      "    num_steps_trained: 4788084\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08476190476192\n",
      "    ram_util_percent: 57.09428571428571\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557904394199156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99435521148761\n",
      "    mean_inference_ms: 2.855590723159724\n",
      "    mean_raw_obs_processing_ms: 3.4636103284650552\n",
      "  time_since_restore: 74843.2874147892\n",
      "  time_this_iter_s: 147.09415459632874\n",
      "  time_total_s: 74843.2874147892\n",
      "  timers:\n",
      "    learn_throughput: 934.635\n",
      "    learn_time_ms: 10695.083\n",
      "    load_throughput: 91645.75\n",
      "    load_time_ms: 109.072\n",
      "    sample_throughput: 67.59\n",
      "    sample_time_ms: 147891.472\n",
      "    update_time_ms: 11.193\n",
      "  timestamp: 1636369271\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4788084\n",
      "  training_iteration: 479\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   479</td><td style=\"text-align: right;\">         74843.3</td><td style=\"text-align: right;\">4788084</td><td style=\"text-align: right;\"> 4.01009</td><td style=\"text-align: right;\">               14.89</td><td style=\"text-align: right;\">               -1.37</td><td style=\"text-align: right;\">           89.3514</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4798080\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-04-01\n",
      "  done: false\n",
      "  episode_len_mean: 87.57391304347826\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.650000000000015\n",
      "  episode_reward_mean: 3.868086956521748\n",
      "  episode_reward_min: -1.5300000000000007\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 52178\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.151420757199964\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011874534800408953\n",
      "          policy_loss: -0.06646596379737314\n",
      "          total_loss: 0.09116730711255701\n",
      "          vf_explained_var: 0.9237534999847412\n",
      "          vf_loss: 0.15209580180195406\n",
      "    num_agent_steps_sampled: 4798080\n",
      "    num_agent_steps_trained: 4798080\n",
      "    num_steps_sampled: 4798080\n",
      "    num_steps_trained: 4798080\n",
      "  iterations_since_restore: 480\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.62962962962963\n",
      "    ram_util_percent: 56.90370370370371\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554531250140918\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99459278921655\n",
      "    mean_inference_ms: 2.85544783399253\n",
      "    mean_raw_obs_processing_ms: 3.4678704882450573\n",
      "  time_since_restore: 75013.97409296036\n",
      "  time_this_iter_s: 170.68667817115784\n",
      "  time_total_s: 75013.97409296036\n",
      "  timers:\n",
      "    learn_throughput: 934.506\n",
      "    learn_time_ms: 10696.564\n",
      "    load_throughput: 91368.0\n",
      "    load_time_ms: 109.404\n",
      "    sample_throughput: 67.079\n",
      "    sample_time_ms: 149017.507\n",
      "    update_time_ms: 11.428\n",
      "  timestamp: 1636369441\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4798080\n",
      "  training_iteration: 480\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   480</td><td style=\"text-align: right;\">           75014</td><td style=\"text-align: right;\">4798080</td><td style=\"text-align: right;\"> 3.86809</td><td style=\"text-align: right;\">               10.65</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">           87.5739</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4808076\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-06-43\n",
      "  done: false\n",
      "  episode_len_mean: 90.83636363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.100000000000017\n",
      "  episode_reward_mean: 3.846545454545464\n",
      "  episode_reward_min: -2.34\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 52288\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.125219185331948\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013407694139478003\n",
      "          policy_loss: -0.06299885592988541\n",
      "          total_loss: 0.11285757099349912\n",
      "          vf_explained_var: 0.938420832157135\n",
      "          vf_loss: 0.16656421476608924\n",
      "    num_agent_steps_sampled: 4808076\n",
      "    num_agent_steps_trained: 4808076\n",
      "    num_steps_sampled: 4808076\n",
      "    num_steps_trained: 4808076\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.38441558441559\n",
      "    ram_util_percent: 57.1961038961039\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555335315950048\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99457876709227\n",
      "    mean_inference_ms: 2.8554707132507224\n",
      "    mean_raw_obs_processing_ms: 3.4691929515167064\n",
      "  time_since_restore: 75175.8253633976\n",
      "  time_this_iter_s: 161.8512704372406\n",
      "  time_total_s: 75175.8253633976\n",
      "  timers:\n",
      "    learn_throughput: 934.463\n",
      "    learn_time_ms: 10697.058\n",
      "    load_throughput: 91413.301\n",
      "    load_time_ms: 109.35\n",
      "    sample_throughput: 68.356\n",
      "    sample_time_ms: 146234.421\n",
      "    update_time_ms: 11.205\n",
      "  timestamp: 1636369603\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4808076\n",
      "  training_iteration: 481\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   481</td><td style=\"text-align: right;\">         75175.8</td><td style=\"text-align: right;\">4808076</td><td style=\"text-align: right;\"> 3.84655</td><td style=\"text-align: right;\">                12.1</td><td style=\"text-align: right;\">               -2.34</td><td style=\"text-align: right;\">           90.8364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4818072\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-09-19\n",
      "  done: false\n",
      "  episode_len_mean: 90.03603603603604\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000017\n",
      "  episode_reward_mean: 4.345495495495506\n",
      "  episode_reward_min: -1.4800000000000004\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 52399\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1300369053824335\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013861023372420534\n",
      "          policy_loss: -0.0637483601943932\n",
      "          total_loss: 0.12870579321797077\n",
      "          vf_explained_var: 0.933076024055481\n",
      "          vf_loss: 0.18217737818789534\n",
      "    num_agent_steps_sampled: 4818072\n",
      "    num_agent_steps_trained: 4818072\n",
      "    num_steps_sampled: 4818072\n",
      "    num_steps_trained: 4818072\n",
      "  iterations_since_restore: 482\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.65650224215247\n",
      "    ram_util_percent: 57.18744394618833\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045567482393582805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99724331101276\n",
      "    mean_inference_ms: 2.8553246129009406\n",
      "    mean_raw_obs_processing_ms: 3.4669616688957055\n",
      "  time_since_restore: 75331.95740652084\n",
      "  time_this_iter_s: 156.13204312324524\n",
      "  time_total_s: 75331.95740652084\n",
      "  timers:\n",
      "    learn_throughput: 934.481\n",
      "    learn_time_ms: 10696.847\n",
      "    load_throughput: 91262.711\n",
      "    load_time_ms: 109.53\n",
      "    sample_throughput: 67.797\n",
      "    sample_time_ms: 147439.406\n",
      "    update_time_ms: 11.532\n",
      "  timestamp: 1636369759\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4818072\n",
      "  training_iteration: 482\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   482</td><td style=\"text-align: right;\">           75332</td><td style=\"text-align: right;\">4818072</td><td style=\"text-align: right;\">  4.3455</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">            90.036</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4828068\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-11-58\n",
      "  done: false\n",
      "  episode_len_mean: 88.98214285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.930000000000012\n",
      "  episode_reward_mean: 3.5931250000000086\n",
      "  episode_reward_min: -2.0400000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 52511\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1235514255670402\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012664122866219487\n",
      "          policy_loss: -0.06453496689597765\n",
      "          total_loss: 0.11062305758778866\n",
      "          vf_explained_var: 0.9200646281242371\n",
      "          vf_loss: 0.1675430819646925\n",
      "    num_agent_steps_sampled: 4828068\n",
      "    num_agent_steps_trained: 4828068\n",
      "    num_steps_sampled: 4828068\n",
      "    num_steps_trained: 4828068\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.7237885462555\n",
      "    ram_util_percent: 57.1057268722467\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557145339911196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0010895814733\n",
      "    mean_inference_ms: 2.8556075181559595\n",
      "    mean_raw_obs_processing_ms: 3.466088581440577\n",
      "  time_since_restore: 75491.00737595558\n",
      "  time_this_iter_s: 159.04996943473816\n",
      "  time_total_s: 75491.00737595558\n",
      "  timers:\n",
      "    learn_throughput: 934.207\n",
      "    learn_time_ms: 10699.984\n",
      "    load_throughput: 91393.235\n",
      "    load_time_ms: 109.374\n",
      "    sample_throughput: 67.736\n",
      "    sample_time_ms: 147572.748\n",
      "    update_time_ms: 11.159\n",
      "  timestamp: 1636369918\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4828068\n",
      "  training_iteration: 483\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   483</td><td style=\"text-align: right;\">           75491</td><td style=\"text-align: right;\">4828068</td><td style=\"text-align: right;\"> 3.59313</td><td style=\"text-align: right;\">               10.93</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           88.9821</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4838064\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-14-38\n",
      "  done: false\n",
      "  episode_len_mean: 87.85964912280701\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.690000000000014\n",
      "  episode_reward_mean: 3.4891228070175524\n",
      "  episode_reward_min: -1.3800000000000006\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 52625\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.106908911313766\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013660442315372388\n",
      "          policy_loss: -0.06414299761223742\n",
      "          total_loss: 0.12691934530774499\n",
      "          vf_explained_var: 0.9160206317901611\n",
      "          vf_loss: 0.18101123401847405\n",
      "    num_agent_steps_sampled: 4838064\n",
      "    num_agent_steps_trained: 4838064\n",
      "    num_steps_sampled: 4838064\n",
      "    num_steps_trained: 4838064\n",
      "  iterations_since_restore: 484\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78157894736843\n",
      "    ram_util_percent: 57.09649122807018\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554700588085985\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.004982819456366\n",
      "    mean_inference_ms: 2.855634334489331\n",
      "    mean_raw_obs_processing_ms: 3.463538406652386\n",
      "  time_since_restore: 75650.68271589279\n",
      "  time_this_iter_s: 159.67533993721008\n",
      "  time_total_s: 75650.68271589279\n",
      "  timers:\n",
      "    learn_throughput: 933.934\n",
      "    learn_time_ms: 10703.111\n",
      "    load_throughput: 91395.905\n",
      "    load_time_ms: 109.37\n",
      "    sample_throughput: 68.118\n",
      "    sample_time_ms: 146745.384\n",
      "    update_time_ms: 11.946\n",
      "  timestamp: 1636370078\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4838064\n",
      "  training_iteration: 484\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   484</td><td style=\"text-align: right;\">         75650.7</td><td style=\"text-align: right;\">4838064</td><td style=\"text-align: right;\"> 3.48912</td><td style=\"text-align: right;\">               10.69</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           87.8596</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4848060\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-17-19\n",
      "  done: false\n",
      "  episode_len_mean: 86.89565217391305\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.390000000000018\n",
      "  episode_reward_mean: 3.4321739130434863\n",
      "  episode_reward_min: -1.3000000000000005\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 52740\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1230008279156483\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01346538196732885\n",
      "          policy_loss: -0.0610503547005037\n",
      "          total_loss: 0.147138537819155\n",
      "          vf_explained_var: 0.9079574942588806\n",
      "          vf_loss: 0.1987430760748366\n",
      "    num_agent_steps_sampled: 4848060\n",
      "    num_agent_steps_trained: 4848060\n",
      "    num_steps_sampled: 4848060\n",
      "    num_steps_trained: 4848060\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.20917030567686\n",
      "    ram_util_percent: 57.06550218340613\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558187773454402\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.011322584313994\n",
      "    mean_inference_ms: 2.855559680882912\n",
      "    mean_raw_obs_processing_ms: 3.465226909769132\n",
      "  time_since_restore: 75811.14396882057\n",
      "  time_this_iter_s: 160.46125292778015\n",
      "  time_total_s: 75811.14396882057\n",
      "  timers:\n",
      "    learn_throughput: 932.908\n",
      "    learn_time_ms: 10714.884\n",
      "    load_throughput: 91534.964\n",
      "    load_time_ms: 109.204\n",
      "    sample_throughput: 67.75\n",
      "    sample_time_ms: 147543.016\n",
      "    update_time_ms: 12.145\n",
      "  timestamp: 1636370239\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4848060\n",
      "  training_iteration: 485\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   485</td><td style=\"text-align: right;\">         75811.1</td><td style=\"text-align: right;\">4848060</td><td style=\"text-align: right;\"> 3.43217</td><td style=\"text-align: right;\">               12.39</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">           86.8957</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4858056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-20-02\n",
      "  done: false\n",
      "  episode_len_mean: 89.21621621621621\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.130000000000013\n",
      "  episode_reward_mean: 4.198108108108118\n",
      "  episode_reward_min: -1.3600000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 52851\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1187694212310335\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012492636166812395\n",
      "          policy_loss: -0.06414870481985883\n",
      "          total_loss: 0.0954791819748397\n",
      "          vf_explained_var: 0.934741199016571\n",
      "          vf_loss: 0.15235579192924958\n",
      "    num_agent_steps_sampled: 4858056\n",
      "    num_agent_steps_trained: 4858056\n",
      "    num_steps_sampled: 4858056\n",
      "    num_steps_trained: 4858056\n",
      "  iterations_since_restore: 486\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.77553648068671\n",
      "    ram_util_percent: 57.078540772532186\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555153105356764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0119398614056\n",
      "    mean_inference_ms: 2.8553967852197486\n",
      "    mean_raw_obs_processing_ms: 3.464129998524363\n",
      "  time_since_restore: 75974.79053473473\n",
      "  time_this_iter_s: 163.64656591415405\n",
      "  time_total_s: 75974.79053473473\n",
      "  timers:\n",
      "    learn_throughput: 933.528\n",
      "    learn_time_ms: 10707.767\n",
      "    load_throughput: 91287.41\n",
      "    load_time_ms: 109.5\n",
      "    sample_throughput: 67.461\n",
      "    sample_time_ms: 148173.803\n",
      "    update_time_ms: 12.769\n",
      "  timestamp: 1636370402\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4858056\n",
      "  training_iteration: 486\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   486</td><td style=\"text-align: right;\">         75974.8</td><td style=\"text-align: right;\">4858056</td><td style=\"text-align: right;\"> 4.19811</td><td style=\"text-align: right;\">               13.13</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           89.2162</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4868052\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-22-54\n",
      "  done: false\n",
      "  episode_len_mean: 86.02564102564102\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.30000000000001\n",
      "  episode_reward_mean: 3.860170940170948\n",
      "  episode_reward_min: -1.410000000000001\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 52968\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.091794089272491\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012829916147487783\n",
      "          policy_loss: -0.06409896334999392\n",
      "          total_loss: 0.10354667310563163\n",
      "          vf_explained_var: 0.9293210506439209\n",
      "          vf_loss: 0.15933542462368297\n",
      "    num_agent_steps_sampled: 4868052\n",
      "    num_agent_steps_trained: 4868052\n",
      "    num_steps_sampled: 4868052\n",
      "    num_steps_trained: 4868052\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.81219512195123\n",
      "    ram_util_percent: 57.085365853658544\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045568088768093734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01538363885816\n",
      "    mean_inference_ms: 2.8554323982645027\n",
      "    mean_raw_obs_processing_ms: 3.4701659547792643\n",
      "  time_since_restore: 76146.83085346222\n",
      "  time_this_iter_s: 172.0403187274933\n",
      "  time_total_s: 76146.83085346222\n",
      "  timers:\n",
      "    learn_throughput: 933.037\n",
      "    learn_time_ms: 10713.401\n",
      "    load_throughput: 91396.104\n",
      "    load_time_ms: 109.37\n",
      "    sample_throughput: 67.314\n",
      "    sample_time_ms: 148497.078\n",
      "    update_time_ms: 13.35\n",
      "  timestamp: 1636370574\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4868052\n",
      "  training_iteration: 487\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   487</td><td style=\"text-align: right;\">         76146.8</td><td style=\"text-align: right;\">4868052</td><td style=\"text-align: right;\"> 3.86017</td><td style=\"text-align: right;\">                13.3</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           86.0256</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4878048\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-25-35\n",
      "  done: false\n",
      "  episode_len_mean: 88.07964601769912\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.060000000000015\n",
      "  episode_reward_mean: 3.8053097345132825\n",
      "  episode_reward_min: -1.2700000000000007\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 53081\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1438143125966063\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013408583796274862\n",
      "          policy_loss: -0.06647935136197469\n",
      "          total_loss: 0.11998540547827626\n",
      "          vf_explained_var: 0.92138671875\n",
      "          vf_loss: 0.17735646866007237\n",
      "    num_agent_steps_sampled: 4878048\n",
      "    num_agent_steps_trained: 4878048\n",
      "    num_steps_sampled: 4878048\n",
      "    num_steps_trained: 4878048\n",
      "  iterations_since_restore: 488\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.7751091703057\n",
      "    ram_util_percent: 57.077292576419204\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455330052784819\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.020202782486685\n",
      "    mean_inference_ms: 2.855512939751177\n",
      "    mean_raw_obs_processing_ms: 3.467437181682682\n",
      "  time_since_restore: 76307.48819708824\n",
      "  time_this_iter_s: 160.65734362602234\n",
      "  time_total_s: 76307.48819708824\n",
      "  timers:\n",
      "    learn_throughput: 932.525\n",
      "    learn_time_ms: 10719.287\n",
      "    load_throughput: 91235.543\n",
      "    load_time_ms: 109.563\n",
      "    sample_throughput: 66.519\n",
      "    sample_time_ms: 150272.969\n",
      "    update_time_ms: 13.379\n",
      "  timestamp: 1636370735\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4878048\n",
      "  training_iteration: 488\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   488</td><td style=\"text-align: right;\">         76307.5</td><td style=\"text-align: right;\">4878048</td><td style=\"text-align: right;\"> 3.80531</td><td style=\"text-align: right;\">               13.06</td><td style=\"text-align: right;\">               -1.27</td><td style=\"text-align: right;\">           88.0796</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4888044\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-28-29\n",
      "  done: false\n",
      "  episode_len_mean: 88.95535714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 3.6676785714285804\n",
      "  episode_reward_min: -1.1900000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 53193\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1302254525005306\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013411749028409085\n",
      "          policy_loss: -0.05885007559823302\n",
      "          total_loss: 0.1271609879998315\n",
      "          vf_explained_var: 0.918953537940979\n",
      "          vf_loss: 0.17675967655566513\n",
      "    num_agent_steps_sampled: 4888044\n",
      "    num_agent_steps_trained: 4888044\n",
      "    num_steps_sampled: 4888044\n",
      "    num_steps_trained: 4888044\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.62489959839358\n",
      "    ram_util_percent: 57.13694779116465\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555190326447716\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02278325036758\n",
      "    mean_inference_ms: 2.8556473597238994\n",
      "    mean_raw_obs_processing_ms: 3.4712905715185505\n",
      "  time_since_restore: 76481.76496839523\n",
      "  time_this_iter_s: 174.27677130699158\n",
      "  time_total_s: 76481.76496839523\n",
      "  timers:\n",
      "    learn_throughput: 932.491\n",
      "    learn_time_ms: 10719.679\n",
      "    load_throughput: 91045.048\n",
      "    load_time_ms: 109.792\n",
      "    sample_throughput: 65.338\n",
      "    sample_time_ms: 152989.815\n",
      "    update_time_ms: 14.351\n",
      "  timestamp: 1636370909\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4888044\n",
      "  training_iteration: 489\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   489</td><td style=\"text-align: right;\">         76481.8</td><td style=\"text-align: right;\">4888044</td><td style=\"text-align: right;\"> 3.66768</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           88.9554</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4898040\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 89.76106194690266\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.740000000000014\n",
      "  episode_reward_mean: 4.1235398230088585\n",
      "  episode_reward_min: -1.4500000000000004\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 53306\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.117258612620525\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013694049663241994\n",
      "          policy_loss: -0.06125812490399067\n",
      "          total_loss: 0.11735161678531231\n",
      "          vf_explained_var: 0.9298210740089417\n",
      "          vf_loss: 0.16858557017090228\n",
      "    num_agent_steps_sampled: 4898040\n",
      "    num_agent_steps_trained: 4898040\n",
      "    num_steps_sampled: 4898040\n",
      "    num_steps_trained: 4898040\n",
      "  iterations_since_restore: 490\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.01845493562232\n",
      "    ram_util_percent: 57.153648068669526\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045566742138562634\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02931741346825\n",
      "    mean_inference_ms: 2.8554876575559707\n",
      "    mean_raw_obs_processing_ms: 3.4727450912645845\n",
      "  time_since_restore: 76645.47926139832\n",
      "  time_this_iter_s: 163.71429300308228\n",
      "  time_total_s: 76645.47926139832\n",
      "  timers:\n",
      "    learn_throughput: 932.598\n",
      "    learn_time_ms: 10718.443\n",
      "    load_throughput: 91168.368\n",
      "    load_time_ms: 109.643\n",
      "    sample_throughput: 65.636\n",
      "    sample_time_ms: 152294.243\n",
      "    update_time_ms: 14.182\n",
      "  timestamp: 1636371073\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4898040\n",
      "  training_iteration: 490\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   490</td><td style=\"text-align: right;\">         76645.5</td><td style=\"text-align: right;\">4898040</td><td style=\"text-align: right;\"> 4.12354</td><td style=\"text-align: right;\">               12.74</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           89.7611</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4908036\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-33-50\n",
      "  done: false\n",
      "  episode_len_mean: 88.32743362831859\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.900000000000016\n",
      "  episode_reward_mean: 3.832477876106203\n",
      "  episode_reward_min: -1.7000000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 53419\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.131615988821046\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013049969689465828\n",
      "          policy_loss: -0.06276037994549315\n",
      "          total_loss: 0.11484681850808681\n",
      "          vf_explained_var: 0.9183028340339661\n",
      "          vf_loss: 0.16919389516115188\n",
      "    num_agent_steps_sampled: 4908036\n",
      "    num_agent_steps_trained: 4908036\n",
      "    num_steps_sampled: 4908036\n",
      "    num_steps_trained: 4908036\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.47187499999998\n",
      "    ram_util_percent: 57.129017857142856\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455528266204546\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.031998298177875\n",
      "    mean_inference_ms: 2.855555823432265\n",
      "    mean_raw_obs_processing_ms: 3.4704214374174955\n",
      "  time_since_restore: 76802.11610269547\n",
      "  time_this_iter_s: 156.63684129714966\n",
      "  time_total_s: 76802.11610269547\n",
      "  timers:\n",
      "    learn_throughput: 932.576\n",
      "    learn_time_ms: 10718.697\n",
      "    load_throughput: 91431.363\n",
      "    load_time_ms: 109.328\n",
      "    sample_throughput: 65.861\n",
      "    sample_time_ms: 151773.345\n",
      "    update_time_ms: 13.597\n",
      "  timestamp: 1636371230\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4908036\n",
      "  training_iteration: 491\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   491</td><td style=\"text-align: right;\">         76802.1</td><td style=\"text-align: right;\">4908036</td><td style=\"text-align: right;\"> 3.83248</td><td style=\"text-align: right;\">                12.9</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           88.3274</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4918032\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-36-12\n",
      "  done: false\n",
      "  episode_len_mean: 91.89908256880734\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.040000000000012\n",
      "  episode_reward_mean: 3.924311926605514\n",
      "  episode_reward_min: -1.3000000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 53528\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1400276463255925\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013264010514972398\n",
      "          policy_loss: -0.062138325576949066\n",
      "          total_loss: 0.10452656916891917\n",
      "          vf_explained_var: 0.923557698726654\n",
      "          vf_loss: 0.1578480965625017\n",
      "    num_agent_steps_sampled: 4918032\n",
      "    num_agent_steps_trained: 4918032\n",
      "    num_steps_sampled: 4918032\n",
      "    num_steps_trained: 4918032\n",
      "  iterations_since_restore: 492\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9559405940594\n",
      "    ram_util_percent: 57.1029702970297\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045539089806922464\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03514231864864\n",
      "    mean_inference_ms: 2.85540368155146\n",
      "    mean_raw_obs_processing_ms: 3.4641151046328846\n",
      "  time_since_restore: 76943.84058022499\n",
      "  time_this_iter_s: 141.72447752952576\n",
      "  time_total_s: 76943.84058022499\n",
      "  timers:\n",
      "    learn_throughput: 932.49\n",
      "    learn_time_ms: 10719.68\n",
      "    load_throughput: 91562.37\n",
      "    load_time_ms: 109.171\n",
      "    sample_throughput: 66.493\n",
      "    sample_time_ms: 150331.7\n",
      "    update_time_ms: 13.658\n",
      "  timestamp: 1636371372\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4918032\n",
      "  training_iteration: 492\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   492</td><td style=\"text-align: right;\">         76943.8</td><td style=\"text-align: right;\">4918032</td><td style=\"text-align: right;\"> 3.92431</td><td style=\"text-align: right;\">               13.04</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">           91.8991</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4928028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-38-52\n",
      "  done: false\n",
      "  episode_len_mean: 89.2072072072072\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.480000000000016\n",
      "  episode_reward_mean: 4.027297297297306\n",
      "  episode_reward_min: -1.3600000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 53639\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1427467939181204\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013071401390221563\n",
      "          policy_loss: -0.06593849297740266\n",
      "          total_loss: 0.11175167959613296\n",
      "          vf_explained_var: 0.9289017915725708\n",
      "          vf_loss: 0.1693393528763937\n",
      "    num_agent_steps_sampled: 4928028\n",
      "    num_agent_steps_trained: 4928028\n",
      "    num_steps_sampled: 4928028\n",
      "    num_steps_trained: 4928028\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.45458515283842\n",
      "    ram_util_percent: 57.02576419213974\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557338080881888\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.039690764731816\n",
      "    mean_inference_ms: 2.8554778254097677\n",
      "    mean_raw_obs_processing_ms: 3.4701123169579837\n",
      "  time_since_restore: 77103.88783884048\n",
      "  time_this_iter_s: 160.04725861549377\n",
      "  time_total_s: 77103.88783884048\n",
      "  timers:\n",
      "    learn_throughput: 932.863\n",
      "    learn_time_ms: 10715.395\n",
      "    load_throughput: 91271.313\n",
      "    load_time_ms: 109.52\n",
      "    sample_throughput: 66.447\n",
      "    sample_time_ms: 150434.849\n",
      "    update_time_ms: 14.062\n",
      "  timestamp: 1636371532\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4928028\n",
      "  training_iteration: 493\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   493</td><td style=\"text-align: right;\">         77103.9</td><td style=\"text-align: right;\">4928028</td><td style=\"text-align: right;\">  4.0273</td><td style=\"text-align: right;\">               10.48</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           89.2072</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4938024\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-41-39\n",
      "  done: false\n",
      "  episode_len_mean: 92.33333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.870000000000017\n",
      "  episode_reward_mean: 4.277962962962973\n",
      "  episode_reward_min: -1.4300000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 53747\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.106743803492978\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013838377746964507\n",
      "          policy_loss: -0.06601509942840307\n",
      "          total_loss: 0.12274564688340721\n",
      "          vf_explained_var: 0.9306842088699341\n",
      "          vf_loss: 0.1783026307184472\n",
      "    num_agent_steps_sampled: 4938024\n",
      "    num_agent_steps_trained: 4938024\n",
      "    num_steps_sampled: 4938024\n",
      "    num_steps_trained: 4938024\n",
      "  iterations_since_restore: 494\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.27782426778244\n",
      "    ram_util_percent: 57.27029288702929\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045512788179889005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03453683365086\n",
      "    mean_inference_ms: 2.855284777622776\n",
      "    mean_raw_obs_processing_ms: 3.4739852259674135\n",
      "  time_since_restore: 77271.51332235336\n",
      "  time_this_iter_s: 167.62548351287842\n",
      "  time_total_s: 77271.51332235336\n",
      "  timers:\n",
      "    learn_throughput: 933.338\n",
      "    learn_time_ms: 10709.944\n",
      "    load_throughput: 91274.771\n",
      "    load_time_ms: 109.515\n",
      "    sample_throughput: 66.095\n",
      "    sample_time_ms: 151236.355\n",
      "    update_time_ms: 13.624\n",
      "  timestamp: 1636371699\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4938024\n",
      "  training_iteration: 494\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   494</td><td style=\"text-align: right;\">         77271.5</td><td style=\"text-align: right;\">4938024</td><td style=\"text-align: right;\"> 4.27796</td><td style=\"text-align: right;\">               14.87</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           92.3333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4948020\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-44-29\n",
      "  done: false\n",
      "  episode_len_mean: 89.4424778761062\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.30000000000001\n",
      "  episode_reward_mean: 4.388318584070806\n",
      "  episode_reward_min: 0.059999999999999255\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 53860\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.122417413067614\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014669350366387253\n",
      "          policy_loss: -0.06404477788819972\n",
      "          total_loss: 0.15830223190431028\n",
      "          vf_explained_var: 0.9227873682975769\n",
      "          vf_loss: 0.21015256817938172\n",
      "    num_agent_steps_sampled: 4948020\n",
      "    num_agent_steps_trained: 4948020\n",
      "    num_steps_sampled: 4948020\n",
      "    num_steps_trained: 4948020\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.06115702479339\n",
      "    ram_util_percent: 57.23140495867768\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554469748574719\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03698026825093\n",
      "    mean_inference_ms: 2.855300148710878\n",
      "    mean_raw_obs_processing_ms: 3.4795749311036994\n",
      "  time_since_restore: 77441.17370128632\n",
      "  time_this_iter_s: 169.66037893295288\n",
      "  time_total_s: 77441.17370128632\n",
      "  timers:\n",
      "    learn_throughput: 934.24\n",
      "    learn_time_ms: 10699.602\n",
      "    load_throughput: 90951.943\n",
      "    load_time_ms: 109.904\n",
      "    sample_throughput: 65.692\n",
      "    sample_time_ms: 152165.619\n",
      "    update_time_ms: 14.26\n",
      "  timestamp: 1636371869\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4948020\n",
      "  training_iteration: 495\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   495</td><td style=\"text-align: right;\">         77441.2</td><td style=\"text-align: right;\">4948020</td><td style=\"text-align: right;\"> 4.38832</td><td style=\"text-align: right;\">                16.3</td><td style=\"text-align: right;\">                0.06</td><td style=\"text-align: right;\">           89.4425</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4958016\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-47-26\n",
      "  done: false\n",
      "  episode_len_mean: 92.35514018691589\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.050000000000015\n",
      "  episode_reward_mean: 4.208317757009355\n",
      "  episode_reward_min: -1.8500000000000008\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 53967\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1247477918608575\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014121859797859865\n",
      "          policy_loss: -0.062545161964929\n",
      "          total_loss: 0.14673957535280632\n",
      "          vf_explained_var: 0.8975574374198914\n",
      "          vf_loss: 0.19836085220942132\n",
      "    num_agent_steps_sampled: 4958016\n",
      "    num_agent_steps_trained: 4958016\n",
      "    num_steps_sampled: 4958016\n",
      "    num_steps_trained: 4958016\n",
      "  iterations_since_restore: 496\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.16561264822136\n",
      "    ram_util_percent: 57.21343873517787\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455418470126752\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03464452968385\n",
      "    mean_inference_ms: 2.8554401420646522\n",
      "    mean_raw_obs_processing_ms: 3.486358534429418\n",
      "  time_since_restore: 77618.25103902817\n",
      "  time_this_iter_s: 177.0773377418518\n",
      "  time_total_s: 77618.25103902817\n",
      "  timers:\n",
      "    learn_throughput: 934.47\n",
      "    learn_time_ms: 10696.968\n",
      "    load_throughput: 91109.171\n",
      "    load_time_ms: 109.715\n",
      "    sample_throughput: 65.116\n",
      "    sample_time_ms: 153511.517\n",
      "    update_time_ms: 13.942\n",
      "  timestamp: 1636372046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4958016\n",
      "  training_iteration: 496\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   496</td><td style=\"text-align: right;\">         77618.3</td><td style=\"text-align: right;\">4958016</td><td style=\"text-align: right;\"> 4.20832</td><td style=\"text-align: right;\">               15.05</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           92.3551</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4968012\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-50-11\n",
      "  done: false\n",
      "  episode_len_mean: 91.76146788990826\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.010000000000018\n",
      "  episode_reward_mean: 4.064403669724781\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 54076\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1365451499947117\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013707092342073707\n",
      "          policy_loss: -0.061141959782371406\n",
      "          total_loss: 0.14534116670584832\n",
      "          vf_explained_var: 0.9208692312240601\n",
      "          vf_loss: 0.1966221071843408\n",
      "    num_agent_steps_sampled: 4968012\n",
      "    num_agent_steps_trained: 4968012\n",
      "    num_steps_sampled: 4968012\n",
      "    num_steps_trained: 4968012\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.26068376068376\n",
      "    ram_util_percent: 57.28076923076923\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552338058164168\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.032427327093714\n",
      "    mean_inference_ms: 2.855170360692713\n",
      "    mean_raw_obs_processing_ms: 3.4907150483820777\n",
      "  time_since_restore: 77782.80670237541\n",
      "  time_this_iter_s: 164.55566334724426\n",
      "  time_total_s: 77782.80670237541\n",
      "  timers:\n",
      "    learn_throughput: 933.398\n",
      "    learn_time_ms: 10709.26\n",
      "    load_throughput: 90867.595\n",
      "    load_time_ms: 110.006\n",
      "    sample_throughput: 65.439\n",
      "    sample_time_ms: 152752.071\n",
      "    update_time_ms: 12.82\n",
      "  timestamp: 1636372211\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4968012\n",
      "  training_iteration: 497\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   497</td><td style=\"text-align: right;\">         77782.8</td><td style=\"text-align: right;\">4968012</td><td style=\"text-align: right;\">  4.0644</td><td style=\"text-align: right;\">               13.01</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           91.7615</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4978008\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-52-54\n",
      "  done: false\n",
      "  episode_len_mean: 91.35454545454546\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.050000000000013\n",
      "  episode_reward_mean: 3.8860909090909175\n",
      "  episode_reward_min: -1.5600000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 54186\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.114571952717936\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013786097292821126\n",
      "          policy_loss: -0.06150772598866596\n",
      "          total_loss: 0.12654122774385743\n",
      "          vf_explained_var: 0.9160634279251099\n",
      "          vf_loss: 0.17778821867675734\n",
      "    num_agent_steps_sampled: 4978008\n",
      "    num_agent_steps_trained: 4978008\n",
      "    num_steps_sampled: 4978008\n",
      "    num_steps_trained: 4978008\n",
      "  iterations_since_restore: 498\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.65236051502146\n",
      "    ram_util_percent: 57.2489270386266\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557664025053043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03436069700263\n",
      "    mean_inference_ms: 2.855379993370959\n",
      "    mean_raw_obs_processing_ms: 3.4945352870261686\n",
      "  time_since_restore: 77945.59555768967\n",
      "  time_this_iter_s: 162.78885531425476\n",
      "  time_total_s: 77945.59555768967\n",
      "  timers:\n",
      "    learn_throughput: 933.84\n",
      "    learn_time_ms: 10704.19\n",
      "    load_throughput: 90865.212\n",
      "    load_time_ms: 110.009\n",
      "    sample_throughput: 65.346\n",
      "    sample_time_ms: 152970.656\n",
      "    update_time_ms: 12.603\n",
      "  timestamp: 1636372374\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4978008\n",
      "  training_iteration: 498\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   498</td><td style=\"text-align: right;\">         77945.6</td><td style=\"text-align: right;\">4978008</td><td style=\"text-align: right;\"> 3.88609</td><td style=\"text-align: right;\">               13.05</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           91.3545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4988004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-55-26\n",
      "  done: false\n",
      "  episode_len_mean: 92.6574074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.80000000000001\n",
      "  episode_reward_mean: 3.9679629629629725\n",
      "  episode_reward_min: -1.4500000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 54294\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1134957034363704\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013963421328782224\n",
      "          policy_loss: -0.06113529131612462\n",
      "          total_loss: 0.13990472574901378\n",
      "          vf_explained_var: 0.9231837391853333\n",
      "          vf_loss: 0.19036455371409144\n",
      "    num_agent_steps_sampled: 4988004\n",
      "    num_agent_steps_trained: 4988004\n",
      "    num_steps_sampled: 4988004\n",
      "    num_steps_trained: 4988004\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.60601851851852\n",
      "    ram_util_percent: 57.29722222222223\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045560331339960375\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03441595994474\n",
      "    mean_inference_ms: 2.855275948128547\n",
      "    mean_raw_obs_processing_ms: 3.4919917895433543\n",
      "  time_since_restore: 78097.48287463188\n",
      "  time_this_iter_s: 151.88731694221497\n",
      "  time_total_s: 78097.48287463188\n",
      "  timers:\n",
      "    learn_throughput: 934.913\n",
      "    learn_time_ms: 10691.908\n",
      "    load_throughput: 90741.571\n",
      "    load_time_ms: 110.159\n",
      "    sample_throughput: 66.311\n",
      "    sample_time_ms: 150744.088\n",
      "    update_time_ms: 12.443\n",
      "  timestamp: 1636372526\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4988004\n",
      "  training_iteration: 499\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   499</td><td style=\"text-align: right;\">         78097.5</td><td style=\"text-align: right;\">4988004</td><td style=\"text-align: right;\"> 3.96796</td><td style=\"text-align: right;\">                16.8</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           92.6574</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 4998000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_11-58-15\n",
      "  done: false\n",
      "  episode_len_mean: 92.6574074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.640000000000018\n",
      "  episode_reward_mean: 4.307314814814824\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 54402\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1206686849268075\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014112650683412218\n",
      "          policy_loss: -0.06475139334320258\n",
      "          total_loss: 0.13005886206674017\n",
      "          vf_explained_var: 0.9158083200454712\n",
      "          vf_loss: 0.18386655848982753\n",
      "    num_agent_steps_sampled: 4998000\n",
      "    num_agent_steps_trained: 4998000\n",
      "    num_steps_sampled: 4998000\n",
      "    num_steps_trained: 4998000\n",
      "  iterations_since_restore: 500\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.40537190082645\n",
      "    ram_util_percent: 57.27520661157025\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045535383474187556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0293978096724\n",
      "    mean_inference_ms: 2.8551172561998053\n",
      "    mean_raw_obs_processing_ms: 3.4956937569232602\n",
      "  time_since_restore: 78267.06273245811\n",
      "  time_this_iter_s: 169.5798578262329\n",
      "  time_total_s: 78267.06273245811\n",
      "  timers:\n",
      "    learn_throughput: 935.116\n",
      "    learn_time_ms: 10689.584\n",
      "    load_throughput: 90843.338\n",
      "    load_time_ms: 110.036\n",
      "    sample_throughput: 66.053\n",
      "    sample_time_ms: 151333.245\n",
      "    update_time_ms: 12.305\n",
      "  timestamp: 1636372695\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4998000\n",
      "  training_iteration: 500\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         78267.1</td><td style=\"text-align: right;\">4998000</td><td style=\"text-align: right;\"> 4.30731</td><td style=\"text-align: right;\">               12.64</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           92.6574</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5007996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-00-52\n",
      "  done: false\n",
      "  episode_len_mean: 94.61904761904762\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.680000000000017\n",
      "  episode_reward_mean: 4.100095238095248\n",
      "  episode_reward_min: -1.4600000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 54507\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.122717368806529\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013724498659072406\n",
      "          policy_loss: -0.06724515453012836\n",
      "          total_loss: 0.11080540200520275\n",
      "          vf_explained_var: 0.9328297972679138\n",
      "          vf_loss: 0.16801160533522438\n",
      "    num_agent_steps_sampled: 5007996\n",
      "    num_agent_steps_trained: 5007996\n",
      "    num_steps_sampled: 5007996\n",
      "    num_steps_trained: 5007996\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.80982142857144\n",
      "    ram_util_percent: 57.30758928571429\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557350111984206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02924826477171\n",
      "    mean_inference_ms: 2.8550755564178396\n",
      "    mean_raw_obs_processing_ms: 3.4956163027670533\n",
      "  time_since_restore: 78423.48286795616\n",
      "  time_this_iter_s: 156.42013549804688\n",
      "  time_total_s: 78423.48286795616\n",
      "  timers:\n",
      "    learn_throughput: 934.989\n",
      "    learn_time_ms: 10691.034\n",
      "    load_throughput: 90718.776\n",
      "    load_time_ms: 110.187\n",
      "    sample_throughput: 66.063\n",
      "    sample_time_ms: 151309.879\n",
      "    update_time_ms: 12.222\n",
      "  timestamp: 1636372852\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5007996\n",
      "  training_iteration: 501\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   501</td><td style=\"text-align: right;\">         78423.5</td><td style=\"text-align: right;\">5007996</td><td style=\"text-align: right;\">  4.1001</td><td style=\"text-align: right;\">               12.68</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">            94.619</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5017992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-03-54\n",
      "  done: false\n",
      "  episode_len_mean: 94.01886792452831\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.160000000000021\n",
      "  episode_reward_mean: 4.235849056603785\n",
      "  episode_reward_min: -1.9600000000000013\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 54613\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.148618249506013\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013022625041439369\n",
      "          policy_loss: -0.06556636420771098\n",
      "          total_loss: 0.09840850991268571\n",
      "          vf_explained_var: 0.9349530339241028\n",
      "          vf_loss: 0.15579388786075463\n",
      "    num_agent_steps_sampled: 5017992\n",
      "    num_agent_steps_trained: 5017992\n",
      "    num_steps_sampled: 5017992\n",
      "    num_steps_trained: 5017992\n",
      "  iterations_since_restore: 502\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.5926640926641\n",
      "    ram_util_percent: 57.300000000000004\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559976811520392\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02736058264403\n",
      "    mean_inference_ms: 2.855029333618388\n",
      "    mean_raw_obs_processing_ms: 3.5051326293393976\n",
      "  time_since_restore: 78605.46053981781\n",
      "  time_this_iter_s: 181.97767186164856\n",
      "  time_total_s: 78605.46053981781\n",
      "  timers:\n",
      "    learn_throughput: 935.083\n",
      "    learn_time_ms: 10689.955\n",
      "    load_throughput: 90658.749\n",
      "    load_time_ms: 110.26\n",
      "    sample_throughput: 64.351\n",
      "    sample_time_ms: 155335.932\n",
      "    update_time_ms: 12.294\n",
      "  timestamp: 1636373034\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5017992\n",
      "  training_iteration: 502\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   502</td><td style=\"text-align: right;\">         78605.5</td><td style=\"text-align: right;\">5017992</td><td style=\"text-align: right;\"> 4.23585</td><td style=\"text-align: right;\">               14.16</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">           94.0189</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5027988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-06-50\n",
      "  done: false\n",
      "  episode_len_mean: 90.68468468468468\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.900000000000015\n",
      "  episode_reward_mean: 4.346486486486496\n",
      "  episode_reward_min: -1.870000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 54724\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.118124048118917\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014046631993819681\n",
      "          policy_loss: -0.06461728049330731\n",
      "          total_loss: 0.12485459443882235\n",
      "          vf_explained_var: 0.9342869520187378\n",
      "          vf_loss: 0.17865313217680678\n",
      "    num_agent_steps_sampled: 5027988\n",
      "    num_agent_steps_trained: 5027988\n",
      "    num_steps_sampled: 5027988\n",
      "    num_steps_trained: 5027988\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.78844621513944\n",
      "    ram_util_percent: 57.20239043824701\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045551714682604084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02869661551451\n",
      "    mean_inference_ms: 2.8549376494142895\n",
      "    mean_raw_obs_processing_ms: 3.506859243353943\n",
      "  time_since_restore: 78781.4590075016\n",
      "  time_this_iter_s: 175.99846768379211\n",
      "  time_total_s: 78781.4590075016\n",
      "  timers:\n",
      "    learn_throughput: 934.864\n",
      "    learn_time_ms: 10692.463\n",
      "    load_throughput: 90716.42\n",
      "    load_time_ms: 110.19\n",
      "    sample_throughput: 63.697\n",
      "    sample_time_ms: 156929.699\n",
      "    update_time_ms: 11.334\n",
      "  timestamp: 1636373210\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5027988\n",
      "  training_iteration: 503\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   503</td><td style=\"text-align: right;\">         78781.5</td><td style=\"text-align: right;\">5027988</td><td style=\"text-align: right;\"> 4.34649</td><td style=\"text-align: right;\">                12.9</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">           90.6847</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5037984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-09-38\n",
      "  done: false\n",
      "  episode_len_mean: 89.8018018018018\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.930000000000012\n",
      "  episode_reward_mean: 4.257387387387396\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 54835\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1068250849715664\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012908847530161215\n",
      "          policy_loss: -0.0639506733076822\n",
      "          total_loss: 0.11635159236243647\n",
      "          vf_explained_var: 0.939650297164917\n",
      "          vf_loss: 0.17196254718602977\n",
      "    num_agent_steps_sampled: 5037984\n",
      "    num_agent_steps_trained: 5037984\n",
      "    num_steps_sampled: 5037984\n",
      "    num_steps_trained: 5037984\n",
      "  iterations_since_restore: 504\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.485\n",
      "    ram_util_percent: 57.32125\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556044902943757\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02741440945899\n",
      "    mean_inference_ms: 2.854989934272553\n",
      "    mean_raw_obs_processing_ms: 3.5133051374076545\n",
      "  time_since_restore: 78949.61384034157\n",
      "  time_this_iter_s: 168.15483283996582\n",
      "  time_total_s: 78949.61384034157\n",
      "  timers:\n",
      "    learn_throughput: 935.0\n",
      "    learn_time_ms: 10690.907\n",
      "    load_throughput: 90594.065\n",
      "    load_time_ms: 110.338\n",
      "    sample_throughput: 63.676\n",
      "    sample_time_ms: 156983.332\n",
      "    update_time_ms: 11.656\n",
      "  timestamp: 1636373378\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5037984\n",
      "  training_iteration: 504\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   504</td><td style=\"text-align: right;\">         78949.6</td><td style=\"text-align: right;\">5037984</td><td style=\"text-align: right;\"> 4.25739</td><td style=\"text-align: right;\">               12.93</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           89.8018</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5047980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-12-23\n",
      "  done: false\n",
      "  episode_len_mean: 90.84684684684684\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.779999999999994\n",
      "  episode_reward_mean: 4.45000000000001\n",
      "  episode_reward_min: -1.2900000000000007\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 54946\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.099194589944986\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013495478670084013\n",
      "          policy_loss: -0.06640118513988634\n",
      "          total_loss: 0.11546583600246753\n",
      "          vf_explained_var: 0.9400841593742371\n",
      "          vf_loss: 0.1721145789210613\n",
      "    num_agent_steps_sampled: 5047980\n",
      "    num_agent_steps_trained: 5047980\n",
      "    num_steps_sampled: 5047980\n",
      "    num_steps_trained: 5047980\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.77848101265823\n",
      "    ram_util_percent: 57.37932489451478\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554589844136703\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02546236448538\n",
      "    mean_inference_ms: 2.8550157634178324\n",
      "    mean_raw_obs_processing_ms: 3.517623621516397\n",
      "  time_since_restore: 79115.16097450256\n",
      "  time_this_iter_s: 165.54713416099548\n",
      "  time_total_s: 79115.16097450256\n",
      "  timers:\n",
      "    learn_throughput: 934.622\n",
      "    learn_time_ms: 10695.23\n",
      "    load_throughput: 90941.053\n",
      "    load_time_ms: 109.917\n",
      "    sample_throughput: 63.844\n",
      "    sample_time_ms: 156568.594\n",
      "    update_time_ms: 11.143\n",
      "  timestamp: 1636373543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5047980\n",
      "  training_iteration: 505\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   505</td><td style=\"text-align: right;\">         79115.2</td><td style=\"text-align: right;\">5047980</td><td style=\"text-align: right;\">    4.45</td><td style=\"text-align: right;\">               18.78</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           90.8468</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5057976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-15-29\n",
      "  done: false\n",
      "  episode_len_mean: 88.4375\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.529999999999983\n",
      "  episode_reward_mean: 3.9705357142857225\n",
      "  episode_reward_min: -1.970000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 55058\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.10300282474257\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012457364515031016\n",
      "          policy_loss: -0.06368333799525713\n",
      "          total_loss: 0.11067916110205726\n",
      "          vf_explained_var: 0.9340835213661194\n",
      "          vf_loss: 0.1670130938816911\n",
      "    num_agent_steps_sampled: 5057976\n",
      "    num_agent_steps_trained: 5057976\n",
      "    num_steps_sampled: 5057976\n",
      "    num_steps_trained: 5057976\n",
      "  iterations_since_restore: 506\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.10415094339622\n",
      "    ram_util_percent: 57.39924528301888\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045566667713382754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02398254199732\n",
      "    mean_inference_ms: 2.854944188537298\n",
      "    mean_raw_obs_processing_ms: 3.5246387947700746\n",
      "  time_since_restore: 79300.91935348511\n",
      "  time_this_iter_s: 185.75837898254395\n",
      "  time_total_s: 79300.91935348511\n",
      "  timers:\n",
      "    learn_throughput: 934.671\n",
      "    learn_time_ms: 10694.671\n",
      "    load_throughput: 90945.512\n",
      "    load_time_ms: 109.912\n",
      "    sample_throughput: 63.492\n",
      "    sample_time_ms: 157437.988\n",
      "    update_time_ms: 10.794\n",
      "  timestamp: 1636373729\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5057976\n",
      "  training_iteration: 506\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   506</td><td style=\"text-align: right;\">         79300.9</td><td style=\"text-align: right;\">5057976</td><td style=\"text-align: right;\"> 3.97054</td><td style=\"text-align: right;\">               18.53</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           88.4375</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5067972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-18-12\n",
      "  done: false\n",
      "  episode_len_mean: 92.87962962962963\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.340000000000014\n",
      "  episode_reward_mean: 4.739907407407419\n",
      "  episode_reward_min: -1.0200000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 55166\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.124860401235075\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014105666214900317\n",
      "          policy_loss: -0.06571241248016939\n",
      "          total_loss: 0.12215237146338974\n",
      "          vf_explained_var: 0.9369056224822998\n",
      "          vf_loss: 0.17697891742946245\n",
      "    num_agent_steps_sampled: 5067972\n",
      "    num_agent_steps_trained: 5067972\n",
      "    num_steps_sampled: 5067972\n",
      "    num_steps_trained: 5067972\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.09094827586206\n",
      "    ram_util_percent: 57.28706896551724\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045559217974543785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02720836676683\n",
      "    mean_inference_ms: 2.854846300215606\n",
      "    mean_raw_obs_processing_ms: 3.5257533034110504\n",
      "  time_since_restore: 79463.37239408493\n",
      "  time_this_iter_s: 162.453040599823\n",
      "  time_total_s: 79463.37239408493\n",
      "  timers:\n",
      "    learn_throughput: 935.767\n",
      "    learn_time_ms: 10682.143\n",
      "    load_throughput: 90998.669\n",
      "    load_time_ms: 109.848\n",
      "    sample_throughput: 63.572\n",
      "    sample_time_ms: 157239.154\n",
      "    update_time_ms: 11.685\n",
      "  timestamp: 1636373892\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5067972\n",
      "  training_iteration: 507\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   507</td><td style=\"text-align: right;\">         79463.4</td><td style=\"text-align: right;\">5067972</td><td style=\"text-align: right;\"> 4.73991</td><td style=\"text-align: right;\">               14.34</td><td style=\"text-align: right;\">               -1.02</td><td style=\"text-align: right;\">           92.8796</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5077968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-20-46\n",
      "  done: false\n",
      "  episode_len_mean: 92.27777777777777\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.610000000000017\n",
      "  episode_reward_mean: 4.183981481481491\n",
      "  episode_reward_min: -1.3100000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 55274\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.145126925370632\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012419163446708318\n",
      "          policy_loss: -0.06369213766267157\n",
      "          total_loss: 0.09176171035864032\n",
      "          vf_explained_var: 0.9333714246749878\n",
      "          vf_loss: 0.14861270927179318\n",
      "    num_agent_steps_sampled: 5077968\n",
      "    num_agent_steps_trained: 5077968\n",
      "    num_steps_sampled: 5077968\n",
      "    num_steps_trained: 5077968\n",
      "  iterations_since_restore: 508\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.55545454545457\n",
      "    ram_util_percent: 57.37272727272729\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555827242936918\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02949324708388\n",
      "    mean_inference_ms: 2.8548870706268787\n",
      "    mean_raw_obs_processing_ms: 3.5236496586590182\n",
      "  time_since_restore: 79617.64639282227\n",
      "  time_this_iter_s: 154.2739987373352\n",
      "  time_total_s: 79617.64639282227\n",
      "  timers:\n",
      "    learn_throughput: 935.06\n",
      "    learn_time_ms: 10690.222\n",
      "    load_throughput: 90870.49\n",
      "    load_time_ms: 110.003\n",
      "    sample_throughput: 63.922\n",
      "    sample_time_ms: 156378.946\n",
      "    update_time_ms: 12.249\n",
      "  timestamp: 1636374046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5077968\n",
      "  training_iteration: 508\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   508</td><td style=\"text-align: right;\">         79617.6</td><td style=\"text-align: right;\">5077968</td><td style=\"text-align: right;\"> 4.18398</td><td style=\"text-align: right;\">               12.61</td><td style=\"text-align: right;\">               -1.31</td><td style=\"text-align: right;\">           92.2778</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5087964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-23-49\n",
      "  done: false\n",
      "  episode_len_mean: 89.8125\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.120000000000013\n",
      "  episode_reward_mean: 4.085982142857152\n",
      "  episode_reward_min: -1.3700000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 55386\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.141884172777844\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013190798204714206\n",
      "          policy_loss: -0.0647337655727871\n",
      "          total_loss: 0.11088151699489253\n",
      "          vf_explained_var: 0.934858500957489\n",
      "          vf_loss: 0.16698383655017002\n",
      "    num_agent_steps_sampled: 5087964\n",
      "    num_agent_steps_trained: 5087964\n",
      "    num_steps_sampled: 5087964\n",
      "    num_steps_trained: 5087964\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.27432950191572\n",
      "    ram_util_percent: 57.25210727969348\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045557472571047544\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.029426646013654\n",
      "    mean_inference_ms: 2.8547745503152995\n",
      "    mean_raw_obs_processing_ms: 3.5284355018109204\n",
      "  time_since_restore: 79800.69636058807\n",
      "  time_this_iter_s: 183.0499677658081\n",
      "  time_total_s: 79800.69636058807\n",
      "  timers:\n",
      "    learn_throughput: 934.348\n",
      "    learn_time_ms: 10698.368\n",
      "    load_throughput: 91129.528\n",
      "    load_time_ms: 109.69\n",
      "    sample_throughput: 62.676\n",
      "    sample_time_ms: 159487.163\n",
      "    update_time_ms: 12.45\n",
      "  timestamp: 1636374229\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5087964\n",
      "  training_iteration: 509\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   509</td><td style=\"text-align: right;\">         79800.7</td><td style=\"text-align: right;\">5087964</td><td style=\"text-align: right;\"> 4.08598</td><td style=\"text-align: right;\">               13.12</td><td style=\"text-align: right;\">               -1.37</td><td style=\"text-align: right;\">           89.8125</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5097960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-26-45\n",
      "  done: false\n",
      "  episode_len_mean: 91.18348623853211\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.65000000000002\n",
      "  episode_reward_mean: 3.446972477064228\n",
      "  episode_reward_min: -1.6200000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 55495\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1479974014127357\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013261710037055719\n",
      "          policy_loss: -0.0657515812649304\n",
      "          total_loss: 0.10594756599738557\n",
      "          vf_explained_var: 0.9234360456466675\n",
      "          vf_loss: 0.16296728585934284\n",
      "    num_agent_steps_sampled: 5097960\n",
      "    num_agent_steps_trained: 5097960\n",
      "    num_steps_sampled: 5097960\n",
      "    num_steps_trained: 5097960\n",
      "  iterations_since_restore: 510\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.20439999999999\n",
      "    ram_util_percent: 57.194799999999994\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045529888123775016\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.030635191005025\n",
      "    mean_inference_ms: 2.854883606324159\n",
      "    mean_raw_obs_processing_ms: 3.529528826613302\n",
      "  time_since_restore: 79976.25268316269\n",
      "  time_this_iter_s: 175.55632257461548\n",
      "  time_total_s: 79976.25268316269\n",
      "  timers:\n",
      "    learn_throughput: 933.802\n",
      "    learn_time_ms: 10704.627\n",
      "    load_throughput: 91073.903\n",
      "    load_time_ms: 109.757\n",
      "    sample_throughput: 62.445\n",
      "    sample_time_ms: 160077.777\n",
      "    update_time_ms: 13.029\n",
      "  timestamp: 1636374405\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5097960\n",
      "  training_iteration: 510\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   510</td><td style=\"text-align: right;\">         79976.3</td><td style=\"text-align: right;\">5097960</td><td style=\"text-align: right;\"> 3.44697</td><td style=\"text-align: right;\">               12.65</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">           91.1835</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5107956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-29-08\n",
      "  done: false\n",
      "  episode_len_mean: 96.48076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000016\n",
      "  episode_reward_mean: 4.69625000000001\n",
      "  episode_reward_min: -1.4200000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 55599\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1309441009138386\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01435272251824833\n",
      "          policy_loss: -0.06415561207880577\n",
      "          total_loss: 0.13657710559697997\n",
      "          vf_explained_var: 0.931501030921936\n",
      "          vf_loss: 0.18934486228495073\n",
      "    num_agent_steps_sampled: 5107956\n",
      "    num_agent_steps_trained: 5107956\n",
      "    num_steps_sampled: 5107956\n",
      "    num_steps_trained: 5107956\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92598039215687\n",
      "    ram_util_percent: 57.28774509803923\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045578584113008414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03529864880386\n",
      "    mean_inference_ms: 2.855022451953511\n",
      "    mean_raw_obs_processing_ms: 3.5245289194820932\n",
      "  time_since_restore: 80119.08589935303\n",
      "  time_this_iter_s: 142.83321619033813\n",
      "  time_total_s: 80119.08589935303\n",
      "  timers:\n",
      "    learn_throughput: 933.514\n",
      "    learn_time_ms: 10707.924\n",
      "    load_throughput: 90949.536\n",
      "    load_time_ms: 109.907\n",
      "    sample_throughput: 62.981\n",
      "    sample_time_ms: 158714.349\n",
      "    update_time_ms: 14.366\n",
      "  timestamp: 1636374548\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5107956\n",
      "  training_iteration: 511\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   511</td><td style=\"text-align: right;\">         80119.1</td><td style=\"text-align: right;\">5107956</td><td style=\"text-align: right;\"> 4.69625</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           96.4808</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5117952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-31-46\n",
      "  done: false\n",
      "  episode_len_mean: 90.8440366972477\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000017\n",
      "  episode_reward_mean: 3.9059633027523017\n",
      "  episode_reward_min: -2.020000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 55708\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1552447345521717\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012849499263374526\n",
      "          policy_loss: -0.06120422552538733\n",
      "          total_loss: 0.11273037917020484\n",
      "          vf_explained_var: 0.9324292540550232\n",
      "          vf_loss: 0.16621428549003142\n",
      "    num_agent_steps_sampled: 5117952\n",
      "    num_agent_steps_trained: 5117952\n",
      "    num_steps_sampled: 5117952\n",
      "    num_steps_trained: 5117952\n",
      "  iterations_since_restore: 512\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.8783185840708\n",
      "    ram_util_percent: 57.239823008849555\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557066033176289\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.038985517597915\n",
      "    mean_inference_ms: 2.8549573730398734\n",
      "    mean_raw_obs_processing_ms: 3.5223947100161945\n",
      "  time_since_restore: 80276.8980448246\n",
      "  time_this_iter_s: 157.81214547157288\n",
      "  time_total_s: 80276.8980448246\n",
      "  timers:\n",
      "    learn_throughput: 932.699\n",
      "    learn_time_ms: 10717.287\n",
      "    load_throughput: 90638.053\n",
      "    load_time_ms: 110.285\n",
      "    sample_throughput: 63.959\n",
      "    sample_time_ms: 156288.673\n",
      "    update_time_ms: 14.007\n",
      "  timestamp: 1636374706\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5117952\n",
      "  training_iteration: 512\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   512</td><td style=\"text-align: right;\">         80276.9</td><td style=\"text-align: right;\">5117952</td><td style=\"text-align: right;\"> 3.90596</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">            90.844</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5127948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-34-32\n",
      "  done: false\n",
      "  episode_len_mean: 91.05405405405405\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.67000000000002\n",
      "  episode_reward_mean: 4.420630630630641\n",
      "  episode_reward_min: -1.2400000000000004\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 55819\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.116588531803881\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014588874855752392\n",
      "          policy_loss: -0.062299148579183804\n",
      "          total_loss: 0.14639612471000252\n",
      "          vf_explained_var: 0.923125147819519\n",
      "          vf_loss: 0.19662587679126578\n",
      "    num_agent_steps_sampled: 5127948\n",
      "    num_agent_steps_trained: 5127948\n",
      "    num_steps_sampled: 5127948\n",
      "    num_steps_trained: 5127948\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.08516949152542\n",
      "    ram_util_percent: 57.152542372881356\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557556456396299\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.040612078975826\n",
      "    mean_inference_ms: 2.855097851120793\n",
      "    mean_raw_obs_processing_ms: 3.526595885934746\n",
      "  time_since_restore: 80442.85519838333\n",
      "  time_this_iter_s: 165.95715355873108\n",
      "  time_total_s: 80442.85519838333\n",
      "  timers:\n",
      "    learn_throughput: 932.354\n",
      "    learn_time_ms: 10721.252\n",
      "    load_throughput: 90491.468\n",
      "    load_time_ms: 110.463\n",
      "    sample_throughput: 64.374\n",
      "    sample_time_ms: 155279.632\n",
      "    update_time_ms: 14.659\n",
      "  timestamp: 1636374872\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5127948\n",
      "  training_iteration: 513\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   513</td><td style=\"text-align: right;\">         80442.9</td><td style=\"text-align: right;\">5127948</td><td style=\"text-align: right;\"> 4.42063</td><td style=\"text-align: right;\">               12.67</td><td style=\"text-align: right;\">               -1.24</td><td style=\"text-align: right;\">           91.0541</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5137944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-37-11\n",
      "  done: false\n",
      "  episode_len_mean: 91.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000017\n",
      "  episode_reward_mean: 5.024818181818193\n",
      "  episode_reward_min: -0.8100000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 55929\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1293307315590035\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013611154981222095\n",
      "          policy_loss: -0.063759255144968\n",
      "          total_loss: 0.12959017267800932\n",
      "          vf_explained_var: 0.9389562606811523\n",
      "          vf_loss: 0.18363482080813912\n",
      "    num_agent_steps_sampled: 5137944\n",
      "    num_agent_steps_trained: 5137944\n",
      "    num_steps_sampled: 5137944\n",
      "    num_steps_trained: 5137944\n",
      "  iterations_since_restore: 514\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.54672489082971\n",
      "    ram_util_percent: 57.34978165938866\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045572249551118646\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04507796190099\n",
      "    mean_inference_ms: 2.854817687289021\n",
      "    mean_raw_obs_processing_ms: 3.5246600037948705\n",
      "  time_since_restore: 80602.75448393822\n",
      "  time_this_iter_s: 159.89928555488586\n",
      "  time_total_s: 80602.75448393822\n",
      "  timers:\n",
      "    learn_throughput: 932.18\n",
      "    learn_time_ms: 10723.245\n",
      "    load_throughput: 90593.36\n",
      "    load_time_ms: 110.339\n",
      "    sample_throughput: 64.719\n",
      "    sample_time_ms: 154452.711\n",
      "    update_time_ms: 13.982\n",
      "  timestamp: 1636375031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5137944\n",
      "  training_iteration: 514\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   514</td><td style=\"text-align: right;\">         80602.8</td><td style=\"text-align: right;\">5137944</td><td style=\"text-align: right;\"> 5.02482</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">               -0.81</td><td style=\"text-align: right;\">              91.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5147940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-39-46\n",
      "  done: false\n",
      "  episode_len_mean: 90.14545454545454\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.020000000000012\n",
      "  episode_reward_mean: 4.607272727272736\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 56039\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.107382189412402\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013446423356463622\n",
      "          policy_loss: -0.064046177533893\n",
      "          total_loss: 0.10879296592763092\n",
      "          vf_explained_var: 0.9464465975761414\n",
      "          vf_loss: 0.16328033143097265\n",
      "    num_agent_steps_sampled: 5147940\n",
      "    num_agent_steps_trained: 5147940\n",
      "    num_steps_sampled: 5147940\n",
      "    num_steps_trained: 5147940\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.24018264840181\n",
      "    ram_util_percent: 57.38447488584475\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555967585602351\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04875712024816\n",
      "    mean_inference_ms: 2.8549098997233626\n",
      "    mean_raw_obs_processing_ms: 3.5223620333031405\n",
      "  time_since_restore: 80756.84578752518\n",
      "  time_this_iter_s: 154.09130358695984\n",
      "  time_total_s: 80756.84578752518\n",
      "  timers:\n",
      "    learn_throughput: 932.204\n",
      "    learn_time_ms: 10722.975\n",
      "    load_throughput: 90427.061\n",
      "    load_time_ms: 110.542\n",
      "    sample_throughput: 65.202\n",
      "    sample_time_ms: 153307.668\n",
      "    update_time_ms: 13.481\n",
      "  timestamp: 1636375186\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5147940\n",
      "  training_iteration: 515\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   515</td><td style=\"text-align: right;\">         80756.8</td><td style=\"text-align: right;\">5147940</td><td style=\"text-align: right;\"> 4.60727</td><td style=\"text-align: right;\">               15.02</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           90.1455</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5157936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-42-21\n",
      "  done: false\n",
      "  episode_len_mean: 91.22727272727273\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.010000000000016\n",
      "  episode_reward_mean: 4.325272727272737\n",
      "  episode_reward_min: -1.260000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 56149\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.121546081192473\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013831795789555129\n",
      "          policy_loss: -0.06321733113951408\n",
      "          total_loss: 0.12992740764609004\n",
      "          vf_explained_var: 0.9294537901878357\n",
      "          vf_loss: 0.18284963903964585\n",
      "    num_agent_steps_sampled: 5157936\n",
      "    num_agent_steps_trained: 5157936\n",
      "    num_steps_sampled: 5157936\n",
      "    num_steps_trained: 5157936\n",
      "  iterations_since_restore: 516\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.92342342342343\n",
      "    ram_util_percent: 57.28333333333333\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045563317531037095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05230251285359\n",
      "    mean_inference_ms: 2.8547165652941233\n",
      "    mean_raw_obs_processing_ms: 3.5205921360668855\n",
      "  time_since_restore: 80912.34474110603\n",
      "  time_this_iter_s: 155.49895358085632\n",
      "  time_total_s: 80912.34474110603\n",
      "  timers:\n",
      "    learn_throughput: 931.915\n",
      "    learn_time_ms: 10726.301\n",
      "    load_throughput: 90427.237\n",
      "    load_time_ms: 110.542\n",
      "    sample_throughput: 66.517\n",
      "    sample_time_ms: 150278.471\n",
      "    update_time_ms: 13.264\n",
      "  timestamp: 1636375341\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5157936\n",
      "  training_iteration: 516\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   516</td><td style=\"text-align: right;\">         80912.3</td><td style=\"text-align: right;\">5157936</td><td style=\"text-align: right;\"> 4.32527</td><td style=\"text-align: right;\">               13.01</td><td style=\"text-align: right;\">               -1.26</td><td style=\"text-align: right;\">           91.2273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5167932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-45-15\n",
      "  done: false\n",
      "  episode_len_mean: 92.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.570000000000007\n",
      "  episode_reward_mean: 4.7620370370370475\n",
      "  episode_reward_min: -1.5000000000000009\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 56257\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1112727558510933\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014972380058203734\n",
      "          policy_loss: -0.06281865862731495\n",
      "          total_loss: 0.1569626497088844\n",
      "          vf_explained_var: 0.9303189516067505\n",
      "          vf_loss: 0.20678508086846425\n",
      "    num_agent_steps_sampled: 5167932\n",
      "    num_agent_steps_trained: 5167932\n",
      "    num_steps_sampled: 5167932\n",
      "    num_steps_trained: 5167932\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.93104838709678\n",
      "    ram_util_percent: 57.33991935483872\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045542342771080824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.053755404644214\n",
      "    mean_inference_ms: 2.854921366162057\n",
      "    mean_raw_obs_processing_ms: 3.5216161637930656\n",
      "  time_since_restore: 81085.82061171532\n",
      "  time_this_iter_s: 173.47587060928345\n",
      "  time_total_s: 81085.82061171532\n",
      "  timers:\n",
      "    learn_throughput: 931.995\n",
      "    learn_time_ms: 10725.375\n",
      "    load_throughput: 90617.15\n",
      "    load_time_ms: 110.31\n",
      "    sample_throughput: 66.031\n",
      "    sample_time_ms: 151382.809\n",
      "    update_time_ms: 12.582\n",
      "  timestamp: 1636375515\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5167932\n",
      "  training_iteration: 517\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   517</td><td style=\"text-align: right;\">         81085.8</td><td style=\"text-align: right;\">5167932</td><td style=\"text-align: right;\"> 4.76204</td><td style=\"text-align: right;\">               16.57</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">              92.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5177928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-47-39\n",
      "  done: false\n",
      "  episode_len_mean: 92.55140186915888\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 4.221308411214962\n",
      "  episode_reward_min: -1.770000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 56364\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.123118661203955\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013749952311232948\n",
      "          policy_loss: -0.05825027614736404\n",
      "          total_loss: 0.15838154334590857\n",
      "          vf_explained_var: 0.920340895652771\n",
      "          vf_loss: 0.20653889369315062\n",
      "    num_agent_steps_sampled: 5177928\n",
      "    num_agent_steps_trained: 5177928\n",
      "    num_steps_sampled: 5177928\n",
      "    num_steps_trained: 5177928\n",
      "  iterations_since_restore: 518\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.09756097560975\n",
      "    ram_util_percent: 57.30146341463416\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045574219056081014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05944310504481\n",
      "    mean_inference_ms: 2.855051839578114\n",
      "    mean_raw_obs_processing_ms: 3.516889507850863\n",
      "  time_since_restore: 81229.70157909393\n",
      "  time_this_iter_s: 143.88096737861633\n",
      "  time_total_s: 81229.70157909393\n",
      "  timers:\n",
      "    learn_throughput: 932.16\n",
      "    learn_time_ms: 10723.476\n",
      "    load_throughput: 90799.82\n",
      "    load_time_ms: 110.088\n",
      "    sample_throughput: 66.487\n",
      "    sample_time_ms: 150346.244\n",
      "    update_time_ms: 11.903\n",
      "  timestamp: 1636375659\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5177928\n",
      "  training_iteration: 518\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   518</td><td style=\"text-align: right;\">         81229.7</td><td style=\"text-align: right;\">5177928</td><td style=\"text-align: right;\"> 4.22131</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           92.5514</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5187924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-50-22\n",
      "  done: false\n",
      "  episode_len_mean: 93.45370370370371\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.200000000000012\n",
      "  episode_reward_mean: 4.577685185185196\n",
      "  episode_reward_min: -1.3400000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 56472\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.11795610658124\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014236283935989564\n",
      "          policy_loss: -0.06187961858848476\n",
      "          total_loss: 0.16955589204867427\n",
      "          vf_explained_var: 0.9234325885772705\n",
      "          vf_loss: 0.22018303617389284\n",
      "    num_agent_steps_sampled: 5187924\n",
      "    num_agent_steps_trained: 5187924\n",
      "    num_steps_sampled: 5187924\n",
      "    num_steps_trained: 5187924\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.63418803418804\n",
      "    ram_util_percent: 57.18076923076923\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553102847585006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05614643774129\n",
      "    mean_inference_ms: 2.854832806499727\n",
      "    mean_raw_obs_processing_ms: 3.5234338143267454\n",
      "  time_since_restore: 81393.18763113022\n",
      "  time_this_iter_s: 163.4860520362854\n",
      "  time_total_s: 81393.18763113022\n",
      "  timers:\n",
      "    learn_throughput: 932.176\n",
      "    learn_time_ms: 10723.292\n",
      "    load_throughput: 90706.058\n",
      "    load_time_ms: 110.202\n",
      "    sample_throughput: 67.363\n",
      "    sample_time_ms: 148389.752\n",
      "    update_time_ms: 12.036\n",
      "  timestamp: 1636375822\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5187924\n",
      "  training_iteration: 519\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   519</td><td style=\"text-align: right;\">         81393.2</td><td style=\"text-align: right;\">5187924</td><td style=\"text-align: right;\"> 4.57769</td><td style=\"text-align: right;\">                13.2</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           93.4537</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5197920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-52-56\n",
      "  done: false\n",
      "  episode_len_mean: 91.87037037037037\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.240000000000006\n",
      "  episode_reward_mean: 4.518148148148158\n",
      "  episode_reward_min: -1.3100000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 56580\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1097878304302182\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013617577171121645\n",
      "          policy_loss: -0.06161391684849166\n",
      "          total_loss: 0.14340945755760384\n",
      "          vf_explained_var: 0.927269697189331\n",
      "          vf_loss: 0.19509871038648052\n",
      "    num_agent_steps_sampled: 5197920\n",
      "    num_agent_steps_trained: 5197920\n",
      "    num_steps_sampled: 5197920\n",
      "    num_steps_trained: 5197920\n",
      "  iterations_since_restore: 520\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.58995433789954\n",
      "    ram_util_percent: 57.46803652968037\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553028459151315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05709200118369\n",
      "    mean_inference_ms: 2.8548707753671754\n",
      "    mean_raw_obs_processing_ms: 3.5213957798098385\n",
      "  time_since_restore: 81546.7166249752\n",
      "  time_this_iter_s: 153.52899384498596\n",
      "  time_total_s: 81546.7166249752\n",
      "  timers:\n",
      "    learn_throughput: 932.573\n",
      "    learn_time_ms: 10718.735\n",
      "    load_throughput: 90904.831\n",
      "    load_time_ms: 109.961\n",
      "    sample_throughput: 68.376\n",
      "    sample_time_ms: 146192.053\n",
      "    update_time_ms: 11.845\n",
      "  timestamp: 1636375976\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5197920\n",
      "  training_iteration: 520\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   520</td><td style=\"text-align: right;\">         81546.7</td><td style=\"text-align: right;\">5197920</td><td style=\"text-align: right;\"> 4.51815</td><td style=\"text-align: right;\">               16.24</td><td style=\"text-align: right;\">               -1.31</td><td style=\"text-align: right;\">           91.8704</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5207916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-55-19\n",
      "  done: false\n",
      "  episode_len_mean: 92.40366972477064\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.60000000000002\n",
      "  episode_reward_mean: 3.763119266055054\n",
      "  episode_reward_min: -1.3800000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 56689\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.115632369579413\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013957235410577048\n",
      "          policy_loss: -0.061212314729793715\n",
      "          total_loss: 0.1457759821262115\n",
      "          vf_explained_var: 0.911159098148346\n",
      "          vf_loss: 0.19634829252066777\n",
      "    num_agent_steps_sampled: 5207916\n",
      "    num_agent_steps_trained: 5207916\n",
      "    num_steps_sampled: 5207916\n",
      "    num_steps_trained: 5207916\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96048780487806\n",
      "    ram_util_percent: 57.3878048780488\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556276577492002\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06181520411853\n",
      "    mean_inference_ms: 2.8550771619309807\n",
      "    mean_raw_obs_processing_ms: 3.516543227032784\n",
      "  time_since_restore: 81690.4888792038\n",
      "  time_this_iter_s: 143.77225422859192\n",
      "  time_total_s: 81690.4888792038\n",
      "  timers:\n",
      "    learn_throughput: 932.826\n",
      "    learn_time_ms: 10715.824\n",
      "    load_throughput: 90986.129\n",
      "    load_time_ms: 109.863\n",
      "    sample_throughput: 68.331\n",
      "    sample_time_ms: 146288.541\n",
      "    update_time_ms: 12.351\n",
      "  timestamp: 1636376119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5207916\n",
      "  training_iteration: 521\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   521</td><td style=\"text-align: right;\">         81690.5</td><td style=\"text-align: right;\">5207916</td><td style=\"text-align: right;\"> 3.76312</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           92.4037</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5217912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_12-58-05\n",
      "  done: false\n",
      "  episode_len_mean: 91.77777777777777\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000016\n",
      "  episode_reward_mean: 3.854907407407415\n",
      "  episode_reward_min: -1.4600000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 56797\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1061897431683336\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013120371759991112\n",
      "          policy_loss: -0.06321739338211015\n",
      "          total_loss: 0.13204655883212885\n",
      "          vf_explained_var: 0.9357517957687378\n",
      "          vf_loss: 0.18643600097101212\n",
      "    num_agent_steps_sampled: 5217912\n",
      "    num_agent_steps_trained: 5217912\n",
      "    num_steps_sampled: 5217912\n",
      "    num_steps_trained: 5217912\n",
      "  iterations_since_restore: 522\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.08220338983051\n",
      "    ram_util_percent: 57.17711864406781\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045552693287716384\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06317775258572\n",
      "    mean_inference_ms: 2.8549583381722874\n",
      "    mean_raw_obs_processing_ms: 3.5227385524998938\n",
      "  time_since_restore: 81855.70061445236\n",
      "  time_this_iter_s: 165.21173524856567\n",
      "  time_total_s: 81855.70061445236\n",
      "  timers:\n",
      "    learn_throughput: 932.762\n",
      "    learn_time_ms: 10716.556\n",
      "    load_throughput: 91392.379\n",
      "    load_time_ms: 109.375\n",
      "    sample_throughput: 67.987\n",
      "    sample_time_ms: 147027.699\n",
      "    update_time_ms: 12.817\n",
      "  timestamp: 1636376285\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5217912\n",
      "  training_iteration: 522\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   522</td><td style=\"text-align: right;\">         81855.7</td><td style=\"text-align: right;\">5217912</td><td style=\"text-align: right;\"> 3.85491</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           91.7778</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5227908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-00-49\n",
      "  done: false\n",
      "  episode_len_mean: 91.6788990825688\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.84000000000002\n",
      "  episode_reward_mean: 3.9786238532110185\n",
      "  episode_reward_min: -1.0200000000000002\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 56906\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.117904774347941\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012920226079659267\n",
      "          policy_loss: -0.06282846046627587\n",
      "          total_loss: 0.11593650874132529\n",
      "          vf_explained_var: 0.9414200186729431\n",
      "          vf_loss: 0.17051012660098128\n",
      "    num_agent_steps_sampled: 5227908\n",
      "    num_agent_steps_trained: 5227908\n",
      "    num_steps_sampled: 5227908\n",
      "    num_steps_trained: 5227908\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.66382978723404\n",
      "    ram_util_percent: 57.4608510638298\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552659394804053\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.061371704247\n",
      "    mean_inference_ms: 2.8549520051896558\n",
      "    mean_raw_obs_processing_ms: 3.5242755230246474\n",
      "  time_since_restore: 82020.4221599102\n",
      "  time_this_iter_s: 164.72154545783997\n",
      "  time_total_s: 82020.4221599102\n",
      "  timers:\n",
      "    learn_throughput: 932.985\n",
      "    learn_time_ms: 10713.993\n",
      "    load_throughput: 91778.217\n",
      "    load_time_ms: 108.915\n",
      "    sample_throughput: 68.043\n",
      "    sample_time_ms: 146907.697\n",
      "    update_time_ms: 12.488\n",
      "  timestamp: 1636376449\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5227908\n",
      "  training_iteration: 523\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   523</td><td style=\"text-align: right;\">         82020.4</td><td style=\"text-align: right;\">5227908</td><td style=\"text-align: right;\"> 3.97862</td><td style=\"text-align: right;\">               10.84</td><td style=\"text-align: right;\">               -1.02</td><td style=\"text-align: right;\">           91.6789</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5237904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-03-13\n",
      "  done: false\n",
      "  episode_len_mean: 92.56880733944953\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.070000000000018\n",
      "  episode_reward_mean: 4.028165137614689\n",
      "  episode_reward_min: -1.5800000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 57015\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1287213825771953\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014042567156743005\n",
      "          policy_loss: -0.06329085616410797\n",
      "          total_loss: 0.12138225234822075\n",
      "          vf_explained_var: 0.928408145904541\n",
      "          vf_loss: 0.1739695975318169\n",
      "    num_agent_steps_sampled: 5237904\n",
      "    num_agent_steps_trained: 5237904\n",
      "    num_steps_sampled: 5237904\n",
      "    num_steps_trained: 5237904\n",
      "  iterations_since_restore: 524\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08872549019607\n",
      "    ram_util_percent: 57.32892156862747\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045531242894455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06548811580031\n",
      "    mean_inference_ms: 2.855042232972437\n",
      "    mean_raw_obs_processing_ms: 3.5190253685273625\n",
      "  time_since_restore: 82163.89579510689\n",
      "  time_this_iter_s: 143.4736351966858\n",
      "  time_total_s: 82163.89579510689\n",
      "  timers:\n",
      "    learn_throughput: 933.283\n",
      "    learn_time_ms: 10710.583\n",
      "    load_throughput: 91735.665\n",
      "    load_time_ms: 108.965\n",
      "    sample_throughput: 68.811\n",
      "    sample_time_ms: 145268.339\n",
      "    update_time_ms: 12.86\n",
      "  timestamp: 1636376593\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5237904\n",
      "  training_iteration: 524\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   524</td><td style=\"text-align: right;\">         82163.9</td><td style=\"text-align: right;\">5237904</td><td style=\"text-align: right;\"> 4.02817</td><td style=\"text-align: right;\">               12.07</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           92.5688</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5247900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-06-05\n",
      "  done: false\n",
      "  episode_len_mean: 92.36697247706422\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.310000000000018\n",
      "  episode_reward_mean: 4.243302752293587\n",
      "  episode_reward_min: -1.3100000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 57124\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1224549461633733\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0141029891189659\n",
      "          policy_loss: -0.06211653473731289\n",
      "          total_loss: 0.1443781211001114\n",
      "          vf_explained_var: 0.9269353747367859\n",
      "          vf_loss: 0.19559083195546498\n",
      "    num_agent_steps_sampled: 5247900\n",
      "    num_agent_steps_trained: 5247900\n",
      "    num_steps_sampled: 5247900\n",
      "    num_steps_trained: 5247900\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.15999999999998\n",
      "    ram_util_percent: 57.29632653061225\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455688524419739\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.067701212576566\n",
      "    mean_inference_ms: 2.855018494704989\n",
      "    mean_raw_obs_processing_ms: 3.5237057835029826\n",
      "  time_since_restore: 82335.68059825897\n",
      "  time_this_iter_s: 171.78480315208435\n",
      "  time_total_s: 82335.68059825897\n",
      "  timers:\n",
      "    learn_throughput: 933.167\n",
      "    learn_time_ms: 10711.907\n",
      "    load_throughput: 91710.963\n",
      "    load_time_ms: 108.995\n",
      "    sample_throughput: 67.983\n",
      "    sample_time_ms: 147035.886\n",
      "    update_time_ms: 13.502\n",
      "  timestamp: 1636376765\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5247900\n",
      "  training_iteration: 525\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   525</td><td style=\"text-align: right;\">         82335.7</td><td style=\"text-align: right;\">5247900</td><td style=\"text-align: right;\">  4.2433</td><td style=\"text-align: right;\">               12.31</td><td style=\"text-align: right;\">               -1.31</td><td style=\"text-align: right;\">            92.367</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5257896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-09-15\n",
      "  done: false\n",
      "  episode_len_mean: 88.65178571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.340000000000016\n",
      "  episode_reward_mean: 4.559196428571438\n",
      "  episode_reward_min: -0.8100000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 57236\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0867025793108165\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014236735597800042\n",
      "          policy_loss: -0.05921387435215661\n",
      "          total_loss: 0.15112157918863062\n",
      "          vf_explained_var: 0.9311022758483887\n",
      "          vf_loss: 0.1987694161856531\n",
      "    num_agent_steps_sampled: 5257896\n",
      "    num_agent_steps_trained: 5257896\n",
      "    num_steps_sampled: 5257896\n",
      "    num_steps_trained: 5257896\n",
      "  iterations_since_restore: 526\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.2059040590406\n",
      "    ram_util_percent: 57.38044280442806\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045558084842896404\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.066397566436265\n",
      "    mean_inference_ms: 2.8547812651163538\n",
      "    mean_raw_obs_processing_ms: 3.539023214603534\n",
      "  time_since_restore: 82525.50880742073\n",
      "  time_this_iter_s: 189.82820916175842\n",
      "  time_total_s: 82525.50880742073\n",
      "  timers:\n",
      "    learn_throughput: 933.105\n",
      "    learn_time_ms: 10712.623\n",
      "    load_throughput: 91597.657\n",
      "    load_time_ms: 109.129\n",
      "    sample_throughput: 66.433\n",
      "    sample_time_ms: 150467.205\n",
      "    update_time_ms: 14.316\n",
      "  timestamp: 1636376955\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5257896\n",
      "  training_iteration: 526\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   526</td><td style=\"text-align: right;\">         82525.5</td><td style=\"text-align: right;\">5257896</td><td style=\"text-align: right;\">  4.5592</td><td style=\"text-align: right;\">               12.34</td><td style=\"text-align: right;\">               -0.81</td><td style=\"text-align: right;\">           88.6518</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5267892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-11-52\n",
      "  done: false\n",
      "  episode_len_mean: 93.58878504672897\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 4.259345794392533\n",
      "  episode_reward_min: -1.4200000000000008\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 57343\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.098027848586058\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014655866090834574\n",
      "          policy_loss: -0.0587108884850501\n",
      "          total_loss: 0.1639556520881179\n",
      "          vf_explained_var: 0.9283369779586792\n",
      "          vf_loss: 0.2102589237670868\n",
      "    num_agent_steps_sampled: 5267892\n",
      "    num_agent_steps_trained: 5267892\n",
      "    num_steps_sampled: 5267892\n",
      "    num_steps_trained: 5267892\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.72666666666667\n",
      "    ram_util_percent: 57.415111111111116\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045574993578296474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.065720910779774\n",
      "    mean_inference_ms: 2.8549725404556616\n",
      "    mean_raw_obs_processing_ms: 3.539400507806722\n",
      "  time_since_restore: 82683.16196084023\n",
      "  time_this_iter_s: 157.65315341949463\n",
      "  time_total_s: 82683.16196084023\n",
      "  timers:\n",
      "    learn_throughput: 933.221\n",
      "    learn_time_ms: 10711.295\n",
      "    load_throughput: 91373.377\n",
      "    load_time_ms: 109.397\n",
      "    sample_throughput: 67.139\n",
      "    sample_time_ms: 148885.859\n",
      "    update_time_ms: 14.525\n",
      "  timestamp: 1636377112\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5267892\n",
      "  training_iteration: 527\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   527</td><td style=\"text-align: right;\">         82683.2</td><td style=\"text-align: right;\">5267892</td><td style=\"text-align: right;\"> 4.25935</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           93.5888</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5277888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-14-24\n",
      "  done: false\n",
      "  episode_len_mean: 94.12380952380953\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000019\n",
      "  episode_reward_mean: 4.346380952380963\n",
      "  episode_reward_min: -1.1400000000000003\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 57448\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1300883459229754\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013496976871551884\n",
      "          policy_loss: -0.06485281226058037\n",
      "          total_loss: 0.14791298045848425\n",
      "          vf_explained_var: 0.9276853203773499\n",
      "          vf_loss: 0.20331887528618686\n",
      "    num_agent_steps_sampled: 5277888\n",
      "    num_agent_steps_trained: 5277888\n",
      "    num_steps_sampled: 5277888\n",
      "    num_steps_trained: 5277888\n",
      "  iterations_since_restore: 528\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.91851851851852\n",
      "    ram_util_percent: 57.365740740740755\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555416208419636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.065776734572495\n",
      "    mean_inference_ms: 2.8548087319350923\n",
      "    mean_raw_obs_processing_ms: 3.537433452738536\n",
      "  time_since_restore: 82834.56305456161\n",
      "  time_this_iter_s: 151.40109372138977\n",
      "  time_total_s: 82834.56305456161\n",
      "  timers:\n",
      "    learn_throughput: 933.105\n",
      "    learn_time_ms: 10712.624\n",
      "    load_throughput: 91136.778\n",
      "    load_time_ms: 109.681\n",
      "    sample_throughput: 66.802\n",
      "    sample_time_ms: 149635.855\n",
      "    update_time_ms: 14.666\n",
      "  timestamp: 1636377264\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5277888\n",
      "  training_iteration: 528\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   528</td><td style=\"text-align: right;\">         82834.6</td><td style=\"text-align: right;\">5277888</td><td style=\"text-align: right;\"> 4.34638</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           94.1238</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5287884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-16-54\n",
      "  done: false\n",
      "  episode_len_mean: 93.6355140186916\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.550000000000017\n",
      "  episode_reward_mean: 4.1935514018691675\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 57555\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.103852041766175\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013829866216996329\n",
      "          policy_loss: -0.062081591106760196\n",
      "          total_loss: 0.1409207211433249\n",
      "          vf_explained_var: 0.9276747107505798\n",
      "          vf_loss: 0.19253466809088857\n",
      "    num_agent_steps_sampled: 5287884\n",
      "    num_agent_steps_trained: 5287884\n",
      "    num_steps_sampled: 5287884\n",
      "    num_steps_trained: 5287884\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.03162790697675\n",
      "    ram_util_percent: 57.2846511627907\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045550832771908266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06725535226125\n",
      "    mean_inference_ms: 2.854882545502036\n",
      "    mean_raw_obs_processing_ms: 3.535290705770368\n",
      "  time_since_restore: 82984.59155273438\n",
      "  time_this_iter_s: 150.02849817276\n",
      "  time_total_s: 82984.59155273438\n",
      "  timers:\n",
      "    learn_throughput: 933.215\n",
      "    learn_time_ms: 10711.363\n",
      "    load_throughput: 91016.527\n",
      "    load_time_ms: 109.826\n",
      "    sample_throughput: 67.408\n",
      "    sample_time_ms: 148291.388\n",
      "    update_time_ms: 14.059\n",
      "  timestamp: 1636377414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5287884\n",
      "  training_iteration: 529\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   529</td><td style=\"text-align: right;\">         82984.6</td><td style=\"text-align: right;\">5287884</td><td style=\"text-align: right;\"> 4.19355</td><td style=\"text-align: right;\">               12.55</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           93.6355</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5297880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-19-44\n",
      "  done: false\n",
      "  episode_len_mean: 91.4770642201835\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.56000000000002\n",
      "  episode_reward_mean: 4.007522935779825\n",
      "  episode_reward_min: -1.4100000000000004\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 57664\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.111947026721433\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013446435920724765\n",
      "          policy_loss: -0.056443963015181384\n",
      "          total_loss: 0.17800765629523457\n",
      "          vf_explained_var: 0.9089188575744629\n",
      "          vf_loss: 0.22493842656636595\n",
      "    num_agent_steps_sampled: 5297880\n",
      "    num_agent_steps_trained: 5297880\n",
      "    num_steps_sampled: 5297880\n",
      "    num_steps_trained: 5297880\n",
      "  iterations_since_restore: 530\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.33677685950413\n",
      "    ram_util_percent: 57.314049586776854\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555585300249116\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06806999442557\n",
      "    mean_inference_ms: 2.8547126629162176\n",
      "    mean_raw_obs_processing_ms: 3.539664922515507\n",
      "  time_since_restore: 83154.50793337822\n",
      "  time_this_iter_s: 169.9163806438446\n",
      "  time_total_s: 83154.50793337822\n",
      "  timers:\n",
      "    learn_throughput: 933.379\n",
      "    learn_time_ms: 10709.481\n",
      "    load_throughput: 90887.687\n",
      "    load_time_ms: 109.982\n",
      "    sample_throughput: 66.67\n",
      "    sample_time_ms: 149932.143\n",
      "    update_time_ms: 13.976\n",
      "  timestamp: 1636377584\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5297880\n",
      "  training_iteration: 530\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   530</td><td style=\"text-align: right;\">         83154.5</td><td style=\"text-align: right;\">5297880</td><td style=\"text-align: right;\"> 4.00752</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           91.4771</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5307876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-22-05\n",
      "  done: false\n",
      "  episode_len_mean: 93.81308411214954\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.400000000000016\n",
      "  episode_reward_mean: 4.543551401869169\n",
      "  episode_reward_min: -1.0300000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 57771\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1086813394839945\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013090634785011365\n",
      "          policy_loss: -0.058955756531885034\n",
      "          total_loss: 0.1524802708520721\n",
      "          vf_explained_var: 0.9332290291786194\n",
      "          vf_loss: 0.2027007366076876\n",
      "    num_agent_steps_sampled: 5307876\n",
      "    num_agent_steps_trained: 5307876\n",
      "    num_steps_sampled: 5307876\n",
      "    num_steps_trained: 5307876\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.17574257425743\n",
      "    ram_util_percent: 57.3950495049505\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045553028232536645\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.071527315659566\n",
      "    mean_inference_ms: 2.8549278995906495\n",
      "    mean_raw_obs_processing_ms: 3.5343793106763837\n",
      "  time_since_restore: 83295.8056666851\n",
      "  time_this_iter_s: 141.29773330688477\n",
      "  time_total_s: 83295.8056666851\n",
      "  timers:\n",
      "    learn_throughput: 933.398\n",
      "    learn_time_ms: 10709.254\n",
      "    load_throughput: 90692.323\n",
      "    load_time_ms: 110.219\n",
      "    sample_throughput: 66.779\n",
      "    sample_time_ms: 149686.8\n",
      "    update_time_ms: 12.089\n",
      "  timestamp: 1636377725\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5307876\n",
      "  training_iteration: 531\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   531</td><td style=\"text-align: right;\">         83295.8</td><td style=\"text-align: right;\">5307876</td><td style=\"text-align: right;\"> 4.54355</td><td style=\"text-align: right;\">                14.4</td><td style=\"text-align: right;\">               -1.03</td><td style=\"text-align: right;\">           93.8131</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5317872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-24-53\n",
      "  done: false\n",
      "  episode_len_mean: 92.19444444444444\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000018\n",
      "  episode_reward_mean: 4.868518518518528\n",
      "  episode_reward_min: 0.20999999999999885\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 57879\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0957597552201688\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013235945593683088\n",
      "          policy_loss: -0.05968620150198794\n",
      "          total_loss: 0.15888229465573772\n",
      "          vf_explained_var: 0.9284929037094116\n",
      "          vf_loss: 0.20937295434757686\n",
      "    num_agent_steps_sampled: 5317872\n",
      "    num_agent_steps_trained: 5317872\n",
      "    num_steps_sampled: 5317872\n",
      "    num_steps_trained: 5317872\n",
      "  iterations_since_restore: 532\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.35146443514645\n",
      "    ram_util_percent: 57.41924686192469\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556135317970832\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.071132133692174\n",
      "    mean_inference_ms: 2.8549187119237183\n",
      "    mean_raw_obs_processing_ms: 3.53876657718747\n",
      "  time_since_restore: 83463.32721590996\n",
      "  time_this_iter_s: 167.52154922485352\n",
      "  time_total_s: 83463.32721590996\n",
      "  timers:\n",
      "    learn_throughput: 933.567\n",
      "    learn_time_ms: 10707.325\n",
      "    load_throughput: 90587.136\n",
      "    load_time_ms: 110.347\n",
      "    sample_throughput: 66.676\n",
      "    sample_time_ms: 149919.945\n",
      "    update_time_ms: 11.704\n",
      "  timestamp: 1636377893\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5317872\n",
      "  training_iteration: 532\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   532</td><td style=\"text-align: right;\">         83463.3</td><td style=\"text-align: right;\">5317872</td><td style=\"text-align: right;\"> 4.86852</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                0.21</td><td style=\"text-align: right;\">           92.1944</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5327868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-27-36\n",
      "  done: false\n",
      "  episode_len_mean: 92.25688073394495\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.709999999999994\n",
      "  episode_reward_mean: 5.014036697247717\n",
      "  episode_reward_min: -1.3300000000000003\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 57988\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0825749575582324\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013982716474234717\n",
      "          policy_loss: -0.059735090143851234\n",
      "          total_loss: 0.15998104583535694\n",
      "          vf_explained_var: 0.936674177646637\n",
      "          vf_loss: 0.208687508580649\n",
      "    num_agent_steps_sampled: 5327868\n",
      "    num_agent_steps_trained: 5327868\n",
      "    num_steps_sampled: 5327868\n",
      "    num_steps_trained: 5327868\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.01637931034485\n",
      "    ram_util_percent: 57.43836206896552\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555357691797147\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07091063019144\n",
      "    mean_inference_ms: 2.8546813275276097\n",
      "    mean_raw_obs_processing_ms: 3.540126144824347\n",
      "  time_since_restore: 83626.32227015495\n",
      "  time_this_iter_s: 162.99505424499512\n",
      "  time_total_s: 83626.32227015495\n",
      "  timers:\n",
      "    learn_throughput: 932.622\n",
      "    learn_time_ms: 10718.17\n",
      "    load_throughput: 90629.843\n",
      "    load_time_ms: 110.295\n",
      "    sample_throughput: 66.757\n",
      "    sample_time_ms: 149736.177\n",
      "    update_time_ms: 11.839\n",
      "  timestamp: 1636378056\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5327868\n",
      "  training_iteration: 533\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   533</td><td style=\"text-align: right;\">         83626.3</td><td style=\"text-align: right;\">5327868</td><td style=\"text-align: right;\"> 5.01404</td><td style=\"text-align: right;\">               16.71</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">           92.2569</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5337864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-30-32\n",
      "  done: false\n",
      "  episode_len_mean: 91.12844036697248\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.960000000000013\n",
      "  episode_reward_mean: 4.142201834862394\n",
      "  episode_reward_min: -1.2900000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 58097\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0958415668234864\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01404722303592444\n",
      "          policy_loss: -0.06038371780170844\n",
      "          total_loss: 0.1562538922708641\n",
      "          vf_explained_var: 0.9165080785751343\n",
      "          vf_loss: 0.20559469498853145\n",
      "    num_agent_steps_sampled: 5337864\n",
      "    num_agent_steps_trained: 5337864\n",
      "    num_steps_sampled: 5337864\n",
      "    num_steps_trained: 5337864\n",
      "  iterations_since_restore: 534\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.05\n",
      "    ram_util_percent: 57.494444444444454\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552372742227784\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06729095906843\n",
      "    mean_inference_ms: 2.8547522438183615\n",
      "    mean_raw_obs_processing_ms: 3.544577136311925\n",
      "  time_since_restore: 83802.68705224991\n",
      "  time_this_iter_s: 176.36478209495544\n",
      "  time_total_s: 83802.68705224991\n",
      "  timers:\n",
      "    learn_throughput: 932.555\n",
      "    learn_time_ms: 10718.94\n",
      "    load_throughput: 90470.204\n",
      "    load_time_ms: 110.489\n",
      "    sample_throughput: 65.324\n",
      "    sample_time_ms: 153022.57\n",
      "    update_time_ms: 13.292\n",
      "  timestamp: 1636378232\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5337864\n",
      "  training_iteration: 534\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   534</td><td style=\"text-align: right;\">         83802.7</td><td style=\"text-align: right;\">5337864</td><td style=\"text-align: right;\">  4.1422</td><td style=\"text-align: right;\">               12.96</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           91.1284</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5347860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-33-10\n",
      "  done: false\n",
      "  episode_len_mean: 92.12962962962963\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.69000000000002\n",
      "  episode_reward_mean: 4.184722222222231\n",
      "  episode_reward_min: -1.0200000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 58205\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.10811417265835\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014250946977197967\n",
      "          policy_loss: -0.05814604886099059\n",
      "          total_loss: 0.1785970377210432\n",
      "          vf_explained_var: 0.9220886826515198\n",
      "          vf_loss: 0.22535879026588976\n",
      "    num_agent_steps_sampled: 5347860\n",
      "    num_agent_steps_trained: 5347860\n",
      "    num_steps_sampled: 5347860\n",
      "    num_steps_trained: 5347860\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.45535714285714\n",
      "    ram_util_percent: 57.310267857142875\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554676051376529\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.070047659272355\n",
      "    mean_inference_ms: 2.8546435612425975\n",
      "    mean_raw_obs_processing_ms: 3.545413588769078\n",
      "  time_since_restore: 83960.03381371498\n",
      "  time_this_iter_s: 157.34676146507263\n",
      "  time_total_s: 83960.03381371498\n",
      "  timers:\n",
      "    learn_throughput: 932.31\n",
      "    learn_time_ms: 10721.75\n",
      "    load_throughput: 90534.888\n",
      "    load_time_ms: 110.41\n",
      "    sample_throughput: 65.947\n",
      "    sample_time_ms: 151575.744\n",
      "    update_time_ms: 13.523\n",
      "  timestamp: 1636378390\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5347860\n",
      "  training_iteration: 535\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   535</td><td style=\"text-align: right;\">           83960</td><td style=\"text-align: right;\">5347860</td><td style=\"text-align: right;\"> 4.18472</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -1.02</td><td style=\"text-align: right;\">           92.1296</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5357856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-35-59\n",
      "  done: false\n",
      "  episode_len_mean: 91.32727272727273\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.150000000000013\n",
      "  episode_reward_mean: 4.803727272727284\n",
      "  episode_reward_min: -1.1199999999999972\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 58315\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1173803890872205\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013800225294744038\n",
      "          policy_loss: -0.06007792347421249\n",
      "          total_loss: 0.17518436686398509\n",
      "          vf_explained_var: 0.9313674569129944\n",
      "          vf_loss: 0.22499745287574255\n",
      "    num_agent_steps_sampled: 5357856\n",
      "    num_agent_steps_trained: 5357856\n",
      "    num_steps_sampled: 5357856\n",
      "    num_steps_trained: 5357856\n",
      "  iterations_since_restore: 536\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.8900826446281\n",
      "    ram_util_percent: 57.38719008264463\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045525994881159326\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.069579966917814\n",
      "    mean_inference_ms: 2.854348412698475\n",
      "    mean_raw_obs_processing_ms: 3.5499949321653745\n",
      "  time_since_restore: 84129.47037172318\n",
      "  time_this_iter_s: 169.43655800819397\n",
      "  time_total_s: 84129.47037172318\n",
      "  timers:\n",
      "    learn_throughput: 932.649\n",
      "    learn_time_ms: 10717.857\n",
      "    load_throughput: 90501.606\n",
      "    load_time_ms: 110.451\n",
      "    sample_throughput: 66.844\n",
      "    sample_time_ms: 149541.594\n",
      "    update_time_ms: 12.29\n",
      "  timestamp: 1636378559\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5357856\n",
      "  training_iteration: 536\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   536</td><td style=\"text-align: right;\">         84129.5</td><td style=\"text-align: right;\">5357856</td><td style=\"text-align: right;\"> 4.80373</td><td style=\"text-align: right;\">               15.15</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">           91.3273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5367852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-38-34\n",
      "  done: false\n",
      "  episode_len_mean: 92.5137614678899\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.230000000000013\n",
      "  episode_reward_mean: 3.9913761467890003\n",
      "  episode_reward_min: -1.0300000000000002\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 58424\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1158148866433364\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013696671013788731\n",
      "          policy_loss: -0.06124350930381025\n",
      "          total_loss: 0.1605529491805559\n",
      "          vf_explained_var: 0.9235116839408875\n",
      "          vf_loss: 0.2117518772936275\n",
      "    num_agent_steps_sampled: 5367852\n",
      "    num_agent_steps_trained: 5367852\n",
      "    num_steps_sampled: 5367852\n",
      "    num_steps_trained: 5367852\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.5954954954955\n",
      "    ram_util_percent: 57.41396396396397\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554490673749717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.071482187068156\n",
      "    mean_inference_ms: 2.8544781046983303\n",
      "    mean_raw_obs_processing_ms: 3.54799366317151\n",
      "  time_since_restore: 84284.61229300499\n",
      "  time_this_iter_s: 155.14192128181458\n",
      "  time_total_s: 84284.61229300499\n",
      "  timers:\n",
      "    learn_throughput: 932.327\n",
      "    learn_time_ms: 10721.556\n",
      "    load_throughput: 90544.37\n",
      "    load_time_ms: 110.399\n",
      "    sample_throughput: 66.958\n",
      "    sample_time_ms: 149287.392\n",
      "    update_time_ms: 11.735\n",
      "  timestamp: 1636378714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5367852\n",
      "  training_iteration: 537\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   537</td><td style=\"text-align: right;\">         84284.6</td><td style=\"text-align: right;\">5367852</td><td style=\"text-align: right;\"> 3.99138</td><td style=\"text-align: right;\">               11.23</td><td style=\"text-align: right;\">               -1.03</td><td style=\"text-align: right;\">           92.5138</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5377848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-41-27\n",
      "  done: false\n",
      "  episode_len_mean: 93.08333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000014\n",
      "  episode_reward_mean: 4.814351851851863\n",
      "  episode_reward_min: -1.5100000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 58532\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.113657966434446\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01365897501662787\n",
      "          policy_loss: -0.059253093913898\n",
      "          total_loss: 0.15795752851085532\n",
      "          vf_explained_var: 0.921197235584259\n",
      "          vf_loss: 0.20723034830556974\n",
      "    num_agent_steps_sampled: 5377848\n",
      "    num_agent_steps_trained: 5377848\n",
      "    num_steps_sampled: 5377848\n",
      "    num_steps_trained: 5377848\n",
      "  iterations_since_restore: 538\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.03943089430894\n",
      "    ram_util_percent: 57.486585365853664\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556498262521021\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07429656909272\n",
      "    mean_inference_ms: 2.854625725237414\n",
      "    mean_raw_obs_processing_ms: 3.549144546381061\n",
      "  time_since_restore: 84457.1642332077\n",
      "  time_this_iter_s: 172.551940202713\n",
      "  time_total_s: 84457.1642332077\n",
      "  timers:\n",
      "    learn_throughput: 932.333\n",
      "    learn_time_ms: 10721.491\n",
      "    load_throughput: 90785.958\n",
      "    load_time_ms: 110.105\n",
      "    sample_throughput: 66.023\n",
      "    sample_time_ms: 151402.358\n",
      "    update_time_ms: 12.556\n",
      "  timestamp: 1636378887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5377848\n",
      "  training_iteration: 538\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   538</td><td style=\"text-align: right;\">         84457.2</td><td style=\"text-align: right;\">5377848</td><td style=\"text-align: right;\"> 4.81435</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">               -1.51</td><td style=\"text-align: right;\">           93.0833</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5387844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-44-18\n",
      "  done: false\n",
      "  episode_len_mean: 90.57798165137615\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.010000000000014\n",
      "  episode_reward_mean: 4.104311926605513\n",
      "  episode_reward_min: -1.1500000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 58641\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.079506234327952\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013938062567815214\n",
      "          policy_loss: -0.0572331278381917\n",
      "          total_loss: 0.1445187621511137\n",
      "          vf_explained_var: 0.92279452085495\n",
      "          vf_loss: 0.19079430221110327\n",
      "    num_agent_steps_sampled: 5387844\n",
      "    num_agent_steps_trained: 5387844\n",
      "    num_steps_sampled: 5387844\n",
      "    num_steps_trained: 5387844\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.94836065573772\n",
      "    ram_util_percent: 57.459016393442624\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045530167019991796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0725529887858\n",
      "    mean_inference_ms: 2.8545226701961264\n",
      "    mean_raw_obs_processing_ms: 3.5533915693096088\n",
      "  time_since_restore: 84628.02450037003\n",
      "  time_this_iter_s: 170.860267162323\n",
      "  time_total_s: 84628.02450037003\n",
      "  timers:\n",
      "    learn_throughput: 932.345\n",
      "    learn_time_ms: 10721.354\n",
      "    load_throughput: 90866.118\n",
      "    load_time_ms: 110.008\n",
      "    sample_throughput: 65.127\n",
      "    sample_time_ms: 153485.854\n",
      "    update_time_ms: 12.679\n",
      "  timestamp: 1636379058\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5387844\n",
      "  training_iteration: 539\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   539</td><td style=\"text-align: right;\">           84628</td><td style=\"text-align: right;\">5387844</td><td style=\"text-align: right;\"> 4.10431</td><td style=\"text-align: right;\">               15.01</td><td style=\"text-align: right;\">               -1.15</td><td style=\"text-align: right;\">            90.578</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5397840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-47-20\n",
      "  done: false\n",
      "  episode_len_mean: 92.19444444444444\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000014\n",
      "  episode_reward_mean: 4.414444444444454\n",
      "  episode_reward_min: -1.3700000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 58749\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1224972596535316\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013513202840703039\n",
      "          policy_loss: -0.05861307194886299\n",
      "          total_loss: 0.1473868373908803\n",
      "          vf_explained_var: 0.9261518716812134\n",
      "          vf_loss: 0.19644011633836816\n",
      "    num_agent_steps_sampled: 5397840\n",
      "    num_agent_steps_trained: 5397840\n",
      "    num_steps_sampled: 5397840\n",
      "    num_steps_trained: 5397840\n",
      "  iterations_since_restore: 540\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.54961538461538\n",
      "    ram_util_percent: 57.51730769230769\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045560800462298386\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.071869184722665\n",
      "    mean_inference_ms: 2.8541877288808943\n",
      "    mean_raw_obs_processing_ms: 3.5581069673714905\n",
      "  time_since_restore: 84810.33022642136\n",
      "  time_this_iter_s: 182.30572605133057\n",
      "  time_total_s: 84810.33022642136\n",
      "  timers:\n",
      "    learn_throughput: 932.328\n",
      "    learn_time_ms: 10721.547\n",
      "    load_throughput: 90918.591\n",
      "    load_time_ms: 109.945\n",
      "    sample_throughput: 64.605\n",
      "    sample_time_ms: 154724.394\n",
      "    update_time_ms: 12.497\n",
      "  timestamp: 1636379240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5397840\n",
      "  training_iteration: 540\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   540</td><td style=\"text-align: right;\">         84810.3</td><td style=\"text-align: right;\">5397840</td><td style=\"text-align: right;\"> 4.41444</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">               -1.37</td><td style=\"text-align: right;\">           92.1944</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5407836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-50-15\n",
      "  done: false\n",
      "  episode_len_mean: 91.84545454545454\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.940000000000017\n",
      "  episode_reward_mean: 4.598545454545464\n",
      "  episode_reward_min: -1.4600000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 58859\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0993182665262466\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013523756899828326\n",
      "          policy_loss: -0.0604423452518944\n",
      "          total_loss: 0.16556128500045364\n",
      "          vf_explained_var: 0.9341967701911926\n",
      "          vf_loss: 0.21618800431362584\n",
      "    num_agent_steps_sampled: 5407836\n",
      "    num_agent_steps_trained: 5407836\n",
      "    num_steps_sampled: 5407836\n",
      "    num_steps_trained: 5407836\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.5476\n",
      "    ram_util_percent: 57.3124\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455384895570942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07148526381074\n",
      "    mean_inference_ms: 2.854519439543554\n",
      "    mean_raw_obs_processing_ms: 3.56042899578704\n",
      "  time_since_restore: 84985.33572626114\n",
      "  time_this_iter_s: 175.00549983978271\n",
      "  time_total_s: 84985.33572626114\n",
      "  timers:\n",
      "    learn_throughput: 931.748\n",
      "    learn_time_ms: 10728.221\n",
      "    load_throughput: 90821.77\n",
      "    load_time_ms: 110.062\n",
      "    sample_throughput: 63.231\n",
      "    sample_time_ms: 158087.307\n",
      "    update_time_ms: 13.321\n",
      "  timestamp: 1636379415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5407836\n",
      "  training_iteration: 541\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   541</td><td style=\"text-align: right;\">         84985.3</td><td style=\"text-align: right;\">5407836</td><td style=\"text-align: right;\"> 4.59855</td><td style=\"text-align: right;\">               12.94</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           91.8455</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5417832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-52-51\n",
      "  done: false\n",
      "  episode_len_mean: 93.10280373831776\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 4.785046728971972\n",
      "  episode_reward_min: -1.2900000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 58966\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.079795038088774\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01601888356858705\n",
      "          policy_loss: -0.05634640531980584\n",
      "          total_loss: 0.19129693815007043\n",
      "          vf_explained_var: 0.9202739000320435\n",
      "          vf_loss: 0.23194827261961934\n",
      "    num_agent_steps_sampled: 5417832\n",
      "    num_agent_steps_trained: 5417832\n",
      "    num_steps_sampled: 5417832\n",
      "    num_steps_trained: 5417832\n",
      "  iterations_since_restore: 542\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.23963963963962\n",
      "    ram_util_percent: 57.359009009009014\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549704497888583\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0708251046153\n",
      "    mean_inference_ms: 2.8543658239294674\n",
      "    mean_raw_obs_processing_ms: 3.5614804904772117\n",
      "  time_since_restore: 85141.07280254364\n",
      "  time_this_iter_s: 155.73707628250122\n",
      "  time_total_s: 85141.07280254364\n",
      "  timers:\n",
      "    learn_throughput: 931.99\n",
      "    learn_time_ms: 10725.441\n",
      "    load_throughput: 90828.008\n",
      "    load_time_ms: 110.054\n",
      "    sample_throughput: 63.705\n",
      "    sample_time_ms: 156909.865\n",
      "    update_time_ms: 14.766\n",
      "  timestamp: 1636379571\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5417832\n",
      "  training_iteration: 542\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   542</td><td style=\"text-align: right;\">         85141.1</td><td style=\"text-align: right;\">5417832</td><td style=\"text-align: right;\"> 4.78505</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           93.1028</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5427828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-55-13\n",
      "  done: false\n",
      "  episode_len_mean: 93.85046728971963\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.03999999999993\n",
      "  episode_reward_mean: 4.428878504672906\n",
      "  episode_reward_min: -1.990000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 59073\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1029617609121862\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012720898227053907\n",
      "          policy_loss: -0.06034982153652316\n",
      "          total_loss: 0.11398557692161228\n",
      "          vf_explained_var: 0.936488687992096\n",
      "          vf_loss: 0.16638521949768575\n",
      "    num_agent_steps_sampled: 5427828\n",
      "    num_agent_steps_trained: 5427828\n",
      "    num_steps_sampled: 5427828\n",
      "    num_steps_trained: 5427828\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12167487684728\n",
      "    ram_util_percent: 57.34433497536946\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553427267358839\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07562521338825\n",
      "    mean_inference_ms: 2.8544416581653764\n",
      "    mean_raw_obs_processing_ms: 3.5565930101239447\n",
      "  time_since_restore: 85283.10868358612\n",
      "  time_this_iter_s: 142.03588104248047\n",
      "  time_total_s: 85283.10868358612\n",
      "  timers:\n",
      "    learn_throughput: 932.628\n",
      "    learn_time_ms: 10718.096\n",
      "    load_throughput: 90597.745\n",
      "    load_time_ms: 110.334\n",
      "    sample_throughput: 64.565\n",
      "    sample_time_ms: 154820.597\n",
      "    update_time_ms: 15.385\n",
      "  timestamp: 1636379713\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5427828\n",
      "  training_iteration: 543\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   543</td><td style=\"text-align: right;\">         85283.1</td><td style=\"text-align: right;\">5427828</td><td style=\"text-align: right;\"> 4.42888</td><td style=\"text-align: right;\">               16.04</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           93.8505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5437824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_13-57-49\n",
      "  done: false\n",
      "  episode_len_mean: 92.77570093457943\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.880000000000008\n",
      "  episode_reward_mean: 3.7232710280373924\n",
      "  episode_reward_min: -1.6299999999999983\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 59180\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.132742713455461\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012828393548039047\n",
      "          policy_loss: -0.06222912662177004\n",
      "          total_loss: 0.1302838707406424\n",
      "          vf_explained_var: 0.931811511516571\n",
      "          vf_loss: 0.18461574034717604\n",
      "    num_agent_steps_sampled: 5437824\n",
      "    num_agent_steps_trained: 5437824\n",
      "    num_steps_sampled: 5437824\n",
      "    num_steps_trained: 5437824\n",
      "  iterations_since_restore: 544\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.36531531531533\n",
      "    ram_util_percent: 57.377927927927935\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553156285604575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07689096686422\n",
      "    mean_inference_ms: 2.854420728660152\n",
      "    mean_raw_obs_processing_ms: 3.557669605642543\n",
      "  time_since_restore: 85439.30418753624\n",
      "  time_this_iter_s: 156.19550395011902\n",
      "  time_total_s: 85439.30418753624\n",
      "  timers:\n",
      "    learn_throughput: 932.811\n",
      "    learn_time_ms: 10715.995\n",
      "    load_throughput: 90676.925\n",
      "    load_time_ms: 110.238\n",
      "    sample_throughput: 65.415\n",
      "    sample_time_ms: 152808.312\n",
      "    update_time_ms: 13.536\n",
      "  timestamp: 1636379869\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5437824\n",
      "  training_iteration: 544\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   544</td><td style=\"text-align: right;\">         85439.3</td><td style=\"text-align: right;\">5437824</td><td style=\"text-align: right;\"> 3.72327</td><td style=\"text-align: right;\">               10.88</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           92.7757</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5447820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-00-33\n",
      "  done: false\n",
      "  episode_len_mean: 93.92592592592592\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000019\n",
      "  episode_reward_mean: 4.43935185185186\n",
      "  episode_reward_min: -1.0300000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 59288\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.117107607666244\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014566742965105604\n",
      "          policy_loss: -0.06164571019924349\n",
      "          total_loss: 0.16456431604953659\n",
      "          vf_explained_var: 0.9144766926765442\n",
      "          vf_loss: 0.21419623875274107\n",
      "    num_agent_steps_sampled: 5447820\n",
      "    num_agent_steps_trained: 5447820\n",
      "    num_steps_sampled: 5447820\n",
      "    num_steps_trained: 5447820\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.60680851063832\n",
      "    ram_util_percent: 57.55063829787233\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553165584707685\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.076999414434844\n",
      "    mean_inference_ms: 2.8543042460285175\n",
      "    mean_raw_obs_processing_ms: 3.5609833038984715\n",
      "  time_since_restore: 85603.36282682419\n",
      "  time_this_iter_s: 164.0586392879486\n",
      "  time_total_s: 85603.36282682419\n",
      "  timers:\n",
      "    learn_throughput: 932.961\n",
      "    learn_time_ms: 10714.272\n",
      "    load_throughput: 90581.46\n",
      "    load_time_ms: 110.354\n",
      "    sample_throughput: 65.128\n",
      "    sample_time_ms: 153481.207\n",
      "    update_time_ms: 13.069\n",
      "  timestamp: 1636380033\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5447820\n",
      "  training_iteration: 545\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   545</td><td style=\"text-align: right;\">         85603.4</td><td style=\"text-align: right;\">5447820</td><td style=\"text-align: right;\"> 4.43935</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">               -1.03</td><td style=\"text-align: right;\">           93.9259</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5457816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-03-25\n",
      "  done: false\n",
      "  episode_len_mean: 94.66346153846153\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.229999999999976\n",
      "  episode_reward_mean: 3.985576923076932\n",
      "  episode_reward_min: -1.4500000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 59392\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0898315430706385\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014023966748892225\n",
      "          policy_loss: -0.060405650422868565\n",
      "          total_loss: 0.14429814017449433\n",
      "          vf_explained_var: 0.9155336022377014\n",
      "          vf_loss: 0.19365375478648478\n",
      "    num_agent_steps_sampled: 5457816\n",
      "    num_agent_steps_trained: 5457816\n",
      "    num_steps_sampled: 5457816\n",
      "    num_steps_trained: 5457816\n",
      "  iterations_since_restore: 546\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.48893442622952\n",
      "    ram_util_percent: 57.54590163934426\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455383823084411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.077350646714265\n",
      "    mean_inference_ms: 2.854525112300725\n",
      "    mean_raw_obs_processing_ms: 3.5624629400826895\n",
      "  time_since_restore: 85774.7064909935\n",
      "  time_this_iter_s: 171.34366416931152\n",
      "  time_total_s: 85774.7064909935\n",
      "  timers:\n",
      "    learn_throughput: 931.977\n",
      "    learn_time_ms: 10725.587\n",
      "    load_throughput: 90621.165\n",
      "    load_time_ms: 110.305\n",
      "    sample_throughput: 65.053\n",
      "    sample_time_ms: 153660.482\n",
      "    update_time_ms: 13.16\n",
      "  timestamp: 1636380205\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5457816\n",
      "  training_iteration: 546\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   546</td><td style=\"text-align: right;\">         85774.7</td><td style=\"text-align: right;\">5457816</td><td style=\"text-align: right;\"> 3.98558</td><td style=\"text-align: right;\">               16.23</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           94.6635</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5467812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-05-45\n",
      "  done: false\n",
      "  episode_len_mean: 97.94174757281553\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.840000000000016\n",
      "  episode_reward_mean: 3.979805825242729\n",
      "  episode_reward_min: -1.1800000000000004\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 59495\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1221640221074094\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012168143496712918\n",
      "          policy_loss: -0.06374057633961495\n",
      "          total_loss: 0.10979448929031053\n",
      "          vf_explained_var: 0.9257641434669495\n",
      "          vf_loss: 0.16703615366425525\n",
      "    num_agent_steps_sampled: 5467812\n",
      "    num_agent_steps_trained: 5467812\n",
      "    num_steps_sampled: 5467812\n",
      "    num_steps_trained: 5467812\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87900000000002\n",
      "    ram_util_percent: 57.401\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554665252422866\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.078716996668966\n",
      "    mean_inference_ms: 2.8544424950676874\n",
      "    mean_raw_obs_processing_ms: 3.557564238859166\n",
      "  time_since_restore: 85914.62765812874\n",
      "  time_this_iter_s: 139.92116713523865\n",
      "  time_total_s: 85914.62765812874\n",
      "  timers:\n",
      "    learn_throughput: 932.284\n",
      "    learn_time_ms: 10722.051\n",
      "    load_throughput: 90504.4\n",
      "    load_time_ms: 110.448\n",
      "    sample_throughput: 65.702\n",
      "    sample_time_ms: 152141.984\n",
      "    update_time_ms: 12.985\n",
      "  timestamp: 1636380345\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5467812\n",
      "  training_iteration: 547\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   547</td><td style=\"text-align: right;\">         85914.6</td><td style=\"text-align: right;\">5467812</td><td style=\"text-align: right;\"> 3.97981</td><td style=\"text-align: right;\">               14.84</td><td style=\"text-align: right;\">               -1.18</td><td style=\"text-align: right;\">           97.9417</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5477808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-08-42\n",
      "  done: false\n",
      "  episode_len_mean: 92.57943925233644\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.52999999999998\n",
      "  episode_reward_mean: 4.531308411214963\n",
      "  episode_reward_min: -1.2100000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 59602\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0901615819360457\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013984358730504107\n",
      "          policy_loss: -0.05962097406005248\n",
      "          total_loss: 0.121728762325982\n",
      "          vf_explained_var: 0.9353776574134827\n",
      "          vf_loss: 0.1703932338211144\n",
      "    num_agent_steps_sampled: 5477808\n",
      "    num_agent_steps_trained: 5477808\n",
      "    num_steps_sampled: 5477808\n",
      "    num_steps_trained: 5477808\n",
      "  iterations_since_restore: 548\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.84268774703557\n",
      "    ram_util_percent: 57.28853754940712\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555724158386695\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07754846743218\n",
      "    mean_inference_ms: 2.8544907319832333\n",
      "    mean_raw_obs_processing_ms: 3.568959117576307\n",
      "  time_since_restore: 86091.98689126968\n",
      "  time_this_iter_s: 177.35923314094543\n",
      "  time_total_s: 86091.98689126968\n",
      "  timers:\n",
      "    learn_throughput: 932.08\n",
      "    learn_time_ms: 10724.407\n",
      "    load_throughput: 90217.554\n",
      "    load_time_ms: 110.799\n",
      "    sample_throughput: 65.496\n",
      "    sample_time_ms: 152620.167\n",
      "    update_time_ms: 12.762\n",
      "  timestamp: 1636380522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5477808\n",
      "  training_iteration: 548\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   548</td><td style=\"text-align: right;\">           86092</td><td style=\"text-align: right;\">5477808</td><td style=\"text-align: right;\"> 4.53131</td><td style=\"text-align: right;\">               18.53</td><td style=\"text-align: right;\">               -1.21</td><td style=\"text-align: right;\">           92.5794</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5487804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-11-33\n",
      "  done: false\n",
      "  episode_len_mean: 97.13461538461539\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.370000000000012\n",
      "  episode_reward_mean: 4.8245192307692415\n",
      "  episode_reward_min: -1.2500000000000009\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 59706\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.106488652412708\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012955207707914848\n",
      "          policy_loss: -0.05929898787767459\n",
      "          total_loss: 0.14620760125705065\n",
      "          vf_explained_var: 0.9313664436340332\n",
      "          vf_loss: 0.1970578927005458\n",
      "    num_agent_steps_sampled: 5487804\n",
      "    num_agent_steps_trained: 5487804\n",
      "    num_steps_sampled: 5487804\n",
      "    num_steps_trained: 5487804\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.63539094650207\n",
      "    ram_util_percent: 57.73292181069959\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550767710223976\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0692497262442\n",
      "    mean_inference_ms: 2.854246419583169\n",
      "    mean_raw_obs_processing_ms: 3.5736835658596204\n",
      "  time_since_restore: 86262.72096848488\n",
      "  time_this_iter_s: 170.7340772151947\n",
      "  time_total_s: 86262.72096848488\n",
      "  timers:\n",
      "    learn_throughput: 932.376\n",
      "    learn_time_ms: 10721.002\n",
      "    load_throughput: 90319.511\n",
      "    load_time_ms: 110.674\n",
      "    sample_throughput: 65.5\n",
      "    sample_time_ms: 152611.54\n",
      "    update_time_ms: 12.096\n",
      "  timestamp: 1636380693\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5487804\n",
      "  training_iteration: 549\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   549</td><td style=\"text-align: right;\">         86262.7</td><td style=\"text-align: right;\">5487804</td><td style=\"text-align: right;\"> 4.82452</td><td style=\"text-align: right;\">               12.37</td><td style=\"text-align: right;\">               -1.25</td><td style=\"text-align: right;\">           97.1346</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5497800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-13-48\n",
      "  done: false\n",
      "  episode_len_mean: 98.41584158415841\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.609999999999964\n",
      "  episode_reward_mean: 4.903168316831693\n",
      "  episode_reward_min: -1.9300000000000008\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 59807\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.087763271576319\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01358697612411217\n",
      "          policy_loss: -0.06110504951773801\n",
      "          total_loss: 0.149701973147945\n",
      "          vf_explained_var: 0.9237630367279053\n",
      "          vf_loss: 0.20073182529045475\n",
      "    num_agent_steps_sampled: 5497800\n",
      "    num_agent_steps_trained: 5497800\n",
      "    num_steps_sampled: 5497800\n",
      "    num_steps_trained: 5497800\n",
      "  iterations_since_restore: 550\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.91088082901555\n",
      "    ram_util_percent: 57.54196891191709\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045548449467447835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07037109154871\n",
      "    mean_inference_ms: 2.854307481813883\n",
      "    mean_raw_obs_processing_ms: 3.568319775132213\n",
      "  time_since_restore: 86397.94827127457\n",
      "  time_this_iter_s: 135.2273027896881\n",
      "  time_total_s: 86397.94827127457\n",
      "  timers:\n",
      "    learn_throughput: 931.957\n",
      "    learn_time_ms: 10725.822\n",
      "    load_throughput: 90346.623\n",
      "    load_time_ms: 110.641\n",
      "    sample_throughput: 67.586\n",
      "    sample_time_ms: 147899.425\n",
      "    update_time_ms: 11.672\n",
      "  timestamp: 1636380828\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5497800\n",
      "  training_iteration: 550\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   550</td><td style=\"text-align: right;\">         86397.9</td><td style=\"text-align: right;\">5497800</td><td style=\"text-align: right;\"> 4.90317</td><td style=\"text-align: right;\">               18.61</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">           98.4158</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5507796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-16-21\n",
      "  done: false\n",
      "  episode_len_mean: 95.04761904761905\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.990000000000013\n",
      "  episode_reward_mean: 3.938285714285724\n",
      "  episode_reward_min: -2.3\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 59912\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.113592221084823\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012761217669983239\n",
      "          policy_loss: -0.0647590008413053\n",
      "          total_loss: 0.1145809355008806\n",
      "          vf_explained_var: 0.9276897311210632\n",
      "          vf_loss: 0.1714042083447815\n",
      "    num_agent_steps_sampled: 5507796\n",
      "    num_agent_steps_trained: 5507796\n",
      "    num_steps_sampled: 5507796\n",
      "    num_steps_trained: 5507796\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.0324200913242\n",
      "    ram_util_percent: 57.50776255707762\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045576065473519445\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07095022372617\n",
      "    mean_inference_ms: 2.8547043019676335\n",
      "    mean_raw_obs_processing_ms: 3.565910539213531\n",
      "  time_since_restore: 86550.76085853577\n",
      "  time_this_iter_s: 152.81258726119995\n",
      "  time_total_s: 86550.76085853577\n",
      "  timers:\n",
      "    learn_throughput: 931.815\n",
      "    learn_time_ms: 10727.451\n",
      "    load_throughput: 90656.201\n",
      "    load_time_ms: 110.263\n",
      "    sample_throughput: 68.616\n",
      "    sample_time_ms: 145679.702\n",
      "    update_time_ms: 11.105\n",
      "  timestamp: 1636380981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5507796\n",
      "  training_iteration: 551\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   551</td><td style=\"text-align: right;\">         86550.8</td><td style=\"text-align: right;\">5507796</td><td style=\"text-align: right;\"> 3.93829</td><td style=\"text-align: right;\">               10.99</td><td style=\"text-align: right;\">                -2.3</td><td style=\"text-align: right;\">           95.0476</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5517792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-19-04\n",
      "  done: false\n",
      "  episode_len_mean: 95.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.559999999999985\n",
      "  episode_reward_mean: 3.7421904761904843\n",
      "  episode_reward_min: -1.6200000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 60017\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1001140689238524\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014142219486582723\n",
      "          policy_loss: -0.05797019996481319\n",
      "          total_loss: 0.1410063862378717\n",
      "          vf_explained_var: 0.9060169458389282\n",
      "          vf_loss: 0.18775998218796955\n",
      "    num_agent_steps_sampled: 5517792\n",
      "    num_agent_steps_trained: 5517792\n",
      "    num_steps_sampled: 5517792\n",
      "    num_steps_trained: 5517792\n",
      "  iterations_since_restore: 552\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.71206896551725\n",
      "    ram_util_percent: 57.43620689655171\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555094300988315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06785286589306\n",
      "    mean_inference_ms: 2.8541881532129736\n",
      "    mean_raw_obs_processing_ms: 3.5674721378391605\n",
      "  time_since_restore: 86713.86231446266\n",
      "  time_this_iter_s: 163.10145592689514\n",
      "  time_total_s: 86713.86231446266\n",
      "  timers:\n",
      "    learn_throughput: 931.165\n",
      "    learn_time_ms: 10734.945\n",
      "    load_throughput: 90287.574\n",
      "    load_time_ms: 110.713\n",
      "    sample_throughput: 68.274\n",
      "    sample_time_ms: 146410.381\n",
      "    update_time_ms: 9.316\n",
      "  timestamp: 1636381144\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5517792\n",
      "  training_iteration: 552\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   552</td><td style=\"text-align: right;\">         86713.9</td><td style=\"text-align: right;\">5517792</td><td style=\"text-align: right;\"> 3.74219</td><td style=\"text-align: right;\">               18.56</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">              95.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5527788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-21-34\n",
      "  done: false\n",
      "  episode_len_mean: 94.82857142857142\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.19999999999997\n",
      "  episode_reward_mean: 3.9903809523809612\n",
      "  episode_reward_min: -1.8700000000000012\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 60122\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0886417756732714\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014578155521683423\n",
      "          policy_loss: -0.05931386993640763\n",
      "          total_loss: 0.1537234797166326\n",
      "          vf_explained_var: 0.9301291704177856\n",
      "          vf_loss: 0.20071290642277806\n",
      "    num_agent_steps_sampled: 5527788\n",
      "    num_agent_steps_trained: 5527788\n",
      "    num_steps_sampled: 5527788\n",
      "    num_steps_trained: 5527788\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.67383177570093\n",
      "    ram_util_percent: 57.46915887850468\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552548241649874\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06598837545258\n",
      "    mean_inference_ms: 2.854348268973608\n",
      "    mean_raw_obs_processing_ms: 3.56535576498432\n",
      "  time_since_restore: 86863.79644703865\n",
      "  time_this_iter_s: 149.93413257598877\n",
      "  time_total_s: 86863.79644703865\n",
      "  timers:\n",
      "    learn_throughput: 931.363\n",
      "    learn_time_ms: 10732.658\n",
      "    load_throughput: 90483.11\n",
      "    load_time_ms: 110.474\n",
      "    sample_throughput: 67.906\n",
      "    sample_time_ms: 147203.81\n",
      "    update_time_ms: 8.277\n",
      "  timestamp: 1636381294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5527788\n",
      "  training_iteration: 553\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   553</td><td style=\"text-align: right;\">         86863.8</td><td style=\"text-align: right;\">5527788</td><td style=\"text-align: right;\"> 3.99038</td><td style=\"text-align: right;\">                16.2</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">           94.8286</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5537784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-24-03\n",
      "  done: false\n",
      "  episode_len_mean: 96.22330097087378\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000018\n",
      "  episode_reward_mean: 4.166310679611661\n",
      "  episode_reward_min: -1.3400000000000003\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 60225\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1305883557368546\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013348259296253374\n",
      "          policy_loss: -0.06127652532429013\n",
      "          total_loss: 0.11463095615498531\n",
      "          vf_explained_var: 0.9268736243247986\n",
      "          vf_loss: 0.1668043609788148\n",
      "    num_agent_steps_sampled: 5537784\n",
      "    num_agent_steps_trained: 5537784\n",
      "    num_steps_sampled: 5537784\n",
      "    num_steps_trained: 5537784\n",
      "  iterations_since_restore: 554\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.33943661971831\n",
      "    ram_util_percent: 57.498122065727706\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554330465182879\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.062960059876694\n",
      "    mean_inference_ms: 2.8545707163928653\n",
      "    mean_raw_obs_processing_ms: 3.5692211758124537\n",
      "  time_since_restore: 87013.08369708061\n",
      "  time_this_iter_s: 149.28725004196167\n",
      "  time_total_s: 87013.08369708061\n",
      "  timers:\n",
      "    learn_throughput: 930.912\n",
      "    learn_time_ms: 10737.853\n",
      "    load_throughput: 90643.618\n",
      "    load_time_ms: 110.278\n",
      "    sample_throughput: 68.229\n",
      "    sample_time_ms: 146507.155\n",
      "    update_time_ms: 9.125\n",
      "  timestamp: 1636381443\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5537784\n",
      "  training_iteration: 554\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   554</td><td style=\"text-align: right;\">         87013.1</td><td style=\"text-align: right;\">5537784</td><td style=\"text-align: right;\"> 4.16631</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           96.2233</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5547780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-26-21\n",
      "  done: false\n",
      "  episode_len_mean: 98.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.56999999999997\n",
      "  episode_reward_mean: 4.212427184466028\n",
      "  episode_reward_min: -1.2300000000000009\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 60328\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.101371503385723\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014350534173940244\n",
      "          policy_loss: -0.0578761015413727\n",
      "          total_loss: 0.1613149062404011\n",
      "          vf_explained_var: 0.9125538468360901\n",
      "          vf_loss: 0.20751241046585078\n",
      "    num_agent_steps_sampled: 5547780\n",
      "    num_agent_steps_trained: 5547780\n",
      "    num_steps_sampled: 5547780\n",
      "    num_steps_trained: 5547780\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28571428571429\n",
      "    ram_util_percent: 57.51632653061223\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553695963895311\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.063632171412635\n",
      "    mean_inference_ms: 2.8544726017825113\n",
      "    mean_raw_obs_processing_ms: 3.5643119729217614\n",
      "  time_since_restore: 87150.54124832153\n",
      "  time_this_iter_s: 137.45755124092102\n",
      "  time_total_s: 87150.54124832153\n",
      "  timers:\n",
      "    learn_throughput: 931.344\n",
      "    learn_time_ms: 10732.878\n",
      "    load_throughput: 90766.795\n",
      "    load_time_ms: 110.128\n",
      "    sample_throughput: 69.488\n",
      "    sample_time_ms: 143851.864\n",
      "    update_time_ms: 9.78\n",
      "  timestamp: 1636381581\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5547780\n",
      "  training_iteration: 555\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   555</td><td style=\"text-align: right;\">         87150.5</td><td style=\"text-align: right;\">5547780</td><td style=\"text-align: right;\"> 4.21243</td><td style=\"text-align: right;\">               18.57</td><td style=\"text-align: right;\">               -1.23</td><td style=\"text-align: right;\">                98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5557776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-28-48\n",
      "  done: false\n",
      "  episode_len_mean: 94.43809523809524\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.619999999999997\n",
      "  episode_reward_mean: 3.8175238095238173\n",
      "  episode_reward_min: -0.8400000000000005\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 60433\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1093335673340365\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013666655944587023\n",
      "          policy_loss: -0.0581693112404428\n",
      "          total_loss: 0.12408526585970679\n",
      "          vf_explained_var: 0.9160301089286804\n",
      "          vf_loss: 0.17221356074397381\n",
      "    num_agent_steps_sampled: 5557776\n",
      "    num_agent_steps_trained: 5557776\n",
      "    num_steps_sampled: 5557776\n",
      "    num_steps_trained: 5557776\n",
      "  iterations_since_restore: 556\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.91848341232229\n",
      "    ram_util_percent: 57.61611374407583\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555738377880461\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06353027334687\n",
      "    mean_inference_ms: 2.8546364608935515\n",
      "    mean_raw_obs_processing_ms: 3.5619630725861557\n",
      "  time_since_restore: 87297.88339090347\n",
      "  time_this_iter_s: 147.3421425819397\n",
      "  time_total_s: 87297.88339090347\n",
      "  timers:\n",
      "    learn_throughput: 932.275\n",
      "    learn_time_ms: 10722.164\n",
      "    load_throughput: 90874.626\n",
      "    load_time_ms: 109.998\n",
      "    sample_throughput: 70.662\n",
      "    sample_time_ms: 141462.717\n",
      "    update_time_ms: 9.732\n",
      "  timestamp: 1636381728\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5557776\n",
      "  training_iteration: 556\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   556</td><td style=\"text-align: right;\">         87297.9</td><td style=\"text-align: right;\">5557776</td><td style=\"text-align: right;\"> 3.81752</td><td style=\"text-align: right;\">               16.62</td><td style=\"text-align: right;\">               -0.84</td><td style=\"text-align: right;\">           94.4381</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5567772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-31-20\n",
      "  done: false\n",
      "  episode_len_mean: 95.31132075471699\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.049999999999944\n",
      "  episode_reward_mean: 3.7350000000000088\n",
      "  episode_reward_min: -0.9500000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 60539\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.130917805789882\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01363034685125795\n",
      "          policy_loss: -0.06078351783828858\n",
      "          total_loss: 0.12173784685790794\n",
      "          vf_explained_var: 0.9223684072494507\n",
      "          vf_loss: 0.17277890781784414\n",
      "    num_agent_steps_sampled: 5567772\n",
      "    num_agent_steps_trained: 5567772\n",
      "    num_steps_sampled: 5567772\n",
      "    num_steps_trained: 5567772\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.6097222222222\n",
      "    ram_util_percent: 57.533796296296295\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552921211513509\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.062965544286826\n",
      "    mean_inference_ms: 2.854370072074036\n",
      "    mean_raw_obs_processing_ms: 3.560628363898292\n",
      "  time_since_restore: 87449.2724199295\n",
      "  time_this_iter_s: 151.3890290260315\n",
      "  time_total_s: 87449.2724199295\n",
      "  timers:\n",
      "    learn_throughput: 932.439\n",
      "    learn_time_ms: 10720.275\n",
      "    load_throughput: 91106.775\n",
      "    load_time_ms: 109.717\n",
      "    sample_throughput: 70.093\n",
      "    sample_time_ms: 142611.056\n",
      "    update_time_ms: 10.128\n",
      "  timestamp: 1636381880\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5567772\n",
      "  training_iteration: 557\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   557</td><td style=\"text-align: right;\">         87449.3</td><td style=\"text-align: right;\">5567772</td><td style=\"text-align: right;\">   3.735</td><td style=\"text-align: right;\">               18.05</td><td style=\"text-align: right;\">               -0.95</td><td style=\"text-align: right;\">           95.3113</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5577768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-34-02\n",
      "  done: false\n",
      "  episode_len_mean: 93.59433962264151\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.399999999999956\n",
      "  episode_reward_mean: 4.58622641509435\n",
      "  episode_reward_min: -0.7900000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 60645\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.102572497037741\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013546017764906538\n",
      "          policy_loss: -0.057151614743261\n",
      "          total_loss: 0.15669177235462345\n",
      "          vf_explained_var: 0.923291027545929\n",
      "          vf_loss: 0.20400958995088042\n",
      "    num_agent_steps_sampled: 5577768\n",
      "    num_agent_steps_trained: 5577768\n",
      "    num_steps_sampled: 5577768\n",
      "    num_steps_trained: 5577768\n",
      "  iterations_since_restore: 558\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.35714285714286\n",
      "    ram_util_percent: 57.41601731601731\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555163055728056\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06261606631834\n",
      "    mean_inference_ms: 2.854402472563269\n",
      "    mean_raw_obs_processing_ms: 3.5614007884209737\n",
      "  time_since_restore: 87611.26844286919\n",
      "  time_this_iter_s: 161.996022939682\n",
      "  time_total_s: 87611.26844286919\n",
      "  timers:\n",
      "    learn_throughput: 933.171\n",
      "    learn_time_ms: 10711.858\n",
      "    load_throughput: 91421.374\n",
      "    load_time_ms: 109.34\n",
      "    sample_throughput: 70.851\n",
      "    sample_time_ms: 141084.085\n",
      "    update_time_ms: 9.678\n",
      "  timestamp: 1636382042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5577768\n",
      "  training_iteration: 558\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   558</td><td style=\"text-align: right;\">         87611.3</td><td style=\"text-align: right;\">5577768</td><td style=\"text-align: right;\"> 4.58623</td><td style=\"text-align: right;\">                18.4</td><td style=\"text-align: right;\">               -0.79</td><td style=\"text-align: right;\">           93.5943</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5587764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-36-19\n",
      "  done: false\n",
      "  episode_len_mean: 96.01923076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.930000000000007\n",
      "  episode_reward_mean: 4.084134615384626\n",
      "  episode_reward_min: -1.6400000000000008\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 60749\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1249206466552537\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012710931475381862\n",
      "          policy_loss: -0.0621241164035522\n",
      "          total_loss: 0.10258069276554972\n",
      "          vf_explained_var: 0.9347090721130371\n",
      "          vf_loss: 0.15699692345900923\n",
      "    num_agent_steps_sampled: 5587764\n",
      "    num_agent_steps_trained: 5587764\n",
      "    num_steps_sampled: 5587764\n",
      "    num_steps_trained: 5587764\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33692307692309\n",
      "    ram_util_percent: 57.484102564102564\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555003845099925\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06308049336345\n",
      "    mean_inference_ms: 2.8545695071026085\n",
      "    mean_raw_obs_processing_ms: 3.5560342502903883\n",
      "  time_since_restore: 87748.36917281151\n",
      "  time_this_iter_s: 137.10072994232178\n",
      "  time_total_s: 87748.36917281151\n",
      "  timers:\n",
      "    learn_throughput: 932.906\n",
      "    learn_time_ms: 10714.902\n",
      "    load_throughput: 91482.854\n",
      "    load_time_ms: 109.266\n",
      "    sample_throughput: 72.583\n",
      "    sample_time_ms: 137717.598\n",
      "    update_time_ms: 10.377\n",
      "  timestamp: 1636382179\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5587764\n",
      "  training_iteration: 559\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   559</td><td style=\"text-align: right;\">         87748.4</td><td style=\"text-align: right;\">5587764</td><td style=\"text-align: right;\"> 4.08413</td><td style=\"text-align: right;\">               15.93</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           96.0192</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5597760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-39-07\n",
      "  done: false\n",
      "  episode_len_mean: 94.73584905660377\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.000000000000016\n",
      "  episode_reward_mean: 4.40433962264152\n",
      "  episode_reward_min: 0.3499999999999992\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 60855\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.111757546204787\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013321529596412779\n",
      "          policy_loss: -0.060682342803248995\n",
      "          total_loss: 0.12996081647534782\n",
      "          vf_explained_var: 0.930446445941925\n",
      "          vf_loss: 0.1814126251822608\n",
      "    num_agent_steps_sampled: 5597760\n",
      "    num_agent_steps_trained: 5597760\n",
      "    num_steps_sampled: 5597760\n",
      "    num_steps_trained: 5597760\n",
      "  iterations_since_restore: 560\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.5356846473029\n",
      "    ram_util_percent: 57.60995850622407\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554263907018453\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05842558582154\n",
      "    mean_inference_ms: 2.8541943439147777\n",
      "    mean_raw_obs_processing_ms: 3.5600780843454136\n",
      "  time_since_restore: 87916.84027433395\n",
      "  time_this_iter_s: 168.47110152244568\n",
      "  time_total_s: 87916.84027433395\n",
      "  timers:\n",
      "    learn_throughput: 933.147\n",
      "    learn_time_ms: 10712.139\n",
      "    load_throughput: 91514.125\n",
      "    load_time_ms: 109.229\n",
      "    sample_throughput: 70.872\n",
      "    sample_time_ms: 141042.61\n",
      "    update_time_ms: 12.583\n",
      "  timestamp: 1636382347\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5597760\n",
      "  training_iteration: 560\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   560</td><td style=\"text-align: right;\">         87916.8</td><td style=\"text-align: right;\">5597760</td><td style=\"text-align: right;\"> 4.40434</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">                0.35</td><td style=\"text-align: right;\">           94.7358</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5607756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-41-42\n",
      "  done: false\n",
      "  episode_len_mean: 93.94339622641509\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000018\n",
      "  episode_reward_mean: 4.3020754716981235\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 60961\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0920642964860314\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014161456346660346\n",
      "          policy_loss: -0.06066488181041856\n",
      "          total_loss: 0.1189184041057005\n",
      "          vf_explained_var: 0.9322993755340576\n",
      "          vf_loss: 0.1682423601914038\n",
      "    num_agent_steps_sampled: 5607756\n",
      "    num_agent_steps_trained: 5607756\n",
      "    num_steps_sampled: 5607756\n",
      "    num_steps_trained: 5607756\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.51590909090909\n",
      "    ram_util_percent: 57.501363636363635\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552881020902962\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.057826328084\n",
      "    mean_inference_ms: 2.8542800269124564\n",
      "    mean_raw_obs_processing_ms: 3.5608751078586254\n",
      "  time_since_restore: 88071.18867826462\n",
      "  time_this_iter_s: 154.34840393066406\n",
      "  time_total_s: 88071.18867826462\n",
      "  timers:\n",
      "    learn_throughput: 933.795\n",
      "    learn_time_ms: 10704.702\n",
      "    load_throughput: 91212.459\n",
      "    load_time_ms: 109.59\n",
      "    sample_throughput: 70.792\n",
      "    sample_time_ms: 141202.481\n",
      "    update_time_ms: 13.317\n",
      "  timestamp: 1636382502\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5607756\n",
      "  training_iteration: 561\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   561</td><td style=\"text-align: right;\">         88071.2</td><td style=\"text-align: right;\">5607756</td><td style=\"text-align: right;\"> 4.30208</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           93.9434</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5617752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-44-14\n",
      "  done: false\n",
      "  episode_len_mean: 94.25471698113208\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.779999999999985\n",
      "  episode_reward_mean: 4.290188679245293\n",
      "  episode_reward_min: -1.4300000000000004\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 61067\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1088318141097697\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012972699754291743\n",
      "          policy_loss: -0.059741780747715224\n",
      "          total_loss: 0.11331195953166764\n",
      "          vf_explained_var: 0.9373618364334106\n",
      "          vf_loss: 0.1645886252610347\n",
      "    num_agent_steps_sampled: 5617752\n",
      "    num_agent_steps_trained: 5617752\n",
      "    num_steps_sampled: 5617752\n",
      "    num_steps_trained: 5617752\n",
      "  iterations_since_restore: 562\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.51290322580645\n",
      "    ram_util_percent: 57.581105990783406\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554295323866229\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.058103304438\n",
      "    mean_inference_ms: 2.8541942743933\n",
      "    mean_raw_obs_processing_ms: 3.559118953272322\n",
      "  time_since_restore: 88223.13684296608\n",
      "  time_this_iter_s: 151.9481647014618\n",
      "  time_total_s: 88223.13684296608\n",
      "  timers:\n",
      "    learn_throughput: 934.688\n",
      "    learn_time_ms: 10694.472\n",
      "    load_throughput: 91552.033\n",
      "    load_time_ms: 109.184\n",
      "    sample_throughput: 71.35\n",
      "    sample_time_ms: 140097.213\n",
      "    update_time_ms: 13.838\n",
      "  timestamp: 1636382654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5617752\n",
      "  training_iteration: 562\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   562</td><td style=\"text-align: right;\">         88223.1</td><td style=\"text-align: right;\">5617752</td><td style=\"text-align: right;\"> 4.29019</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           94.2547</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5627748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-46-52\n",
      "  done: false\n",
      "  episode_len_mean: 96.37142857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.709999999999997\n",
      "  episode_reward_mean: 4.108857142857152\n",
      "  episode_reward_min: -1.3800000000000008\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 61172\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.111761159876473\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012903218447010914\n",
      "          policy_loss: -0.0611564925338468\n",
      "          total_loss: 0.11632023781386769\n",
      "          vf_explained_var: 0.927923858165741\n",
      "          vf_loss: 0.1691991965708315\n",
      "    num_agent_steps_sampled: 5627748\n",
      "    num_agent_steps_trained: 5627748\n",
      "    num_steps_sampled: 5627748\n",
      "    num_steps_trained: 5627748\n",
      "  iterations_since_restore: 563\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.98230088495575\n",
      "    ram_util_percent: 57.540265486725666\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556077807030411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05667370289217\n",
      "    mean_inference_ms: 2.8542929111337734\n",
      "    mean_raw_obs_processing_ms: 3.559677856674484\n",
      "  time_since_restore: 88381.48287367821\n",
      "  time_this_iter_s: 158.34603071212769\n",
      "  time_total_s: 88381.48287367821\n",
      "  timers:\n",
      "    learn_throughput: 934.539\n",
      "    learn_time_ms: 10696.181\n",
      "    load_throughput: 91502.421\n",
      "    load_time_ms: 109.243\n",
      "    sample_throughput: 70.926\n",
      "    sample_time_ms: 140935.305\n",
      "    update_time_ms: 14.92\n",
      "  timestamp: 1636382812\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5627748\n",
      "  training_iteration: 563\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   563</td><td style=\"text-align: right;\">         88381.5</td><td style=\"text-align: right;\">5627748</td><td style=\"text-align: right;\"> 4.10886</td><td style=\"text-align: right;\">               16.71</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           96.3714</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5637744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-49-19\n",
      "  done: false\n",
      "  episode_len_mean: 97.80392156862744\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.860000000000017\n",
      "  episode_reward_mean: 4.350784313725501\n",
      "  episode_reward_min: -1.4800000000000006\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 61274\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0831594235876687\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01360411753299439\n",
      "          policy_loss: -0.057978357116763406\n",
      "          total_loss: 0.1398462994499769\n",
      "          vf_explained_var: 0.93357914686203\n",
      "          vf_loss: 0.1876643703565893\n",
      "    num_agent_steps_sampled: 5637744\n",
      "    num_agent_steps_trained: 5637744\n",
      "    num_steps_sampled: 5637744\n",
      "    num_steps_trained: 5637744\n",
      "  iterations_since_restore: 564\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.57129186602872\n",
      "    ram_util_percent: 57.539712918660285\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550834154591028\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05155420728373\n",
      "    mean_inference_ms: 2.8543547616610967\n",
      "    mean_raw_obs_processing_ms: 3.557005714507104\n",
      "  time_since_restore: 88528.08591032028\n",
      "  time_this_iter_s: 146.60303664207458\n",
      "  time_total_s: 88528.08591032028\n",
      "  timers:\n",
      "    learn_throughput: 934.383\n",
      "    learn_time_ms: 10697.964\n",
      "    load_throughput: 91475.29\n",
      "    load_time_ms: 109.275\n",
      "    sample_throughput: 71.062\n",
      "    sample_time_ms: 140665.54\n",
      "    update_time_ms: 14.445\n",
      "  timestamp: 1636382959\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5637744\n",
      "  training_iteration: 564\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   564</td><td style=\"text-align: right;\">         88528.1</td><td style=\"text-align: right;\">5637744</td><td style=\"text-align: right;\"> 4.35078</td><td style=\"text-align: right;\">               14.86</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           97.8039</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5647740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-51-46\n",
      "  done: false\n",
      "  episode_len_mean: 95.73076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.519999999999957\n",
      "  episode_reward_mean: 3.8318269230769317\n",
      "  episode_reward_min: -1.4900000000000009\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 61378\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1114331655013254\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014193142736159613\n",
      "          policy_loss: -0.05732968415205295\n",
      "          total_loss: 0.13388233005395558\n",
      "          vf_explained_var: 0.9313586950302124\n",
      "          vf_loss: 0.17999259233474732\n",
      "    num_agent_steps_sampled: 5647740\n",
      "    num_agent_steps_trained: 5647740\n",
      "    num_steps_sampled: 5647740\n",
      "    num_steps_trained: 5647740\n",
      "  iterations_since_restore: 565\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.89333333333333\n",
      "    ram_util_percent: 57.5495238095238\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045581456944540265\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.053329476386615\n",
      "    mean_inference_ms: 2.8544676516003826\n",
      "    mean_raw_obs_processing_ms: 3.5555158613140723\n",
      "  time_since_restore: 88675.56083869934\n",
      "  time_this_iter_s: 147.47492837905884\n",
      "  time_total_s: 88675.56083869934\n",
      "  timers:\n",
      "    learn_throughput: 934.071\n",
      "    learn_time_ms: 10701.543\n",
      "    load_throughput: 91489.003\n",
      "    load_time_ms: 109.259\n",
      "    sample_throughput: 70.562\n",
      "    sample_time_ms: 141663.293\n",
      "    update_time_ms: 14.734\n",
      "  timestamp: 1636383106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5647740\n",
      "  training_iteration: 565\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   565</td><td style=\"text-align: right;\">         88675.6</td><td style=\"text-align: right;\">5647740</td><td style=\"text-align: right;\"> 3.83183</td><td style=\"text-align: right;\">               16.52</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">           95.7308</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5657736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-54-33\n",
      "  done: false\n",
      "  episode_len_mean: 96.2135922330097\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.549999999999965\n",
      "  episode_reward_mean: 4.449029126213602\n",
      "  episode_reward_min: -1.830000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 61481\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.125589787348723\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013694745164425795\n",
      "          policy_loss: -0.05725410152067486\n",
      "          total_loss: 0.15695247527562145\n",
      "          vf_explained_var: 0.930344820022583\n",
      "          vf_loss: 0.20426413255114842\n",
      "    num_agent_steps_sampled: 5657736\n",
      "    num_agent_steps_trained: 5657736\n",
      "    num_steps_sampled: 5657736\n",
      "    num_steps_trained: 5657736\n",
      "  iterations_since_restore: 566\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.91470588235295\n",
      "    ram_util_percent: 57.61176470588236\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554443409223964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04828849685386\n",
      "    mean_inference_ms: 2.854263537989514\n",
      "    mean_raw_obs_processing_ms: 3.5584218232964604\n",
      "  time_since_restore: 88842.12295222282\n",
      "  time_this_iter_s: 166.56211352348328\n",
      "  time_total_s: 88842.12295222282\n",
      "  timers:\n",
      "    learn_throughput: 933.755\n",
      "    learn_time_ms: 10705.158\n",
      "    load_throughput: 91356.832\n",
      "    load_time_ms: 109.417\n",
      "    sample_throughput: 69.619\n",
      "    sample_time_ms: 143581.494\n",
      "    update_time_ms: 14.909\n",
      "  timestamp: 1636383273\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5657736\n",
      "  training_iteration: 566\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   566</td><td style=\"text-align: right;\">         88842.1</td><td style=\"text-align: right;\">5657736</td><td style=\"text-align: right;\"> 4.44903</td><td style=\"text-align: right;\">               18.55</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           96.2136</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5667732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-56-48\n",
      "  done: false\n",
      "  episode_len_mean: 98.39603960396039\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.559999999999985\n",
      "  episode_reward_mean: 4.673069306930703\n",
      "  episode_reward_min: -1.0600000000000005\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 61582\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1246428875841645\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013805994990320744\n",
      "          policy_loss: -0.05637580822261735\n",
      "          total_loss: 0.16774615691576758\n",
      "          vf_explained_var: 0.9338754415512085\n",
      "          vf_loss: 0.21391661034053208\n",
      "    num_agent_steps_sampled: 5667732\n",
      "    num_agent_steps_trained: 5667732\n",
      "    num_steps_sampled: 5667732\n",
      "    num_steps_trained: 5667732\n",
      "  iterations_since_restore: 567\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99585492227978\n",
      "    ram_util_percent: 57.56528497409326\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553090998184481\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04725309284586\n",
      "    mean_inference_ms: 2.85433738757275\n",
      "    mean_raw_obs_processing_ms: 3.553307582639065\n",
      "  time_since_restore: 88977.05783081055\n",
      "  time_this_iter_s: 134.93487858772278\n",
      "  time_total_s: 88977.05783081055\n",
      "  timers:\n",
      "    learn_throughput: 933.534\n",
      "    learn_time_ms: 10707.693\n",
      "    load_throughput: 91093.869\n",
      "    load_time_ms: 109.733\n",
      "    sample_throughput: 70.427\n",
      "    sample_time_ms: 141933.432\n",
      "    update_time_ms: 14.859\n",
      "  timestamp: 1636383408\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5667732\n",
      "  training_iteration: 567\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   567</td><td style=\"text-align: right;\">         88977.1</td><td style=\"text-align: right;\">5667732</td><td style=\"text-align: right;\"> 4.67307</td><td style=\"text-align: right;\">               18.56</td><td style=\"text-align: right;\">               -1.06</td><td style=\"text-align: right;\">            98.396</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5677728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_14-59-44\n",
      "  done: false\n",
      "  episode_len_mean: 94.51401869158879\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.630000000000013\n",
      "  episode_reward_mean: 4.22373831775702\n",
      "  episode_reward_min: -1.5900000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 61689\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.111798931187035\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012712736163032305\n",
      "          policy_loss: -0.05579937226815611\n",
      "          total_loss: 0.1250577067160326\n",
      "          vf_explained_var: 0.9399455785751343\n",
      "          vf_loss: 0.1730138639593099\n",
      "    num_agent_steps_sampled: 5677728\n",
      "    num_agent_steps_trained: 5677728\n",
      "    num_steps_sampled: 5677728\n",
      "    num_steps_trained: 5677728\n",
      "  iterations_since_restore: 568\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.8312\n",
      "    ram_util_percent: 57.65\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550765808379392\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.041862158584244\n",
      "    mean_inference_ms: 2.854187242595119\n",
      "    mean_raw_obs_processing_ms: 3.558068526061715\n",
      "  time_since_restore: 89152.66758012772\n",
      "  time_this_iter_s: 175.6097493171692\n",
      "  time_total_s: 89152.66758012772\n",
      "  timers:\n",
      "    learn_throughput: 933.361\n",
      "    learn_time_ms: 10709.68\n",
      "    load_throughput: 91012.773\n",
      "    load_time_ms: 109.831\n",
      "    sample_throughput: 69.759\n",
      "    sample_time_ms: 143293.209\n",
      "    update_time_ms: 14.177\n",
      "  timestamp: 1636383584\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5677728\n",
      "  training_iteration: 568\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   568</td><td style=\"text-align: right;\">         89152.7</td><td style=\"text-align: right;\">5677728</td><td style=\"text-align: right;\"> 4.22374</td><td style=\"text-align: right;\">               16.63</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">            94.514</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5687724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-02-11\n",
      "  done: false\n",
      "  episode_len_mean: 95.35576923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.460000000000015\n",
      "  episode_reward_mean: 3.738942307692317\n",
      "  episode_reward_min: -1.6800000000000008\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 61793\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1293568797600577\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01274605658765556\n",
      "          policy_loss: -0.06260139083442015\n",
      "          total_loss: 0.11342840661398239\n",
      "          vf_explained_var: 0.927426815032959\n",
      "          vf_loss: 0.1682862551500782\n",
      "    num_agent_steps_sampled: 5687724\n",
      "    num_agent_steps_trained: 5687724\n",
      "    num_steps_sampled: 5687724\n",
      "    num_steps_trained: 5687724\n",
      "  iterations_since_restore: 569\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.92037914691946\n",
      "    ram_util_percent: 57.657819905213266\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557586855142689\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04331966253803\n",
      "    mean_inference_ms: 2.854454612862507\n",
      "    mean_raw_obs_processing_ms: 3.5555199306367604\n",
      "  time_since_restore: 89300.21220135689\n",
      "  time_this_iter_s: 147.54462122917175\n",
      "  time_total_s: 89300.21220135689\n",
      "  timers:\n",
      "    learn_throughput: 933.137\n",
      "    learn_time_ms: 10712.256\n",
      "    load_throughput: 91045.008\n",
      "    load_time_ms: 109.792\n",
      "    sample_throughput: 69.256\n",
      "    sample_time_ms: 144334.201\n",
      "    update_time_ms: 14.796\n",
      "  timestamp: 1636383731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5687724\n",
      "  training_iteration: 569\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   569</td><td style=\"text-align: right;\">         89300.2</td><td style=\"text-align: right;\">5687724</td><td style=\"text-align: right;\"> 3.73894</td><td style=\"text-align: right;\">               12.46</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           95.3558</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5697720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-04-27\n",
      "  done: false\n",
      "  episode_len_mean: 97.36274509803921\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.790000000000013\n",
      "  episode_reward_mean: 3.954313725490205\n",
      "  episode_reward_min: -0.7900000000000006\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 61895\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1289142335581985\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012876059788955957\n",
      "          policy_loss: -0.06154343008867696\n",
      "          total_loss: 0.11185215872147272\n",
      "          vf_explained_var: 0.9265124201774597\n",
      "          vf_loss: 0.16535145655815672\n",
      "    num_agent_steps_sampled: 5697720\n",
      "    num_agent_steps_trained: 5697720\n",
      "    num_steps_sampled: 5697720\n",
      "    num_steps_trained: 5697720\n",
      "  iterations_since_restore: 570\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04278350515466\n",
      "    ram_util_percent: 57.60876288659793\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551798962836569\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.040627768513446\n",
      "    mean_inference_ms: 2.854335870972705\n",
      "    mean_raw_obs_processing_ms: 3.550648464616548\n",
      "  time_since_restore: 89436.15098643303\n",
      "  time_this_iter_s: 135.93878507614136\n",
      "  time_total_s: 89436.15098643303\n",
      "  timers:\n",
      "    learn_throughput: 933.014\n",
      "    learn_time_ms: 10713.666\n",
      "    load_throughput: 90909.818\n",
      "    load_time_ms: 109.955\n",
      "    sample_throughput: 70.853\n",
      "    sample_time_ms: 141081.514\n",
      "    update_time_ms: 12.582\n",
      "  timestamp: 1636383867\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5697720\n",
      "  training_iteration: 570\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   570</td><td style=\"text-align: right;\">         89436.2</td><td style=\"text-align: right;\">5697720</td><td style=\"text-align: right;\"> 3.95431</td><td style=\"text-align: right;\">               12.79</td><td style=\"text-align: right;\">               -0.79</td><td style=\"text-align: right;\">           97.3627</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5707716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-07-22\n",
      "  done: false\n",
      "  episode_len_mean: 98.95098039215686\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.99000000000001\n",
      "  episode_reward_mean: 4.88529411764707\n",
      "  episode_reward_min: -1.2300000000000006\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 61997\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.11611845177463\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013918796629754336\n",
      "          policy_loss: -0.05853500746063187\n",
      "          total_loss: 0.14110093718856317\n",
      "          vf_explained_var: 0.9326081871986389\n",
      "          vf_loss: 0.1890883695620757\n",
      "    num_agent_steps_sampled: 5707716\n",
      "    num_agent_steps_trained: 5707716\n",
      "    num_steps_sampled: 5707716\n",
      "    num_steps_trained: 5707716\n",
      "  iterations_since_restore: 571\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.56360000000001\n",
      "    ram_util_percent: 57.676\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045533837003684845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0346688328274\n",
      "    mean_inference_ms: 2.8545734242551144\n",
      "    mean_raw_obs_processing_ms: 3.554002301669857\n",
      "  time_since_restore: 89611.18899941444\n",
      "  time_this_iter_s: 175.0380129814148\n",
      "  time_total_s: 89611.18899941444\n",
      "  timers:\n",
      "    learn_throughput: 932.878\n",
      "    learn_time_ms: 10715.224\n",
      "    load_throughput: 90936.24\n",
      "    load_time_ms: 109.923\n",
      "    sample_throughput: 69.829\n",
      "    sample_time_ms: 143149.821\n",
      "    update_time_ms: 11.784\n",
      "  timestamp: 1636384042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5707716\n",
      "  training_iteration: 571\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   571</td><td style=\"text-align: right;\">         89611.2</td><td style=\"text-align: right;\">5707716</td><td style=\"text-align: right;\"> 4.88529</td><td style=\"text-align: right;\">               14.99</td><td style=\"text-align: right;\">               -1.23</td><td style=\"text-align: right;\">            98.951</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5717712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-10-11\n",
      "  done: false\n",
      "  episode_len_mean: 94.48571428571428\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.349999999999977\n",
      "  episode_reward_mean: 4.718571428571438\n",
      "  episode_reward_min: -1.3300000000000005\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 62102\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0956934713909767\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015026483812684038\n",
      "          policy_loss: -0.05660930984359012\n",
      "          total_loss: 0.18063569214736294\n",
      "          vf_explained_var: 0.92402583360672\n",
      "          vf_loss: 0.22396972761449652\n",
      "    num_agent_steps_sampled: 5717712\n",
      "    num_agent_steps_trained: 5717712\n",
      "    num_steps_sampled: 5717712\n",
      "    num_steps_trained: 5717712\n",
      "  iterations_since_restore: 572\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.01750000000001\n",
      "    ram_util_percent: 57.56083333333333\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553910694345167\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03365547459742\n",
      "    mean_inference_ms: 2.854318302234832\n",
      "    mean_raw_obs_processing_ms: 3.5567552422147375\n",
      "  time_since_restore: 89779.51256918907\n",
      "  time_this_iter_s: 168.32356977462769\n",
      "  time_total_s: 89779.51256918907\n",
      "  timers:\n",
      "    learn_throughput: 932.305\n",
      "    learn_time_ms: 10721.809\n",
      "    load_throughput: 91084.468\n",
      "    load_time_ms: 109.744\n",
      "    sample_throughput: 69.042\n",
      "    sample_time_ms: 144781.701\n",
      "    update_time_ms: 11.043\n",
      "  timestamp: 1636384211\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5717712\n",
      "  training_iteration: 572\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   572</td><td style=\"text-align: right;\">         89779.5</td><td style=\"text-align: right;\">5717712</td><td style=\"text-align: right;\"> 4.71857</td><td style=\"text-align: right;\">               18.35</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">           94.4857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5727708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-12-27\n",
      "  done: false\n",
      "  episode_len_mean: 96.86538461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.150000000000018\n",
      "  episode_reward_mean: 3.9190384615384706\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 62206\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1222985537643106\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013088027680257621\n",
      "          policy_loss: -0.05929172728688289\n",
      "          total_loss: 0.13136825050251225\n",
      "          vf_explained_var: 0.9302048087120056\n",
      "          vf_loss: 0.18206679937230724\n",
      "    num_agent_steps_sampled: 5727708\n",
      "    num_agent_steps_trained: 5727708\n",
      "    num_steps_sampled: 5727708\n",
      "    num_steps_trained: 5727708\n",
      "  iterations_since_restore: 573\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92974358974361\n",
      "    ram_util_percent: 57.513846153846146\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045515440522297515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03271370700199\n",
      "    mean_inference_ms: 2.8543714011036108\n",
      "    mean_raw_obs_processing_ms: 3.551861712359491\n",
      "  time_since_restore: 89916.10888290405\n",
      "  time_this_iter_s: 136.59631371498108\n",
      "  time_total_s: 89916.10888290405\n",
      "  timers:\n",
      "    learn_throughput: 932.497\n",
      "    learn_time_ms: 10719.603\n",
      "    load_throughput: 91037.872\n",
      "    load_time_ms: 109.8\n",
      "    sample_throughput: 70.093\n",
      "    sample_time_ms: 142610.233\n",
      "    update_time_ms: 9.888\n",
      "  timestamp: 1636384347\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5727708\n",
      "  training_iteration: 573\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   573</td><td style=\"text-align: right;\">         89916.1</td><td style=\"text-align: right;\">5727708</td><td style=\"text-align: right;\"> 3.91904</td><td style=\"text-align: right;\">               14.15</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           96.8654</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5737704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 95.35576923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.239999999999952\n",
      "  episode_reward_mean: 4.041346153846163\n",
      "  episode_reward_min: -1.660000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 62310\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1104150819982217\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013011378765768961\n",
      "          policy_loss: -0.054749308401543614\n",
      "          total_loss: 0.12710538263886403\n",
      "          vf_explained_var: 0.9332365393638611\n",
      "          vf_loss: 0.1733172937320211\n",
      "    num_agent_steps_sampled: 5737704\n",
      "    num_agent_steps_trained: 5737704\n",
      "    num_steps_sampled: 5737704\n",
      "    num_steps_trained: 5737704\n",
      "  iterations_since_restore: 574\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.39778761061946\n",
      "    ram_util_percent: 57.555309734513266\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556877432689107\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0305124881683\n",
      "    mean_inference_ms: 2.854645939234482\n",
      "    mean_raw_obs_processing_ms: 3.5523971854186325\n",
      "  time_since_restore: 90074.91092348099\n",
      "  time_this_iter_s: 158.80204057693481\n",
      "  time_total_s: 90074.91092348099\n",
      "  timers:\n",
      "    learn_throughput: 932.548\n",
      "    learn_time_ms: 10719.023\n",
      "    load_throughput: 91005.444\n",
      "    load_time_ms: 109.84\n",
      "    sample_throughput: 69.499\n",
      "    sample_time_ms: 143829.583\n",
      "    update_time_ms: 11.139\n",
      "  timestamp: 1636384506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5737704\n",
      "  training_iteration: 574\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   574</td><td style=\"text-align: right;\">         90074.9</td><td style=\"text-align: right;\">5737704</td><td style=\"text-align: right;\"> 4.04135</td><td style=\"text-align: right;\">               16.24</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           95.3558</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5747700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-17-51\n",
      "  done: false\n",
      "  episode_len_mean: 96.01904761904763\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.640000000000015\n",
      "  episode_reward_mean: 4.517142857142867\n",
      "  episode_reward_min: -1.3500000000000003\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 62415\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1175304061327225\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013377492058826487\n",
      "          policy_loss: -0.05812235514545797\n",
      "          total_loss: 0.12376510336453843\n",
      "          vf_explained_var: 0.9337720274925232\n",
      "          vf_loss: 0.17258716298537885\n",
      "    num_agent_steps_sampled: 5747700\n",
      "    num_agent_steps_trained: 5747700\n",
      "    num_steps_sampled: 5747700\n",
      "    num_steps_trained: 5747700\n",
      "  iterations_since_restore: 575\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.6063829787234\n",
      "    ram_util_percent: 57.62042553191489\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045553637609242345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02672561842612\n",
      "    mean_inference_ms: 2.8541856953800853\n",
      "    mean_raw_obs_processing_ms: 3.5560227706121115\n",
      "  time_since_restore: 90239.53258562088\n",
      "  time_this_iter_s: 164.62166213989258\n",
      "  time_total_s: 90239.53258562088\n",
      "  timers:\n",
      "    learn_throughput: 933.124\n",
      "    learn_time_ms: 10712.4\n",
      "    load_throughput: 91237.012\n",
      "    load_time_ms: 109.561\n",
      "    sample_throughput: 68.676\n",
      "    sample_time_ms: 145552.142\n",
      "    update_time_ms: 10.227\n",
      "  timestamp: 1636384671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5747700\n",
      "  training_iteration: 575\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   575</td><td style=\"text-align: right;\">         90239.5</td><td style=\"text-align: right;\">5747700</td><td style=\"text-align: right;\"> 4.51714</td><td style=\"text-align: right;\">               16.64</td><td style=\"text-align: right;\">               -1.35</td><td style=\"text-align: right;\">            96.019</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5757696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-20-27\n",
      "  done: false\n",
      "  episode_len_mean: 97.86274509803921\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.480000000000016\n",
      "  episode_reward_mean: 4.164803921568638\n",
      "  episode_reward_min: -1.5800000000000005\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 62517\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1415650240376465\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013022765933451965\n",
      "          policy_loss: -0.05839841022100459\n",
      "          total_loss: 0.1108402054104158\n",
      "          vf_explained_var: 0.9338297247886658\n",
      "          vf_loss: 0.16098677593991798\n",
      "    num_agent_steps_sampled: 5757696\n",
      "    num_agent_steps_trained: 5757696\n",
      "    num_steps_sampled: 5757696\n",
      "    num_steps_trained: 5757696\n",
      "  iterations_since_restore: 576\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.66547085201795\n",
      "    ram_util_percent: 57.58430493273542\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551435063237205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02097306725784\n",
      "    mean_inference_ms: 2.8541346049936425\n",
      "    mean_raw_obs_processing_ms: 3.5568305772702313\n",
      "  time_since_restore: 90395.45909023285\n",
      "  time_this_iter_s: 155.926504611969\n",
      "  time_total_s: 90395.45909023285\n",
      "  timers:\n",
      "    learn_throughput: 933.578\n",
      "    learn_time_ms: 10707.197\n",
      "    load_throughput: 91425.9\n",
      "    load_time_ms: 109.334\n",
      "    sample_throughput: 69.18\n",
      "    sample_time_ms: 144492.397\n",
      "    update_time_ms: 11.591\n",
      "  timestamp: 1636384827\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5757696\n",
      "  training_iteration: 576\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   576</td><td style=\"text-align: right;\">         90395.5</td><td style=\"text-align: right;\">5757696</td><td style=\"text-align: right;\">  4.1648</td><td style=\"text-align: right;\">               10.48</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           97.8627</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5767692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-22-56\n",
      "  done: false\n",
      "  episode_len_mean: 98.26732673267327\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.180000000000017\n",
      "  episode_reward_mean: 3.7522772277227836\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 62618\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1368523485640174\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01223401428030731\n",
      "          policy_loss: -0.061329151237081006\n",
      "          total_loss: 0.10362102854280518\n",
      "          vf_explained_var: 0.932658314704895\n",
      "          vf_loss: 0.15844808905106833\n",
      "    num_agent_steps_sampled: 5767692\n",
      "    num_agent_steps_trained: 5767692\n",
      "    num_steps_sampled: 5767692\n",
      "    num_steps_trained: 5767692\n",
      "  iterations_since_restore: 577\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.08215962441315\n",
      "    ram_util_percent: 57.542253521126746\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554239279975171\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02120539347729\n",
      "    mean_inference_ms: 2.854106155055482\n",
      "    mean_raw_obs_processing_ms: 3.5555053211417897\n",
      "  time_since_restore: 90544.94812488556\n",
      "  time_this_iter_s: 149.48903465270996\n",
      "  time_total_s: 90544.94812488556\n",
      "  timers:\n",
      "    learn_throughput: 933.621\n",
      "    learn_time_ms: 10706.698\n",
      "    load_throughput: 91568.889\n",
      "    load_time_ms: 109.164\n",
      "    sample_throughput: 68.49\n",
      "    sample_time_ms: 145948.186\n",
      "    update_time_ms: 11.733\n",
      "  timestamp: 1636384976\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5767692\n",
      "  training_iteration: 577\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   577</td><td style=\"text-align: right;\">         90544.9</td><td style=\"text-align: right;\">5767692</td><td style=\"text-align: right;\"> 3.75228</td><td style=\"text-align: right;\">               14.18</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           98.2673</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5777688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-25-25\n",
      "  done: false\n",
      "  episode_len_mean: 97.1826923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.549999999999994\n",
      "  episode_reward_mean: 4.41644230769232\n",
      "  episode_reward_min: -0.6900000000000004\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 62722\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0897754640660735\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014193872556980939\n",
      "          policy_loss: -0.06148469492188122\n",
      "          total_loss: 0.1301862336257393\n",
      "          vf_explained_var: 0.9389698505401611\n",
      "          vf_loss: 0.18023326695920566\n",
      "    num_agent_steps_sampled: 5777688\n",
      "    num_agent_steps_trained: 5777688\n",
      "    num_steps_sampled: 5777688\n",
      "    num_steps_trained: 5777688\n",
      "  iterations_since_restore: 578\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.47042253521126\n",
      "    ram_util_percent: 57.460563380281684\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556628958304036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02053791642448\n",
      "    mean_inference_ms: 2.85444241270639\n",
      "    mean_raw_obs_processing_ms: 3.5525115997018415\n",
      "  time_since_restore: 90693.96169304848\n",
      "  time_this_iter_s: 149.0135681629181\n",
      "  time_total_s: 90693.96169304848\n",
      "  timers:\n",
      "    learn_throughput: 933.57\n",
      "    learn_time_ms: 10707.279\n",
      "    load_throughput: 91375.348\n",
      "    load_time_ms: 109.395\n",
      "    sample_throughput: 69.762\n",
      "    sample_time_ms: 143288.021\n",
      "    update_time_ms: 11.753\n",
      "  timestamp: 1636385125\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5777688\n",
      "  training_iteration: 578\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   578</td><td style=\"text-align: right;\">           90694</td><td style=\"text-align: right;\">5777688</td><td style=\"text-align: right;\"> 4.41644</td><td style=\"text-align: right;\">               18.55</td><td style=\"text-align: right;\">               -0.69</td><td style=\"text-align: right;\">           97.1827</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5787684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-28-01\n",
      "  done: false\n",
      "  episode_len_mean: 94.80952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.389999999999976\n",
      "  episode_reward_mean: 4.1093333333333435\n",
      "  episode_reward_min: -1.3600000000000008\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 62827\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.11247673921096\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013258675426111028\n",
      "          policy_loss: -0.05678113014715859\n",
      "          total_loss: 0.11954396263911174\n",
      "          vf_explained_var: 0.9340867400169373\n",
      "          vf_loss: 0.16724493984196687\n",
      "    num_agent_steps_sampled: 5787684\n",
      "    num_agent_steps_trained: 5787684\n",
      "    num_steps_sampled: 5787684\n",
      "    num_steps_trained: 5787684\n",
      "  iterations_since_restore: 579\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.73632286995517\n",
      "    ram_util_percent: 57.536771300448436\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045521768946189554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0167511498831\n",
      "    mean_inference_ms: 2.8541946242011007\n",
      "    mean_raw_obs_processing_ms: 3.5552454437433414\n",
      "  time_since_restore: 90850.17128396034\n",
      "  time_this_iter_s: 156.20959091186523\n",
      "  time_total_s: 90850.17128396034\n",
      "  timers:\n",
      "    learn_throughput: 934.061\n",
      "    learn_time_ms: 10701.655\n",
      "    load_throughput: 91171.282\n",
      "    load_time_ms: 109.64\n",
      "    sample_throughput: 69.339\n",
      "    sample_time_ms: 144160.364\n",
      "    update_time_ms: 11.639\n",
      "  timestamp: 1636385281\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5787684\n",
      "  training_iteration: 579\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   579</td><td style=\"text-align: right;\">         90850.2</td><td style=\"text-align: right;\">5787684</td><td style=\"text-align: right;\"> 4.10933</td><td style=\"text-align: right;\">               18.39</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           94.8095</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5797680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 96.23809523809524\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.810000000000016\n",
      "  episode_reward_mean: 4.37752380952382\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 62932\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.139003818564945\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012632674746849589\n",
      "          policy_loss: -0.06047894972989447\n",
      "          total_loss: 0.10914798924683505\n",
      "          vf_explained_var: 0.9325283765792847\n",
      "          vf_loss: 0.16223816505322855\n",
      "    num_agent_steps_sampled: 5797680\n",
      "    num_agent_steps_trained: 5797680\n",
      "    num_steps_sampled: 5797680\n",
      "    num_steps_trained: 5797680\n",
      "  iterations_since_restore: 580\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.99227272727273\n",
      "    ram_util_percent: 57.566818181818164\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553756315354938\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01718160952322\n",
      "    mean_inference_ms: 2.854183028589152\n",
      "    mean_raw_obs_processing_ms: 3.5540005350083934\n",
      "  time_since_restore: 91004.34133434296\n",
      "  time_this_iter_s: 154.17005038261414\n",
      "  time_total_s: 91004.34133434296\n",
      "  timers:\n",
      "    learn_throughput: 933.756\n",
      "    learn_time_ms: 10705.152\n",
      "    load_throughput: 91213.054\n",
      "    load_time_ms: 109.59\n",
      "    sample_throughput: 68.476\n",
      "    sample_time_ms: 145978.994\n",
      "    update_time_ms: 12.677\n",
      "  timestamp: 1636385436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5797680\n",
      "  training_iteration: 580\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   580</td><td style=\"text-align: right;\">         91004.3</td><td style=\"text-align: right;\">5797680</td><td style=\"text-align: right;\"> 4.37752</td><td style=\"text-align: right;\">               14.81</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           96.2381</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5807676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-32-57\n",
      "  done: false\n",
      "  episode_len_mean: 94.8173076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.620000000000017\n",
      "  episode_reward_mean: 3.7976923076923166\n",
      "  episode_reward_min: -1.6900000000000008\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 63036\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1235980173461457\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013047743152547732\n",
      "          policy_loss: -0.0610131273077976\n",
      "          total_loss: 0.11772249293967317\n",
      "          vf_explained_var: 0.931091845035553\n",
      "          vf_loss: 0.17024720936663384\n",
      "    num_agent_steps_sampled: 5807676\n",
      "    num_agent_steps_trained: 5807676\n",
      "    num_steps_sampled: 5807676\n",
      "    num_steps_trained: 5807676\n",
      "  iterations_since_restore: 581\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79353233830845\n",
      "    ram_util_percent: 57.54328358208956\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045557583332842516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01921348198595\n",
      "    mean_inference_ms: 2.8543733785234524\n",
      "    mean_raw_obs_processing_ms: 3.548707279321879\n",
      "  time_since_restore: 91145.61866211891\n",
      "  time_this_iter_s: 141.2773277759552\n",
      "  time_total_s: 91145.61866211891\n",
      "  timers:\n",
      "    learn_throughput: 933.613\n",
      "    learn_time_ms: 10706.788\n",
      "    load_throughput: 91305.72\n",
      "    load_time_ms: 109.478\n",
      "    sample_throughput: 70.098\n",
      "    sample_time_ms: 142601.17\n",
      "    update_time_ms: 12.567\n",
      "  timestamp: 1636385577\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5807676\n",
      "  training_iteration: 581\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   581</td><td style=\"text-align: right;\">         91145.6</td><td style=\"text-align: right;\">5807676</td><td style=\"text-align: right;\"> 3.79769</td><td style=\"text-align: right;\">               12.62</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           94.8173</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5817672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-35-43\n",
      "  done: false\n",
      "  episode_len_mean: 93.27522935779817\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.810000000000018\n",
      "  episode_reward_mean: 4.417339449541296\n",
      "  episode_reward_min: -1.0200000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 63145\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0888265744233743\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012787690342119327\n",
      "          policy_loss: -0.05942912434076524\n",
      "          total_loss: 0.0952718137174399\n",
      "          vf_explained_var: 0.9450990557670593\n",
      "          vf_loss: 0.14645724596025853\n",
      "    num_agent_steps_sampled: 5817672\n",
      "    num_agent_steps_trained: 5817672\n",
      "    num_steps_sampled: 5817672\n",
      "    num_steps_trained: 5817672\n",
      "  iterations_since_restore: 582\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.53924050632912\n",
      "    ram_util_percent: 57.479324894514775\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553213780795712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01461349825138\n",
      "    mean_inference_ms: 2.854316044811007\n",
      "    mean_raw_obs_processing_ms: 3.553758977510593\n",
      "  time_since_restore: 91311.65844130516\n",
      "  time_this_iter_s: 166.03977918624878\n",
      "  time_total_s: 91311.65844130516\n",
      "  timers:\n",
      "    learn_throughput: 934.174\n",
      "    learn_time_ms: 10700.363\n",
      "    load_throughput: 91215.951\n",
      "    load_time_ms: 109.586\n",
      "    sample_throughput: 70.207\n",
      "    sample_time_ms: 142378.584\n",
      "    update_time_ms: 12.672\n",
      "  timestamp: 1636385743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5817672\n",
      "  training_iteration: 582\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   582</td><td style=\"text-align: right;\">         91311.7</td><td style=\"text-align: right;\">5817672</td><td style=\"text-align: right;\"> 4.41734</td><td style=\"text-align: right;\">               14.81</td><td style=\"text-align: right;\">               -1.02</td><td style=\"text-align: right;\">           93.2752</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5827668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-38-40\n",
      "  done: false\n",
      "  episode_len_mean: 93.47169811320755\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.729999999999993\n",
      "  episode_reward_mean: 4.451415094339632\n",
      "  episode_reward_min: -1.0900000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 63251\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1105083973998697\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013114676600634105\n",
      "          policy_loss: -0.058445780376434074\n",
      "          total_loss: 0.13139237880818228\n",
      "          vf_explained_var: 0.9309390783309937\n",
      "          vf_loss: 0.1810663706328497\n",
      "    num_agent_steps_sampled: 5827668\n",
      "    num_agent_steps_trained: 5827668\n",
      "    num_steps_sampled: 5827668\n",
      "    num_steps_trained: 5827668\n",
      "  iterations_since_restore: 583\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90750988142292\n",
      "    ram_util_percent: 57.64624505928853\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045549730334422\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01526407697672\n",
      "    mean_inference_ms: 2.8542949964550552\n",
      "    mean_raw_obs_processing_ms: 3.5575020820511623\n",
      "  time_since_restore: 91488.9387383461\n",
      "  time_this_iter_s: 177.28029704093933\n",
      "  time_total_s: 91488.9387383461\n",
      "  timers:\n",
      "    learn_throughput: 933.601\n",
      "    learn_time_ms: 10706.925\n",
      "    load_throughput: 91307.271\n",
      "    load_time_ms: 109.476\n",
      "    sample_throughput: 68.26\n",
      "    sample_time_ms: 146440.193\n",
      "    update_time_ms: 12.966\n",
      "  timestamp: 1636385920\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5827668\n",
      "  training_iteration: 583\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   583</td><td style=\"text-align: right;\">         91488.9</td><td style=\"text-align: right;\">5827668</td><td style=\"text-align: right;\"> 4.45142</td><td style=\"text-align: right;\">               18.73</td><td style=\"text-align: right;\">               -1.09</td><td style=\"text-align: right;\">           93.4717</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5837664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-41-24\n",
      "  done: false\n",
      "  episode_len_mean: 94.29245283018868\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.450000000000017\n",
      "  episode_reward_mean: 4.426603773584917\n",
      "  episode_reward_min: -1.690000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 63357\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.135132402334458\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012615785338136537\n",
      "          policy_loss: -0.06299000650835343\n",
      "          total_loss: 0.11981204319745302\n",
      "          vf_explained_var: 0.9225195646286011\n",
      "          vf_loss: 0.17541303541033695\n",
      "    num_agent_steps_sampled: 5837664\n",
      "    num_agent_steps_trained: 5837664\n",
      "    num_steps_sampled: 5837664\n",
      "    num_steps_trained: 5837664\n",
      "  iterations_since_restore: 584\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.30940170940171\n",
      "    ram_util_percent: 57.836752136752146\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558705383454916\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01494375308609\n",
      "    mean_inference_ms: 2.8542772368190126\n",
      "    mean_raw_obs_processing_ms: 3.5591308325246542\n",
      "  time_since_restore: 91652.48091578484\n",
      "  time_this_iter_s: 163.54217743873596\n",
      "  time_total_s: 91652.48091578484\n",
      "  timers:\n",
      "    learn_throughput: 933.403\n",
      "    learn_time_ms: 10709.202\n",
      "    load_throughput: 91345.645\n",
      "    load_time_ms: 109.431\n",
      "    sample_throughput: 68.04\n",
      "    sample_time_ms: 146912.882\n",
      "    update_time_ms: 11.674\n",
      "  timestamp: 1636386084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5837664\n",
      "  training_iteration: 584\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   584</td><td style=\"text-align: right;\">         91652.5</td><td style=\"text-align: right;\">5837664</td><td style=\"text-align: right;\">  4.4266</td><td style=\"text-align: right;\">               14.45</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           94.2925</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5847660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-44-00\n",
      "  done: false\n",
      "  episode_len_mean: 93.20560747663552\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.589999999999943\n",
      "  episode_reward_mean: 4.168691588785056\n",
      "  episode_reward_min: -0.8800000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 63464\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0994578001845596\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013408779114780932\n",
      "          policy_loss: -0.05935329878623159\n",
      "          total_loss: 0.12297094432859976\n",
      "          vf_explained_var: 0.9290771484375\n",
      "          vf_loss: 0.17277194406582505\n",
      "    num_agent_steps_sampled: 5847660\n",
      "    num_agent_steps_trained: 5847660\n",
      "    num_steps_sampled: 5847660\n",
      "    num_steps_trained: 5847660\n",
      "  iterations_since_restore: 585\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.9762331838565\n",
      "    ram_util_percent: 57.68206278026904\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552757479403861\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01243850806849\n",
      "    mean_inference_ms: 2.85434943093439\n",
      "    mean_raw_obs_processing_ms: 3.5561650610841165\n",
      "  time_since_restore: 91808.66223621368\n",
      "  time_this_iter_s: 156.18132042884827\n",
      "  time_total_s: 91808.66223621368\n",
      "  timers:\n",
      "    learn_throughput: 932.481\n",
      "    learn_time_ms: 10719.793\n",
      "    load_throughput: 91185.876\n",
      "    load_time_ms: 109.622\n",
      "    sample_throughput: 68.439\n",
      "    sample_time_ms: 146057.64\n",
      "    update_time_ms: 11.872\n",
      "  timestamp: 1636386240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5847660\n",
      "  training_iteration: 585\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   585</td><td style=\"text-align: right;\">         91808.7</td><td style=\"text-align: right;\">5847660</td><td style=\"text-align: right;\"> 4.16869</td><td style=\"text-align: right;\">               18.59</td><td style=\"text-align: right;\">               -0.88</td><td style=\"text-align: right;\">           93.2056</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5857656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-46-21\n",
      "  done: false\n",
      "  episode_len_mean: 93.61682242990655\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.84000000000001\n",
      "  episode_reward_mean: 3.639065420560756\n",
      "  episode_reward_min: -1.0700000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 63571\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1475603682363134\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013065970761701923\n",
      "          policy_loss: -0.061166023080929735\n",
      "          total_loss: 0.10554548617945904\n",
      "          vf_explained_var: 0.9128769636154175\n",
      "          vf_loss: 0.15842119538758556\n",
      "    num_agent_steps_sampled: 5857656\n",
      "    num_agent_steps_trained: 5857656\n",
      "    num_steps_sampled: 5857656\n",
      "    num_steps_trained: 5857656\n",
      "  iterations_since_restore: 586\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.807\n",
      "    ram_util_percent: 57.6095\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045566659020194786\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01598088188575\n",
      "    mean_inference_ms: 2.854436396259587\n",
      "    mean_raw_obs_processing_ms: 3.5516318319511266\n",
      "  time_since_restore: 91949.3187110424\n",
      "  time_this_iter_s: 140.6564748287201\n",
      "  time_total_s: 91949.3187110424\n",
      "  timers:\n",
      "    learn_throughput: 932.149\n",
      "    learn_time_ms: 10723.605\n",
      "    load_throughput: 89374.245\n",
      "    load_time_ms: 111.844\n",
      "    sample_throughput: 69.164\n",
      "    sample_time_ms: 144525.759\n",
      "    update_time_ms: 10.843\n",
      "  timestamp: 1636386381\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5857656\n",
      "  training_iteration: 586\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   586</td><td style=\"text-align: right;\">         91949.3</td><td style=\"text-align: right;\">5857656</td><td style=\"text-align: right;\"> 3.63907</td><td style=\"text-align: right;\">               12.84</td><td style=\"text-align: right;\">               -1.07</td><td style=\"text-align: right;\">           93.6168</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5867652\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-48-48\n",
      "  done: false\n",
      "  episode_len_mean: 96.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.81\n",
      "  episode_reward_mean: 4.437115384615395\n",
      "  episode_reward_min: -1.0200000000000005\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 63675\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.123581993070423\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013928562996960764\n",
      "          policy_loss: -0.059352648500193894\n",
      "          total_loss: 0.11803770516004063\n",
      "          vf_explained_var: 0.9377892017364502\n",
      "          vf_loss: 0.16689516631806764\n",
      "    num_agent_steps_sampled: 5867652\n",
      "    num_agent_steps_trained: 5867652\n",
      "    num_steps_sampled: 5867652\n",
      "    num_steps_trained: 5867652\n",
      "  iterations_since_restore: 587\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.9557142857143\n",
      "    ram_util_percent: 57.71238095238095\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557496324844667\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.014957709876306\n",
      "    mean_inference_ms: 2.8546132231314867\n",
      "    mean_raw_obs_processing_ms: 3.54881340949182\n",
      "  time_since_restore: 92096.03553628922\n",
      "  time_this_iter_s: 146.7168252468109\n",
      "  time_total_s: 92096.03553628922\n",
      "  timers:\n",
      "    learn_throughput: 932.411\n",
      "    learn_time_ms: 10720.593\n",
      "    load_throughput: 89464.662\n",
      "    load_time_ms: 111.731\n",
      "    sample_throughput: 69.295\n",
      "    sample_time_ms: 144251.953\n",
      "    update_time_ms: 10.739\n",
      "  timestamp: 1636386528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5867652\n",
      "  training_iteration: 587\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   587</td><td style=\"text-align: right;\">           92096</td><td style=\"text-align: right;\">5867652</td><td style=\"text-align: right;\"> 4.43712</td><td style=\"text-align: right;\">               16.81</td><td style=\"text-align: right;\">               -1.02</td><td style=\"text-align: right;\">                96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5877648\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-51-32\n",
      "  done: false\n",
      "  episode_len_mean: 92.25925925925925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.43999999999996\n",
      "  episode_reward_mean: 4.383518518518527\n",
      "  episode_reward_min: -1.990000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 63783\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.124985766105163\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013527383604483429\n",
      "          policy_loss: -0.05806903232557651\n",
      "          total_loss: 0.11112539591586106\n",
      "          vf_explained_var: 0.9344698190689087\n",
      "          vf_loss: 0.1596272146456644\n",
      "    num_agent_steps_sampled: 5877648\n",
      "    num_agent_steps_trained: 5877648\n",
      "    num_steps_sampled: 5877648\n",
      "    num_steps_trained: 5877648\n",
      "  iterations_since_restore: 588\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.21709401709401\n",
      "    ram_util_percent: 57.685042735042735\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554491038614042\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01334375337177\n",
      "    mean_inference_ms: 2.8542594922574485\n",
      "    mean_raw_obs_processing_ms: 3.553922633729806\n",
      "  time_since_restore: 92260.14488458633\n",
      "  time_this_iter_s: 164.10934829711914\n",
      "  time_total_s: 92260.14488458633\n",
      "  timers:\n",
      "    learn_throughput: 932.558\n",
      "    learn_time_ms: 10718.9\n",
      "    load_throughput: 90216.7\n",
      "    load_time_ms: 110.8\n",
      "    sample_throughput: 68.577\n",
      "    sample_time_ms: 145763.393\n",
      "    update_time_ms: 11.152\n",
      "  timestamp: 1636386692\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5877648\n",
      "  training_iteration: 588\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   588</td><td style=\"text-align: right;\">         92260.1</td><td style=\"text-align: right;\">5877648</td><td style=\"text-align: right;\"> 4.38352</td><td style=\"text-align: right;\">               18.44</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           92.2593</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5887644\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-54-00\n",
      "  done: false\n",
      "  episode_len_mean: 94.76415094339623\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.379999999999995\n",
      "  episode_reward_mean: 4.299528301886803\n",
      "  episode_reward_min: -1.3100000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 63889\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1708978046718825\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01390035472534917\n",
      "          policy_loss: -0.05904315555961723\n",
      "          total_loss: 0.1286022069792335\n",
      "          vf_explained_var: 0.9323331117630005\n",
      "          vf_loss: 0.17768759459862088\n",
      "    num_agent_steps_sampled: 5887644\n",
      "    num_agent_steps_trained: 5887644\n",
      "    num_steps_sampled: 5887644\n",
      "    num_steps_trained: 5887644\n",
      "  iterations_since_restore: 589\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.41226415094337\n",
      "    ram_util_percent: 57.74669811320754\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556310889541005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.011198099054965\n",
      "    mean_inference_ms: 2.8544656199797225\n",
      "    mean_raw_obs_processing_ms: 3.553972613336832\n",
      "  time_since_restore: 92408.52286100388\n",
      "  time_this_iter_s: 148.3779764175415\n",
      "  time_total_s: 92408.52286100388\n",
      "  timers:\n",
      "    learn_throughput: 932.015\n",
      "    learn_time_ms: 10725.149\n",
      "    load_throughput: 90216.06\n",
      "    load_time_ms: 110.801\n",
      "    sample_throughput: 68.95\n",
      "    sample_time_ms: 144974.986\n",
      "    update_time_ms: 9.973\n",
      "  timestamp: 1636386840\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5887644\n",
      "  training_iteration: 589\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   589</td><td style=\"text-align: right;\">         92408.5</td><td style=\"text-align: right;\">5887644</td><td style=\"text-align: right;\"> 4.29953</td><td style=\"text-align: right;\">               16.38</td><td style=\"text-align: right;\">               -1.31</td><td style=\"text-align: right;\">           94.7642</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5897640\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-56-44\n",
      "  done: false\n",
      "  episode_len_mean: 94.07619047619048\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.240000000000018\n",
      "  episode_reward_mean: 3.932857142857153\n",
      "  episode_reward_min: -1.5100000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 63994\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.161429124408298\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013044921797192256\n",
      "          policy_loss: -0.05960427982270972\n",
      "          total_loss: 0.09470152233719316\n",
      "          vf_explained_var: 0.9346832036972046\n",
      "          vf_loss: 0.1462021298531411\n",
      "    num_agent_steps_sampled: 5897640\n",
      "    num_agent_steps_trained: 5897640\n",
      "    num_steps_sampled: 5897640\n",
      "    num_steps_trained: 5897640\n",
      "  iterations_since_restore: 590\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.45665236051502\n",
      "    ram_util_percent: 57.77596566523606\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553782063675925\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0073094786917\n",
      "    mean_inference_ms: 2.854418628614019\n",
      "    mean_raw_obs_processing_ms: 3.55793967231312\n",
      "  time_since_restore: 92572.32681584358\n",
      "  time_this_iter_s: 163.80395483970642\n",
      "  time_total_s: 92572.32681584358\n",
      "  timers:\n",
      "    learn_throughput: 931.945\n",
      "    learn_time_ms: 10725.958\n",
      "    load_throughput: 90173.644\n",
      "    load_time_ms: 110.853\n",
      "    sample_throughput: 68.495\n",
      "    sample_time_ms: 145937.191\n",
      "    update_time_ms: 10.652\n",
      "  timestamp: 1636387004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5897640\n",
      "  training_iteration: 590\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   590</td><td style=\"text-align: right;\">         92572.3</td><td style=\"text-align: right;\">5897640</td><td style=\"text-align: right;\"> 3.93286</td><td style=\"text-align: right;\">               12.24</td><td style=\"text-align: right;\">               -1.51</td><td style=\"text-align: right;\">           94.0762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5907636\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_15-59-35\n",
      "  done: false\n",
      "  episode_len_mean: 94.40186915887851\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.389999999999954\n",
      "  episode_reward_mean: 4.645420560747674\n",
      "  episode_reward_min: -1.3800000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 64101\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1440144416613456\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013758097355336464\n",
      "          policy_loss: -0.058257630384630624\n",
      "          total_loss: 0.1458266498059289\n",
      "          vf_explained_var: 0.9303377866744995\n",
      "          vf_loss: 0.1941817581701355\n",
      "    num_agent_steps_sampled: 5907636\n",
      "    num_agent_steps_trained: 5907636\n",
      "    num_steps_sampled: 5907636\n",
      "    num_steps_trained: 5907636\n",
      "  iterations_since_restore: 591\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.61639344262295\n",
      "    ram_util_percent: 57.784426229508206\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553803761065171\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00305272371262\n",
      "    mean_inference_ms: 2.854177834826339\n",
      "    mean_raw_obs_processing_ms: 3.5674562220271664\n",
      "  time_since_restore: 92743.14263176918\n",
      "  time_this_iter_s: 170.81581592559814\n",
      "  time_total_s: 92743.14263176918\n",
      "  timers:\n",
      "    learn_throughput: 931.995\n",
      "    learn_time_ms: 10725.383\n",
      "    load_throughput: 90291.929\n",
      "    load_time_ms: 110.708\n",
      "    sample_throughput: 67.136\n",
      "    sample_time_ms: 148891.001\n",
      "    update_time_ms: 11.463\n",
      "  timestamp: 1636387175\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5907636\n",
      "  training_iteration: 591\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   591</td><td style=\"text-align: right;\">         92743.1</td><td style=\"text-align: right;\">5907636</td><td style=\"text-align: right;\"> 4.64542</td><td style=\"text-align: right;\">               16.39</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           94.4019</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5917632\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-02-10\n",
      "  done: false\n",
      "  episode_len_mean: 94.97142857142858\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.11999999999993\n",
      "  episode_reward_mean: 4.503047619047628\n",
      "  episode_reward_min: -1.1900000000000008\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 64206\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.130168798438504\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01339760308818369\n",
      "          policy_loss: -0.05607923977713809\n",
      "          total_loss: 0.13200290953167357\n",
      "          vf_explained_var: 0.9246425628662109\n",
      "          vf_loss: 0.17886242219207124\n",
      "    num_agent_steps_sampled: 5917632\n",
      "    num_agent_steps_trained: 5917632\n",
      "    num_steps_sampled: 5917632\n",
      "    num_steps_trained: 5917632\n",
      "  iterations_since_restore: 592\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.07782805429865\n",
      "    ram_util_percent: 57.87013574660636\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045534824742135306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00121682798819\n",
      "    mean_inference_ms: 2.8543465234218792\n",
      "    mean_raw_obs_processing_ms: 3.565919576247799\n",
      "  time_since_restore: 92898.24928045273\n",
      "  time_this_iter_s: 155.10664868354797\n",
      "  time_total_s: 92898.24928045273\n",
      "  timers:\n",
      "    learn_throughput: 931.858\n",
      "    learn_time_ms: 10726.951\n",
      "    load_throughput: 90202.434\n",
      "    load_time_ms: 110.817\n",
      "    sample_throughput: 67.634\n",
      "    sample_time_ms: 147795.322\n",
      "    update_time_ms: 12.676\n",
      "  timestamp: 1636387330\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5917632\n",
      "  training_iteration: 592\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   592</td><td style=\"text-align: right;\">         92898.2</td><td style=\"text-align: right;\">5917632</td><td style=\"text-align: right;\"> 4.50305</td><td style=\"text-align: right;\">               18.12</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           94.9714</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5927628\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-04-45\n",
      "  done: false\n",
      "  episode_len_mean: 94.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.940000000000014\n",
      "  episode_reward_mean: 3.780000000000009\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 64312\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.150738593655774\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013227631653614494\n",
      "          policy_loss: -0.06098084485747366\n",
      "          total_loss: 0.11883582885130349\n",
      "          vf_explained_var: 0.9121790528297424\n",
      "          vf_loss: 0.17118985978170084\n",
      "    num_agent_steps_sampled: 5927628\n",
      "    num_agent_steps_trained: 5927628\n",
      "    num_steps_sampled: 5927628\n",
      "    num_steps_trained: 5927628\n",
      "  iterations_since_restore: 593\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.46936936936936\n",
      "    ram_util_percent: 57.8572072072072\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045522793916041686\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00184601119842\n",
      "    mean_inference_ms: 2.8544196334871472\n",
      "    mean_raw_obs_processing_ms: 3.5637725870204062\n",
      "  time_since_restore: 93053.31329727173\n",
      "  time_this_iter_s: 155.06401681900024\n",
      "  time_total_s: 93053.31329727173\n",
      "  timers:\n",
      "    learn_throughput: 931.819\n",
      "    learn_time_ms: 10727.406\n",
      "    load_throughput: 90247.286\n",
      "    load_time_ms: 110.762\n",
      "    sample_throughput: 68.666\n",
      "    sample_time_ms: 145573.375\n",
      "    update_time_ms: 12.5\n",
      "  timestamp: 1636387485\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5927628\n",
      "  training_iteration: 593\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   593</td><td style=\"text-align: right;\">         93053.3</td><td style=\"text-align: right;\">5927628</td><td style=\"text-align: right;\">    3.78</td><td style=\"text-align: right;\">               10.94</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">              94.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5937624\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-07-01\n",
      "  done: false\n",
      "  episode_len_mean: 96.15384615384616\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.910000000000021\n",
      "  episode_reward_mean: 4.121346153846165\n",
      "  episode_reward_min: -1.9600000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 64416\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1234185085337387\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013588477816308597\n",
      "          policy_loss: -0.05855492487963703\n",
      "          total_loss: 0.13206734011889013\n",
      "          vf_explained_var: 0.9326071739196777\n",
      "          vf_loss: 0.18090019777226143\n",
      "    num_agent_steps_sampled: 5937624\n",
      "    num_agent_steps_trained: 5937624\n",
      "    num_steps_sampled: 5937624\n",
      "    num_steps_trained: 5937624\n",
      "  iterations_since_restore: 594\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11443298969073\n",
      "    ram_util_percent: 57.69329896907217\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556655540320757\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00452589731797\n",
      "    mean_inference_ms: 2.854426011304272\n",
      "    mean_raw_obs_processing_ms: 3.5596433962728984\n",
      "  time_since_restore: 93189.47617173195\n",
      "  time_this_iter_s: 136.16287446022034\n",
      "  time_total_s: 93189.47617173195\n",
      "  timers:\n",
      "    learn_throughput: 931.768\n",
      "    learn_time_ms: 10727.994\n",
      "    load_throughput: 90128.245\n",
      "    load_time_ms: 110.909\n",
      "    sample_throughput: 69.983\n",
      "    sample_time_ms: 142834.475\n",
      "    update_time_ms: 12.809\n",
      "  timestamp: 1636387621\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5937624\n",
      "  training_iteration: 594\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   594</td><td style=\"text-align: right;\">         93189.5</td><td style=\"text-align: right;\">5937624</td><td style=\"text-align: right;\"> 4.12135</td><td style=\"text-align: right;\">               13.91</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">           96.1538</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5947620\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-09-45\n",
      "  done: false\n",
      "  episode_len_mean: 92.42990654205607\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.680000000000007\n",
      "  episode_reward_mean: 4.141121495327113\n",
      "  episode_reward_min: -1.1800000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 64523\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1268386359907625\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013582260174002402\n",
      "          policy_loss: -0.058077648553487835\n",
      "          total_loss: 0.13345923917288455\n",
      "          vf_explained_var: 0.9291658401489258\n",
      "          vf_loss: 0.181863186818858\n",
      "    num_agent_steps_sampled: 5947620\n",
      "    num_agent_steps_trained: 5947620\n",
      "    num_steps_sampled: 5947620\n",
      "    num_steps_trained: 5947620\n",
      "  iterations_since_restore: 595\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.59141630901287\n",
      "    ram_util_percent: 57.624892703862656\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455274672036378\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.000317751330904\n",
      "    mean_inference_ms: 2.8543583496925105\n",
      "    mean_raw_obs_processing_ms: 3.563228979253554\n",
      "  time_since_restore: 93352.54662251472\n",
      "  time_this_iter_s: 163.07045078277588\n",
      "  time_total_s: 93352.54662251472\n",
      "  timers:\n",
      "    learn_throughput: 932.479\n",
      "    learn_time_ms: 10719.813\n",
      "    load_throughput: 90137.333\n",
      "    load_time_ms: 110.897\n",
      "    sample_throughput: 69.643\n",
      "    sample_time_ms: 143531.592\n",
      "    update_time_ms: 13.004\n",
      "  timestamp: 1636387785\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5947620\n",
      "  training_iteration: 595\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   595</td><td style=\"text-align: right;\">         93352.5</td><td style=\"text-align: right;\">5947620</td><td style=\"text-align: right;\"> 4.14112</td><td style=\"text-align: right;\">               18.68</td><td style=\"text-align: right;\">               -1.18</td><td style=\"text-align: right;\">           92.4299</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5957616\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-12-28\n",
      "  done: false\n",
      "  episode_len_mean: 95.02830188679245\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.830000000000013\n",
      "  episode_reward_mean: 3.833962264150953\n",
      "  episode_reward_min: -1.0900000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 64629\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1669265762353556\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012891657054149049\n",
      "          policy_loss: -0.06105582023787702\n",
      "          total_loss: 0.10757751285186053\n",
      "          vf_explained_var: 0.9119713306427002\n",
      "          vf_loss: 0.16093379092426635\n",
      "    num_agent_steps_sampled: 5957616\n",
      "    num_agent_steps_trained: 5957616\n",
      "    num_steps_sampled: 5957616\n",
      "    num_steps_trained: 5957616\n",
      "  iterations_since_restore: 596\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.3175965665236\n",
      "    ram_util_percent: 57.776824034334766\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045550813039585164\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99812947390799\n",
      "    mean_inference_ms: 2.854236721202338\n",
      "    mean_raw_obs_processing_ms: 3.5709431084476524\n",
      "  time_since_restore: 93515.69570469856\n",
      "  time_this_iter_s: 163.1490821838379\n",
      "  time_total_s: 93515.69570469856\n",
      "  timers:\n",
      "    learn_throughput: 932.714\n",
      "    learn_time_ms: 10717.113\n",
      "    load_throughput: 91934.244\n",
      "    load_time_ms: 108.73\n",
      "    sample_throughput: 68.566\n",
      "    sample_time_ms: 145785.851\n",
      "    update_time_ms: 13.015\n",
      "  timestamp: 1636387948\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5957616\n",
      "  training_iteration: 596\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   596</td><td style=\"text-align: right;\">         93515.7</td><td style=\"text-align: right;\">5957616</td><td style=\"text-align: right;\"> 3.83396</td><td style=\"text-align: right;\">               10.83</td><td style=\"text-align: right;\">               -1.09</td><td style=\"text-align: right;\">           95.0283</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5967612\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-15-01\n",
      "  done: false\n",
      "  episode_len_mean: 96.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.280000000000005\n",
      "  episode_reward_mean: 3.7023076923077025\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 64733\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1401639098795053\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013463769548662631\n",
      "          policy_loss: -0.056806754445832254\n",
      "          total_loss: 0.12019490659650829\n",
      "          vf_explained_var: 0.9250617623329163\n",
      "          vf_loss: 0.1677311497939448\n",
      "    num_agent_steps_sampled: 5967612\n",
      "    num_agent_steps_trained: 5967612\n",
      "    num_steps_sampled: 5967612\n",
      "    num_steps_trained: 5967612\n",
      "  iterations_since_restore: 597\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.99862385321101\n",
      "    ram_util_percent: 57.84128440366973\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557209946057345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.998787257300776\n",
      "    mean_inference_ms: 2.8544878764211767\n",
      "    mean_raw_obs_processing_ms: 3.5683361715459787\n",
      "  time_since_restore: 93668.9812746048\n",
      "  time_this_iter_s: 153.28556990623474\n",
      "  time_total_s: 93668.9812746048\n",
      "  timers:\n",
      "    learn_throughput: 932.603\n",
      "    learn_time_ms: 10718.383\n",
      "    load_throughput: 91927.774\n",
      "    load_time_ms: 108.738\n",
      "    sample_throughput: 68.259\n",
      "    sample_time_ms: 146441.578\n",
      "    update_time_ms: 12.923\n",
      "  timestamp: 1636388101\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5967612\n",
      "  training_iteration: 597\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   597</td><td style=\"text-align: right;\">           93669</td><td style=\"text-align: right;\">5967612</td><td style=\"text-align: right;\"> 3.70231</td><td style=\"text-align: right;\">               16.28</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">                96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5977608\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-17-18\n",
      "  done: false\n",
      "  episode_len_mean: 97.84313725490196\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.920000000000016\n",
      "  episode_reward_mean: 4.048921568627462\n",
      "  episode_reward_min: -1.0000000000000007\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 64835\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.151366860132951\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012954233246761775\n",
      "          policy_loss: -0.05918484636797355\n",
      "          total_loss: 0.11483853229631981\n",
      "          vf_explained_var: 0.9263361096382141\n",
      "          vf_loss: 0.16602568375344715\n",
      "    num_agent_steps_sampled: 5977608\n",
      "    num_agent_steps_trained: 5977608\n",
      "    num_steps_sampled: 5977608\n",
      "    num_steps_trained: 5977608\n",
      "  iterations_since_restore: 598\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.81025641025641\n",
      "    ram_util_percent: 57.855897435897454\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555154421778505\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99883979152022\n",
      "    mean_inference_ms: 2.854356276297476\n",
      "    mean_raw_obs_processing_ms: 3.5639183281190587\n",
      "  time_since_restore: 93805.3966293335\n",
      "  time_this_iter_s: 136.41535472869873\n",
      "  time_total_s: 93805.3966293335\n",
      "  timers:\n",
      "    learn_throughput: 932.528\n",
      "    learn_time_ms: 10719.253\n",
      "    load_throughput: 91411.009\n",
      "    load_time_ms: 109.352\n",
      "    sample_throughput: 69.576\n",
      "    sample_time_ms: 143670.466\n",
      "    update_time_ms: 13.11\n",
      "  timestamp: 1636388238\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5977608\n",
      "  training_iteration: 598\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   598</td><td style=\"text-align: right;\">         93805.4</td><td style=\"text-align: right;\">5977608</td><td style=\"text-align: right;\"> 4.04892</td><td style=\"text-align: right;\">               12.92</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">           97.8431</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5987604\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-19-47\n",
      "  done: false\n",
      "  episode_len_mean: 96.48076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.800000000000008\n",
      "  episode_reward_mean: 4.1527884615384725\n",
      "  episode_reward_min: -1.5000000000000013\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 64939\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1101163412770654\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013229292464051131\n",
      "          policy_loss: -0.055623831728903145\n",
      "          total_loss: 0.13284822104450983\n",
      "          vf_explained_var: 0.9338278770446777\n",
      "          vf_loss: 0.17943523382592916\n",
      "    num_agent_steps_sampled: 5987604\n",
      "    num_agent_steps_trained: 5987604\n",
      "    num_steps_sampled: 5987604\n",
      "    num_steps_trained: 5987604\n",
      "  iterations_since_restore: 599\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.56572769953051\n",
      "    ram_util_percent: 57.77840375586856\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045521081709279494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99582104363656\n",
      "    mean_inference_ms: 2.8545636645787096\n",
      "    mean_raw_obs_processing_ms: 3.560721801673268\n",
      "  time_since_restore: 93954.57826209068\n",
      "  time_this_iter_s: 149.1816327571869\n",
      "  time_total_s: 93954.57826209068\n",
      "  timers:\n",
      "    learn_throughput: 932.719\n",
      "    learn_time_ms: 10717.057\n",
      "    load_throughput: 91520.317\n",
      "    load_time_ms: 109.222\n",
      "    sample_throughput: 69.536\n",
      "    sample_time_ms: 143753.29\n",
      "    update_time_ms: 13.025\n",
      "  timestamp: 1636388387\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5987604\n",
      "  training_iteration: 599\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   599</td><td style=\"text-align: right;\">         93954.6</td><td style=\"text-align: right;\">5987604</td><td style=\"text-align: right;\"> 4.15279</td><td style=\"text-align: right;\">                16.8</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           96.4808</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 5997600\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-22-40\n",
      "  done: false\n",
      "  episode_len_mean: 92.55045871559633\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.360000000000019\n",
      "  episode_reward_mean: 3.7272477064220277\n",
      "  episode_reward_min: -2.229999999999999\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 65048\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.117859230795477\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012295408742214842\n",
      "          policy_loss: -0.059410868385313155\n",
      "          total_loss: 0.1088710914652508\n",
      "          vf_explained_var: 0.9214643239974976\n",
      "          vf_loss: 0.16145007294626573\n",
      "    num_agent_steps_sampled: 5997600\n",
      "    num_agent_steps_trained: 5997600\n",
      "    num_steps_sampled: 5997600\n",
      "    num_steps_trained: 5997600\n",
      "  iterations_since_restore: 600\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.63765182186235\n",
      "    ram_util_percent: 57.71781376518218\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557173364337941\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99615704903276\n",
      "    mean_inference_ms: 2.8542506359869315\n",
      "    mean_raw_obs_processing_ms: 3.5682217312088547\n",
      "  time_since_restore: 94127.62499117851\n",
      "  time_this_iter_s: 173.0467290878296\n",
      "  time_total_s: 94127.62499117851\n",
      "  timers:\n",
      "    learn_throughput: 933.137\n",
      "    learn_time_ms: 10712.256\n",
      "    load_throughput: 91540.659\n",
      "    load_time_ms: 109.197\n",
      "    sample_throughput: 69.089\n",
      "    sample_time_ms: 144683.071\n",
      "    update_time_ms: 11.983\n",
      "  timestamp: 1636388560\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5997600\n",
      "  training_iteration: 600\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   600</td><td style=\"text-align: right;\">         94127.6</td><td style=\"text-align: right;\">5997600</td><td style=\"text-align: right;\"> 3.72725</td><td style=\"text-align: right;\">               14.36</td><td style=\"text-align: right;\">               -2.23</td><td style=\"text-align: right;\">           92.5505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6007596\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-25-18\n",
      "  done: false\n",
      "  episode_len_mean: 95.36538461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.40999999999997\n",
      "  episode_reward_mean: 4.263653846153856\n",
      "  episode_reward_min: -1.2400000000000002\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 65152\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.093578578468062\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013538664759100807\n",
      "          policy_loss: -0.05654829387736117\n",
      "          total_loss: 0.12993837884571563\n",
      "          vf_explained_var: 0.925896406173706\n",
      "          vf_loss: 0.17657968611735056\n",
      "    num_agent_steps_sampled: 6007596\n",
      "    num_agent_steps_trained: 6007596\n",
      "    num_steps_sampled: 6007596\n",
      "    num_steps_trained: 6007596\n",
      "  iterations_since_restore: 601\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.86844444444445\n",
      "    ram_util_percent: 57.68711111111111\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555171680602568\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99728913323527\n",
      "    mean_inference_ms: 2.8540708356578155\n",
      "    mean_raw_obs_processing_ms: 3.5669726435520923\n",
      "  time_since_restore: 94285.41709709167\n",
      "  time_this_iter_s: 157.79210591316223\n",
      "  time_total_s: 94285.41709709167\n",
      "  timers:\n",
      "    learn_throughput: 933.3\n",
      "    learn_time_ms: 10710.382\n",
      "    load_throughput: 91362.127\n",
      "    load_time_ms: 109.411\n",
      "    sample_throughput: 69.716\n",
      "    sample_time_ms: 143382.41\n",
      "    update_time_ms: 12.031\n",
      "  timestamp: 1636388718\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6007596\n",
      "  training_iteration: 601\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   601</td><td style=\"text-align: right;\">         94285.4</td><td style=\"text-align: right;\">6007596</td><td style=\"text-align: right;\"> 4.26365</td><td style=\"text-align: right;\">               16.41</td><td style=\"text-align: right;\">               -1.24</td><td style=\"text-align: right;\">           95.3654</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6017592\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-27-53\n",
      "  done: false\n",
      "  episode_len_mean: 96.625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.100000000000014\n",
      "  episode_reward_mean: 4.438942307692319\n",
      "  episode_reward_min: -1.8100000000000012\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 65256\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.134808207882775\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013567326058598542\n",
      "          policy_loss: -0.05793546962305012\n",
      "          total_loss: 0.14122960823707473\n",
      "          vf_explained_var: 0.9290462732315063\n",
      "          vf_loss: 0.18960509311057563\n",
      "    num_agent_steps_sampled: 6017592\n",
      "    num_agent_steps_trained: 6017592\n",
      "    num_steps_sampled: 6017592\n",
      "    num_steps_trained: 6017592\n",
      "  iterations_since_restore: 602\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.74864864864865\n",
      "    ram_util_percent: 57.66576576576577\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553668478396641\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99460116065159\n",
      "    mean_inference_ms: 2.854120990489582\n",
      "    mean_raw_obs_processing_ms: 3.5659059221598346\n",
      "  time_since_restore: 94440.97145748138\n",
      "  time_this_iter_s: 155.55436038970947\n",
      "  time_total_s: 94440.97145748138\n",
      "  timers:\n",
      "    learn_throughput: 933.7\n",
      "    learn_time_ms: 10705.792\n",
      "    load_throughput: 91576.87\n",
      "    load_time_ms: 109.154\n",
      "    sample_throughput: 69.691\n",
      "    sample_time_ms: 143432.876\n",
      "    update_time_ms: 10.961\n",
      "  timestamp: 1636388873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6017592\n",
      "  training_iteration: 602\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   602</td><td style=\"text-align: right;\">           94441</td><td style=\"text-align: right;\">6017592</td><td style=\"text-align: right;\"> 4.43894</td><td style=\"text-align: right;\">                13.1</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">            96.625</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6027588\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-30-22\n",
      "  done: false\n",
      "  episode_len_mean: 95.26666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.320000000000016\n",
      "  episode_reward_mean: 4.1758095238095345\n",
      "  episode_reward_min: -1.1400000000000003\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 65361\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0967081141268085\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014061174528990436\n",
      "          policy_loss: -0.05650557609450104\n",
      "          total_loss: 0.1549942787290893\n",
      "          vf_explained_var: 0.9187370538711548\n",
      "          vf_loss: 0.20043382317337216\n",
      "    num_agent_steps_sampled: 6027588\n",
      "    num_agent_steps_trained: 6027588\n",
      "    num_steps_sampled: 6027588\n",
      "    num_steps_trained: 6027588\n",
      "  iterations_since_restore: 603\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78962264150944\n",
      "    ram_util_percent: 57.61509433962264\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045540388865742354\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.9943275972442\n",
      "    mean_inference_ms: 2.854068302507983\n",
      "    mean_raw_obs_processing_ms: 3.5645981187307325\n",
      "  time_since_restore: 94589.58186531067\n",
      "  time_this_iter_s: 148.61040782928467\n",
      "  time_total_s: 94589.58186531067\n",
      "  timers:\n",
      "    learn_throughput: 934.304\n",
      "    learn_time_ms: 10698.871\n",
      "    load_throughput: 91527.45\n",
      "    load_time_ms: 109.213\n",
      "    sample_throughput: 70.003\n",
      "    sample_time_ms: 142793.731\n",
      "    update_time_ms: 11.732\n",
      "  timestamp: 1636389022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6027588\n",
      "  training_iteration: 603\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   603</td><td style=\"text-align: right;\">         94589.6</td><td style=\"text-align: right;\">6027588</td><td style=\"text-align: right;\"> 4.17581</td><td style=\"text-align: right;\">               14.32</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           95.2667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6037584\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-32-58\n",
      "  done: false\n",
      "  episode_len_mean: 92.3177570093458\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.36000000000001\n",
      "  episode_reward_mean: 4.167289719626178\n",
      "  episode_reward_min: -0.9700000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 65468\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1071212492437446\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013369670695793692\n",
      "          policy_loss: -0.05846573930774999\n",
      "          total_loss: 0.15065426809442603\n",
      "          vf_explained_var: 0.9226050972938538\n",
      "          vf_loss: 0.19973343782381625\n",
      "    num_agent_steps_sampled: 6037584\n",
      "    num_agent_steps_trained: 6037584\n",
      "    num_steps_sampled: 6037584\n",
      "    num_steps_trained: 6037584\n",
      "  iterations_since_restore: 604\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.77354260089686\n",
      "    ram_util_percent: 57.73632286995516\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554857396934065\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.995265241045125\n",
      "    mean_inference_ms: 2.8542814346416985\n",
      "    mean_raw_obs_processing_ms: 3.5642296569719476\n",
      "  time_since_restore: 94745.68993496895\n",
      "  time_this_iter_s: 156.10806965827942\n",
      "  time_total_s: 94745.68993496895\n",
      "  timers:\n",
      "    learn_throughput: 934.452\n",
      "    learn_time_ms: 10697.183\n",
      "    load_throughput: 91626.563\n",
      "    load_time_ms: 109.095\n",
      "    sample_throughput: 69.038\n",
      "    sample_time_ms: 144789.182\n",
      "    update_time_ms: 12.484\n",
      "  timestamp: 1636389178\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6037584\n",
      "  training_iteration: 604\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   604</td><td style=\"text-align: right;\">         94745.7</td><td style=\"text-align: right;\">6037584</td><td style=\"text-align: right;\"> 4.16729</td><td style=\"text-align: right;\">               16.36</td><td style=\"text-align: right;\">               -0.97</td><td style=\"text-align: right;\">           92.3178</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6047580\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-35-50\n",
      "  done: false\n",
      "  episode_len_mean: 91.21621621621621\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.639999999999976\n",
      "  episode_reward_mean: 4.434414414414424\n",
      "  episode_reward_min: -1.6900000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 65579\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0822798090103345\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015528589776854167\n",
      "          policy_loss: -0.051732172368046565\n",
      "          total_loss: 0.20033554388050978\n",
      "          vf_explained_var: 0.9221460819244385\n",
      "          vf_loss: 0.23751444423364268\n",
      "    num_agent_steps_sampled: 6047580\n",
      "    num_agent_steps_trained: 6047580\n",
      "    num_steps_sampled: 6047580\n",
      "    num_steps_trained: 6047580\n",
      "  iterations_since_restore: 605\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.68775510204081\n",
      "    ram_util_percent: 57.8595918367347\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045541841308130805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.992679797187236\n",
      "    mean_inference_ms: 2.8539819168753646\n",
      "    mean_raw_obs_processing_ms: 3.571642125115636\n",
      "  time_since_restore: 94917.22207069397\n",
      "  time_this_iter_s: 171.53213572502136\n",
      "  time_total_s: 94917.22207069397\n",
      "  timers:\n",
      "    learn_throughput: 934.072\n",
      "    learn_time_ms: 10701.535\n",
      "    load_throughput: 91653.023\n",
      "    load_time_ms: 109.064\n",
      "    sample_throughput: 68.639\n",
      "    sample_time_ms: 145631.31\n",
      "    update_time_ms: 11.816\n",
      "  timestamp: 1636389350\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6047580\n",
      "  training_iteration: 605\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   605</td><td style=\"text-align: right;\">         94917.2</td><td style=\"text-align: right;\">6047580</td><td style=\"text-align: right;\"> 4.43441</td><td style=\"text-align: right;\">               16.64</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           91.2162</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6057576\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-38-48\n",
      "  done: false\n",
      "  episode_len_mean: 94.14150943396227\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.539999999999978\n",
      "  episode_reward_mean: 4.543679245283029\n",
      "  episode_reward_min: -0.8900000000000006\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 65685\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1024950867025263\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012433871149733405\n",
      "          policy_loss: -0.05750427319485153\n",
      "          total_loss: 0.13576658898884925\n",
      "          vf_explained_var: 0.9236668348312378\n",
      "          vf_loss: 0.18596989940692726\n",
      "    num_agent_steps_sampled: 6057576\n",
      "    num_agent_steps_trained: 6057576\n",
      "    num_steps_sampled: 6057576\n",
      "    num_steps_trained: 6057576\n",
      "  iterations_since_restore: 606\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.04133858267717\n",
      "    ram_util_percent: 57.79133858267716\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557463530265296\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99144189109529\n",
      "    mean_inference_ms: 2.854076928223237\n",
      "    mean_raw_obs_processing_ms: 3.5789275866619263\n",
      "  time_since_restore: 95095.55209159851\n",
      "  time_this_iter_s: 178.33002090454102\n",
      "  time_total_s: 95095.55209159851\n",
      "  timers:\n",
      "    learn_throughput: 934.182\n",
      "    learn_time_ms: 10700.274\n",
      "    load_throughput: 91566.75\n",
      "    load_time_ms: 109.166\n",
      "    sample_throughput: 67.931\n",
      "    sample_time_ms: 147149.441\n",
      "    update_time_ms: 12.19\n",
      "  timestamp: 1636389528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6057576\n",
      "  training_iteration: 606\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   606</td><td style=\"text-align: right;\">         95095.6</td><td style=\"text-align: right;\">6057576</td><td style=\"text-align: right;\"> 4.54368</td><td style=\"text-align: right;\">               22.54</td><td style=\"text-align: right;\">               -0.89</td><td style=\"text-align: right;\">           94.1415</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6067572\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-41-54\n",
      "  done: false\n",
      "  episode_len_mean: 92.61682242990655\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.820000000000002\n",
      "  episode_reward_mean: 4.4189719626168324\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 65792\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1156532370127166\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013828350586568904\n",
      "          policy_loss: -0.05493472648354677\n",
      "          total_loss: 0.14536073698988583\n",
      "          vf_explained_var: 0.9321929812431335\n",
      "          vf_loss: 0.18994928425830654\n",
      "    num_agent_steps_sampled: 6067572\n",
      "    num_agent_steps_trained: 6067572\n",
      "    num_steps_sampled: 6067572\n",
      "    num_steps_trained: 6067572\n",
      "  iterations_since_restore: 607\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00377358490566\n",
      "    ram_util_percent: 57.91056603773586\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045546488404435696\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.990082589336296\n",
      "    mean_inference_ms: 2.854135200813976\n",
      "    mean_raw_obs_processing_ms: 3.5819329177640604\n",
      "  time_since_restore: 95280.99837327003\n",
      "  time_this_iter_s: 185.44628167152405\n",
      "  time_total_s: 95280.99837327003\n",
      "  timers:\n",
      "    learn_throughput: 933.923\n",
      "    learn_time_ms: 10703.241\n",
      "    load_throughput: 91342.302\n",
      "    load_time_ms: 109.435\n",
      "    sample_throughput: 66.48\n",
      "    sample_time_ms: 150362.041\n",
      "    update_time_ms: 12.178\n",
      "  timestamp: 1636389714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6067572\n",
      "  training_iteration: 607\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   607</td><td style=\"text-align: right;\">           95281</td><td style=\"text-align: right;\">6067572</td><td style=\"text-align: right;\"> 4.41897</td><td style=\"text-align: right;\">               15.82</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           92.6168</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6077568\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-44-31\n",
      "  done: false\n",
      "  episode_len_mean: 92.06481481481481\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.16999999999995\n",
      "  episode_reward_mean: 3.904629629629639\n",
      "  episode_reward_min: -1.7000000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 65900\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1009035646405994\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013514540853004834\n",
      "          policy_loss: -0.05127679873417076\n",
      "          total_loss: 0.1417413914703533\n",
      "          vf_explained_var: 0.9280036687850952\n",
      "          vf_loss: 0.18323941202117847\n",
      "    num_agent_steps_sampled: 6077568\n",
      "    num_agent_steps_trained: 6077568\n",
      "    num_steps_sampled: 6077568\n",
      "    num_steps_trained: 6077568\n",
      "  iterations_since_restore: 608\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.54285714285713\n",
      "    ram_util_percent: 57.88392857142858\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556299841503671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99394858838831\n",
      "    mean_inference_ms: 2.8539832489665624\n",
      "    mean_raw_obs_processing_ms: 3.581201750849542\n",
      "  time_since_restore: 95437.98555922508\n",
      "  time_this_iter_s: 156.9871859550476\n",
      "  time_total_s: 95437.98555922508\n",
      "  timers:\n",
      "    learn_throughput: 933.875\n",
      "    learn_time_ms: 10703.786\n",
      "    load_throughput: 91694.716\n",
      "    load_time_ms: 109.014\n",
      "    sample_throughput: 65.582\n",
      "    sample_time_ms: 152419.061\n",
      "    update_time_ms: 12.395\n",
      "  timestamp: 1636389871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6077568\n",
      "  training_iteration: 608\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   608</td><td style=\"text-align: right;\">           95438</td><td style=\"text-align: right;\">6077568</td><td style=\"text-align: right;\"> 3.90463</td><td style=\"text-align: right;\">               18.17</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           92.0648</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6087564\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-47-03\n",
      "  done: false\n",
      "  episode_len_mean: 93.61682242990655\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.850000000000021\n",
      "  episode_reward_mean: 3.9930841121495426\n",
      "  episode_reward_min: -1.4900000000000004\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 66007\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1136604143004134\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012981545013456995\n",
      "          policy_loss: -0.05548564346395751\n",
      "          total_loss: 0.11695129473128507\n",
      "          vf_explained_var: 0.9358007311820984\n",
      "          vf_loss: 0.16399995928837194\n",
      "    num_agent_steps_sampled: 6087564\n",
      "    num_agent_steps_trained: 6087564\n",
      "    num_steps_sampled: 6087564\n",
      "    num_steps_trained: 6087564\n",
      "  iterations_since_restore: 609\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.80506912442395\n",
      "    ram_util_percent: 57.798617511520746\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045552747279853596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99508121210445\n",
      "    mean_inference_ms: 2.8539125826428355\n",
      "    mean_raw_obs_processing_ms: 3.5796636333410117\n",
      "  time_since_restore: 95590.56022715569\n",
      "  time_this_iter_s: 152.57466793060303\n",
      "  time_total_s: 95590.56022715569\n",
      "  timers:\n",
      "    learn_throughput: 933.995\n",
      "    learn_time_ms: 10702.413\n",
      "    load_throughput: 91778.378\n",
      "    load_time_ms: 108.915\n",
      "    sample_throughput: 65.437\n",
      "    sample_time_ms: 152758.588\n",
      "    update_time_ms: 13.569\n",
      "  timestamp: 1636390023\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6087564\n",
      "  training_iteration: 609\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   609</td><td style=\"text-align: right;\">         95590.6</td><td style=\"text-align: right;\">6087564</td><td style=\"text-align: right;\"> 3.99308</td><td style=\"text-align: right;\">               11.85</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">           93.6168</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6097560\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-49-52\n",
      "  done: false\n",
      "  episode_len_mean: 96.4095238095238\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.910000000000016\n",
      "  episode_reward_mean: 3.6632380952381047\n",
      "  episode_reward_min: -1.7300000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 66112\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1318097994877743\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01303435134609167\n",
      "          policy_loss: -0.05833752757240819\n",
      "          total_loss: 0.1239823107002701\n",
      "          vf_explained_var: 0.9184681177139282\n",
      "          vf_loss: 0.17394405394856238\n",
      "    num_agent_steps_sampled: 6097560\n",
      "    num_agent_steps_trained: 6097560\n",
      "    num_steps_sampled: 6097560\n",
      "    num_steps_trained: 6097560\n",
      "  iterations_since_restore: 610\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.05826446280992\n",
      "    ram_util_percent: 57.84834710743802\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045495833846177926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98879416808777\n",
      "    mean_inference_ms: 2.8540926864002887\n",
      "    mean_raw_obs_processing_ms: 3.579319390087338\n",
      "  time_since_restore: 95759.5108551979\n",
      "  time_this_iter_s: 168.95062804222107\n",
      "  time_total_s: 95759.5108551979\n",
      "  timers:\n",
      "    learn_throughput: 934.185\n",
      "    learn_time_ms: 10700.234\n",
      "    load_throughput: 91888.144\n",
      "    load_time_ms: 108.784\n",
      "    sample_throughput: 65.611\n",
      "    sample_time_ms: 152351.997\n",
      "    update_time_ms: 12.93\n",
      "  timestamp: 1636390192\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6097560\n",
      "  training_iteration: 610\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   610</td><td style=\"text-align: right;\">         95759.5</td><td style=\"text-align: right;\">6097560</td><td style=\"text-align: right;\"> 3.66324</td><td style=\"text-align: right;\">               10.91</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           96.4095</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6107556\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-52-55\n",
      "  done: false\n",
      "  episode_len_mean: 94.67619047619047\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.609999999999985\n",
      "  episode_reward_mean: 4.09742857142858\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 66217\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1394429372926043\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01354917852273248\n",
      "          policy_loss: -0.05569731776053325\n",
      "          total_loss: 0.15396437496344886\n",
      "          vf_explained_var: 0.9152456521987915\n",
      "          vf_loss: 0.20018939829598634\n",
      "    num_agent_steps_sampled: 6107556\n",
      "    num_agent_steps_trained: 6107556\n",
      "    num_steps_sampled: 6107556\n",
      "    num_steps_trained: 6107556\n",
      "  iterations_since_restore: 611\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.8544061302682\n",
      "    ram_util_percent: 57.75363984674329\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552272842452023\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.988077638479346\n",
      "    mean_inference_ms: 2.853846791145556\n",
      "    mean_raw_obs_processing_ms: 3.591980448738181\n",
      "  time_since_restore: 95942.47302603722\n",
      "  time_this_iter_s: 182.9621708393097\n",
      "  time_total_s: 95942.47302603722\n",
      "  timers:\n",
      "    learn_throughput: 934.069\n",
      "    learn_time_ms: 10701.569\n",
      "    load_throughput: 91919.249\n",
      "    load_time_ms: 108.748\n",
      "    sample_throughput: 64.546\n",
      "    sample_time_ms: 154867.094\n",
      "    update_time_ms: 13.393\n",
      "  timestamp: 1636390375\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6107556\n",
      "  training_iteration: 611\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   611</td><td style=\"text-align: right;\">         95942.5</td><td style=\"text-align: right;\">6107556</td><td style=\"text-align: right;\"> 4.09743</td><td style=\"text-align: right;\">               18.61</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           94.6762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6117552\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-55-49\n",
      "  done: false\n",
      "  episode_len_mean: 97.13592233009709\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.410000000000023\n",
      "  episode_reward_mean: 3.984271844660205\n",
      "  episode_reward_min: -1.590000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 66320\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.141811663370866\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011737417124215005\n",
      "          policy_loss: -0.058952699986915304\n",
      "          total_loss: 0.10028115069955333\n",
      "          vf_explained_var: 0.9161065816879272\n",
      "          vf_loss: 0.15391266309520882\n",
      "    num_agent_steps_sampled: 6117552\n",
      "    num_agent_steps_trained: 6117552\n",
      "    num_steps_sampled: 6117552\n",
      "    num_steps_trained: 6117552\n",
      "  iterations_since_restore: 612\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.21209677419354\n",
      "    ram_util_percent: 57.84596774193549\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455390094888411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98552554046485\n",
      "    mean_inference_ms: 2.8536006842450896\n",
      "    mean_raw_obs_processing_ms: 3.597042741536737\n",
      "  time_since_restore: 96116.2186024189\n",
      "  time_this_iter_s: 173.74557638168335\n",
      "  time_total_s: 96116.2186024189\n",
      "  timers:\n",
      "    learn_throughput: 933.859\n",
      "    learn_time_ms: 10703.976\n",
      "    load_throughput: 91820.185\n",
      "    load_time_ms: 108.865\n",
      "    sample_throughput: 63.797\n",
      "    sample_time_ms: 156683.651\n",
      "    update_time_ms: 13.183\n",
      "  timestamp: 1636390549\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6117552\n",
      "  training_iteration: 612\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   612</td><td style=\"text-align: right;\">         96116.2</td><td style=\"text-align: right;\">6117552</td><td style=\"text-align: right;\"> 3.98427</td><td style=\"text-align: right;\">               11.41</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           97.1359</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6127548\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_16-58-22\n",
      "  done: false\n",
      "  episode_len_mean: 95.125\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.57999999999992\n",
      "  episode_reward_mean: 3.7516346153846243\n",
      "  episode_reward_min: -2.0700000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 66424\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.120319952414586\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012886219191915483\n",
      "          policy_loss: -0.05925345919612381\n",
      "          total_loss: 0.13729405915563625\n",
      "          vf_explained_var: 0.9189614057540894\n",
      "          vf_loss: 0.18839429812267042\n",
      "    num_agent_steps_sampled: 6127548\n",
      "    num_agent_steps_trained: 6127548\n",
      "    num_steps_sampled: 6127548\n",
      "    num_steps_trained: 6127548\n",
      "  iterations_since_restore: 613\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.36422018348624\n",
      "    ram_util_percent: 57.82064220183487\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045529509021229986\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98478842422987\n",
      "    mean_inference_ms: 2.854019785650375\n",
      "    mean_raw_obs_processing_ms: 3.5914467316316676\n",
      "  time_since_restore: 96268.88971281052\n",
      "  time_this_iter_s: 152.67111039161682\n",
      "  time_total_s: 96268.88971281052\n",
      "  timers:\n",
      "    learn_throughput: 933.713\n",
      "    learn_time_ms: 10705.648\n",
      "    load_throughput: 91797.528\n",
      "    load_time_ms: 108.892\n",
      "    sample_throughput: 63.633\n",
      "    sample_time_ms: 157089.019\n",
      "    update_time_ms: 12.276\n",
      "  timestamp: 1636390702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6127548\n",
      "  training_iteration: 613\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   613</td><td style=\"text-align: right;\">         96268.9</td><td style=\"text-align: right;\">6127548</td><td style=\"text-align: right;\"> 3.75163</td><td style=\"text-align: right;\">               18.58</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">            95.125</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6137544\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-01-08\n",
      "  done: false\n",
      "  episode_len_mean: 95.15094339622641\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.280000000000019\n",
      "  episode_reward_mean: 3.47877358490567\n",
      "  episode_reward_min: -1.5300000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 66530\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.12180387403211\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013311748286458426\n",
      "          policy_loss: -0.05419582814678677\n",
      "          total_loss: 0.15469016740814998\n",
      "          vf_explained_var: 0.9160909652709961\n",
      "          vf_loss: 0.19977820693777923\n",
      "    num_agent_steps_sampled: 6137544\n",
      "    num_agent_steps_trained: 6137544\n",
      "    num_steps_sampled: 6137544\n",
      "    num_steps_trained: 6137544\n",
      "  iterations_since_restore: 614\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.09915611814345\n",
      "    ram_util_percent: 57.854852320675114\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554685724869366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98709075876624\n",
      "    mean_inference_ms: 2.853827000972506\n",
      "    mean_raw_obs_processing_ms: 3.5939677724967107\n",
      "  time_since_restore: 96435.25617575645\n",
      "  time_this_iter_s: 166.3664629459381\n",
      "  time_total_s: 96435.25617575645\n",
      "  timers:\n",
      "    learn_throughput: 934.166\n",
      "    learn_time_ms: 10700.459\n",
      "    load_throughput: 91699.57\n",
      "    load_time_ms: 109.008\n",
      "    sample_throughput: 63.218\n",
      "    sample_time_ms: 158120.64\n",
      "    update_time_ms: 11.59\n",
      "  timestamp: 1636390868\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6137544\n",
      "  training_iteration: 614\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   614</td><td style=\"text-align: right;\">         96435.3</td><td style=\"text-align: right;\">6137544</td><td style=\"text-align: right;\"> 3.47877</td><td style=\"text-align: right;\">               14.28</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">           95.1509</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6147540\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-04-02\n",
      "  done: false\n",
      "  episode_len_mean: 93.05607476635514\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000014\n",
      "  episode_reward_mean: 4.698785046728982\n",
      "  episode_reward_min: -1.2500000000000004\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 66637\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0946137798138156\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013183184017993552\n",
      "          policy_loss: -0.055388165478650324\n",
      "          total_loss: 0.1641604634734173\n",
      "          vf_explained_var: 0.9237150549888611\n",
      "          vf_loss: 0.21046182425039955\n",
      "    num_agent_steps_sampled: 6147540\n",
      "    num_agent_steps_trained: 6147540\n",
      "    num_steps_sampled: 6147540\n",
      "    num_steps_trained: 6147540\n",
      "  iterations_since_restore: 615\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.06024096385542\n",
      "    ram_util_percent: 57.77710843373494\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04557830026067773\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.9861990760951\n",
      "    mean_inference_ms: 2.8539263283594924\n",
      "    mean_raw_obs_processing_ms: 3.598149809504489\n",
      "  time_since_restore: 96609.62578463554\n",
      "  time_this_iter_s: 174.36960887908936\n",
      "  time_total_s: 96609.62578463554\n",
      "  timers:\n",
      "    learn_throughput: 934.687\n",
      "    learn_time_ms: 10694.487\n",
      "    load_throughput: 91717.102\n",
      "    load_time_ms: 108.987\n",
      "    sample_throughput: 63.102\n",
      "    sample_time_ms: 158410.664\n",
      "    update_time_ms: 11.813\n",
      "  timestamp: 1636391042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6147540\n",
      "  training_iteration: 615\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   615</td><td style=\"text-align: right;\">         96609.6</td><td style=\"text-align: right;\">6147540</td><td style=\"text-align: right;\"> 4.69879</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">               -1.25</td><td style=\"text-align: right;\">           93.0561</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6157536\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-06-50\n",
      "  done: false\n",
      "  episode_len_mean: 94.45283018867924\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.88000000000002\n",
      "  episode_reward_mean: 4.133113207547179\n",
      "  episode_reward_min: -1.660000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 66743\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.082654885043446\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011800768637631942\n",
      "          policy_loss: -0.057999110040374294\n",
      "          total_loss: 0.12190185900315897\n",
      "          vf_explained_var: 0.9146696925163269\n",
      "          vf_loss: 0.1738438916161784\n",
      "    num_agent_steps_sampled: 6157536\n",
      "    num_agent_steps_trained: 6157536\n",
      "    num_steps_sampled: 6157536\n",
      "    num_steps_trained: 6157536\n",
      "  iterations_since_restore: 616\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.67782426778243\n",
      "    ram_util_percent: 57.93723849372385\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045552477817897015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98265073885668\n",
      "    mean_inference_ms: 2.8538832813004826\n",
      "    mean_raw_obs_processing_ms: 3.602480868552544\n",
      "  time_since_restore: 96777.17572307587\n",
      "  time_this_iter_s: 167.54993844032288\n",
      "  time_total_s: 96777.17572307587\n",
      "  timers:\n",
      "    learn_throughput: 934.186\n",
      "    learn_time_ms: 10700.219\n",
      "    load_throughput: 91660.817\n",
      "    load_time_ms: 109.054\n",
      "    sample_throughput: 63.536\n",
      "    sample_time_ms: 157327.712\n",
      "    update_time_ms: 11.577\n",
      "  timestamp: 1636391210\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6157536\n",
      "  training_iteration: 616\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   616</td><td style=\"text-align: right;\">         96777.2</td><td style=\"text-align: right;\">6157536</td><td style=\"text-align: right;\"> 4.13311</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           94.4528</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6167532\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-09-25\n",
      "  done: false\n",
      "  episode_len_mean: 95.08571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.329999999999945\n",
      "  episode_reward_mean: 4.12495238095239\n",
      "  episode_reward_min: -1.880000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 66848\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.100297076987405\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013645882627848988\n",
      "          policy_loss: -0.05515100805518719\n",
      "          total_loss: 0.14720715572579932\n",
      "          vf_explained_var: 0.923581063747406\n",
      "          vf_loss: 0.192274108213874\n",
      "    num_agent_steps_sampled: 6167532\n",
      "    num_agent_steps_trained: 6167532\n",
      "    num_steps_sampled: 6167532\n",
      "    num_steps_trained: 6167532\n",
      "  iterations_since_restore: 617\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.18590909090909\n",
      "    ram_util_percent: 57.96590909090909\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552726273203321\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.982558609294685\n",
      "    mean_inference_ms: 2.8538967585957433\n",
      "    mean_raw_obs_processing_ms: 3.600010611024605\n",
      "  time_since_restore: 96931.78020358086\n",
      "  time_this_iter_s: 154.60448050498962\n",
      "  time_total_s: 96931.78020358086\n",
      "  timers:\n",
      "    learn_throughput: 933.875\n",
      "    learn_time_ms: 10703.791\n",
      "    load_throughput: 91899.765\n",
      "    load_time_ms: 108.771\n",
      "    sample_throughput: 64.808\n",
      "    sample_time_ms: 154239.954\n",
      "    update_time_ms: 11.971\n",
      "  timestamp: 1636391365\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6167532\n",
      "  training_iteration: 617\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   617</td><td style=\"text-align: right;\">         96931.8</td><td style=\"text-align: right;\">6167532</td><td style=\"text-align: right;\"> 4.12495</td><td style=\"text-align: right;\">               16.33</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           95.0857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6177528\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-11-42\n",
      "  done: false\n",
      "  episode_len_mean: 97.45631067961165\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.410000000000014\n",
      "  episode_reward_mean: 4.155728155339816\n",
      "  episode_reward_min: -1.940000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 66951\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0950582385063172\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012684439993401549\n",
      "          policy_loss: -0.059331819414296466\n",
      "          total_loss: 0.1176136783292342\n",
      "          vf_explained_var: 0.9330384731292725\n",
      "          vf_loss: 0.16899933819460053\n",
      "    num_agent_steps_sampled: 6177528\n",
      "    num_agent_steps_trained: 6177528\n",
      "    num_steps_sampled: 6177528\n",
      "    num_steps_trained: 6177528\n",
      "  iterations_since_restore: 618\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0040609137056\n",
      "    ram_util_percent: 57.94771573604061\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553123123252892\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.9833039532565\n",
      "    mean_inference_ms: 2.8538427971714824\n",
      "    mean_raw_obs_processing_ms: 3.596122539536188\n",
      "  time_since_restore: 97069.18183922768\n",
      "  time_this_iter_s: 137.40163564682007\n",
      "  time_total_s: 97069.18183922768\n",
      "  timers:\n",
      "    learn_throughput: 934.16\n",
      "    learn_time_ms: 10700.521\n",
      "    load_throughput: 91377.34\n",
      "    load_time_ms: 109.393\n",
      "    sample_throughput: 65.641\n",
      "    sample_time_ms: 152283.624\n",
      "    update_time_ms: 12.008\n",
      "  timestamp: 1636391502\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6177528\n",
      "  training_iteration: 618\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   618</td><td style=\"text-align: right;\">         97069.2</td><td style=\"text-align: right;\">6177528</td><td style=\"text-align: right;\"> 4.15573</td><td style=\"text-align: right;\">               12.41</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           97.4563</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6187524\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-14-24\n",
      "  done: false\n",
      "  episode_len_mean: 94.70476190476191\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.710000000000022\n",
      "  episode_reward_mean: 4.341238095238106\n",
      "  episode_reward_min: -2.05\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 67056\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1198540503143244\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01279845023206267\n",
      "          policy_loss: -0.06043919415141528\n",
      "          total_loss: 0.1144770239933561\n",
      "          vf_explained_var: 0.9372344613075256\n",
      "          vf_loss: 0.16695828733121992\n",
      "    num_agent_steps_sampled: 6187524\n",
      "    num_agent_steps_trained: 6187524\n",
      "    num_steps_sampled: 6187524\n",
      "    num_steps_trained: 6187524\n",
      "  iterations_since_restore: 619\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.55695652173912\n",
      "    ram_util_percent: 57.82652173913044\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555073264572448\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98125112424262\n",
      "    mean_inference_ms: 2.8539402706207095\n",
      "    mean_raw_obs_processing_ms: 3.5991175416046612\n",
      "  time_since_restore: 97230.5969657898\n",
      "  time_this_iter_s: 161.41512656211853\n",
      "  time_total_s: 97230.5969657898\n",
      "  timers:\n",
      "    learn_throughput: 934.402\n",
      "    learn_time_ms: 10697.752\n",
      "    load_throughput: 91263.327\n",
      "    load_time_ms: 109.529\n",
      "    sample_throughput: 65.261\n",
      "    sample_time_ms: 153170.414\n",
      "    update_time_ms: 11.641\n",
      "  timestamp: 1636391664\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6187524\n",
      "  training_iteration: 619\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   619</td><td style=\"text-align: right;\">         97230.6</td><td style=\"text-align: right;\">6187524</td><td style=\"text-align: right;\"> 4.34124</td><td style=\"text-align: right;\">               13.71</td><td style=\"text-align: right;\">               -2.05</td><td style=\"text-align: right;\">           94.7048</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6197520\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-16-40\n",
      "  done: false\n",
      "  episode_len_mean: 97.41747572815534\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.55999999999994\n",
      "  episode_reward_mean: 4.434077669902924\n",
      "  episode_reward_min: -0.9600000000000003\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 67159\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1046169069078235\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012683676685013467\n",
      "          policy_loss: -0.05780966350347058\n",
      "          total_loss: 0.12389444047027928\n",
      "          vf_explained_var: 0.9248759746551514\n",
      "          vf_loss: 0.17385527105986054\n",
      "    num_agent_steps_sampled: 6197520\n",
      "    num_agent_steps_trained: 6197520\n",
      "    num_steps_sampled: 6197520\n",
      "    num_steps_trained: 6197520\n",
      "  iterations_since_restore: 620\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.22307692307692\n",
      "    ram_util_percent: 57.84564102564104\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549814438230675\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97951944796466\n",
      "    mean_inference_ms: 2.853588516810148\n",
      "    mean_raw_obs_processing_ms: 3.5967567400659504\n",
      "  time_since_restore: 97367.10718989372\n",
      "  time_this_iter_s: 136.5102241039276\n",
      "  time_total_s: 97367.10718989372\n",
      "  timers:\n",
      "    learn_throughput: 934.498\n",
      "    learn_time_ms: 10696.658\n",
      "    load_throughput: 90872.834\n",
      "    load_time_ms: 110.0\n",
      "    sample_throughput: 66.672\n",
      "    sample_time_ms: 149926.907\n",
      "    update_time_ms: 11.969\n",
      "  timestamp: 1636391800\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6197520\n",
      "  training_iteration: 620\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   620</td><td style=\"text-align: right;\">         97367.1</td><td style=\"text-align: right;\">6197520</td><td style=\"text-align: right;\"> 4.43408</td><td style=\"text-align: right;\">               16.56</td><td style=\"text-align: right;\">               -0.96</td><td style=\"text-align: right;\">           97.4175</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6207516\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-19-01\n",
      "  done: false\n",
      "  episode_len_mean: 97.3921568627451\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.239999999999945\n",
      "  episode_reward_mean: 3.707450980392166\n",
      "  episode_reward_min: -1.9900000000000009\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 67261\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.114752863818764\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014391086302995312\n",
      "          policy_loss: -0.05431700977377402\n",
      "          total_loss: 0.14236401968325177\n",
      "          vf_explained_var: 0.9125540256500244\n",
      "          vf_loss: 0.18504386358281485\n",
      "    num_agent_steps_sampled: 6207516\n",
      "    num_agent_steps_trained: 6207516\n",
      "    num_steps_sampled: 6207516\n",
      "    num_steps_trained: 6207516\n",
      "  iterations_since_restore: 621\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59601990049751\n",
      "    ram_util_percent: 57.850248756218924\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554363960309415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98410371162008\n",
      "    mean_inference_ms: 2.8538755733962833\n",
      "    mean_raw_obs_processing_ms: 3.591054156304425\n",
      "  time_since_restore: 97508.19804477692\n",
      "  time_this_iter_s: 141.09085488319397\n",
      "  time_total_s: 97508.19804477692\n",
      "  timers:\n",
      "    learn_throughput: 934.615\n",
      "    learn_time_ms: 10695.316\n",
      "    load_throughput: 91206.566\n",
      "    load_time_ms: 109.597\n",
      "    sample_throughput: 68.587\n",
      "    sample_time_ms: 145741.776\n",
      "    update_time_ms: 11.593\n",
      "  timestamp: 1636391941\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6207516\n",
      "  training_iteration: 621\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   621</td><td style=\"text-align: right;\">         97508.2</td><td style=\"text-align: right;\">6207516</td><td style=\"text-align: right;\"> 3.70745</td><td style=\"text-align: right;\">               16.24</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           97.3922</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6217512\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-21-43\n",
      "  done: false\n",
      "  episode_len_mean: 96.76699029126213\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000015\n",
      "  episode_reward_mean: 3.8441747572815643\n",
      "  episode_reward_min: -0.8800000000000006\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 67364\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1345779091883927\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012644858792888848\n",
      "          policy_loss: -0.06091077424044538\n",
      "          total_loss: 0.10646468593667333\n",
      "          vf_explained_var: 0.9241423606872559\n",
      "          vf_loss: 0.15991466956324557\n",
      "    num_agent_steps_sampled: 6217512\n",
      "    num_agent_steps_trained: 6217512\n",
      "    num_steps_sampled: 6217512\n",
      "    num_steps_trained: 6217512\n",
      "  iterations_since_restore: 622\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.70260869565217\n",
      "    ram_util_percent: 57.739565217391295\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553005377846586\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.979431108522434\n",
      "    mean_inference_ms: 2.853794947363745\n",
      "    mean_raw_obs_processing_ms: 3.5943342183686053\n",
      "  time_since_restore: 97669.62435793877\n",
      "  time_this_iter_s: 161.42631316184998\n",
      "  time_total_s: 97669.62435793877\n",
      "  timers:\n",
      "    learn_throughput: 934.633\n",
      "    learn_time_ms: 10695.106\n",
      "    load_throughput: 91085.26\n",
      "    load_time_ms: 109.743\n",
      "    sample_throughput: 69.172\n",
      "    sample_time_ms: 144509.183\n",
      "    update_time_ms: 12.509\n",
      "  timestamp: 1636392103\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6217512\n",
      "  training_iteration: 622\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   622</td><td style=\"text-align: right;\">         97669.6</td><td style=\"text-align: right;\">6217512</td><td style=\"text-align: right;\"> 3.84417</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">               -0.88</td><td style=\"text-align: right;\">            96.767</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6227508\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-24-12\n",
      "  done: false\n",
      "  episode_len_mean: 96.67619047619047\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.800000000000024\n",
      "  episode_reward_mean: 4.124095238095248\n",
      "  episode_reward_min: 0.040000000000001874\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 67469\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1263530381724367\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013068710621019119\n",
      "          policy_loss: -0.060062190383258794\n",
      "          total_loss: 0.1294089432288375\n",
      "          vf_explained_var: 0.921183705329895\n",
      "          vf_loss: 0.18096250601144684\n",
      "    num_agent_steps_sampled: 6227508\n",
      "    num_agent_steps_trained: 6227508\n",
      "    num_steps_sampled: 6227508\n",
      "    num_steps_trained: 6227508\n",
      "  iterations_since_restore: 623\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.35446009389673\n",
      "    ram_util_percent: 57.86901408450705\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555163120675731\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97766403312544\n",
      "    mean_inference_ms: 2.853919674957543\n",
      "    mean_raw_obs_processing_ms: 3.5927871617807603\n",
      "  time_since_restore: 97818.92037296295\n",
      "  time_this_iter_s: 149.29601502418518\n",
      "  time_total_s: 97818.92037296295\n",
      "  timers:\n",
      "    learn_throughput: 934.578\n",
      "    learn_time_ms: 10695.733\n",
      "    load_throughput: 90923.737\n",
      "    load_time_ms: 109.938\n",
      "    sample_throughput: 69.335\n",
      "    sample_time_ms: 144169.832\n",
      "    update_time_ms: 13.404\n",
      "  timestamp: 1636392252\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6227508\n",
      "  training_iteration: 623\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   623</td><td style=\"text-align: right;\">         97818.9</td><td style=\"text-align: right;\">6227508</td><td style=\"text-align: right;\">  4.1241</td><td style=\"text-align: right;\">                13.8</td><td style=\"text-align: right;\">                0.04</td><td style=\"text-align: right;\">           96.6762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6237504\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-26-45\n",
      "  done: false\n",
      "  episode_len_mean: 96.72549019607843\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.250000000000018\n",
      "  episode_reward_mean: 3.6206862745098145\n",
      "  episode_reward_min: -1.5800000000000007\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 67571\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.106545439337054\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013224135834274458\n",
      "          policy_loss: -0.05853356032863132\n",
      "          total_loss: 0.11266049646860005\n",
      "          vf_explained_var: 0.9220457673072815\n",
      "          vf_loss: 0.16213327585998127\n",
      "    num_agent_steps_sampled: 6237504\n",
      "    num_agent_steps_trained: 6237504\n",
      "    num_steps_sampled: 6237504\n",
      "    num_steps_trained: 6237504\n",
      "  iterations_since_restore: 624\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.19403669724772\n",
      "    ram_util_percent: 58.0591743119266\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556636183959913\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.977941296219335\n",
      "    mean_inference_ms: 2.853896868999923\n",
      "    mean_raw_obs_processing_ms: 3.5917965908710916\n",
      "  time_since_restore: 97971.43252635002\n",
      "  time_this_iter_s: 152.5121533870697\n",
      "  time_total_s: 97971.43252635002\n",
      "  timers:\n",
      "    learn_throughput: 934.429\n",
      "    learn_time_ms: 10697.439\n",
      "    load_throughput: 91071.272\n",
      "    load_time_ms: 109.76\n",
      "    sample_throughput: 70.008\n",
      "    sample_time_ms: 142783.261\n",
      "    update_time_ms: 13.23\n",
      "  timestamp: 1636392405\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6237504\n",
      "  training_iteration: 624\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   624</td><td style=\"text-align: right;\">         97971.4</td><td style=\"text-align: right;\">6237504</td><td style=\"text-align: right;\"> 3.62069</td><td style=\"text-align: right;\">               14.25</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           96.7255</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6247500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-29-07\n",
      "  done: false\n",
      "  episode_len_mean: 99.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.560000000000015\n",
      "  episode_reward_mean: 3.5917000000000106\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 67671\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1123040532454467\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012871281657375198\n",
      "          policy_loss: -0.05876612865612802\n",
      "          total_loss: 0.12491543687497958\n",
      "          vf_explained_var: 0.9062916040420532\n",
      "          vf_loss: 0.1754822165458503\n",
      "    num_agent_steps_sampled: 6247500\n",
      "    num_agent_steps_trained: 6247500\n",
      "    num_steps_sampled: 6247500\n",
      "    num_steps_trained: 6247500\n",
      "  iterations_since_restore: 625\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.42266009852219\n",
      "    ram_util_percent: 57.91822660098523\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554171060333401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97298584518268\n",
      "    mean_inference_ms: 2.8539860343011445\n",
      "    mean_raw_obs_processing_ms: 3.588713785707697\n",
      "  time_since_restore: 98113.41047787666\n",
      "  time_this_iter_s: 141.97795152664185\n",
      "  time_total_s: 98113.41047787666\n",
      "  timers:\n",
      "    learn_throughput: 933.965\n",
      "    learn_time_ms: 10702.759\n",
      "    load_throughput: 91085.715\n",
      "    load_time_ms: 109.743\n",
      "    sample_throughput: 71.636\n",
      "    sample_time_ms: 139538.646\n",
      "    update_time_ms: 13.051\n",
      "  timestamp: 1636392547\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6247500\n",
      "  training_iteration: 625\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   625</td><td style=\"text-align: right;\">         98113.4</td><td style=\"text-align: right;\">6247500</td><td style=\"text-align: right;\">  3.5917</td><td style=\"text-align: right;\">               12.56</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">             99.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6257496\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-31-19\n",
      "  done: false\n",
      "  episode_len_mean: 99.66336633663366\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.810000000000022\n",
      "  episode_reward_mean: 4.192178217821793\n",
      "  episode_reward_min: -1.280000000000001\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 67772\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0894555706244247\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01372775265603025\n",
      "          policy_loss: -0.05575425863488872\n",
      "          total_loss: 0.14292282059502143\n",
      "          vf_explained_var: 0.9151705503463745\n",
      "          vf_loss: 0.18829809666062014\n",
      "    num_agent_steps_sampled: 6257496\n",
      "    num_agent_steps_trained: 6257496\n",
      "    num_steps_sampled: 6257496\n",
      "    num_steps_trained: 6257496\n",
      "  iterations_since_restore: 626\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14627659574468\n",
      "    ram_util_percent: 57.90531914893617\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554198092631994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.9716319753436\n",
      "    mean_inference_ms: 2.853955291393156\n",
      "    mean_raw_obs_processing_ms: 3.584845593973257\n",
      "  time_since_restore: 98245.42774248123\n",
      "  time_this_iter_s: 132.01726460456848\n",
      "  time_total_s: 98245.42774248123\n",
      "  timers:\n",
      "    learn_throughput: 934.607\n",
      "    learn_time_ms: 10695.401\n",
      "    load_throughput: 91013.939\n",
      "    load_time_ms: 109.829\n",
      "    sample_throughput: 73.504\n",
      "    sample_time_ms: 135992.524\n",
      "    update_time_ms: 13.233\n",
      "  timestamp: 1636392679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6257496\n",
      "  training_iteration: 626\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   626</td><td style=\"text-align: right;\">         98245.4</td><td style=\"text-align: right;\">6257496</td><td style=\"text-align: right;\"> 4.19218</td><td style=\"text-align: right;\">               13.81</td><td style=\"text-align: right;\">               -1.28</td><td style=\"text-align: right;\">           99.6634</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6267492\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-33-57\n",
      "  done: false\n",
      "  episode_len_mean: 94.95283018867924\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.78999999999994\n",
      "  episode_reward_mean: 3.9749056603773676\n",
      "  episode_reward_min: -1.0799999999999983\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 67878\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1070522842244204\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012630216519284346\n",
      "          policy_loss: -0.058772862075358374\n",
      "          total_loss: 0.10754620911091821\n",
      "          vf_explained_var: 0.9272792935371399\n",
      "          vf_loss: 0.1586163807532981\n",
      "    num_agent_steps_sampled: 6267492\n",
      "    num_agent_steps_trained: 6267492\n",
      "    num_steps_sampled: 6267492\n",
      "    num_steps_trained: 6267492\n",
      "  iterations_since_restore: 627\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.82610619469027\n",
      "    ram_util_percent: 57.779203539823\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552959228560301\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96800535340725\n",
      "    mean_inference_ms: 2.8538232827530123\n",
      "    mean_raw_obs_processing_ms: 3.588906652748529\n",
      "  time_since_restore: 98404.01487016678\n",
      "  time_this_iter_s: 158.58712768554688\n",
      "  time_total_s: 98404.01487016678\n",
      "  timers:\n",
      "    learn_throughput: 934.73\n",
      "    learn_time_ms: 10694.003\n",
      "    load_throughput: 91136.759\n",
      "    load_time_ms: 109.681\n",
      "    sample_throughput: 73.288\n",
      "    sample_time_ms: 136393.164\n",
      "    update_time_ms: 12.429\n",
      "  timestamp: 1636392837\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6267492\n",
      "  training_iteration: 627\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   627</td><td style=\"text-align: right;\">           98404</td><td style=\"text-align: right;\">6267492</td><td style=\"text-align: right;\"> 3.97491</td><td style=\"text-align: right;\">               16.79</td><td style=\"text-align: right;\">               -1.08</td><td style=\"text-align: right;\">           94.9528</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6277488\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-36-26\n",
      "  done: false\n",
      "  episode_len_mean: 96.10679611650485\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.830000000000018\n",
      "  episode_reward_mean: 4.20873786407768\n",
      "  episode_reward_min: -1.3400000000000005\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 67981\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1178475110958783\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012913935660341103\n",
      "          policy_loss: -0.06081228264344808\n",
      "          total_loss: 0.10247373833742916\n",
      "          vf_explained_var: 0.9360601902008057\n",
      "          vf_loss: 0.15504493564048893\n",
      "    num_agent_steps_sampled: 6277488\n",
      "    num_agent_steps_trained: 6277488\n",
      "    num_steps_sampled: 6277488\n",
      "    num_steps_trained: 6277488\n",
      "  iterations_since_restore: 628\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.58207547169812\n",
      "    ram_util_percent: 57.94245283018868\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045553688252813834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96798100461375\n",
      "    mean_inference_ms: 2.8538946014589692\n",
      "    mean_raw_obs_processing_ms: 3.5868269101554042\n",
      "  time_since_restore: 98552.3044705391\n",
      "  time_this_iter_s: 148.28960037231445\n",
      "  time_total_s: 98552.3044705391\n",
      "  timers:\n",
      "    learn_throughput: 934.65\n",
      "    learn_time_ms: 10694.918\n",
      "    load_throughput: 91289.179\n",
      "    load_time_ms: 109.498\n",
      "    sample_throughput: 72.707\n",
      "    sample_time_ms: 137482.788\n",
      "    update_time_ms: 11.381\n",
      "  timestamp: 1636392986\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6277488\n",
      "  training_iteration: 628\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   628</td><td style=\"text-align: right;\">         98552.3</td><td style=\"text-align: right;\">6277488</td><td style=\"text-align: right;\"> 4.20874</td><td style=\"text-align: right;\">               12.83</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           96.1068</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6287484\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-38-56\n",
      "  done: false\n",
      "  episode_len_mean: 95.0952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.660000000000018\n",
      "  episode_reward_mean: 4.342857142857154\n",
      "  episode_reward_min: -1.1400000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 68086\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.086567222256946\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012423595368888806\n",
      "          policy_loss: -0.05834424680687933\n",
      "          total_loss: 0.10558884851475302\n",
      "          vf_explained_var: 0.9474406838417053\n",
      "          vf_loss: 0.15649626353262072\n",
      "    num_agent_steps_sampled: 6287484\n",
      "    num_agent_steps_trained: 6287484\n",
      "    num_steps_sampled: 6287484\n",
      "    num_steps_trained: 6287484\n",
      "  iterations_since_restore: 629\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.68418604651163\n",
      "    ram_util_percent: 57.95860465116281\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551991332056717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.965755513756605\n",
      "    mean_inference_ms: 2.853739094492787\n",
      "    mean_raw_obs_processing_ms: 3.59139590292762\n",
      "  time_since_restore: 98703.04769706726\n",
      "  time_this_iter_s: 150.74322652816772\n",
      "  time_total_s: 98703.04769706726\n",
      "  timers:\n",
      "    learn_throughput: 934.242\n",
      "    learn_time_ms: 10699.585\n",
      "    load_throughput: 91292.877\n",
      "    load_time_ms: 109.494\n",
      "    sample_throughput: 73.278\n",
      "    sample_time_ms: 136411.681\n",
      "    update_time_ms: 10.99\n",
      "  timestamp: 1636393136\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6287484\n",
      "  training_iteration: 629\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   629</td><td style=\"text-align: right;\">           98703</td><td style=\"text-align: right;\">6287484</td><td style=\"text-align: right;\"> 4.34286</td><td style=\"text-align: right;\">               16.66</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           95.0952</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6297480\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-41-11\n",
      "  done: false\n",
      "  episode_len_mean: 99.85148514851485\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.95000000000002\n",
      "  episode_reward_mean: 4.418316831683181\n",
      "  episode_reward_min: -1.690000000000001\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 68187\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.113251913714613\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01183459126027435\n",
      "          policy_loss: -0.06069063166649932\n",
      "          total_loss: 0.09622735132773717\n",
      "          vf_explained_var: 0.9348501563072205\n",
      "          vf_loss: 0.15108982310908983\n",
      "    num_agent_steps_sampled: 6297480\n",
      "    num_agent_steps_trained: 6297480\n",
      "    num_steps_sampled: 6297480\n",
      "    num_steps_trained: 6297480\n",
      "  iterations_since_restore: 630\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.93125000000002\n",
      "    ram_util_percent: 57.760416666666664\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554302480881633\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96560067236042\n",
      "    mean_inference_ms: 2.853962115493401\n",
      "    mean_raw_obs_processing_ms: 3.585879765482345\n",
      "  time_since_restore: 98837.82511949539\n",
      "  time_this_iter_s: 134.7774224281311\n",
      "  time_total_s: 98837.82511949539\n",
      "  timers:\n",
      "    learn_throughput: 934.205\n",
      "    learn_time_ms: 10700.007\n",
      "    load_throughput: 91461.86\n",
      "    load_time_ms: 109.291\n",
      "    sample_throughput: 73.371\n",
      "    sample_time_ms: 136238.364\n",
      "    update_time_ms: 10.877\n",
      "  timestamp: 1636393271\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6297480\n",
      "  training_iteration: 630\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   630</td><td style=\"text-align: right;\">         98837.8</td><td style=\"text-align: right;\">6297480</td><td style=\"text-align: right;\"> 4.41832</td><td style=\"text-align: right;\">               13.95</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           99.8515</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6307476\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-43-29\n",
      "  done: false\n",
      "  episode_len_mean: 101.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.139999999999926\n",
      "  episode_reward_mean: 4.19860000000001\n",
      "  episode_reward_min: -1.6999999999999982\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 68285\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.118701749581557\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012393853615584182\n",
      "          policy_loss: -0.05517072833151135\n",
      "          total_loss: 0.13393953920652468\n",
      "          vf_explained_var: 0.924375057220459\n",
      "          vf_loss: 0.18206253659425892\n",
      "    num_agent_steps_sampled: 6307476\n",
      "    num_agent_steps_trained: 6307476\n",
      "    num_steps_sampled: 6307476\n",
      "    num_steps_trained: 6307476\n",
      "  iterations_since_restore: 631\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.48781725888328\n",
      "    ram_util_percent: 58.01269035532994\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045555211932241074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.965701015795894\n",
      "    mean_inference_ms: 2.853969461311575\n",
      "    mean_raw_obs_processing_ms: 3.581591558908096\n",
      "  time_since_restore: 98975.33158040047\n",
      "  time_this_iter_s: 137.50646090507507\n",
      "  time_total_s: 98975.33158040047\n",
      "  timers:\n",
      "    learn_throughput: 933.929\n",
      "    learn_time_ms: 10703.173\n",
      "    load_throughput: 91066.227\n",
      "    load_time_ms: 109.766\n",
      "    sample_throughput: 73.567\n",
      "    sample_time_ms: 135876.589\n",
      "    update_time_ms: 10.627\n",
      "  timestamp: 1636393409\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6307476\n",
      "  training_iteration: 631\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   631</td><td style=\"text-align: right;\">         98975.3</td><td style=\"text-align: right;\">6307476</td><td style=\"text-align: right;\">  4.1986</td><td style=\"text-align: right;\">               16.14</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">            101.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6317472\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-45-48\n",
      "  done: false\n",
      "  episode_len_mean: 103.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.910000000000016\n",
      "  episode_reward_mean: 3.943500000000011\n",
      "  episode_reward_min: -0.9300000000000006\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 68380\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.123613566211146\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01311602963423951\n",
      "          policy_loss: -0.05710262749980912\n",
      "          total_loss: 0.1312737734654011\n",
      "          vf_explained_var: 0.9243239164352417\n",
      "          vf_loss: 0.1797325808642448\n",
      "    num_agent_steps_sampled: 6317472\n",
      "    num_agent_steps_trained: 6317472\n",
      "    num_steps_sampled: 6317472\n",
      "    num_steps_trained: 6317472\n",
      "  iterations_since_restore: 632\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.49444444444445\n",
      "    ram_util_percent: 57.95505050505051\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04559817969182603\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96174568926304\n",
      "    mean_inference_ms: 2.8543868956793097\n",
      "    mean_raw_obs_processing_ms: 3.576917162412977\n",
      "  time_since_restore: 99114.69116258621\n",
      "  time_this_iter_s: 139.35958218574524\n",
      "  time_total_s: 99114.69116258621\n",
      "  timers:\n",
      "    learn_throughput: 933.785\n",
      "    learn_time_ms: 10704.816\n",
      "    load_throughput: 91182.663\n",
      "    load_time_ms: 109.626\n",
      "    sample_throughput: 74.782\n",
      "    sample_time_ms: 133669.373\n",
      "    update_time_ms: 9.964\n",
      "  timestamp: 1636393548\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6317472\n",
      "  training_iteration: 632\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   632</td><td style=\"text-align: right;\">         99114.7</td><td style=\"text-align: right;\">6317472</td><td style=\"text-align: right;\">  3.9435</td><td style=\"text-align: right;\">               14.91</td><td style=\"text-align: right;\">               -0.93</td><td style=\"text-align: right;\">            103.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6327468\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-48-51\n",
      "  done: false\n",
      "  episode_len_mean: 97.28571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.420000000000014\n",
      "  episode_reward_mean: 3.9178095238095354\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 68485\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.117346666715084\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012249413024605778\n",
      "          policy_loss: -0.059656484259499445\n",
      "          total_loss: 0.11878997089468643\n",
      "          vf_explained_var: 0.9186502695083618\n",
      "          vf_loss: 0.1717142253413669\n",
      "    num_agent_steps_sampled: 6327468\n",
      "    num_agent_steps_trained: 6327468\n",
      "    num_steps_sampled: 6327468\n",
      "    num_steps_trained: 6327468\n",
      "  iterations_since_restore: 633\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.60459770114942\n",
      "    ram_util_percent: 57.890804597701155\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045542508405816924\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95420911730019\n",
      "    mean_inference_ms: 2.853767321674519\n",
      "    mean_raw_obs_processing_ms: 3.5905317368187926\n",
      "  time_since_restore: 99297.55104923248\n",
      "  time_this_iter_s: 182.85988664627075\n",
      "  time_total_s: 99297.55104923248\n",
      "  timers:\n",
      "    learn_throughput: 933.918\n",
      "    learn_time_ms: 10703.29\n",
      "    load_throughput: 91320.636\n",
      "    load_time_ms: 109.46\n",
      "    sample_throughput: 72.949\n",
      "    sample_time_ms: 137027.774\n",
      "    update_time_ms: 9.712\n",
      "  timestamp: 1636393731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6327468\n",
      "  training_iteration: 633\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   633</td><td style=\"text-align: right;\">         99297.6</td><td style=\"text-align: right;\">6327468</td><td style=\"text-align: right;\"> 3.91781</td><td style=\"text-align: right;\">               10.42</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           97.2857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6337464\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-51-35\n",
      "  done: false\n",
      "  episode_len_mean: 97.46534653465346\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.330000000000014\n",
      "  episode_reward_mean: 3.97861386138615\n",
      "  episode_reward_min: -1.610000000000001\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 68586\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.142625557255541\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012654940707430857\n",
      "          policy_loss: -0.05743785988316577\n",
      "          total_loss: 0.11517724403076701\n",
      "          vf_explained_var: 0.924217700958252\n",
      "          vf_loss: 0.16521182093992193\n",
      "    num_agent_steps_sampled: 6337464\n",
      "    num_agent_steps_trained: 6337464\n",
      "    num_steps_sampled: 6337464\n",
      "    num_steps_trained: 6337464\n",
      "  iterations_since_restore: 634\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.80555555555556\n",
      "    ram_util_percent: 58.074358974358965\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045562429057755746\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.949951306752745\n",
      "    mean_inference_ms: 2.853862306557329\n",
      "    mean_raw_obs_processing_ms: 3.594602354852944\n",
      "  time_since_restore: 99461.42733597755\n",
      "  time_this_iter_s: 163.8762867450714\n",
      "  time_total_s: 99461.42733597755\n",
      "  timers:\n",
      "    learn_throughput: 934.152\n",
      "    learn_time_ms: 10700.61\n",
      "    load_throughput: 91231.533\n",
      "    load_time_ms: 109.567\n",
      "    sample_throughput: 72.347\n",
      "    sample_time_ms: 138167.494\n",
      "    update_time_ms: 9.029\n",
      "  timestamp: 1636393895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6337464\n",
      "  training_iteration: 634\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   634</td><td style=\"text-align: right;\">         99461.4</td><td style=\"text-align: right;\">6337464</td><td style=\"text-align: right;\"> 3.97861</td><td style=\"text-align: right;\">               12.33</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           97.4653</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6347460\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-53-58\n",
      "  done: false\n",
      "  episode_len_mean: 100.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.030000000000012\n",
      "  episode_reward_mean: 3.436900000000009\n",
      "  episode_reward_min: -1.98\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 68686\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.140519972438486\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0118519826825405\n",
      "          policy_loss: -0.05691906264704517\n",
      "          total_loss: 0.10251134436450199\n",
      "          vf_explained_var: 0.9130175709724426\n",
      "          vf_loss: 0.15383530862024453\n",
      "    num_agent_steps_sampled: 6347460\n",
      "    num_agent_steps_trained: 6347460\n",
      "    num_steps_sampled: 6347460\n",
      "    num_steps_trained: 6347460\n",
      "  iterations_since_restore: 635\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.73804878048782\n",
      "    ram_util_percent: 58.11170731707316\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552611196235784\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94570327462794\n",
      "    mean_inference_ms: 2.8537069727362807\n",
      "    mean_raw_obs_processing_ms: 3.59317959557426\n",
      "  time_since_restore: 99604.70592331886\n",
      "  time_this_iter_s: 143.2785873413086\n",
      "  time_total_s: 99604.70592331886\n",
      "  timers:\n",
      "    learn_throughput: 933.817\n",
      "    learn_time_ms: 10704.456\n",
      "    load_throughput: 91177.528\n",
      "    load_time_ms: 109.632\n",
      "    sample_throughput: 72.281\n",
      "    sample_time_ms: 138293.29\n",
      "    update_time_ms: 9.594\n",
      "  timestamp: 1636394038\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6347460\n",
      "  training_iteration: 635\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   635</td><td style=\"text-align: right;\">         99604.7</td><td style=\"text-align: right;\">6347460</td><td style=\"text-align: right;\">  3.4369</td><td style=\"text-align: right;\">               17.03</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">            100.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6357456\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-56-10\n",
      "  done: false\n",
      "  episode_len_mean: 102.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.14000000000002\n",
      "  episode_reward_mean: 3.6482000000000117\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 68784\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1293492117498674\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012821190474202604\n",
      "          policy_loss: -0.05517621328974636\n",
      "          total_loss: 0.12006350140381827\n",
      "          vf_explained_var: 0.9224836826324463\n",
      "          vf_loss: 0.16732493098984416\n",
      "    num_agent_steps_sampled: 6357456\n",
      "    num_agent_steps_trained: 6357456\n",
      "    num_steps_sampled: 6357456\n",
      "    num_steps_trained: 6357456\n",
      "  iterations_since_restore: 636\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.78609625668449\n",
      "    ram_util_percent: 58.03529411764706\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045552195138719095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.944451592121496\n",
      "    mean_inference_ms: 2.853841734145538\n",
      "    mean_raw_obs_processing_ms: 3.588706036787299\n",
      "  time_since_restore: 99736.03483390808\n",
      "  time_this_iter_s: 131.32891058921814\n",
      "  time_total_s: 99736.03483390808\n",
      "  timers:\n",
      "    learn_throughput: 932.819\n",
      "    learn_time_ms: 10715.905\n",
      "    load_throughput: 91198.789\n",
      "    load_time_ms: 109.607\n",
      "    sample_throughput: 72.323\n",
      "    sample_time_ms: 138212.695\n",
      "    update_time_ms: 9.883\n",
      "  timestamp: 1636394170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6357456\n",
      "  training_iteration: 636\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   636</td><td style=\"text-align: right;\">           99736</td><td style=\"text-align: right;\">6357456</td><td style=\"text-align: right;\">  3.6482</td><td style=\"text-align: right;\">               14.14</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">            102.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6367452\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_17-58-35\n",
      "  done: false\n",
      "  episode_len_mean: 100.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.25000000000001\n",
      "  episode_reward_mean: 3.9467000000000114\n",
      "  episode_reward_min: -1.3400000000000005\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 68884\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1281569289346027\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011523526611302464\n",
      "          policy_loss: -0.062103668850265505\n",
      "          total_loss: 0.08576773337414886\n",
      "          vf_explained_var: 0.9342751502990723\n",
      "          vf_loss: 0.14290093541559246\n",
      "    num_agent_steps_sampled: 6367452\n",
      "    num_agent_steps_trained: 6367452\n",
      "    num_steps_sampled: 6367452\n",
      "    num_steps_trained: 6367452\n",
      "  iterations_since_restore: 637\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78357487922707\n",
      "    ram_util_percent: 57.950724637681176\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554298468128584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94154515171937\n",
      "    mean_inference_ms: 2.853663767709085\n",
      "    mean_raw_obs_processing_ms: 3.588016367103636\n",
      "  time_since_restore: 99881.07223033905\n",
      "  time_this_iter_s: 145.03739643096924\n",
      "  time_total_s: 99881.07223033905\n",
      "  timers:\n",
      "    learn_throughput: 932.152\n",
      "    learn_time_ms: 10723.571\n",
      "    load_throughput: 91129.687\n",
      "    load_time_ms: 109.69\n",
      "    sample_throughput: 73.044\n",
      "    sample_time_ms: 136848.701\n",
      "    update_time_ms: 11.148\n",
      "  timestamp: 1636394315\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6367452\n",
      "  training_iteration: 637\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   637</td><td style=\"text-align: right;\">         99881.1</td><td style=\"text-align: right;\">6367452</td><td style=\"text-align: right;\">  3.9467</td><td style=\"text-align: right;\">               11.25</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">            100.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6377448\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-01-16\n",
      "  done: false\n",
      "  episode_len_mean: 94.43809523809524\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.930000000000016\n",
      "  episode_reward_mean: 4.568380952380963\n",
      "  episode_reward_min: -0.8100000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 68989\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0799764674952907\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012693914616573142\n",
      "          policy_loss: -0.05478779181567395\n",
      "          total_loss: 0.12230415735234562\n",
      "          vf_explained_var: 0.9285669326782227\n",
      "          vf_loss: 0.16897338864863173\n",
      "    num_agent_steps_sampled: 6377448\n",
      "    num_agent_steps_trained: 6377448\n",
      "    num_steps_sampled: 6377448\n",
      "    num_steps_trained: 6377448\n",
      "  iterations_since_restore: 638\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.90869565217392\n",
      "    ram_util_percent: 57.86217391304348\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553928551977686\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94079202045197\n",
      "    mean_inference_ms: 2.85370558152627\n",
      "    mean_raw_obs_processing_ms: 3.5880366686328267\n",
      "  time_since_restore: 100042.12828683853\n",
      "  time_this_iter_s: 161.0560564994812\n",
      "  time_total_s: 100042.12828683853\n",
      "  timers:\n",
      "    learn_throughput: 932.453\n",
      "    learn_time_ms: 10720.114\n",
      "    load_throughput: 90963.408\n",
      "    load_time_ms: 109.89\n",
      "    sample_throughput: 72.368\n",
      "    sample_time_ms: 138127.604\n",
      "    update_time_ms: 11.781\n",
      "  timestamp: 1636394476\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6377448\n",
      "  training_iteration: 638\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   638</td><td style=\"text-align: right;\">          100042</td><td style=\"text-align: right;\">6377448</td><td style=\"text-align: right;\"> 4.56838</td><td style=\"text-align: right;\">               12.93</td><td style=\"text-align: right;\">               -0.81</td><td style=\"text-align: right;\">           94.4381</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6387444\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-04-05\n",
      "  done: false\n",
      "  episode_len_mean: 98.48039215686275\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.780000000000017\n",
      "  episode_reward_mean: 3.8176470588235403\n",
      "  episode_reward_min: -1.4000000000000004\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 69091\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.115636889649253\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012285372953158269\n",
      "          policy_loss: -0.061657169609306714\n",
      "          total_loss: 0.08872353640607852\n",
      "          vf_explained_var: 0.9426584839820862\n",
      "          vf_loss: 0.14354945882422548\n",
      "    num_agent_steps_sampled: 6387444\n",
      "    num_agent_steps_trained: 6387444\n",
      "    num_steps_sampled: 6387444\n",
      "    num_steps_trained: 6387444\n",
      "  iterations_since_restore: 639\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.27136929460582\n",
      "    ram_util_percent: 58.132780082987544\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04556331573782322\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93764382486224\n",
      "    mean_inference_ms: 2.8537496751124696\n",
      "    mean_raw_obs_processing_ms: 3.5904374589147467\n",
      "  time_since_restore: 100210.79905486107\n",
      "  time_this_iter_s: 168.67076802253723\n",
      "  time_total_s: 100210.79905486107\n",
      "  timers:\n",
      "    learn_throughput: 932.598\n",
      "    learn_time_ms: 10718.442\n",
      "    load_throughput: 91071.212\n",
      "    load_time_ms: 109.76\n",
      "    sample_throughput: 71.439\n",
      "    sample_time_ms: 139922.653\n",
      "    update_time_ms: 11.317\n",
      "  timestamp: 1636394645\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6387444\n",
      "  training_iteration: 639\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   639</td><td style=\"text-align: right;\">          100211</td><td style=\"text-align: right;\">6387444</td><td style=\"text-align: right;\"> 3.81765</td><td style=\"text-align: right;\">               10.78</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           98.4804</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6397440\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-06-48\n",
      "  done: false\n",
      "  episode_len_mean: 97.00970873786407\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.000000000000012\n",
      "  episode_reward_mean: 4.215436893203895\n",
      "  episode_reward_min: -1.2500000000000004\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 69194\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0876201935303516\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012420178382621714\n",
      "          policy_loss: -0.060282779534339394\n",
      "          total_loss: 0.10409262371209697\n",
      "          vf_explained_var: 0.936872124671936\n",
      "          vf_loss: 0.15695688616261522\n",
      "    num_agent_steps_sampled: 6397440\n",
      "    num_agent_steps_trained: 6397440\n",
      "    num_steps_sampled: 6397440\n",
      "    num_steps_trained: 6397440\n",
      "  iterations_since_restore: 640\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.29827586206896\n",
      "    ram_util_percent: 58.025431034482764\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551339876297892\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93595049643866\n",
      "    mean_inference_ms: 2.8537528529621183\n",
      "    mean_raw_obs_processing_ms: 3.588940700082112\n",
      "  time_since_restore: 100373.88452196121\n",
      "  time_this_iter_s: 163.08546710014343\n",
      "  time_total_s: 100373.88452196121\n",
      "  timers:\n",
      "    learn_throughput: 932.331\n",
      "    learn_time_ms: 10721.511\n",
      "    load_throughput: 90987.689\n",
      "    load_time_ms: 109.861\n",
      "    sample_throughput: 70.025\n",
      "    sample_time_ms: 142749.16\n",
      "    update_time_ms: 12.089\n",
      "  timestamp: 1636394808\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6397440\n",
      "  training_iteration: 640\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   640</td><td style=\"text-align: right;\">          100374</td><td style=\"text-align: right;\">6397440</td><td style=\"text-align: right;\"> 4.21544</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">               -1.25</td><td style=\"text-align: right;\">           97.0097</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6407436\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-09-04\n",
      "  done: false\n",
      "  episode_len_mean: 99.8019801980198\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.380000000000017\n",
      "  episode_reward_mean: 4.541089108910901\n",
      "  episode_reward_min: -1.4800000000000004\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 69295\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0969147297052237\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013175122926060654\n",
      "          policy_loss: -0.056612046378163194\n",
      "          total_loss: 0.12676224902622465\n",
      "          vf_explained_var: 0.928215742111206\n",
      "          vf_loss: 0.1743288649723698\n",
      "    num_agent_steps_sampled: 6407436\n",
      "    num_agent_steps_trained: 6407436\n",
      "    num_steps_sampled: 6407436\n",
      "    num_steps_trained: 6407436\n",
      "  iterations_since_restore: 641\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.58820512820513\n",
      "    ram_util_percent: 57.96717948717948\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555305507893909\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.937660884007045\n",
      "    mean_inference_ms: 2.8537073622523543\n",
      "    mean_raw_obs_processing_ms: 3.5860820887118403\n",
      "  time_since_restore: 100510.36693644524\n",
      "  time_this_iter_s: 136.48241448402405\n",
      "  time_total_s: 100510.36693644524\n",
      "  timers:\n",
      "    learn_throughput: 932.633\n",
      "    learn_time_ms: 10718.047\n",
      "    load_throughput: 91068.423\n",
      "    load_time_ms: 109.764\n",
      "    sample_throughput: 70.073\n",
      "    sample_time_ms: 142650.853\n",
      "    update_time_ms: 11.51\n",
      "  timestamp: 1636394944\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6407436\n",
      "  training_iteration: 641\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   641</td><td style=\"text-align: right;\">          100510</td><td style=\"text-align: right;\">6407436</td><td style=\"text-align: right;\"> 4.54109</td><td style=\"text-align: right;\">               14.38</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">            99.802</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6417432\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-12-07\n",
      "  done: false\n",
      "  episode_len_mean: 97.02941176470588\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.130000000000011\n",
      "  episode_reward_mean: 3.7358823529411853\n",
      "  episode_reward_min: -1.3400000000000005\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 69397\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0973756942993553\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012060053976511814\n",
      "          policy_loss: -0.05606928283874041\n",
      "          total_loss: 0.12063362407935863\n",
      "          vf_explained_var: 0.9262916445732117\n",
      "          vf_loss: 0.17020235240427603\n",
      "    num_agent_steps_sampled: 6417432\n",
      "    num_agent_steps_trained: 6417432\n",
      "    num_steps_sampled: 6417432\n",
      "    num_steps_trained: 6417432\n",
      "  iterations_since_restore: 642\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.35134099616859\n",
      "    ram_util_percent: 58.002681992337166\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045569622657424425\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93364534537376\n",
      "    mean_inference_ms: 2.853848059368226\n",
      "    mean_raw_obs_processing_ms: 3.5898800194591076\n",
      "  time_since_restore: 100692.81382989883\n",
      "  time_this_iter_s: 182.44689345359802\n",
      "  time_total_s: 100692.81382989883\n",
      "  timers:\n",
      "    learn_throughput: 932.14\n",
      "    learn_time_ms: 10723.706\n",
      "    load_throughput: 91090.089\n",
      "    load_time_ms: 109.738\n",
      "    sample_throughput: 68.021\n",
      "    sample_time_ms: 146953.599\n",
      "    update_time_ms: 11.687\n",
      "  timestamp: 1636395127\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6417432\n",
      "  training_iteration: 642\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   642</td><td style=\"text-align: right;\">          100693</td><td style=\"text-align: right;\">6417432</td><td style=\"text-align: right;\"> 3.73588</td><td style=\"text-align: right;\">               13.13</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           97.0294</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6427428\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-14-55\n",
      "  done: false\n",
      "  episode_len_mean: 94.33962264150944\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.190000000000012\n",
      "  episode_reward_mean: 4.004905660377369\n",
      "  episode_reward_min: -1.1800000000000004\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 69503\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1128677553600737\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012689316536046337\n",
      "          policy_loss: -0.0610414585385185\n",
      "          total_loss: 0.1118976059791624\n",
      "          vf_explained_var: 0.9296600818634033\n",
      "          vf_loss: 0.1651598918880535\n",
      "    num_agent_steps_sampled: 6427428\n",
      "    num_agent_steps_trained: 6427428\n",
      "    num_steps_sampled: 6427428\n",
      "    num_steps_trained: 6427428\n",
      "  iterations_since_restore: 643\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.02000000000001\n",
      "    ram_util_percent: 58.02666666666666\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045526440112791375\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93025465027037\n",
      "    mean_inference_ms: 2.85353863988028\n",
      "    mean_raw_obs_processing_ms: 3.5926675090185918\n",
      "  time_since_restore: 100861.4149954319\n",
      "  time_this_iter_s: 168.6011655330658\n",
      "  time_total_s: 100861.4149954319\n",
      "  timers:\n",
      "    learn_throughput: 932.119\n",
      "    learn_time_ms: 10723.951\n",
      "    load_throughput: 91219.643\n",
      "    load_time_ms: 109.582\n",
      "    sample_throughput: 68.688\n",
      "    sample_time_ms: 145527.489\n",
      "    update_time_ms: 11.805\n",
      "  timestamp: 1636395295\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6427428\n",
      "  training_iteration: 643\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   643</td><td style=\"text-align: right;\">          100861</td><td style=\"text-align: right;\">6427428</td><td style=\"text-align: right;\"> 4.00491</td><td style=\"text-align: right;\">               15.19</td><td style=\"text-align: right;\">               -1.18</td><td style=\"text-align: right;\">           94.3396</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6437424\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-17-43\n",
      "  done: false\n",
      "  episode_len_mean: 94.95283018867924\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 4.04754716981133\n",
      "  episode_reward_min: -1.830000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 69609\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1087853924840942\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01197881673052555\n",
      "          policy_loss: -0.05932621809247977\n",
      "          total_loss: 0.1060474258218693\n",
      "          vf_explained_var: 0.9361407160758972\n",
      "          vf_loss: 0.15917225453015577\n",
      "    num_agent_steps_sampled: 6437424\n",
      "    num_agent_steps_trained: 6437424\n",
      "    num_steps_sampled: 6437424\n",
      "    num_steps_trained: 6437424\n",
      "  iterations_since_restore: 644\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.96583333333335\n",
      "    ram_util_percent: 58.104583333333316\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550362580302884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.92855976421648\n",
      "    mean_inference_ms: 2.8534468500437207\n",
      "    mean_raw_obs_processing_ms: 3.5942025831691993\n",
      "  time_since_restore: 101029.40394091606\n",
      "  time_this_iter_s: 167.98894548416138\n",
      "  time_total_s: 101029.40394091606\n",
      "  timers:\n",
      "    learn_throughput: 931.87\n",
      "    learn_time_ms: 10726.821\n",
      "    load_throughput: 91261.499\n",
      "    load_time_ms: 109.531\n",
      "    sample_throughput: 68.496\n",
      "    sample_time_ms: 145935.147\n",
      "    update_time_ms: 12.578\n",
      "  timestamp: 1636395463\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6437424\n",
      "  training_iteration: 644\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   644</td><td style=\"text-align: right;\">          101029</td><td style=\"text-align: right;\">6437424</td><td style=\"text-align: right;\"> 4.04755</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           94.9528</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6447420\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-20-13\n",
      "  done: false\n",
      "  episode_len_mean: 95.22115384615384\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.630000000000022\n",
      "  episode_reward_mean: 4.233557692307703\n",
      "  episode_reward_min: -0.8600000000000003\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 69713\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0858237811642835\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012950469971812945\n",
      "          policy_loss: -0.05882630376861646\n",
      "          total_loss: 0.12210778764679901\n",
      "          vf_explained_var: 0.9263931512832642\n",
      "          vf_loss: 0.1722895385331323\n",
      "    num_agent_steps_sampled: 6447420\n",
      "    num_agent_steps_trained: 6447420\n",
      "    num_steps_sampled: 6447420\n",
      "    num_steps_trained: 6447420\n",
      "  iterations_since_restore: 645\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.87897196261682\n",
      "    ram_util_percent: 57.98084112149532\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555194416196135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93038334638742\n",
      "    mean_inference_ms: 2.853540074635883\n",
      "    mean_raw_obs_processing_ms: 3.5928316397800804\n",
      "  time_since_restore: 101179.44215321541\n",
      "  time_this_iter_s: 150.03821229934692\n",
      "  time_total_s: 101179.44215321541\n",
      "  timers:\n",
      "    learn_throughput: 932.512\n",
      "    learn_time_ms: 10719.432\n",
      "    load_throughput: 89290.229\n",
      "    load_time_ms: 111.95\n",
      "    sample_throughput: 68.178\n",
      "    sample_time_ms: 146616.495\n",
      "    update_time_ms: 12.144\n",
      "  timestamp: 1636395613\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6447420\n",
      "  training_iteration: 645\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   645</td><td style=\"text-align: right;\">          101179</td><td style=\"text-align: right;\">6447420</td><td style=\"text-align: right;\"> 4.23356</td><td style=\"text-align: right;\">               12.63</td><td style=\"text-align: right;\">               -0.86</td><td style=\"text-align: right;\">           95.2212</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6457416\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-23-03\n",
      "  done: false\n",
      "  episode_len_mean: 97.03921568627452\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.560000000000018\n",
      "  episode_reward_mean: 4.288921568627463\n",
      "  episode_reward_min: -1.3500000000000008\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 69815\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1050481245049046\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01333033855723909\n",
      "          policy_loss: -0.05739469797565387\n",
      "          total_loss: 0.13259072835979044\n",
      "          vf_explained_var: 0.9308678507804871\n",
      "          vf_loss: 0.18066772976651405\n",
      "    num_agent_steps_sampled: 6457416\n",
      "    num_agent_steps_trained: 6457416\n",
      "    num_steps_sampled: 6457416\n",
      "    num_steps_trained: 6457416\n",
      "  iterations_since_restore: 646\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.6595041322314\n",
      "    ram_util_percent: 57.94049586776859\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045500101144576616\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.924356844530436\n",
      "    mean_inference_ms: 2.853468152103825\n",
      "    mean_raw_obs_processing_ms: 3.5971374546609174\n",
      "  time_since_restore: 101348.81975030899\n",
      "  time_this_iter_s: 169.37759709358215\n",
      "  time_total_s: 101348.81975030899\n",
      "  timers:\n",
      "    learn_throughput: 932.56\n",
      "    learn_time_ms: 10718.882\n",
      "    load_throughput: 89339.241\n",
      "    load_time_ms: 111.888\n",
      "    sample_throughput: 66.453\n",
      "    sample_time_ms: 150422.973\n",
      "    update_time_ms: 11.049\n",
      "  timestamp: 1636395783\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6457416\n",
      "  training_iteration: 646\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   646</td><td style=\"text-align: right;\">          101349</td><td style=\"text-align: right;\">6457416</td><td style=\"text-align: right;\"> 4.28892</td><td style=\"text-align: right;\">               12.56</td><td style=\"text-align: right;\">               -1.35</td><td style=\"text-align: right;\">           97.0392</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6467412\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-26-03\n",
      "  done: false\n",
      "  episode_len_mean: 96.59615384615384\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.88000000000002\n",
      "  episode_reward_mean: 3.826923076923087\n",
      "  episode_reward_min: -1.6099999999999979\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 69919\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.091619976565369\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01251823294174947\n",
      "          policy_loss: -0.0557683488035686\n",
      "          total_loss: 0.11929559134042415\n",
      "          vf_explained_var: 0.937125563621521\n",
      "          vf_loss: 0.1674620404298234\n",
      "    num_agent_steps_sampled: 6467412\n",
      "    num_agent_steps_trained: 6467412\n",
      "    num_steps_sampled: 6467412\n",
      "    num_steps_trained: 6467412\n",
      "  iterations_since_restore: 647\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.37782101167315\n",
      "    ram_util_percent: 58.17665369649805\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04558905367295871\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.923730417411136\n",
      "    mean_inference_ms: 2.853819916395668\n",
      "    mean_raw_obs_processing_ms: 3.600401230581\n",
      "  time_since_restore: 101528.82070231438\n",
      "  time_this_iter_s: 180.00095200538635\n",
      "  time_total_s: 101528.82070231438\n",
      "  timers:\n",
      "    learn_throughput: 932.862\n",
      "    learn_time_ms: 10715.413\n",
      "    load_throughput: 89377.579\n",
      "    load_time_ms: 111.84\n",
      "    sample_throughput: 64.941\n",
      "    sample_time_ms: 153923.545\n",
      "    update_time_ms: 10.338\n",
      "  timestamp: 1636395963\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6467412\n",
      "  training_iteration: 647\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   647</td><td style=\"text-align: right;\">          101529</td><td style=\"text-align: right;\">6467412</td><td style=\"text-align: right;\"> 3.82692</td><td style=\"text-align: right;\">               11.88</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           96.5962</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6477408\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-28-19\n",
      "  done: false\n",
      "  episode_len_mean: 98.25490196078431\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.889999999999983\n",
      "  episode_reward_mean: 4.084019607843147\n",
      "  episode_reward_min: -1.5400000000000005\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 70021\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.089839349954556\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012614911502128828\n",
      "          policy_loss: -0.06073410746951898\n",
      "          total_loss: 0.12315531094900818\n",
      "          vf_explained_var: 0.9235032200813293\n",
      "          vf_loss: 0.17604946562240267\n",
      "    num_agent_steps_sampled: 6477408\n",
      "    num_agent_steps_trained: 6477408\n",
      "    num_steps_sampled: 6477408\n",
      "    num_steps_trained: 6477408\n",
      "  iterations_since_restore: 648\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.27098445595854\n",
      "    ram_util_percent: 57.949740932642484\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455372105036577\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.92288995159781\n",
      "    mean_inference_ms: 2.8534861920039414\n",
      "    mean_raw_obs_processing_ms: 3.597186694438341\n",
      "  time_since_restore: 101664.72271633148\n",
      "  time_this_iter_s: 135.9020140171051\n",
      "  time_total_s: 101664.72271633148\n",
      "  timers:\n",
      "    learn_throughput: 932.534\n",
      "    learn_time_ms: 10719.178\n",
      "    load_throughput: 89538.526\n",
      "    load_time_ms: 111.639\n",
      "    sample_throughput: 66.022\n",
      "    sample_time_ms: 151404.966\n",
      "    update_time_ms: 9.92\n",
      "  timestamp: 1636396099\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6477408\n",
      "  training_iteration: 648\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   648</td><td style=\"text-align: right;\">          101665</td><td style=\"text-align: right;\">6477408</td><td style=\"text-align: right;\"> 4.08402</td><td style=\"text-align: right;\">               18.89</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           98.2549</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6487404\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-31-18\n",
      "  done: false\n",
      "  episode_len_mean: 94.61320754716981\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.790000000000015\n",
      "  episode_reward_mean: 4.027358490566047\n",
      "  episode_reward_min: -1.4400000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 70127\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.103625282059368\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013175593282941418\n",
      "          policy_loss: -0.059901044509795484\n",
      "          total_loss: 0.12977767544519953\n",
      "          vf_explained_var: 0.9241238236427307\n",
      "          vf_loss: 0.18069932305564482\n",
      "    num_agent_steps_sampled: 6487404\n",
      "    num_agent_steps_trained: 6487404\n",
      "    num_steps_sampled: 6487404\n",
      "    num_steps_trained: 6487404\n",
      "  iterations_since_restore: 649\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.30859375\n",
      "    ram_util_percent: 57.930859375000004\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045560707939015746\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.922297356331036\n",
      "    mean_inference_ms: 2.8534642055703108\n",
      "    mean_raw_obs_processing_ms: 3.6033441655135827\n",
      "  time_since_restore: 101844.02339148521\n",
      "  time_this_iter_s: 179.3006751537323\n",
      "  time_total_s: 101844.02339148521\n",
      "  timers:\n",
      "    learn_throughput: 932.357\n",
      "    learn_time_ms: 10721.21\n",
      "    load_throughput: 89319.124\n",
      "    load_time_ms: 111.913\n",
      "    sample_throughput: 65.563\n",
      "    sample_time_ms: 152465.205\n",
      "    update_time_ms: 10.167\n",
      "  timestamp: 1636396278\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6487404\n",
      "  training_iteration: 649\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   649</td><td style=\"text-align: right;\">          101844</td><td style=\"text-align: right;\">6487404</td><td style=\"text-align: right;\"> 4.02736</td><td style=\"text-align: right;\">               14.79</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           94.6132</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6497400\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-33-58\n",
      "  done: false\n",
      "  episode_len_mean: 94.60377358490567\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000016\n",
      "  episode_reward_mean: 3.985283018867934\n",
      "  episode_reward_min: -1.5400000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 70233\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0809662480639597\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012960156338965927\n",
      "          policy_loss: -0.05963583439747747\n",
      "          total_loss: 0.1294702168291387\n",
      "          vf_explained_var: 0.9108231663703918\n",
      "          vf_loss: 0.1803908573049638\n",
      "    num_agent_steps_sampled: 6497400\n",
      "    num_agent_steps_trained: 6497400\n",
      "    num_steps_sampled: 6497400\n",
      "    num_steps_trained: 6497400\n",
      "  iterations_since_restore: 650\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.66140350877193\n",
      "    ram_util_percent: 58.01271929824562\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552314388396344\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.91997452559229\n",
      "    mean_inference_ms: 2.8534373093017447\n",
      "    mean_raw_obs_processing_ms: 3.6029282250290313\n",
      "  time_since_restore: 102003.84190940857\n",
      "  time_this_iter_s: 159.8185179233551\n",
      "  time_total_s: 102003.84190940857\n",
      "  timers:\n",
      "    learn_throughput: 932.709\n",
      "    learn_time_ms: 10717.175\n",
      "    load_throughput: 89476.213\n",
      "    load_time_ms: 111.717\n",
      "    sample_throughput: 65.701\n",
      "    sample_time_ms: 152143.748\n",
      "    update_time_ms: 9.106\n",
      "  timestamp: 1636396438\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6497400\n",
      "  training_iteration: 650\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   650</td><td style=\"text-align: right;\">          102004</td><td style=\"text-align: right;\">6497400</td><td style=\"text-align: right;\"> 3.98528</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           94.6038</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6507396\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-36-31\n",
      "  done: false\n",
      "  episode_len_mean: 92.43518518518519\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.810000000000016\n",
      "  episode_reward_mean: 3.3151851851851926\n",
      "  episode_reward_min: -2.04\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 70341\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.084811293467497\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012180233240774286\n",
      "          policy_loss: -0.05955448549352268\n",
      "          total_loss: 0.09584483133199123\n",
      "          vf_explained_var: 0.9319225549697876\n",
      "          vf_loss: 0.1484993351599536\n",
      "    num_agent_steps_sampled: 6507396\n",
      "    num_agent_steps_trained: 6507396\n",
      "    num_steps_sampled: 6507396\n",
      "    num_steps_trained: 6507396\n",
      "  iterations_since_restore: 651\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78119266055047\n",
      "    ram_util_percent: 58.09449541284403\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552260904692776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.9210784456736\n",
      "    mean_inference_ms: 2.853511817787544\n",
      "    mean_raw_obs_processing_ms: 3.6007118410244914\n",
      "  time_since_restore: 102156.58727312088\n",
      "  time_this_iter_s: 152.7453637123108\n",
      "  time_total_s: 102156.58727312088\n",
      "  timers:\n",
      "    learn_throughput: 933.21\n",
      "    learn_time_ms: 10711.41\n",
      "    load_throughput: 89382.991\n",
      "    load_time_ms: 111.833\n",
      "    sample_throughput: 65.004\n",
      "    sample_time_ms: 153775.664\n",
      "    update_time_ms: 9.001\n",
      "  timestamp: 1636396591\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6507396\n",
      "  training_iteration: 651\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   651</td><td style=\"text-align: right;\">          102157</td><td style=\"text-align: right;\">6507396</td><td style=\"text-align: right;\"> 3.31519</td><td style=\"text-align: right;\">               12.81</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           92.4352</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6517392\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-38-51\n",
      "  done: false\n",
      "  episode_len_mean: 95.45714285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.890000000000015\n",
      "  episode_reward_mean: 4.106857142857153\n",
      "  episode_reward_min: -1.4100000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 70446\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0801804209366823\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011751431347077694\n",
      "          policy_loss: -0.05845319085682814\n",
      "          total_loss: 0.1154877215050734\n",
      "          vf_explained_var: 0.9304966926574707\n",
      "          vf_loss: 0.16797148517500132\n",
      "    num_agent_steps_sampled: 6517392\n",
      "    num_agent_steps_trained: 6517392\n",
      "    num_steps_sampled: 6517392\n",
      "    num_steps_trained: 6517392\n",
      "  iterations_since_restore: 652\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.26700000000001\n",
      "    ram_util_percent: 58.1215\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553783315597678\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.922934853595166\n",
      "    mean_inference_ms: 2.853474312266337\n",
      "    mean_raw_obs_processing_ms: 3.597170139434046\n",
      "  time_since_restore: 102296.45107126236\n",
      "  time_this_iter_s: 139.8637981414795\n",
      "  time_total_s: 102296.45107126236\n",
      "  timers:\n",
      "    learn_throughput: 933.858\n",
      "    learn_time_ms: 10703.988\n",
      "    load_throughput: 89160.272\n",
      "    load_time_ms: 112.113\n",
      "    sample_throughput: 66.853\n",
      "    sample_time_ms: 149523.194\n",
      "    update_time_ms: 10.128\n",
      "  timestamp: 1636396731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6517392\n",
      "  training_iteration: 652\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   652</td><td style=\"text-align: right;\">          102296</td><td style=\"text-align: right;\">6517392</td><td style=\"text-align: right;\"> 4.10686</td><td style=\"text-align: right;\">               14.89</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           95.4571</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6527388\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-41-23\n",
      "  done: false\n",
      "  episode_len_mean: 95.57692307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.37000000000002\n",
      "  episode_reward_mean: 3.523365384615394\n",
      "  episode_reward_min: -1.6300000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 70550\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0868625773323908\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012281185997203625\n",
      "          policy_loss: -0.05871092019140975\n",
      "          total_loss: 0.08944147542899109\n",
      "          vf_explained_var: 0.9207701086997986\n",
      "          vf_loss: 0.1410429445318241\n",
      "    num_agent_steps_sampled: 6527388\n",
      "    num_agent_steps_trained: 6527388\n",
      "    num_steps_sampled: 6527388\n",
      "    num_steps_trained: 6527388\n",
      "  iterations_since_restore: 653\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.45555555555556\n",
      "    ram_util_percent: 57.9662037037037\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045540859640180134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.92256752151936\n",
      "    mean_inference_ms: 2.8533401757711427\n",
      "    mean_raw_obs_processing_ms: 3.596766980113536\n",
      "  time_since_restore: 102448.17981624603\n",
      "  time_this_iter_s: 151.7287449836731\n",
      "  time_total_s: 102448.17981624603\n",
      "  timers:\n",
      "    learn_throughput: 933.909\n",
      "    learn_time_ms: 10703.403\n",
      "    load_throughput: 89122.48\n",
      "    load_time_ms: 112.16\n",
      "    sample_throughput: 67.615\n",
      "    sample_time_ms: 147837.03\n",
      "    update_time_ms: 9.505\n",
      "  timestamp: 1636396883\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6527388\n",
      "  training_iteration: 653\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   653</td><td style=\"text-align: right;\">          102448</td><td style=\"text-align: right;\">6527388</td><td style=\"text-align: right;\"> 3.52337</td><td style=\"text-align: right;\">               14.37</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           95.5769</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6537384\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-44-26\n",
      "  done: false\n",
      "  episode_len_mean: 90.78181818181818\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.01000000000002\n",
      "  episode_reward_mean: 3.3275454545454624\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 70660\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0588995433261252\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01224345118614928\n",
      "          policy_loss: -0.058824482902438725\n",
      "          total_loss: 0.09984949406347851\n",
      "          vf_explained_var: 0.9150777459144592\n",
      "          vf_loss: 0.1513708602844013\n",
      "    num_agent_steps_sampled: 6537384\n",
      "    num_agent_steps_trained: 6537384\n",
      "    num_steps_sampled: 6537384\n",
      "    num_steps_trained: 6537384\n",
      "  iterations_since_restore: 654\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.07862595419847\n",
      "    ram_util_percent: 57.899236641221385\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553858218400483\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.92169199605684\n",
      "    mean_inference_ms: 2.8532407374690654\n",
      "    mean_raw_obs_processing_ms: 3.6054831843384596\n",
      "  time_since_restore: 102631.75741529465\n",
      "  time_this_iter_s: 183.5775990486145\n",
      "  time_total_s: 102631.75741529465\n",
      "  timers:\n",
      "    learn_throughput: 933.93\n",
      "    learn_time_ms: 10703.16\n",
      "    load_throughput: 88966.611\n",
      "    load_time_ms: 112.357\n",
      "    sample_throughput: 66.909\n",
      "    sample_time_ms: 149396.71\n",
      "    update_time_ms: 8.897\n",
      "  timestamp: 1636397066\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6537384\n",
      "  training_iteration: 654\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   654</td><td style=\"text-align: right;\">          102632</td><td style=\"text-align: right;\">6537384</td><td style=\"text-align: right;\"> 3.32755</td><td style=\"text-align: right;\">               12.01</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           90.7818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6547380\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-46-59\n",
      "  done: false\n",
      "  episode_len_mean: 92.4862385321101\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.850000000000012\n",
      "  episode_reward_mean: 3.811284403669734\n",
      "  episode_reward_min: -1.4300000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 70769\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0567455400768506\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012928914546814635\n",
      "          policy_loss: -0.06118620125592774\n",
      "          total_loss: 0.09575088823962416\n",
      "          vf_explained_var: 0.9334475994110107\n",
      "          vf_loss: 0.14805085984910402\n",
      "    num_agent_steps_sampled: 6547380\n",
      "    num_agent_steps_trained: 6547380\n",
      "    num_steps_sampled: 6547380\n",
      "    num_steps_trained: 6547380\n",
      "  iterations_since_restore: 655\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.85229357798167\n",
      "    ram_util_percent: 58.12293577981651\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553668927918977\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.92392506335088\n",
      "    mean_inference_ms: 2.853332075451198\n",
      "    mean_raw_obs_processing_ms: 3.603191511131479\n",
      "  time_since_restore: 102784.15269184113\n",
      "  time_this_iter_s: 152.39527654647827\n",
      "  time_total_s: 102784.15269184113\n",
      "  timers:\n",
      "    learn_throughput: 934.005\n",
      "    learn_time_ms: 10702.3\n",
      "    load_throughput: 90709.256\n",
      "    load_time_ms: 110.198\n",
      "    sample_throughput: 66.803\n",
      "    sample_time_ms: 149634.691\n",
      "    update_time_ms: 9.386\n",
      "  timestamp: 1636397219\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6547380\n",
      "  training_iteration: 655\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   655</td><td style=\"text-align: right;\">          102784</td><td style=\"text-align: right;\">6547380</td><td style=\"text-align: right;\"> 3.81128</td><td style=\"text-align: right;\">               10.85</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           92.4862</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6557376\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-49-33\n",
      "  done: false\n",
      "  episode_len_mean: 91.1559633027523\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.639999999999993\n",
      "  episode_reward_mean: 3.522201834862393\n",
      "  episode_reward_min: -1.4000000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 70878\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0385164262902022\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013011471904397115\n",
      "          policy_loss: -0.058942986672951114\n",
      "          total_loss: 0.10595343878699673\n",
      "          vf_explained_var: 0.9361138343811035\n",
      "          vf_loss: 0.15563983065832374\n",
      "    num_agent_steps_sampled: 6557376\n",
      "    num_agent_steps_trained: 6557376\n",
      "    num_steps_sampled: 6557376\n",
      "    num_steps_trained: 6557376\n",
      "  iterations_since_restore: 656\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.43272727272728\n",
      "    ram_util_percent: 58.145\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554254062660884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.92668951536707\n",
      "    mean_inference_ms: 2.8537128955357356\n",
      "    mean_raw_obs_processing_ms: 3.5992038056526523\n",
      "  time_since_restore: 102938.1311223507\n",
      "  time_this_iter_s: 153.97843050956726\n",
      "  time_total_s: 102938.1311223507\n",
      "  timers:\n",
      "    learn_throughput: 934.993\n",
      "    learn_time_ms: 10690.988\n",
      "    load_throughput: 90706.411\n",
      "    load_time_ms: 110.202\n",
      "    sample_throughput: 67.492\n",
      "    sample_time_ms: 148106.089\n",
      "    update_time_ms: 9.399\n",
      "  timestamp: 1636397373\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6557376\n",
      "  training_iteration: 656\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   656</td><td style=\"text-align: right;\">          102938</td><td style=\"text-align: right;\">6557376</td><td style=\"text-align: right;\">  3.5222</td><td style=\"text-align: right;\">               16.64</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">            91.156</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6567372\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-52-31\n",
      "  done: false\n",
      "  episode_len_mean: 91.83636363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.54999999999993\n",
      "  episode_reward_mean: 3.942181818181826\n",
      "  episode_reward_min: -1.329999999999999\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 70988\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0532801565960943\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013003104758408318\n",
      "          policy_loss: -0.057055527441458316\n",
      "          total_loss: 0.12806594168815094\n",
      "          vf_explained_var: 0.9209141135215759\n",
      "          vf_loss: 0.17603157256912982\n",
      "    num_agent_steps_sampled: 6567372\n",
      "    num_agent_steps_trained: 6567372\n",
      "    num_steps_sampled: 6567372\n",
      "    num_steps_trained: 6567372\n",
      "  iterations_since_restore: 657\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.25275590551182\n",
      "    ram_util_percent: 58.10354330708661\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045535789065747845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.929077330521906\n",
      "    mean_inference_ms: 2.8534711401295114\n",
      "    mean_raw_obs_processing_ms: 3.6025358642111036\n",
      "  time_since_restore: 103116.40287613869\n",
      "  time_this_iter_s: 178.27175378799438\n",
      "  time_total_s: 103116.40287613869\n",
      "  timers:\n",
      "    learn_throughput: 935.637\n",
      "    learn_time_ms: 10683.626\n",
      "    load_throughput: 90363.797\n",
      "    load_time_ms: 110.62\n",
      "    sample_throughput: 67.568\n",
      "    sample_time_ms: 147940.121\n",
      "    update_time_ms: 9.067\n",
      "  timestamp: 1636397551\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6567372\n",
      "  training_iteration: 657\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   657</td><td style=\"text-align: right;\">          103116</td><td style=\"text-align: right;\">6567372</td><td style=\"text-align: right;\"> 3.94218</td><td style=\"text-align: right;\">               18.55</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">           91.8364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6577368\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-55-38\n",
      "  done: false\n",
      "  episode_len_mean: 89.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.58000000000001\n",
      "  episode_reward_mean: 4.314545454545464\n",
      "  episode_reward_min: -1.5500000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 71098\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0447927937548385\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012646400089128604\n",
      "          policy_loss: -0.0579728945166382\n",
      "          total_loss: 0.1486119363250004\n",
      "          vf_explained_var: 0.9274337887763977\n",
      "          vf_loss: 0.19822267837758756\n",
      "    num_agent_steps_sampled: 6577368\n",
      "    num_agent_steps_trained: 6577368\n",
      "    num_steps_sampled: 6577368\n",
      "    num_steps_trained: 6577368\n",
      "  iterations_since_restore: 658\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.11015037593985\n",
      "    ram_util_percent: 58.077819548872185\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045555879164177346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93190853721023\n",
      "    mean_inference_ms: 2.8534988502503262\n",
      "    mean_raw_obs_processing_ms: 3.610416354333469\n",
      "  time_since_restore: 103302.94976854324\n",
      "  time_this_iter_s: 186.54689240455627\n",
      "  time_total_s: 103302.94976854324\n",
      "  timers:\n",
      "    learn_throughput: 935.489\n",
      "    learn_time_ms: 10685.318\n",
      "    load_throughput: 90350.497\n",
      "    load_time_ms: 110.636\n",
      "    sample_throughput: 65.332\n",
      "    sample_time_ms: 153003.179\n",
      "    update_time_ms: 8.992\n",
      "  timestamp: 1636397738\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6577368\n",
      "  training_iteration: 658\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   658</td><td style=\"text-align: right;\">          103303</td><td style=\"text-align: right;\">6577368</td><td style=\"text-align: right;\"> 4.31455</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">               -1.55</td><td style=\"text-align: right;\">              89.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6587364\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_18-58-27\n",
      "  done: false\n",
      "  episode_len_mean: 92.09174311926606\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.819999999999936\n",
      "  episode_reward_mean: 4.060733944954136\n",
      "  episode_reward_min: -2.1300000000000003\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 71207\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.072230127428332\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012788564812094581\n",
      "          policy_loss: -0.05713152786095937\n",
      "          total_loss: 0.13978665615153363\n",
      "          vf_explained_var: 0.9369814395904541\n",
      "          vf_loss: 0.18850653428170416\n",
      "    num_agent_steps_sampled: 6587364\n",
      "    num_agent_steps_trained: 6587364\n",
      "    num_steps_sampled: 6587364\n",
      "    num_steps_trained: 6587364\n",
      "  iterations_since_restore: 659\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.19338842975208\n",
      "    ram_util_percent: 58.164049586776855\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553833259976739\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93254205531883\n",
      "    mean_inference_ms: 2.8532871424855686\n",
      "    mean_raw_obs_processing_ms: 3.6121119245289965\n",
      "  time_since_restore: 103472.29982495308\n",
      "  time_this_iter_s: 169.35005640983582\n",
      "  time_total_s: 103472.29982495308\n",
      "  timers:\n",
      "    learn_throughput: 935.798\n",
      "    learn_time_ms: 10681.79\n",
      "    load_throughput: 90397.543\n",
      "    load_time_ms: 110.578\n",
      "    sample_throughput: 65.758\n",
      "    sample_time_ms: 152011.897\n",
      "    update_time_ms: 8.761\n",
      "  timestamp: 1636397907\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6587364\n",
      "  training_iteration: 659\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   659</td><td style=\"text-align: right;\">          103472</td><td style=\"text-align: right;\">6587364</td><td style=\"text-align: right;\"> 4.06073</td><td style=\"text-align: right;\">               17.82</td><td style=\"text-align: right;\">               -2.13</td><td style=\"text-align: right;\">           92.0917</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6597360\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-01-01\n",
      "  done: false\n",
      "  episode_len_mean: 90.42727272727272\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000016\n",
      "  episode_reward_mean: 3.867000000000009\n",
      "  episode_reward_min: -1.3500000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 71317\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0488222814013817\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01176159091558544\n",
      "          policy_loss: -0.05700748407751576\n",
      "          total_loss: 0.10305491057901174\n",
      "          vf_explained_var: 0.9361528158187866\n",
      "          vf_loss: 0.1537562425224445\n",
      "    num_agent_steps_sampled: 6597360\n",
      "    num_agent_steps_trained: 6597360\n",
      "    num_steps_sampled: 6597360\n",
      "    num_steps_trained: 6597360\n",
      "  iterations_since_restore: 660\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.04590909090912\n",
      "    ram_util_percent: 58.07636363636363\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549788300410207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93385901872359\n",
      "    mean_inference_ms: 2.8534478440480795\n",
      "    mean_raw_obs_processing_ms: 3.6082301756041617\n",
      "  time_since_restore: 103626.8604388237\n",
      "  time_this_iter_s: 154.56061387062073\n",
      "  time_total_s: 103626.8604388237\n",
      "  timers:\n",
      "    learn_throughput: 935.865\n",
      "    learn_time_ms: 10681.025\n",
      "    load_throughput: 90310.542\n",
      "    load_time_ms: 110.685\n",
      "    sample_throughput: 65.986\n",
      "    sample_time_ms: 151486.176\n",
      "    update_time_ms: 9.655\n",
      "  timestamp: 1636398061\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6597360\n",
      "  training_iteration: 660\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   660</td><td style=\"text-align: right;\">          103627</td><td style=\"text-align: right;\">6597360</td><td style=\"text-align: right;\">   3.867</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -1.35</td><td style=\"text-align: right;\">           90.4273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6607356\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-04-20\n",
      "  done: false\n",
      "  episode_len_mean: 90.60909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.67000000000002\n",
      "  episode_reward_mean: 4.455090909090918\n",
      "  episode_reward_min: -1.1400000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 71427\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.045650729562482\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012647303857855619\n",
      "          policy_loss: -0.05408687591552734\n",
      "          total_loss: 0.1184812245468617\n",
      "          vf_explained_var: 0.9318872690200806\n",
      "          vf_loss: 0.1642124674609329\n",
      "    num_agent_steps_sampled: 6607356\n",
      "    num_agent_steps_trained: 6607356\n",
      "    num_steps_sampled: 6607356\n",
      "    num_steps_trained: 6607356\n",
      "  iterations_since_restore: 661\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.6095406360424\n",
      "    ram_util_percent: 58.13003533568903\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045522028593447346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93734077255536\n",
      "    mean_inference_ms: 2.8532526522167814\n",
      "    mean_raw_obs_processing_ms: 3.615514535363464\n",
      "  time_since_restore: 103825.12584209442\n",
      "  time_this_iter_s: 198.26540327072144\n",
      "  time_total_s: 103825.12584209442\n",
      "  timers:\n",
      "    learn_throughput: 935.347\n",
      "    learn_time_ms: 10686.94\n",
      "    load_throughput: 90443.993\n",
      "    load_time_ms: 110.521\n",
      "    sample_throughput: 64.064\n",
      "    sample_time_ms: 156032.378\n",
      "    update_time_ms: 10.125\n",
      "  timestamp: 1636398260\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6607356\n",
      "  training_iteration: 661\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   661</td><td style=\"text-align: right;\">          103825</td><td style=\"text-align: right;\">6607356</td><td style=\"text-align: right;\"> 4.45509</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           90.6091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6617352\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-07-11\n",
      "  done: false\n",
      "  episode_len_mean: 89.89285714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.44999999999996\n",
      "  episode_reward_mean: 3.442410714285722\n",
      "  episode_reward_min: -1.6400000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 71539\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.068394163225451\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011890022578185425\n",
      "          policy_loss: -0.057687324008498436\n",
      "          total_loss: 0.0862324164623124\n",
      "          vf_explained_var: 0.9361966848373413\n",
      "          vf_loss: 0.1375167246669149\n",
      "    num_agent_steps_sampled: 6617352\n",
      "    num_agent_steps_trained: 6617352\n",
      "    num_steps_sampled: 6617352\n",
      "    num_steps_trained: 6617352\n",
      "  iterations_since_restore: 662\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.2530612244898\n",
      "    ram_util_percent: 58.220408163265304\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045525610725700105\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94196780238919\n",
      "    mean_inference_ms: 2.853130322834013\n",
      "    mean_raw_obs_processing_ms: 3.61620283842944\n",
      "  time_since_restore: 103996.56870555878\n",
      "  time_this_iter_s: 171.44286346435547\n",
      "  time_total_s: 103996.56870555878\n",
      "  timers:\n",
      "    learn_throughput: 935.267\n",
      "    learn_time_ms: 10687.856\n",
      "    load_throughput: 90552.897\n",
      "    load_time_ms: 110.389\n",
      "    sample_throughput: 62.793\n",
      "    sample_time_ms: 159190.401\n",
      "    update_time_ms: 9.192\n",
      "  timestamp: 1636398431\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6617352\n",
      "  training_iteration: 662\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   662</td><td style=\"text-align: right;\">          103997</td><td style=\"text-align: right;\">6617352</td><td style=\"text-align: right;\"> 3.44241</td><td style=\"text-align: right;\">               16.45</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           89.8929</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6627348\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-09-57\n",
      "  done: false\n",
      "  episode_len_mean: 92.61111111111111\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.33000000000002\n",
      "  episode_reward_mean: 3.902500000000009\n",
      "  episode_reward_min: -1.400000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 71647\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0757303278670354\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013318360042443278\n",
      "          policy_loss: -0.05744982808828354\n",
      "          total_loss: 0.13740611928316135\n",
      "          vf_explained_var: 0.908545732498169\n",
      "          vf_loss: 0.18527236057716048\n",
      "    num_agent_steps_sampled: 6627348\n",
      "    num_agent_steps_trained: 6627348\n",
      "    num_steps_sampled: 6627348\n",
      "    num_steps_trained: 6627348\n",
      "  iterations_since_restore: 663\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.77203389830508\n",
      "    ram_util_percent: 58.121186440677974\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045538350080775676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94237111250892\n",
      "    mean_inference_ms: 2.853437707721216\n",
      "    mean_raw_obs_processing_ms: 3.617792727822565\n",
      "  time_since_restore: 104162.05711865425\n",
      "  time_this_iter_s: 165.48841309547424\n",
      "  time_total_s: 104162.05711865425\n",
      "  timers:\n",
      "    learn_throughput: 934.241\n",
      "    learn_time_ms: 10699.595\n",
      "    load_throughput: 90290.996\n",
      "    load_time_ms: 110.709\n",
      "    sample_throughput: 62.26\n",
      "    sample_time_ms: 160553.215\n",
      "    update_time_ms: 10.018\n",
      "  timestamp: 1636398597\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6627348\n",
      "  training_iteration: 663\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   663</td><td style=\"text-align: right;\">          104162</td><td style=\"text-align: right;\">6627348</td><td style=\"text-align: right;\">  3.9025</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           92.6111</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6637344\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-12-34\n",
      "  done: false\n",
      "  episode_len_mean: 91.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.980000000000015\n",
      "  episode_reward_mean: 4.571834862385331\n",
      "  episode_reward_min: -1.0300000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 71756\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.05213249371602\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01220780169017648\n",
      "          policy_loss: -0.05517318899400978\n",
      "          total_loss: 0.11117317619550432\n",
      "          vf_explained_var: 0.946626603603363\n",
      "          vf_loss: 0.15905679054399077\n",
      "    num_agent_steps_sampled: 6637344\n",
      "    num_agent_steps_trained: 6637344\n",
      "    num_steps_sampled: 6637344\n",
      "    num_steps_trained: 6637344\n",
      "  iterations_since_restore: 664\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.54017857142857\n",
      "    ram_util_percent: 58.193303571428565\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554468363213337\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94367864859145\n",
      "    mean_inference_ms: 2.8531414337372882\n",
      "    mean_raw_obs_processing_ms: 3.618131676724665\n",
      "  time_since_restore: 104318.80536651611\n",
      "  time_this_iter_s: 156.74824786186218\n",
      "  time_total_s: 104318.80536651611\n",
      "  timers:\n",
      "    learn_throughput: 933.76\n",
      "    learn_time_ms: 10705.108\n",
      "    load_throughput: 90297.899\n",
      "    load_time_ms: 110.7\n",
      "    sample_throughput: 63.32\n",
      "    sample_time_ms: 157864.386\n",
      "    update_time_ms: 10.226\n",
      "  timestamp: 1636398754\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6637344\n",
      "  training_iteration: 664\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   664</td><td style=\"text-align: right;\">          104319</td><td style=\"text-align: right;\">6637344</td><td style=\"text-align: right;\"> 4.57183</td><td style=\"text-align: right;\">               14.98</td><td style=\"text-align: right;\">               -1.03</td><td style=\"text-align: right;\">                91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6647340\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-14-57\n",
      "  done: false\n",
      "  episode_len_mean: 93.25925925925925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.52000000000002\n",
      "  episode_reward_mean: 3.7680555555555637\n",
      "  episode_reward_min: -1.560000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 71864\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0838170761736032\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012471645043517622\n",
      "          policy_loss: -0.06009361004440958\n",
      "          total_loss: 0.11231807237252212\n",
      "          vf_explained_var: 0.9350976943969727\n",
      "          vf_loss: 0.1648378856941803\n",
      "    num_agent_steps_sampled: 6647340\n",
      "    num_agent_steps_trained: 6647340\n",
      "    num_steps_sampled: 6647340\n",
      "    num_steps_trained: 6647340\n",
      "  iterations_since_restore: 665\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9390243902439\n",
      "    ram_util_percent: 58.085853658536585\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552815275380103\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94609155159965\n",
      "    mean_inference_ms: 2.853320827717578\n",
      "    mean_raw_obs_processing_ms: 3.612507279226261\n",
      "  time_since_restore: 104462.38198161125\n",
      "  time_this_iter_s: 143.57661509513855\n",
      "  time_total_s: 104462.38198161125\n",
      "  timers:\n",
      "    learn_throughput: 933.549\n",
      "    learn_time_ms: 10707.529\n",
      "    load_throughput: 90442.12\n",
      "    load_time_ms: 110.524\n",
      "    sample_throughput: 63.677\n",
      "    sample_time_ms: 156980.685\n",
      "    update_time_ms: 9.941\n",
      "  timestamp: 1636398897\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6647340\n",
      "  training_iteration: 665\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   665</td><td style=\"text-align: right;\">          104462</td><td style=\"text-align: right;\">6647340</td><td style=\"text-align: right;\"> 3.76806</td><td style=\"text-align: right;\">               16.52</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           93.2593</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6657336\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-17-43\n",
      "  done: false\n",
      "  episode_len_mean: 90.60909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.750000000000014\n",
      "  episode_reward_mean: 3.498272727272735\n",
      "  episode_reward_min: -1.6100000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 71974\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.039556627497714\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01131186565481237\n",
      "          policy_loss: -0.055956165325374174\n",
      "          total_loss: 0.11080751954617664\n",
      "          vf_explained_var: 0.9292172789573669\n",
      "          vf_loss: 0.16138940789601486\n",
      "    num_agent_steps_sampled: 6657336\n",
      "    num_agent_steps_trained: 6657336\n",
      "    num_steps_sampled: 6657336\n",
      "    num_steps_trained: 6657336\n",
      "  iterations_since_restore: 666\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.72838983050848\n",
      "    ram_util_percent: 58.13177966101694\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552543710413965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.946796145575284\n",
      "    mean_inference_ms: 2.853362404047482\n",
      "    mean_raw_obs_processing_ms: 3.6128063236876167\n",
      "  time_since_restore: 104627.83639574051\n",
      "  time_this_iter_s: 165.4544141292572\n",
      "  time_total_s: 104627.83639574051\n",
      "  timers:\n",
      "    learn_throughput: 932.923\n",
      "    learn_time_ms: 10714.707\n",
      "    load_throughput: 90502.817\n",
      "    load_time_ms: 110.45\n",
      "    sample_throughput: 63.217\n",
      "    sample_time_ms: 158121.036\n",
      "    update_time_ms: 10.026\n",
      "  timestamp: 1636399063\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6657336\n",
      "  training_iteration: 666\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   666</td><td style=\"text-align: right;\">          104628</td><td style=\"text-align: right;\">6657336</td><td style=\"text-align: right;\"> 3.49827</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           90.6091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6667332\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-20-33\n",
      "  done: false\n",
      "  episode_len_mean: 87.09482758620689\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.890000000000013\n",
      "  episode_reward_mean: 3.7704310344827676\n",
      "  episode_reward_min: -1.1600000000000006\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 72090\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0482063471761522\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011337388518588122\n",
      "          policy_loss: -0.05829283062559672\n",
      "          total_loss: 0.08309171022051293\n",
      "          vf_explained_var: 0.9395766854286194\n",
      "          vf_loss: 0.13603861533009853\n",
      "    num_agent_steps_sampled: 6667332\n",
      "    num_agent_steps_trained: 6667332\n",
      "    num_steps_sampled: 6667332\n",
      "    num_steps_trained: 6667332\n",
      "  iterations_since_restore: 667\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.89218106995884\n",
      "    ram_util_percent: 58.090946502057605\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045516303794934654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.94976914307826\n",
      "    mean_inference_ms: 2.8531831031046946\n",
      "    mean_raw_obs_processing_ms: 3.614536321577284\n",
      "  time_since_restore: 104798.17450547218\n",
      "  time_this_iter_s: 170.3381097316742\n",
      "  time_total_s: 104798.17450547218\n",
      "  timers:\n",
      "    learn_throughput: 932.785\n",
      "    learn_time_ms: 10716.297\n",
      "    load_throughput: 90790.617\n",
      "    load_time_ms: 110.099\n",
      "    sample_throughput: 63.537\n",
      "    sample_time_ms: 157326.485\n",
      "    update_time_ms: 10.491\n",
      "  timestamp: 1636399233\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6667332\n",
      "  training_iteration: 667\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   667</td><td style=\"text-align: right;\">          104798</td><td style=\"text-align: right;\">6667332</td><td style=\"text-align: right;\"> 3.77043</td><td style=\"text-align: right;\">               10.89</td><td style=\"text-align: right;\">               -1.16</td><td style=\"text-align: right;\">           87.0948</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6677328\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-23-08\n",
      "  done: false\n",
      "  episode_len_mean: 91.13761467889908\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000015\n",
      "  episode_reward_mean: 3.713302752293586\n",
      "  episode_reward_min: -1.4700000000000009\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 72199\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.052867533916082\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012989955181422444\n",
      "          policy_loss: -0.05958310084767703\n",
      "          total_loss: 0.11396348226624421\n",
      "          vf_explained_var: 0.9297605156898499\n",
      "          vf_loss: 0.1644825162143152\n",
      "    num_agent_steps_sampled: 6677328\n",
      "    num_agent_steps_trained: 6677328\n",
      "    num_steps_sampled: 6677328\n",
      "    num_steps_trained: 6677328\n",
      "  iterations_since_restore: 668\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.0714932126697\n",
      "    ram_util_percent: 58.14162895927601\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045535828587828314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95364414047753\n",
      "    mean_inference_ms: 2.8533532418893492\n",
      "    mean_raw_obs_processing_ms: 3.6124558547580556\n",
      "  time_since_restore: 104953.43795967102\n",
      "  time_this_iter_s: 155.26345419883728\n",
      "  time_total_s: 104953.43795967102\n",
      "  timers:\n",
      "    learn_throughput: 932.204\n",
      "    learn_time_ms: 10722.978\n",
      "    load_throughput: 90817.855\n",
      "    load_time_ms: 110.066\n",
      "    sample_throughput: 64.829\n",
      "    sample_time_ms: 154191.015\n",
      "    update_time_ms: 10.866\n",
      "  timestamp: 1636399388\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6677328\n",
      "  training_iteration: 668\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   668</td><td style=\"text-align: right;\">          104953</td><td style=\"text-align: right;\">6677328</td><td style=\"text-align: right;\">  3.7133</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           91.1376</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6687324\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-25-34\n",
      "  done: false\n",
      "  episode_len_mean: 91.50925925925925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.54999999999999\n",
      "  episode_reward_mean: 4.513796296296305\n",
      "  episode_reward_min: -1.2799999999999978\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 72307\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0488787742761465\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012592684303330083\n",
      "          policy_loss: -0.05896738350598348\n",
      "          total_loss: 0.1251894233159275\n",
      "          vf_explained_var: 0.9376405477523804\n",
      "          vf_loss: 0.1759578850120306\n",
      "    num_agent_steps_sampled: 6687324\n",
      "    num_agent_steps_trained: 6687324\n",
      "    num_steps_sampled: 6687324\n",
      "    num_steps_trained: 6687324\n",
      "  iterations_since_restore: 669\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.65865384615384\n",
      "    ram_util_percent: 58.024038461538446\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551751485393491\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95723132832419\n",
      "    mean_inference_ms: 2.8531762898026036\n",
      "    mean_raw_obs_processing_ms: 3.60913759951987\n",
      "  time_since_restore: 105098.77539992332\n",
      "  time_this_iter_s: 145.33744025230408\n",
      "  time_total_s: 105098.77539992332\n",
      "  timers:\n",
      "    learn_throughput: 932.155\n",
      "    learn_time_ms: 10723.536\n",
      "    load_throughput: 90719.738\n",
      "    load_time_ms: 110.186\n",
      "    sample_throughput: 65.855\n",
      "    sample_time_ms: 151788.496\n",
      "    update_time_ms: 11.668\n",
      "  timestamp: 1636399534\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6687324\n",
      "  training_iteration: 669\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   669</td><td style=\"text-align: right;\">          105099</td><td style=\"text-align: right;\">6687324</td><td style=\"text-align: right;\">  4.5138</td><td style=\"text-align: right;\">               20.55</td><td style=\"text-align: right;\">               -1.28</td><td style=\"text-align: right;\">           91.5093</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6697320\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-28-13\n",
      "  done: false\n",
      "  episode_len_mean: 88.87610619469027\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.570000000000018\n",
      "  episode_reward_mean: 3.9998230088495665\n",
      "  episode_reward_min: -1.5000000000000002\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 72420\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0482296967098854\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011904552048491007\n",
      "          policy_loss: -0.06024129504385667\n",
      "          total_loss: 0.10008947127458886\n",
      "          vf_explained_var: 0.9348509907722473\n",
      "          vf_loss: 0.15369300558749172\n",
      "    num_agent_steps_sampled: 6697320\n",
      "    num_agent_steps_trained: 6697320\n",
      "    num_steps_sampled: 6697320\n",
      "    num_steps_trained: 6697320\n",
      "  iterations_since_restore: 670\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.83815789473684\n",
      "    ram_util_percent: 57.85570175438596\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551481595072745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96032177858584\n",
      "    mean_inference_ms: 2.8532380886486703\n",
      "    mean_raw_obs_processing_ms: 3.6122128817442434\n",
      "  time_since_restore: 105258.39910387993\n",
      "  time_this_iter_s: 159.623703956604\n",
      "  time_total_s: 105258.39910387993\n",
      "  timers:\n",
      "    learn_throughput: 931.839\n",
      "    learn_time_ms: 10727.179\n",
      "    load_throughput: 90703.722\n",
      "    load_time_ms: 110.205\n",
      "    sample_throughput: 65.637\n",
      "    sample_time_ms: 152291.737\n",
      "    update_time_ms: 10.768\n",
      "  timestamp: 1636399693\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6697320\n",
      "  training_iteration: 670\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   670</td><td style=\"text-align: right;\">          105258</td><td style=\"text-align: right;\">6697320</td><td style=\"text-align: right;\"> 3.99982</td><td style=\"text-align: right;\">               12.57</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           88.8761</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6707316\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 87.34782608695652\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.410000000000014\n",
      "  episode_reward_mean: 4.022086956521747\n",
      "  episode_reward_min: -1.3800000000000006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 72535\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.043817471744668\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01204184463728615\n",
      "          policy_loss: -0.06041968185932208\n",
      "          total_loss: 0.10922047789407592\n",
      "          vf_explained_var: 0.93963223695755\n",
      "          vf_loss: 0.16264550572531855\n",
      "    num_agent_steps_sampled: 6707316\n",
      "    num_agent_steps_trained: 6707316\n",
      "    num_steps_sampled: 6707316\n",
      "    num_steps_trained: 6707316\n",
      "  iterations_since_restore: 671\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.3578125\n",
      "    ram_util_percent: 58.186718750000004\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554435184039997\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96234815125482\n",
      "    mean_inference_ms: 2.8532702135115238\n",
      "    mean_raw_obs_processing_ms: 3.6176719282322694\n",
      "  time_since_restore: 105438.29692268372\n",
      "  time_this_iter_s: 179.89781880378723\n",
      "  time_total_s: 105438.29692268372\n",
      "  timers:\n",
      "    learn_throughput: 932.229\n",
      "    learn_time_ms: 10722.686\n",
      "    load_throughput: 90718.697\n",
      "    load_time_ms: 110.187\n",
      "    sample_throughput: 66.437\n",
      "    sample_time_ms: 150459.411\n",
      "    update_time_ms: 10.603\n",
      "  timestamp: 1636399873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6707316\n",
      "  training_iteration: 671\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   671</td><td style=\"text-align: right;\">          105438</td><td style=\"text-align: right;\">6707316</td><td style=\"text-align: right;\"> 4.02209</td><td style=\"text-align: right;\">               14.41</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           87.3478</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6717312\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-33-50\n",
      "  done: false\n",
      "  episode_len_mean: 90.85454545454546\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000011\n",
      "  episode_reward_mean: 4.538000000000009\n",
      "  episode_reward_min: -1.5400000000000011\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 72645\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.051485375359527\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013518658704588902\n",
      "          policy_loss: -0.05637620610431728\n",
      "          total_loss: 0.12390483755490973\n",
      "          vf_explained_var: 0.9349269270896912\n",
      "          vf_loss: 0.16999870168092923\n",
      "    num_agent_steps_sampled: 6717312\n",
      "    num_agent_steps_trained: 6717312\n",
      "    num_steps_sampled: 6717312\n",
      "    num_steps_trained: 6717312\n",
      "  iterations_since_restore: 672\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.70493273542601\n",
      "    ram_util_percent: 58.13094170403586\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045518871032293004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.963588837174264\n",
      "    mean_inference_ms: 2.853362437108935\n",
      "    mean_raw_obs_processing_ms: 3.6146194597313475\n",
      "  time_since_restore: 105594.46563005447\n",
      "  time_this_iter_s: 156.16870737075806\n",
      "  time_total_s: 105594.46563005447\n",
      "  timers:\n",
      "    learn_throughput: 932.444\n",
      "    learn_time_ms: 10720.217\n",
      "    load_throughput: 90558.412\n",
      "    load_time_ms: 110.382\n",
      "    sample_throughput: 67.117\n",
      "    sample_time_ms: 148934.296\n",
      "    update_time_ms: 10.614\n",
      "  timestamp: 1636400030\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6717312\n",
      "  training_iteration: 672\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   672</td><td style=\"text-align: right;\">          105594</td><td style=\"text-align: right;\">6717312</td><td style=\"text-align: right;\">   4.538</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           90.8545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6727308\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-36-41\n",
      "  done: false\n",
      "  episode_len_mean: 89.29464285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.89000000000002\n",
      "  episode_reward_mean: 4.4853571428571515\n",
      "  episode_reward_min: -1.4100000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 72757\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0140828080666373\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01305033847750287\n",
      "          policy_loss: -0.057715468684959616\n",
      "          total_loss: 0.13676678400295667\n",
      "          vf_explained_var: 0.9386956691741943\n",
      "          vf_loss: 0.18489277753978967\n",
      "    num_agent_steps_sampled: 6727308\n",
      "    num_agent_steps_trained: 6727308\n",
      "    num_steps_sampled: 6727308\n",
      "    num_steps_trained: 6727308\n",
      "  iterations_since_restore: 673\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.98606557377049\n",
      "    ram_util_percent: 57.96516393442622\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045529859307500954\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.965332725752326\n",
      "    mean_inference_ms: 2.853322410017231\n",
      "    mean_raw_obs_processing_ms: 3.618491867424775\n",
      "  time_since_restore: 105765.32530379295\n",
      "  time_this_iter_s: 170.85967373847961\n",
      "  time_total_s: 105765.32530379295\n",
      "  timers:\n",
      "    learn_throughput: 932.601\n",
      "    learn_time_ms: 10718.414\n",
      "    load_throughput: 90781.535\n",
      "    load_time_ms: 110.11\n",
      "    sample_throughput: 66.874\n",
      "    sample_time_ms: 149474.551\n",
      "    update_time_ms: 10.029\n",
      "  timestamp: 1636400201\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6727308\n",
      "  training_iteration: 673\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   673</td><td style=\"text-align: right;\">          105765</td><td style=\"text-align: right;\">6727308</td><td style=\"text-align: right;\"> 4.48536</td><td style=\"text-align: right;\">               16.89</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           89.2946</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6737304\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-39-17\n",
      "  done: false\n",
      "  episode_len_mean: 90.47272727272727\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000011\n",
      "  episode_reward_mean: 4.112636363636372\n",
      "  episode_reward_min: -0.9800000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 72867\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.037155901672494\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012201254191969848\n",
      "          policy_loss: -0.054956895652680825\n",
      "          total_loss: 0.12824161612293405\n",
      "          vf_explained_var: 0.9315275549888611\n",
      "          vf_loss: 0.17577408788582452\n",
      "    num_agent_steps_sampled: 6737304\n",
      "    num_agent_steps_trained: 6737304\n",
      "    num_steps_sampled: 6737304\n",
      "    num_steps_trained: 6737304\n",
      "  iterations_since_restore: 674\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.04977578475335\n",
      "    ram_util_percent: 58.16860986547085\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552124606763872\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.96746669116319\n",
      "    mean_inference_ms: 2.8533400988003828\n",
      "    mean_raw_obs_processing_ms: 3.6163198419120364\n",
      "  time_since_restore: 105921.66706466675\n",
      "  time_this_iter_s: 156.34176087379456\n",
      "  time_total_s: 105921.66706466675\n",
      "  timers:\n",
      "    learn_throughput: 933.304\n",
      "    learn_time_ms: 10710.339\n",
      "    load_throughput: 90753.73\n",
      "    load_time_ms: 110.144\n",
      "    sample_throughput: 66.889\n",
      "    sample_time_ms: 149441.846\n",
      "    update_time_ms: 10.188\n",
      "  timestamp: 1636400357\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6737304\n",
      "  training_iteration: 674\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   674</td><td style=\"text-align: right;\">          105922</td><td style=\"text-align: right;\">6737304</td><td style=\"text-align: right;\"> 4.11264</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">               -0.98</td><td style=\"text-align: right;\">           90.4727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6747300\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-41-54\n",
      "  done: false\n",
      "  episode_len_mean: 89.625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000019\n",
      "  episode_reward_mean: 3.841785714285723\n",
      "  episode_reward_min: -1.1700000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 72979\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0255638871437465\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011488027854503693\n",
      "          policy_loss: -0.05605028050386498\n",
      "          total_loss: 0.10603025279079492\n",
      "          vf_explained_var: 0.9226750135421753\n",
      "          vf_loss: 0.15616500603401254\n",
      "    num_agent_steps_sampled: 6747300\n",
      "    num_agent_steps_trained: 6747300\n",
      "    num_steps_sampled: 6747300\n",
      "    num_steps_trained: 6747300\n",
      "  iterations_since_restore: 675\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.93733333333334\n",
      "    ram_util_percent: 58.1711111111111\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045543384323602575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.971330653253865\n",
      "    mean_inference_ms: 2.853486606362527\n",
      "    mean_raw_obs_processing_ms: 3.614428886414437\n",
      "  time_since_restore: 106079.25134634972\n",
      "  time_this_iter_s: 157.58428168296814\n",
      "  time_total_s: 106079.25134634972\n",
      "  timers:\n",
      "    learn_throughput: 933.476\n",
      "    learn_time_ms: 10708.362\n",
      "    load_throughput: 90668.042\n",
      "    load_time_ms: 110.248\n",
      "    sample_throughput: 66.267\n",
      "    sample_time_ms: 150844.663\n",
      "    update_time_ms: 10.014\n",
      "  timestamp: 1636400514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6747300\n",
      "  training_iteration: 675\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   675</td><td style=\"text-align: right;\">          106079</td><td style=\"text-align: right;\">6747300</td><td style=\"text-align: right;\"> 3.84179</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">               -1.17</td><td style=\"text-align: right;\">            89.625</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6757296\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-44-47\n",
      "  done: false\n",
      "  episode_len_mean: 89.84821428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.44999999999995\n",
      "  episode_reward_mean: 4.28642857142858\n",
      "  episode_reward_min: -1.3800000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 73091\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.035893272029029\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012408182969954948\n",
      "          policy_loss: -0.05811852166731643\n",
      "          total_loss: 0.11473704184660226\n",
      "          vf_explained_var: 0.9352589249610901\n",
      "          vf_loss: 0.16494710441901644\n",
      "    num_agent_steps_sampled: 6757296\n",
      "    num_agent_steps_trained: 6757296\n",
      "    num_steps_sampled: 6757296\n",
      "    num_steps_trained: 6757296\n",
      "  iterations_since_restore: 676\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.83821138211384\n",
      "    ram_util_percent: 57.976422764227635\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455112013544992\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97033498465887\n",
      "    mean_inference_ms: 2.8532216034894566\n",
      "    mean_raw_obs_processing_ms: 3.6205420481572506\n",
      "  time_since_restore: 106251.24840474129\n",
      "  time_this_iter_s: 171.99705839157104\n",
      "  time_total_s: 106251.24840474129\n",
      "  timers:\n",
      "    learn_throughput: 933.731\n",
      "    learn_time_ms: 10705.442\n",
      "    load_throughput: 90588.545\n",
      "    load_time_ms: 110.345\n",
      "    sample_throughput: 65.979\n",
      "    sample_time_ms: 151501.736\n",
      "    update_time_ms: 10.178\n",
      "  timestamp: 1636400687\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6757296\n",
      "  training_iteration: 676\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   676</td><td style=\"text-align: right;\">          106251</td><td style=\"text-align: right;\">6757296</td><td style=\"text-align: right;\"> 4.28643</td><td style=\"text-align: right;\">               16.45</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           89.8482</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6767292\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-47-26\n",
      "  done: false\n",
      "  episode_len_mean: 91.12844036697248\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000016\n",
      "  episode_reward_mean: 3.611834862385329\n",
      "  episode_reward_min: -1.5200000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 73200\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0346881648414157\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011596301816615903\n",
      "          policy_loss: -0.06048599410897646\n",
      "          total_loss: 0.088369267522238\n",
      "          vf_explained_var: 0.9366360902786255\n",
      "          vf_loss: 0.1427843184520801\n",
      "    num_agent_steps_sampled: 6767292\n",
      "    num_agent_steps_trained: 6767292\n",
      "    num_steps_sampled: 6767292\n",
      "    num_steps_trained: 6767292\n",
      "  iterations_since_restore: 677\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.03656387665198\n",
      "    ram_util_percent: 58.07621145374449\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553226411962658\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.971802412943696\n",
      "    mean_inference_ms: 2.8532685607505095\n",
      "    mean_raw_obs_processing_ms: 3.6206974185545278\n",
      "  time_since_restore: 106410.47408533096\n",
      "  time_this_iter_s: 159.2256805896759\n",
      "  time_total_s: 106410.47408533096\n",
      "  timers:\n",
      "    learn_throughput: 934.288\n",
      "    learn_time_ms: 10699.058\n",
      "    load_throughput: 90590.835\n",
      "    load_time_ms: 110.342\n",
      "    sample_throughput: 66.464\n",
      "    sample_time_ms: 150396.356\n",
      "    update_time_ms: 10.46\n",
      "  timestamp: 1636400846\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6767292\n",
      "  training_iteration: 677\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   677</td><td style=\"text-align: right;\">          106410</td><td style=\"text-align: right;\">6767292</td><td style=\"text-align: right;\"> 3.61183</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">               -1.52</td><td style=\"text-align: right;\">           91.1284</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6777288\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-50-08\n",
      "  done: false\n",
      "  episode_len_mean: 92.27777777777777\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.790000000000013\n",
      "  episode_reward_mean: 4.669907407407418\n",
      "  episode_reward_min: -1.2800000000000002\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 73308\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0359113259193227\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012223492169840108\n",
      "          policy_loss: -0.060205752736864945\n",
      "          total_loss: 0.11451310245559002\n",
      "          vf_explained_var: 0.9384337067604065\n",
      "          vf_loss: 0.16723132592458756\n",
      "    num_agent_steps_sampled: 6777288\n",
      "    num_agent_steps_trained: 6777288\n",
      "    num_steps_sampled: 6777288\n",
      "    num_steps_trained: 6777288\n",
      "  iterations_since_restore: 678\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.72813852813853\n",
      "    ram_util_percent: 58.29523809523808\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553537254124052\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97273431969026\n",
      "    mean_inference_ms: 2.853097217756162\n",
      "    mean_raw_obs_processing_ms: 3.621427683360913\n",
      "  time_since_restore: 106572.48465871811\n",
      "  time_this_iter_s: 162.010573387146\n",
      "  time_total_s: 106572.48465871811\n",
      "  timers:\n",
      "    learn_throughput: 934.658\n",
      "    learn_time_ms: 10694.816\n",
      "    load_throughput: 90591.892\n",
      "    load_time_ms: 110.341\n",
      "    sample_throughput: 66.165\n",
      "    sample_time_ms: 151075.876\n",
      "    update_time_ms: 10.047\n",
      "  timestamp: 1636401008\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6777288\n",
      "  training_iteration: 678\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   678</td><td style=\"text-align: right;\">          106572</td><td style=\"text-align: right;\">6777288</td><td style=\"text-align: right;\"> 4.66991</td><td style=\"text-align: right;\">               12.79</td><td style=\"text-align: right;\">               -1.28</td><td style=\"text-align: right;\">           92.2778</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6787284\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-53-07\n",
      "  done: false\n",
      "  episode_len_mean: 91.14678899082568\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.16999999999995\n",
      "  episode_reward_mean: 4.174678899082577\n",
      "  episode_reward_min: -1.4600000000000004\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 73417\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0409505027991073\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01365069693945125\n",
      "          policy_loss: -0.05757736635641155\n",
      "          total_loss: 0.11907471570098757\n",
      "          vf_explained_var: 0.9348528385162354\n",
      "          vf_loss: 0.1659635922210848\n",
      "    num_agent_steps_sampled: 6787284\n",
      "    num_agent_steps_trained: 6787284\n",
      "    num_steps_sampled: 6787284\n",
      "    num_steps_trained: 6787284\n",
      "  iterations_since_restore: 679\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.51796875\n",
      "    ram_util_percent: 58.114062499999996\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045510784567843895\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97367574037032\n",
      "    mean_inference_ms: 2.8531640760901267\n",
      "    mean_raw_obs_processing_ms: 3.6243716136463906\n",
      "  time_since_restore: 106751.95542383194\n",
      "  time_this_iter_s: 179.47076511383057\n",
      "  time_total_s: 106751.95542383194\n",
      "  timers:\n",
      "    learn_throughput: 934.755\n",
      "    learn_time_ms: 10693.707\n",
      "    load_throughput: 90679.24\n",
      "    load_time_ms: 110.235\n",
      "    sample_throughput: 64.703\n",
      "    sample_time_ms: 154490.379\n",
      "    update_time_ms: 10.032\n",
      "  timestamp: 1636401187\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6787284\n",
      "  training_iteration: 679\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   679</td><td style=\"text-align: right;\">          106752</td><td style=\"text-align: right;\">6787284</td><td style=\"text-align: right;\"> 4.17468</td><td style=\"text-align: right;\">               18.17</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           91.1468</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6797280\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-55-46\n",
      "  done: false\n",
      "  episode_len_mean: 90.82882882882883\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.249999999999932\n",
      "  episode_reward_mean: 4.287927927927936\n",
      "  episode_reward_min: -0.7300000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 73528\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.037274308489938\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012596058579502512\n",
      "          policy_loss: -0.06029103222605573\n",
      "          total_loss: 0.12158343871959891\n",
      "          vf_explained_var: 0.9329907298088074\n",
      "          vf_loss: 0.17355181750897158\n",
      "    num_agent_steps_sampled: 6797280\n",
      "    num_agent_steps_trained: 6797280\n",
      "    num_steps_sampled: 6797280\n",
      "    num_steps_trained: 6797280\n",
      "  iterations_since_restore: 680\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.79513274336281\n",
      "    ram_util_percent: 58.1358407079646\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551357854187892\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97725450659321\n",
      "    mean_inference_ms: 2.8530667249875177\n",
      "    mean_raw_obs_processing_ms: 3.623838826276022\n",
      "  time_since_restore: 106910.69526124\n",
      "  time_this_iter_s: 158.7398374080658\n",
      "  time_total_s: 106910.69526124\n",
      "  timers:\n",
      "    learn_throughput: 935.057\n",
      "    learn_time_ms: 10690.261\n",
      "    load_throughput: 90830.526\n",
      "    load_time_ms: 110.051\n",
      "    sample_throughput: 64.739\n",
      "    sample_time_ms: 154405.281\n",
      "    update_time_ms: 10.793\n",
      "  timestamp: 1636401346\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6797280\n",
      "  training_iteration: 680\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   680</td><td style=\"text-align: right;\">          106911</td><td style=\"text-align: right;\">6797280</td><td style=\"text-align: right;\"> 4.28793</td><td style=\"text-align: right;\">               18.25</td><td style=\"text-align: right;\">               -0.73</td><td style=\"text-align: right;\">           90.8288</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6807276\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_19-58-10\n",
      "  done: false\n",
      "  episode_len_mean: 92.4954128440367\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.479999999999933\n",
      "  episode_reward_mean: 3.7078899082568886\n",
      "  episode_reward_min: -1.4200000000000004\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 73637\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.068667156268389\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012161456844881176\n",
      "          policy_loss: -0.05299088796361899\n",
      "          total_loss: 0.1241942315752435\n",
      "          vf_explained_var: 0.9226062893867493\n",
      "          vf_loss: 0.17016647160690054\n",
      "    num_agent_steps_sampled: 6807276\n",
      "    num_agent_steps_trained: 6807276\n",
      "    num_steps_sampled: 6807276\n",
      "    num_steps_trained: 6807276\n",
      "  iterations_since_restore: 681\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89174757281552\n",
      "    ram_util_percent: 58.12815533980583\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550895811053002\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98064485235156\n",
      "    mean_inference_ms: 2.8532526082895413\n",
      "    mean_raw_obs_processing_ms: 3.6184338517473353\n",
      "  time_since_restore: 107054.37282419205\n",
      "  time_this_iter_s: 143.67756295204163\n",
      "  time_total_s: 107054.37282419205\n",
      "  timers:\n",
      "    learn_throughput: 934.873\n",
      "    learn_time_ms: 10692.361\n",
      "    load_throughput: 90959.639\n",
      "    load_time_ms: 109.895\n",
      "    sample_throughput: 66.295\n",
      "    sample_time_ms: 150780.939\n",
      "    update_time_ms: 11.335\n",
      "  timestamp: 1636401490\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6807276\n",
      "  training_iteration: 681\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   681</td><td style=\"text-align: right;\">          107054</td><td style=\"text-align: right;\">6807276</td><td style=\"text-align: right;\"> 3.70789</td><td style=\"text-align: right;\">               16.48</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           92.4954</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6817272\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-01-05\n",
      "  done: false\n",
      "  episode_len_mean: 92.95327102803738\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.03000000000001\n",
      "  episode_reward_mean: 4.2073831775701045\n",
      "  episode_reward_min: -1.560000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 73744\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0676602309585634\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011933510291809916\n",
      "          policy_loss: -0.05963562399339981\n",
      "          total_loss: 0.11888500071870975\n",
      "          vf_explained_var: 0.9285861253738403\n",
      "          vf_loss: 0.1720111978534832\n",
      "    num_agent_steps_sampled: 6817272\n",
      "    num_agent_steps_trained: 6817272\n",
      "    num_steps_sampled: 6817272\n",
      "    num_steps_trained: 6817272\n",
      "  iterations_since_restore: 682\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.896\n",
      "    ram_util_percent: 58.104\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551869696520416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98387191349417\n",
      "    mean_inference_ms: 2.853355165973669\n",
      "    mean_raw_obs_processing_ms: 3.619355576784774\n",
      "  time_since_restore: 107229.73973870277\n",
      "  time_this_iter_s: 175.36691451072693\n",
      "  time_total_s: 107229.73973870277\n",
      "  timers:\n",
      "    learn_throughput: 934.733\n",
      "    learn_time_ms: 10693.965\n",
      "    load_throughput: 91164.443\n",
      "    load_time_ms: 109.648\n",
      "    sample_throughput: 65.462\n",
      "    sample_time_ms: 152699.528\n",
      "    update_time_ms: 11.169\n",
      "  timestamp: 1636401665\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6817272\n",
      "  training_iteration: 682\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   682</td><td style=\"text-align: right;\">          107230</td><td style=\"text-align: right;\">6817272</td><td style=\"text-align: right;\"> 4.20738</td><td style=\"text-align: right;\">               13.03</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           92.9533</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6827268\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-03-42\n",
      "  done: false\n",
      "  episode_len_mean: 91.53703703703704\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.080000000000014\n",
      "  episode_reward_mean: 3.8485185185185276\n",
      "  episode_reward_min: -1.3300000000000003\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 73852\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0524885448635133\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01171596239164418\n",
      "          policy_loss: -0.05844462987067353\n",
      "          total_loss: 0.08984246070170378\n",
      "          vf_explained_var: 0.9414390325546265\n",
      "          vf_loss: 0.1421215483600385\n",
      "    num_agent_steps_sampled: 6827268\n",
      "    num_agent_steps_trained: 6827268\n",
      "    num_steps_sampled: 6827268\n",
      "    num_steps_trained: 6827268\n",
      "  iterations_since_restore: 683\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.7659192825112\n",
      "    ram_util_percent: 58.055156950672625\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554095073064917\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98687137933275\n",
      "    mean_inference_ms: 2.8533599098718763\n",
      "    mean_raw_obs_processing_ms: 3.6189010418278373\n",
      "  time_since_restore: 107386.09269428253\n",
      "  time_this_iter_s: 156.3529555797577\n",
      "  time_total_s: 107386.09269428253\n",
      "  timers:\n",
      "    learn_throughput: 935.517\n",
      "    learn_time_ms: 10685.001\n",
      "    load_throughput: 91162.738\n",
      "    load_time_ms: 109.65\n",
      "    sample_throughput: 66.086\n",
      "    sample_time_ms: 151257.164\n",
      "    update_time_ms: 11.397\n",
      "  timestamp: 1636401822\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6827268\n",
      "  training_iteration: 683\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   683</td><td style=\"text-align: right;\">          107386</td><td style=\"text-align: right;\">6827268</td><td style=\"text-align: right;\"> 3.84852</td><td style=\"text-align: right;\">               13.08</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">            91.537</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6837264\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-06-16\n",
      "  done: false\n",
      "  episode_len_mean: 91.8256880733945\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.750000000000014\n",
      "  episode_reward_mean: 4.0365137614679\n",
      "  episode_reward_min: -1.2100000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 73961\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.04130304195942\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012998302929249287\n",
      "          policy_loss: -0.055972027014463376\n",
      "          total_loss: 0.13435903646561326\n",
      "          vf_explained_var: 0.9238901138305664\n",
      "          vf_loss: 0.18113233413005997\n",
      "    num_agent_steps_sampled: 6837264\n",
      "    num_agent_steps_trained: 6837264\n",
      "    num_steps_sampled: 6837264\n",
      "    num_steps_trained: 6837264\n",
      "  iterations_since_restore: 684\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.80090909090909\n",
      "    ram_util_percent: 58.19727272727272\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045507270364252686\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98778293268613\n",
      "    mean_inference_ms: 2.853303592281931\n",
      "    mean_raw_obs_processing_ms: 3.615898864872041\n",
      "  time_since_restore: 107540.49840831757\n",
      "  time_this_iter_s: 154.40571403503418\n",
      "  time_total_s: 107540.49840831757\n",
      "  timers:\n",
      "    learn_throughput: 935.281\n",
      "    learn_time_ms: 10687.694\n",
      "    load_throughput: 91430.226\n",
      "    load_time_ms: 109.329\n",
      "    sample_throughput: 66.172\n",
      "    sample_time_ms: 151061.169\n",
      "    update_time_ms: 11.322\n",
      "  timestamp: 1636401976\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6837264\n",
      "  training_iteration: 684\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   684</td><td style=\"text-align: right;\">          107540</td><td style=\"text-align: right;\">6837264</td><td style=\"text-align: right;\"> 4.03651</td><td style=\"text-align: right;\">               12.75</td><td style=\"text-align: right;\">               -1.21</td><td style=\"text-align: right;\">           91.8257</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6847260\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-09-13\n",
      "  done: false\n",
      "  episode_len_mean: 91.33944954128441\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.98000000000002\n",
      "  episode_reward_mean: 4.074311926605513\n",
      "  episode_reward_min: -1.0200000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 74070\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.070141843852834\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011833602611334008\n",
      "          policy_loss: -0.059027267752103825\n",
      "          total_loss: 0.11018094675074148\n",
      "          vf_explained_var: 0.9345974326133728\n",
      "          vf_loss: 0.16295120590645024\n",
      "    num_agent_steps_sampled: 6847260\n",
      "    num_agent_steps_trained: 6847260\n",
      "    num_steps_sampled: 6847260\n",
      "    num_steps_trained: 6847260\n",
      "  iterations_since_restore: 685\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.50316205533595\n",
      "    ram_util_percent: 58.20395256916996\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552716236130359\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98810201403405\n",
      "    mean_inference_ms: 2.853350753202233\n",
      "    mean_raw_obs_processing_ms: 3.622738646985086\n",
      "  time_since_restore: 107717.33480286598\n",
      "  time_this_iter_s: 176.83639454841614\n",
      "  time_total_s: 107717.33480286598\n",
      "  timers:\n",
      "    learn_throughput: 934.991\n",
      "    learn_time_ms: 10691.011\n",
      "    load_throughput: 91541.819\n",
      "    load_time_ms: 109.196\n",
      "    sample_throughput: 65.341\n",
      "    sample_time_ms: 152982.695\n",
      "    update_time_ms: 11.9\n",
      "  timestamp: 1636402153\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6847260\n",
      "  training_iteration: 685\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   685</td><td style=\"text-align: right;\">          107717</td><td style=\"text-align: right;\">6847260</td><td style=\"text-align: right;\"> 4.07431</td><td style=\"text-align: right;\">               13.98</td><td style=\"text-align: right;\">               -1.02</td><td style=\"text-align: right;\">           91.3394</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6857256\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-12-29\n",
      "  done: false\n",
      "  episode_len_mean: 88.3859649122807\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 3.9240350877193064\n",
      "  episode_reward_min: -1.4700000000000006\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 74184\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.039184144215706\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01183662830792475\n",
      "          policy_loss: -0.056045123764401315\n",
      "          total_loss: 0.10639969117732512\n",
      "          vf_explained_var: 0.9308170080184937\n",
      "          vf_loss: 0.15587133742295778\n",
      "    num_agent_steps_sampled: 6857256\n",
      "    num_agent_steps_trained: 6857256\n",
      "    num_steps_sampled: 6857256\n",
      "    num_steps_trained: 6857256\n",
      "  iterations_since_restore: 686\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.25340501792114\n",
      "    ram_util_percent: 58.13906810035841\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552411922629402\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.989995001005155\n",
      "    mean_inference_ms: 2.853392175627473\n",
      "    mean_raw_obs_processing_ms: 3.6265395185466804\n",
      "  time_since_restore: 107913.22839140892\n",
      "  time_this_iter_s: 195.89358854293823\n",
      "  time_total_s: 107913.22839140892\n",
      "  timers:\n",
      "    learn_throughput: 934.936\n",
      "    learn_time_ms: 10691.639\n",
      "    load_throughput: 91685.232\n",
      "    load_time_ms: 109.025\n",
      "    sample_throughput: 64.336\n",
      "    sample_time_ms: 155371.532\n",
      "    update_time_ms: 12.031\n",
      "  timestamp: 1636402349\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6857256\n",
      "  training_iteration: 686\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   686</td><td style=\"text-align: right;\">          107913</td><td style=\"text-align: right;\">6857256</td><td style=\"text-align: right;\"> 3.92404</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">            88.386</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6867252\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-15-03\n",
      "  done: false\n",
      "  episode_len_mean: 92.35185185185185\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.049999999999944\n",
      "  episode_reward_mean: 3.9693518518518602\n",
      "  episode_reward_min: -1.5800000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 74292\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0784068321570373\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012350330048570304\n",
      "          policy_loss: -0.05814981078649433\n",
      "          total_loss: 0.12251566875821505\n",
      "          vf_explained_var: 0.9372898936271667\n",
      "          vf_loss: 0.1733139520463271\n",
      "    num_agent_steps_sampled: 6867252\n",
      "    num_agent_steps_trained: 6867252\n",
      "    num_steps_sampled: 6867252\n",
      "    num_steps_trained: 6867252\n",
      "  iterations_since_restore: 687\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.289592760181\n",
      "    ram_util_percent: 58.28009049773756\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550884474196908\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.98949551090578\n",
      "    mean_inference_ms: 2.8531050703379046\n",
      "    mean_raw_obs_processing_ms: 3.6267261157091117\n",
      "  time_since_restore: 108067.7208366394\n",
      "  time_this_iter_s: 154.492445230484\n",
      "  time_total_s: 108067.7208366394\n",
      "  timers:\n",
      "    learn_throughput: 934.706\n",
      "    learn_time_ms: 10694.271\n",
      "    load_throughput: 91486.667\n",
      "    load_time_ms: 109.262\n",
      "    sample_throughput: 64.534\n",
      "    sample_time_ms: 154895.141\n",
      "    update_time_ms: 12.451\n",
      "  timestamp: 1636402503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6867252\n",
      "  training_iteration: 687\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   687</td><td style=\"text-align: right;\">          108068</td><td style=\"text-align: right;\">6867252</td><td style=\"text-align: right;\"> 3.96935</td><td style=\"text-align: right;\">               18.05</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           92.3519</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6877248\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 91.90825688073394\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.630000000000017\n",
      "  episode_reward_mean: 3.8855045871559724\n",
      "  episode_reward_min: -1.2000000000000004\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 74401\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0711985797963592\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012304336101224084\n",
      "          policy_loss: -0.059633877695912225\n",
      "          total_loss: 0.09972082011751894\n",
      "          vf_explained_var: 0.9303794503211975\n",
      "          vf_loss: 0.15203586667139307\n",
      "    num_agent_steps_sampled: 6877248\n",
      "    num_agent_steps_trained: 6877248\n",
      "    num_steps_sampled: 6877248\n",
      "    num_steps_trained: 6877248\n",
      "  iterations_since_restore: 688\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0024154589372\n",
      "    ram_util_percent: 58.199999999999996\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551974826401072\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99374289210046\n",
      "    mean_inference_ms: 2.853233534898989\n",
      "    mean_raw_obs_processing_ms: 3.6226798403340443\n",
      "  time_since_restore: 108213.19179463387\n",
      "  time_this_iter_s: 145.47095799446106\n",
      "  time_total_s: 108213.19179463387\n",
      "  timers:\n",
      "    learn_throughput: 934.702\n",
      "    learn_time_ms: 10694.318\n",
      "    load_throughput: 91354.403\n",
      "    load_time_ms: 109.42\n",
      "    sample_throughput: 65.231\n",
      "    sample_time_ms: 153240.506\n",
      "    update_time_ms: 12.721\n",
      "  timestamp: 1636402649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6877248\n",
      "  training_iteration: 688\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   688</td><td style=\"text-align: right;\">          108213</td><td style=\"text-align: right;\">6877248</td><td style=\"text-align: right;\">  3.8855</td><td style=\"text-align: right;\">               10.63</td><td style=\"text-align: right;\">                -1.2</td><td style=\"text-align: right;\">           91.9083</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6887244\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-20-00\n",
      "  done: false\n",
      "  episode_len_mean: 92.8785046728972\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.29999999999995\n",
      "  episode_reward_mean: 4.53682242990655\n",
      "  episode_reward_min: -1.5100000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 74508\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0476911690500046\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012568511394608904\n",
      "          policy_loss: -0.05283870957871405\n",
      "          total_loss: 0.14499319123629575\n",
      "          vf_explained_var: 0.9354273080825806\n",
      "          vf_loss: 0.189676171899415\n",
      "    num_agent_steps_sampled: 6887244\n",
      "    num_agent_steps_trained: 6887244\n",
      "    num_steps_sampled: 6887244\n",
      "    num_steps_trained: 6887244\n",
      "  iterations_since_restore: 689\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.95694444444446\n",
      "    ram_util_percent: 58.17962962962962\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045515026314431946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99491860430723\n",
      "    mean_inference_ms: 2.853380028186244\n",
      "    mean_raw_obs_processing_ms: 3.6198524644076744\n",
      "  time_since_restore: 108364.43211221695\n",
      "  time_this_iter_s: 151.2403175830841\n",
      "  time_total_s: 108364.43211221695\n",
      "  timers:\n",
      "    learn_throughput: 934.642\n",
      "    learn_time_ms: 10695.003\n",
      "    load_throughput: 91593.075\n",
      "    load_time_ms: 109.135\n",
      "    sample_throughput: 66.455\n",
      "    sample_time_ms: 150418.157\n",
      "    update_time_ms: 11.916\n",
      "  timestamp: 1636402800\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6887244\n",
      "  training_iteration: 689\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   689</td><td style=\"text-align: right;\">          108364</td><td style=\"text-align: right;\">6887244</td><td style=\"text-align: right;\"> 4.53682</td><td style=\"text-align: right;\">                20.3</td><td style=\"text-align: right;\">               -1.51</td><td style=\"text-align: right;\">           92.8785</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6897240\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-23-06\n",
      "  done: false\n",
      "  episode_len_mean: 91.10909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.030000000000015\n",
      "  episode_reward_mean: 4.252090909090919\n",
      "  episode_reward_min: -1.2600000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 74618\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0659172255768734\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011829176244551591\n",
      "          policy_loss: -0.06236260883812594\n",
      "          total_loss: 0.08996264150557227\n",
      "          vf_explained_var: 0.9362631440162659\n",
      "          vf_loss: 0.14603607952276357\n",
      "    num_agent_steps_sampled: 6897240\n",
      "    num_agent_steps_trained: 6897240\n",
      "    num_steps_sampled: 6897240\n",
      "    num_steps_trained: 6897240\n",
      "  iterations_since_restore: 690\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.57018867924528\n",
      "    ram_util_percent: 58.160377358490564\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045514428637697626\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99634790140186\n",
      "    mean_inference_ms: 2.8533397219952117\n",
      "    mean_raw_obs_processing_ms: 3.623351614207138\n",
      "  time_since_restore: 108549.93002414703\n",
      "  time_this_iter_s: 185.49791193008423\n",
      "  time_total_s: 108549.93002414703\n",
      "  timers:\n",
      "    learn_throughput: 934.381\n",
      "    learn_time_ms: 10697.989\n",
      "    load_throughput: 91481.876\n",
      "    load_time_ms: 109.268\n",
      "    sample_throughput: 65.294\n",
      "    sample_time_ms: 153091.547\n",
      "    update_time_ms: 11.136\n",
      "  timestamp: 1636402986\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6897240\n",
      "  training_iteration: 690\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   690</td><td style=\"text-align: right;\">          108550</td><td style=\"text-align: right;\">6897240</td><td style=\"text-align: right;\"> 4.25209</td><td style=\"text-align: right;\">               13.03</td><td style=\"text-align: right;\">               -1.26</td><td style=\"text-align: right;\">           91.1091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6907236\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-25-41\n",
      "  done: false\n",
      "  episode_len_mean: 94.07476635514018\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.360000000000003\n",
      "  episode_reward_mean: 4.729252336448609\n",
      "  episode_reward_min: -1.1100000000000003\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 74725\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.052806007148873\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013765518284860483\n",
      "          policy_loss: -0.054198771845708545\n",
      "          total_loss: 0.14232415941376717\n",
      "          vf_explained_var: 0.9492300152778625\n",
      "          vf_loss: 0.185691417947921\n",
      "    num_agent_steps_sampled: 6907236\n",
      "    num_agent_steps_trained: 6907236\n",
      "    num_steps_sampled: 6907236\n",
      "    num_steps_trained: 6907236\n",
      "  iterations_since_restore: 691\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.88468468468466\n",
      "    ram_util_percent: 58.1981981981982\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045505405005662684\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.998978984884275\n",
      "    mean_inference_ms: 2.8531802659024597\n",
      "    mean_raw_obs_processing_ms: 3.62212178934582\n",
      "  time_since_restore: 108705.42808818817\n",
      "  time_this_iter_s: 155.4980640411377\n",
      "  time_total_s: 108705.42808818817\n",
      "  timers:\n",
      "    learn_throughput: 934.191\n",
      "    learn_time_ms: 10700.166\n",
      "    load_throughput: 91457.59\n",
      "    load_time_ms: 109.297\n",
      "    sample_throughput: 64.794\n",
      "    sample_time_ms: 154272.466\n",
      "    update_time_ms: 10.263\n",
      "  timestamp: 1636403141\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6907236\n",
      "  training_iteration: 691\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   691</td><td style=\"text-align: right;\">          108705</td><td style=\"text-align: right;\">6907236</td><td style=\"text-align: right;\"> 4.72925</td><td style=\"text-align: right;\">               16.36</td><td style=\"text-align: right;\">               -1.11</td><td style=\"text-align: right;\">           94.0748</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6917232\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-28-26\n",
      "  done: false\n",
      "  episode_len_mean: 94.82857142857142\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.779999999999966\n",
      "  episode_reward_mean: 4.39942857142858\n",
      "  episode_reward_min: -1.1900000000000008\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 74830\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.1018796428655966\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012016823034034499\n",
      "          policy_loss: -0.05808990828087952\n",
      "          total_loss: 0.10350568829677426\n",
      "          vf_explained_var: 0.9475623369216919\n",
      "          vf_loss: 0.15523856746462675\n",
      "    num_agent_steps_sampled: 6917232\n",
      "    num_agent_steps_trained: 6917232\n",
      "    num_steps_sampled: 6917232\n",
      "    num_steps_trained: 6917232\n",
      "  iterations_since_restore: 692\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.74700854700855\n",
      "    ram_util_percent: 58.23418803418803\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045527380972196635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.000008244510795\n",
      "    mean_inference_ms: 2.853121183921324\n",
      "    mean_raw_obs_processing_ms: 3.6243610106772826\n",
      "  time_since_restore: 108869.86488175392\n",
      "  time_this_iter_s: 164.43679356575012\n",
      "  time_total_s: 108869.86488175392\n",
      "  timers:\n",
      "    learn_throughput: 934.329\n",
      "    learn_time_ms: 10698.587\n",
      "    load_throughput: 91603.941\n",
      "    load_time_ms: 109.122\n",
      "    sample_throughput: 65.256\n",
      "    sample_time_ms: 153181.371\n",
      "    update_time_ms: 10.083\n",
      "  timestamp: 1636403306\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6917232\n",
      "  training_iteration: 692\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   692</td><td style=\"text-align: right;\">          108870</td><td style=\"text-align: right;\">6917232</td><td style=\"text-align: right;\"> 4.39943</td><td style=\"text-align: right;\">               16.78</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           94.8286</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6927228\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-31-03\n",
      "  done: false\n",
      "  episode_len_mean: 93.33644859813084\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.980000000000013\n",
      "  episode_reward_mean: 4.042616822429916\n",
      "  episode_reward_min: -1.6100000000000008\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 74937\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0778777345632897\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01259875306462083\n",
      "          policy_loss: -0.05320439901139237\n",
      "          total_loss: 0.11912307598604224\n",
      "          vf_explained_var: 0.9328851103782654\n",
      "          vf_loss: 0.16440471736793844\n",
      "    num_agent_steps_sampled: 6927228\n",
      "    num_agent_steps_trained: 6927228\n",
      "    num_steps_sampled: 6927228\n",
      "    num_steps_trained: 6927228\n",
      "  iterations_since_restore: 693\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.94088888888888\n",
      "    ram_util_percent: 58.06533333333333\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551050101145818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.000203283737115\n",
      "    mean_inference_ms: 2.853292386682216\n",
      "    mean_raw_obs_processing_ms: 3.62394183037046\n",
      "  time_since_restore: 109027.46094751358\n",
      "  time_this_iter_s: 157.5960657596588\n",
      "  time_total_s: 109027.46094751358\n",
      "  timers:\n",
      "    learn_throughput: 934.059\n",
      "    learn_time_ms: 10701.683\n",
      "    load_throughput: 91245.808\n",
      "    load_time_ms: 109.55\n",
      "    sample_throughput: 65.204\n",
      "    sample_time_ms: 153302.691\n",
      "    update_time_ms: 9.62\n",
      "  timestamp: 1636403463\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6927228\n",
      "  training_iteration: 693\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   693</td><td style=\"text-align: right;\">          109027</td><td style=\"text-align: right;\">6927228</td><td style=\"text-align: right;\"> 4.04262</td><td style=\"text-align: right;\">               14.98</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           93.3364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6937224\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-33-40\n",
      "  done: false\n",
      "  episode_len_mean: 91.8348623853211\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.849999999999998\n",
      "  episode_reward_mean: 3.634495412844046\n",
      "  episode_reward_min: -1.5400000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 75046\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.047481531668932\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013903167513331028\n",
      "          policy_loss: -0.05472711958946326\n",
      "          total_loss: 0.1394389888128409\n",
      "          vf_explained_var: 0.9281265735626221\n",
      "          vf_loss: 0.1829677695647264\n",
      "    num_agent_steps_sampled: 6937224\n",
      "    num_agent_steps_trained: 6937224\n",
      "    num_steps_sampled: 6937224\n",
      "    num_steps_trained: 6937224\n",
      "  iterations_since_restore: 694\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.75067264573991\n",
      "    ram_util_percent: 58.29417040358747\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551301788644076\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.002180854909135\n",
      "    mean_inference_ms: 2.8531254970333144\n",
      "    mean_raw_obs_processing_ms: 3.6235323795567673\n",
      "  time_since_restore: 109183.71938967705\n",
      "  time_this_iter_s: 156.2584421634674\n",
      "  time_total_s: 109183.71938967705\n",
      "  timers:\n",
      "    learn_throughput: 934.003\n",
      "    learn_time_ms: 10702.319\n",
      "    load_throughput: 91199.106\n",
      "    load_time_ms: 109.606\n",
      "    sample_throughput: 65.126\n",
      "    sample_time_ms: 153487.347\n",
      "    update_time_ms: 9.777\n",
      "  timestamp: 1636403620\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6937224\n",
      "  training_iteration: 694\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   694</td><td style=\"text-align: right;\">          109184</td><td style=\"text-align: right;\">6937224</td><td style=\"text-align: right;\">  3.6345</td><td style=\"text-align: right;\">               15.85</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           91.8349</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6947220\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-36-15\n",
      "  done: false\n",
      "  episode_len_mean: 92.43518518518519\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.340000000000018\n",
      "  episode_reward_mean: 4.345092592592603\n",
      "  episode_reward_min: -1.1400000000000003\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 75154\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.045051695852198\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012072848904706479\n",
      "          policy_loss: -0.06071393818904956\n",
      "          total_loss: 0.09987445937421842\n",
      "          vf_explained_var: 0.9392983913421631\n",
      "          vf_loss: 0.15353545501477953\n",
      "    num_agent_steps_sampled: 6947220\n",
      "    num_agent_steps_trained: 6947220\n",
      "    num_steps_sampled: 6947220\n",
      "    num_steps_trained: 6947220\n",
      "  iterations_since_restore: 695\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.79638009049773\n",
      "    ram_util_percent: 58.32805429864255\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551202036489351\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00307756468723\n",
      "    mean_inference_ms: 2.8531839733289774\n",
      "    mean_raw_obs_processing_ms: 3.6237861178662985\n",
      "  time_since_restore: 109338.59527468681\n",
      "  time_this_iter_s: 154.87588500976562\n",
      "  time_total_s: 109338.59527468681\n",
      "  timers:\n",
      "    learn_throughput: 933.999\n",
      "    learn_time_ms: 10702.361\n",
      "    load_throughput: 91196.468\n",
      "    load_time_ms: 109.61\n",
      "    sample_throughput: 66.071\n",
      "    sample_time_ms: 151290.684\n",
      "    update_time_ms: 10.382\n",
      "  timestamp: 1636403775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6947220\n",
      "  training_iteration: 695\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   695</td><td style=\"text-align: right;\">          109339</td><td style=\"text-align: right;\">6947220</td><td style=\"text-align: right;\"> 4.34509</td><td style=\"text-align: right;\">               12.34</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           92.4352</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6957216\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-38-44\n",
      "  done: false\n",
      "  episode_len_mean: 95.12380952380953\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.28000000000001\n",
      "  episode_reward_mean: 3.6036190476190573\n",
      "  episode_reward_min: -1.5000000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 75259\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0772543313156846\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011220346337143411\n",
      "          policy_loss: -0.05956322086067536\n",
      "          total_loss: 0.06237604797650606\n",
      "          vf_explained_var: 0.9465705752372742\n",
      "          vf_loss: 0.11715045890364892\n",
      "    num_agent_steps_sampled: 6957216\n",
      "    num_agent_steps_trained: 6957216\n",
      "    num_steps_sampled: 6957216\n",
      "    num_steps_trained: 6957216\n",
      "  iterations_since_restore: 696\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.70747663551403\n",
      "    ram_util_percent: 58.348130841121495\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552179642873737\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00288492388359\n",
      "    mean_inference_ms: 2.8533389806307015\n",
      "    mean_raw_obs_processing_ms: 3.6213781967650545\n",
      "  time_since_restore: 109488.32890176773\n",
      "  time_this_iter_s: 149.73362708091736\n",
      "  time_total_s: 109488.32890176773\n",
      "  timers:\n",
      "    learn_throughput: 933.731\n",
      "    learn_time_ms: 10705.435\n",
      "    load_throughput: 91383.016\n",
      "    load_time_ms: 109.386\n",
      "    sample_throughput: 68.152\n",
      "    sample_time_ms: 146671.848\n",
      "    update_time_ms: 10.627\n",
      "  timestamp: 1636403924\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6957216\n",
      "  training_iteration: 696\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   696</td><td style=\"text-align: right;\">          109488</td><td style=\"text-align: right;\">6957216</td><td style=\"text-align: right;\"> 3.60362</td><td style=\"text-align: right;\">               12.28</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           95.1238</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6967212\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-41-32\n",
      "  done: false\n",
      "  episode_len_mean: 90.1981981981982\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.020000000000012\n",
      "  episode_reward_mean: 4.177027027027036\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 75370\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0521521912680734\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012068688802144213\n",
      "          policy_loss: -0.055395343695950304\n",
      "          total_loss: 0.10368185134079212\n",
      "          vf_explained_var: 0.9367672801017761\n",
      "          vf_loss: 0.15210473464053664\n",
      "    num_agent_steps_sampled: 6967212\n",
      "    num_agent_steps_trained: 6967212\n",
      "    num_steps_sampled: 6967212\n",
      "    num_steps_trained: 6967212\n",
      "  iterations_since_restore: 697\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.95062761506277\n",
      "    ram_util_percent: 58.41506276150628\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551266333086139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00174123754302\n",
      "    mean_inference_ms: 2.8531422319598607\n",
      "    mean_raw_obs_processing_ms: 3.6255825124726835\n",
      "  time_since_restore: 109656.05681276321\n",
      "  time_this_iter_s: 167.7279109954834\n",
      "  time_total_s: 109656.05681276321\n",
      "  timers:\n",
      "    learn_throughput: 933.745\n",
      "    learn_time_ms: 10705.282\n",
      "    load_throughput: 91658.373\n",
      "    load_time_ms: 109.057\n",
      "    sample_throughput: 67.542\n",
      "    sample_time_ms: 147996.786\n",
      "    update_time_ms: 9.231\n",
      "  timestamp: 1636404092\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6967212\n",
      "  training_iteration: 697\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   697</td><td style=\"text-align: right;\">          109656</td><td style=\"text-align: right;\">6967212</td><td style=\"text-align: right;\"> 4.17703</td><td style=\"text-align: right;\">               13.02</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           90.1982</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6977208\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-44-07\n",
      "  done: false\n",
      "  episode_len_mean: 91.74074074074075\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.46999999999998\n",
      "  episode_reward_mean: 4.245000000000009\n",
      "  episode_reward_min: -1.3900000000000003\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 75478\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0568164109164835\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012498183959199913\n",
      "          policy_loss: -0.062109217569868785\n",
      "          total_loss: 0.10904229821390513\n",
      "          vf_explained_var: 0.9420475959777832\n",
      "          vf_loss: 0.1632472539320588\n",
      "    num_agent_steps_sampled: 6977208\n",
      "    num_agent_steps_trained: 6977208\n",
      "    num_steps_sampled: 6977208\n",
      "    num_steps_trained: 6977208\n",
      "  iterations_since_restore: 698\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.66334841628958\n",
      "    ram_util_percent: 58.40859728506787\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552056444987148\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.003347048586996\n",
      "    mean_inference_ms: 2.8533158169137782\n",
      "    mean_raw_obs_processing_ms: 3.6233287550168196\n",
      "  time_since_restore: 109811.02942276001\n",
      "  time_this_iter_s: 154.97260999679565\n",
      "  time_total_s: 109811.02942276001\n",
      "  timers:\n",
      "    learn_throughput: 933.992\n",
      "    learn_time_ms: 10702.443\n",
      "    load_throughput: 91672.903\n",
      "    load_time_ms: 109.04\n",
      "    sample_throughput: 67.11\n",
      "    sample_time_ms: 148950.103\n",
      "    update_time_ms: 9.252\n",
      "  timestamp: 1636404247\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6977208\n",
      "  training_iteration: 698\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   698</td><td style=\"text-align: right;\">          109811</td><td style=\"text-align: right;\">6977208</td><td style=\"text-align: right;\">   4.245</td><td style=\"text-align: right;\">               16.47</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">           91.7407</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6987204\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-46-51\n",
      "  done: false\n",
      "  episode_len_mean: 92.13636363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.980000000000011\n",
      "  episode_reward_mean: 4.218909090909099\n",
      "  episode_reward_min: -1.3600000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 75588\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.061504519189525\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011798158558710548\n",
      "          policy_loss: -0.05795882409836492\n",
      "          total_loss: 0.09391871327932319\n",
      "          vf_explained_var: 0.940834105014801\n",
      "          vf_loss: 0.14561490265684376\n",
      "    num_agent_steps_sampled: 6987204\n",
      "    num_agent_steps_trained: 6987204\n",
      "    num_steps_sampled: 6987204\n",
      "    num_steps_trained: 6987204\n",
      "  iterations_since_restore: 699\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.17777777777778\n",
      "    ram_util_percent: 58.356837606837615\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548875542634536\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.003586019008246\n",
      "    mean_inference_ms: 2.853168706066778\n",
      "    mean_raw_obs_processing_ms: 3.622461715182547\n",
      "  time_since_restore: 109975.00902962685\n",
      "  time_this_iter_s: 163.97960686683655\n",
      "  time_total_s: 109975.00902962685\n",
      "  timers:\n",
      "    learn_throughput: 934.059\n",
      "    learn_time_ms: 10701.678\n",
      "    load_throughput: 91657.992\n",
      "    load_time_ms: 109.058\n",
      "    sample_throughput: 66.541\n",
      "    sample_time_ms: 150223.94\n",
      "    update_time_ms: 9.682\n",
      "  timestamp: 1636404411\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6987204\n",
      "  training_iteration: 699\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   699</td><td style=\"text-align: right;\">          109975</td><td style=\"text-align: right;\">6987204</td><td style=\"text-align: right;\"> 4.21891</td><td style=\"text-align: right;\">               12.98</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           92.1364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 6997200\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-49-43\n",
      "  done: false\n",
      "  episode_len_mean: 90.72727272727273\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000014\n",
      "  episode_reward_mean: 4.362272727272736\n",
      "  episode_reward_min: -1.4800000000000004\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 75698\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0590232199073855\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012543860336128037\n",
      "          policy_loss: -0.0570206905532087\n",
      "          total_loss: 0.11911947055377511\n",
      "          vf_explained_var: 0.9425324201583862\n",
      "          vf_loss: 0.16815391037867874\n",
      "    num_agent_steps_sampled: 6997200\n",
      "    num_agent_steps_trained: 6997200\n",
      "    num_steps_sampled: 6997200\n",
      "    num_steps_trained: 6997200\n",
      "  iterations_since_restore: 700\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.77020408163264\n",
      "    ram_util_percent: 58.26489795918366\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455087377822409\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00269283272026\n",
      "    mean_inference_ms: 2.8531518278991648\n",
      "    mean_raw_obs_processing_ms: 3.6276130166893847\n",
      "  time_since_restore: 110146.75970673561\n",
      "  time_this_iter_s: 171.75067710876465\n",
      "  time_total_s: 110146.75970673561\n",
      "  timers:\n",
      "    learn_throughput: 934.328\n",
      "    learn_time_ms: 10698.601\n",
      "    load_throughput: 91854.484\n",
      "    load_time_ms: 108.824\n",
      "    sample_throughput: 67.154\n",
      "    sample_time_ms: 148852.072\n",
      "    update_time_ms: 10.017\n",
      "  timestamp: 1636404583\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6997200\n",
      "  training_iteration: 700\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   700</td><td style=\"text-align: right;\">          110147</td><td style=\"text-align: right;\">6997200</td><td style=\"text-align: right;\"> 4.36227</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           90.7273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7007196\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-52-19\n",
      "  done: false\n",
      "  episode_len_mean: 92.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000015\n",
      "  episode_reward_mean: 3.6433944954128523\n",
      "  episode_reward_min: -2.0100000000000002\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 75807\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0541772298323804\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012951957014781718\n",
      "          policy_loss: -0.05523140471524153\n",
      "          total_loss: 0.12367356247626818\n",
      "          vf_explained_var: 0.9257563948631287\n",
      "          vf_loss: 0.16994056191581947\n",
      "    num_agent_steps_sampled: 7007196\n",
      "    num_agent_steps_trained: 7007196\n",
      "    num_steps_sampled: 7007196\n",
      "    num_steps_trained: 7007196\n",
      "  iterations_since_restore: 701\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.05695067264574\n",
      "    ram_util_percent: 58.27443946188342\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550843210198094\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00372493266218\n",
      "    mean_inference_ms: 2.8532161352664356\n",
      "    mean_raw_obs_processing_ms: 3.6279374460095046\n",
      "  time_since_restore: 110302.57285881042\n",
      "  time_this_iter_s: 155.81315207481384\n",
      "  time_total_s: 110302.57285881042\n",
      "  timers:\n",
      "    learn_throughput: 934.53\n",
      "    learn_time_ms: 10696.283\n",
      "    load_throughput: 91841.687\n",
      "    load_time_ms: 108.839\n",
      "    sample_throughput: 67.139\n",
      "    sample_time_ms: 148885.095\n",
      "    update_time_ms: 10.606\n",
      "  timestamp: 1636404739\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7007196\n",
      "  training_iteration: 701\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   701</td><td style=\"text-align: right;\">          110303</td><td style=\"text-align: right;\">7007196</td><td style=\"text-align: right;\"> 3.64339</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">               -2.01</td><td style=\"text-align: right;\">                92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7017192\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-55-15\n",
      "  done: false\n",
      "  episode_len_mean: 91.30909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.10000000000002\n",
      "  episode_reward_mean: 3.576272727272736\n",
      "  episode_reward_min: -1.5000000000000004\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 75917\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.089961229226528\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011730186048373894\n",
      "          policy_loss: -0.05721948609695348\n",
      "          total_loss: 0.10380382655172521\n",
      "          vf_explained_var: 0.9274312853813171\n",
      "          vf_loss: 0.15520009435872492\n",
      "    num_agent_steps_sampled: 7017192\n",
      "    num_agent_steps_trained: 7017192\n",
      "    num_steps_sampled: 7017192\n",
      "    num_steps_trained: 7017192\n",
      "  iterations_since_restore: 702\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.75697211155378\n",
      "    ram_util_percent: 58.480478087649395\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550115742129921\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.002473227468656\n",
      "    mean_inference_ms: 2.852949022575121\n",
      "    mean_raw_obs_processing_ms: 3.63170271851229\n",
      "  time_since_restore: 110478.75796461105\n",
      "  time_this_iter_s: 176.18510580062866\n",
      "  time_total_s: 110478.75796461105\n",
      "  timers:\n",
      "    learn_throughput: 934.383\n",
      "    learn_time_ms: 10697.967\n",
      "    load_throughput: 91563.11\n",
      "    load_time_ms: 109.171\n",
      "    sample_throughput: 66.614\n",
      "    sample_time_ms: 150058.137\n",
      "    update_time_ms: 10.828\n",
      "  timestamp: 1636404915\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7017192\n",
      "  training_iteration: 702\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   702</td><td style=\"text-align: right;\">          110479</td><td style=\"text-align: right;\">7017192</td><td style=\"text-align: right;\"> 3.57627</td><td style=\"text-align: right;\">                14.1</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           91.3091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7027188\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_20-57-39\n",
      "  done: false\n",
      "  episode_len_mean: 92.12037037037037\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.99999999999998\n",
      "  episode_reward_mean: 4.326296296296306\n",
      "  episode_reward_min: -1.0400000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 76025\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.084609376772856\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01248936105037136\n",
      "          policy_loss: -0.059409896476974346\n",
      "          total_loss: 0.10871763759507583\n",
      "          vf_explained_var: 0.9435846209526062\n",
      "          vf_loss: 0.16052130156347894\n",
      "    num_agent_steps_sampled: 7027188\n",
      "    num_agent_steps_trained: 7027188\n",
      "    num_steps_sampled: 7027188\n",
      "    num_steps_trained: 7027188\n",
      "  iterations_since_restore: 703\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.21756097560974\n",
      "    ram_util_percent: 58.35073170731709\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045529481478649866\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00707992679409\n",
      "    mean_inference_ms: 2.8529911667841135\n",
      "    mean_raw_obs_processing_ms: 3.6286410799328697\n",
      "  time_since_restore: 110622.87219452858\n",
      "  time_this_iter_s: 144.11422991752625\n",
      "  time_total_s: 110622.87219452858\n",
      "  timers:\n",
      "    learn_throughput: 934.932\n",
      "    learn_time_ms: 10691.691\n",
      "    load_throughput: 91778.458\n",
      "    load_time_ms: 108.914\n",
      "    sample_throughput: 67.215\n",
      "    sample_time_ms: 148716.355\n",
      "    update_time_ms: 11.183\n",
      "  timestamp: 1636405059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7027188\n",
      "  training_iteration: 703\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   703</td><td style=\"text-align: right;\">          110623</td><td style=\"text-align: right;\">7027188</td><td style=\"text-align: right;\">  4.3263</td><td style=\"text-align: right;\">                  17</td><td style=\"text-align: right;\">               -1.04</td><td style=\"text-align: right;\">           92.1204</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7037184\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-00-27\n",
      "  done: false\n",
      "  episode_len_mean: 89.52252252252252\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.960000000000024\n",
      "  episode_reward_mean: 3.737657657657666\n",
      "  episode_reward_min: -1.7300000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 76136\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0552593627546587\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011948432950318536\n",
      "          policy_loss: -0.05835780792065665\n",
      "          total_loss: 0.10034071228458968\n",
      "          vf_explained_var: 0.9320175647735596\n",
      "          vf_loss: 0.15203108906777751\n",
      "    num_agent_steps_sampled: 7037184\n",
      "    num_agent_steps_trained: 7037184\n",
      "    num_steps_sampled: 7037184\n",
      "    num_steps_trained: 7037184\n",
      "  iterations_since_restore: 704\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.69037656903764\n",
      "    ram_util_percent: 58.231799163179915\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553695488967779\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00771564248055\n",
      "    mean_inference_ms: 2.8531155218010817\n",
      "    mean_raw_obs_processing_ms: 3.631633239738086\n",
      "  time_since_restore: 110790.29652690887\n",
      "  time_this_iter_s: 167.4243323802948\n",
      "  time_total_s: 110790.29652690887\n",
      "  timers:\n",
      "    learn_throughput: 935.192\n",
      "    learn_time_ms: 10688.715\n",
      "    load_throughput: 91232.267\n",
      "    load_time_ms: 109.566\n",
      "    sample_throughput: 66.713\n",
      "    sample_time_ms: 149835.649\n",
      "    update_time_ms: 10.563\n",
      "  timestamp: 1636405227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7037184\n",
      "  training_iteration: 704\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   704</td><td style=\"text-align: right;\">          110790</td><td style=\"text-align: right;\">7037184</td><td style=\"text-align: right;\"> 3.73766</td><td style=\"text-align: right;\">               13.96</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           89.5225</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7047180\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-03-05\n",
      "  done: false\n",
      "  episode_len_mean: 91.71296296296296\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000019\n",
      "  episode_reward_mean: 5.200555555555566\n",
      "  episode_reward_min: -1.1700000000000004\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 76244\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9982247341392387\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013181030103139023\n",
      "          policy_loss: -0.054400265807461025\n",
      "          total_loss: 0.14707978654047874\n",
      "          vf_explained_var: 0.9415457248687744\n",
      "          vf_loss: 0.19143426433269284\n",
      "    num_agent_steps_sampled: 7047180\n",
      "    num_agent_steps_trained: 7047180\n",
      "    num_steps_sampled: 7047180\n",
      "    num_steps_trained: 7047180\n",
      "  iterations_since_restore: 705\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.81629955947137\n",
      "    ram_util_percent: 58.371365638766534\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552432463430724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.00975286648519\n",
      "    mean_inference_ms: 2.8532002662543645\n",
      "    mean_raw_obs_processing_ms: 3.628959030332382\n",
      "  time_since_restore: 110949.00109624863\n",
      "  time_this_iter_s: 158.7045693397522\n",
      "  time_total_s: 110949.00109624863\n",
      "  timers:\n",
      "    learn_throughput: 935.292\n",
      "    learn_time_ms: 10687.57\n",
      "    load_throughput: 91080.867\n",
      "    load_time_ms: 109.749\n",
      "    sample_throughput: 66.542\n",
      "    sample_time_ms: 150220.346\n",
      "    update_time_ms: 9.634\n",
      "  timestamp: 1636405385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7047180\n",
      "  training_iteration: 705\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   705</td><td style=\"text-align: right;\">          110949</td><td style=\"text-align: right;\">7047180</td><td style=\"text-align: right;\"> 5.20056</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">               -1.17</td><td style=\"text-align: right;\">            91.713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7057176\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-05-51\n",
      "  done: false\n",
      "  episode_len_mean: 92.28440366972477\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.95000000000001\n",
      "  episode_reward_mean: 4.373669724770652\n",
      "  episode_reward_min: -1.1100000000000003\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 76353\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0352098662629086\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011131083090285218\n",
      "          policy_loss: -0.060880114924576546\n",
      "          total_loss: 0.0741304389312545\n",
      "          vf_explained_var: 0.9449453353881836\n",
      "          vf_loss: 0.13000465496244212\n",
      "    num_agent_steps_sampled: 7057176\n",
      "    num_agent_steps_trained: 7057176\n",
      "    num_steps_sampled: 7057176\n",
      "    num_steps_trained: 7057176\n",
      "  iterations_since_restore: 706\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.47796610169492\n",
      "    ram_util_percent: 58.05338983050847\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550393104388007\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.010631601385406\n",
      "    mean_inference_ms: 2.8530424657108657\n",
      "    mean_raw_obs_processing_ms: 3.6308469658414078\n",
      "  time_since_restore: 111114.70281791687\n",
      "  time_this_iter_s: 165.7017216682434\n",
      "  time_total_s: 111114.70281791687\n",
      "  timers:\n",
      "    learn_throughput: 935.496\n",
      "    learn_time_ms: 10685.24\n",
      "    load_throughput: 90793.429\n",
      "    load_time_ms: 110.096\n",
      "    sample_throughput: 65.842\n",
      "    sample_time_ms: 151818.789\n",
      "    update_time_ms: 9.824\n",
      "  timestamp: 1636405551\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7057176\n",
      "  training_iteration: 706\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   706</td><td style=\"text-align: right;\">          111115</td><td style=\"text-align: right;\">7057176</td><td style=\"text-align: right;\"> 4.37367</td><td style=\"text-align: right;\">               12.95</td><td style=\"text-align: right;\">               -1.11</td><td style=\"text-align: right;\">           92.2844</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7067172\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-08-57\n",
      "  done: false\n",
      "  episode_len_mean: 89.66964285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.020000000000023\n",
      "  episode_reward_mean: 4.150089285714295\n",
      "  episode_reward_min: -1.1800000000000004\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 76465\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.031402108200595\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01209309395921347\n",
      "          policy_loss: -0.05820568011452754\n",
      "          total_loss: 0.10155162631064399\n",
      "          vf_explained_var: 0.940680205821991\n",
      "          vf_loss: 0.1525217487484726\n",
      "    num_agent_steps_sampled: 7067172\n",
      "    num_agent_steps_trained: 7067172\n",
      "    num_steps_sampled: 7067172\n",
      "    num_steps_trained: 7067172\n",
      "  iterations_since_restore: 707\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.22905660377359\n",
      "    ram_util_percent: 58.20566037735849\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045495029711031025\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0105927322967\n",
      "    mean_inference_ms: 2.8528256526044906\n",
      "    mean_raw_obs_processing_ms: 3.6347958397091102\n",
      "  time_since_restore: 111300.27448034286\n",
      "  time_this_iter_s: 185.57166242599487\n",
      "  time_total_s: 111300.27448034286\n",
      "  timers:\n",
      "    learn_throughput: 935.424\n",
      "    learn_time_ms: 10686.06\n",
      "    load_throughput: 90733.265\n",
      "    load_time_ms: 110.169\n",
      "    sample_throughput: 65.077\n",
      "    sample_time_ms: 153601.746\n",
      "    update_time_ms: 10.497\n",
      "  timestamp: 1636405737\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7067172\n",
      "  training_iteration: 707\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   707</td><td style=\"text-align: right;\">          111300</td><td style=\"text-align: right;\">7067172</td><td style=\"text-align: right;\"> 4.15009</td><td style=\"text-align: right;\">               14.02</td><td style=\"text-align: right;\">               -1.18</td><td style=\"text-align: right;\">           89.6696</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7077168\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-11-31\n",
      "  done: false\n",
      "  episode_len_mean: 92.14814814814815\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.679999999999975\n",
      "  episode_reward_mean: 4.071944444444453\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 76573\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.051965972704765\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012714177925857831\n",
      "          policy_loss: -0.061088491013098475\n",
      "          total_loss: 0.10831534440955545\n",
      "          vf_explained_var: 0.9242082238197327\n",
      "          vf_loss: 0.1609590068586871\n",
      "    num_agent_steps_sampled: 7077168\n",
      "    num_agent_steps_trained: 7077168\n",
      "    num_steps_sampled: 7077168\n",
      "    num_steps_trained: 7077168\n",
      "  iterations_since_restore: 708\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.04545454545455\n",
      "    ram_util_percent: 58.0090909090909\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551481067300931\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01361263093748\n",
      "    mean_inference_ms: 2.852980425261372\n",
      "    mean_raw_obs_processing_ms: 3.633259386500898\n",
      "  time_since_restore: 111454.11828017235\n",
      "  time_this_iter_s: 153.84379982948303\n",
      "  time_total_s: 111454.11828017235\n",
      "  timers:\n",
      "    learn_throughput: 935.117\n",
      "    learn_time_ms: 10689.574\n",
      "    load_throughput: 90699.563\n",
      "    load_time_ms: 110.21\n",
      "    sample_throughput: 65.127\n",
      "    sample_time_ms: 153484.33\n",
      "    update_time_ms: 11.135\n",
      "  timestamp: 1636405891\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7077168\n",
      "  training_iteration: 708\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   708</td><td style=\"text-align: right;\">          111454</td><td style=\"text-align: right;\">7077168</td><td style=\"text-align: right;\"> 4.07194</td><td style=\"text-align: right;\">               16.68</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           92.1481</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7087164\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-14-44\n",
      "  done: false\n",
      "  episode_len_mean: 88.53982300884955\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.970000000000013\n",
      "  episode_reward_mean: 3.4805309734513346\n",
      "  episode_reward_min: -1.1700000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 76686\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0271156571869158\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012036429020681472\n",
      "          policy_loss: -0.05578638035008031\n",
      "          total_loss: 0.11135397509663787\n",
      "          vf_explained_var: 0.9256315231323242\n",
      "          vf_loss: 0.15999102163741477\n",
      "    num_agent_steps_sampled: 7087164\n",
      "    num_agent_steps_trained: 7087164\n",
      "    num_steps_sampled: 7087164\n",
      "    num_steps_trained: 7087164\n",
      "  iterations_since_restore: 709\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.46123188405798\n",
      "    ram_util_percent: 57.95869565217392\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552004606298319\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01514398368221\n",
      "    mean_inference_ms: 2.8531657134219786\n",
      "    mean_raw_obs_processing_ms: 3.636973565586793\n",
      "  time_since_restore: 111647.43739008904\n",
      "  time_this_iter_s: 193.319109916687\n",
      "  time_total_s: 111647.43739008904\n",
      "  timers:\n",
      "    learn_throughput: 934.958\n",
      "    learn_time_ms: 10691.392\n",
      "    load_throughput: 90326.672\n",
      "    load_time_ms: 110.665\n",
      "    sample_throughput: 63.907\n",
      "    sample_time_ms: 156415.992\n",
      "    update_time_ms: 11.521\n",
      "  timestamp: 1636406084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7087164\n",
      "  training_iteration: 709\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   709</td><td style=\"text-align: right;\">          111647</td><td style=\"text-align: right;\">7087164</td><td style=\"text-align: right;\"> 3.48053</td><td style=\"text-align: right;\">               10.97</td><td style=\"text-align: right;\">               -1.17</td><td style=\"text-align: right;\">           88.5398</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7097160\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-17-09\n",
      "  done: false\n",
      "  episode_len_mean: 93.37037037037037\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.37999999999997\n",
      "  episode_reward_mean: 4.271296296296305\n",
      "  episode_reward_min: -1.6900000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 76794\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0338250266181097\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012506406439491928\n",
      "          policy_loss: -0.059086978347956114\n",
      "          total_loss: 0.1051148583396123\n",
      "          vf_explained_var: 0.9337288737297058\n",
      "          vf_loss: 0.15604892875840012\n",
      "    num_agent_steps_sampled: 7097160\n",
      "    num_agent_steps_trained: 7097160\n",
      "    num_steps_sampled: 7097160\n",
      "    num_steps_trained: 7097160\n",
      "  iterations_since_restore: 710\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73043478260868\n",
      "    ram_util_percent: 57.950724637681155\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455141592336208\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01796313398101\n",
      "    mean_inference_ms: 2.8529770603997386\n",
      "    mean_raw_obs_processing_ms: 3.6336264618002923\n",
      "  time_since_restore: 111792.47174954414\n",
      "  time_this_iter_s: 145.03435945510864\n",
      "  time_total_s: 111792.47174954414\n",
      "  timers:\n",
      "    learn_throughput: 934.824\n",
      "    learn_time_ms: 10692.927\n",
      "    load_throughput: 90168.718\n",
      "    load_time_ms: 110.859\n",
      "    sample_throughput: 65.018\n",
      "    sample_time_ms: 153741.53\n",
      "    update_time_ms: 12.439\n",
      "  timestamp: 1636406229\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7097160\n",
      "  training_iteration: 710\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   710</td><td style=\"text-align: right;\">          111792</td><td style=\"text-align: right;\">7097160</td><td style=\"text-align: right;\">  4.2713</td><td style=\"text-align: right;\">               16.38</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           93.3704</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7107156\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-20-06\n",
      "  done: false\n",
      "  episode_len_mean: 90.91818181818182\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.710000000000015\n",
      "  episode_reward_mean: 3.9231818181818277\n",
      "  episode_reward_min: -1.4400000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 76904\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.049628181437142\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011684187020973813\n",
      "          policy_loss: -0.05790018578115692\n",
      "          total_loss: 0.09588791760655804\n",
      "          vf_explained_var: 0.9416105151176453\n",
      "          vf_loss: 0.14766634627062286\n",
      "    num_agent_steps_sampled: 7107156\n",
      "    num_agent_steps_trained: 7107156\n",
      "    num_steps_sampled: 7107156\n",
      "    num_steps_trained: 7107156\n",
      "  iterations_since_restore: 711\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.17460317460318\n",
      "    ram_util_percent: 57.91031746031746\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045511038303679086\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01845729145474\n",
      "    mean_inference_ms: 2.8529830052036456\n",
      "    mean_raw_obs_processing_ms: 3.6370636741312574\n",
      "  time_since_restore: 111969.59690475464\n",
      "  time_this_iter_s: 177.125155210495\n",
      "  time_total_s: 111969.59690475464\n",
      "  timers:\n",
      "    learn_throughput: 934.719\n",
      "    learn_time_ms: 10694.122\n",
      "    load_throughput: 90114.976\n",
      "    load_time_ms: 110.925\n",
      "    sample_throughput: 64.13\n",
      "    sample_time_ms: 155870.849\n",
      "    update_time_ms: 13.056\n",
      "  timestamp: 1636406406\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7107156\n",
      "  training_iteration: 711\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   711</td><td style=\"text-align: right;\">          111970</td><td style=\"text-align: right;\">7107156</td><td style=\"text-align: right;\"> 3.92318</td><td style=\"text-align: right;\">               12.71</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           90.9182</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7117152\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-23-00\n",
      "  done: false\n",
      "  episode_len_mean: 92.70093457943925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.760000000000014\n",
      "  episode_reward_mean: 4.520747663551412\n",
      "  episode_reward_min: -1.6000000000000008\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 77011\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0513881938070315\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01220646800501192\n",
      "          policy_loss: -0.06213361094267959\n",
      "          total_loss: 0.09108185708427276\n",
      "          vf_explained_var: 0.9378252029418945\n",
      "          vf_loss: 0.1459214877162097\n",
      "    num_agent_steps_sampled: 7117152\n",
      "    num_agent_steps_trained: 7117152\n",
      "    num_steps_sampled: 7117152\n",
      "    num_steps_trained: 7117152\n",
      "  iterations_since_restore: 712\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.13588709677418\n",
      "    ram_util_percent: 58.099596774193536\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551158759614148\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01757451635243\n",
      "    mean_inference_ms: 2.8529344728795896\n",
      "    mean_raw_obs_processing_ms: 3.6393540171888663\n",
      "  time_since_restore: 112143.42621588707\n",
      "  time_this_iter_s: 173.82931113243103\n",
      "  time_total_s: 112143.42621588707\n",
      "  timers:\n",
      "    learn_throughput: 934.255\n",
      "    learn_time_ms: 10699.439\n",
      "    load_throughput: 90230.854\n",
      "    load_time_ms: 110.783\n",
      "    sample_throughput: 64.229\n",
      "    sample_time_ms: 155630.369\n",
      "    update_time_ms: 12.604\n",
      "  timestamp: 1636406580\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7117152\n",
      "  training_iteration: 712\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   712</td><td style=\"text-align: right;\">          112143</td><td style=\"text-align: right;\">7117152</td><td style=\"text-align: right;\"> 4.52075</td><td style=\"text-align: right;\">               12.76</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           92.7009</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7127148\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-25-45\n",
      "  done: false\n",
      "  episode_len_mean: 92.46296296296296\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.36999999999996\n",
      "  episode_reward_mean: 4.015277777777787\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 77119\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0369058053717652\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012577838804094268\n",
      "          policy_loss: -0.05938706929739724\n",
      "          total_loss: 0.1164117922496974\n",
      "          vf_explained_var: 0.9402981996536255\n",
      "          vf_loss: 0.16751402965945822\n",
      "    num_agent_steps_sampled: 7127148\n",
      "    num_agent_steps_trained: 7127148\n",
      "    num_steps_sampled: 7127148\n",
      "    num_steps_trained: 7127148\n",
      "  iterations_since_restore: 713\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.59829787234044\n",
      "    ram_util_percent: 58.07531914893616\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045491422678446074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01736957077022\n",
      "    mean_inference_ms: 2.852748793983932\n",
      "    mean_raw_obs_processing_ms: 3.6387216232337063\n",
      "  time_since_restore: 112308.17597222328\n",
      "  time_this_iter_s: 164.74975633621216\n",
      "  time_total_s: 112308.17597222328\n",
      "  timers:\n",
      "    learn_throughput: 934.375\n",
      "    learn_time_ms: 10698.065\n",
      "    load_throughput: 90218.855\n",
      "    load_time_ms: 110.797\n",
      "    sample_throughput: 63.388\n",
      "    sample_time_ms: 157694.863\n",
      "    update_time_ms: 13.24\n",
      "  timestamp: 1636406745\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7127148\n",
      "  training_iteration: 713\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   713</td><td style=\"text-align: right;\">          112308</td><td style=\"text-align: right;\">7127148</td><td style=\"text-align: right;\"> 4.01528</td><td style=\"text-align: right;\">               16.37</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">            92.463</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7137144\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-28-26\n",
      "  done: false\n",
      "  episode_len_mean: 91.38181818181818\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.150000000000013\n",
      "  episode_reward_mean: 3.9911818181818273\n",
      "  episode_reward_min: -1.1400000000000003\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 77229\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0200001526082683\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011477746263428243\n",
      "          policy_loss: -0.0600814120286805\n",
      "          total_loss: 0.10984115946210093\n",
      "          vf_explained_var: 0.9360304474830627\n",
      "          vf_loss: 0.16397483186302786\n",
      "    num_agent_steps_sampled: 7137144\n",
      "    num_agent_steps_trained: 7137144\n",
      "    num_steps_sampled: 7137144\n",
      "    num_steps_trained: 7137144\n",
      "  iterations_since_restore: 714\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.7995652173913\n",
      "    ram_util_percent: 58.10999999999998\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045494345998154724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.022200448220254\n",
      "    mean_inference_ms: 2.852846328465117\n",
      "    mean_raw_obs_processing_ms: 3.63675832637146\n",
      "  time_since_restore: 112468.87235736847\n",
      "  time_this_iter_s: 160.69638514518738\n",
      "  time_total_s: 112468.87235736847\n",
      "  timers:\n",
      "    learn_throughput: 934.177\n",
      "    learn_time_ms: 10700.327\n",
      "    load_throughput: 90625.749\n",
      "    load_time_ms: 110.3\n",
      "    sample_throughput: 63.661\n",
      "    sample_time_ms: 157019.253\n",
      "    update_time_ms: 14.08\n",
      "  timestamp: 1636406906\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7137144\n",
      "  training_iteration: 714\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   714</td><td style=\"text-align: right;\">          112469</td><td style=\"text-align: right;\">7137144</td><td style=\"text-align: right;\"> 3.99118</td><td style=\"text-align: right;\">               13.15</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           91.3818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7147140\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-31-12\n",
      "  done: false\n",
      "  episode_len_mean: 92.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.910000000000013\n",
      "  episode_reward_mean: 4.695740740740752\n",
      "  episode_reward_min: -1.640000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 77337\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.00985500486488\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012684829394120285\n",
      "          policy_loss: -0.056229871327582844\n",
      "          total_loss: 0.11162382393207751\n",
      "          vf_explained_var: 0.9428830146789551\n",
      "          vf_loss: 0.15905461947186889\n",
      "    num_agent_steps_sampled: 7147140\n",
      "    num_agent_steps_trained: 7147140\n",
      "    num_steps_sampled: 7147140\n",
      "    num_steps_trained: 7147140\n",
      "  iterations_since_restore: 715\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.80590717299577\n",
      "    ram_util_percent: 57.94556962025316\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0454948761170912\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.022167088872784\n",
      "    mean_inference_ms: 2.8527384428207485\n",
      "    mean_raw_obs_processing_ms: 3.6404918333556706\n",
      "  time_since_restore: 112635.04015946388\n",
      "  time_this_iter_s: 166.1678020954132\n",
      "  time_total_s: 112635.04015946388\n",
      "  timers:\n",
      "    learn_throughput: 934.086\n",
      "    learn_time_ms: 10701.365\n",
      "    load_throughput: 90752.079\n",
      "    load_time_ms: 110.146\n",
      "    sample_throughput: 63.36\n",
      "    sample_time_ms: 157765.08\n",
      "    update_time_ms: 13.9\n",
      "  timestamp: 1636407072\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7147140\n",
      "  training_iteration: 715\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   715</td><td style=\"text-align: right;\">          112635</td><td style=\"text-align: right;\">7147140</td><td style=\"text-align: right;\"> 4.69574</td><td style=\"text-align: right;\">               10.91</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">              92.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7157136\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-33-45\n",
      "  done: false\n",
      "  episode_len_mean: 92.4074074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.760000000000025\n",
      "  episode_reward_mean: 3.7915740740740835\n",
      "  episode_reward_min: -1.5100000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 77445\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.050736242176121\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011870733638322901\n",
      "          policy_loss: -0.059748457606213216\n",
      "          total_loss: 0.08425294217836653\n",
      "          vf_explained_var: 0.9249081015586853\n",
      "          vf_loss: 0.13746574516129545\n",
      "    num_agent_steps_sampled: 7157136\n",
      "    num_agent_steps_trained: 7157136\n",
      "    num_steps_sampled: 7157136\n",
      "    num_steps_trained: 7157136\n",
      "  iterations_since_restore: 716\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.89633027522936\n",
      "    ram_util_percent: 58.05091743119265\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553761648688224\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.025660517994666\n",
      "    mean_inference_ms: 2.8528945643807826\n",
      "    mean_raw_obs_processing_ms: 3.639904843887269\n",
      "  time_since_restore: 112787.68205976486\n",
      "  time_this_iter_s: 152.64190030097961\n",
      "  time_total_s: 112787.68205976486\n",
      "  timers:\n",
      "    learn_throughput: 934.125\n",
      "    learn_time_ms: 10700.928\n",
      "    load_throughput: 90606.379\n",
      "    load_time_ms: 110.323\n",
      "    sample_throughput: 63.889\n",
      "    sample_time_ms: 156459.556\n",
      "    update_time_ms: 13.826\n",
      "  timestamp: 1636407225\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7157136\n",
      "  training_iteration: 716\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   716</td><td style=\"text-align: right;\">          112788</td><td style=\"text-align: right;\">7157136</td><td style=\"text-align: right;\"> 3.79157</td><td style=\"text-align: right;\">               11.76</td><td style=\"text-align: right;\">               -1.51</td><td style=\"text-align: right;\">           92.4074</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7167132\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-36-32\n",
      "  done: false\n",
      "  episode_len_mean: 91.44036697247707\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.170000000000018\n",
      "  episode_reward_mean: 4.160642201834872\n",
      "  episode_reward_min: -1.1100000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 77554\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.03119687891414\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011833524843271654\n",
      "          policy_loss: -0.05559417099381487\n",
      "          total_loss: 0.12742955517660604\n",
      "          vf_explained_var: 0.925957977771759\n",
      "          vf_loss: 0.17637744553100604\n",
      "    num_agent_steps_sampled: 7167132\n",
      "    num_agent_steps_trained: 7167132\n",
      "    num_steps_sampled: 7167132\n",
      "    num_steps_trained: 7167132\n",
      "  iterations_since_restore: 717\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.7390756302521\n",
      "    ram_util_percent: 58.14201680672267\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553290160387254\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02591542430211\n",
      "    mean_inference_ms: 2.852997239762807\n",
      "    mean_raw_obs_processing_ms: 3.640163228706113\n",
      "  time_since_restore: 112954.55794000626\n",
      "  time_this_iter_s: 166.87588024139404\n",
      "  time_total_s: 112954.55794000626\n",
      "  timers:\n",
      "    learn_throughput: 934.017\n",
      "    learn_time_ms: 10702.156\n",
      "    load_throughput: 90540.342\n",
      "    load_time_ms: 110.404\n",
      "    sample_throughput: 64.662\n",
      "    sample_time_ms: 154589.45\n",
      "    update_time_ms: 13.27\n",
      "  timestamp: 1636407392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7167132\n",
      "  training_iteration: 717\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   717</td><td style=\"text-align: right;\">          112955</td><td style=\"text-align: right;\">7167132</td><td style=\"text-align: right;\"> 4.16064</td><td style=\"text-align: right;\">               14.17</td><td style=\"text-align: right;\">               -1.11</td><td style=\"text-align: right;\">           91.4404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7177128\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-39-10\n",
      "  done: false\n",
      "  episode_len_mean: 93.86792452830188\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 4.745471698113217\n",
      "  episode_reward_min: -1.1000000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 77660\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0138528601736083\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013171301611823833\n",
      "          policy_loss: -0.05400658314092419\n",
      "          total_loss: 0.1368710628710687\n",
      "          vf_explained_var: 0.9423031210899353\n",
      "          vf_loss: 0.1810103039440309\n",
      "    num_agent_steps_sampled: 7177128\n",
      "    num_agent_steps_trained: 7177128\n",
      "    num_steps_sampled: 7177128\n",
      "    num_steps_trained: 7177128\n",
      "  iterations_since_restore: 718\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.94581497797357\n",
      "    ram_util_percent: 58.040969162995594\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045568878451133575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02708261096174\n",
      "    mean_inference_ms: 2.852983688199593\n",
      "    mean_raw_obs_processing_ms: 3.643403701117889\n",
      "  time_since_restore: 113113.4484500885\n",
      "  time_this_iter_s: 158.89051008224487\n",
      "  time_total_s: 113113.4484500885\n",
      "  timers:\n",
      "    learn_throughput: 934.551\n",
      "    learn_time_ms: 10696.04\n",
      "    load_throughput: 90464.582\n",
      "    load_time_ms: 110.496\n",
      "    sample_throughput: 64.449\n",
      "    sample_time_ms: 155099.869\n",
      "    update_time_ms: 13.271\n",
      "  timestamp: 1636407550\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7177128\n",
      "  training_iteration: 718\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   718</td><td style=\"text-align: right;\">          113113</td><td style=\"text-align: right;\">7177128</td><td style=\"text-align: right;\"> 4.74547</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                -1.1</td><td style=\"text-align: right;\">           93.8679</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7187124\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-41-42\n",
      "  done: false\n",
      "  episode_len_mean: 94.32075471698113\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 4.419150943396236\n",
      "  episode_reward_min: -1.0600000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 77766\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.031149444417057\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011316223714665152\n",
      "          policy_loss: -0.06122471935824197\n",
      "          total_loss: 0.09020615061347047\n",
      "          vf_explained_var: 0.9501964449882507\n",
      "          vf_loss: 0.14596259128620737\n",
      "    num_agent_steps_sampled: 7187124\n",
      "    num_agent_steps_trained: 7187124\n",
      "    num_steps_sampled: 7187124\n",
      "    num_steps_trained: 7187124\n",
      "  iterations_since_restore: 719\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.06064814814815\n",
      "    ram_util_percent: 58.06481481481482\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551469416555404\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02576502149421\n",
      "    mean_inference_ms: 2.852651786458817\n",
      "    mean_raw_obs_processing_ms: 3.640622198540205\n",
      "  time_since_restore: 113265.36675548553\n",
      "  time_this_iter_s: 151.9183053970337\n",
      "  time_total_s: 113265.36675548553\n",
      "  timers:\n",
      "    learn_throughput: 934.453\n",
      "    learn_time_ms: 10697.168\n",
      "    load_throughput: 90687.536\n",
      "    load_time_ms: 110.225\n",
      "    sample_throughput: 66.217\n",
      "    sample_time_ms: 150958.741\n",
      "    update_time_ms: 13.252\n",
      "  timestamp: 1636407702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7187124\n",
      "  training_iteration: 719\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   719</td><td style=\"text-align: right;\">          113265</td><td style=\"text-align: right;\">7187124</td><td style=\"text-align: right;\"> 4.41915</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -1.06</td><td style=\"text-align: right;\">           94.3208</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7197120\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-43-59\n",
      "  done: false\n",
      "  episode_len_mean: 96.50961538461539\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.339999999999964\n",
      "  episode_reward_mean: 4.493173076923086\n",
      "  episode_reward_min: -1.2900000000000005\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 77870\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0242253014165112\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012548357961112854\n",
      "          policy_loss: -0.057597664173724306\n",
      "          total_loss: 0.1240085062960911\n",
      "          vf_explained_var: 0.9386026263237\n",
      "          vf_loss: 0.1732616967497728\n",
      "    num_agent_steps_sampled: 7197120\n",
      "    num_agent_steps_trained: 7197120\n",
      "    num_steps_sampled: 7197120\n",
      "    num_steps_trained: 7197120\n",
      "  iterations_since_restore: 720\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.3188775510204\n",
      "    ram_util_percent: 58.1362244897959\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045502193120860776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02587322499444\n",
      "    mean_inference_ms: 2.852692118907211\n",
      "    mean_raw_obs_processing_ms: 3.6361573651764467\n",
      "  time_since_restore: 113402.17282414436\n",
      "  time_this_iter_s: 136.80606865882874\n",
      "  time_total_s: 113402.17282414436\n",
      "  timers:\n",
      "    learn_throughput: 934.607\n",
      "    learn_time_ms: 10695.41\n",
      "    load_throughput: 90641.678\n",
      "    load_time_ms: 110.28\n",
      "    sample_throughput: 66.578\n",
      "    sample_time_ms: 150138.803\n",
      "    update_time_ms: 12.238\n",
      "  timestamp: 1636407839\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7197120\n",
      "  training_iteration: 720\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   720</td><td style=\"text-align: right;\">          113402</td><td style=\"text-align: right;\">7197120</td><td style=\"text-align: right;\"> 4.49317</td><td style=\"text-align: right;\">               16.34</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           96.5096</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7207116\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-47-12\n",
      "  done: false\n",
      "  episode_len_mean: 89.40178571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.020000000000014\n",
      "  episode_reward_mean: 3.9904464285714374\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 77982\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9971671561909536\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011856194484147233\n",
      "          policy_loss: -0.055342659628034654\n",
      "          total_loss: 0.10479840896864477\n",
      "          vf_explained_var: 0.9407345652580261\n",
      "          vf_loss: 0.153102846048836\n",
      "    num_agent_steps_sampled: 7207116\n",
      "    num_agent_steps_trained: 7207116\n",
      "    num_steps_sampled: 7207116\n",
      "    num_steps_trained: 7207116\n",
      "  iterations_since_restore: 721\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.72518248175182\n",
      "    ram_util_percent: 57.98248175182482\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548027034367904\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02396730634172\n",
      "    mean_inference_ms: 2.852634431879978\n",
      "    mean_raw_obs_processing_ms: 3.645642725212512\n",
      "  time_since_restore: 113594.51657557487\n",
      "  time_this_iter_s: 192.34375143051147\n",
      "  time_total_s: 113594.51657557487\n",
      "  timers:\n",
      "    learn_throughput: 934.568\n",
      "    learn_time_ms: 10695.85\n",
      "    load_throughput: 90420.236\n",
      "    load_time_ms: 110.55\n",
      "    sample_throughput: 65.911\n",
      "    sample_time_ms: 151660.076\n",
      "    update_time_ms: 12.055\n",
      "  timestamp: 1636408032\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7207116\n",
      "  training_iteration: 721\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   721</td><td style=\"text-align: right;\">          113595</td><td style=\"text-align: right;\">7207116</td><td style=\"text-align: right;\"> 3.99045</td><td style=\"text-align: right;\">               13.02</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           89.4018</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7217112\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-50-01\n",
      "  done: false\n",
      "  episode_len_mean: 92.74074074074075\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.610000000000015\n",
      "  episode_reward_mean: 3.65148148148149\n",
      "  episode_reward_min: -1.4600000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 78090\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0327119309678037\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01213062879591528\n",
      "          policy_loss: -0.05530587607341954\n",
      "          total_loss: 0.1251917515690319\n",
      "          vf_explained_var: 0.9315354824066162\n",
      "          vf_loss: 0.1731896580539198\n",
      "    num_agent_steps_sampled: 7217112\n",
      "    num_agent_steps_trained: 7217112\n",
      "    num_steps_sampled: 7217112\n",
      "    num_steps_trained: 7217112\n",
      "  iterations_since_restore: 722\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.57479338842977\n",
      "    ram_util_percent: 58.175206611570246\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549021280621824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.023236652052496\n",
      "    mean_inference_ms: 2.8525660495980496\n",
      "    mean_raw_obs_processing_ms: 3.6497465394728335\n",
      "  time_since_restore: 113763.98918795586\n",
      "  time_this_iter_s: 169.47261238098145\n",
      "  time_total_s: 113763.98918795586\n",
      "  timers:\n",
      "    learn_throughput: 934.805\n",
      "    learn_time_ms: 10693.14\n",
      "    load_throughput: 90330.155\n",
      "    load_time_ms: 110.661\n",
      "    sample_throughput: 66.1\n",
      "    sample_time_ms: 151226.171\n",
      "    update_time_ms: 12.722\n",
      "  timestamp: 1636408201\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7217112\n",
      "  training_iteration: 722\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   722</td><td style=\"text-align: right;\">          113764</td><td style=\"text-align: right;\">7217112</td><td style=\"text-align: right;\"> 3.65148</td><td style=\"text-align: right;\">               12.61</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           92.7407</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7227108\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-52-35\n",
      "  done: false\n",
      "  episode_len_mean: 94.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000014\n",
      "  episode_reward_mean: 4.001523809523819\n",
      "  episode_reward_min: -1.3300000000000005\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 78195\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0102528418231214\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011688445012013262\n",
      "          policy_loss: -0.055526922463288164\n",
      "          total_loss: 0.10454560821621209\n",
      "          vf_explained_var: 0.9291244149208069\n",
      "          vf_loss: 0.1535473197332432\n",
      "    num_agent_steps_sampled: 7227108\n",
      "    num_agent_steps_trained: 7227108\n",
      "    num_steps_sampled: 7227108\n",
      "    num_steps_trained: 7227108\n",
      "  iterations_since_restore: 723\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.00818181818182\n",
      "    ram_util_percent: 58.12681818181817\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552572044589457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0253922352074\n",
      "    mean_inference_ms: 2.8525856217402827\n",
      "    mean_raw_obs_processing_ms: 3.6489371926336585\n",
      "  time_since_restore: 113917.98983573914\n",
      "  time_this_iter_s: 154.00064778327942\n",
      "  time_total_s: 113917.98983573914\n",
      "  timers:\n",
      "    learn_throughput: 934.346\n",
      "    learn_time_ms: 10698.396\n",
      "    load_throughput: 90317.682\n",
      "    load_time_ms: 110.676\n",
      "    sample_throughput: 66.575\n",
      "    sample_time_ms: 150145.347\n",
      "    update_time_ms: 13.249\n",
      "  timestamp: 1636408355\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7227108\n",
      "  training_iteration: 723\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   723</td><td style=\"text-align: right;\">          113918</td><td style=\"text-align: right;\">7227108</td><td style=\"text-align: right;\"> 4.00152</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">              94.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7237104\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-55-33\n",
      "  done: false\n",
      "  episode_len_mean: 91.16363636363636\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.340000000000018\n",
      "  episode_reward_mean: 3.9061818181818264\n",
      "  episode_reward_min: -1.3200000000000005\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 78305\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0156822448102836\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011820195424776003\n",
      "          policy_loss: -0.05825386097352219\n",
      "          total_loss: 0.10705375150482879\n",
      "          vf_explained_var: 0.9327852725982666\n",
      "          vf_loss: 0.15853655209494197\n",
      "    num_agent_steps_sampled: 7237104\n",
      "    num_agent_steps_trained: 7237104\n",
      "    num_steps_sampled: 7237104\n",
      "    num_steps_trained: 7237104\n",
      "  iterations_since_restore: 724\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.12007874015748\n",
      "    ram_util_percent: 58.13976377952756\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549458290975213\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02400660191242\n",
      "    mean_inference_ms: 2.852723670134031\n",
      "    mean_raw_obs_processing_ms: 3.6523812295638414\n",
      "  time_since_restore: 114096.04222011566\n",
      "  time_this_iter_s: 178.05238437652588\n",
      "  time_total_s: 114096.04222011566\n",
      "  timers:\n",
      "    learn_throughput: 934.547\n",
      "    learn_time_ms: 10696.086\n",
      "    load_throughput: 90365.687\n",
      "    load_time_ms: 110.617\n",
      "    sample_throughput: 65.813\n",
      "    sample_time_ms: 151883.904\n",
      "    update_time_ms: 12.673\n",
      "  timestamp: 1636408533\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7237104\n",
      "  training_iteration: 724\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   724</td><td style=\"text-align: right;\">          114096</td><td style=\"text-align: right;\">7237104</td><td style=\"text-align: right;\"> 3.90618</td><td style=\"text-align: right;\">               14.34</td><td style=\"text-align: right;\">               -1.32</td><td style=\"text-align: right;\">           91.1636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7247100\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_21-58-06\n",
      "  done: false\n",
      "  episode_len_mean: 94.33962264150944\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.140000000000022\n",
      "  episode_reward_mean: 4.092547169811331\n",
      "  episode_reward_min: -1.670000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 78411\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0372923445497824\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012052569070812112\n",
      "          policy_loss: -0.05853349119106419\n",
      "          total_loss: 0.10877467658227453\n",
      "          vf_explained_var: 0.9346842169761658\n",
      "          vf_loss: 0.1602238317187398\n",
      "    num_agent_steps_sampled: 7247100\n",
      "    num_agent_steps_trained: 7247100\n",
      "    num_steps_sampled: 7247100\n",
      "    num_steps_trained: 7247100\n",
      "  iterations_since_restore: 725\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.32672811059909\n",
      "    ram_util_percent: 58.11336405529954\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552589233294643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02505565005495\n",
      "    mean_inference_ms: 2.85242214462968\n",
      "    mean_raw_obs_processing_ms: 3.6521767204960587\n",
      "  time_since_restore: 114248.22031354904\n",
      "  time_this_iter_s: 152.17809343338013\n",
      "  time_total_s: 114248.22031354904\n",
      "  timers:\n",
      "    learn_throughput: 934.957\n",
      "    learn_time_ms: 10691.4\n",
      "    load_throughput: 90339.595\n",
      "    load_time_ms: 110.649\n",
      "    sample_throughput: 66.423\n",
      "    sample_time_ms: 150489.117\n",
      "    update_time_ms: 12.945\n",
      "  timestamp: 1636408686\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7247100\n",
      "  training_iteration: 725\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   725</td><td style=\"text-align: right;\">          114248</td><td style=\"text-align: right;\">7247100</td><td style=\"text-align: right;\"> 4.09255</td><td style=\"text-align: right;\">               14.14</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           94.3396</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7257096\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-00-46\n",
      "  done: false\n",
      "  episode_len_mean: 93.70093457943925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.849999999999943\n",
      "  episode_reward_mean: 4.156822429906552\n",
      "  episode_reward_min: -1.570000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 78518\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0173763938439198\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011407888501915028\n",
      "          policy_loss: -0.059657845883351615\n",
      "          total_loss: 0.08257899337933741\n",
      "          vf_explained_var: 0.9452478289604187\n",
      "          vf_loss: 0.13642200656139697\n",
      "    num_agent_steps_sampled: 7257096\n",
      "    num_agent_steps_trained: 7257096\n",
      "    num_steps_sampled: 7257096\n",
      "    num_steps_trained: 7257096\n",
      "  iterations_since_restore: 726\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.20087719298243\n",
      "    ram_util_percent: 58.065789473684205\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552434914147019\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02729722172053\n",
      "    mean_inference_ms: 2.8525738662715256\n",
      "    mean_raw_obs_processing_ms: 3.6501056287254072\n",
      "  time_since_restore: 114408.23022079468\n",
      "  time_this_iter_s: 160.009907245636\n",
      "  time_total_s: 114408.23022079468\n",
      "  timers:\n",
      "    learn_throughput: 935.033\n",
      "    learn_time_ms: 10690.529\n",
      "    load_throughput: 90565.337\n",
      "    load_time_ms: 110.373\n",
      "    sample_throughput: 66.099\n",
      "    sample_time_ms: 151227.372\n",
      "    update_time_ms: 12.306\n",
      "  timestamp: 1636408846\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7257096\n",
      "  training_iteration: 726\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   726</td><td style=\"text-align: right;\">          114408</td><td style=\"text-align: right;\">7257096</td><td style=\"text-align: right;\"> 4.15682</td><td style=\"text-align: right;\">               15.85</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           93.7009</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7267092\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-03-36\n",
      "  done: false\n",
      "  episode_len_mean: 91.78899082568807\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.4\n",
      "  episode_reward_mean: 3.7322935779816606\n",
      "  episode_reward_min: -1.4800000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 78627\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0510700677195164\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012262078399526982\n",
      "          policy_loss: -0.057231969660163945\n",
      "          total_loss: 0.09862981089032613\n",
      "          vf_explained_var: 0.9325704574584961\n",
      "          vf_loss: 0.14843793337543806\n",
      "    num_agent_steps_sampled: 7267092\n",
      "    num_agent_steps_trained: 7267092\n",
      "    num_steps_sampled: 7267092\n",
      "    num_steps_trained: 7267092\n",
      "  iterations_since_restore: 727\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.23811475409835\n",
      "    ram_util_percent: 57.932377049180324\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045510057957930845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.02858943291845\n",
      "    mean_inference_ms: 2.8526920855307925\n",
      "    mean_raw_obs_processing_ms: 3.652214859858008\n",
      "  time_since_restore: 114578.84752392769\n",
      "  time_this_iter_s: 170.61730313301086\n",
      "  time_total_s: 114578.84752392769\n",
      "  timers:\n",
      "    learn_throughput: 933.917\n",
      "    learn_time_ms: 10703.303\n",
      "    load_throughput: 90595.22\n",
      "    load_time_ms: 110.337\n",
      "    sample_throughput: 65.942\n",
      "    sample_time_ms: 151588.867\n",
      "    update_time_ms: 12.21\n",
      "  timestamp: 1636409016\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7267092\n",
      "  training_iteration: 727\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   727</td><td style=\"text-align: right;\">          114579</td><td style=\"text-align: right;\">7267092</td><td style=\"text-align: right;\"> 3.73229</td><td style=\"text-align: right;\">                17.4</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">            91.789</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7277088\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-06-13\n",
      "  done: false\n",
      "  episode_len_mean: 92.36111111111111\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.13000000000001\n",
      "  episode_reward_mean: 4.201018518518527\n",
      "  episode_reward_min: -1.8100000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 78735\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.034145303363474\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011102612960196349\n",
      "          policy_loss: -0.057101103346635644\n",
      "          total_loss: 0.08113701401166937\n",
      "          vf_explained_var: 0.9345253705978394\n",
      "          vf_loss: 0.13328643060711204\n",
      "    num_agent_steps_sampled: 7277088\n",
      "    num_agent_steps_trained: 7277088\n",
      "    num_steps_sampled: 7277088\n",
      "    num_steps_trained: 7277088\n",
      "  iterations_since_restore: 728\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.65892857142856\n",
      "    ram_util_percent: 58.082589285714285\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455111827635425\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03118985218855\n",
      "    mean_inference_ms: 2.852553353385296\n",
      "    mean_raw_obs_processing_ms: 3.651200240986136\n",
      "  time_since_restore: 114735.79819130898\n",
      "  time_this_iter_s: 156.95066738128662\n",
      "  time_total_s: 114735.79819130898\n",
      "  timers:\n",
      "    learn_throughput: 933.9\n",
      "    learn_time_ms: 10703.5\n",
      "    load_throughput: 90772.042\n",
      "    load_time_ms: 110.122\n",
      "    sample_throughput: 66.026\n",
      "    sample_time_ms: 151395.879\n",
      "    update_time_ms: 11.74\n",
      "  timestamp: 1636409173\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7277088\n",
      "  training_iteration: 728\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   728</td><td style=\"text-align: right;\">          114736</td><td style=\"text-align: right;\">7277088</td><td style=\"text-align: right;\"> 4.20102</td><td style=\"text-align: right;\">               11.13</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           92.3611</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7287084\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-08-35\n",
      "  done: false\n",
      "  episode_len_mean: 96.21153846153847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.010000000000012\n",
      "  episode_reward_mean: 3.8376923076923166\n",
      "  episode_reward_min: -1.1400000000000008\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 78839\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0582993152814035\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011891968078500233\n",
      "          policy_loss: -0.05948771515335792\n",
      "          total_loss: 0.08780743692659287\n",
      "          vf_explained_var: 0.9333718419075012\n",
      "          vf_loss: 0.1407867544163496\n",
      "    num_agent_steps_sampled: 7287084\n",
      "    num_agent_steps_trained: 7287084\n",
      "    num_steps_sampled: 7287084\n",
      "    num_steps_trained: 7287084\n",
      "  iterations_since_restore: 729\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12178217821783\n",
      "    ram_util_percent: 58.146039603960396\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045511294021874586\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03361254993074\n",
      "    mean_inference_ms: 2.8526504587839265\n",
      "    mean_raw_obs_processing_ms: 3.646947748914364\n",
      "  time_since_restore: 114877.28209328651\n",
      "  time_this_iter_s: 141.48390197753906\n",
      "  time_total_s: 114877.28209328651\n",
      "  timers:\n",
      "    learn_throughput: 933.662\n",
      "    learn_time_ms: 10706.227\n",
      "    load_throughput: 90652.045\n",
      "    load_time_ms: 110.268\n",
      "    sample_throughput: 66.485\n",
      "    sample_time_ms: 150349.265\n",
      "    update_time_ms: 12.063\n",
      "  timestamp: 1636409315\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7287084\n",
      "  training_iteration: 729\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   729</td><td style=\"text-align: right;\">          114877</td><td style=\"text-align: right;\">7287084</td><td style=\"text-align: right;\"> 3.83769</td><td style=\"text-align: right;\">               13.01</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           96.2115</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7297080\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-11-25\n",
      "  done: false\n",
      "  episode_len_mean: 93.22429906542057\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.830000000000018\n",
      "  episode_reward_mean: 4.528411214953281\n",
      "  episode_reward_min: -1.5900000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 78946\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.019760281407935\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013021798589645245\n",
      "          policy_loss: -0.05175860460815776\n",
      "          total_loss: 0.12591833127264537\n",
      "          vf_explained_var: 0.9327818155288696\n",
      "          vf_loss: 0.16820925270549508\n",
      "    num_agent_steps_sampled: 7297080\n",
      "    num_agent_steps_trained: 7297080\n",
      "    num_steps_sampled: 7297080\n",
      "    num_steps_trained: 7297080\n",
      "  iterations_since_restore: 730\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.49547325102881\n",
      "    ram_util_percent: 58.01810699588477\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554760925626235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03669571509135\n",
      "    mean_inference_ms: 2.852638543744132\n",
      "    mean_raw_obs_processing_ms: 3.648662973920854\n",
      "  time_since_restore: 115047.62349557877\n",
      "  time_this_iter_s: 170.3414022922516\n",
      "  time_total_s: 115047.62349557877\n",
      "  timers:\n",
      "    learn_throughput: 933.506\n",
      "    learn_time_ms: 10708.014\n",
      "    load_throughput: 90609.395\n",
      "    load_time_ms: 110.32\n",
      "    sample_throughput: 65.035\n",
      "    sample_time_ms: 153701.283\n",
      "    update_time_ms: 11.807\n",
      "  timestamp: 1636409485\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7297080\n",
      "  training_iteration: 730\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   730</td><td style=\"text-align: right;\">          115048</td><td style=\"text-align: right;\">7297080</td><td style=\"text-align: right;\"> 4.52841</td><td style=\"text-align: right;\">               12.83</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           93.2243</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7307076\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-14-14\n",
      "  done: false\n",
      "  episode_len_mean: 94.16037735849056\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.199999999999996\n",
      "  episode_reward_mean: 4.73500000000001\n",
      "  episode_reward_min: -1.5600000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 79052\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0533513199569833\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011897653017366679\n",
      "          policy_loss: -0.05763450926726955\n",
      "          total_loss: 0.1202524099785548\n",
      "          vf_explained_var: 0.9344891309738159\n",
      "          vf_loss: 0.17131609205220244\n",
      "    num_agent_steps_sampled: 7307076\n",
      "    num_agent_steps_trained: 7307076\n",
      "    num_steps_sampled: 7307076\n",
      "    num_steps_trained: 7307076\n",
      "  iterations_since_restore: 731\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.11291666666666\n",
      "    ram_util_percent: 57.92166666666667\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045500702691574246\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03492257991006\n",
      "    mean_inference_ms: 2.8525754233696285\n",
      "    mean_raw_obs_processing_ms: 3.648555517207592\n",
      "  time_since_restore: 115216.19432091713\n",
      "  time_this_iter_s: 168.57082533836365\n",
      "  time_total_s: 115216.19432091713\n",
      "  timers:\n",
      "    learn_throughput: 933.836\n",
      "    learn_time_ms: 10704.233\n",
      "    load_throughput: 90744.046\n",
      "    load_time_ms: 110.156\n",
      "    sample_throughput: 66.055\n",
      "    sample_time_ms: 151328.263\n",
      "    update_time_ms: 11.686\n",
      "  timestamp: 1636409654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7307076\n",
      "  training_iteration: 731\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   731</td><td style=\"text-align: right;\">          115216</td><td style=\"text-align: right;\">7307076</td><td style=\"text-align: right;\">   4.735</td><td style=\"text-align: right;\">                18.2</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           94.1604</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7317072\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-16-47\n",
      "  done: false\n",
      "  episode_len_mean: 94.99056603773585\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.980000000000022\n",
      "  episode_reward_mean: 4.181037735849067\n",
      "  episode_reward_min: -1.2600000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 79158\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.045997083900321\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011494108122513788\n",
      "          policy_loss: -0.06000605127654779\n",
      "          total_loss: 0.09666544482366651\n",
      "          vf_explained_var: 0.9431989192962646\n",
      "          vf_loss: 0.15094645026211556\n",
      "    num_agent_steps_sampled: 7317072\n",
      "    num_agent_steps_trained: 7317072\n",
      "    num_steps_sampled: 7317072\n",
      "    num_steps_trained: 7317072\n",
      "  iterations_since_restore: 732\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.70366972477065\n",
      "    ram_util_percent: 58.09587155963303\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551516708414992\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03641986295346\n",
      "    mean_inference_ms: 2.85253852237966\n",
      "    mean_raw_obs_processing_ms: 3.6474519405641863\n",
      "  time_since_restore: 115369.04305505753\n",
      "  time_this_iter_s: 152.84873414039612\n",
      "  time_total_s: 115369.04305505753\n",
      "  timers:\n",
      "    learn_throughput: 934.096\n",
      "    learn_time_ms: 10701.258\n",
      "    load_throughput: 90683.358\n",
      "    load_time_ms: 110.23\n",
      "    sample_throughput: 66.787\n",
      "    sample_time_ms: 149669.273\n",
      "    update_time_ms: 11.082\n",
      "  timestamp: 1636409807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7317072\n",
      "  training_iteration: 732\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   732</td><td style=\"text-align: right;\">          115369</td><td style=\"text-align: right;\">7317072</td><td style=\"text-align: right;\"> 4.18104</td><td style=\"text-align: right;\">               11.98</td><td style=\"text-align: right;\">               -1.26</td><td style=\"text-align: right;\">           94.9906</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7327068\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-19-34\n",
      "  done: false\n",
      "  episode_len_mean: 94.625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.860000000000019\n",
      "  episode_reward_mean: 4.574134615384627\n",
      "  episode_reward_min: -1.1100000000000003\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 79262\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0277335254555076\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012174874751890852\n",
      "          policy_loss: -0.05804275814443827\n",
      "          total_loss: 0.0987998075552412\n",
      "          vf_explained_var: 0.951367199420929\n",
      "          vf_loss: 0.14938401209079047\n",
      "    num_agent_steps_sampled: 7327068\n",
      "    num_agent_steps_trained: 7327068\n",
      "    num_steps_sampled: 7327068\n",
      "    num_steps_trained: 7327068\n",
      "  iterations_since_restore: 733\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.56541666666666\n",
      "    ram_util_percent: 57.951666666666675\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045505861329418223\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.035753263350294\n",
      "    mean_inference_ms: 2.8528876685690654\n",
      "    mean_raw_obs_processing_ms: 3.647004585412279\n",
      "  time_since_restore: 115536.80843162537\n",
      "  time_this_iter_s: 167.76537656784058\n",
      "  time_total_s: 115536.80843162537\n",
      "  timers:\n",
      "    learn_throughput: 934.281\n",
      "    learn_time_ms: 10699.135\n",
      "    load_throughput: 90497.797\n",
      "    load_time_ms: 110.456\n",
      "    sample_throughput: 66.177\n",
      "    sample_time_ms: 151048.417\n",
      "    update_time_ms: 10.217\n",
      "  timestamp: 1636409974\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7327068\n",
      "  training_iteration: 733\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   733</td><td style=\"text-align: right;\">          115537</td><td style=\"text-align: right;\">7327068</td><td style=\"text-align: right;\"> 4.57413</td><td style=\"text-align: right;\">               12.86</td><td style=\"text-align: right;\">               -1.11</td><td style=\"text-align: right;\">            94.625</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7337064\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-22-46\n",
      "  done: false\n",
      "  episode_len_mean: 93.76851851851852\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.23000000000002\n",
      "  episode_reward_mean: 3.731759259259268\n",
      "  episode_reward_min: -1.930000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 79370\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.038976996882349\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011828768757171107\n",
      "          policy_loss: -0.05534471527824544\n",
      "          total_loss: 0.11038403545673459\n",
      "          vf_explained_var: 0.9308470487594604\n",
      "          vf_loss: 0.15917110562356365\n",
      "    num_agent_steps_sampled: 7337064\n",
      "    num_agent_steps_trained: 7337064\n",
      "    num_steps_sampled: 7337064\n",
      "    num_steps_trained: 7337064\n",
      "  iterations_since_restore: 734\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98205128205127\n",
      "    ram_util_percent: 58.04542124542125\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0454968021105155\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03403472915644\n",
      "    mean_inference_ms: 2.8522213160638206\n",
      "    mean_raw_obs_processing_ms: 3.6555054172592105\n",
      "  time_since_restore: 115728.0368885994\n",
      "  time_this_iter_s: 191.22845697402954\n",
      "  time_total_s: 115728.0368885994\n",
      "  timers:\n",
      "    learn_throughput: 933.956\n",
      "    learn_time_ms: 10702.862\n",
      "    load_throughput: 90220.564\n",
      "    load_time_ms: 110.795\n",
      "    sample_throughput: 65.607\n",
      "    sample_time_ms: 152361.902\n",
      "    update_time_ms: 10.768\n",
      "  timestamp: 1636410166\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7337064\n",
      "  training_iteration: 734\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   734</td><td style=\"text-align: right;\">          115728</td><td style=\"text-align: right;\">7337064</td><td style=\"text-align: right;\"> 3.73176</td><td style=\"text-align: right;\">               14.23</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">           93.7685</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7347060\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-25-41\n",
      "  done: false\n",
      "  episode_len_mean: 93.55660377358491\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.41999999999996\n",
      "  episode_reward_mean: 4.477924528301896\n",
      "  episode_reward_min: -1.3000000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 79476\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0674331850475736\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013028044283806006\n",
      "          policy_loss: -0.055405556843576266\n",
      "          total_loss: 0.12759616798283452\n",
      "          vf_explained_var: 0.9290504455566406\n",
      "          vf_loss: 0.17399654226918887\n",
      "    num_agent_steps_sampled: 7347060\n",
      "    num_agent_steps_trained: 7347060\n",
      "    num_steps_sampled: 7347060\n",
      "    num_steps_trained: 7347060\n",
      "  iterations_since_restore: 735\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.0408\n",
      "    ram_util_percent: 58.06920000000001\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550094482551177\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03484848415722\n",
      "    mean_inference_ms: 2.852474914450826\n",
      "    mean_raw_obs_processing_ms: 3.658586723415877\n",
      "  time_since_restore: 115903.54920339584\n",
      "  time_this_iter_s: 175.51231479644775\n",
      "  time_total_s: 115903.54920339584\n",
      "  timers:\n",
      "    learn_throughput: 933.673\n",
      "    learn_time_ms: 10706.103\n",
      "    load_throughput: 90204.064\n",
      "    load_time_ms: 110.815\n",
      "    sample_throughput: 64.619\n",
      "    sample_time_ms: 154690.378\n",
      "    update_time_ms: 12.185\n",
      "  timestamp: 1636410341\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7347060\n",
      "  training_iteration: 735\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   735</td><td style=\"text-align: right;\">          115904</td><td style=\"text-align: right;\">7347060</td><td style=\"text-align: right;\"> 4.47792</td><td style=\"text-align: right;\">               16.42</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">           93.5566</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7357056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-28-27\n",
      "  done: false\n",
      "  episode_len_mean: 91.88073394495413\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 3.651192660550467\n",
      "  episode_reward_min: -1.6800000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 79585\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0341403082904654\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010788334843446063\n",
      "          policy_loss: -0.053628795203935896\n",
      "          total_loss: 0.09037510212510824\n",
      "          vf_explained_var: 0.9271177649497986\n",
      "          vf_loss: 0.1397681246105677\n",
      "    num_agent_steps_sampled: 7357056\n",
      "    num_agent_steps_trained: 7357056\n",
      "    num_steps_sampled: 7357056\n",
      "    num_steps_trained: 7357056\n",
      "  iterations_since_restore: 736\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.76075949367089\n",
      "    ram_util_percent: 58.282700421940945\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553928052341409\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03676205503697\n",
      "    mean_inference_ms: 2.8524706021332786\n",
      "    mean_raw_obs_processing_ms: 3.660385736827077\n",
      "  time_since_restore: 116069.2162156105\n",
      "  time_this_iter_s: 165.66701221466064\n",
      "  time_total_s: 116069.2162156105\n",
      "  timers:\n",
      "    learn_throughput: 933.949\n",
      "    learn_time_ms: 10702.938\n",
      "    load_throughput: 90095.94\n",
      "    load_time_ms: 110.948\n",
      "    sample_throughput: 64.382\n",
      "    sample_time_ms: 155259.908\n",
      "    update_time_ms: 11.971\n",
      "  timestamp: 1636410507\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7357056\n",
      "  training_iteration: 736\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   736</td><td style=\"text-align: right;\">          116069</td><td style=\"text-align: right;\">7357056</td><td style=\"text-align: right;\"> 3.65119</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           91.8807</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7367052\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-31-06\n",
      "  done: false\n",
      "  episode_len_mean: 93.59813084112149\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.45000000000001\n",
      "  episode_reward_mean: 4.292897196261692\n",
      "  episode_reward_min: -1.4000000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 79692\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0417228762920088\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012750595400430855\n",
      "          policy_loss: -0.05653066739447924\n",
      "          total_loss: 0.10545919193034498\n",
      "          vf_explained_var: 0.9372024536132812\n",
      "          vf_loss: 0.1533596376227772\n",
      "    num_agent_steps_sampled: 7367052\n",
      "    num_agent_steps_trained: 7367052\n",
      "    num_steps_sampled: 7367052\n",
      "    num_steps_trained: 7367052\n",
      "  iterations_since_restore: 737\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.12787610619469\n",
      "    ram_util_percent: 58.21327433628318\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04547288923738072\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03538775522935\n",
      "    mean_inference_ms: 2.852130531025028\n",
      "    mean_raw_obs_processing_ms: 3.66031520013554\n",
      "  time_since_restore: 116227.90537929535\n",
      "  time_this_iter_s: 158.68916368484497\n",
      "  time_total_s: 116227.90537929535\n",
      "  timers:\n",
      "    learn_throughput: 934.811\n",
      "    learn_time_ms: 10693.071\n",
      "    load_throughput: 89846.529\n",
      "    load_time_ms: 111.256\n",
      "    sample_throughput: 64.877\n",
      "    sample_time_ms: 154075.343\n",
      "    update_time_ms: 13.095\n",
      "  timestamp: 1636410666\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7367052\n",
      "  training_iteration: 737\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   737</td><td style=\"text-align: right;\">          116228</td><td style=\"text-align: right;\">7367052</td><td style=\"text-align: right;\">  4.2929</td><td style=\"text-align: right;\">               16.45</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           93.5981</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7377048\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-33-59\n",
      "  done: false\n",
      "  episode_len_mean: 91.26605504587155\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 4.459633027522946\n",
      "  episode_reward_min: -1.2000000000000004\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 79801\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0088254397750918\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012482023730401177\n",
      "          policy_loss: -0.054839923076777375\n",
      "          total_loss: 0.1400323829239505\n",
      "          vf_explained_var: 0.9355411529541016\n",
      "          vf_loss: 0.1865249494329477\n",
      "    num_agent_steps_sampled: 7377048\n",
      "    num_agent_steps_trained: 7377048\n",
      "    num_steps_sampled: 7377048\n",
      "    num_steps_trained: 7377048\n",
      "  iterations_since_restore: 738\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.5429149797571\n",
      "    ram_util_percent: 58.24574898785427\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551014928552708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.04050416696072\n",
      "    mean_inference_ms: 2.8525883216346077\n",
      "    mean_raw_obs_processing_ms: 3.6595173147135394\n",
      "  time_since_restore: 116401.14754414558\n",
      "  time_this_iter_s: 173.24216485023499\n",
      "  time_total_s: 116401.14754414558\n",
      "  timers:\n",
      "    learn_throughput: 934.334\n",
      "    learn_time_ms: 10698.531\n",
      "    load_throughput: 89737.877\n",
      "    load_time_ms: 111.391\n",
      "    sample_throughput: 64.201\n",
      "    sample_time_ms: 155699.283\n",
      "    update_time_ms: 12.676\n",
      "  timestamp: 1636410839\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7377048\n",
      "  training_iteration: 738\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   738</td><td style=\"text-align: right;\">          116401</td><td style=\"text-align: right;\">7377048</td><td style=\"text-align: right;\"> 4.45963</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                -1.2</td><td style=\"text-align: right;\">           91.2661</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7387044\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-36-28\n",
      "  done: false\n",
      "  episode_len_mean: 92.5137614678899\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.660000000000018\n",
      "  episode_reward_mean: 3.8777981651376234\n",
      "  episode_reward_min: -1.580000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 79910\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0362442470004414\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01150486395574197\n",
      "          policy_loss: -0.056710921477876666\n",
      "          total_loss: 0.10201754594842592\n",
      "          vf_explained_var: 0.9392250776290894\n",
      "          vf_loss: 0.1528813900043949\n",
      "    num_agent_steps_sampled: 7387044\n",
      "    num_agent_steps_trained: 7387044\n",
      "    num_steps_sampled: 7387044\n",
      "    num_steps_trained: 7387044\n",
      "  iterations_since_restore: 739\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89295774647886\n",
      "    ram_util_percent: 58.16572769953049\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553806072630023\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.0454636211655\n",
      "    mean_inference_ms: 2.852462923447382\n",
      "    mean_raw_obs_processing_ms: 3.6568480495798785\n",
      "  time_since_restore: 116550.51245999336\n",
      "  time_this_iter_s: 149.36491584777832\n",
      "  time_total_s: 116550.51245999336\n",
      "  timers:\n",
      "    learn_throughput: 934.68\n",
      "    learn_time_ms: 10694.564\n",
      "    load_throughput: 89893.841\n",
      "    load_time_ms: 111.198\n",
      "    sample_throughput: 63.875\n",
      "    sample_time_ms: 156491.965\n",
      "    update_time_ms: 12.185\n",
      "  timestamp: 1636410988\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7387044\n",
      "  training_iteration: 739\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   739</td><td style=\"text-align: right;\">          116551</td><td style=\"text-align: right;\">7387044</td><td style=\"text-align: right;\">  3.8778</td><td style=\"text-align: right;\">               12.66</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           92.5138</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7397040\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-39-37\n",
      "  done: false\n",
      "  episode_len_mean: 91.94444444444444\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000015\n",
      "  episode_reward_mean: 4.4421296296296395\n",
      "  episode_reward_min: -1.4600000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 80018\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0463558953032535\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011305528871457433\n",
      "          policy_loss: -0.0561179808826528\n",
      "          total_loss: 0.10134090690706403\n",
      "          vf_explained_var: 0.9467591643333435\n",
      "          vf_loss: 0.15216703792540437\n",
      "    num_agent_steps_sampled: 7397040\n",
      "    num_agent_steps_trained: 7397040\n",
      "    num_steps_sampled: 7397040\n",
      "    num_steps_trained: 7397040\n",
      "  iterations_since_restore: 740\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.28252788104089\n",
      "    ram_util_percent: 58.14423791821561\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550501881786863\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.044239992929455\n",
      "    mean_inference_ms: 2.852302124401877\n",
      "    mean_raw_obs_processing_ms: 3.666696470420671\n",
      "  time_since_restore: 116738.89045095444\n",
      "  time_this_iter_s: 188.37799096107483\n",
      "  time_total_s: 116738.89045095444\n",
      "  timers:\n",
      "    learn_throughput: 934.706\n",
      "    learn_time_ms: 10694.272\n",
      "    load_throughput: 89927.468\n",
      "    load_time_ms: 111.156\n",
      "    sample_throughput: 63.148\n",
      "    sample_time_ms: 158295.311\n",
      "    update_time_ms: 12.531\n",
      "  timestamp: 1636411177\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7397040\n",
      "  training_iteration: 740\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   740</td><td style=\"text-align: right;\">          116739</td><td style=\"text-align: right;\">7397040</td><td style=\"text-align: right;\"> 4.44213</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           91.9444</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7407036\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-42-30\n",
      "  done: false\n",
      "  episode_len_mean: 91.95454545454545\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.24999999999994\n",
      "  episode_reward_mean: 4.506818181818191\n",
      "  episode_reward_min: -1.6000000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 80128\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.047503886671148\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011843694274140502\n",
      "          policy_loss: -0.05820201242931633\n",
      "          total_loss: 0.12441963337234452\n",
      "          vf_explained_var: 0.9320133328437805\n",
      "          vf_loss: 0.17611526762111446\n",
      "    num_agent_steps_sampled: 7407036\n",
      "    num_agent_steps_trained: 7407036\n",
      "    num_steps_sampled: 7407036\n",
      "    num_steps_trained: 7407036\n",
      "  iterations_since_restore: 741\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.44858299595143\n",
      "    ram_util_percent: 58.23157894736844\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551233267593681\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.044854012215986\n",
      "    mean_inference_ms: 2.852520566993764\n",
      "    mean_raw_obs_processing_ms: 3.6703027042257057\n",
      "  time_since_restore: 116912.1144759655\n",
      "  time_this_iter_s: 173.22402501106262\n",
      "  time_total_s: 116912.1144759655\n",
      "  timers:\n",
      "    learn_throughput: 934.586\n",
      "    learn_time_ms: 10695.64\n",
      "    load_throughput: 89955.29\n",
      "    load_time_ms: 111.122\n",
      "    sample_throughput: 62.964\n",
      "    sample_time_ms: 158758.129\n",
      "    update_time_ms: 13.514\n",
      "  timestamp: 1636411350\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7407036\n",
      "  training_iteration: 741\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   741</td><td style=\"text-align: right;\">          116912</td><td style=\"text-align: right;\">7407036</td><td style=\"text-align: right;\"> 4.50682</td><td style=\"text-align: right;\">               18.25</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           91.9545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7417032\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-45-16\n",
      "  done: false\n",
      "  episode_len_mean: 89.27927927927928\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.99000000000001\n",
      "  episode_reward_mean: 3.8918918918919\n",
      "  episode_reward_min: -1.4200000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 80239\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.031227233369126\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011895708496474273\n",
      "          policy_loss: -0.055736197090238075\n",
      "          total_loss: 0.1284681188635146\n",
      "          vf_explained_var: 0.9300735592842102\n",
      "          vf_loss: 0.1774166767222759\n",
      "    num_agent_steps_sampled: 7417032\n",
      "    num_agent_steps_trained: 7417032\n",
      "    num_steps_sampled: 7417032\n",
      "    num_steps_trained: 7417032\n",
      "  iterations_since_restore: 742\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.31054852320676\n",
      "    ram_util_percent: 58.30843881856539\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548199962530303\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.045704915887264\n",
      "    mean_inference_ms: 2.852205000788507\n",
      "    mean_raw_obs_processing_ms: 3.6723922810242953\n",
      "  time_since_restore: 117077.59405970573\n",
      "  time_this_iter_s: 165.47958374023438\n",
      "  time_total_s: 117077.59405970573\n",
      "  timers:\n",
      "    learn_throughput: 934.281\n",
      "    learn_time_ms: 10699.14\n",
      "    load_throughput: 90021.984\n",
      "    load_time_ms: 111.04\n",
      "    sample_throughput: 62.468\n",
      "    sample_time_ms: 160017.845\n",
      "    update_time_ms: 13.629\n",
      "  timestamp: 1636411516\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7417032\n",
      "  training_iteration: 742\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   742</td><td style=\"text-align: right;\">          117078</td><td style=\"text-align: right;\">7417032</td><td style=\"text-align: right;\"> 3.89189</td><td style=\"text-align: right;\">               12.99</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           89.2793</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7427028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-47-40\n",
      "  done: false\n",
      "  episode_len_mean: 94.16981132075472\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.62999999999998\n",
      "  episode_reward_mean: 4.982169811320766\n",
      "  episode_reward_min: -2.1100000000000003\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 80345\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0397506693489533\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012613751222182093\n",
      "          policy_loss: -0.05883433396935973\n",
      "          total_loss: 0.11681097865614117\n",
      "          vf_explained_var: 0.9466959834098816\n",
      "          vf_loss: 0.16730711615015553\n",
      "    num_agent_steps_sampled: 7427028\n",
      "    num_agent_steps_trained: 7427028\n",
      "    num_steps_sampled: 7427028\n",
      "    num_steps_trained: 7427028\n",
      "  iterations_since_restore: 743\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72233009708738\n",
      "    ram_util_percent: 58.180097087378634\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045527853022160704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05033722916514\n",
      "    mean_inference_ms: 2.8522954248913024\n",
      "    mean_raw_obs_processing_ms: 3.669069758770782\n",
      "  time_since_restore: 117222.03611660004\n",
      "  time_this_iter_s: 144.44205689430237\n",
      "  time_total_s: 117222.03611660004\n",
      "  timers:\n",
      "    learn_throughput: 934.456\n",
      "    learn_time_ms: 10697.134\n",
      "    load_throughput: 90314.9\n",
      "    load_time_ms: 110.679\n",
      "    sample_throughput: 63.391\n",
      "    sample_time_ms: 157688.44\n",
      "    update_time_ms: 13.134\n",
      "  timestamp: 1636411660\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7427028\n",
      "  training_iteration: 743\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   743</td><td style=\"text-align: right;\">          117222</td><td style=\"text-align: right;\">7427028</td><td style=\"text-align: right;\"> 4.98217</td><td style=\"text-align: right;\">               16.63</td><td style=\"text-align: right;\">               -2.11</td><td style=\"text-align: right;\">           94.1698</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7437024\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-50-21\n",
      "  done: false\n",
      "  episode_len_mean: 93.36111111111111\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.69000000000001\n",
      "  episode_reward_mean: 4.663981481481493\n",
      "  episode_reward_min: -1.6800000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 80453\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0201648286265184\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012508680471655277\n",
      "          policy_loss: -0.056477974395020905\n",
      "          total_loss: 0.1225447240500496\n",
      "          vf_explained_var: 0.9378181099891663\n",
      "          vf_loss: 0.17072800820390893\n",
      "    num_agent_steps_sampled: 7437024\n",
      "    num_agent_steps_trained: 7437024\n",
      "    num_steps_sampled: 7437024\n",
      "    num_steps_trained: 7437024\n",
      "  iterations_since_restore: 744\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.52532751091702\n",
      "    ram_util_percent: 58.29650655021836\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04554115154251711\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05384713967853\n",
      "    mean_inference_ms: 2.852627553651082\n",
      "    mean_raw_obs_processing_ms: 3.66638565731822\n",
      "  time_since_restore: 117382.93087053299\n",
      "  time_this_iter_s: 160.89475393295288\n",
      "  time_total_s: 117382.93087053299\n",
      "  timers:\n",
      "    learn_throughput: 934.535\n",
      "    learn_time_ms: 10696.229\n",
      "    load_throughput: 90502.642\n",
      "    load_time_ms: 110.45\n",
      "    sample_throughput: 64.634\n",
      "    sample_time_ms: 154654.807\n",
      "    update_time_ms: 14.316\n",
      "  timestamp: 1636411821\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7437024\n",
      "  training_iteration: 744\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   744</td><td style=\"text-align: right;\">          117383</td><td style=\"text-align: right;\">7437024</td><td style=\"text-align: right;\"> 4.66398</td><td style=\"text-align: right;\">               16.69</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           93.3611</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7447020\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-53-16\n",
      "  done: false\n",
      "  episode_len_mean: 89.09821428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.440000000000019\n",
      "  episode_reward_mean: 4.483035714285725\n",
      "  episode_reward_min: -1.4300000000000004\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 80565\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0365759150594727\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011946285929324662\n",
      "          policy_loss: -0.05552857765911991\n",
      "          total_loss: 0.13537399010000448\n",
      "          vf_explained_var: 0.9379496574401855\n",
      "          vf_loss: 0.18405319263155645\n",
      "    num_agent_steps_sampled: 7447020\n",
      "    num_agent_steps_trained: 7447020\n",
      "    num_steps_sampled: 7447020\n",
      "    num_steps_trained: 7447020\n",
      "  iterations_since_restore: 745\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.17630522088353\n",
      "    ram_util_percent: 58.29799196787149\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045503153383937074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05461448392851\n",
      "    mean_inference_ms: 2.852148084073957\n",
      "    mean_raw_obs_processing_ms: 3.670270653646824\n",
      "  time_since_restore: 117557.53237509727\n",
      "  time_this_iter_s: 174.60150456428528\n",
      "  time_total_s: 117557.53237509727\n",
      "  timers:\n",
      "    learn_throughput: 934.791\n",
      "    learn_time_ms: 10693.299\n",
      "    load_throughput: 90511.238\n",
      "    load_time_ms: 110.439\n",
      "    sample_throughput: 64.67\n",
      "    sample_time_ms: 154568.855\n",
      "    update_time_ms: 12.326\n",
      "  timestamp: 1636411996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7447020\n",
      "  training_iteration: 745\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   745</td><td style=\"text-align: right;\">          117558</td><td style=\"text-align: right;\">7447020</td><td style=\"text-align: right;\"> 4.48304</td><td style=\"text-align: right;\">               12.44</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           89.0982</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7457016\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-55-53\n",
      "  done: false\n",
      "  episode_len_mean: 93.07476635514018\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.850000000000016\n",
      "  episode_reward_mean: 5.16196261682244\n",
      "  episode_reward_min: -1.4100000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 80672\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.008964231482938\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01307501335594129\n",
      "          policy_loss: -0.054708013995590374\n",
      "          total_loss: 0.15617696300156925\n",
      "          vf_explained_var: 0.9474495649337769\n",
      "          vf_loss: 0.20118810532248427\n",
      "    num_agent_steps_sampled: 7457016\n",
      "    num_agent_steps_trained: 7457016\n",
      "    num_steps_sampled: 7457016\n",
      "    num_steps_trained: 7457016\n",
      "  iterations_since_restore: 746\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.8\n",
      "    ram_util_percent: 58.38666666666668\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045506868272384766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05721294540662\n",
      "    mean_inference_ms: 2.8524323339156004\n",
      "    mean_raw_obs_processing_ms: 3.6674962186082296\n",
      "  time_since_restore: 117714.61663484573\n",
      "  time_this_iter_s: 157.08425974845886\n",
      "  time_total_s: 117714.61663484573\n",
      "  timers:\n",
      "    learn_throughput: 934.769\n",
      "    learn_time_ms: 10693.55\n",
      "    load_throughput: 90562.618\n",
      "    load_time_ms: 110.377\n",
      "    sample_throughput: 65.032\n",
      "    sample_time_ms: 153709.281\n",
      "    update_time_ms: 13.199\n",
      "  timestamp: 1636412153\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7457016\n",
      "  training_iteration: 746\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   746</td><td style=\"text-align: right;\">          117715</td><td style=\"text-align: right;\">7457016</td><td style=\"text-align: right;\"> 5.16196</td><td style=\"text-align: right;\">               14.85</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           93.0748</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7467012\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-58-39\n",
      "  done: false\n",
      "  episode_len_mean: 92.26851851851852\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.02000000000001\n",
      "  episode_reward_mean: 4.303703703703713\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 80780\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0558470992960483\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011127347955278756\n",
      "          policy_loss: -0.05982140930385416\n",
      "          total_loss: 0.10165759332987488\n",
      "          vf_explained_var: 0.9438791871070862\n",
      "          vf_loss: 0.1566879836221536\n",
      "    num_agent_steps_sampled: 7467012\n",
      "    num_agent_steps_trained: 7467012\n",
      "    num_steps_sampled: 7467012\n",
      "    num_steps_trained: 7467012\n",
      "  iterations_since_restore: 747\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.66877637130801\n",
      "    ram_util_percent: 58.48438818565399\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045516757399717396\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05810536821996\n",
      "    mean_inference_ms: 2.852464080688985\n",
      "    mean_raw_obs_processing_ms: 3.668217058970955\n",
      "  time_since_restore: 117881.15522670746\n",
      "  time_this_iter_s: 166.53859186172485\n",
      "  time_total_s: 117881.15522670746\n",
      "  timers:\n",
      "    learn_throughput: 934.921\n",
      "    learn_time_ms: 10691.814\n",
      "    load_throughput: 90561.581\n",
      "    load_time_ms: 110.378\n",
      "    sample_throughput: 64.701\n",
      "    sample_time_ms: 154496.2\n",
      "    update_time_ms: 13.063\n",
      "  timestamp: 1636412319\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7467012\n",
      "  training_iteration: 747\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   747</td><td style=\"text-align: right;\">          117881</td><td style=\"text-align: right;\">7467012</td><td style=\"text-align: right;\">  4.3037</td><td style=\"text-align: right;\">               13.02</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           92.2685</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7477008\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-01-31\n",
      "  done: false\n",
      "  episode_len_mean: 91.24770642201835\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.139999999999997\n",
      "  episode_reward_mean: 4.433669724770652\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 80889\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.026423074037601\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013124004855926567\n",
      "          policy_loss: -0.053203143313145025\n",
      "          total_loss: 0.16760867146186084\n",
      "          vf_explained_var: 0.928193986415863\n",
      "          vf_loss: 0.21117792199564794\n",
      "    num_agent_steps_sampled: 7477008\n",
      "    num_agent_steps_trained: 7477008\n",
      "    num_steps_sampled: 7477008\n",
      "    num_steps_trained: 7477008\n",
      "  iterations_since_restore: 748\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.14204081632653\n",
      "    ram_util_percent: 58.48367346938775\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04547392252154766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.05710687601465\n",
      "    mean_inference_ms: 2.852217498018751\n",
      "    mean_raw_obs_processing_ms: 3.6688630901657597\n",
      "  time_since_restore: 118052.79821372032\n",
      "  time_this_iter_s: 171.64298701286316\n",
      "  time_total_s: 118052.79821372032\n",
      "  timers:\n",
      "    learn_throughput: 935.414\n",
      "    learn_time_ms: 10686.172\n",
      "    load_throughput: 90569.935\n",
      "    load_time_ms: 110.368\n",
      "    sample_throughput: 64.765\n",
      "    sample_time_ms: 154341.573\n",
      "    update_time_ms: 13.357\n",
      "  timestamp: 1636412491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7477008\n",
      "  training_iteration: 748\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   748</td><td style=\"text-align: right;\">          118053</td><td style=\"text-align: right;\">7477008</td><td style=\"text-align: right;\"> 4.43367</td><td style=\"text-align: right;\">               17.14</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">           91.2477</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7487004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-04-06\n",
      "  done: false\n",
      "  episode_len_mean: 92.3425925925926\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.249999999999947\n",
      "  episode_reward_mean: 4.293148148148157\n",
      "  episode_reward_min: -1.2100000000000009\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 80997\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.04289796556163\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01217280110684102\n",
      "          policy_loss: -0.056390302427686174\n",
      "          total_loss: 0.12238854250003002\n",
      "          vf_explained_var: 0.9357507228851318\n",
      "          vf_loss: 0.17147666105411502\n",
      "    num_agent_steps_sampled: 7487004\n",
      "    num_agent_steps_trained: 7487004\n",
      "    num_steps_sampled: 7487004\n",
      "    num_steps_trained: 7487004\n",
      "  iterations_since_restore: 749\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.79864864864867\n",
      "    ram_util_percent: 58.460810810810806\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045506155853373365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06083252235793\n",
      "    mean_inference_ms: 2.8522796089730273\n",
      "    mean_raw_obs_processing_ms: 3.667741113107465\n",
      "  time_since_restore: 118208.05999159813\n",
      "  time_this_iter_s: 155.26177787780762\n",
      "  time_total_s: 118208.05999159813\n",
      "  timers:\n",
      "    learn_throughput: 935.647\n",
      "    learn_time_ms: 10683.519\n",
      "    load_throughput: 90423.668\n",
      "    load_time_ms: 110.546\n",
      "    sample_throughput: 64.518\n",
      "    sample_time_ms: 154934.002\n",
      "    update_time_ms: 13.161\n",
      "  timestamp: 1636412646\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7487004\n",
      "  training_iteration: 749\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   749</td><td style=\"text-align: right;\">          118208</td><td style=\"text-align: right;\">7487004</td><td style=\"text-align: right;\"> 4.29315</td><td style=\"text-align: right;\">               18.25</td><td style=\"text-align: right;\">               -1.21</td><td style=\"text-align: right;\">           92.3426</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7497000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-06-34\n",
      "  done: false\n",
      "  episode_len_mean: 92.53211009174312\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.940000000000008\n",
      "  episode_reward_mean: 4.645596330275239\n",
      "  episode_reward_min: -1.4199999999999997\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 81106\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0456599166250635\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012340468493478028\n",
      "          policy_loss: -0.056597922070540936\n",
      "          total_loss: 0.12374270977293197\n",
      "          vf_explained_var: 0.9430824518203735\n",
      "          vf_loss: 0.17268410038489562\n",
      "    num_agent_steps_sampled: 7497000\n",
      "    num_agent_steps_trained: 7497000\n",
      "    num_steps_sampled: 7497000\n",
      "    num_steps_trained: 7497000\n",
      "  iterations_since_restore: 750\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.20190476190477\n",
      "    ram_util_percent: 58.448095238095235\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04547478183461764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06347328041265\n",
      "    mean_inference_ms: 2.852235195536081\n",
      "    mean_raw_obs_processing_ms: 3.663403851805678\n",
      "  time_since_restore: 118355.72925686836\n",
      "  time_this_iter_s: 147.66926527023315\n",
      "  time_total_s: 118355.72925686836\n",
      "  timers:\n",
      "    learn_throughput: 935.68\n",
      "    learn_time_ms: 10683.135\n",
      "    load_throughput: 90239.846\n",
      "    load_time_ms: 110.771\n",
      "    sample_throughput: 66.259\n",
      "    sample_time_ms: 150863.477\n",
      "    update_time_ms: 13.291\n",
      "  timestamp: 1636412794\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7497000\n",
      "  training_iteration: 750\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   750</td><td style=\"text-align: right;\">          118356</td><td style=\"text-align: right;\">7497000</td><td style=\"text-align: right;\">  4.6456</td><td style=\"text-align: right;\">               12.94</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           92.5321</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7506996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-09-38\n",
      "  done: false\n",
      "  episode_len_mean: 90.69090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.250000000000016\n",
      "  episode_reward_mean: 3.8102727272727357\n",
      "  episode_reward_min: -1.6800000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 81216\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0604707327663387\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011300725914708163\n",
      "          policy_loss: -0.05926519298615555\n",
      "          total_loss: 0.08230763078054301\n",
      "          vf_explained_var: 0.9466552734375\n",
      "          vf_loss: 0.13643306438675804\n",
      "    num_agent_steps_sampled: 7506996\n",
      "    num_agent_steps_trained: 7506996\n",
      "    num_steps_sampled: 7506996\n",
      "    num_steps_trained: 7506996\n",
      "  iterations_since_restore: 751\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.80988593155894\n",
      "    ram_util_percent: 58.467300380228146\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455176052035594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.066690919721076\n",
      "    mean_inference_ms: 2.8522744359066823\n",
      "    mean_raw_obs_processing_ms: 3.667231775846031\n",
      "  time_since_restore: 118539.72280287743\n",
      "  time_this_iter_s: 183.99354600906372\n",
      "  time_total_s: 118539.72280287743\n",
      "  timers:\n",
      "    learn_throughput: 935.549\n",
      "    learn_time_ms: 10684.636\n",
      "    load_throughput: 89998.119\n",
      "    load_time_ms: 111.069\n",
      "    sample_throughput: 65.789\n",
      "    sample_time_ms: 151939.785\n",
      "    update_time_ms: 12.164\n",
      "  timestamp: 1636412978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7506996\n",
      "  training_iteration: 751\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   751</td><td style=\"text-align: right;\">          118540</td><td style=\"text-align: right;\">7506996</td><td style=\"text-align: right;\"> 3.81027</td><td style=\"text-align: right;\">               12.25</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           90.6909</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7516992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-12-49\n",
      "  done: false\n",
      "  episode_len_mean: 88.14912280701755\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.400000000000016\n",
      "  episode_reward_mean: 3.8841228070175524\n",
      "  episode_reward_min: -1.2900000000000005\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 81330\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.020374859907688\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011301942456527162\n",
      "          policy_loss: -0.052696043763182356\n",
      "          total_loss: 0.13813106537693076\n",
      "          vf_explained_var: 0.9267853498458862\n",
      "          vf_loss: 0.185283619329397\n",
      "    num_agent_steps_sampled: 7516992\n",
      "    num_agent_steps_trained: 7516992\n",
      "    num_steps_sampled: 7516992\n",
      "    num_steps_trained: 7516992\n",
      "  iterations_since_restore: 752\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.79227941176472\n",
      "    ram_util_percent: 58.49117647058823\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045506038653427124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06686768150167\n",
      "    mean_inference_ms: 2.852209185613917\n",
      "    mean_raw_obs_processing_ms: 3.6735500406653774\n",
      "  time_since_restore: 118730.2979400158\n",
      "  time_this_iter_s: 190.5751371383667\n",
      "  time_total_s: 118730.2979400158\n",
      "  timers:\n",
      "    learn_throughput: 936.184\n",
      "    learn_time_ms: 10677.386\n",
      "    load_throughput: 89893.263\n",
      "    load_time_ms: 111.199\n",
      "    sample_throughput: 64.718\n",
      "    sample_time_ms: 154455.724\n",
      "    update_time_ms: 12.463\n",
      "  timestamp: 1636413169\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7516992\n",
      "  training_iteration: 752\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   752</td><td style=\"text-align: right;\">          118730</td><td style=\"text-align: right;\">7516992</td><td style=\"text-align: right;\"> 3.88412</td><td style=\"text-align: right;\">                14.4</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           88.1491</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7526988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-15-39\n",
      "  done: false\n",
      "  episode_len_mean: 91.11009174311927\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.730000000000015\n",
      "  episode_reward_mean: 4.385412844036708\n",
      "  episode_reward_min: -1.5200000000000007\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 81439\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0313136697834375\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011728952882483283\n",
      "          policy_loss: -0.05573898928526502\n",
      "          total_loss: 0.11179539007731737\n",
      "          vf_explained_var: 0.930083155632019\n",
      "          vf_loss: 0.16112749386722078\n",
      "    num_agent_steps_sampled: 7526988\n",
      "    num_agent_steps_trained: 7526988\n",
      "    num_steps_sampled: 7526988\n",
      "    num_steps_trained: 7526988\n",
      "  iterations_since_restore: 753\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.46033057851238\n",
      "    ram_util_percent: 58.5400826446281\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549289962724997\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06592913233112\n",
      "    mean_inference_ms: 2.8521776552681195\n",
      "    mean_raw_obs_processing_ms: 3.6763943814751494\n",
      "  time_since_restore: 118900.21499967575\n",
      "  time_this_iter_s: 169.91705965995789\n",
      "  time_total_s: 118900.21499967575\n",
      "  timers:\n",
      "    learn_throughput: 935.802\n",
      "    learn_time_ms: 10681.749\n",
      "    load_throughput: 89625.386\n",
      "    load_time_ms: 111.531\n",
      "    sample_throughput: 63.67\n",
      "    sample_time_ms: 156997.822\n",
      "    update_time_ms: 13.181\n",
      "  timestamp: 1636413339\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7526988\n",
      "  training_iteration: 753\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   753</td><td style=\"text-align: right;\">          118900</td><td style=\"text-align: right;\">7526988</td><td style=\"text-align: right;\"> 4.38541</td><td style=\"text-align: right;\">               16.73</td><td style=\"text-align: right;\">               -1.52</td><td style=\"text-align: right;\">           91.1101</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7536984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-18-05\n",
      "  done: false\n",
      "  episode_len_mean: 90.009009009009\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.500000000000016\n",
      "  episode_reward_mean: 3.579369369369378\n",
      "  episode_reward_min: -1.5800000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 81550\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0709400904484285\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011151175346368924\n",
      "          policy_loss: -0.06263814110340726\n",
      "          total_loss: 0.06575608470946805\n",
      "          vf_explained_var: 0.9507629871368408\n",
      "          vf_loss: 0.1236998541933349\n",
      "    num_agent_steps_sampled: 7536984\n",
      "    num_agent_steps_trained: 7536984\n",
      "    num_steps_sampled: 7536984\n",
      "    num_steps_trained: 7536984\n",
      "  iterations_since_restore: 754\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.20095693779905\n",
      "    ram_util_percent: 58.504306220095685\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045482392807221335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.069785332979336\n",
      "    mean_inference_ms: 2.8521512603412313\n",
      "    mean_raw_obs_processing_ms: 3.672699375139751\n",
      "  time_since_restore: 119046.52215194702\n",
      "  time_this_iter_s: 146.30715227127075\n",
      "  time_total_s: 119046.52215194702\n",
      "  timers:\n",
      "    learn_throughput: 936.101\n",
      "    learn_time_ms: 10678.33\n",
      "    load_throughput: 89513.942\n",
      "    load_time_ms: 111.67\n",
      "    sample_throughput: 64.265\n",
      "    sample_time_ms: 155543.803\n",
      "    update_time_ms: 11.606\n",
      "  timestamp: 1636413485\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7536984\n",
      "  training_iteration: 754\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   754</td><td style=\"text-align: right;\">          119047</td><td style=\"text-align: right;\">7536984</td><td style=\"text-align: right;\"> 3.57937</td><td style=\"text-align: right;\">                10.5</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">            90.009</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7546980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-20-41\n",
      "  done: false\n",
      "  episode_len_mean: 92.08256880733946\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.600000000000016\n",
      "  episode_reward_mean: 4.058256880733954\n",
      "  episode_reward_min: -1.6000000000000005\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 81659\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.035083876308213\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013065786753952629\n",
      "          policy_loss: -0.05859276873624732\n",
      "          total_loss: 0.12180529516588291\n",
      "          vf_explained_var: 0.9271795153617859\n",
      "          vf_loss: 0.17098340563253206\n",
      "    num_agent_steps_sampled: 7546980\n",
      "    num_agent_steps_trained: 7546980\n",
      "    num_steps_sampled: 7546980\n",
      "    num_steps_trained: 7546980\n",
      "  iterations_since_restore: 755\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.81165919282509\n",
      "    ram_util_percent: 58.53139013452915\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549103314565805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.071179220586515\n",
      "    mean_inference_ms: 2.8522224394104603\n",
      "    mean_raw_obs_processing_ms: 3.6733272226052036\n",
      "  time_since_restore: 119202.76595854759\n",
      "  time_this_iter_s: 156.24380660057068\n",
      "  time_total_s: 119202.76595854759\n",
      "  timers:\n",
      "    learn_throughput: 935.658\n",
      "    learn_time_ms: 10683.39\n",
      "    load_throughput: 89355.845\n",
      "    load_time_ms: 111.867\n",
      "    sample_throughput: 65.035\n",
      "    sample_time_ms: 153703.022\n",
      "    update_time_ms: 11.475\n",
      "  timestamp: 1636413641\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7546980\n",
      "  training_iteration: 755\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   755</td><td style=\"text-align: right;\">          119203</td><td style=\"text-align: right;\">7546980</td><td style=\"text-align: right;\"> 4.05826</td><td style=\"text-align: right;\">                12.6</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           92.0826</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7556976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-23-20\n",
      "  done: false\n",
      "  episode_len_mean: 89.96396396396396\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.910000000000014\n",
      "  episode_reward_mean: 4.127657657657666\n",
      "  episode_reward_min: -2.079999999999999\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 81770\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.045500679810842\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012090247658048704\n",
      "          policy_loss: -0.06135746375617818\n",
      "          total_loss: 0.0949428926468787\n",
      "          vf_explained_var: 0.9349818229675293\n",
      "          vf_loss: 0.14921226647929248\n",
      "    num_agent_steps_sampled: 7556976\n",
      "    num_agent_steps_trained: 7556976\n",
      "    num_steps_sampled: 7556976\n",
      "    num_steps_trained: 7556976\n",
      "  iterations_since_restore: 756\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.7863436123348\n",
      "    ram_util_percent: 58.5533039647577\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552041717323881\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07564789448941\n",
      "    mean_inference_ms: 2.852520183655973\n",
      "    mean_raw_obs_processing_ms: 3.6710364096228685\n",
      "  time_since_restore: 119361.77451896667\n",
      "  time_this_iter_s: 159.00856041908264\n",
      "  time_total_s: 119361.77451896667\n",
      "  timers:\n",
      "    learn_throughput: 935.513\n",
      "    learn_time_ms: 10685.042\n",
      "    load_throughput: 89022.772\n",
      "    load_time_ms: 112.286\n",
      "    sample_throughput: 64.955\n",
      "    sample_time_ms: 153892.285\n",
      "    update_time_ms: 12.549\n",
      "  timestamp: 1636413800\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7556976\n",
      "  training_iteration: 756\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   756</td><td style=\"text-align: right;\">          119362</td><td style=\"text-align: right;\">7556976</td><td style=\"text-align: right;\"> 4.12766</td><td style=\"text-align: right;\">               12.91</td><td style=\"text-align: right;\">               -2.08</td><td style=\"text-align: right;\">            89.964</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7566972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-26-17\n",
      "  done: false\n",
      "  episode_len_mean: 90.67272727272727\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.700000000000014\n",
      "  episode_reward_mean: 4.334545454545464\n",
      "  episode_reward_min: -1.430000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 81880\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.040098328773792\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011461925170541017\n",
      "          policy_loss: -0.05523485157511428\n",
      "          total_loss: 0.11386992387935264\n",
      "          vf_explained_var: 0.9390733242034912\n",
      "          vf_loss: 0.16339406022467676\n",
      "    num_agent_steps_sampled: 7566972\n",
      "    num_agent_steps_trained: 7566972\n",
      "    num_steps_sampled: 7566972\n",
      "    num_steps_trained: 7566972\n",
      "  iterations_since_restore: 757\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.74382470119521\n",
      "    ram_util_percent: 58.5390438247012\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04546635288803937\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.072635662363375\n",
      "    mean_inference_ms: 2.8522424048045214\n",
      "    mean_raw_obs_processing_ms: 3.6734426139942786\n",
      "  time_since_restore: 119537.89837265015\n",
      "  time_this_iter_s: 176.12385368347168\n",
      "  time_total_s: 119537.89837265015\n",
      "  timers:\n",
      "    learn_throughput: 935.81\n",
      "    learn_time_ms: 10681.659\n",
      "    load_throughput: 89117.271\n",
      "    load_time_ms: 112.167\n",
      "    sample_throughput: 64.551\n",
      "    sample_time_ms: 154855.066\n",
      "    update_time_ms: 11.601\n",
      "  timestamp: 1636413977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7566972\n",
      "  training_iteration: 757\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   757</td><td style=\"text-align: right;\">          119538</td><td style=\"text-align: right;\">7566972</td><td style=\"text-align: right;\"> 4.33455</td><td style=\"text-align: right;\">                12.7</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           90.6727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7576968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-29-18\n",
      "  done: false\n",
      "  episode_len_mean: 89.49107142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.56999999999997\n",
      "  episode_reward_mean: 4.528839285714294\n",
      "  episode_reward_min: -1.4000000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 81992\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.040688460097354\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011642223061264492\n",
      "          policy_loss: -0.05739103196363928\n",
      "          total_loss: 0.08443641140659014\n",
      "          vf_explained_var: 0.955069899559021\n",
      "          vf_loss: 0.13571188827721864\n",
      "    num_agent_steps_sampled: 7576968\n",
      "    num_agent_steps_trained: 7576968\n",
      "    num_steps_sampled: 7576968\n",
      "    num_steps_trained: 7576968\n",
      "  iterations_since_restore: 758\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.23629343629344\n",
      "    ram_util_percent: 58.51119691119691\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550325432948586\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.073334471519765\n",
      "    mean_inference_ms: 2.8520730868515805\n",
      "    mean_raw_obs_processing_ms: 3.679887364089456\n",
      "  time_since_restore: 119719.5422346592\n",
      "  time_this_iter_s: 181.64386200904846\n",
      "  time_total_s: 119719.5422346592\n",
      "  timers:\n",
      "    learn_throughput: 935.809\n",
      "    learn_time_ms: 10681.662\n",
      "    load_throughput: 89090.475\n",
      "    load_time_ms: 112.201\n",
      "    sample_throughput: 64.136\n",
      "    sample_time_ms: 155855.53\n",
      "    update_time_ms: 11.191\n",
      "  timestamp: 1636414158\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7576968\n",
      "  training_iteration: 758\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   758</td><td style=\"text-align: right;\">          119720</td><td style=\"text-align: right;\">7576968</td><td style=\"text-align: right;\"> 4.52884</td><td style=\"text-align: right;\">               18.57</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           89.4911</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7586964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-31-44\n",
      "  done: false\n",
      "  episode_len_mean: 91.33636363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.909999999999993\n",
      "  episode_reward_mean: 4.16681818181819\n",
      "  episode_reward_min: -1.3300000000000003\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 82102\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.073180796040429\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011427856293039447\n",
      "          policy_loss: -0.05723865276091119\n",
      "          total_loss: 0.12286864164739084\n",
      "          vf_explained_var: 0.9270882606506348\n",
      "          vf_loss: 0.17480501692710268\n",
      "    num_agent_steps_sampled: 7586964\n",
      "    num_agent_steps_trained: 7586964\n",
      "    num_steps_sampled: 7586964\n",
      "    num_steps_trained: 7586964\n",
      "  iterations_since_restore: 759\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95961538461538\n",
      "    ram_util_percent: 58.4076923076923\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549527684932036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.07658252509716\n",
      "    mean_inference_ms: 2.8521114152135794\n",
      "    mean_raw_obs_processing_ms: 3.67579743880527\n",
      "  time_since_restore: 119864.94421839714\n",
      "  time_this_iter_s: 145.40198373794556\n",
      "  time_total_s: 119864.94421839714\n",
      "  timers:\n",
      "    learn_throughput: 935.526\n",
      "    learn_time_ms: 10684.896\n",
      "    load_throughput: 89101.608\n",
      "    load_time_ms: 112.187\n",
      "    sample_throughput: 64.546\n",
      "    sample_time_ms: 154865.609\n",
      "    update_time_ms: 11.886\n",
      "  timestamp: 1636414304\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7586964\n",
      "  training_iteration: 759\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   759</td><td style=\"text-align: right;\">          119865</td><td style=\"text-align: right;\">7586964</td><td style=\"text-align: right;\"> 4.16682</td><td style=\"text-align: right;\">               16.91</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">           91.3364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7596960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-34-28\n",
      "  done: false\n",
      "  episode_len_mean: 87.96491228070175\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.630000000000013\n",
      "  episode_reward_mean: 4.523508771929834\n",
      "  episode_reward_min: -0.9300000000000006\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 82216\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0198308352731233\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011099223064883399\n",
      "          policy_loss: -0.05756158030185944\n",
      "          total_loss: 0.08903134947276523\n",
      "          vf_explained_var: 0.9496151208877563\n",
      "          vf_loss: 0.1415058195988974\n",
      "    num_agent_steps_sampled: 7596960\n",
      "    num_agent_steps_trained: 7596960\n",
      "    num_steps_sampled: 7596960\n",
      "    num_steps_trained: 7596960\n",
      "  iterations_since_restore: 760\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.32382978723405\n",
      "    ram_util_percent: 58.43617021276595\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551047814600835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.08113353656329\n",
      "    mean_inference_ms: 2.8519599568373657\n",
      "    mean_raw_obs_processing_ms: 3.677688111386152\n",
      "  time_since_restore: 120029.63729667664\n",
      "  time_this_iter_s: 164.69307827949524\n",
      "  time_total_s: 120029.63729667664\n",
      "  timers:\n",
      "    learn_throughput: 935.666\n",
      "    learn_time_ms: 10683.304\n",
      "    load_throughput: 89345.734\n",
      "    load_time_ms: 111.88\n",
      "    sample_throughput: 63.844\n",
      "    sample_time_ms: 156570.288\n",
      "    update_time_ms: 11.638\n",
      "  timestamp: 1636414468\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7596960\n",
      "  training_iteration: 760\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   760</td><td style=\"text-align: right;\">          120030</td><td style=\"text-align: right;\">7596960</td><td style=\"text-align: right;\"> 4.52351</td><td style=\"text-align: right;\">               12.63</td><td style=\"text-align: right;\">               -0.93</td><td style=\"text-align: right;\">           87.9649</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7606956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-37-18\n",
      "  done: false\n",
      "  episode_len_mean: 87.41592920353982\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.309999999999956\n",
      "  episode_reward_mean: 4.420707964601779\n",
      "  episode_reward_min: -1.1300000000000003\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 82329\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0604005075927474\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011725548605101317\n",
      "          policy_loss: -0.059774076586796177\n",
      "          total_loss: 0.09557299681692424\n",
      "          vf_explained_var: 0.949367105960846\n",
      "          vf_loss: 0.1492388119905168\n",
      "    num_agent_steps_sampled: 7606956\n",
      "    num_agent_steps_trained: 7606956\n",
      "    num_steps_sampled: 7606956\n",
      "    num_steps_trained: 7606956\n",
      "  iterations_since_restore: 761\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.21452282157675\n",
      "    ram_util_percent: 58.31867219917012\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045500660933316464\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.08499160349358\n",
      "    mean_inference_ms: 2.851875333517159\n",
      "    mean_raw_obs_processing_ms: 3.6786196823672617\n",
      "  time_since_restore: 120198.73096060753\n",
      "  time_this_iter_s: 169.09366393089294\n",
      "  time_total_s: 120198.73096060753\n",
      "  timers:\n",
      "    learn_throughput: 935.665\n",
      "    learn_time_ms: 10683.308\n",
      "    load_throughput: 89529.941\n",
      "    load_time_ms: 111.65\n",
      "    sample_throughput: 64.457\n",
      "    sample_time_ms: 155081.333\n",
      "    update_time_ms: 10.816\n",
      "  timestamp: 1636414638\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7606956\n",
      "  training_iteration: 761\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   761</td><td style=\"text-align: right;\">          120199</td><td style=\"text-align: right;\">7606956</td><td style=\"text-align: right;\"> 4.42071</td><td style=\"text-align: right;\">               16.31</td><td style=\"text-align: right;\">               -1.13</td><td style=\"text-align: right;\">           87.4159</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7616952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-39-43\n",
      "  done: false\n",
      "  episode_len_mean: 91.57272727272728\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.550000000000008\n",
      "  episode_reward_mean: 4.574818181818193\n",
      "  episode_reward_min: -1.7100000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 82439\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.026859654626276\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013004867296080047\n",
      "          policy_loss: -0.05604085099572937\n",
      "          total_loss: 0.11994348580383847\n",
      "          vf_explained_var: 0.9487645030021667\n",
      "          vf_loss: 0.16662621974913228\n",
      "    num_agent_steps_sampled: 7616952\n",
      "    num_agent_steps_trained: 7616952\n",
      "    num_steps_sampled: 7616952\n",
      "    num_steps_trained: 7616952\n",
      "  iterations_since_restore: 762\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03028846153846\n",
      "    ram_util_percent: 58.48413461538462\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045490151699212444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.08786237282119\n",
      "    mean_inference_ms: 2.851959117954619\n",
      "    mean_raw_obs_processing_ms: 3.6741019814392777\n",
      "  time_since_restore: 120344.02918601036\n",
      "  time_this_iter_s: 145.29822540283203\n",
      "  time_total_s: 120344.02918601036\n",
      "  timers:\n",
      "    learn_throughput: 935.411\n",
      "    learn_time_ms: 10686.208\n",
      "    load_throughput: 88801.448\n",
      "    load_time_ms: 112.566\n",
      "    sample_throughput: 66.396\n",
      "    sample_time_ms: 150550.449\n",
      "    update_time_ms: 10.79\n",
      "  timestamp: 1636414783\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7616952\n",
      "  training_iteration: 762\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   762</td><td style=\"text-align: right;\">          120344</td><td style=\"text-align: right;\">7616952</td><td style=\"text-align: right;\"> 4.57482</td><td style=\"text-align: right;\">               16.55</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           91.5727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7626948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-42-27\n",
      "  done: false\n",
      "  episode_len_mean: 89.16964285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.900000000000011\n",
      "  episode_reward_mean: 4.509910714285724\n",
      "  episode_reward_min: -1.770000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 82551\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0425289979347814\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011915577140298832\n",
      "          policy_loss: -0.05886439807617511\n",
      "          total_loss: 0.11252759392333464\n",
      "          vf_explained_var: 0.9483529925346375\n",
      "          vf_loss: 0.16467210818878097\n",
      "    num_agent_steps_sampled: 7626948\n",
      "    num_agent_steps_trained: 7626948\n",
      "    num_steps_sampled: 7626948\n",
      "    num_steps_trained: 7626948\n",
      "  iterations_since_restore: 763\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.37339055793991\n",
      "    ram_util_percent: 58.43175965665236\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0454960062736625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09300353071741\n",
      "    mean_inference_ms: 2.8522101625211707\n",
      "    mean_raw_obs_processing_ms: 3.6714844769594235\n",
      "  time_since_restore: 120507.7762298584\n",
      "  time_this_iter_s: 163.74704384803772\n",
      "  time_total_s: 120507.7762298584\n",
      "  timers:\n",
      "    learn_throughput: 935.64\n",
      "    learn_time_ms: 10683.599\n",
      "    load_throughput: 88888.447\n",
      "    load_time_ms: 112.456\n",
      "    sample_throughput: 66.668\n",
      "    sample_time_ms: 149936.805\n",
      "    update_time_ms: 9.832\n",
      "  timestamp: 1636414947\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7626948\n",
      "  training_iteration: 763\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   763</td><td style=\"text-align: right;\">          120508</td><td style=\"text-align: right;\">7626948</td><td style=\"text-align: right;\"> 4.50991</td><td style=\"text-align: right;\">                10.9</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           89.1696</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7636944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-45-23\n",
      "  done: false\n",
      "  episode_len_mean: 87.75438596491227\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.950000000000014\n",
      "  episode_reward_mean: 4.361228070175447\n",
      "  episode_reward_min: -1.4400000000000006\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 82665\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.034271281193464\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011699858620248358\n",
      "          policy_loss: -0.05641521142843442\n",
      "          total_loss: 0.133411982585477\n",
      "          vf_explained_var: 0.9324982762336731\n",
      "          vf_loss: 0.18351616378889507\n",
      "    num_agent_steps_sampled: 7636944\n",
      "    num_agent_steps_trained: 7636944\n",
      "    num_steps_sampled: 7636944\n",
      "    num_steps_trained: 7636944\n",
      "  iterations_since_restore: 764\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.54444444444445\n",
      "    ram_util_percent: 58.201587301587296\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551116857318523\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09606932723285\n",
      "    mean_inference_ms: 2.851941091367742\n",
      "    mean_raw_obs_processing_ms: 3.6761169121415347\n",
      "  time_since_restore: 120683.89933156967\n",
      "  time_this_iter_s: 176.1231017112732\n",
      "  time_total_s: 120683.89933156967\n",
      "  timers:\n",
      "    learn_throughput: 935.451\n",
      "    learn_time_ms: 10685.749\n",
      "    load_throughput: 88959.098\n",
      "    load_time_ms: 112.366\n",
      "    sample_throughput: 65.369\n",
      "    sample_time_ms: 152916.131\n",
      "    update_time_ms: 10.018\n",
      "  timestamp: 1636415123\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7636944\n",
      "  training_iteration: 764\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   764</td><td style=\"text-align: right;\">          120684</td><td style=\"text-align: right;\">7636944</td><td style=\"text-align: right;\"> 4.36123</td><td style=\"text-align: right;\">               14.95</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           87.7544</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7646940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-48-03\n",
      "  done: false\n",
      "  episode_len_mean: 89.84821428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.430000000000014\n",
      "  episode_reward_mean: 4.190089285714295\n",
      "  episode_reward_min: -1.2700000000000007\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 82777\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.051578382345346\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011827423219124212\n",
      "          policy_loss: -0.05893815211378611\n",
      "          total_loss: 0.09426331035315226\n",
      "          vf_explained_var: 0.9421722888946533\n",
      "          vf_loss: 0.1467728962755611\n",
      "    num_agent_steps_sampled: 7646940\n",
      "    num_agent_steps_trained: 7646940\n",
      "    num_steps_sampled: 7646940\n",
      "    num_steps_trained: 7646940\n",
      "  iterations_since_restore: 765\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.87543859649122\n",
      "    ram_util_percent: 58.54736842105263\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04547431642022889\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09783152037194\n",
      "    mean_inference_ms: 2.852083707477265\n",
      "    mean_raw_obs_processing_ms: 3.6727906882616224\n",
      "  time_since_restore: 120843.89087200165\n",
      "  time_this_iter_s: 159.99154043197632\n",
      "  time_total_s: 120843.89087200165\n",
      "  timers:\n",
      "    learn_throughput: 935.77\n",
      "    learn_time_ms: 10682.109\n",
      "    load_throughput: 88856.553\n",
      "    load_time_ms: 112.496\n",
      "    sample_throughput: 65.208\n",
      "    sample_time_ms: 153293.814\n",
      "    update_time_ms: 10.857\n",
      "  timestamp: 1636415283\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7646940\n",
      "  training_iteration: 765\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   765</td><td style=\"text-align: right;\">          120844</td><td style=\"text-align: right;\">7646940</td><td style=\"text-align: right;\"> 4.19009</td><td style=\"text-align: right;\">               14.43</td><td style=\"text-align: right;\">               -1.27</td><td style=\"text-align: right;\">           89.8482</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7656936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-50-32\n",
      "  done: false\n",
      "  episode_len_mean: 88.74774774774775\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.99000000000001\n",
      "  episode_reward_mean: 4.039639639639649\n",
      "  episode_reward_min: -1.3000000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 82888\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.050622863851042\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011938934806219303\n",
      "          policy_loss: -0.060762633443770246\n",
      "          total_loss: 0.10877918109584313\n",
      "          vf_explained_var: 0.929267168045044\n",
      "          vf_loss: 0.16284965827870063\n",
      "    num_agent_steps_sampled: 7656936\n",
      "    num_agent_steps_trained: 7656936\n",
      "    num_steps_sampled: 7656936\n",
      "    num_steps_trained: 7656936\n",
      "  iterations_since_restore: 766\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.32075471698113\n",
      "    ram_util_percent: 58.52405660377359\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550921677667782\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10462509807506\n",
      "    mean_inference_ms: 2.8522056382138183\n",
      "    mean_raw_obs_processing_ms: 3.6693423933216893\n",
      "  time_since_restore: 120992.50148463249\n",
      "  time_this_iter_s: 148.61061263084412\n",
      "  time_total_s: 120992.50148463249\n",
      "  timers:\n",
      "    learn_throughput: 935.807\n",
      "    learn_time_ms: 10681.69\n",
      "    load_throughput: 89055.126\n",
      "    load_time_ms: 112.245\n",
      "    sample_throughput: 65.652\n",
      "    sample_time_ms: 152256.552\n",
      "    update_time_ms: 9.019\n",
      "  timestamp: 1636415432\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7656936\n",
      "  training_iteration: 766\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   766</td><td style=\"text-align: right;\">          120993</td><td style=\"text-align: right;\">7656936</td><td style=\"text-align: right;\"> 4.03964</td><td style=\"text-align: right;\">               14.99</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">           88.7477</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7666932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-53-27\n",
      "  done: false\n",
      "  episode_len_mean: 88.59292035398231\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.44999999999997\n",
      "  episode_reward_mean: 4.552566371681426\n",
      "  episode_reward_min: -1.7500000000000009\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 83001\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.026527641981076\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012145418769737997\n",
      "          policy_loss: -0.05790300136193251\n",
      "          total_loss: 0.09950117021480687\n",
      "          vf_explained_var: 0.9493969678878784\n",
      "          vf_loss: 0.15000066530500722\n",
      "    num_agent_steps_sampled: 7666932\n",
      "    num_agent_steps_trained: 7666932\n",
      "    num_steps_sampled: 7666932\n",
      "    num_steps_trained: 7666932\n",
      "  iterations_since_restore: 767\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.2808\n",
      "    ram_util_percent: 58.45759999999999\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552732881694453\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10583607232976\n",
      "    mean_inference_ms: 2.8522870811272365\n",
      "    mean_raw_obs_processing_ms: 3.6729577385484924\n",
      "  time_since_restore: 121167.86589121819\n",
      "  time_this_iter_s: 175.36440658569336\n",
      "  time_total_s: 121167.86589121819\n",
      "  timers:\n",
      "    learn_throughput: 935.46\n",
      "    learn_time_ms: 10685.648\n",
      "    load_throughput: 89174.78\n",
      "    load_time_ms: 112.094\n",
      "    sample_throughput: 65.687\n",
      "    sample_time_ms: 152176.342\n",
      "    update_time_ms: 9.615\n",
      "  timestamp: 1636415607\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7666932\n",
      "  training_iteration: 767\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   767</td><td style=\"text-align: right;\">          121168</td><td style=\"text-align: right;\">7666932</td><td style=\"text-align: right;\"> 4.55257</td><td style=\"text-align: right;\">               16.45</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           88.5929</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7676928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-56-21\n",
      "  done: false\n",
      "  episode_len_mean: 87.7719298245614\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.71999999999998\n",
      "  episode_reward_mean: 4.887719298245624\n",
      "  episode_reward_min: -1.2200000000000004\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 83115\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.001530882639763\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01332343569398289\n",
      "          policy_loss: -0.05930844610158959\n",
      "          total_loss: 0.13480095262519823\n",
      "          vf_explained_var: 0.944628894329071\n",
      "          vf_loss: 0.18377225431812624\n",
      "    num_agent_steps_sampled: 7676928\n",
      "    num_agent_steps_trained: 7676928\n",
      "    num_steps_sampled: 7676928\n",
      "    num_steps_trained: 7676928\n",
      "  iterations_since_restore: 768\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.36653225806451\n",
      "    ram_util_percent: 58.471370967741926\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045494452627034596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10729391664204\n",
      "    mean_inference_ms: 2.8521875716040337\n",
      "    mean_raw_obs_processing_ms: 3.6734042349610725\n",
      "  time_since_restore: 121341.59851264954\n",
      "  time_this_iter_s: 173.7326214313507\n",
      "  time_total_s: 121341.59851264954\n",
      "  timers:\n",
      "    learn_throughput: 935.375\n",
      "    learn_time_ms: 10686.628\n",
      "    load_throughput: 89240.853\n",
      "    load_time_ms: 112.011\n",
      "    sample_throughput: 66.031\n",
      "    sample_time_ms: 151383.916\n",
      "    update_time_ms: 10.138\n",
      "  timestamp: 1636415781\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7676928\n",
      "  training_iteration: 768\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   768</td><td style=\"text-align: right;\">          121342</td><td style=\"text-align: right;\">7676928</td><td style=\"text-align: right;\"> 4.88772</td><td style=\"text-align: right;\">               16.72</td><td style=\"text-align: right;\">               -1.22</td><td style=\"text-align: right;\">           87.7719</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7686924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-59-03\n",
      "  done: false\n",
      "  episode_len_mean: 87.53508771929825\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.810000000000013\n",
      "  episode_reward_mean: 4.541666666666676\n",
      "  episode_reward_min: -1.7200000000000006\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 83229\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0017540851209916\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011436992294581103\n",
      "          policy_loss: -0.05503516797071848\n",
      "          total_loss: 0.1200203696377257\n",
      "          vf_explained_var: 0.9400305151939392\n",
      "          vf_loss: 0.169018180302989\n",
      "    num_agent_steps_sampled: 7686924\n",
      "    num_agent_steps_trained: 7686924\n",
      "    num_steps_sampled: 7686924\n",
      "    num_steps_trained: 7686924\n",
      "  iterations_since_restore: 769\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.68706896551724\n",
      "    ram_util_percent: 58.53275862068965\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548537581096181\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.110523964066154\n",
      "    mean_inference_ms: 2.8520574173997826\n",
      "    mean_raw_obs_processing_ms: 3.6725248320118826\n",
      "  time_since_restore: 121503.88792228699\n",
      "  time_this_iter_s: 162.28940963745117\n",
      "  time_total_s: 121503.88792228699\n",
      "  timers:\n",
      "    learn_throughput: 935.532\n",
      "    learn_time_ms: 10684.824\n",
      "    load_throughput: 89372.397\n",
      "    load_time_ms: 111.847\n",
      "    sample_throughput: 65.301\n",
      "    sample_time_ms: 153075.088\n",
      "    update_time_ms: 9.419\n",
      "  timestamp: 1636415943\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7686924\n",
      "  training_iteration: 769\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   769</td><td style=\"text-align: right;\">          121504</td><td style=\"text-align: right;\">7686924</td><td style=\"text-align: right;\"> 4.54167</td><td style=\"text-align: right;\">               12.81</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           87.5351</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7696920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-02-00\n",
      "  done: false\n",
      "  episode_len_mean: 87.55652173913043\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.67999999999994\n",
      "  episode_reward_mean: 4.296869565217398\n",
      "  episode_reward_min: -1.4300000000000006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 83344\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.024310477065225\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012096609818812604\n",
      "          policy_loss: -0.054438974564242314\n",
      "          total_loss: 0.14037244936140875\n",
      "          vf_explained_var: 0.9392223358154297\n",
      "          vf_loss: 0.18749693896716985\n",
      "    num_agent_steps_sampled: 7696920\n",
      "    num_agent_steps_trained: 7696920\n",
      "    num_steps_sampled: 7696920\n",
      "    num_steps_trained: 7696920\n",
      "  iterations_since_restore: 770\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.34722222222223\n",
      "    ram_util_percent: 58.34325396825397\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045486379995009624\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.112997236478215\n",
      "    mean_inference_ms: 2.851941854850577\n",
      "    mean_raw_obs_processing_ms: 3.6757841388005597\n",
      "  time_since_restore: 121681.01198863983\n",
      "  time_this_iter_s: 177.12406635284424\n",
      "  time_total_s: 121681.01198863983\n",
      "  timers:\n",
      "    learn_throughput: 935.462\n",
      "    learn_time_ms: 10685.628\n",
      "    load_throughput: 89356.359\n",
      "    load_time_ms: 111.867\n",
      "    sample_throughput: 64.776\n",
      "    sample_time_ms: 154316.672\n",
      "    update_time_ms: 9.987\n",
      "  timestamp: 1636416120\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7696920\n",
      "  training_iteration: 770\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   770</td><td style=\"text-align: right;\">          121681</td><td style=\"text-align: right;\">7696920</td><td style=\"text-align: right;\"> 4.29687</td><td style=\"text-align: right;\">               18.68</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           87.5565</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7706916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-04-56\n",
      "  done: false\n",
      "  episode_len_mean: 87.11504424778761\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000013\n",
      "  episode_reward_mean: 4.256902654867266\n",
      "  episode_reward_min: -1.620000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 83457\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.02380239637489\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011000707536775338\n",
      "          policy_loss: -0.05880421751584762\n",
      "          total_loss: 0.07653692279361252\n",
      "          vf_explained_var: 0.9448068141937256\n",
      "          vf_loss: 0.1305181773331685\n",
      "    num_agent_steps_sampled: 7706916\n",
      "    num_agent_steps_trained: 7706916\n",
      "    num_steps_sampled: 7706916\n",
      "    num_steps_trained: 7706916\n",
      "  iterations_since_restore: 771\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.55816733067729\n",
      "    ram_util_percent: 58.5\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550770556515232\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.1168213056789\n",
      "    mean_inference_ms: 2.851914281890634\n",
      "    mean_raw_obs_processing_ms: 3.67701675085066\n",
      "  time_since_restore: 121856.31193876266\n",
      "  time_this_iter_s: 175.29995012283325\n",
      "  time_total_s: 121856.31193876266\n",
      "  timers:\n",
      "    learn_throughput: 935.941\n",
      "    learn_time_ms: 10680.156\n",
      "    load_throughput: 89364.625\n",
      "    load_time_ms: 111.856\n",
      "    sample_throughput: 64.514\n",
      "    sample_time_ms: 154942.039\n",
      "    update_time_ms: 10.472\n",
      "  timestamp: 1636416296\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7706916\n",
      "  training_iteration: 771\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   771</td><td style=\"text-align: right;\">          121856</td><td style=\"text-align: right;\">7706916</td><td style=\"text-align: right;\">  4.2569</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">            87.115</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7716912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-07-42\n",
      "  done: false\n",
      "  episode_len_mean: 87.65217391304348\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.87000000000001\n",
      "  episode_reward_mean: 4.367217391304356\n",
      "  episode_reward_min: -1.3800000000000006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 83572\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9867036377262866\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012389058822080148\n",
      "          policy_loss: -0.053222003919828655\n",
      "          total_loss: 0.1379171248907462\n",
      "          vf_explained_var: 0.9333925843238831\n",
      "          vf_loss: 0.18278234087599393\n",
      "    num_agent_steps_sampled: 7716912\n",
      "    num_agent_steps_trained: 7716912\n",
      "    num_steps_sampled: 7716912\n",
      "    num_steps_trained: 7716912\n",
      "  iterations_since_restore: 772\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.1705882352941\n",
      "    ram_util_percent: 58.5516806722689\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045510863591693006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.12088379742803\n",
      "    mean_inference_ms: 2.8523423091661964\n",
      "    mean_raw_obs_processing_ms: 3.6734596128809547\n",
      "  time_since_restore: 122023.11346244812\n",
      "  time_this_iter_s: 166.80152368545532\n",
      "  time_total_s: 122023.11346244812\n",
      "  timers:\n",
      "    learn_throughput: 935.827\n",
      "    learn_time_ms: 10681.46\n",
      "    load_throughput: 90225.612\n",
      "    load_time_ms: 110.789\n",
      "    sample_throughput: 63.632\n",
      "    sample_time_ms: 157090.958\n",
      "    update_time_ms: 11.418\n",
      "  timestamp: 1636416462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7716912\n",
      "  training_iteration: 772\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   772</td><td style=\"text-align: right;\">          122023</td><td style=\"text-align: right;\">7716912</td><td style=\"text-align: right;\"> 4.36722</td><td style=\"text-align: right;\">               16.87</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           87.6522</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7726908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-10-32\n",
      "  done: false\n",
      "  episode_len_mean: 90.30630630630631\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.690000000000012\n",
      "  episode_reward_mean: 3.9976576576576655\n",
      "  episode_reward_min: -1.3600000000000003\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 83683\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.004740552107493\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012345700359021642\n",
      "          policy_loss: -0.05316506771323008\n",
      "          total_loss: 0.11339615566226152\n",
      "          vf_explained_var: 0.9357135891914368\n",
      "          vf_loss: 0.15848357965692114\n",
      "    num_agent_steps_sampled: 7726908\n",
      "    num_agent_steps_trained: 7726908\n",
      "    num_steps_sampled: 7726908\n",
      "    num_steps_trained: 7726908\n",
      "  iterations_since_restore: 773\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.96570247933886\n",
      "    ram_util_percent: 58.63512396694215\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553208246342266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.12350551219017\n",
      "    mean_inference_ms: 2.851884252376498\n",
      "    mean_raw_obs_processing_ms: 3.6771844889065384\n",
      "  time_since_restore: 122192.65946507454\n",
      "  time_this_iter_s: 169.54600262641907\n",
      "  time_total_s: 122192.65946507454\n",
      "  timers:\n",
      "    learn_throughput: 935.69\n",
      "    learn_time_ms: 10683.027\n",
      "    load_throughput: 90308.986\n",
      "    load_time_ms: 110.687\n",
      "    sample_throughput: 63.399\n",
      "    sample_time_ms: 157667.275\n",
      "    update_time_ms: 13.483\n",
      "  timestamp: 1636416632\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7726908\n",
      "  training_iteration: 773\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   773</td><td style=\"text-align: right;\">          122193</td><td style=\"text-align: right;\">7726908</td><td style=\"text-align: right;\"> 3.99766</td><td style=\"text-align: right;\">               10.69</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           90.3063</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7736904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-13-13\n",
      "  done: false\n",
      "  episode_len_mean: 90.95454545454545\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.29000000000001\n",
      "  episode_reward_mean: 3.9631818181818264\n",
      "  episode_reward_min: -1.8400000000000012\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 83793\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.017347782697433\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01232384988690923\n",
      "          policy_loss: -0.05621152217619312\n",
      "          total_loss: 0.1041709075984346\n",
      "          vf_explained_var: 0.9323046207427979\n",
      "          vf_loss: 0.15248063582942908\n",
      "    num_agent_steps_sampled: 7736904\n",
      "    num_agent_steps_trained: 7736904\n",
      "    num_steps_sampled: 7736904\n",
      "    num_steps_trained: 7736904\n",
      "  iterations_since_restore: 774\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.54978165938866\n",
      "    ram_util_percent: 58.5183406113537\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455116164603888\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.12591283740846\n",
      "    mean_inference_ms: 2.8522844855271225\n",
      "    mean_raw_obs_processing_ms: 3.6729487653556796\n",
      "  time_since_restore: 122353.56556916237\n",
      "  time_this_iter_s: 160.9061040878296\n",
      "  time_total_s: 122353.56556916237\n",
      "  timers:\n",
      "    learn_throughput: 936.163\n",
      "    learn_time_ms: 10677.63\n",
      "    load_throughput: 90252.92\n",
      "    load_time_ms: 110.755\n",
      "    sample_throughput: 64.015\n",
      "    sample_time_ms: 156150.051\n",
      "    update_time_ms: 14.415\n",
      "  timestamp: 1636416793\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7736904\n",
      "  training_iteration: 774\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   774</td><td style=\"text-align: right;\">          122354</td><td style=\"text-align: right;\">7736904</td><td style=\"text-align: right;\"> 3.96318</td><td style=\"text-align: right;\">               13.29</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           90.9545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7746900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-15-39\n",
      "  done: false\n",
      "  episode_len_mean: 91.30275229357798\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.669999999999984\n",
      "  episode_reward_mean: 4.178990825688083\n",
      "  episode_reward_min: -1.280000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 83902\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0102213330757923\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012146769337532962\n",
      "          policy_loss: -0.056975124849595576\n",
      "          total_loss: 0.12655989329656983\n",
      "          vf_explained_var: 0.9276513457298279\n",
      "          vf_loss: 0.17596537122487002\n",
      "    num_agent_steps_sampled: 7746900\n",
      "    num_agent_steps_trained: 7746900\n",
      "    num_steps_sampled: 7746900\n",
      "    num_steps_trained: 7746900\n",
      "  iterations_since_restore: 775\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.20382775119619\n",
      "    ram_util_percent: 58.583732057416256\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548503641179873\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.12769688781081\n",
      "    mean_inference_ms: 2.851957917054529\n",
      "    mean_raw_obs_processing_ms: 3.6707640268293003\n",
      "  time_since_restore: 122500.03584432602\n",
      "  time_this_iter_s: 146.4702751636505\n",
      "  time_total_s: 122500.03584432602\n",
      "  timers:\n",
      "    learn_throughput: 936.2\n",
      "    learn_time_ms: 10677.206\n",
      "    load_throughput: 90680.907\n",
      "    load_time_ms: 110.233\n",
      "    sample_throughput: 64.574\n",
      "    sample_time_ms: 154798.655\n",
      "    update_time_ms: 14.128\n",
      "  timestamp: 1636416939\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7746900\n",
      "  training_iteration: 775\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   775</td><td style=\"text-align: right;\">          122500</td><td style=\"text-align: right;\">7746900</td><td style=\"text-align: right;\"> 4.17899</td><td style=\"text-align: right;\">               16.67</td><td style=\"text-align: right;\">               -1.28</td><td style=\"text-align: right;\">           91.3028</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7756896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-18-20\n",
      "  done: false\n",
      "  episode_len_mean: 89.49107142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.350000000000012\n",
      "  episode_reward_mean: 4.203482142857152\n",
      "  episode_reward_min: -1.4200000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 84014\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.02952579820258\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01173176110497023\n",
      "          policy_loss: -0.05780504535342384\n",
      "          total_loss: 0.13656244134514506\n",
      "          vf_explained_var: 0.9298693537712097\n",
      "          vf_loss: 0.18793632661621285\n",
      "    num_agent_steps_sampled: 7756896\n",
      "    num_agent_steps_trained: 7756896\n",
      "    num_steps_sampled: 7756896\n",
      "    num_steps_trained: 7756896\n",
      "  iterations_since_restore: 776\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.19260869565218\n",
      "    ram_util_percent: 58.5195652173913\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0454795711860978\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.13047177269116\n",
      "    mean_inference_ms: 2.852183942173243\n",
      "    mean_raw_obs_processing_ms: 3.6701332718735307\n",
      "  time_since_restore: 122661.08905601501\n",
      "  time_this_iter_s: 161.05321168899536\n",
      "  time_total_s: 122661.08905601501\n",
      "  timers:\n",
      "    learn_throughput: 936.116\n",
      "    learn_time_ms: 10678.165\n",
      "    load_throughput: 90810.223\n",
      "    load_time_ms: 110.076\n",
      "    sample_throughput: 64.06\n",
      "    sample_time_ms: 156041.079\n",
      "    update_time_ms: 14.921\n",
      "  timestamp: 1636417100\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7756896\n",
      "  training_iteration: 776\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   776</td><td style=\"text-align: right;\">          122661</td><td style=\"text-align: right;\">7756896</td><td style=\"text-align: right;\"> 4.20348</td><td style=\"text-align: right;\">               12.35</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           89.4911</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7766892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-21-16\n",
      "  done: false\n",
      "  episode_len_mean: 88.60176991150442\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.320000000000007\n",
      "  episode_reward_mean: 4.579911504424788\n",
      "  episode_reward_min: -0.8800000000000002\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 84127\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9653964303497575\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012202686299998433\n",
      "          policy_loss: -0.0547027172250116\n",
      "          total_loss: 0.12185719574395663\n",
      "          vf_explained_var: 0.94972163438797\n",
      "          vf_loss: 0.16841463164354747\n",
      "    num_agent_steps_sampled: 7766892\n",
      "    num_agent_steps_trained: 7766892\n",
      "    num_steps_sampled: 7766892\n",
      "    num_steps_trained: 7766892\n",
      "  iterations_since_restore: 777\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.70318725099601\n",
      "    ram_util_percent: 58.493227091633464\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045514346618434336\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.135186970088554\n",
      "    mean_inference_ms: 2.852069274625132\n",
      "    mean_raw_obs_processing_ms: 3.672094994204254\n",
      "  time_since_restore: 122836.81834793091\n",
      "  time_this_iter_s: 175.72929191589355\n",
      "  time_total_s: 122836.81834793091\n",
      "  timers:\n",
      "    learn_throughput: 936.299\n",
      "    learn_time_ms: 10676.08\n",
      "    load_throughput: 90784.68\n",
      "    load_time_ms: 110.107\n",
      "    sample_throughput: 64.044\n",
      "    sample_time_ms: 156080.095\n",
      "    update_time_ms: 14.28\n",
      "  timestamp: 1636417276\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7766892\n",
      "  training_iteration: 777\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   777</td><td style=\"text-align: right;\">          122837</td><td style=\"text-align: right;\">7766892</td><td style=\"text-align: right;\"> 4.57991</td><td style=\"text-align: right;\">               13.32</td><td style=\"text-align: right;\">               -0.88</td><td style=\"text-align: right;\">           88.6018</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7776888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-23-58\n",
      "  done: false\n",
      "  episode_len_mean: 91.53211009174312\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.30000000000001\n",
      "  episode_reward_mean: 4.323302752293587\n",
      "  episode_reward_min: -1.990000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 84236\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.012614755243318\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012385679729474738\n",
      "          policy_loss: -0.056519947554438545\n",
      "          total_loss: 0.10975335488796362\n",
      "          vf_explained_var: 0.938232421875\n",
      "          vf_loss: 0.15818332358080353\n",
      "    num_agent_steps_sampled: 7776888\n",
      "    num_agent_steps_trained: 7776888\n",
      "    num_steps_sampled: 7776888\n",
      "    num_steps_trained: 7776888\n",
      "  iterations_since_restore: 778\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.97173913043478\n",
      "    ram_util_percent: 58.59608695652173\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045484168679144295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.13672831607043\n",
      "    mean_inference_ms: 2.851935844802228\n",
      "    mean_raw_obs_processing_ms: 3.670803801266301\n",
      "  time_since_restore: 122998.36778354645\n",
      "  time_this_iter_s: 161.54943561553955\n",
      "  time_total_s: 122998.36778354645\n",
      "  timers:\n",
      "    learn_throughput: 935.972\n",
      "    learn_time_ms: 10679.81\n",
      "    load_throughput: 90793.783\n",
      "    load_time_ms: 110.096\n",
      "    sample_throughput: 64.55\n",
      "    sample_time_ms: 154857.344\n",
      "    update_time_ms: 14.898\n",
      "  timestamp: 1636417438\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7776888\n",
      "  training_iteration: 778\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   778</td><td style=\"text-align: right;\">          122998</td><td style=\"text-align: right;\">7776888</td><td style=\"text-align: right;\">  4.3233</td><td style=\"text-align: right;\">                13.3</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           91.5321</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7786884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-26-52\n",
      "  done: false\n",
      "  episode_len_mean: 90.85321100917432\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 4.4566055045871655\n",
      "  episode_reward_min: -1.4300000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 84345\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.027178911571829\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01253858328619344\n",
      "          policy_loss: -0.05601272072770402\n",
      "          total_loss: 0.1377234162794601\n",
      "          vf_explained_var: 0.9360888004302979\n",
      "          vf_loss: 0.18544346533683884\n",
      "    num_agent_steps_sampled: 7786884\n",
      "    num_agent_steps_trained: 7786884\n",
      "    num_steps_sampled: 7786884\n",
      "    num_steps_trained: 7786884\n",
      "  iterations_since_restore: 779\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.41606425702811\n",
      "    ram_util_percent: 58.56024096385542\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549238987229008\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.13848683429092\n",
      "    mean_inference_ms: 2.8520545417413246\n",
      "    mean_raw_obs_processing_ms: 3.6728119324448696\n",
      "  time_since_restore: 123172.68393039703\n",
      "  time_this_iter_s: 174.31614685058594\n",
      "  time_total_s: 123172.68393039703\n",
      "  timers:\n",
      "    learn_throughput: 935.931\n",
      "    learn_time_ms: 10680.272\n",
      "    load_throughput: 90837.04\n",
      "    load_time_ms: 110.043\n",
      "    sample_throughput: 64.053\n",
      "    sample_time_ms: 156059.049\n",
      "    update_time_ms: 15.693\n",
      "  timestamp: 1636417612\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7786884\n",
      "  training_iteration: 779\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   779</td><td style=\"text-align: right;\">          123173</td><td style=\"text-align: right;\">7786884</td><td style=\"text-align: right;\"> 4.45661</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           90.8532</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7796880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-29-21\n",
      "  done: false\n",
      "  episode_len_mean: 91.51351351351352\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.550000000000017\n",
      "  episode_reward_mean: 4.097657657657666\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 84456\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0186223359189484\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012227365496066726\n",
      "          policy_loss: -0.058506058068930084\n",
      "          total_loss: 0.10025700200747094\n",
      "          vf_explained_var: 0.9363325238227844\n",
      "          vf_loss: 0.15109381627800883\n",
      "    num_agent_steps_sampled: 7796880\n",
      "    num_agent_steps_trained: 7796880\n",
      "    num_steps_sampled: 7796880\n",
      "    num_steps_trained: 7796880\n",
      "  iterations_since_restore: 780\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.06886792452829\n",
      "    ram_util_percent: 58.506132075471676\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045497285701248655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.14298941029722\n",
      "    mean_inference_ms: 2.851950785141779\n",
      "    mean_raw_obs_processing_ms: 3.670110683003153\n",
      "  time_since_restore: 123321.15744566917\n",
      "  time_this_iter_s: 148.4735152721405\n",
      "  time_total_s: 123321.15744566917\n",
      "  timers:\n",
      "    learn_throughput: 935.698\n",
      "    learn_time_ms: 10682.931\n",
      "    load_throughput: 90813.98\n",
      "    load_time_ms: 110.071\n",
      "    sample_throughput: 65.252\n",
      "    sample_time_ms: 153190.589\n",
      "    update_time_ms: 16.285\n",
      "  timestamp: 1636417761\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7796880\n",
      "  training_iteration: 780\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   780</td><td style=\"text-align: right;\">          123321</td><td style=\"text-align: right;\">7796880</td><td style=\"text-align: right;\"> 4.09766</td><td style=\"text-align: right;\">               12.55</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           91.5135</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7806876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-32-19\n",
      "  done: false\n",
      "  episode_len_mean: 90.35454545454546\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.730000000000016\n",
      "  episode_reward_mean: 4.313636363636373\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 84566\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0067702802837406\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012390227947908677\n",
      "          policy_loss: -0.05659697588501323\n",
      "          total_loss: 0.11585970822976441\n",
      "          vf_explained_var: 0.9332121014595032\n",
      "          vf_loss: 0.1642978977603026\n",
      "    num_agent_steps_sampled: 7806876\n",
      "    num_agent_steps_trained: 7806876\n",
      "    num_steps_sampled: 7806876\n",
      "    num_steps_trained: 7806876\n",
      "  iterations_since_restore: 781\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.7156862745098\n",
      "    ram_util_percent: 58.50705882352941\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045480579706540555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.14263440293606\n",
      "    mean_inference_ms: 2.8520409628649004\n",
      "    mean_raw_obs_processing_ms: 3.6732581041382812\n",
      "  time_since_restore: 123499.81199502945\n",
      "  time_this_iter_s: 178.65454936027527\n",
      "  time_total_s: 123499.81199502945\n",
      "  timers:\n",
      "    learn_throughput: 935.436\n",
      "    learn_time_ms: 10685.924\n",
      "    load_throughput: 90885.559\n",
      "    load_time_ms: 109.984\n",
      "    sample_throughput: 65.11\n",
      "    sample_time_ms: 153523.746\n",
      "    update_time_ms: 15.871\n",
      "  timestamp: 1636417939\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7806876\n",
      "  training_iteration: 781\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   781</td><td style=\"text-align: right;\">          123500</td><td style=\"text-align: right;\">7806876</td><td style=\"text-align: right;\"> 4.31364</td><td style=\"text-align: right;\">               12.73</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           90.3545</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7816872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-35-26\n",
      "  done: false\n",
      "  episode_len_mean: 90.10810810810811\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.49999999999997\n",
      "  episode_reward_mean: 4.3618018018018105\n",
      "  episode_reward_min: -1.2400000000000007\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 84677\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9970376381507287\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012565094299493842\n",
      "          policy_loss: -0.05363065102097825\n",
      "          total_loss: 0.13345128210961946\n",
      "          vf_explained_var: 0.9306148290634155\n",
      "          vf_loss: 0.1784274528821946\n",
      "    num_agent_steps_sampled: 7816872\n",
      "    num_agent_steps_trained: 7816872\n",
      "    num_steps_sampled: 7816872\n",
      "    num_steps_trained: 7816872\n",
      "  iterations_since_restore: 782\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13571428571429\n",
      "    ram_util_percent: 58.525939849624066\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552504020418675\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.14649540847597\n",
      "    mean_inference_ms: 2.85212721098188\n",
      "    mean_raw_obs_processing_ms: 3.678932908936235\n",
      "  time_since_restore: 123685.94473147392\n",
      "  time_this_iter_s: 186.13273644447327\n",
      "  time_total_s: 123685.94473147392\n",
      "  timers:\n",
      "    learn_throughput: 935.577\n",
      "    learn_time_ms: 10684.316\n",
      "    load_throughput: 91063.34\n",
      "    load_time_ms: 109.77\n",
      "    sample_throughput: 64.3\n",
      "    sample_time_ms: 155459.556\n",
      "    update_time_ms: 15.259\n",
      "  timestamp: 1636418126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7816872\n",
      "  training_iteration: 782\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   782</td><td style=\"text-align: right;\">          123686</td><td style=\"text-align: right;\">7816872</td><td style=\"text-align: right;\">  4.3618</td><td style=\"text-align: right;\">                18.5</td><td style=\"text-align: right;\">               -1.24</td><td style=\"text-align: right;\">           90.1081</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7826868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-38-00\n",
      "  done: false\n",
      "  episode_len_mean: 90.88181818181818\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.99000000000001\n",
      "  episode_reward_mean: 4.901727272727283\n",
      "  episode_reward_min: -1.560000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 84787\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9950338738596338\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012820110205815267\n",
      "          policy_loss: -0.05197588262012881\n",
      "          total_loss: 0.14703358564780564\n",
      "          vf_explained_var: 0.9519028067588806\n",
      "          vf_loss: 0.1897539929845012\n",
      "    num_agent_steps_sampled: 7826868\n",
      "    num_agent_steps_trained: 7826868\n",
      "    num_steps_sampled: 7826868\n",
      "    num_steps_trained: 7826868\n",
      "  iterations_since_restore: 783\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.31681818181816\n",
      "    ram_util_percent: 58.59772727272726\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549330010523929\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.14814721098583\n",
      "    mean_inference_ms: 2.8519810581232186\n",
      "    mean_raw_obs_processing_ms: 3.6771993186626517\n",
      "  time_since_restore: 123840.38401937485\n",
      "  time_this_iter_s: 154.43928790092468\n",
      "  time_total_s: 123840.38401937485\n",
      "  timers:\n",
      "    learn_throughput: 935.013\n",
      "    learn_time_ms: 10690.755\n",
      "    load_throughput: 90984.313\n",
      "    load_time_ms: 109.865\n",
      "    sample_throughput: 64.933\n",
      "    sample_time_ms: 153944.304\n",
      "    update_time_ms: 13.324\n",
      "  timestamp: 1636418280\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7826868\n",
      "  training_iteration: 783\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   783</td><td style=\"text-align: right;\">          123840</td><td style=\"text-align: right;\">7826868</td><td style=\"text-align: right;\"> 4.90173</td><td style=\"text-align: right;\">               14.99</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           90.8818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7836864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-40-50\n",
      "  done: false\n",
      "  episode_len_mean: 88.61061946902655\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.359999999999946\n",
      "  episode_reward_mean: 4.863185840707973\n",
      "  episode_reward_min: -1.4400000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 84900\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.986476402506869\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012310420974892057\n",
      "          policy_loss: -0.05512069932017953\n",
      "          total_loss: 0.11444053056403103\n",
      "          vf_explained_var: 0.9503492116928101\n",
      "          vf_loss: 0.16138131422205612\n",
      "    num_agent_steps_sampled: 7836864\n",
      "    num_agent_steps_trained: 7836864\n",
      "    num_steps_sampled: 7836864\n",
      "    num_steps_trained: 7836864\n",
      "  iterations_since_restore: 784\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.76872427983538\n",
      "    ram_util_percent: 58.51358024691358\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549309933674325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.14890305425032\n",
      "    mean_inference_ms: 2.8519433937794467\n",
      "    mean_raw_obs_processing_ms: 3.6803684705298383\n",
      "  time_since_restore: 124010.41517567635\n",
      "  time_this_iter_s: 170.0311563014984\n",
      "  time_total_s: 124010.41517567635\n",
      "  timers:\n",
      "    learn_throughput: 934.94\n",
      "    learn_time_ms: 10691.597\n",
      "    load_throughput: 91196.825\n",
      "    load_time_ms: 109.609\n",
      "    sample_throughput: 64.55\n",
      "    sample_time_ms: 154857.385\n",
      "    update_time_ms: 11.827\n",
      "  timestamp: 1636418450\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7836864\n",
      "  training_iteration: 784\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   784</td><td style=\"text-align: right;\">          124010</td><td style=\"text-align: right;\">7836864</td><td style=\"text-align: right;\"> 4.86319</td><td style=\"text-align: right;\">               16.36</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           88.6106</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7846860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-43-27\n",
      "  done: false\n",
      "  episode_len_mean: 91.2090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.36999999999997\n",
      "  episode_reward_mean: 4.720727272727282\n",
      "  episode_reward_min: -1.2800000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 85010\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0132480124123076\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012736200428297215\n",
      "          policy_loss: -0.05291271619339529\n",
      "          total_loss: 0.12889571147055454\n",
      "          vf_explained_var: 0.9463139176368713\n",
      "          vf_loss: 0.17292625014789595\n",
      "    num_agent_steps_sampled: 7846860\n",
      "    num_agent_steps_trained: 7846860\n",
      "    num_steps_sampled: 7846860\n",
      "    num_steps_trained: 7846860\n",
      "  iterations_since_restore: 785\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.74196428571429\n",
      "    ram_util_percent: 58.54330357142857\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045506129518111414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.1515328670447\n",
      "    mean_inference_ms: 2.8518824697989866\n",
      "    mean_raw_obs_processing_ms: 3.6798794539708948\n",
      "  time_since_restore: 124167.67202782631\n",
      "  time_this_iter_s: 157.25685214996338\n",
      "  time_total_s: 124167.67202782631\n",
      "  timers:\n",
      "    learn_throughput: 933.921\n",
      "    learn_time_ms: 10703.258\n",
      "    load_throughput: 91062.924\n",
      "    load_time_ms: 109.77\n",
      "    sample_throughput: 64.108\n",
      "    sample_time_ms: 155925.187\n",
      "    update_time_ms: 11.4\n",
      "  timestamp: 1636418607\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7846860\n",
      "  training_iteration: 785\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   785</td><td style=\"text-align: right;\">          124168</td><td style=\"text-align: right;\">7846860</td><td style=\"text-align: right;\"> 4.72073</td><td style=\"text-align: right;\">               18.37</td><td style=\"text-align: right;\">               -1.28</td><td style=\"text-align: right;\">           91.2091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7856856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-46-24\n",
      "  done: false\n",
      "  episode_len_mean: 88.87387387387388\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.42999999999995\n",
      "  episode_reward_mean: 5.065225225225234\n",
      "  episode_reward_min: -1.5000000000000007\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 85121\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9900626473956637\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012620450885116624\n",
      "          policy_loss: -0.05325275937365925\n",
      "          total_loss: 0.12053314020904975\n",
      "          vf_explained_var: 0.9512946009635925\n",
      "          vf_loss: 0.16493555986855785\n",
      "    num_agent_steps_sampled: 7856856\n",
      "    num_agent_steps_trained: 7856856\n",
      "    num_steps_sampled: 7856856\n",
      "    num_steps_trained: 7856856\n",
      "  iterations_since_restore: 786\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.42103174603174\n",
      "    ram_util_percent: 58.56984126984128\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550168557505564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.15169746656728\n",
      "    mean_inference_ms: 2.8519864512577247\n",
      "    mean_raw_obs_processing_ms: 3.6825304184898546\n",
      "  time_since_restore: 124344.10953235626\n",
      "  time_this_iter_s: 176.437504529953\n",
      "  time_total_s: 124344.10953235626\n",
      "  timers:\n",
      "    learn_throughput: 934.191\n",
      "    learn_time_ms: 10700.173\n",
      "    load_throughput: 91076.534\n",
      "    load_time_ms: 109.754\n",
      "    sample_throughput: 63.48\n",
      "    sample_time_ms: 157467.179\n",
      "    update_time_ms: 11.195\n",
      "  timestamp: 1636418784\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7856856\n",
      "  training_iteration: 786\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   786</td><td style=\"text-align: right;\">          124344</td><td style=\"text-align: right;\">7856856</td><td style=\"text-align: right;\"> 5.06523</td><td style=\"text-align: right;\">               16.43</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           88.8739</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7866852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-49-04\n",
      "  done: false\n",
      "  episode_len_mean: 92.47222222222223\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000017\n",
      "  episode_reward_mean: 4.720833333333342\n",
      "  episode_reward_min: -0.8600000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 85229\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9788467737344595\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012965881688553655\n",
      "          policy_loss: -0.05508384148064905\n",
      "          total_loss: 0.16103576912234227\n",
      "          vf_explained_var: 0.9410158395767212\n",
      "          vf_loss: 0.20637017876610286\n",
      "    num_agent_steps_sampled: 7866852\n",
      "    num_agent_steps_trained: 7866852\n",
      "    num_steps_sampled: 7866852\n",
      "    num_steps_trained: 7866852\n",
      "  iterations_since_restore: 787\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.93070175438595\n",
      "    ram_util_percent: 58.6798245614035\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045480701515025854\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.152532584604735\n",
      "    mean_inference_ms: 2.851934627431825\n",
      "    mean_raw_obs_processing_ms: 3.680787875935479\n",
      "  time_since_restore: 124503.9271235466\n",
      "  time_this_iter_s: 159.81759119033813\n",
      "  time_total_s: 124503.9271235466\n",
      "  timers:\n",
      "    learn_throughput: 934.078\n",
      "    learn_time_ms: 10701.462\n",
      "    load_throughput: 91053.807\n",
      "    load_time_ms: 109.781\n",
      "    sample_throughput: 64.128\n",
      "    sample_time_ms: 155874.79\n",
      "    update_time_ms: 11.373\n",
      "  timestamp: 1636418944\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7866852\n",
      "  training_iteration: 787\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   787</td><td style=\"text-align: right;\">          124504</td><td style=\"text-align: right;\">7866852</td><td style=\"text-align: right;\"> 4.72083</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.86</td><td style=\"text-align: right;\">           92.4722</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7876848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-51-59\n",
      "  done: false\n",
      "  episode_len_mean: 88.91228070175438\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.930000000000014\n",
      "  episode_reward_mean: 4.407631578947378\n",
      "  episode_reward_min: -1.3200000000000007\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 85343\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.001951375985757\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01172971176940043\n",
      "          policy_loss: -0.0534315346294425\n",
      "          total_loss: 0.09537338054715058\n",
      "          vf_explained_var: 0.9507599472999573\n",
      "          vf_loss: 0.1421026787155459\n",
      "    num_agent_steps_sampled: 7876848\n",
      "    num_agent_steps_trained: 7876848\n",
      "    num_steps_sampled: 7876848\n",
      "    num_steps_trained: 7876848\n",
      "  iterations_since_restore: 788\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.2484\n",
      "    ram_util_percent: 58.5412\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04547245016335668\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.15464265565909\n",
      "    mean_inference_ms: 2.85177023145738\n",
      "    mean_raw_obs_processing_ms: 3.6843984774812495\n",
      "  time_since_restore: 124679.4583940506\n",
      "  time_this_iter_s: 175.5312705039978\n",
      "  time_total_s: 124679.4583940506\n",
      "  timers:\n",
      "    learn_throughput: 934.442\n",
      "    learn_time_ms: 10697.297\n",
      "    load_throughput: 91121.329\n",
      "    load_time_ms: 109.7\n",
      "    sample_throughput: 63.556\n",
      "    sample_time_ms: 157278.051\n",
      "    update_time_ms: 10.632\n",
      "  timestamp: 1636419119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7876848\n",
      "  training_iteration: 788\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   788</td><td style=\"text-align: right;\">          124679</td><td style=\"text-align: right;\">7876848</td><td style=\"text-align: right;\"> 4.40763</td><td style=\"text-align: right;\">               12.93</td><td style=\"text-align: right;\">               -1.32</td><td style=\"text-align: right;\">           88.9123</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7886844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-54-27\n",
      "  done: false\n",
      "  episode_len_mean: 92.98130841121495\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.99000000000001\n",
      "  episode_reward_mean: 4.859252336448609\n",
      "  episode_reward_min: -1.6100000000000005\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 85450\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9939552450791382\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013611601124160204\n",
      "          policy_loss: -0.05475129032205058\n",
      "          total_loss: 0.11674576989319335\n",
      "          vf_explained_var: 0.9451492428779602\n",
      "          vf_loss: 0.16042768193138207\n",
      "    num_agent_steps_sampled: 7886844\n",
      "    num_agent_steps_trained: 7886844\n",
      "    num_steps_sampled: 7886844\n",
      "    num_steps_trained: 7886844\n",
      "  iterations_since_restore: 789\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.02748815165879\n",
      "    ram_util_percent: 58.550236966824635\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550287436688514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.15952588359736\n",
      "    mean_inference_ms: 2.851877134841047\n",
      "    mean_raw_obs_processing_ms: 3.6812732927009564\n",
      "  time_since_restore: 124826.86203598976\n",
      "  time_this_iter_s: 147.4036419391632\n",
      "  time_total_s: 124826.86203598976\n",
      "  timers:\n",
      "    learn_throughput: 934.272\n",
      "    learn_time_ms: 10699.237\n",
      "    load_throughput: 91085.517\n",
      "    load_time_ms: 109.743\n",
      "    sample_throughput: 64.663\n",
      "    sample_time_ms: 154585.439\n",
      "    update_time_ms: 10.039\n",
      "  timestamp: 1636419267\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7886844\n",
      "  training_iteration: 789\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   789</td><td style=\"text-align: right;\">          124827</td><td style=\"text-align: right;\">7886844</td><td style=\"text-align: right;\"> 4.85925</td><td style=\"text-align: right;\">               14.99</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           92.9813</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7896840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-57-24\n",
      "  done: false\n",
      "  episode_len_mean: 91.96330275229357\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.78999999999999\n",
      "  episode_reward_mean: 4.6933944954128535\n",
      "  episode_reward_min: -1.3200000000000003\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 85559\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.020534381805322\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012807742415573899\n",
      "          policy_loss: -0.057803545229168786\n",
      "          total_loss: 0.11557838577403026\n",
      "          vf_explained_var: 0.9477292895317078\n",
      "          vf_loss: 0.1644096353958942\n",
      "    num_agent_steps_sampled: 7896840\n",
      "    num_agent_steps_trained: 7896840\n",
      "    num_steps_sampled: 7896840\n",
      "    num_steps_trained: 7896840\n",
      "  iterations_since_restore: 790\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.45238095238095\n",
      "    ram_util_percent: 58.669047619047625\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548773123252284\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.158557390795096\n",
      "    mean_inference_ms: 2.8520375975881427\n",
      "    mean_raw_obs_processing_ms: 3.683643257058913\n",
      "  time_since_restore: 125003.57433128357\n",
      "  time_this_iter_s: 176.71229529380798\n",
      "  time_total_s: 125003.57433128357\n",
      "  timers:\n",
      "    learn_throughput: 934.235\n",
      "    learn_time_ms: 10699.663\n",
      "    load_throughput: 91057.387\n",
      "    load_time_ms: 109.777\n",
      "    sample_throughput: 63.503\n",
      "    sample_time_ms: 157409.943\n",
      "    update_time_ms: 9.077\n",
      "  timestamp: 1636419444\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7896840\n",
      "  training_iteration: 790\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   790</td><td style=\"text-align: right;\">          125004</td><td style=\"text-align: right;\">7896840</td><td style=\"text-align: right;\"> 4.69339</td><td style=\"text-align: right;\">               16.79</td><td style=\"text-align: right;\">               -1.32</td><td style=\"text-align: right;\">           91.9633</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7906836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 90.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.42\n",
      "  episode_reward_mean: 4.253454545454555\n",
      "  episode_reward_min: -1.2600000000000002\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 85669\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9812031995536934\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01240801552649696\n",
      "          policy_loss: -0.05730794610407872\n",
      "          total_loss: 0.10174684092784539\n",
      "          vf_explained_var: 0.9382365942001343\n",
      "          vf_loss: 0.15059980815674504\n",
      "    num_agent_steps_sampled: 7906836\n",
      "    num_agent_steps_trained: 7906836\n",
      "    num_steps_sampled: 7906836\n",
      "    num_steps_trained: 7906836\n",
      "  iterations_since_restore: 791\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.19469026548673\n",
      "    ram_util_percent: 58.46769911504425\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045478843021668755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.1596561297473\n",
      "    mean_inference_ms: 2.852036081143713\n",
      "    mean_raw_obs_processing_ms: 3.683899405643552\n",
      "  time_since_restore: 125162.25022768974\n",
      "  time_this_iter_s: 158.6758964061737\n",
      "  time_total_s: 125162.25022768974\n",
      "  timers:\n",
      "    learn_throughput: 933.927\n",
      "    learn_time_ms: 10703.196\n",
      "    load_throughput: 91044.04\n",
      "    load_time_ms: 109.793\n",
      "    sample_throughput: 64.321\n",
      "    sample_time_ms: 155408.253\n",
      "    update_time_ms: 9.713\n",
      "  timestamp: 1636419602\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7906836\n",
      "  training_iteration: 791\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   791</td><td style=\"text-align: right;\">          125162</td><td style=\"text-align: right;\">7906836</td><td style=\"text-align: right;\"> 4.25345</td><td style=\"text-align: right;\">               16.42</td><td style=\"text-align: right;\">               -1.26</td><td style=\"text-align: right;\">              90.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7916832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-03-10\n",
      "  done: false\n",
      "  episode_len_mean: 89.65765765765765\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.120000000000019\n",
      "  episode_reward_mean: 3.9206306306306393\n",
      "  episode_reward_min: -1.3600000000000003\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 85780\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9995646299459995\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011630307787598434\n",
      "          policy_loss: -0.057101776727881186\n",
      "          total_loss: 0.11022548716133222\n",
      "          vf_explained_var: 0.9333921670913696\n",
      "          vf_loss: 0.16082761405179133\n",
      "    num_agent_steps_sampled: 7916832\n",
      "    num_agent_steps_trained: 7916832\n",
      "    num_steps_sampled: 7916832\n",
      "    num_steps_trained: 7916832\n",
      "  iterations_since_restore: 792\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.50223880597014\n",
      "    ram_util_percent: 58.57276119402985\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045514196279882124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.16376346665266\n",
      "    mean_inference_ms: 2.8519642479408405\n",
      "    mean_raw_obs_processing_ms: 3.6881794078934513\n",
      "  time_since_restore: 125350.09410357475\n",
      "  time_this_iter_s: 187.84387588500977\n",
      "  time_total_s: 125350.09410357475\n",
      "  timers:\n",
      "    learn_throughput: 933.766\n",
      "    learn_time_ms: 10705.042\n",
      "    load_throughput: 90944.446\n",
      "    load_time_ms: 109.913\n",
      "    sample_throughput: 64.251\n",
      "    sample_time_ms: 155578.052\n",
      "    update_time_ms: 8.95\n",
      "  timestamp: 1636419790\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7916832\n",
      "  training_iteration: 792\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   792</td><td style=\"text-align: right;\">          125350</td><td style=\"text-align: right;\">7916832</td><td style=\"text-align: right;\"> 3.92063</td><td style=\"text-align: right;\">               14.12</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           89.6577</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7926828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-06-07\n",
      "  done: false\n",
      "  episode_len_mean: 88.90178571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.030000000000008\n",
      "  episode_reward_mean: 4.658392857142866\n",
      "  episode_reward_min: -1.3900000000000003\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 85892\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9999267075815772\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012346717479361275\n",
      "          policy_loss: -0.0593889148078031\n",
      "          total_loss: 0.10856600021545448\n",
      "          vf_explained_var: 0.9419257044792175\n",
      "          vf_loss: 0.15982681467619717\n",
      "    num_agent_steps_sampled: 7926828\n",
      "    num_agent_steps_trained: 7926828\n",
      "    num_steps_sampled: 7926828\n",
      "    num_steps_trained: 7926828\n",
      "  iterations_since_restore: 793\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.52687747035573\n",
      "    ram_util_percent: 58.467984189723325\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549744438917388\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.16538607947575\n",
      "    mean_inference_ms: 2.8521626999895964\n",
      "    mean_raw_obs_processing_ms: 3.688596375781457\n",
      "  time_since_restore: 125526.79958176613\n",
      "  time_this_iter_s: 176.70547819137573\n",
      "  time_total_s: 125526.79958176613\n",
      "  timers:\n",
      "    learn_throughput: 934.581\n",
      "    learn_time_ms: 10695.699\n",
      "    load_throughput: 91114.081\n",
      "    load_time_ms: 109.709\n",
      "    sample_throughput: 63.34\n",
      "    sample_time_ms: 157814.329\n",
      "    update_time_ms: 9.071\n",
      "  timestamp: 1636419967\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7926828\n",
      "  training_iteration: 793\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   793</td><td style=\"text-align: right;\">          125527</td><td style=\"text-align: right;\">7926828</td><td style=\"text-align: right;\"> 4.65839</td><td style=\"text-align: right;\">               11.03</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">           88.9018</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7936824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-08-48\n",
      "  done: false\n",
      "  episode_len_mean: 93.81308411214954\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.519999999999957\n",
      "  episode_reward_mean: 4.9104672897196355\n",
      "  episode_reward_min: -0.7700000000000006\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 85999\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0214968568239455\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012423315521805329\n",
      "          policy_loss: -0.056320161467943435\n",
      "          total_loss: 0.12205852142845591\n",
      "          vf_explained_var: 0.9484840035438538\n",
      "          vf_loss: 0.17029178524947064\n",
      "    num_agent_steps_sampled: 7936824\n",
      "    num_agent_steps_trained: 7936824\n",
      "    num_steps_sampled: 7936824\n",
      "    num_steps_trained: 7936824\n",
      "  iterations_since_restore: 794\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.18034934497818\n",
      "    ram_util_percent: 58.59694323144105\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551922175024414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.16737831422328\n",
      "    mean_inference_ms: 2.852148303114007\n",
      "    mean_raw_obs_processing_ms: 3.688856786072208\n",
      "  time_since_restore: 125687.75375175476\n",
      "  time_this_iter_s: 160.9541699886322\n",
      "  time_total_s: 125687.75375175476\n",
      "  timers:\n",
      "    learn_throughput: 934.258\n",
      "    learn_time_ms: 10699.406\n",
      "    load_throughput: 91077.82\n",
      "    load_time_ms: 109.752\n",
      "    sample_throughput: 63.708\n",
      "    sample_time_ms: 156902.504\n",
      "    update_time_ms: 9.685\n",
      "  timestamp: 1636420128\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7936824\n",
      "  training_iteration: 794\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   794</td><td style=\"text-align: right;\">          125688</td><td style=\"text-align: right;\">7936824</td><td style=\"text-align: right;\"> 4.91047</td><td style=\"text-align: right;\">               18.52</td><td style=\"text-align: right;\">               -0.77</td><td style=\"text-align: right;\">           93.8131</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7946820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-11-34\n",
      "  done: false\n",
      "  episode_len_mean: 91.41284403669725\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.610000000000014\n",
      "  episode_reward_mean: 4.060550458715605\n",
      "  episode_reward_min: -2.219999999999999\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 86108\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.055725995190123\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012146521740322635\n",
      "          policy_loss: -0.05854442850328409\n",
      "          total_loss: 0.0977110077889684\n",
      "          vf_explained_var: 0.9352782964706421\n",
      "          vf_loss: 0.14914140108431506\n",
      "    num_agent_steps_sampled: 7946820\n",
      "    num_agent_steps_trained: 7946820\n",
      "    num_steps_sampled: 7946820\n",
      "    num_steps_trained: 7946820\n",
      "  iterations_since_restore: 795\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.47426160337554\n",
      "    ram_util_percent: 58.45991561181433\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045521015031013516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.168072182570164\n",
      "    mean_inference_ms: 2.851971663436989\n",
      "    mean_raw_obs_processing_ms: 3.693204664762777\n",
      "  time_since_restore: 125854.05610132217\n",
      "  time_this_iter_s: 166.30234956741333\n",
      "  time_total_s: 125854.05610132217\n",
      "  timers:\n",
      "    learn_throughput: 935.216\n",
      "    learn_time_ms: 10688.441\n",
      "    load_throughput: 91079.937\n",
      "    load_time_ms: 109.75\n",
      "    sample_throughput: 63.339\n",
      "    sample_time_ms: 157816.762\n",
      "    update_time_ms: 10.544\n",
      "  timestamp: 1636420294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7946820\n",
      "  training_iteration: 795\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   795</td><td style=\"text-align: right;\">          125854</td><td style=\"text-align: right;\">7946820</td><td style=\"text-align: right;\"> 4.06055</td><td style=\"text-align: right;\">               12.61</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           91.4128</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7956816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-14-28\n",
      "  done: false\n",
      "  episode_len_mean: 91.77981651376147\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.360000000000015\n",
      "  episode_reward_mean: 4.121009174311937\n",
      "  episode_reward_min: -0.46000000000000085\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 86217\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0540742854786735\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011299953569556006\n",
      "          policy_loss: -0.05997214243452773\n",
      "          total_loss: 0.0904823470621919\n",
      "          vf_explained_var: 0.9463887810707092\n",
      "          vf_loss: 0.14525252419691057\n",
      "    num_agent_steps_sampled: 7956816\n",
      "    num_agent_steps_trained: 7956816\n",
      "    num_steps_sampled: 7956816\n",
      "    num_steps_trained: 7956816\n",
      "  iterations_since_restore: 796\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.22782258064517\n",
      "    ram_util_percent: 58.58346774193547\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045492457598007484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.168664347583835\n",
      "    mean_inference_ms: 2.851753390542633\n",
      "    mean_raw_obs_processing_ms: 3.694308026451539\n",
      "  time_since_restore: 126027.7213101387\n",
      "  time_this_iter_s: 173.66520881652832\n",
      "  time_total_s: 126027.7213101387\n",
      "  timers:\n",
      "    learn_throughput: 935.35\n",
      "    learn_time_ms: 10686.909\n",
      "    load_throughput: 90159.605\n",
      "    load_time_ms: 110.87\n",
      "    sample_throughput: 63.45\n",
      "    sample_time_ms: 157540.183\n",
      "    update_time_ms: 9.977\n",
      "  timestamp: 1636420468\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7956816\n",
      "  training_iteration: 796\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   796</td><td style=\"text-align: right;\">          126028</td><td style=\"text-align: right;\">7956816</td><td style=\"text-align: right;\"> 4.12101</td><td style=\"text-align: right;\">               12.36</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           91.7798</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7966812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-17-09\n",
      "  done: false\n",
      "  episode_len_mean: 90.91818181818182\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.98000000000002\n",
      "  episode_reward_mean: 4.001727272727282\n",
      "  episode_reward_min: -1.9300000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 86327\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.020423078129434\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01142316389677771\n",
      "          policy_loss: -0.05978890828406199\n",
      "          total_loss: 0.10257357495367272\n",
      "          vf_explained_var: 0.9310057759284973\n",
      "          vf_loss: 0.15654331618585648\n",
      "    num_agent_steps_sampled: 7966812\n",
      "    num_agent_steps_trained: 7966812\n",
      "    num_steps_sampled: 7966812\n",
      "    num_steps_trained: 7966812\n",
      "  iterations_since_restore: 797\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.50869565217391\n",
      "    ram_util_percent: 58.51521739130435\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045518476357961614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.17205732768319\n",
      "    mean_inference_ms: 2.8521424297564515\n",
      "    mean_raw_obs_processing_ms: 3.6931246653087544\n",
      "  time_since_restore: 126188.58867526054\n",
      "  time_this_iter_s: 160.86736512184143\n",
      "  time_total_s: 126188.58867526054\n",
      "  timers:\n",
      "    learn_throughput: 935.893\n",
      "    learn_time_ms: 10680.712\n",
      "    load_throughput: 90126.986\n",
      "    load_time_ms: 110.91\n",
      "    sample_throughput: 63.406\n",
      "    sample_time_ms: 157650.635\n",
      "    update_time_ms: 10.505\n",
      "  timestamp: 1636420629\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7966812\n",
      "  training_iteration: 797\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   797</td><td style=\"text-align: right;\">          126189</td><td style=\"text-align: right;\">7966812</td><td style=\"text-align: right;\"> 4.00173</td><td style=\"text-align: right;\">               11.98</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">           90.9182</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7976808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-19-31\n",
      "  done: false\n",
      "  episode_len_mean: 92.31481481481481\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.490000000000014\n",
      "  episode_reward_mean: 4.035277777777788\n",
      "  episode_reward_min: -1.7100000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 86435\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0502053203745785\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01175738231778927\n",
      "          policy_loss: -0.05776225894004998\n",
      "          total_loss: 0.10238894659420873\n",
      "          vf_explained_var: 0.9335981607437134\n",
      "          vf_loss: 0.15386847061956796\n",
      "    num_agent_steps_sampled: 7976808\n",
      "    num_agent_steps_trained: 7976808\n",
      "    num_steps_sampled: 7976808\n",
      "    num_steps_trained: 7976808\n",
      "  iterations_since_restore: 798\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10689655172412\n",
      "    ram_util_percent: 58.61822660098521\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552115202120955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.17456932353157\n",
      "    mean_inference_ms: 2.852113391675368\n",
      "    mean_raw_obs_processing_ms: 3.690084093464633\n",
      "  time_since_restore: 126330.99010276794\n",
      "  time_this_iter_s: 142.4014275074005\n",
      "  time_total_s: 126330.99010276794\n",
      "  timers:\n",
      "    learn_throughput: 935.971\n",
      "    learn_time_ms: 10679.823\n",
      "    load_throughput: 90260.012\n",
      "    load_time_ms: 110.747\n",
      "    sample_throughput: 64.767\n",
      "    sample_time_ms: 154339.034\n",
      "    update_time_ms: 10.154\n",
      "  timestamp: 1636420771\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7976808\n",
      "  training_iteration: 798\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   798</td><td style=\"text-align: right;\">          126331</td><td style=\"text-align: right;\">7976808</td><td style=\"text-align: right;\"> 4.03528</td><td style=\"text-align: right;\">               10.49</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           92.3148</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7986804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-22-09\n",
      "  done: false\n",
      "  episode_len_mean: 92.44444444444444\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.780000000000017\n",
      "  episode_reward_mean: 4.570925925925936\n",
      "  episode_reward_min: -1.6800000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 86543\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.02771276795966\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01259142573746063\n",
      "          policy_loss: -0.05655530881391377\n",
      "          total_loss: 0.1174073038670497\n",
      "          vf_explained_var: 0.9496863484382629\n",
      "          vf_loss: 0.16555489842167012\n",
      "    num_agent_steps_sampled: 7986804\n",
      "    num_agent_steps_trained: 7986804\n",
      "    num_steps_sampled: 7986804\n",
      "    num_steps_trained: 7986804\n",
      "  iterations_since_restore: 799\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.02678571428571\n",
      "    ram_util_percent: 58.53035714285715\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548699369274938\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.17379284949623\n",
      "    mean_inference_ms: 2.852116824958035\n",
      "    mean_raw_obs_processing_ms: 3.6889985326699235\n",
      "  time_since_restore: 126488.23972630501\n",
      "  time_this_iter_s: 157.2496235370636\n",
      "  time_total_s: 126488.23972630501\n",
      "  timers:\n",
      "    learn_throughput: 936.463\n",
      "    learn_time_ms: 10674.202\n",
      "    load_throughput: 90230.408\n",
      "    load_time_ms: 110.783\n",
      "    sample_throughput: 64.354\n",
      "    sample_time_ms: 155329.007\n",
      "    update_time_ms: 10.409\n",
      "  timestamp: 1636420929\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7986804\n",
      "  training_iteration: 799\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   799</td><td style=\"text-align: right;\">          126488</td><td style=\"text-align: right;\">7986804</td><td style=\"text-align: right;\"> 4.57093</td><td style=\"text-align: right;\">               12.78</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           92.4444</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 7996800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-25-02\n",
      "  done: false\n",
      "  episode_len_mean: 89.41592920353982\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.050000000000015\n",
      "  episode_reward_mean: 4.506814159292046\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 86656\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0414497325563024\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012076241807845597\n",
      "          policy_loss: -0.05604463603793301\n",
      "          total_loss: 0.11866835681243967\n",
      "          vf_explained_var: 0.941871166229248\n",
      "          vf_loss: 0.16761630139130557\n",
      "    num_agent_steps_sampled: 7996800\n",
      "    num_agent_steps_trained: 7996800\n",
      "    num_steps_sampled: 7996800\n",
      "    num_steps_trained: 7996800\n",
      "  iterations_since_restore: 800\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.89190283400809\n",
      "    ram_util_percent: 58.465587044534395\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045476100188941104\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.17560024109081\n",
      "    mean_inference_ms: 2.852006667129929\n",
      "    mean_raw_obs_processing_ms: 3.689754083174511\n",
      "  time_since_restore: 126661.30703496933\n",
      "  time_this_iter_s: 173.0673086643219\n",
      "  time_total_s: 126661.30703496933\n",
      "  timers:\n",
      "    learn_throughput: 936.427\n",
      "    learn_time_ms: 10674.617\n",
      "    load_throughput: 90259.584\n",
      "    load_time_ms: 110.747\n",
      "    sample_throughput: 64.506\n",
      "    sample_time_ms: 154963.439\n",
      "    update_time_ms: 10.839\n",
      "  timestamp: 1636421102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7996800\n",
      "  training_iteration: 800\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   800</td><td style=\"text-align: right;\">          126661</td><td style=\"text-align: right;\">7996800</td><td style=\"text-align: right;\"> 4.50681</td><td style=\"text-align: right;\">               14.05</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           89.4159</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8006796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-27-35\n",
      "  done: false\n",
      "  episode_len_mean: 91.46296296296296\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.290000000000019\n",
      "  episode_reward_mean: 4.342870370370379\n",
      "  episode_reward_min: -1.4100000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 86764\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0260860315754883\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012008649170930157\n",
      "          policy_loss: -0.058367310443686114\n",
      "          total_loss: 0.08674948759790924\n",
      "          vf_explained_var: 0.9476712942123413\n",
      "          vf_loss: 0.13802045189226286\n",
      "    num_agent_steps_sampled: 8006796\n",
      "    num_agent_steps_trained: 8006796\n",
      "    num_steps_sampled: 8006796\n",
      "    num_steps_trained: 8006796\n",
      "  iterations_since_restore: 801\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69223744292239\n",
      "    ram_util_percent: 58.56301369863012\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551066255012026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.18291857240438\n",
      "    mean_inference_ms: 2.8519460789129134\n",
      "    mean_raw_obs_processing_ms: 3.6883722421324308\n",
      "  time_since_restore: 126814.52243566513\n",
      "  time_this_iter_s: 153.21540069580078\n",
      "  time_total_s: 126814.52243566513\n",
      "  timers:\n",
      "    learn_throughput: 936.761\n",
      "    learn_time_ms: 10670.807\n",
      "    load_throughput: 90219.496\n",
      "    load_time_ms: 110.796\n",
      "    sample_throughput: 64.732\n",
      "    sample_time_ms: 154421.185\n",
      "    update_time_ms: 10.321\n",
      "  timestamp: 1636421255\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8006796\n",
      "  training_iteration: 801\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   801</td><td style=\"text-align: right;\">          126815</td><td style=\"text-align: right;\">8006796</td><td style=\"text-align: right;\"> 4.34287</td><td style=\"text-align: right;\">               14.29</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">            91.463</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8016792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-30-19\n",
      "  done: false\n",
      "  episode_len_mean: 89.28947368421052\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.840000000000018\n",
      "  episode_reward_mean: 4.745877192982467\n",
      "  episode_reward_min: -1.4400000000000008\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 86878\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.970775547496274\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01271554375710174\n",
      "          policy_loss: -0.05313920229832586\n",
      "          total_loss: 0.14739533840463712\n",
      "          vf_explained_var: 0.9505671858787537\n",
      "          vf_loss: 0.19127469704223748\n",
      "    num_agent_steps_sampled: 8016792\n",
      "    num_agent_steps_trained: 8016792\n",
      "    num_steps_sampled: 8016792\n",
      "    num_steps_trained: 8016792\n",
      "  iterations_since_restore: 802\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.87991452991453\n",
      "    ram_util_percent: 58.50811965811967\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045517326909560625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.18642491095489\n",
      "    mean_inference_ms: 2.852129580198158\n",
      "    mean_raw_obs_processing_ms: 3.6883403279199207\n",
      "  time_since_restore: 126978.26530146599\n",
      "  time_this_iter_s: 163.74286580085754\n",
      "  time_total_s: 126978.26530146599\n",
      "  timers:\n",
      "    learn_throughput: 937.144\n",
      "    learn_time_ms: 10666.454\n",
      "    load_throughput: 89960.193\n",
      "    load_time_ms: 111.116\n",
      "    sample_throughput: 65.757\n",
      "    sample_time_ms: 152015.036\n",
      "    update_time_ms: 10.504\n",
      "  timestamp: 1636421419\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8016792\n",
      "  training_iteration: 802\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   802</td><td style=\"text-align: right;\">          126978</td><td style=\"text-align: right;\">8016792</td><td style=\"text-align: right;\"> 4.74588</td><td style=\"text-align: right;\">               14.84</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           89.2895</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8026788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-32-58\n",
      "  done: false\n",
      "  episode_len_mean: 91.3425925925926\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000016\n",
      "  episode_reward_mean: 4.4969444444444555\n",
      "  episode_reward_min: -1.6800000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 86986\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.008252569549104\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01169635777195503\n",
      "          policy_loss: -0.05635243283314073\n",
      "          total_loss: 0.10756384110412537\n",
      "          vf_explained_var: 0.9505149722099304\n",
      "          vf_loss: 0.15735303443084414\n",
      "    num_agent_steps_sampled: 8026788\n",
      "    num_agent_steps_trained: 8026788\n",
      "    num_steps_sampled: 8026788\n",
      "    num_steps_trained: 8026788\n",
      "  iterations_since_restore: 803\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.05506607929516\n",
      "    ram_util_percent: 58.588546255506614\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0454789930418797\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.18707831751361\n",
      "    mean_inference_ms: 2.852018989703186\n",
      "    mean_raw_obs_processing_ms: 3.6860264440336383\n",
      "  time_since_restore: 127137.15868210793\n",
      "  time_this_iter_s: 158.89338064193726\n",
      "  time_total_s: 127137.15868210793\n",
      "  timers:\n",
      "    learn_throughput: 937.249\n",
      "    learn_time_ms: 10665.261\n",
      "    load_throughput: 89940.759\n",
      "    load_time_ms: 111.14\n",
      "    sample_throughput: 66.536\n",
      "    sample_time_ms: 150235.085\n",
      "    update_time_ms: 10.553\n",
      "  timestamp: 1636421578\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8026788\n",
      "  training_iteration: 803\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   803</td><td style=\"text-align: right;\">          127137</td><td style=\"text-align: right;\">8026788</td><td style=\"text-align: right;\"> 4.49694</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           91.3426</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8036784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-35-24\n",
      "  done: false\n",
      "  episode_len_mean: 89.91964285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.31999999999994\n",
      "  episode_reward_mean: 4.2353571428571515\n",
      "  episode_reward_min: -1.7400000000000007\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 87098\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.973890263402564\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01246785067680229\n",
      "          policy_loss: -0.05587807329785493\n",
      "          total_loss: 0.13453116007149218\n",
      "          vf_explained_var: 0.9399173855781555\n",
      "          vf_loss: 0.18174481343669005\n",
      "    num_agent_steps_sampled: 8036784\n",
      "    num_agent_steps_trained: 8036784\n",
      "    num_steps_sampled: 8036784\n",
      "    num_steps_trained: 8036784\n",
      "  iterations_since_restore: 804\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.19326923076922\n",
      "    ram_util_percent: 58.37307692307694\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551090014253069\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.192377725893735\n",
      "    mean_inference_ms: 2.8522133890275483\n",
      "    mean_raw_obs_processing_ms: 3.682660060307772\n",
      "  time_since_restore: 127283.43561267853\n",
      "  time_this_iter_s: 146.27693057060242\n",
      "  time_total_s: 127283.43561267853\n",
      "  timers:\n",
      "    learn_throughput: 937.584\n",
      "    learn_time_ms: 10661.448\n",
      "    load_throughput: 89944.889\n",
      "    load_time_ms: 111.135\n",
      "    sample_throughput: 67.191\n",
      "    sample_time_ms: 148770.555\n",
      "    update_time_ms: 11.263\n",
      "  timestamp: 1636421724\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8036784\n",
      "  training_iteration: 804\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   804</td><td style=\"text-align: right;\">          127283</td><td style=\"text-align: right;\">8036784</td><td style=\"text-align: right;\"> 4.23536</td><td style=\"text-align: right;\">               16.32</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           89.9196</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8046780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-38-04\n",
      "  done: false\n",
      "  episode_len_mean: 89.76576576576576\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.620000000000017\n",
      "  episode_reward_mean: 4.253963963963974\n",
      "  episode_reward_min: -1.4500000000000006\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 87209\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0273294683195586\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011204341165950675\n",
      "          policy_loss: -0.059660505545604176\n",
      "          total_loss: 0.09554625122099478\n",
      "          vf_explained_var: 0.9455888867378235\n",
      "          vf_loss: 0.14995516019308158\n",
      "    num_agent_steps_sampled: 8046780\n",
      "    num_agent_steps_trained: 8046780\n",
      "    num_steps_sampled: 8046780\n",
      "    num_steps_trained: 8046780\n",
      "  iterations_since_restore: 805\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.74585152838428\n",
      "    ram_util_percent: 58.38602620087335\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550750845683127\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.19440460027408\n",
      "    mean_inference_ms: 2.8522893241059086\n",
      "    mean_raw_obs_processing_ms: 3.6849609140891575\n",
      "  time_since_restore: 127443.57875442505\n",
      "  time_this_iter_s: 160.143141746521\n",
      "  time_total_s: 127443.57875442505\n",
      "  timers:\n",
      "    learn_throughput: 937.265\n",
      "    learn_time_ms: 10665.078\n",
      "    load_throughput: 89787.497\n",
      "    load_time_ms: 111.33\n",
      "    sample_throughput: 67.472\n",
      "    sample_time_ms: 148150.181\n",
      "    update_time_ms: 11.762\n",
      "  timestamp: 1636421884\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8046780\n",
      "  training_iteration: 805\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   805</td><td style=\"text-align: right;\">          127444</td><td style=\"text-align: right;\">8046780</td><td style=\"text-align: right;\"> 4.25396</td><td style=\"text-align: right;\">               12.62</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           89.7658</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8056776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-40-45\n",
      "  done: false\n",
      "  episode_len_mean: 91.00909090909092\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.17999999999993\n",
      "  episode_reward_mean: 4.542181818181828\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 87319\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.024103043935238\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012342249045161919\n",
      "          policy_loss: -0.05637266150015032\n",
      "          total_loss: 0.12191749083148873\n",
      "          vf_explained_var: 0.9373980760574341\n",
      "          vf_loss: 0.17041399601496693\n",
      "    num_agent_steps_sampled: 8056776\n",
      "    num_agent_steps_trained: 8056776\n",
      "    num_steps_sampled: 8056776\n",
      "    num_steps_trained: 8056776\n",
      "  iterations_since_restore: 806\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.78515283842795\n",
      "    ram_util_percent: 58.567685589519655\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045497220020732955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.19677280868659\n",
      "    mean_inference_ms: 2.852214827514299\n",
      "    mean_raw_obs_processing_ms: 3.6836611071626604\n",
      "  time_since_restore: 127603.89711499214\n",
      "  time_this_iter_s: 160.3183605670929\n",
      "  time_total_s: 127603.89711499214\n",
      "  timers:\n",
      "    learn_throughput: 936.801\n",
      "    learn_time_ms: 10670.36\n",
      "    load_throughput: 90509.323\n",
      "    load_time_ms: 110.442\n",
      "    sample_throughput: 68.088\n",
      "    sample_time_ms: 146810.373\n",
      "    update_time_ms: 12.555\n",
      "  timestamp: 1636422045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8056776\n",
      "  training_iteration: 806\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   806</td><td style=\"text-align: right;\">          127604</td><td style=\"text-align: right;\">8056776</td><td style=\"text-align: right;\"> 4.54218</td><td style=\"text-align: right;\">               18.18</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           91.0091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8066772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-43-13\n",
      "  done: false\n",
      "  episode_len_mean: 90.52727272727273\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.940000000000017\n",
      "  episode_reward_mean: 4.35409090909092\n",
      "  episode_reward_min: -1.6500000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 87429\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9888786440221673\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011701755832419199\n",
      "          policy_loss: -0.05764001670779071\n",
      "          total_loss: 0.11398042766934531\n",
      "          vf_explained_var: 0.9474801421165466\n",
      "          vf_loss: 0.16485116795087473\n",
      "    num_agent_steps_sampled: 8066772\n",
      "    num_agent_steps_trained: 8066772\n",
      "    num_steps_sampled: 8066772\n",
      "    num_steps_trained: 8066772\n",
      "  iterations_since_restore: 807\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.13507109004739\n",
      "    ram_util_percent: 58.574407582938385\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551987493943497\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.20218023759451\n",
      "    mean_inference_ms: 2.8523286695229264\n",
      "    mean_raw_obs_processing_ms: 3.6803722297309904\n",
      "  time_since_restore: 127752.29575943947\n",
      "  time_this_iter_s: 148.39864444732666\n",
      "  time_total_s: 127752.29575943947\n",
      "  timers:\n",
      "    learn_throughput: 936.842\n",
      "    learn_time_ms: 10669.885\n",
      "    load_throughput: 90562.246\n",
      "    load_time_ms: 110.377\n",
      "    sample_throughput: 68.671\n",
      "    sample_time_ms: 145564.618\n",
      "    update_time_ms: 12.145\n",
      "  timestamp: 1636422193\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8066772\n",
      "  training_iteration: 807\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   807</td><td style=\"text-align: right;\">          127752</td><td style=\"text-align: right;\">8066772</td><td style=\"text-align: right;\"> 4.35409</td><td style=\"text-align: right;\">               14.94</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           90.5273</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8076768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-45-59\n",
      "  done: false\n",
      "  episode_len_mean: 89.36607142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000016\n",
      "  episode_reward_mean: 4.629375000000009\n",
      "  episode_reward_min: -1.1000000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 87541\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0336488443562106\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012687737448624935\n",
      "          policy_loss: -0.056335755962973987\n",
      "          total_loss: 0.14350827496785384\n",
      "          vf_explained_var: 0.9464468359947205\n",
      "          vf_loss: 0.1912762668270331\n",
      "    num_agent_steps_sampled: 8076768\n",
      "    num_agent_steps_trained: 8076768\n",
      "    num_steps_sampled: 8076768\n",
      "    num_steps_trained: 8076768\n",
      "  iterations_since_restore: 808\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.71645569620252\n",
      "    ram_util_percent: 58.554430379746826\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045501471686163884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.20610839874161\n",
      "    mean_inference_ms: 2.852130028249846\n",
      "    mean_raw_obs_processing_ms: 3.679933223018869\n",
      "  time_since_restore: 127918.16865587234\n",
      "  time_this_iter_s: 165.8728964328766\n",
      "  time_total_s: 127918.16865587234\n",
      "  timers:\n",
      "    learn_throughput: 936.762\n",
      "    learn_time_ms: 10670.796\n",
      "    load_throughput: 90397.406\n",
      "    load_time_ms: 110.578\n",
      "    sample_throughput: 67.582\n",
      "    sample_time_ms: 147910.248\n",
      "    update_time_ms: 12.51\n",
      "  timestamp: 1636422359\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8076768\n",
      "  training_iteration: 808\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   808</td><td style=\"text-align: right;\">          127918</td><td style=\"text-align: right;\">8076768</td><td style=\"text-align: right;\"> 4.62938</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">                -1.1</td><td style=\"text-align: right;\">           89.3661</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8086764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-48-49\n",
      "  done: false\n",
      "  episode_len_mean: 90.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.570000000000016\n",
      "  episode_reward_mean: 4.547636363636373\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 87651\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0162664024238914\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012260150591946389\n",
      "          policy_loss: -0.05441039559455254\n",
      "          total_loss: 0.13767156993898635\n",
      "          vf_explained_var: 0.9256844520568848\n",
      "          vf_loss: 0.18431447219326455\n",
      "    num_agent_steps_sampled: 8086764\n",
      "    num_agent_steps_trained: 8086764\n",
      "    num_steps_sampled: 8086764\n",
      "    num_steps_trained: 8086764\n",
      "  iterations_since_restore: 809\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.38388429752067\n",
      "    ram_util_percent: 58.56611570247934\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455100084486804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.20750378259453\n",
      "    mean_inference_ms: 2.8521661607345528\n",
      "    mean_raw_obs_processing_ms: 3.6825857010664316\n",
      "  time_since_restore: 128088.05865979195\n",
      "  time_this_iter_s: 169.89000391960144\n",
      "  time_total_s: 128088.05865979195\n",
      "  timers:\n",
      "    learn_throughput: 936.242\n",
      "    learn_time_ms: 10676.725\n",
      "    load_throughput: 90396.12\n",
      "    load_time_ms: 110.58\n",
      "    sample_throughput: 67.012\n",
      "    sample_time_ms: 149168.121\n",
      "    update_time_ms: 12.905\n",
      "  timestamp: 1636422529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8086764\n",
      "  training_iteration: 809\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   809</td><td style=\"text-align: right;\">          128088</td><td style=\"text-align: right;\">8086764</td><td style=\"text-align: right;\"> 4.54764</td><td style=\"text-align: right;\">               12.57</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">              90.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8096760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-51-55\n",
      "  done: false\n",
      "  episode_len_mean: 87.929203539823\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.569999999999947\n",
      "  episode_reward_mean: 4.755752212389389\n",
      "  episode_reward_min: -1.540000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 87764\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.974078028731876\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01263400463403214\n",
      "          policy_loss: -0.05382683118884889\n",
      "          total_loss: 0.14369974146063766\n",
      "          vf_explained_var: 0.9367064237594604\n",
      "          vf_loss: 0.18848551051993656\n",
      "    num_agent_steps_sampled: 8096760\n",
      "    num_agent_steps_trained: 8096760\n",
      "    num_steps_sampled: 8096760\n",
      "    num_steps_trained: 8096760\n",
      "  iterations_since_restore: 810\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.35243445692883\n",
      "    ram_util_percent: 58.60337078651685\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549583132191658\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.20837605015351\n",
      "    mean_inference_ms: 2.8521802309149047\n",
      "    mean_raw_obs_processing_ms: 3.6842660074580595\n",
      "  time_since_restore: 128274.56971693039\n",
      "  time_this_iter_s: 186.511057138443\n",
      "  time_total_s: 128274.56971693039\n",
      "  timers:\n",
      "    learn_throughput: 936.568\n",
      "    learn_time_ms: 10673.011\n",
      "    load_throughput: 90501.919\n",
      "    load_time_ms: 110.451\n",
      "    sample_throughput: 66.411\n",
      "    sample_time_ms: 150516.812\n",
      "    update_time_ms: 12.574\n",
      "  timestamp: 1636422715\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8096760\n",
      "  training_iteration: 810\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   810</td><td style=\"text-align: right;\">          128275</td><td style=\"text-align: right;\">8096760</td><td style=\"text-align: right;\"> 4.75575</td><td style=\"text-align: right;\">               16.57</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           87.9292</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8106756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-54-24\n",
      "  done: false\n",
      "  episode_len_mean: 89.69642857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.890000000000013\n",
      "  episode_reward_mean: 4.145803571428582\n",
      "  episode_reward_min: -1.1500000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 87876\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9995857533226666\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011198987674995683\n",
      "          policy_loss: -0.05911794443511301\n",
      "          total_loss: 0.0923683694555846\n",
      "          vf_explained_var: 0.9528408050537109\n",
      "          vf_loss: 0.14596947607480817\n",
      "    num_agent_steps_sampled: 8106756\n",
      "    num_agent_steps_trained: 8106756\n",
      "    num_steps_sampled: 8106756\n",
      "    num_steps_trained: 8106756\n",
      "  iterations_since_restore: 811\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08349056603774\n",
      "    ram_util_percent: 58.641981132075465\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455026489663531\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.21312378402506\n",
      "    mean_inference_ms: 2.852075482338324\n",
      "    mean_raw_obs_processing_ms: 3.6819487793541428\n",
      "  time_since_restore: 128423.55834746361\n",
      "  time_this_iter_s: 148.98863053321838\n",
      "  time_total_s: 128423.55834746361\n",
      "  timers:\n",
      "    learn_throughput: 936.572\n",
      "    learn_time_ms: 10672.959\n",
      "    load_throughput: 90442.237\n",
      "    load_time_ms: 110.524\n",
      "    sample_throughput: 66.598\n",
      "    sample_time_ms: 150094.38\n",
      "    update_time_ms: 12.647\n",
      "  timestamp: 1636422864\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8106756\n",
      "  training_iteration: 811\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   811</td><td style=\"text-align: right;\">          128424</td><td style=\"text-align: right;\">8106756</td><td style=\"text-align: right;\">  4.1458</td><td style=\"text-align: right;\">               10.89</td><td style=\"text-align: right;\">               -1.15</td><td style=\"text-align: right;\">           89.6964</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8116752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-57-05\n",
      "  done: false\n",
      "  episode_len_mean: 89.22321428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.45999999999995\n",
      "  episode_reward_mean: 4.706607142857152\n",
      "  episode_reward_min: -1.5000000000000007\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 87988\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.998280931232322\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013417131639880257\n",
      "          policy_loss: -0.05403777039092448\n",
      "          total_loss: 0.1571687808371762\n",
      "          vf_explained_var: 0.9237889051437378\n",
      "          vf_loss: 0.20062345611966317\n",
      "    num_agent_steps_sampled: 8116752\n",
      "    num_agent_steps_trained: 8116752\n",
      "    num_steps_sampled: 8116752\n",
      "    num_steps_trained: 8116752\n",
      "  iterations_since_restore: 812\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.91260869565218\n",
      "    ram_util_percent: 58.58695652173914\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455131325495732\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.21722579483555\n",
      "    mean_inference_ms: 2.8520073232606102\n",
      "    mean_raw_obs_processing_ms: 3.6817678993026286\n",
      "  time_since_restore: 128584.59092020988\n",
      "  time_this_iter_s: 161.03257274627686\n",
      "  time_total_s: 128584.59092020988\n",
      "  timers:\n",
      "    learn_throughput: 936.277\n",
      "    learn_time_ms: 10676.33\n",
      "    load_throughput: 90725.077\n",
      "    load_time_ms: 110.179\n",
      "    sample_throughput: 66.72\n",
      "    sample_time_ms: 149819.927\n",
      "    update_time_ms: 13.017\n",
      "  timestamp: 1636423025\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8116752\n",
      "  training_iteration: 812\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   812</td><td style=\"text-align: right;\">          128585</td><td style=\"text-align: right;\">8116752</td><td style=\"text-align: right;\"> 4.70661</td><td style=\"text-align: right;\">               20.46</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           89.2232</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8126748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-00-07\n",
      "  done: false\n",
      "  episode_len_mean: 87.57894736842105\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.369999999999926\n",
      "  episode_reward_mean: 4.825526315789482\n",
      "  episode_reward_min: -1.6700000000000013\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 88102\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9866559831505148\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011654131318660802\n",
      "          policy_loss: -0.05582420982929886\n",
      "          total_loss: 0.12436513473542454\n",
      "          vf_explained_var: 0.9504060745239258\n",
      "          vf_loss: 0.17350633564508625\n",
      "    num_agent_steps_sampled: 8126748\n",
      "    num_agent_steps_trained: 8126748\n",
      "    num_steps_sampled: 8126748\n",
      "    num_steps_trained: 8126748\n",
      "  iterations_since_restore: 813\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.8248062015504\n",
      "    ram_util_percent: 58.542635658914726\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550458546766313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.22031780971756\n",
      "    mean_inference_ms: 2.8522854672178783\n",
      "    mean_raw_obs_processing_ms: 3.6798197854331915\n",
      "  time_since_restore: 128765.7331457138\n",
      "  time_this_iter_s: 181.1422255039215\n",
      "  time_total_s: 128765.7331457138\n",
      "  timers:\n",
      "    learn_throughput: 935.182\n",
      "    learn_time_ms: 10688.828\n",
      "    load_throughput: 90698.483\n",
      "    load_time_ms: 110.211\n",
      "    sample_throughput: 65.75\n",
      "    sample_time_ms: 152031.281\n",
      "    update_time_ms: 13.452\n",
      "  timestamp: 1636423207\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8126748\n",
      "  training_iteration: 813\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   813</td><td style=\"text-align: right;\">          128766</td><td style=\"text-align: right;\">8126748</td><td style=\"text-align: right;\"> 4.82553</td><td style=\"text-align: right;\">               18.37</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           87.5789</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8136744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-02-52\n",
      "  done: false\n",
      "  episode_len_mean: 86.66956521739131\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000012\n",
      "  episode_reward_mean: 3.9881739130434877\n",
      "  episode_reward_min: -1.4300000000000006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 88217\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0110391904146243\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010992602044271854\n",
      "          policy_loss: -0.05535362901595923\n",
      "          total_loss: 0.08267939726814118\n",
      "          vf_explained_var: 0.9471849799156189\n",
      "          vf_loss: 0.13310089494045982\n",
      "    num_agent_steps_sampled: 8136744\n",
      "    num_agent_steps_trained: 8136744\n",
      "    num_steps_sampled: 8136744\n",
      "    num_steps_trained: 8136744\n",
      "  iterations_since_restore: 814\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.14788135593221\n",
      "    ram_util_percent: 58.60466101694916\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045498774844194484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.22496079473109\n",
      "    mean_inference_ms: 2.8520783892946886\n",
      "    mean_raw_obs_processing_ms: 3.679782443382205\n",
      "  time_since_restore: 128930.59416365623\n",
      "  time_this_iter_s: 164.8610179424286\n",
      "  time_total_s: 128930.59416365623\n",
      "  timers:\n",
      "    learn_throughput: 934.786\n",
      "    learn_time_ms: 10693.355\n",
      "    load_throughput: 90621.224\n",
      "    load_time_ms: 110.305\n",
      "    sample_throughput: 64.957\n",
      "    sample_time_ms: 153885.596\n",
      "    update_time_ms: 12.894\n",
      "  timestamp: 1636423372\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8136744\n",
      "  training_iteration: 814\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   814</td><td style=\"text-align: right;\">          128931</td><td style=\"text-align: right;\">8136744</td><td style=\"text-align: right;\"> 3.98817</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           86.6696</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8146740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-05-22\n",
      "  done: false\n",
      "  episode_len_mean: 90.27027027027027\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.039999999999994\n",
      "  episode_reward_mean: 5.346756756756769\n",
      "  episode_reward_min: -1.5400000000000007\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 88328\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9669061289893257\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011958902861468947\n",
      "          policy_loss: -0.05622205276074063\n",
      "          total_loss: 0.0980270867005118\n",
      "          vf_explained_var: 0.958682656288147\n",
      "          vf_loss: 0.1466743245243262\n",
      "    num_agent_steps_sampled: 8146740\n",
      "    num_agent_steps_trained: 8146740\n",
      "    num_steps_sampled: 8146740\n",
      "    num_steps_trained: 8146740\n",
      "  iterations_since_restore: 815\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94018691588785\n",
      "    ram_util_percent: 58.647196261682225\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045483813248831655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.22909868419877\n",
      "    mean_inference_ms: 2.8522706921175045\n",
      "    mean_raw_obs_processing_ms: 3.6744641384679584\n",
      "  time_since_restore: 129080.69491147995\n",
      "  time_this_iter_s: 150.1007478237152\n",
      "  time_total_s: 129080.69491147995\n",
      "  timers:\n",
      "    learn_throughput: 934.999\n",
      "    learn_time_ms: 10690.926\n",
      "    load_throughput: 90696.678\n",
      "    load_time_ms: 110.214\n",
      "    sample_throughput: 65.382\n",
      "    sample_time_ms: 152885.209\n",
      "    update_time_ms: 11.505\n",
      "  timestamp: 1636423522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8146740\n",
      "  training_iteration: 815\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   815</td><td style=\"text-align: right;\">          129081</td><td style=\"text-align: right;\">8146740</td><td style=\"text-align: right;\"> 5.34676</td><td style=\"text-align: right;\">               15.04</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           90.2703</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8156736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-08-17\n",
      "  done: false\n",
      "  episode_len_mean: 88.46902654867256\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.550000000000013\n",
      "  episode_reward_mean: 4.457522123893815\n",
      "  episode_reward_min: -1.4000000000000008\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 88441\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.00633488414634\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012531476352206632\n",
      "          policy_loss: -0.05340250223620325\n",
      "          total_loss: 0.11610962242827329\n",
      "          vf_explained_var: 0.9483603835105896\n",
      "          vf_loss: 0.16102720193612652\n",
      "    num_agent_steps_sampled: 8156736\n",
      "    num_agent_steps_trained: 8156736\n",
      "    num_steps_sampled: 8156736\n",
      "    num_steps_trained: 8156736\n",
      "  iterations_since_restore: 816\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.1756\n",
      "    ram_util_percent: 58.6328\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04547878609451981\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.230801511167\n",
      "    mean_inference_ms: 2.852177771720442\n",
      "    mean_raw_obs_processing_ms: 3.6753096303246506\n",
      "  time_since_restore: 129256.08682918549\n",
      "  time_this_iter_s: 175.3919177055359\n",
      "  time_total_s: 129256.08682918549\n",
      "  timers:\n",
      "    learn_throughput: 934.865\n",
      "    learn_time_ms: 10692.45\n",
      "    load_throughput: 90699.916\n",
      "    load_time_ms: 110.21\n",
      "    sample_throughput: 64.745\n",
      "    sample_time_ms: 154390.994\n",
      "    update_time_ms: 11.673\n",
      "  timestamp: 1636423697\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8156736\n",
      "  training_iteration: 816\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   816</td><td style=\"text-align: right;\">          129256</td><td style=\"text-align: right;\">8156736</td><td style=\"text-align: right;\"> 4.45752</td><td style=\"text-align: right;\">               12.55</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">            88.469</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8166732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-11-13\n",
      "  done: false\n",
      "  episode_len_mean: 90.48648648648648\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.37999999999997\n",
      "  episode_reward_mean: 4.612612612612623\n",
      "  episode_reward_min: -1.0700000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 88552\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.024192133418515\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011168322929612413\n",
      "          policy_loss: -0.0591984401552532\n",
      "          total_loss: 0.09997132720951087\n",
      "          vf_explained_var: 0.9531886577606201\n",
      "          vf_loss: 0.15396885266925533\n",
      "    num_agent_steps_sampled: 8166732\n",
      "    num_agent_steps_trained: 8166732\n",
      "    num_steps_sampled: 8166732\n",
      "    num_steps_trained: 8166732\n",
      "  iterations_since_restore: 817\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.13705179282869\n",
      "    ram_util_percent: 58.53426294820717\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045527176827193316\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.23408008790558\n",
      "    mean_inference_ms: 2.852017145584723\n",
      "    mean_raw_obs_processing_ms: 3.6817843962059946\n",
      "  time_since_restore: 129431.58859920502\n",
      "  time_this_iter_s: 175.50177001953125\n",
      "  time_total_s: 129431.58859920502\n",
      "  timers:\n",
      "    learn_throughput: 934.582\n",
      "    learn_time_ms: 10695.694\n",
      "    load_throughput: 90597.921\n",
      "    load_time_ms: 110.334\n",
      "    sample_throughput: 63.629\n",
      "    sample_time_ms: 157098.086\n",
      "    update_time_ms: 11.561\n",
      "  timestamp: 1636423873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8166732\n",
      "  training_iteration: 817\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   817</td><td style=\"text-align: right;\">          129432</td><td style=\"text-align: right;\">8166732</td><td style=\"text-align: right;\"> 4.61261</td><td style=\"text-align: right;\">               16.38</td><td style=\"text-align: right;\">               -1.07</td><td style=\"text-align: right;\">           90.4865</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8176728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-13-52\n",
      "  done: false\n",
      "  episode_len_mean: 88.20353982300885\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.770000000000014\n",
      "  episode_reward_mean: 4.695132743362842\n",
      "  episode_reward_min: -1.3600000000000005\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 88665\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0053594335531577\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012288864708889749\n",
      "          policy_loss: -0.05573397155564565\n",
      "          total_loss: 0.10295007531172955\n",
      "          vf_explained_var: 0.9522085189819336\n",
      "          vf_loss: 0.15074206980534344\n",
      "    num_agent_steps_sampled: 8176728\n",
      "    num_agent_steps_trained: 8176728\n",
      "    num_steps_sampled: 8176728\n",
      "    num_steps_trained: 8176728\n",
      "  iterations_since_restore: 818\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.98546255506608\n",
      "    ram_util_percent: 58.59383259911894\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549928196281694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.23609860009069\n",
      "    mean_inference_ms: 2.852256862821503\n",
      "    mean_raw_obs_processing_ms: 3.6770692857806613\n",
      "  time_since_restore: 129590.69428062439\n",
      "  time_this_iter_s: 159.10568141937256\n",
      "  time_total_s: 129590.69428062439\n",
      "  timers:\n",
      "    learn_throughput: 934.597\n",
      "    learn_time_ms: 10695.519\n",
      "    load_throughput: 90504.361\n",
      "    load_time_ms: 110.448\n",
      "    sample_throughput: 63.904\n",
      "    sample_time_ms: 156421.068\n",
      "    update_time_ms: 12.02\n",
      "  timestamp: 1636424032\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8176728\n",
      "  training_iteration: 818\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   818</td><td style=\"text-align: right;\">          129591</td><td style=\"text-align: right;\">8176728</td><td style=\"text-align: right;\"> 4.69513</td><td style=\"text-align: right;\">               12.77</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           88.2035</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8186724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-16-41\n",
      "  done: false\n",
      "  episode_len_mean: 89.05405405405405\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.680000000000016\n",
      "  episode_reward_mean: 4.312072072072081\n",
      "  episode_reward_min: -2.14\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 88776\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.999515148717114\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011814228881269739\n",
      "          policy_loss: -0.05427690441919188\n",
      "          total_loss: 0.10189257453824592\n",
      "          vf_explained_var: 0.9493074417114258\n",
      "          vf_loss: 0.14925034020701025\n",
      "    num_agent_steps_sampled: 8186724\n",
      "    num_agent_steps_trained: 8186724\n",
      "    num_steps_sampled: 8186724\n",
      "    num_steps_trained: 8186724\n",
      "  iterations_since_restore: 819\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.60539419087138\n",
      "    ram_util_percent: 58.650207468879664\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045508291857469685\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.238260231769445\n",
      "    mean_inference_ms: 2.8523222669684034\n",
      "    mean_raw_obs_processing_ms: 3.6775277714043226\n",
      "  time_since_restore: 129759.49171996117\n",
      "  time_this_iter_s: 168.79743933677673\n",
      "  time_total_s: 129759.49171996117\n",
      "  timers:\n",
      "    learn_throughput: 934.345\n",
      "    learn_time_ms: 10698.403\n",
      "    load_throughput: 90521.81\n",
      "    load_time_ms: 110.426\n",
      "    sample_throughput: 63.95\n",
      "    sample_time_ms: 156310.118\n",
      "    update_time_ms: 10.766\n",
      "  timestamp: 1636424201\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8186724\n",
      "  training_iteration: 819\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   819</td><td style=\"text-align: right;\">          129759</td><td style=\"text-align: right;\">8186724</td><td style=\"text-align: right;\"> 4.31207</td><td style=\"text-align: right;\">               12.68</td><td style=\"text-align: right;\">               -2.14</td><td style=\"text-align: right;\">           89.0541</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8196720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-19-35\n",
      "  done: false\n",
      "  episode_len_mean: 89.17699115044248\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.13999999999993\n",
      "  episode_reward_mean: 4.93008849557523\n",
      "  episode_reward_min: -1.6200000000000012\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 88889\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0298830561148815\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012871605226314371\n",
      "          policy_loss: -0.05454446794067183\n",
      "          total_loss: 0.11793348643307884\n",
      "          vf_explained_var: 0.9539872407913208\n",
      "          vf_loss: 0.16345365786781677\n",
      "    num_agent_steps_sampled: 8196720\n",
      "    num_agent_steps_trained: 8196720\n",
      "    num_steps_sampled: 8196720\n",
      "    num_steps_trained: 8196720\n",
      "  iterations_since_restore: 820\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.84072580645162\n",
      "    ram_util_percent: 58.58951612903227\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548372313459005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.237606710509944\n",
      "    mean_inference_ms: 2.8522611710712265\n",
      "    mean_raw_obs_processing_ms: 3.6815321762181914\n",
      "  time_since_restore: 129933.78414487839\n",
      "  time_this_iter_s: 174.29242491722107\n",
      "  time_total_s: 129933.78414487839\n",
      "  timers:\n",
      "    learn_throughput: 934.426\n",
      "    learn_time_ms: 10697.481\n",
      "    load_throughput: 90305.29\n",
      "    load_time_ms: 110.691\n",
      "    sample_throughput: 64.453\n",
      "    sample_time_ms: 155088.809\n",
      "    update_time_ms: 10.929\n",
      "  timestamp: 1636424375\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8196720\n",
      "  training_iteration: 820\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   820</td><td style=\"text-align: right;\">          129934</td><td style=\"text-align: right;\">8196720</td><td style=\"text-align: right;\"> 4.93009</td><td style=\"text-align: right;\">               18.14</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">            89.177</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8206716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-22-14\n",
      "  done: false\n",
      "  episode_len_mean: 89.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.250000000000018\n",
      "  episode_reward_mean: 5.17544642857144\n",
      "  episode_reward_min: -1.4100000000000006\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 89001\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0032986124356587\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012909319454248355\n",
      "          policy_loss: -0.053570504661681305\n",
      "          total_loss: 0.1376221955132981\n",
      "          vf_explained_var: 0.9496254324913025\n",
      "          vf_loss: 0.18181664259929178\n",
      "    num_agent_steps_sampled: 8206716\n",
      "    num_agent_steps_trained: 8206716\n",
      "    num_steps_sampled: 8206716\n",
      "    num_steps_trained: 8206716\n",
      "  iterations_since_restore: 821\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.70308370044052\n",
      "    ram_util_percent: 58.63127753303964\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04552127253853474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.24197931043821\n",
      "    mean_inference_ms: 2.8521156564993317\n",
      "    mean_raw_obs_processing_ms: 3.6827095347022967\n",
      "  time_since_restore: 130092.72215151787\n",
      "  time_this_iter_s: 158.9380066394806\n",
      "  time_total_s: 130092.72215151787\n",
      "  timers:\n",
      "    learn_throughput: 934.423\n",
      "    learn_time_ms: 10697.512\n",
      "    load_throughput: 90502.798\n",
      "    load_time_ms: 110.45\n",
      "    sample_throughput: 64.043\n",
      "    sample_time_ms: 156083.698\n",
      "    update_time_ms: 10.807\n",
      "  timestamp: 1636424534\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8206716\n",
      "  training_iteration: 821\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   821</td><td style=\"text-align: right;\">          130093</td><td style=\"text-align: right;\">8206716</td><td style=\"text-align: right;\"> 5.17545</td><td style=\"text-align: right;\">               12.25</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">              89.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8216712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-24-45\n",
      "  done: false\n",
      "  episode_len_mean: 87.46491228070175\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.930000000000012\n",
      "  episode_reward_mean: 4.801754385964921\n",
      "  episode_reward_min: -1.950000000000001\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 89115\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.9972474429342482\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011784482897517193\n",
      "          policy_loss: -0.05647795741470196\n",
      "          total_loss: 0.11393331580468986\n",
      "          vf_explained_var: 0.9528455138206482\n",
      "          vf_loss: 0.16353722207853172\n",
      "    num_agent_steps_sampled: 8216712\n",
      "    num_agent_steps_trained: 8216712\n",
      "    num_steps_sampled: 8216712\n",
      "    num_steps_trained: 8216712\n",
      "  iterations_since_restore: 822\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.26388888888889\n",
      "    ram_util_percent: 58.55972222222222\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045480128778864023\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.244989790888184\n",
      "    mean_inference_ms: 2.852082945299182\n",
      "    mean_raw_obs_processing_ms: 3.678075665852426\n",
      "  time_since_restore: 130244.034709692\n",
      "  time_this_iter_s: 151.3125581741333\n",
      "  time_total_s: 130244.034709692\n",
      "  timers:\n",
      "    learn_throughput: 934.451\n",
      "    learn_time_ms: 10697.192\n",
      "    load_throughput: 90580.658\n",
      "    load_time_ms: 110.355\n",
      "    sample_throughput: 64.443\n",
      "    sample_time_ms: 155113.019\n",
      "    update_time_ms: 10.116\n",
      "  timestamp: 1636424685\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8216712\n",
      "  training_iteration: 822\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   822</td><td style=\"text-align: right;\">          130244</td><td style=\"text-align: right;\">8216712</td><td style=\"text-align: right;\"> 4.80175</td><td style=\"text-align: right;\">               12.93</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           87.4649</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8226708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-27-54\n",
      "  done: false\n",
      "  episode_len_mean: 88.20353982300885\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.750000000000018\n",
      "  episode_reward_mean: 4.563185840707974\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 89228\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0059926002453534\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012204271602577565\n",
      "          policy_loss: -0.054213522393734025\n",
      "          total_loss: 0.12198969945470747\n",
      "          vf_explained_var: 0.949812114238739\n",
      "          vf_loss: 0.16846029217012673\n",
      "    num_agent_steps_sampled: 8226708\n",
      "    num_agent_steps_trained: 8226708\n",
      "    num_steps_sampled: 8226708\n",
      "    num_steps_trained: 8226708\n",
      "  iterations_since_restore: 823\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.4353159851301\n",
      "    ram_util_percent: 58.643494423791815\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045518092527613636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.248576793312985\n",
      "    mean_inference_ms: 2.852271043383229\n",
      "    mean_raw_obs_processing_ms: 3.6807279977383063\n",
      "  time_since_restore: 130432.30487346649\n",
      "  time_this_iter_s: 188.27016377449036\n",
      "  time_total_s: 130432.30487346649\n",
      "  timers:\n",
      "    learn_throughput: 935.147\n",
      "    learn_time_ms: 10689.231\n",
      "    load_throughput: 90617.033\n",
      "    load_time_ms: 110.31\n",
      "    sample_throughput: 64.145\n",
      "    sample_time_ms: 155834.928\n",
      "    update_time_ms: 9.392\n",
      "  timestamp: 1636424874\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8226708\n",
      "  training_iteration: 823\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   823</td><td style=\"text-align: right;\">          130432</td><td style=\"text-align: right;\">8226708</td><td style=\"text-align: right;\"> 4.56319</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           88.2035</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8236704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-30-44\n",
      "  done: false\n",
      "  episode_len_mean: 88.56637168141593\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.900000000000016\n",
      "  episode_reward_mean: 4.361592920353992\n",
      "  episode_reward_min: -1.320000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 89341\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.033000546133416\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011487110772446634\n",
      "          policy_loss: -0.05708630595308466\n",
      "          total_loss: 0.09646931735830556\n",
      "          vf_explained_var: 0.9513277411460876\n",
      "          vf_loss: 0.1477165522149358\n",
      "    num_agent_steps_sampled: 8236704\n",
      "    num_agent_steps_trained: 8236704\n",
      "    num_steps_sampled: 8236704\n",
      "    num_steps_trained: 8236704\n",
      "  iterations_since_restore: 824\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.01859504132231\n",
      "    ram_util_percent: 58.684297520661154\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0454988266760031\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.24883088436801\n",
      "    mean_inference_ms: 2.8521855233013422\n",
      "    mean_raw_obs_processing_ms: 3.6812187533050706\n",
      "  time_since_restore: 130602.30242037773\n",
      "  time_this_iter_s: 169.99754691123962\n",
      "  time_total_s: 130602.30242037773\n",
      "  timers:\n",
      "    learn_throughput: 934.582\n",
      "    learn_time_ms: 10695.685\n",
      "    load_throughput: 89713.97\n",
      "    load_time_ms: 111.421\n",
      "    sample_throughput: 63.937\n",
      "    sample_time_ms: 156341.634\n",
      "    update_time_ms: 8.749\n",
      "  timestamp: 1636425044\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8236704\n",
      "  training_iteration: 824\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   824</td><td style=\"text-align: right;\">          130602</td><td style=\"text-align: right;\">8236704</td><td style=\"text-align: right;\"> 4.36159</td><td style=\"text-align: right;\">                12.9</td><td style=\"text-align: right;\">               -1.32</td><td style=\"text-align: right;\">           88.5664</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8246700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-33-11\n",
      "  done: false\n",
      "  episode_len_mean: 89.35398230088495\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000014\n",
      "  episode_reward_mean: 4.408053097345142\n",
      "  episode_reward_min: -1.1700000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 89454\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0192937332340795\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011551227777265805\n",
      "          policy_loss: -0.058705697972805074\n",
      "          total_loss: 0.08852769394015145\n",
      "          vf_explained_var: 0.9419835209846497\n",
      "          vf_loss: 0.1411111870302986\n",
      "    num_agent_steps_sampled: 8246700\n",
      "    num_agent_steps_trained: 8246700\n",
      "    num_steps_sampled: 8246700\n",
      "    num_steps_trained: 8246700\n",
      "  iterations_since_restore: 825\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28904761904762\n",
      "    ram_util_percent: 58.621428571428574\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551201087172363\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.2534027054743\n",
      "    mean_inference_ms: 2.852161570168716\n",
      "    mean_raw_obs_processing_ms: 3.6788511587722708\n",
      "  time_since_restore: 130749.53842616081\n",
      "  time_this_iter_s: 147.23600578308105\n",
      "  time_total_s: 130749.53842616081\n",
      "  timers:\n",
      "    learn_throughput: 935.026\n",
      "    learn_time_ms: 10690.611\n",
      "    load_throughput: 89780.748\n",
      "    load_time_ms: 111.338\n",
      "    sample_throughput: 64.052\n",
      "    sample_time_ms: 156059.485\n",
      "    update_time_ms: 9.629\n",
      "  timestamp: 1636425191\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8246700\n",
      "  training_iteration: 825\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   825</td><td style=\"text-align: right;\">          130750</td><td style=\"text-align: right;\">8246700</td><td style=\"text-align: right;\"> 4.40805</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">               -1.17</td><td style=\"text-align: right;\">            89.354</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8256696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-35-53\n",
      "  done: false\n",
      "  episode_len_mean: 88.66964285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.14999999999993\n",
      "  episode_reward_mean: 4.69455357142858\n",
      "  episode_reward_min: -1.3400000000000003\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 89566\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0339315420542006\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01241780740456788\n",
      "          policy_loss: -0.055576244708246146\n",
      "          total_loss: 0.13499543519021992\n",
      "          vf_explained_var: 0.9432545304298401\n",
      "          vf_loss: 0.18262167585551994\n",
      "    num_agent_steps_sampled: 8256696\n",
      "    num_agent_steps_trained: 8256696\n",
      "    num_steps_sampled: 8256696\n",
      "    num_steps_trained: 8256696\n",
      "  iterations_since_restore: 826\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.30991379310345\n",
      "    ram_util_percent: 58.648275862068964\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549290764177969\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.25469138387665\n",
      "    mean_inference_ms: 2.8519260913773685\n",
      "    mean_raw_obs_processing_ms: 3.680532330751177\n",
      "  time_since_restore: 130911.79486012459\n",
      "  time_this_iter_s: 162.25643396377563\n",
      "  time_total_s: 130911.79486012459\n",
      "  timers:\n",
      "    learn_throughput: 935.386\n",
      "    learn_time_ms: 10686.502\n",
      "    load_throughput: 90320.698\n",
      "    load_time_ms: 110.672\n",
      "    sample_throughput: 64.594\n",
      "    sample_time_ms: 154750.822\n",
      "    update_time_ms: 9.574\n",
      "  timestamp: 1636425353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8256696\n",
      "  training_iteration: 826\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   826</td><td style=\"text-align: right;\">          130912</td><td style=\"text-align: right;\">8256696</td><td style=\"text-align: right;\"> 4.69455</td><td style=\"text-align: right;\">               18.15</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           88.6696</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8266692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-38-37\n",
      "  done: false\n",
      "  episode_len_mean: 86.99130434782609\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000014\n",
      "  episode_reward_mean: 4.499304347826096\n",
      "  episode_reward_min: -1.1700000000000008\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 89681\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.022734294182215\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01157495658835197\n",
      "          policy_loss: -0.0574080794556146\n",
      "          total_loss: 0.0914863152596622\n",
      "          vf_explained_var: 0.9453955292701721\n",
      "          vf_loss: 0.14275253960846837\n",
      "    num_agent_steps_sampled: 8266692\n",
      "    num_agent_steps_trained: 8266692\n",
      "    num_steps_sampled: 8266692\n",
      "    num_steps_trained: 8266692\n",
      "  iterations_since_restore: 827\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.33333333333333\n",
      "    ram_util_percent: 58.58418803418804\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045507159502721314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.25926789326308\n",
      "    mean_inference_ms: 2.8522015406449044\n",
      "    mean_raw_obs_processing_ms: 3.679340673978033\n",
      "  time_since_restore: 131075.9431977272\n",
      "  time_this_iter_s: 164.14833760261536\n",
      "  time_total_s: 131075.9431977272\n",
      "  timers:\n",
      "    learn_throughput: 935.618\n",
      "    learn_time_ms: 10683.843\n",
      "    load_throughput: 90532.366\n",
      "    load_time_ms: 110.414\n",
      "    sample_throughput: 65.07\n",
      "    sample_time_ms: 153618.178\n",
      "    update_time_ms: 9.738\n",
      "  timestamp: 1636425517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8266692\n",
      "  training_iteration: 827\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   827</td><td style=\"text-align: right;\">          131076</td><td style=\"text-align: right;\">8266692</td><td style=\"text-align: right;\">  4.4993</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -1.17</td><td style=\"text-align: right;\">           86.9913</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8276688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-41-15\n",
      "  done: false\n",
      "  episode_len_mean: 89.83783783783784\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.300000000000017\n",
      "  episode_reward_mean: 4.718468468468479\n",
      "  episode_reward_min: -0.3999999999999999\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 89792\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0217610138094324\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012418595053688494\n",
      "          policy_loss: -0.0596304470876184\n",
      "          total_loss: 0.12068885410857251\n",
      "          vf_explained_var: 0.9460579752922058\n",
      "          vf_loss: 0.17224579890871533\n",
      "    num_agent_steps_sampled: 8276688\n",
      "    num_agent_steps_trained: 8276688\n",
      "    num_steps_sampled: 8276688\n",
      "    num_steps_trained: 8276688\n",
      "  iterations_since_restore: 828\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.82977777777776\n",
      "    ram_util_percent: 58.72133333333333\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045520452358175326\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.262462126814825\n",
      "    mean_inference_ms: 2.8522070960895882\n",
      "    mean_raw_obs_processing_ms: 3.678550099502338\n",
      "  time_since_restore: 131233.78555560112\n",
      "  time_this_iter_s: 157.84235787391663\n",
      "  time_total_s: 131233.78555560112\n",
      "  timers:\n",
      "    learn_throughput: 935.632\n",
      "    learn_time_ms: 10683.689\n",
      "    load_throughput: 90460.639\n",
      "    load_time_ms: 110.501\n",
      "    sample_throughput: 65.124\n",
      "    sample_time_ms: 153492.261\n",
      "    update_time_ms: 9.367\n",
      "  timestamp: 1636425675\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8276688\n",
      "  training_iteration: 828\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   828</td><td style=\"text-align: right;\">          131234</td><td style=\"text-align: right;\">8276688</td><td style=\"text-align: right;\"> 4.71847</td><td style=\"text-align: right;\">                12.3</td><td style=\"text-align: right;\">                -0.4</td><td style=\"text-align: right;\">           89.8378</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8286684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-43-55\n",
      "  done: false\n",
      "  episode_len_mean: 90.60909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.46999999999997\n",
      "  episode_reward_mean: 5.06500000000001\n",
      "  episode_reward_min: -1.5800000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 89902\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.003424648443858\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012837637695826463\n",
      "          policy_loss: -0.05350117004778968\n",
      "          total_loss: 0.13702848939041998\n",
      "          vf_explained_var: 0.9426419734954834\n",
      "          vf_loss: 0.18131816193429579\n",
      "    num_agent_steps_sampled: 8286684\n",
      "    num_agent_steps_trained: 8286684\n",
      "    num_steps_sampled: 8286684\n",
      "    num_steps_trained: 8286684\n",
      "  iterations_since_restore: 829\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.7280701754386\n",
      "    ram_util_percent: 58.72368421052632\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549033061585571\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.264022773476476\n",
      "    mean_inference_ms: 2.8520992126555575\n",
      "    mean_raw_obs_processing_ms: 3.6769842621603597\n",
      "  time_since_restore: 131393.49455332756\n",
      "  time_this_iter_s: 159.70899772644043\n",
      "  time_total_s: 131393.49455332756\n",
      "  timers:\n",
      "    learn_throughput: 936.314\n",
      "    learn_time_ms: 10675.905\n",
      "    load_throughput: 90327.645\n",
      "    load_time_ms: 110.664\n",
      "    sample_throughput: 65.509\n",
      "    sample_time_ms: 152589.776\n",
      "    update_time_ms: 10.32\n",
      "  timestamp: 1636425835\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8286684\n",
      "  training_iteration: 829\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   829</td><td style=\"text-align: right;\">          131393</td><td style=\"text-align: right;\">8286684</td><td style=\"text-align: right;\">   5.065</td><td style=\"text-align: right;\">               18.47</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           90.6091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8296680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-46-47\n",
      "  done: false\n",
      "  episode_len_mean: 90.69369369369369\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.54000000000001\n",
      "  episode_reward_mean: 4.751261261261271\n",
      "  episode_reward_min: -1.6700000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 90013\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.03239900556385\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011328914738309099\n",
      "          policy_loss: -0.05779286799315586\n",
      "          total_loss: 0.09977422639504711\n",
      "          vf_explained_var: 0.9522592425346375\n",
      "          vf_loss: 0.15208239803074772\n",
      "    num_agent_steps_sampled: 8296680\n",
      "    num_agent_steps_trained: 8296680\n",
      "    num_steps_sampled: 8296680\n",
      "    num_steps_trained: 8296680\n",
      "  iterations_since_restore: 830\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.33333333333333\n",
      "    ram_util_percent: 58.660162601626006\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045514267610365956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.267395390914\n",
      "    mean_inference_ms: 2.852117230689528\n",
      "    mean_raw_obs_processing_ms: 3.6786628638756436\n",
      "  time_since_restore: 131565.89974713326\n",
      "  time_this_iter_s: 172.40519380569458\n",
      "  time_total_s: 131565.89974713326\n",
      "  timers:\n",
      "    learn_throughput: 935.868\n",
      "    learn_time_ms: 10680.99\n",
      "    load_throughput: 90305.64\n",
      "    load_time_ms: 110.691\n",
      "    sample_throughput: 65.592\n",
      "    sample_time_ms: 152395.479\n",
      "    update_time_ms: 10.69\n",
      "  timestamp: 1636426007\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8296680\n",
      "  training_iteration: 830\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   830</td><td style=\"text-align: right;\">          131566</td><td style=\"text-align: right;\">8296680</td><td style=\"text-align: right;\"> 4.75126</td><td style=\"text-align: right;\">               16.54</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           90.6937</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8306676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-49-11\n",
      "  done: false\n",
      "  episode_len_mean: 91.69724770642202\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.139999999999954\n",
      "  episode_reward_mean: 4.733211009174321\n",
      "  episode_reward_min: -1.6400000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 90122\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0361287150627527\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012663154595238363\n",
      "          policy_loss: -0.056102007796239646\n",
      "          total_loss: 0.12427753371974597\n",
      "          vf_explained_var: 0.9432310461997986\n",
      "          vf_loss: 0.17189257805609806\n",
      "    num_agent_steps_sampled: 8306676\n",
      "    num_agent_steps_trained: 8306676\n",
      "    num_steps_sampled: 8306676\n",
      "    num_steps_trained: 8306676\n",
      "  iterations_since_restore: 831\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.25268292682925\n",
      "    ram_util_percent: 58.590243902439006\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548938983925219\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.26895632158654\n",
      "    mean_inference_ms: 2.8522527059908054\n",
      "    mean_raw_obs_processing_ms: 3.6733866094677885\n",
      "  time_since_restore: 131709.69268727303\n",
      "  time_this_iter_s: 143.7929401397705\n",
      "  time_total_s: 131709.69268727303\n",
      "  timers:\n",
      "    learn_throughput: 935.705\n",
      "    learn_time_ms: 10682.858\n",
      "    load_throughput: 90261.236\n",
      "    load_time_ms: 110.745\n",
      "    sample_throughput: 66.252\n",
      "    sample_time_ms: 150878.23\n",
      "    update_time_ms: 11.674\n",
      "  timestamp: 1636426151\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8306676\n",
      "  training_iteration: 831\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   831</td><td style=\"text-align: right;\">          131710</td><td style=\"text-align: right;\">8306676</td><td style=\"text-align: right;\"> 4.73321</td><td style=\"text-align: right;\">               16.14</td><td style=\"text-align: right;\">               -1.64</td><td style=\"text-align: right;\">           91.6972</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8316672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-51-52\n",
      "  done: false\n",
      "  episode_len_mean: 89.26785714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.250000000000007\n",
      "  episode_reward_mean: 4.338660714285724\n",
      "  episode_reward_min: -1.2600000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 90234\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.03472487580063\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011573274137000183\n",
      "          policy_loss: -0.05551482806953355\n",
      "          total_loss: 0.10164254566129201\n",
      "          vf_explained_var: 0.9408558011054993\n",
      "          vf_loss: 0.15113925820487178\n",
      "    num_agent_steps_sampled: 8316672\n",
      "    num_agent_steps_trained: 8316672\n",
      "    num_steps_sampled: 8316672\n",
      "    num_steps_trained: 8316672\n",
      "  iterations_since_restore: 832\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.96521739130435\n",
      "    ram_util_percent: 58.55\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04549092331548864\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.27213053403694\n",
      "    mean_inference_ms: 2.852252764260269\n",
      "    mean_raw_obs_processing_ms: 3.6720836817592177\n",
      "  time_since_restore: 131870.50739240646\n",
      "  time_this_iter_s: 160.8147051334381\n",
      "  time_total_s: 131870.50739240646\n",
      "  timers:\n",
      "    learn_throughput: 935.339\n",
      "    learn_time_ms: 10687.036\n",
      "    load_throughput: 90089.203\n",
      "    load_time_ms: 110.957\n",
      "    sample_throughput: 65.839\n",
      "    sample_time_ms: 151823.774\n",
      "    update_time_ms: 12.006\n",
      "  timestamp: 1636426312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8316672\n",
      "  training_iteration: 832\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   832</td><td style=\"text-align: right;\">          131871</td><td style=\"text-align: right;\">8316672</td><td style=\"text-align: right;\"> 4.33866</td><td style=\"text-align: right;\">               16.25</td><td style=\"text-align: right;\">               -1.26</td><td style=\"text-align: right;\">           89.2679</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8326668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-54-46\n",
      "  done: false\n",
      "  episode_len_mean: 88.83928571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.540000000000015\n",
      "  episode_reward_mean: 4.3713392857142965\n",
      "  episode_reward_min: -0.9000000000000002\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 90346\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0186942047542997\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011883352749364234\n",
      "          policy_loss: -0.05697083067960846\n",
      "          total_loss: 0.10043637668713927\n",
      "          vf_explained_var: 0.9506039023399353\n",
      "          vf_loss: 0.15052238470500606\n",
      "    num_agent_steps_sampled: 8326668\n",
      "    num_agent_steps_trained: 8326668\n",
      "    num_steps_sampled: 8326668\n",
      "    num_steps_trained: 8326668\n",
      "  iterations_since_restore: 833\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.8741935483871\n",
      "    ram_util_percent: 58.58790322580645\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04551998114671822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.27569097275503\n",
      "    mean_inference_ms: 2.852426538887707\n",
      "    mean_raw_obs_processing_ms: 3.6720896909433867\n",
      "  time_since_restore: 132044.23049664497\n",
      "  time_this_iter_s: 173.72310423851013\n",
      "  time_total_s: 132044.23049664497\n",
      "  timers:\n",
      "    learn_throughput: 935.077\n",
      "    learn_time_ms: 10690.026\n",
      "    load_throughput: 90147.411\n",
      "    load_time_ms: 110.885\n",
      "    sample_throughput: 66.478\n",
      "    sample_time_ms: 150365.467\n",
      "    update_time_ms: 12.65\n",
      "  timestamp: 1636426486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8326668\n",
      "  training_iteration: 833\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   833</td><td style=\"text-align: right;\">          132044</td><td style=\"text-align: right;\">8326668</td><td style=\"text-align: right;\"> 4.37134</td><td style=\"text-align: right;\">               12.54</td><td style=\"text-align: right;\">                -0.9</td><td style=\"text-align: right;\">           88.8393</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8336664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-57-45\n",
      "  done: false\n",
      "  episode_len_mean: 88.47787610619469\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.730000000000008\n",
      "  episode_reward_mean: 4.751327433628328\n",
      "  episode_reward_min: -0.2600000000000009\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 90459\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.032829807049189\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012237973376792492\n",
      "          policy_loss: -0.05616273751211727\n",
      "          total_loss: 0.10196639432723069\n",
      "          vf_explained_var: 0.9560261964797974\n",
      "          vf_loss: 0.15057779578651245\n",
      "    num_agent_steps_sampled: 8336664\n",
      "    num_agent_steps_trained: 8336664\n",
      "    num_steps_sampled: 8336664\n",
      "    num_steps_trained: 8336664\n",
      "  iterations_since_restore: 834\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.9964705882353\n",
      "    ram_util_percent: 58.69764705882353\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550628239345091\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.27852934918092\n",
      "    mean_inference_ms: 2.8520951672658694\n",
      "    mean_raw_obs_processing_ms: 3.677387992047724\n",
      "  time_since_restore: 132223.11515688896\n",
      "  time_this_iter_s: 178.88466024398804\n",
      "  time_total_s: 132223.11515688896\n",
      "  timers:\n",
      "    learn_throughput: 932.679\n",
      "    learn_time_ms: 10717.519\n",
      "    load_throughput: 91586.352\n",
      "    load_time_ms: 109.143\n",
      "    sample_throughput: 66.099\n",
      "    sample_time_ms: 151227.616\n",
      "    update_time_ms: 13.376\n",
      "  timestamp: 1636426665\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8336664\n",
      "  training_iteration: 834\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   834</td><td style=\"text-align: right;\">          132223</td><td style=\"text-align: right;\">8336664</td><td style=\"text-align: right;\"> 4.75133</td><td style=\"text-align: right;\">               16.73</td><td style=\"text-align: right;\">               -0.26</td><td style=\"text-align: right;\">           88.4779</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558906)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8346660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-00-45\n",
      "  done: false\n",
      "  episode_len_mean: 86.19827586206897\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.409999999999982\n",
      "  episode_reward_mean: 5.510689655172422\n",
      "  episode_reward_min: -1.4800000000000004\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 90575\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 1.991789450502803\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012586459669780201\n",
      "          policy_loss: -0.052989495219264784\n",
      "          total_loss: 0.14960848445980213\n",
      "          vf_explained_var: 0.9528253674507141\n",
      "          vf_loss: 0.19384234425349114\n",
      "    num_agent_steps_sampled: 8346660\n",
      "    num_agent_steps_trained: 8346660\n",
      "    num_steps_sampled: 8346660\n",
      "    num_steps_trained: 8346660\n",
      "  iterations_since_restore: 835\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.67656249999999\n",
      "    ram_util_percent: 58.80390625000001\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04550556790730048\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28196394209813\n",
      "    mean_inference_ms: 2.8521018169298027\n",
      "    mean_raw_obs_processing_ms: 3.68025066474557\n",
      "  time_since_restore: 132402.80874156952\n",
      "  time_this_iter_s: 179.69358468055725\n",
      "  time_total_s: 132402.80874156952\n",
      "  timers:\n",
      "    learn_throughput: 931.638\n",
      "    learn_time_ms: 10729.492\n",
      "    load_throughput: 91675.989\n",
      "    load_time_ms: 109.036\n",
      "    sample_throughput: 64.715\n",
      "    sample_time_ms: 154461.427\n",
      "    update_time_ms: 13.764\n",
      "  timestamp: 1636426845\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8346660\n",
      "  training_iteration: 835\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   835</td><td style=\"text-align: right;\">          132403</td><td style=\"text-align: right;\">8346660</td><td style=\"text-align: right;\"> 5.51069</td><td style=\"text-align: right;\">               16.41</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           86.1983</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_da758_00000:\n",
      "  agent_timesteps_total: 8356656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-03-31\n",
      "  done: false\n",
      "  episode_len_mean: 89.77477477477477\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.700000000000015\n",
      "  episode_reward_mean: 4.728738738738749\n",
      "  episode_reward_min: -1.5900000000000005\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 90686\n",
      "  experiment_id: 80d9cec4f47b40b6adb7244052f82fbe\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.0134148326694454\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012314572681975198\n",
      "          policy_loss: -0.05799217506622275\n",
      "          total_loss: 0.11674719932608497\n",
      "          vf_explained_var: 0.9464603662490845\n",
      "          vf_loss: 0.16681938608391927\n",
      "    num_agent_steps_sampled: 8356656\n",
      "    num_agent_steps_trained: 8356656\n",
      "    num_steps_sampled: 8356656\n",
      "    num_steps_trained: 8356656\n",
      "  iterations_since_restore: 836\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.5181434599156\n",
      "    ram_util_percent: 58.8227848101266\n",
      "  pid: 558908\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045491569872967805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28577552986289\n",
      "    mean_inference_ms: 2.852362121763343\n",
      "    mean_raw_obs_processing_ms: 3.6760227041089526\n",
      "  time_since_restore: 132568.87294769287\n",
      "  time_this_iter_s: 166.06420612335205\n",
      "  time_total_s: 132568.87294769287\n",
      "  timers:\n",
      "    learn_throughput: 930.439\n",
      "    learn_time_ms: 10743.321\n",
      "    load_throughput: 91323.381\n",
      "    load_time_ms: 109.457\n",
      "    sample_throughput: 64.562\n",
      "    sample_time_ms: 154828.454\n",
      "    update_time_ms: 13.404\n",
      "  timestamp: 1636427011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8356656\n",
      "  training_iteration: 836\n",
      "  trial_id: da758_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.28 GiB heap, 0.0/10.64 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks/PPO_2021-11-07_14-13-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_da758_00000</td><td>RUNNING </td><td>192.168.3.5:558908</td><td style=\"text-align: right;\">   836</td><td style=\"text-align: right;\">          132569</td><td style=\"text-align: right;\">8356656</td><td style=\"text-align: right;\"> 4.72874</td><td style=\"text-align: right;\">                12.7</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           89.7748</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=558907)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 256,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 5_000,\n",
    "             \"lr\": 1e-4,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO All Tasks 2 \n",
    "                      \n",
    "                      \n",
    "                      pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/all_tasks\",\n",
    "        keep_checkpoints_num=50,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
