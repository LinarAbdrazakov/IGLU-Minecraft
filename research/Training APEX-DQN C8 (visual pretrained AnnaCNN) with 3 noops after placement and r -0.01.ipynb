{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import dqn\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4, padding=0),  \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(64, 512, kernel_size=2, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        features_dim = 512\n",
    "        self.encoder = VisualEncoder()\n",
    "        self.encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AnnaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.qvalue_head = nn.Linear(features_dim, num_outputs)\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.encoder.cuda()\n",
    "            self.qvalue_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        if self.use_cuda:\n",
    "            obs.cuda()\n",
    "            \n",
    "        features = self.encoder(obs)\n",
    "        qvalues = self.qvalue_head(features)\n",
    "        return qvalues, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=500)\n",
    "    env.update_taskset(TaskSet(preset=['C8']))\n",
    "    env = PovOnlyWrapper(env)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.dqn import ApexTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-10-20 08:49:14,970\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-10-20 08:49:14,983\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id ae4f4_00000 but id 9a6b4_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">APEX C8 pretrained (AnnaCNN) r: -0.01</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/9a6b4_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/9a6b4_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211020_084915-9a6b4_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m 2021-10-20 08:49:18,485\tINFO dqn.py:188 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m 2021-10-20 08:49:18,485\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m 2021-10-20 08:49:25,129\tWARNING deprecation.py:39 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=166)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=166)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m 2021-10-20 08:49:28,695\tINFO trainable.py:109 -- Trainable.setup took 12.727 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=162)\u001b[0m 2021-10-20 08:49:28,695\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=164)\u001b[0m 2021-10-20 08:50:25,038\tINFO replay_buffer.py:46 -- Estimated max memory usage for replay buffer is 1.53925 GB (62500.0 batches of size 1, 24628 bytes each), available system memory is 50.46360064 GB\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m 2021-10-20 08:50:25,270\tINFO replay_buffer.py:46 -- Estimated max memory usage for replay buffer is 1.5390625 GB (62500.0 batches of size 1, 24625 bytes each), available system memory is 50.46360064 GB\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m 2021-10-20 08:50:25,528\tINFO replay_buffer.py:46 -- Estimated max memory usage for replay buffer is 1.5390625 GB (62500.0 batches of size 1, 24625 bytes each), available system memory is 50.46360064 GB\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m 2021-10-20 08:50:25,753\tINFO replay_buffer.py:46 -- Estimated max memory usage for replay buffer is 1.5390625 GB (62500.0 batches of size 1, 24625 bytes each), available system memory is 50.46360064 GB\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2021-10-20 08:57:36,407\tWARNING logger.py:654 -- You are trying to log an invalid value (ray/tune/info/exploration_infos=[{'cur_epsilon': 0.0, 'last_timestep': 0}, {'cur_epsilon': 0.4, 'last_timestep': 24655}, {'cur_epsilon': 0.0006553600000000003, 'last_timestep': 24967}]) via TBXLoggerCallback!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 25000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_08-57-36\n",
      "  done: false\n",
      "  episode_len_mean: 194.7741935483871\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.09000000000000141\n",
      "  episode_reward_mean: -1.9091935483870903\n",
      "  episode_reward_min: -4.999999999999938\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 62\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 24655\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 24967\n",
      "    last_target_update_ts: 6096000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.7736769914627075\n",
      "        max_q: 23.064054489135742\n",
      "        mean_q: 7.344659328460693\n",
      "        min_q: 3.002164840698242\n",
      "    learner_queue:\n",
      "      size_count: 6108\n",
      "      size_mean: 14.9\n",
      "      size_quantiles:\n",
      "      - 6.0\n",
      "      - 10.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 2.5475478405713994\n",
      "    num_agent_steps_sampled: 25000\n",
      "    num_steps_sampled: 25000\n",
      "    num_steps_trained: 6097000\n",
      "    num_target_updates: 1016\n",
      "    num_weight_syncs: 62\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.374\n",
      "      policy_default_policy:\n",
      "        added_count: 6304\n",
      "        est_size_bytes: 155236492\n",
      "        num_entries: 6304\n",
      "        sampled_count: 1544000\n",
      "      replay_time_ms: 74.343\n",
      "      update_priorities_time_ms: 75.421\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.76589928057554\n",
      "    ram_util_percent: 33.873237410071944\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05621961504161017\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.48632637249203\n",
      "    mean_inference_ms: 1.9837357472487183\n",
      "    mean_raw_obs_processing_ms: 3.2428057332445177\n",
      "  time_since_restore: 487.6337249279022\n",
      "  time_this_iter_s: 487.6337249279022\n",
      "  time_total_s: 487.6337249279022\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 22255.507\n",
      "    learner_grad_time_ms: 44.933\n",
      "    learner_overall_throughput: 22237.407\n",
      "    learner_overall_time_ms: 44.969\n",
      "  timestamp: 1634720256\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25000\n",
      "  training_iteration: 1\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         487.634</td><td style=\"text-align: right;\">25000</td><td style=\"text-align: right;\">-1.90919</td><td style=\"text-align: right;\">               -0.09</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">           194.774</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 50000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_09-07-03\n",
      "  done: false\n",
      "  episode_len_mean: 181.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.47000000000000064\n",
      "  episode_reward_mean: -1.7834999999999923\n",
      "  episode_reward_min: -6.8199999999999195\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 126\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 49475\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 49911\n",
      "    last_target_update_ts: 17172000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.6480166912078857\n",
      "        max_q: 12.831802368164062\n",
      "        mean_q: 5.357852935791016\n",
      "        min_q: 1.970428705215454\n",
      "    learner_queue:\n",
      "      size_count: 17194\n",
      "      size_mean: 13.28\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 4.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 4.745692783988446\n",
      "    num_agent_steps_sampled: 50000\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 17177000\n",
      "    num_target_updates: 2862\n",
      "    num_weight_syncs: 124\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.291\n",
      "      policy_default_policy:\n",
      "        added_count: 12576\n",
      "        est_size_bytes: 309685036\n",
      "        num_entries: 12576\n",
      "        sampled_count: 4313000\n",
      "      replay_time_ms: 61.21\n",
      "      update_priorities_time_ms: 58.669\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.13374689826306\n",
      "    ram_util_percent: 42.6681141439206\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05452392948805295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.290139507387146\n",
      "    mean_inference_ms: 1.9745439202141448\n",
      "    mean_raw_obs_processing_ms: 3.304309260878566\n",
      "  time_since_restore: 1054.67973279953\n",
      "  time_this_iter_s: 567.0460078716278\n",
      "  time_total_s: 1054.67973279953\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.013\n",
      "    learner_grad_throughput: 27439.057\n",
      "    learner_grad_time_ms: 36.444\n",
      "    learner_overall_throughput: 27408.252\n",
      "    learner_overall_time_ms: 36.485\n",
      "  timestamp: 1634720823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 2\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1054.68</td><td style=\"text-align: right;\">50000</td><td style=\"text-align: right;\"> -1.7835</td><td style=\"text-align: right;\">                0.47</td><td style=\"text-align: right;\">               -6.82</td><td style=\"text-align: right;\">            181.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 75000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_09-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 209.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.4900000000000173\n",
      "  episode_reward_mean: -1.682799999999989\n",
      "  episode_reward_min: -5.949999999999917\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 183\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 74795\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 74551\n",
      "    last_target_update_ts: 27306000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.5590872168540955\n",
      "        max_q: 13.527922630310059\n",
      "        mean_q: 5.163458824157715\n",
      "        min_q: 1.9996591806411743\n",
      "    learner_queue:\n",
      "      size_count: 27320\n",
      "      size_mean: 14.44\n",
      "      size_quantiles:\n",
      "      - 4.0\n",
      "      - 8.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 3.2505999446256064\n",
      "    num_agent_steps_sampled: 75000\n",
      "    num_steps_sampled: 75000\n",
      "    num_steps_trained: 27307000\n",
      "    num_target_updates: 4551\n",
      "    num_weight_syncs: 186\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.472\n",
      "      policy_default_policy:\n",
      "        added_count: 18952\n",
      "        est_size_bytes: 466694908\n",
      "        num_entries: 18952\n",
      "        sampled_count: 6845000\n",
      "      replay_time_ms: 78.727\n",
      "      update_priorities_time_ms: 69.637\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.48643835616437\n",
      "    ram_util_percent: 46.82397260273972\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0532872687233212\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 37.087671665076854\n",
      "    mean_inference_ms: 1.968956006240063\n",
      "    mean_raw_obs_processing_ms: 3.295247879793138\n",
      "  time_since_restore: 1568.3925421237946\n",
      "  time_this_iter_s: 513.7128093242645\n",
      "  time_total_s: 1568.3925421237946\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 33625.045\n",
      "    learner_grad_time_ms: 29.74\n",
      "    learner_overall_throughput: 33584.255\n",
      "    learner_overall_time_ms: 29.776\n",
      "  timestamp: 1634721337\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 75000\n",
      "  training_iteration: 3\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         1568.39</td><td style=\"text-align: right;\">75000</td><td style=\"text-align: right;\"> -1.6828</td><td style=\"text-align: right;\">                1.49</td><td style=\"text-align: right;\">               -5.95</td><td style=\"text-align: right;\">            209.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 100004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_09-26-02\n",
      "  done: false\n",
      "  episode_len_mean: 173.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.7600000000000247\n",
      "  episode_reward_mean: -0.47079999999999367\n",
      "  episode_reward_min: -5.949999999999917\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 256\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 99903\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 99635\n",
      "    last_target_update_ts: 40002000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.2877110540866852\n",
      "        max_q: 19.161291122436523\n",
      "        mean_q: 7.0736284255981445\n",
      "        min_q: 3.3476362228393555\n",
      "    learner_queue:\n",
      "      size_count: 40019\n",
      "      size_mean: 13.9\n",
      "      size_quantiles:\n",
      "      - 2.0\n",
      "      - 6.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 3.986226285598949\n",
      "    num_agent_steps_sampled: 100004\n",
      "    num_steps_sampled: 100004\n",
      "    num_steps_trained: 40004000\n",
      "    num_target_updates: 6667\n",
      "    num_weight_syncs: 249\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.486\n",
      "      policy_default_policy:\n",
      "        added_count: 25320\n",
      "        est_size_bytes: 623508956\n",
      "        num_entries: 25320\n",
      "        sampled_count: 10018000\n",
      "      replay_time_ms: 65.486\n",
      "      update_priorities_time_ms: 63.202\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.27578828828828\n",
      "    ram_util_percent: 48.914527027027034\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05255146125513774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 38.880112518082065\n",
      "    mean_inference_ms: 1.956526782793905\n",
      "    mean_raw_obs_processing_ms: 3.3048868182441073\n",
      "  time_since_restore: 2194.022734642029\n",
      "  time_this_iter_s: 625.6301925182343\n",
      "  time_total_s: 2194.022734642029\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.009\n",
      "    learner_grad_throughput: 37055.2\n",
      "    learner_grad_time_ms: 26.987\n",
      "    learner_overall_throughput: 37009.065\n",
      "    learner_overall_time_ms: 27.02\n",
      "  timestamp: 1634721962\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 100004\n",
      "  training_iteration: 4\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         2194.02</td><td style=\"text-align: right;\">100004</td><td style=\"text-align: right;\"> -0.4708</td><td style=\"text-align: right;\">                2.76</td><td style=\"text-align: right;\">               -5.95</td><td style=\"text-align: right;\">            173.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=166)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=166)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=166)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=166)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 125004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_09-36-06\n",
      "  done: false\n",
      "  episode_len_mean: 181.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.95000000000002\n",
      "  episode_reward_mean: -0.2559999999999943\n",
      "  episode_reward_min: -5.50999999999997\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 322\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 500.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -4.999999999999938\n",
      "    episode_reward_mean: -4.999999999999938\n",
      "    episode_reward_min: -4.999999999999938\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - -4.999999999999938\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.040027195821979084\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 79.8522940652813\n",
      "      mean_inference_ms: 1.4646724312605257\n",
      "      mean_raw_obs_processing_ms: 0.597338476580774\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 124843\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 124919\n",
      "    last_target_update_ts: 51564000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.3362210988998413\n",
      "        max_q: 22.333026885986328\n",
      "        mean_q: 7.4191436767578125\n",
      "        min_q: 3.6053967475891113\n",
      "    learner_queue:\n",
      "      size_count: 51574\n",
      "      size_mean: 15.7\n",
      "      size_quantiles:\n",
      "      - 11.0\n",
      "      - 15.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 1.004987562112089\n",
      "    num_agent_steps_sampled: 125004\n",
      "    num_steps_sampled: 125004\n",
      "    num_steps_trained: 51568000\n",
      "    num_target_updates: 8594\n",
      "    num_weight_syncs: 312\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.371\n",
      "      policy_default_policy:\n",
      "        added_count: 31440\n",
      "        est_size_bytes: 774215360\n",
      "        num_entries: 31440\n",
      "        sampled_count: 12910000\n",
      "      replay_time_ms: 54.067\n",
      "      update_priorities_time_ms: 53.923\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.36573426573425\n",
      "    ram_util_percent: 52.547902097902096\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05208720786808655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 39.82291077603383\n",
      "    mean_inference_ms: 1.9391724585425352\n",
      "    mean_raw_obs_processing_ms: 3.3043484608960214\n",
      "  time_since_restore: 2797.725439786911\n",
      "  time_this_iter_s: 603.7027051448822\n",
      "  time_total_s: 2797.725439786911\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 25700.723\n",
      "    learner_grad_time_ms: 38.909\n",
      "    learner_overall_throughput: 25676.494\n",
      "    learner_overall_time_ms: 38.946\n",
      "  timestamp: 1634722566\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 125004\n",
      "  training_iteration: 5\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         2797.73</td><td style=\"text-align: right;\">125004</td><td style=\"text-align: right;\">  -0.256</td><td style=\"text-align: right;\">                4.95</td><td style=\"text-align: right;\">               -5.51</td><td style=\"text-align: right;\">            181.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 150004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_09-45-32\n",
      "  done: false\n",
      "  episode_len_mean: 196.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.95000000000002\n",
      "  episode_reward_mean: -0.014699999999993931\n",
      "  episode_reward_min: -4.759999999999965\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 384\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 149719\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 149839\n",
      "    last_target_update_ts: 61974000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.4692617654800415\n",
      "        max_q: 19.81983757019043\n",
      "        mean_q: 6.801989555358887\n",
      "        min_q: 2.3713719844818115\n",
      "    learner_queue:\n",
      "      size_count: 61981\n",
      "      size_mean: 15.88\n",
      "      size_quantiles:\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 0.5153639490690051\n",
      "    num_agent_steps_sampled: 150004\n",
      "    num_steps_sampled: 150004\n",
      "    num_steps_trained: 61977000\n",
      "    num_target_updates: 10329\n",
      "    num_weight_syncs: 374\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.366\n",
      "      policy_default_policy:\n",
      "        added_count: 37724\n",
      "        est_size_bytes: 928960116\n",
      "        num_entries: 37724\n",
      "        sampled_count: 15513000\n",
      "      replay_time_ms: 90.753\n",
      "      update_priorities_time_ms: 70.027\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.23561643835617\n",
      "    ram_util_percent: 60.34570361145704\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051998281729941045\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 39.827961529635076\n",
      "    mean_inference_ms: 1.9243469259028283\n",
      "    mean_raw_obs_processing_ms: 3.280157713473408\n",
      "  time_since_restore: 3364.0888271331787\n",
      "  time_this_iter_s: 566.3633873462677\n",
      "  time_total_s: 3364.0888271331787\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 19389.466\n",
      "    learner_grad_time_ms: 51.574\n",
      "    learner_overall_throughput: 19377.328\n",
      "    learner_overall_time_ms: 51.607\n",
      "  timestamp: 1634723132\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 150004\n",
      "  training_iteration: 6\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         3364.09</td><td style=\"text-align: right;\">150004</td><td style=\"text-align: right;\"> -0.0147</td><td style=\"text-align: right;\">                4.95</td><td style=\"text-align: right;\">               -4.76</td><td style=\"text-align: right;\">            196.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 175004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_09-55-40\n",
      "  done: false\n",
      "  episode_len_mean: 171.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.490000000000009\n",
      "  episode_reward_mean: 2.081000000000017\n",
      "  episode_reward_min: -4.999999999999938\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 451\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 174283\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 174839\n",
      "    last_target_update_ts: 73050000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.40282002091407776\n",
      "        max_q: 20.576526641845703\n",
      "        mean_q: 7.125546455383301\n",
      "        min_q: 3.744353771209717\n",
      "    learner_queue:\n",
      "      size_count: 73065\n",
      "      size_mean: 14.9\n",
      "      size_quantiles:\n",
      "      - 6.0\n",
      "      - 10.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 2.5475478405713994\n",
      "    num_agent_steps_sampled: 175004\n",
      "    num_steps_sampled: 175004\n",
      "    num_steps_trained: 73054000\n",
      "    num_target_updates: 12175\n",
      "    num_weight_syncs: 436\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 1.24\n",
      "      policy_default_policy:\n",
      "        added_count: 43940\n",
      "        est_size_bytes: 1082029808\n",
      "        num_entries: 43940\n",
      "        sampled_count: 18282000\n",
      "      replay_time_ms: 77.811\n",
      "      update_priorities_time_ms: 65.198\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.28273464658169\n",
      "    ram_util_percent: 64.44924681344148\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051696135766840665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.269997151896796\n",
      "    mean_inference_ms: 1.9128970361630122\n",
      "    mean_raw_obs_processing_ms: 3.28729643210169\n",
      "  time_since_restore: 3971.451782464981\n",
      "  time_this_iter_s: 607.3629553318024\n",
      "  time_total_s: 3971.451782464981\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 23803.898\n",
      "    learner_grad_time_ms: 42.01\n",
      "    learner_overall_throughput: 23783.894\n",
      "    learner_overall_time_ms: 42.045\n",
      "  timestamp: 1634723740\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 175004\n",
      "  training_iteration: 7\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         3971.45</td><td style=\"text-align: right;\">175004</td><td style=\"text-align: right;\">   2.081</td><td style=\"text-align: right;\">                5.49</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            171.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 200004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_10-05-58\n",
      "  done: false\n",
      "  episode_len_mean: 167.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.0000000000000195\n",
      "  episode_reward_mean: 2.61370000000002\n",
      "  episode_reward_min: -3.9499999999999593\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 520\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 199275\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 200003\n",
      "    last_target_update_ts: 84246000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.2842072248458862\n",
      "        max_q: 23.794164657592773\n",
      "        mean_q: 8.675408363342285\n",
      "        min_q: 3.5812556743621826\n",
      "    learner_queue:\n",
      "      size_count: 84254\n",
      "      size_mean: 15.7\n",
      "      size_quantiles:\n",
      "      - 11.0\n",
      "      - 15.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 1.004987562112089\n",
      "    num_agent_steps_sampled: 200004\n",
      "    num_steps_sampled: 200004\n",
      "    num_steps_trained: 84248000\n",
      "    num_target_updates: 14041\n",
      "    num_weight_syncs: 499\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.289\n",
      "      policy_default_policy:\n",
      "        added_count: 50060\n",
      "        est_size_bytes: 1232735516\n",
      "        num_entries: 50060\n",
      "        sampled_count: 21078000\n",
      "      replay_time_ms: 80.705\n",
      "      update_priorities_time_ms: 75.45\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.31014823261117\n",
      "    ram_util_percent: 68.31197263397948\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05126789403559373\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.008944535139435\n",
      "    mean_inference_ms: 1.9020058784640645\n",
      "    mean_raw_obs_processing_ms: 3.315951817743046\n",
      "  time_since_restore: 4589.236933231354\n",
      "  time_this_iter_s: 617.7851507663727\n",
      "  time_total_s: 4589.236933231354\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 23822.502\n",
      "    learner_grad_time_ms: 41.977\n",
      "    learner_overall_throughput: 23801.615\n",
      "    learner_overall_time_ms: 42.014\n",
      "  timestamp: 1634724358\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 200004\n",
      "  training_iteration: 8\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 33.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         4589.24</td><td style=\"text-align: right;\">200004</td><td style=\"text-align: right;\">  2.6137</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">               -3.95</td><td style=\"text-align: right;\">            167.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 225004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_10-15-31\n",
      "  done: false\n",
      "  episode_len_mean: 193.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.230000000000015\n",
      "  episode_reward_mean: 2.0901000000000196\n",
      "  episode_reward_min: -4.999999999999938\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 584\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 224455\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 224791\n",
      "    last_target_update_ts: 94650000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.8807483315467834\n",
      "        max_q: 18.68961524963379\n",
      "        mean_q: 8.523677825927734\n",
      "        min_q: 4.418423175811768\n",
      "    learner_queue:\n",
      "      size_count: 94660\n",
      "      size_mean: 15.8\n",
      "      size_quantiles:\n",
      "      - 12.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 0.7483314773547882\n",
      "    num_agent_steps_sampled: 225004\n",
      "    num_steps_sampled: 225004\n",
      "    num_steps_trained: 94655000\n",
      "    num_target_updates: 15775\n",
      "    num_weight_syncs: 561\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.309\n",
      "      policy_default_policy:\n",
      "        added_count: 56256\n",
      "        est_size_bytes: 1385313396\n",
      "        num_entries: 56256\n",
      "        sampled_count: 23678000\n",
      "      replay_time_ms: 87.278\n",
      "      update_priorities_time_ms: 71.102\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.31695331695332\n",
      "    ram_util_percent: 72.47911547911548\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050909494951183146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.120617605066855\n",
      "    mean_inference_ms: 1.8947853674748927\n",
      "    mean_raw_obs_processing_ms: 3.3192448983288854\n",
      "  time_since_restore: 5162.569833517075\n",
      "  time_this_iter_s: 573.3329002857208\n",
      "  time_total_s: 5162.569833517075\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 18953.742\n",
      "    learner_grad_time_ms: 52.76\n",
      "    learner_overall_throughput: 18942.033\n",
      "    learner_overall_time_ms: 52.793\n",
      "  timestamp: 1634724931\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 225004\n",
      "  training_iteration: 9\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 35.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         5162.57</td><td style=\"text-align: right;\">225004</td><td style=\"text-align: right;\">  2.0901</td><td style=\"text-align: right;\">                8.23</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            193.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 250004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_10-25-13\n",
      "  done: false\n",
      "  episode_len_mean: 197.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.570000000000029\n",
      "  episode_reward_mean: 1.4387000000000199\n",
      "  episode_reward_min: -5.649999999999923\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 647\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 132.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -0.30000000000000066\n",
      "    episode_reward_mean: -0.30000000000000066\n",
      "    episode_reward_min: -0.30000000000000066\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 132\n",
      "      episode_reward:\n",
      "      - -0.30000000000000066\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.039863360436606744\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 72.31051021654271\n",
      "      mean_inference_ms: 1.4627160619220463\n",
      "      mean_raw_obs_processing_ms: 0.7091589260251978\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 249831\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 249775\n",
      "    last_target_update_ts: 105162000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.7220712900161743\n",
      "        max_q: 26.41543960571289\n",
      "        mean_q: 8.071435928344727\n",
      "        min_q: 4.4317827224731445\n",
      "    learner_queue:\n",
      "      size_count: 105173\n",
      "      size_mean: 15.44\n",
      "      size_quantiles:\n",
      "      - 9.0\n",
      "      - 13.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 1.5768322675541617\n",
      "    num_agent_steps_sampled: 250004\n",
      "    num_steps_sampled: 250004\n",
      "    num_steps_trained: 105165000\n",
      "    num_target_updates: 17527\n",
      "    num_weight_syncs: 624\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.416\n",
      "      policy_default_policy:\n",
      "        added_count: 62580\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 26302000\n",
      "      replay_time_ms: 89.186\n",
      "      update_priorities_time_ms: 79.25\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.23748488512697\n",
      "    ram_util_percent: 76.39891172914147\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050626223539181794\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.95940379615756\n",
      "    mean_inference_ms: 1.889615296203024\n",
      "    mean_raw_obs_processing_ms: 3.3098161507668866\n",
      "  time_since_restore: 5744.695007801056\n",
      "  time_this_iter_s: 582.1251742839813\n",
      "  time_total_s: 5744.695007801056\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.012\n",
      "    learner_grad_throughput: 25512.922\n",
      "    learner_grad_time_ms: 39.196\n",
      "    learner_overall_throughput: 25488.008\n",
      "    learner_overall_time_ms: 39.234\n",
      "  timestamp: 1634725513\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 250004\n",
      "  training_iteration: 10\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">          5744.7</td><td style=\"text-align: right;\">250004</td><td style=\"text-align: right;\">  1.4387</td><td style=\"text-align: right;\">                6.57</td><td style=\"text-align: right;\">               -5.65</td><td style=\"text-align: right;\">            197.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 275004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_10-34-15\n",
      "  done: false\n",
      "  episode_len_mean: 213.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.8600000000000225\n",
      "  episode_reward_mean: 1.7794000000000207\n",
      "  episode_reward_min: -4.669999999999945\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 706\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 274991\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 274775\n",
      "    last_target_update_ts: 114966000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.9960803389549255\n",
      "        max_q: 18.645931243896484\n",
      "        mean_q: 8.224692344665527\n",
      "        min_q: 0.47992491722106934\n",
      "    learner_queue:\n",
      "      size_count: 114984\n",
      "      size_mean: 14.44\n",
      "      size_quantiles:\n",
      "      - 4.0\n",
      "      - 8.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 3.250599944625607\n",
      "    num_agent_steps_sampled: 275004\n",
      "    num_steps_sampled: 275004\n",
      "    num_steps_trained: 114971000\n",
      "    num_target_updates: 19161\n",
      "    num_weight_syncs: 687\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.727\n",
      "      policy_default_policy:\n",
      "        added_count: 68892\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 28741000\n",
      "      replay_time_ms: 89.132\n",
      "      update_priorities_time_ms: 64.804\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.3478543563069\n",
      "    ram_util_percent: 78.57269180754227\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05042905446004237\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.50929687940689\n",
      "    mean_inference_ms: 1.8854366271405467\n",
      "    mean_raw_obs_processing_ms: 3.2942224765909818\n",
      "  time_since_restore: 6286.018708944321\n",
      "  time_this_iter_s: 541.3237011432648\n",
      "  time_total_s: 6286.018708944321\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.009\n",
      "    learner_grad_throughput: 31795.963\n",
      "    learner_grad_time_ms: 31.451\n",
      "    learner_overall_throughput: 31762.422\n",
      "    learner_overall_time_ms: 31.484\n",
      "  timestamp: 1634726055\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 275004\n",
      "  training_iteration: 11\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         6286.02</td><td style=\"text-align: right;\">275004</td><td style=\"text-align: right;\">  1.7794</td><td style=\"text-align: right;\">                6.86</td><td style=\"text-align: right;\">               -4.67</td><td style=\"text-align: right;\">            213.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 300004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_10-43-57\n",
      "  done: false\n",
      "  episode_len_mean: 209.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.310000000000013\n",
      "  episode_reward_mean: 1.6739000000000224\n",
      "  episode_reward_min: -4.999999999999938\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 771\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 299951\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 299711\n",
      "    last_target_update_ts: 125544000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.6520278453826904\n",
      "        max_q: 19.133159637451172\n",
      "        mean_q: 7.748793125152588\n",
      "        min_q: 4.047493934631348\n",
      "    learner_queue:\n",
      "      size_count: 125556\n",
      "      size_mean: 14.68\n",
      "      size_quantiles:\n",
      "      - 5.0\n",
      "      - 9.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 2.894408402420087\n",
      "    num_agent_steps_sampled: 300004\n",
      "    num_steps_sampled: 300004\n",
      "    num_steps_trained: 125544000\n",
      "    num_target_updates: 20924\n",
      "    num_weight_syncs: 749\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.336\n",
      "      policy_default_policy:\n",
      "        added_count: 75280\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 31373000\n",
      "      replay_time_ms: 89.285\n",
      "      update_priorities_time_ms: 71.233\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.35586457073761\n",
      "    ram_util_percent: 78.76638452237\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050411357958354074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.264884053100396\n",
      "    mean_inference_ms: 1.8802896195243866\n",
      "    mean_raw_obs_processing_ms: 3.2834582928342417\n",
      "  time_since_restore: 6868.026157140732\n",
      "  time_this_iter_s: 582.0074481964111\n",
      "  time_total_s: 6868.026157140732\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 22742.81\n",
      "    learner_grad_time_ms: 43.97\n",
      "    learner_overall_throughput: 22725.447\n",
      "    learner_overall_time_ms: 44.004\n",
      "  timestamp: 1634726637\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300004\n",
      "  training_iteration: 12\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         6868.03</td><td style=\"text-align: right;\">300004</td><td style=\"text-align: right;\">  1.6739</td><td style=\"text-align: right;\">                7.31</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            209.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 325008\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_10-53-33\n",
      "  done: false\n",
      "  episode_len_mean: 202.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.490000000000009\n",
      "  episode_reward_mean: 2.310500000000023\n",
      "  episode_reward_min: -4.999999999999938\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 834\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 324547\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 324819\n",
      "    last_target_update_ts: 136008000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.2368075847625732\n",
      "        max_q: 17.204023361206055\n",
      "        mean_q: 7.835657119750977\n",
      "        min_q: 3.846951961517334\n",
      "    learner_queue:\n",
      "      size_count: 136015\n",
      "      size_mean: 15.8\n",
      "      size_quantiles:\n",
      "      - 12.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 0.7483314773547882\n",
      "    num_agent_steps_sampled: 325008\n",
      "    num_steps_sampled: 325008\n",
      "    num_steps_trained: 136010000\n",
      "    num_target_updates: 22668\n",
      "    num_weight_syncs: 811\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.554\n",
      "      policy_default_policy:\n",
      "        added_count: 81564\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 33987000\n",
      "      replay_time_ms: 77.04\n",
      "      update_priorities_time_ms: 66.963\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.36593137254903\n",
      "    ram_util_percent: 78.79950980392157\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050387061616473966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.18150123388425\n",
      "    mean_inference_ms: 1.876489774165885\n",
      "    mean_raw_obs_processing_ms: 3.2752920712850924\n",
      "  time_since_restore: 7444.168910264969\n",
      "  time_this_iter_s: 576.1427531242371\n",
      "  time_total_s: 7444.168910264969\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 21063.473\n",
      "    learner_grad_time_ms: 47.476\n",
      "    learner_overall_throughput: 21048.801\n",
      "    learner_overall_time_ms: 47.509\n",
      "  timestamp: 1634727213\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 325008\n",
      "  training_iteration: 13\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         7444.17</td><td style=\"text-align: right;\">325008</td><td style=\"text-align: right;\">  2.3105</td><td style=\"text-align: right;\">                7.49</td><td style=\"text-align: right;\">                  -5</td><td style=\"text-align: right;\">            202.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 350012\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_11-03-35\n",
      "  done: false\n",
      "  episode_len_mean: 187.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.490000000000009\n",
      "  episode_reward_mean: 2.1191000000000217\n",
      "  episode_reward_min: -4.88999999999994\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 900\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 349723\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 350003\n",
      "    last_target_update_ts: 146994000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.45303821563720703\n",
      "        max_q: 20.518218994140625\n",
      "        mean_q: 7.792074680328369\n",
      "        min_q: 4.035220146179199\n",
      "    learner_queue:\n",
      "      size_count: 147009\n",
      "      size_mean: 14.68\n",
      "      size_quantiles:\n",
      "      - 5.0\n",
      "      - 9.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 2.8944084024200873\n",
      "    num_agent_steps_sampled: 350012\n",
      "    num_steps_sampled: 350012\n",
      "    num_steps_trained: 146997000\n",
      "    num_target_updates: 24499\n",
      "    num_weight_syncs: 875\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.377\n",
      "      policy_default_policy:\n",
      "        added_count: 87800\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 36724000\n",
      "      replay_time_ms: 88.605\n",
      "      update_priorities_time_ms: 82.009\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.35064327485381\n",
      "    ram_util_percent: 78.75309941520467\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050379968811353454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.22439760016043\n",
      "    mean_inference_ms: 1.873927052870644\n",
      "    mean_raw_obs_processing_ms: 3.3409764855231856\n",
      "  time_since_restore: 8046.459352016449\n",
      "  time_this_iter_s: 602.2904417514801\n",
      "  time_total_s: 8046.459352016449\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.009\n",
      "    learner_grad_throughput: 17754.307\n",
      "    learner_grad_time_ms: 56.324\n",
      "    learner_overall_throughput: 17744.647\n",
      "    learner_overall_time_ms: 56.355\n",
      "  timestamp: 1634727815\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 350012\n",
      "  training_iteration: 14\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         8046.46</td><td style=\"text-align: right;\">350012</td><td style=\"text-align: right;\">  2.1191</td><td style=\"text-align: right;\">                7.49</td><td style=\"text-align: right;\">               -4.89</td><td style=\"text-align: right;\">            187.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 375012\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_11-13-04\n",
      "  done: false\n",
      "  episode_len_mean: 198.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.270000000000014\n",
      "  episode_reward_mean: 1.881500000000021\n",
      "  episode_reward_min: -4.799999999999942\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 961\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 160.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 3.5300000000000296\n",
      "    episode_reward_mean: 3.5300000000000296\n",
      "    episode_reward_min: 3.5300000000000296\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 160\n",
      "      episode_reward:\n",
      "      - 3.5300000000000296\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.03981439944023142\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 63.36444683964887\n",
      "      mean_inference_ms: 1.4559332690052547\n",
      "      mean_raw_obs_processing_ms: 0.7005095632199532\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 374707\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 374971\n",
      "    last_target_update_ts: 157404000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.8215301036834717\n",
      "        max_q: 21.042835235595703\n",
      "        mean_q: 7.559121608734131\n",
      "        min_q: 4.181038856506348\n",
      "    learner_queue:\n",
      "      size_count: 157410\n",
      "      size_mean: 15.7\n",
      "      size_quantiles:\n",
      "      - 11.0\n",
      "      - 15.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 1.004987562112089\n",
      "    num_agent_steps_sampled: 375012\n",
      "    num_steps_sampled: 375012\n",
      "    num_steps_trained: 157404000\n",
      "    num_target_updates: 26234\n",
      "    num_weight_syncs: 937\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.682\n",
      "      policy_default_policy:\n",
      "        added_count: 94328\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 39300000\n",
      "      replay_time_ms: 74.656\n",
      "      update_priorities_time_ms: 70.849\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.32630272952854\n",
      "    ram_util_percent: 78.74019851116626\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050364516130789225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.17946863757013\n",
      "    mean_inference_ms: 1.8729322246680191\n",
      "    mean_raw_obs_processing_ms: 3.3755869594630075\n",
      "  time_since_restore: 8615.063117980957\n",
      "  time_this_iter_s: 568.603765964508\n",
      "  time_total_s: 8615.063117980957\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 19094.267\n",
      "    learner_grad_time_ms: 52.372\n",
      "    learner_overall_throughput: 19081.966\n",
      "    learner_overall_time_ms: 52.406\n",
      "  timestamp: 1634728384\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 375012\n",
      "  training_iteration: 15\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         8615.06</td><td style=\"text-align: right;\">375012</td><td style=\"text-align: right;\">  1.8815</td><td style=\"text-align: right;\">                7.27</td><td style=\"text-align: right;\">                -4.8</td><td style=\"text-align: right;\">            198.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 400012\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_11-22-21\n",
      "  done: false\n",
      "  episode_len_mean: 205.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.630000000000026\n",
      "  episode_reward_mean: 2.7598000000000265\n",
      "  episode_reward_min: -4.799999999999942\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 1023\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 399839\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 399739\n",
      "    last_target_update_ts: 167880000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.7734353542327881\n",
      "        max_q: 17.750133514404297\n",
      "        mean_q: 7.266451835632324\n",
      "        min_q: 3.8521690368652344\n",
      "    learner_queue:\n",
      "      size_count: 167883\n",
      "      size_mean: 2.66\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 1.9000000000000004\n",
      "      - 3.0\n",
      "      - 4.0\n",
      "      - 5.0\n",
      "      size_std: 1.050904372433572\n",
      "    num_agent_steps_sampled: 400012\n",
      "    num_steps_sampled: 400012\n",
      "    num_steps_trained: 167880000\n",
      "    num_target_updates: 27980\n",
      "    num_weight_syncs: 999\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.411\n",
      "      policy_default_policy:\n",
      "        added_count: 100816\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 41884000\n",
      "      replay_time_ms: 74.948\n",
      "      update_priorities_time_ms: 60.458\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.43560606060606\n",
      "    ram_util_percent: 78.73358585858585\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05030264442267849\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.01267108908464\n",
      "    mean_inference_ms: 1.8721884525448038\n",
      "    mean_raw_obs_processing_ms: 3.36656913718203\n",
      "  time_since_restore: 9172.623077869415\n",
      "  time_this_iter_s: 557.5599598884583\n",
      "  time_total_s: 9172.623077869415\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.009\n",
      "    learner_grad_throughput: 22510.447\n",
      "    learner_grad_time_ms: 44.424\n",
      "    learner_overall_throughput: 22493.51\n",
      "    learner_overall_time_ms: 44.457\n",
      "  timestamp: 1634728941\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 400012\n",
      "  training_iteration: 16\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         9172.62</td><td style=\"text-align: right;\">400012</td><td style=\"text-align: right;\">  2.7598</td><td style=\"text-align: right;\">                7.63</td><td style=\"text-align: right;\">                -4.8</td><td style=\"text-align: right;\">            205.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 425016\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_11-31-58\n",
      "  done: false\n",
      "  episode_len_mean: 200.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.170000000000016\n",
      "  episode_reward_mean: 2.8746000000000267\n",
      "  episode_reward_min: -4.9199999999999395\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 1087\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 424879\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 424987\n",
      "    last_target_update_ts: 178680000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.0546131134033203\n",
      "        max_q: 18.876495361328125\n",
      "        mean_q: 7.149586200714111\n",
      "        min_q: 4.0302934646606445\n",
      "    learner_queue:\n",
      "      size_count: 178692\n",
      "      size_mean: 9.2\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 4.9\n",
      "      - 10.0\n",
      "      - 12.0\n",
      "      - 13.0\n",
      "      size_std: 2.932575659723036\n",
      "    num_agent_steps_sampled: 425016\n",
      "    num_steps_sampled: 425016\n",
      "    num_steps_trained: 178683000\n",
      "    num_target_updates: 29780\n",
      "    num_weight_syncs: 1062\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.37\n",
      "      policy_default_policy:\n",
      "        added_count: 107084\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 44549000\n",
      "      replay_time_ms: 78.946\n",
      "      update_priorities_time_ms: 69.251\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.41756097560975\n",
      "    ram_util_percent: 78.70353658536587\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050246932195025754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 39.89350253109657\n",
      "    mean_inference_ms: 1.8708642095316532\n",
      "    mean_raw_obs_processing_ms: 3.3633807363586175\n",
      "  time_since_restore: 9749.762984991074\n",
      "  time_this_iter_s: 577.1399071216583\n",
      "  time_total_s: 9749.762984991074\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.009\n",
      "    learner_grad_throughput: 17688.723\n",
      "    learner_grad_time_ms: 56.533\n",
      "    learner_overall_throughput: 17675.283\n",
      "    learner_overall_time_ms: 56.576\n",
      "  timestamp: 1634729518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 425016\n",
      "  training_iteration: 17\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         9749.76</td><td style=\"text-align: right;\">425016</td><td style=\"text-align: right;\">  2.8746</td><td style=\"text-align: right;\">                8.17</td><td style=\"text-align: right;\">               -4.92</td><td style=\"text-align: right;\">            200.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 450016\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_11-42-23\n",
      "  done: false\n",
      "  episode_len_mean: 184.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.3000000000000345\n",
      "  episode_reward_mean: 2.060000000000019\n",
      "  episode_reward_min: -2.879999999999984\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 1156\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 449819\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 449991\n",
      "    last_target_update_ts: 190356000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.5527015924453735\n",
      "        max_q: 19.836103439331055\n",
      "        mean_q: 7.651308536529541\n",
      "        min_q: 3.1310322284698486\n",
      "    learner_queue:\n",
      "      size_count: 190363\n",
      "      size_mean: 3.22\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 3.0\n",
      "      - 5.0\n",
      "      - 6.0\n",
      "      size_std: 1.46\n",
      "    num_agent_steps_sampled: 450016\n",
      "    num_steps_sampled: 450016\n",
      "    num_steps_trained: 190359000\n",
      "    num_target_updates: 31726\n",
      "    num_weight_syncs: 1124\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.599\n",
      "      policy_default_policy:\n",
      "        added_count: 113220\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 47449000\n",
      "      replay_time_ms: 74.65\n",
      "      update_priorities_time_ms: 64.017\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.38058690744921\n",
      "    ram_util_percent: 78.69232505643342\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05015651516190033\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.09603103401699\n",
      "    mean_inference_ms: 1.8691991894190292\n",
      "    mean_raw_obs_processing_ms: 3.3660591523042105\n",
      "  time_since_restore: 10373.796196699142\n",
      "  time_this_iter_s: 624.0332117080688\n",
      "  time_total_s: 10373.796196699142\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.009\n",
      "    learner_grad_throughput: 24410.083\n",
      "    learner_grad_time_ms: 40.967\n",
      "    learner_overall_throughput: 24391.558\n",
      "    learner_overall_time_ms: 40.998\n",
      "  timestamp: 1634730143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 450016\n",
      "  training_iteration: 18\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         10373.8</td><td style=\"text-align: right;\">450016</td><td style=\"text-align: right;\">    2.06</td><td style=\"text-align: right;\">                 7.3</td><td style=\"text-align: right;\">               -2.88</td><td style=\"text-align: right;\">            184.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:01:27.899586, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 475020\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_11-53-33\n",
      "  done: false\n",
      "  episode_len_mean: 149.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.050000000000018\n",
      "  episode_reward_mean: 3.522600000000018\n",
      "  episode_reward_min: -2.879999999999984\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 1231\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 474919\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 474899\n",
      "    last_target_update_ts: 202758000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.822008490562439\n",
      "        max_q: 20.5135555267334\n",
      "        mean_q: 7.920034408569336\n",
      "        min_q: 4.375148773193359\n",
      "    learner_queue:\n",
      "      size_count: 202772\n",
      "      size_mean: 8.62\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 4.9\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "      - 11.0\n",
      "      size_std: 2.5130857526156962\n",
      "    num_agent_steps_sampled: 475020\n",
      "    num_steps_sampled: 475020\n",
      "    num_steps_trained: 202762000\n",
      "    num_target_updates: 33793\n",
      "    num_weight_syncs: 1187\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.486\n",
      "      policy_default_policy:\n",
      "        added_count: 119448\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 50549000\n",
      "      replay_time_ms: 71.977\n",
      "      update_priorities_time_ms: 58.881\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.36334033613446\n",
      "    ram_util_percent: 78.71502100840337\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05009466304990872\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.74251796981347\n",
      "    mean_inference_ms: 1.8686321228552736\n",
      "    mean_raw_obs_processing_ms: 3.3737377806399973\n",
      "  time_since_restore: 11043.902455568314\n",
      "  time_this_iter_s: 670.1062588691711\n",
      "  time_total_s: 11043.902455568314\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 28108.34\n",
      "    learner_grad_time_ms: 35.577\n",
      "    learner_overall_throughput: 28081.749\n",
      "    learner_overall_time_ms: 35.61\n",
      "  timestamp: 1634730813\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 475020\n",
      "  training_iteration: 19\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         11043.9</td><td style=\"text-align: right;\">475020</td><td style=\"text-align: right;\">  3.5226</td><td style=\"text-align: right;\">                8.05</td><td style=\"text-align: right;\">               -2.88</td><td style=\"text-align: right;\">            149.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 500020\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_12-04-21\n",
      "  done: false\n",
      "  episode_len_mean: 168.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.930000000000021\n",
      "  episode_reward_mean: 3.2698000000000205\n",
      "  episode_reward_min: -2.389999999999993\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 1301\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 108.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -1.0800000000000007\n",
      "    episode_reward_mean: -1.0800000000000007\n",
      "    episode_reward_min: -1.0800000000000007\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 108\n",
      "      episode_reward:\n",
      "      - -1.0800000000000007\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.03960712106855013\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 60.42379650238748\n",
      "      mean_inference_ms: 1.4531371596121496\n",
      "      mean_raw_obs_processing_ms: 0.7024372325224034\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 500007\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 500007\n",
      "    last_target_update_ts: 214488000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.183242917060852\n",
      "        max_q: 23.205528259277344\n",
      "        mean_q: 8.470865249633789\n",
      "        min_q: 3.5191102027893066\n",
      "    learner_queue:\n",
      "      size_count: 214502\n",
      "      size_mean: 14.44\n",
      "      size_quantiles:\n",
      "      - 4.0\n",
      "      - 8.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 3.250599944625607\n",
      "    num_agent_steps_sampled: 500020\n",
      "    num_steps_sampled: 500020\n",
      "    num_steps_trained: 214489000\n",
      "    num_target_updates: 35748\n",
      "    num_weight_syncs: 1250\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.457\n",
      "      policy_default_policy:\n",
      "        added_count: 125664\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 53502000\n",
      "      replay_time_ms: 83.337\n",
      "      update_priorities_time_ms: 70.557\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.35549510337324\n",
      "    ram_util_percent: 78.78835690968444\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05012014749667758\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.16680515506478\n",
      "    mean_inference_ms: 1.867676890942787\n",
      "    mean_raw_obs_processing_ms: 3.3783443756720066\n",
      "  time_since_restore: 11692.241652727127\n",
      "  time_this_iter_s: 648.3391971588135\n",
      "  time_total_s: 11692.241652727127\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 30214.519\n",
      "    learner_grad_time_ms: 33.097\n",
      "    learner_overall_throughput: 30183.448\n",
      "    learner_overall_time_ms: 33.131\n",
      "  timestamp: 1634731461\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 500020\n",
      "  training_iteration: 20\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         11692.2</td><td style=\"text-align: right;\">500020</td><td style=\"text-align: right;\">  3.2698</td><td style=\"text-align: right;\">                7.93</td><td style=\"text-align: right;\">               -2.39</td><td style=\"text-align: right;\">            168.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 525028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_12-14-18\n",
      "  done: false\n",
      "  episode_len_mean: 175.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.870000000000021\n",
      "  episode_reward_mean: 2.389400000000018\n",
      "  episode_reward_min: -2.279999999999954\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 1367\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 524707\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 524943\n",
      "    last_target_update_ts: 225666000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.5061358213424683\n",
      "        max_q: 28.610883712768555\n",
      "        mean_q: 7.697455883026123\n",
      "        min_q: 3.032377243041992\n",
      "    learner_queue:\n",
      "      size_count: 225680\n",
      "      size_mean: 5.2\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 2.0\n",
      "      - 5.0\n",
      "      - 8.0\n",
      "      - 9.0\n",
      "      size_std: 2.262741699796952\n",
      "    num_agent_steps_sampled: 525028\n",
      "    num_steps_sampled: 525028\n",
      "    num_steps_trained: 225670000\n",
      "    num_target_updates: 37611\n",
      "    num_weight_syncs: 1312\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.432\n",
      "      policy_default_policy:\n",
      "        added_count: 131984\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 56335000\n",
      "      replay_time_ms: 69.211\n",
      "      update_priorities_time_ms: 65.864\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.41533018867923\n",
      "    ram_util_percent: 78.6379716981132\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050091524422250115\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.30275787548848\n",
      "    mean_inference_ms: 1.8669526701572141\n",
      "    mean_raw_obs_processing_ms: 3.3753872275436096\n",
      "  time_since_restore: 12289.359457731247\n",
      "  time_this_iter_s: 597.1178050041199\n",
      "  time_total_s: 12289.359457731247\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 18888.709\n",
      "    learner_grad_time_ms: 52.942\n",
      "    learner_overall_throughput: 18875.602\n",
      "    learner_overall_time_ms: 52.978\n",
      "  timestamp: 1634732058\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 525028\n",
      "  training_iteration: 21\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         12289.4</td><td style=\"text-align: right;\">525028</td><td style=\"text-align: right;\">  2.3894</td><td style=\"text-align: right;\">                5.87</td><td style=\"text-align: right;\">               -2.28</td><td style=\"text-align: right;\">             175.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 550028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_12-24-12\n",
      "  done: false\n",
      "  episode_len_mean: 192.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.320000000000034\n",
      "  episode_reward_mean: 2.0620000000000207\n",
      "  episode_reward_min: -3.5299999999999683\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 1434\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 549923\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 549675\n",
      "    last_target_update_ts: 236748000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.47206225991249084\n",
      "        max_q: 26.89636993408203\n",
      "        mean_q: 8.323863983154297\n",
      "        min_q: 2.9766685962677\n",
      "    learner_queue:\n",
      "      size_count: 236757\n",
      "      size_mean: 15.28\n",
      "      size_quantiles:\n",
      "      - 8.0\n",
      "      - 12.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 1.887220177933672\n",
      "    num_agent_steps_sampled: 550028\n",
      "    num_steps_sampled: 550028\n",
      "    num_steps_trained: 236748000\n",
      "    num_target_updates: 39458\n",
      "    num_weight_syncs: 1374\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.782\n",
      "      policy_default_policy:\n",
      "        added_count: 138344\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 59154000\n",
      "      replay_time_ms: 84.195\n",
      "      update_priorities_time_ms: 76.864\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.41800947867299\n",
      "    ram_util_percent: 78.66279620853084\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002152288755834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.31572405438162\n",
      "    mean_inference_ms: 1.8664852344368492\n",
      "    mean_raw_obs_processing_ms: 3.3773240412749237\n",
      "  time_since_restore: 12883.201881170273\n",
      "  time_this_iter_s: 593.8424234390259\n",
      "  time_total_s: 12883.201881170273\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 33828.115\n",
      "    learner_grad_time_ms: 29.561\n",
      "    learner_overall_throughput: 33784.899\n",
      "    learner_overall_time_ms: 29.599\n",
      "  timestamp: 1634732652\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 550028\n",
      "  training_iteration: 22\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         12883.2</td><td style=\"text-align: right;\">550028</td><td style=\"text-align: right;\">   2.062</td><td style=\"text-align: right;\">                6.32</td><td style=\"text-align: right;\">               -3.53</td><td style=\"text-align: right;\">            192.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 575028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_12-34-29\n",
      "  done: false\n",
      "  episode_len_mean: 180.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.820000000000023\n",
      "  episode_reward_mean: 2.7562000000000206\n",
      "  episode_reward_min: -5.439999999999923\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 1501\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 574979\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 574823\n",
      "    last_target_update_ts: 248010000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.7458610534667969\n",
      "        max_q: 32.39504623413086\n",
      "        mean_q: 8.327836036682129\n",
      "        min_q: 3.284803867340088\n",
      "    learner_queue:\n",
      "      size_count: 248019\n",
      "      size_mean: 15.28\n",
      "      size_quantiles:\n",
      "      - 8.0\n",
      "      - 12.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 1.887220177933672\n",
      "    num_agent_steps_sampled: 575028\n",
      "    num_steps_sampled: 575028\n",
      "    num_steps_trained: 248010000\n",
      "    num_target_updates: 41335\n",
      "    num_weight_syncs: 1437\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.332\n",
      "      policy_default_policy:\n",
      "        added_count: 144704\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 61981000\n",
      "      replay_time_ms: 86.255\n",
      "      update_priorities_time_ms: 77.058\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.33949771689497\n",
      "    ram_util_percent: 78.7170091324201\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04998082665408788\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.39882090136303\n",
      "    mean_inference_ms: 1.86570882328227\n",
      "    mean_raw_obs_processing_ms: 3.4279591736254487\n",
      "  time_since_restore: 13500.30367565155\n",
      "  time_this_iter_s: 617.1017944812775\n",
      "  time_total_s: 13500.30367565155\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.013\n",
      "    learner_grad_throughput: 21722.837\n",
      "    learner_grad_time_ms: 46.035\n",
      "    learner_overall_throughput: 21704.716\n",
      "    learner_overall_time_ms: 46.073\n",
      "  timestamp: 1634733269\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 575028\n",
      "  training_iteration: 23\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         13500.3</td><td style=\"text-align: right;\">575028</td><td style=\"text-align: right;\">  2.7562</td><td style=\"text-align: right;\">                7.82</td><td style=\"text-align: right;\">               -5.44</td><td style=\"text-align: right;\">            180.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 600028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_12-45-12\n",
      "  done: false\n",
      "  episode_len_mean: 157.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.8600000000000225\n",
      "  episode_reward_mean: 2.5267000000000173\n",
      "  episode_reward_min: -3.5699999999999745\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 1572\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 599767\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 599887\n",
      "    last_target_update_ts: 260010000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.4628368616104126\n",
      "        max_q: 25.50403594970703\n",
      "        mean_q: 8.805436134338379\n",
      "        min_q: 3.9942331314086914\n",
      "    learner_queue:\n",
      "      size_count: 260027\n",
      "      size_mean: 12.58\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 4.9\n",
      "      - 15.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 4.386752785375533\n",
      "    num_agent_steps_sampled: 600028\n",
      "    num_steps_sampled: 600028\n",
      "    num_steps_trained: 260012000\n",
      "    num_target_updates: 43335\n",
      "    num_weight_syncs: 1499\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.508\n",
      "      policy_default_policy:\n",
      "        added_count: 150796\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 65036000\n",
      "      replay_time_ms: 83.447\n",
      "      update_priorities_time_ms: 71.707\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.42636761487967\n",
      "    ram_util_percent: 78.69792122538293\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05001481344694616\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.669456374264776\n",
      "    mean_inference_ms: 1.8640736759300907\n",
      "    mean_raw_obs_processing_ms: 3.4596338754098492\n",
      "  time_since_restore: 14143.395158052444\n",
      "  time_this_iter_s: 643.0914824008942\n",
      "  time_total_s: 14143.395158052444\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 24759.764\n",
      "    learner_grad_time_ms: 40.388\n",
      "    learner_overall_throughput: 24738.662\n",
      "    learner_overall_time_ms: 40.423\n",
      "  timestamp: 1634733912\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600028\n",
      "  training_iteration: 24\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         14143.4</td><td style=\"text-align: right;\">600028</td><td style=\"text-align: right;\">  2.5267</td><td style=\"text-align: right;\">                7.86</td><td style=\"text-align: right;\">               -3.57</td><td style=\"text-align: right;\">            157.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 625028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_12-55-27\n",
      "  done: false\n",
      "  episode_len_mean: 175.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.850000000000023\n",
      "  episode_reward_mean: 2.568800000000019\n",
      "  episode_reward_min: -4.349999999999984\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 1639\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 116.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 5.270000000000014\n",
      "    episode_reward_mean: 5.270000000000014\n",
      "    episode_reward_min: 5.270000000000014\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 116\n",
      "      episode_reward:\n",
      "      - 5.270000000000014\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.03957912516336056\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 58.09801916574423\n",
      "      mean_inference_ms: 1.4514536280899273\n",
      "      mean_raw_obs_processing_ms: 0.7215973901889317\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 624791\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 624599\n",
      "    last_target_update_ts: 271308000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.742940366268158\n",
      "        max_q: 24.87534523010254\n",
      "        mean_q: 8.793967247009277\n",
      "        min_q: 3.1405515670776367\n",
      "    learner_queue:\n",
      "      size_count: 271323\n",
      "      size_mean: 14.9\n",
      "      size_quantiles:\n",
      "      - 6.0\n",
      "      - 10.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 2.5475478405713994\n",
      "    num_agent_steps_sampled: 625028\n",
      "    num_steps_sampled: 625028\n",
      "    num_steps_trained: 271312000\n",
      "    num_target_updates: 45218\n",
      "    num_weight_syncs: 1561\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.383\n",
      "      policy_default_policy:\n",
      "        added_count: 157008\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 67897000\n",
      "      replay_time_ms: 82.268\n",
      "      update_priorities_time_ms: 70.556\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.31972477064221\n",
      "    ram_util_percent: 78.74529816513763\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003668547703638\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.816271951697935\n",
      "    mean_inference_ms: 1.8632960812759602\n",
      "    mean_raw_obs_processing_ms: 3.4653405489900084\n",
      "  time_since_restore: 14757.815508127213\n",
      "  time_this_iter_s: 614.4203500747681\n",
      "  time_total_s: 14757.815508127213\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 22719.982\n",
      "    learner_grad_time_ms: 44.014\n",
      "    learner_overall_throughput: 22680.912\n",
      "    learner_overall_time_ms: 44.09\n",
      "  timestamp: 1634734527\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 625028\n",
      "  training_iteration: 25\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         14757.8</td><td style=\"text-align: right;\">625028</td><td style=\"text-align: right;\">  2.5688</td><td style=\"text-align: right;\">                5.85</td><td style=\"text-align: right;\">               -4.35</td><td style=\"text-align: right;\">            175.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 650028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_13-05-32\n",
      "  done: false\n",
      "  episode_len_mean: 195.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.940000000000021\n",
      "  episode_reward_mean: 2.564000000000023\n",
      "  episode_reward_min: -3.439999999999993\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 1705\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 649895\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 649735\n",
      "    last_target_update_ts: 282336000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.324009895324707\n",
      "        max_q: 33.8082389831543\n",
      "        mean_q: 9.101675987243652\n",
      "        min_q: 3.467761278152466\n",
      "    learner_queue:\n",
      "      size_count: 282345\n",
      "      size_mean: 15.28\n",
      "      size_quantiles:\n",
      "      - 8.0\n",
      "      - 12.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 1.8872201779336721\n",
      "    num_agent_steps_sampled: 650028\n",
      "    num_steps_sampled: 650028\n",
      "    num_steps_trained: 282336000\n",
      "    num_target_updates: 47056\n",
      "    num_weight_syncs: 1624\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.52\n",
      "      policy_default_policy:\n",
      "        added_count: 163196\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 70664000\n",
      "      replay_time_ms: 83.588\n",
      "      update_priorities_time_ms: 75.073\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.41827706635621\n",
      "    ram_util_percent: 78.57497089639116\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050028497545106576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.849150327623136\n",
      "    mean_inference_ms: 1.8633462300474344\n",
      "    mean_raw_obs_processing_ms: 3.4599761214940816\n",
      "  time_since_restore: 15362.656734466553\n",
      "  time_this_iter_s: 604.8412263393402\n",
      "  time_total_s: 15362.656734466553\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.013\n",
      "    learner_grad_throughput: 28521.408\n",
      "    learner_grad_time_ms: 35.061\n",
      "    learner_overall_throughput: 28485.921\n",
      "    learner_overall_time_ms: 35.105\n",
      "  timestamp: 1634735132\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 650028\n",
      "  training_iteration: 26\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         15362.7</td><td style=\"text-align: right;\">650028</td><td style=\"text-align: right;\">   2.564</td><td style=\"text-align: right;\">                5.94</td><td style=\"text-align: right;\">               -3.44</td><td style=\"text-align: right;\">            195.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 675028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_13-16-12\n",
      "  done: false\n",
      "  episode_len_mean: 179.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.320000000000013\n",
      "  episode_reward_mean: 2.7885000000000217\n",
      "  episode_reward_min: -2.3999999999999835\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 1776\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 674415\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 674851\n",
      "    last_target_update_ts: 293880000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.7001587748527527\n",
      "        max_q: 38.86638641357422\n",
      "        mean_q: 9.934392929077148\n",
      "        min_q: 4.782171249389648\n",
      "    learner_queue:\n",
      "      size_count: 293892\n",
      "      size_mean: 14.9\n",
      "      size_quantiles:\n",
      "      - 6.0\n",
      "      - 10.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 2.5475478405713994\n",
      "    num_agent_steps_sampled: 675028\n",
      "    num_steps_sampled: 675028\n",
      "    num_steps_trained: 293881000\n",
      "    num_target_updates: 48980\n",
      "    num_weight_syncs: 1686\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.576\n",
      "      policy_default_policy:\n",
      "        added_count: 169416\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 73556000\n",
      "      replay_time_ms: 87.981\n",
      "      update_priorities_time_ms: 66.876\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.38930540242559\n",
      "    ram_util_percent: 78.63175303197355\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05004158898037511\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.98608371746536\n",
      "    mean_inference_ms: 1.8629350803794886\n",
      "    mean_raw_obs_processing_ms: 3.4529216353625687\n",
      "  time_since_restore: 16003.170273065567\n",
      "  time_this_iter_s: 640.5135385990143\n",
      "  time_total_s: 16003.170273065567\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 19652.586\n",
      "    learner_grad_time_ms: 50.884\n",
      "    learner_overall_throughput: 19639.703\n",
      "    learner_overall_time_ms: 50.917\n",
      "  timestamp: 1634735772\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 675028\n",
      "  training_iteration: 27\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         16003.2</td><td style=\"text-align: right;\">675028</td><td style=\"text-align: right;\">  2.7885</td><td style=\"text-align: right;\">                6.32</td><td style=\"text-align: right;\">                -2.4</td><td style=\"text-align: right;\">            179.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 700028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_13-26-58\n",
      "  done: false\n",
      "  episode_len_mean: 171.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.97000000000002\n",
      "  episode_reward_mean: 3.1793000000000236\n",
      "  episode_reward_min: -3.2299999999999907\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 1849\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 698943\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 699971\n",
      "    last_target_update_ts: 305652000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.2548389434814453\n",
      "        max_q: 56.63157653808594\n",
      "        mean_q: 9.673287391662598\n",
      "        min_q: 4.732296943664551\n",
      "    learner_queue:\n",
      "      size_count: 305665\n",
      "      size_mean: 15.28\n",
      "      size_quantiles:\n",
      "      - 8.0\n",
      "      - 12.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 1.887220177933672\n",
      "    num_agent_steps_sampled: 700028\n",
      "    num_steps_sampled: 700028\n",
      "    num_steps_trained: 305656000\n",
      "    num_target_updates: 50942\n",
      "    num_weight_syncs: 1749\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 1.539\n",
      "      policy_default_policy:\n",
      "        added_count: 175624\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 76509000\n",
      "      replay_time_ms: 93.343\n",
      "      update_priorities_time_ms: 74.434\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.34907306434025\n",
      "    ram_util_percent: 78.69574700109052\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04997469098156818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.142541413957744\n",
      "    mean_inference_ms: 1.8620738915451318\n",
      "    mean_raw_obs_processing_ms: 3.4513470759865252\n",
      "  time_since_restore: 16649.242387771606\n",
      "  time_this_iter_s: 646.0721147060394\n",
      "  time_total_s: 16649.242387771606\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.012\n",
      "    learner_grad_throughput: 19209.394\n",
      "    learner_grad_time_ms: 52.058\n",
      "    learner_overall_throughput: 19196.022\n",
      "    learner_overall_time_ms: 52.094\n",
      "  timestamp: 1634736418\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 700028\n",
      "  training_iteration: 28\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         16649.2</td><td style=\"text-align: right;\">700028</td><td style=\"text-align: right;\">  3.1793</td><td style=\"text-align: right;\">                5.97</td><td style=\"text-align: right;\">               -3.23</td><td style=\"text-align: right;\">            171.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 725028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_13-37-43\n",
      "  done: false\n",
      "  episode_len_mean: 178.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.930000000000021\n",
      "  episode_reward_mean: 2.5554000000000228\n",
      "  episode_reward_min: -1.6100000000000012\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 1917\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 725015\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 724779\n",
      "    last_target_update_ts: 317256000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.9419304132461548\n",
      "        max_q: 61.5631103515625\n",
      "        mean_q: 10.556578636169434\n",
      "        min_q: 4.406432628631592\n",
      "    learner_queue:\n",
      "      size_count: 317271\n",
      "      size_mean: 14.44\n",
      "      size_quantiles:\n",
      "      - 4.0\n",
      "      - 8.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 3.250599944625607\n",
      "    num_agent_steps_sampled: 725028\n",
      "    num_steps_sampled: 725028\n",
      "    num_steps_trained: 317258000\n",
      "    num_target_updates: 52876\n",
      "    num_weight_syncs: 1812\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.462\n",
      "      policy_default_policy:\n",
      "        added_count: 181996\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 79426000\n",
      "      replay_time_ms: 85.554\n",
      "      update_priorities_time_ms: 74.62\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.38630887185106\n",
      "    ram_util_percent: 78.76243154435926\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04988989011837271\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.336150943376445\n",
      "    mean_inference_ms: 1.8610849775378728\n",
      "    mean_raw_obs_processing_ms: 3.448371532019672\n",
      "  time_since_restore: 17293.46602320671\n",
      "  time_this_iter_s: 644.2236354351044\n",
      "  time_total_s: 17293.46602320671\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.013\n",
      "    learner_grad_throughput: 34027.358\n",
      "    learner_grad_time_ms: 29.388\n",
      "    learner_overall_throughput: 33984.237\n",
      "    learner_overall_time_ms: 29.425\n",
      "  timestamp: 1634737063\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 725028\n",
      "  training_iteration: 29\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         17293.5</td><td style=\"text-align: right;\">725028</td><td style=\"text-align: right;\">  2.5554</td><td style=\"text-align: right;\">                5.93</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">            178.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 750028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_13-48-21\n",
      "  done: false\n",
      "  episode_len_mean: 170.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.950000000000021\n",
      "  episode_reward_mean: 2.806300000000023\n",
      "  episode_reward_min: -2.070000000000001\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 1984\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 456.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 0.5600000000000609\n",
      "    episode_reward_mean: 0.5600000000000609\n",
      "    episode_reward_min: 0.5600000000000609\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 456\n",
      "      episode_reward:\n",
      "      - 0.5600000000000609\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.039188212791593076\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 42.99895616105359\n",
      "      mean_inference_ms: 1.45492145825792\n",
      "      mean_raw_obs_processing_ms: 0.6607061167274781\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 749895\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 749787\n",
      "    last_target_update_ts: 328866000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.9297414422035217\n",
      "        max_q: 40.40980529785156\n",
      "        mean_q: 9.477090835571289\n",
      "        min_q: 4.523705959320068\n",
      "    learner_queue:\n",
      "      size_count: 328872\n",
      "      size_mean: 15.8\n",
      "      size_quantiles:\n",
      "      - 12.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 0.7483314773547883\n",
      "    num_agent_steps_sampled: 750028\n",
      "    num_steps_sampled: 750028\n",
      "    num_steps_trained: 328867000\n",
      "    num_target_updates: 54811\n",
      "    num_weight_syncs: 1874\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.344\n",
      "      policy_default_policy:\n",
      "        added_count: 188168\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 82351000\n",
      "      replay_time_ms: 84.405\n",
      "      update_priorities_time_ms: 76.848\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.28333333333335\n",
      "    ram_util_percent: 78.76909492273731\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04989586336817555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.46163481971902\n",
      "    mean_inference_ms: 1.8598314272968326\n",
      "    mean_raw_obs_processing_ms: 3.4792059522910765\n",
      "  time_since_restore: 17931.982268333435\n",
      "  time_this_iter_s: 638.5162451267242\n",
      "  time_total_s: 17931.982268333435\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 19688.148\n",
      "    learner_grad_time_ms: 50.792\n",
      "    learner_overall_throughput: 19675.08\n",
      "    learner_overall_time_ms: 50.826\n",
      "  timestamp: 1634737701\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 750028\n",
      "  training_iteration: 30\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">           17932</td><td style=\"text-align: right;\">750028</td><td style=\"text-align: right;\">  2.8063</td><td style=\"text-align: right;\">                5.95</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">            170.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 775028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_13-59-00\n",
      "  done: false\n",
      "  episode_len_mean: 180.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.210000000000015\n",
      "  episode_reward_mean: 2.996400000000022\n",
      "  episode_reward_min: -2.070000000000001\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 2055\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 774479\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 774847\n",
      "    last_target_update_ts: 340824000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.5437505841255188\n",
      "        max_q: 43.6215705871582\n",
      "        mean_q: 10.890299797058105\n",
      "        min_q: 3.178647041320801\n",
      "    learner_queue:\n",
      "      size_count: 340827\n",
      "      size_mean: 3.6\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 2.0\n",
      "      - 4.0\n",
      "      - 5.0\n",
      "      - 6.0\n",
      "      size_std: 1.296148139681572\n",
      "    num_agent_steps_sampled: 775028\n",
      "    num_steps_sampled: 775028\n",
      "    num_steps_trained: 340824000\n",
      "    num_target_updates: 56804\n",
      "    num_weight_syncs: 1936\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.455\n",
      "      policy_default_policy:\n",
      "        added_count: 194360\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 85372000\n",
      "      replay_time_ms: 68.046\n",
      "      update_priorities_time_ms: 65.855\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.39361233480176\n",
      "    ram_util_percent: 78.78149779735682\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986289029050472\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.60771642813291\n",
      "    mean_inference_ms: 1.8588421267500796\n",
      "    mean_raw_obs_processing_ms: 3.4953002669515194\n",
      "  time_since_restore: 18571.163435935974\n",
      "  time_this_iter_s: 639.1811676025391\n",
      "  time_total_s: 18571.163435935974\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.104\n",
      "    learner_grad_throughput: 20753.658\n",
      "    learner_grad_time_ms: 48.184\n",
      "    learner_overall_throughput: 20699.181\n",
      "    learner_overall_time_ms: 48.311\n",
      "  timestamp: 1634738340\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 775028\n",
      "  training_iteration: 31\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         18571.2</td><td style=\"text-align: right;\">775028</td><td style=\"text-align: right;\">  2.9964</td><td style=\"text-align: right;\">                6.21</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">            180.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 800028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_14-10-18\n",
      "  done: false\n",
      "  episode_len_mean: 154.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.100000000000017\n",
      "  episode_reward_mean: 2.8432000000000186\n",
      "  episode_reward_min: -3.2899999999999814\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 2130\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 799775\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 799871\n",
      "    last_target_update_ts: 353466000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.7959231734275818\n",
      "        max_q: 46.343502044677734\n",
      "        mean_q: 11.150803565979004\n",
      "        min_q: 4.781230926513672\n",
      "    learner_queue:\n",
      "      size_count: 353471\n",
      "      size_mean: 4.86\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 3.0\n",
      "      - 5.0\n",
      "      - 6.100000000000001\n",
      "      - 7.0\n",
      "      size_std: 1.5621779668142808\n",
      "    num_agent_steps_sampled: 800028\n",
      "    num_steps_sampled: 800028\n",
      "    num_steps_trained: 353467000\n",
      "    num_target_updates: 58911\n",
      "    num_weight_syncs: 1999\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.497\n",
      "      policy_default_policy:\n",
      "        added_count: 200552\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 88575000\n",
      "      replay_time_ms: 73.291\n",
      "      update_priorities_time_ms: 61.173\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.41609553478713\n",
      "    ram_util_percent: 78.8159916926272\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04978842730806079\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.880993139790306\n",
      "    mean_inference_ms: 1.858074612789356\n",
      "    mean_raw_obs_processing_ms: 3.4948973325724575\n",
      "  time_since_restore: 19249.0324947834\n",
      "  time_this_iter_s: 677.8690588474274\n",
      "  time_total_s: 19249.0324947834\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 24317.033\n",
      "    learner_grad_time_ms: 41.123\n",
      "    learner_overall_throughput: 24286.816\n",
      "    learner_overall_time_ms: 41.175\n",
      "  timestamp: 1634739018\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 800028\n",
      "  training_iteration: 32\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">           19249</td><td style=\"text-align: right;\">800028</td><td style=\"text-align: right;\">  2.8432</td><td style=\"text-align: right;\">                 8.1</td><td style=\"text-align: right;\">               -3.29</td><td style=\"text-align: right;\">             154.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 825028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_14-20-51\n",
      "  done: false\n",
      "  episode_len_mean: 171.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.100000000000017\n",
      "  episode_reward_mean: 2.567000000000019\n",
      "  episode_reward_min: -3.2899999999999814\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 2199\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 824751\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 824703\n",
      "    last_target_update_ts: 365256000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 0.9530483484268188\n",
      "        max_q: 48.00981521606445\n",
      "        mean_q: 11.326390266418457\n",
      "        min_q: 3.620976686477661\n",
      "    learner_queue:\n",
      "      size_count: 365276\n",
      "      size_mean: 13.14\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 4.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 4.677648982127667\n",
      "    num_agent_steps_sampled: 825028\n",
      "    num_steps_sampled: 825028\n",
      "    num_steps_trained: 365260000\n",
      "    num_target_updates: 60876\n",
      "    num_weight_syncs: 2061\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.628\n",
      "      policy_default_policy:\n",
      "        added_count: 207196\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 91548000\n",
      "      replay_time_ms: 76.347\n",
      "      update_priorities_time_ms: 70.668\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.37764182424917\n",
      "    ram_util_percent: 78.853170189099\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04971218398036388\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.9935401102467\n",
      "    mean_inference_ms: 1.8571702686188019\n",
      "    mean_raw_obs_processing_ms: 3.4919462948057998\n",
      "  time_since_restore: 19882.09700870514\n",
      "  time_this_iter_s: 633.0645139217377\n",
      "  time_total_s: 19882.09700870514\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.013\n",
      "    learner_grad_throughput: 24456.925\n",
      "    learner_grad_time_ms: 40.888\n",
      "    learner_overall_throughput: 24434.186\n",
      "    learner_overall_time_ms: 40.926\n",
      "  timestamp: 1634739651\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 825028\n",
      "  training_iteration: 33\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         19882.1</td><td style=\"text-align: right;\">825028</td><td style=\"text-align: right;\">   2.567</td><td style=\"text-align: right;\">                 8.1</td><td style=\"text-align: right;\">               -3.29</td><td style=\"text-align: right;\">            171.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 850028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_14-32-09\n",
      "  done: false\n",
      "  episode_len_mean: 161.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.360000000000012\n",
      "  episode_reward_mean: 2.383500000000016\n",
      "  episode_reward_min: -3.009999999999959\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 2274\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 849919\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 849835\n",
      "    last_target_update_ts: 377760000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 2.3055105209350586\n",
      "        max_q: 58.27530288696289\n",
      "        mean_q: 11.255085945129395\n",
      "        min_q: 2.85054349899292\n",
      "    learner_queue:\n",
      "      size_count: 377774\n",
      "      size_mean: 14.18\n",
      "      size_quantiles:\n",
      "      - 3.0\n",
      "      - 7.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 3.6149135535998647\n",
      "    num_agent_steps_sampled: 850028\n",
      "    num_steps_sampled: 850028\n",
      "    num_steps_trained: 377760000\n",
      "    num_target_updates: 62960\n",
      "    num_weight_syncs: 2124\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.373\n",
      "      policy_default_policy:\n",
      "        added_count: 213308\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 94699000\n",
      "      replay_time_ms: 85.521\n",
      "      update_priorities_time_ms: 74.156\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.37089397089397\n",
      "    ram_util_percent: 78.88419958419959\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04968245935734293\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 43.21952086513037\n",
      "    mean_inference_ms: 1.8560666826664676\n",
      "    mean_raw_obs_processing_ms: 3.4914409839670895\n",
      "  time_since_restore: 20560.13687467575\n",
      "  time_this_iter_s: 678.0398659706116\n",
      "  time_total_s: 20560.13687467575\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.01\n",
      "    learner_grad_throughput: 30288.288\n",
      "    learner_grad_time_ms: 33.016\n",
      "    learner_overall_throughput: 30252.09\n",
      "    learner_overall_time_ms: 33.056\n",
      "  timestamp: 1634740329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 850028\n",
      "  training_iteration: 34\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         20560.1</td><td style=\"text-align: right;\">850028</td><td style=\"text-align: right;\">  2.3835</td><td style=\"text-align: right;\">                7.36</td><td style=\"text-align: right;\">               -3.01</td><td style=\"text-align: right;\">            161.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 875028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_14-43-42\n",
      "  done: false\n",
      "  episode_len_mean: 156.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.680000000000005\n",
      "  episode_reward_mean: 2.719500000000016\n",
      "  episode_reward_min: -2.809999999999994\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2346\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 496.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -2.949999999999983\n",
      "    episode_reward_mean: -2.949999999999983\n",
      "    episode_reward_min: -2.949999999999983\n",
      "    episodes_this_iter: 1\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 496\n",
      "      episode_reward:\n",
      "      - -2.949999999999983\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.03886779835528077\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 34.325094256926576\n",
      "      mean_inference_ms: 1.4524114743412417\n",
      "      mean_raw_obs_processing_ms: 0.6329584630265824\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 874931\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 874883\n",
      "    last_target_update_ts: 390234000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.456257939338684\n",
      "        max_q: 57.626895904541016\n",
      "        mean_q: 10.618064880371094\n",
      "        min_q: 2.144247531890869\n",
      "    learner_queue:\n",
      "      size_count: 390240\n",
      "      size_mean: 15.8\n",
      "      size_quantiles:\n",
      "      - 12.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 0.7483314773547883\n",
      "    num_agent_steps_sampled: 875028\n",
      "    num_steps_sampled: 875028\n",
      "    num_steps_trained: 390235000\n",
      "    num_target_updates: 65039\n",
      "    num_weight_syncs: 2187\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.526\n",
      "      policy_default_policy:\n",
      "        added_count: 219580\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 97838000\n",
      "      replay_time_ms: 101.602\n",
      "      update_priorities_time_ms: 65.645\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.34658511722732\n",
      "    ram_util_percent: 78.81355759429155\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049621056628238146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 43.492570108234965\n",
      "    mean_inference_ms: 1.8553065013084378\n",
      "    mean_raw_obs_processing_ms: 3.5287080730280467\n",
      "  time_since_restore: 21252.402523994446\n",
      "  time_this_iter_s: 692.2656493186951\n",
      "  time_total_s: 21252.402523994446\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 21088.869\n",
      "    learner_grad_time_ms: 47.418\n",
      "    learner_overall_throughput: 21073.452\n",
      "    learner_overall_time_ms: 47.453\n",
      "  timestamp: 1634741022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 875028\n",
      "  training_iteration: 35\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         21252.4</td><td style=\"text-align: right;\">875028</td><td style=\"text-align: right;\">  2.7195</td><td style=\"text-align: right;\">                7.68</td><td style=\"text-align: right;\">               -2.81</td><td style=\"text-align: right;\">            156.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 900028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_14-54-25\n",
      "  done: false\n",
      "  episode_len_mean: 161.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.160000000000016\n",
      "  episode_reward_mean: 2.4632000000000147\n",
      "  episode_reward_min: -1.8800000000000012\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 2417\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 899931\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 899595\n",
      "    last_target_update_ts: 402090000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 2.2668983936309814\n",
      "        max_q: 61.24565124511719\n",
      "        mean_q: 10.856223106384277\n",
      "        min_q: 3.101163625717163\n",
      "    learner_queue:\n",
      "      size_count: 402105\n",
      "      size_mean: 15.1\n",
      "      size_quantiles:\n",
      "      - 7.0\n",
      "      - 11.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 2.2113344387495983\n",
      "    num_agent_steps_sampled: 900028\n",
      "    num_steps_sampled: 900028\n",
      "    num_steps_trained: 402095000\n",
      "    num_target_updates: 67015\n",
      "    num_weight_syncs: 2249\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.553\n",
      "      policy_default_policy:\n",
      "        added_count: 225792\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 100842000\n",
      "      replay_time_ms: 87.527\n",
      "      update_priorities_time_ms: 72.494\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.39364731653887\n",
      "    ram_util_percent: 78.70492880613364\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049601993396156854\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 43.64397873772874\n",
      "    mean_inference_ms: 1.854913863757002\n",
      "    mean_raw_obs_processing_ms: 3.539460056078939\n",
      "  time_since_restore: 21895.72233223915\n",
      "  time_this_iter_s: 643.3198082447052\n",
      "  time_total_s: 21895.72233223915\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.011\n",
      "    learner_grad_throughput: 28425.36\n",
      "    learner_grad_time_ms: 35.18\n",
      "    learner_overall_throughput: 28395.416\n",
      "    learner_overall_time_ms: 35.217\n",
      "  timestamp: 1634741665\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 900028\n",
      "  training_iteration: 36\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 37.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         21895.7</td><td style=\"text-align: right;\">900028</td><td style=\"text-align: right;\">  2.4632</td><td style=\"text-align: right;\">                7.16</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">            161.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_9a6b4_00000:\n",
      "  agent_timesteps_total: 925028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-20_15-05-27\n",
      "  done: false\n",
      "  episode_len_mean: 158.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.060000000000018\n",
      "  episode_reward_mean: 2.8365000000000147\n",
      "  episode_reward_min: -2.3099999999999743\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2489\n",
      "  experiment_id: 6c20111047d54658a08015ab604d7e9f\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 924419\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 924787\n",
      "    last_target_update_ts: 414144000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 1.0e-05\n",
      "        grad_gnorm: 1.6672449111938477\n",
      "        max_q: 38.29267120361328\n",
      "        mean_q: 11.324572563171387\n",
      "        min_q: 3.3063716888427734\n",
      "    learner_queue:\n",
      "      size_count: 414160\n",
      "      size_mean: 14.68\n",
      "      size_quantiles:\n",
      "      - 5.0\n",
      "      - 9.9\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      size_std: 2.894408402420087\n",
      "    num_agent_steps_sampled: 925028\n",
      "    num_steps_sampled: 925028\n",
      "    num_steps_trained: 414148000\n",
      "    num_target_updates: 69024\n",
      "    num_weight_syncs: 2311\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.46\n",
      "      policy_default_policy:\n",
      "        added_count: 232292\n",
      "        est_size_bytes: 1539072932\n",
      "        num_entries: 62500\n",
      "        sampled_count: 103881000\n",
      "      replay_time_ms: 93.794\n",
      "      update_priorities_time_ms: 80.972\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.43642172523964\n",
      "    ram_util_percent: 78.64206602768904\n",
      "  pid: 162\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04956624579944239\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 43.77976721486934\n",
      "    mean_inference_ms: 1.8551330785187856\n",
      "    mean_raw_obs_processing_ms: 3.540058606681778\n",
      "  time_since_restore: 22557.42398428917\n",
      "  time_this_iter_s: 661.7016520500183\n",
      "  time_total_s: 22557.42398428917\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 0.009\n",
      "    learner_grad_throughput: 19660.932\n",
      "    learner_grad_time_ms: 50.862\n",
      "    learner_overall_throughput: 19648.204\n",
      "    learner_overall_time_ms: 50.895\n",
      "  timestamp: 1634742327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 925028\n",
      "  training_iteration: 37\n",
      "  trial_id: 9a6b4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 36.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.89 GiB heap, 0.0/13.94 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-20_08-49-14<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_9a6b4_00000</td><td>RUNNING </td><td>192.168.3.5:162</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         22557.4</td><td style=\"text-align: right;\">925028</td><td style=\"text-align: right;\">  2.8365</td><td style=\"text-align: right;\">                7.06</td><td style=\"text-align: right;\">               -2.31</td><td style=\"text-align: right;\">            158.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(ApexTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             #\"gamma\": 0.99,\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 2,\n",
    "             \"buffer_size\": 250_000,\n",
    "             \"learning_starts\": 10_000,\n",
    "             \"train_batch_size\": 1000,\n",
    "             \"target_network_update_freq\": 5000,\n",
    "             #\"prioritized_replay_alpha\": 0.5,\n",
    "             #\"final_prioritized_replay_beta\": 1.0,\n",
    "             \"min_iter_time_s\": 30, \n",
    "             \"rollout_fragment_length\": 4,\n",
    "             \"collect_metrics_timeout\": 1800,\n",
    "             \n",
    "             \"v_min\": -10.0,\n",
    "             \"v_max\": 100.0,\n",
    "             \n",
    "             \"exploration_config\": {\n",
    "                  \"initial_epsilon\": 1,\n",
    "                  \"epsilon_timesteps\": 100_000,\n",
    "                  \"final_epsilon\": 0.05,\n",
    "              },\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"APEX C8 pretrained (AnnaCNN) r: -0.01\"\n",
    "                  }\n",
    "              },\n",
    "              #\"training_intensity\": 50,\n",
    "              \"lr\": 1e-5,\n",
    "             \n",
    "              \"evaluation_num_workers\": 1,\n",
    "              \"evaluation_interval\": 5,\n",
    "              \"evaluation_num_episodes\": 1,\n",
    "              \"evaluation_config\": {\n",
    "                  #\"input\": \"sampler\",\n",
    "                  \"explore\": False,  \n",
    "              },\n",
    "        },\n",
    "        loggers=[WandbLogger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebfaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
