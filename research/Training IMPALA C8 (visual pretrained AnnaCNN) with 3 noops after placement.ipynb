{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import impala\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4, padding=0),  \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(64, 512, kernel_size=2, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        features_dim = 512\n",
    "        self.encoder = VisualEncoder()\n",
    "        self.encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AnnaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.action_head = nn.Linear(features_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(features_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.encoder.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        if self.use_cuda:\n",
    "            obs.cuda()\n",
    "            \n",
    "        features = self.encoder(obs)\n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=1000)\n",
    "    env.update_taskset(TaskSet(preset=['C32']))\n",
    "    env = PovOnlyWrapper(env)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.impala import ImpalaTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-10-07 22:37:07,796\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-10-07 22:37:07,809\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 3.2/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/8.05 GiB heap, 0.0/4.03 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/IMPALA_2021-10-07_22-37-07<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_my_env_1a598_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=11153)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11153)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">IMPALA C32 pretrained (AnnaCNN) (3 noops after placement)</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/1a598_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/1a598_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211007_223708-1a598_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11153)\u001b[0m 2021-10-07 22:37:11,275\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=11152)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11152)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=11148)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11148)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=11153)\u001b[0m 2021-10-07 22:37:18,655\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=11152)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11152)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=11148)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11148)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=11152)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11152)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=11152)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=11152)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=11148)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11148)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=11148)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=11148)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_my_env_1a598_00000:\n",
      "  agent_timesteps_total: 2500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-07_22-42-44\n",
      "  done: false\n",
      "  episode_len_mean: 441.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: 0.0\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 5\n",
      "  experiment_id: a24d0318e6224d569c66a7bb0a3b8f0b\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy: {}\n",
      "    learner_queue:\n",
      "      size_count: 1\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_agent_steps_sampled: 2500\n",
      "    num_steps_sampled: 2500\n",
      "    num_steps_trained: 1\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 145350.868\n",
      "      learner_grad_time_ms: 93.857\n",
      "      learner_load_time_ms: 22.654\n",
      "      learner_load_wait_time_ms: 145372.356\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.84043010752687\n",
      "    ram_util_percent: 71.61655913978494\n",
      "  pid: 11153\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.038493116593447556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 100.40187158188414\n",
      "    mean_inference_ms: 1.4061373163711424\n",
      "    mean_raw_obs_processing_ms: 0.23714461951615146\n",
      "  time_since_restore: 325.4792366027832\n",
      "  time_this_iter_s: 325.4792366027832\n",
      "  time_total_s: 325.4792366027832\n",
      "  timers:\n",
      "    sample_throughput: 34.401\n",
      "    sample_time_ms: 145346.611\n",
      "  timestamp: 1633646564\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2500\n",
      "  training_iteration: 1\n",
      "  trial_id: 1a598_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/8.05 GiB heap, 0.0/4.03 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/IMPALA_2021-10-07_22-37-07<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_my_env_1a598_00000</td><td>RUNNING </td><td>192.168.3.5:11153</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         325.479</td><td style=\"text-align: right;\">2500</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">             441.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m Failed to take a step (error timed out). Terminating episode and sending random observation, be aware. To account for this failure case in your code check to see if `'error' in info` where info is the info dictionary returned by the step function.\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_my_env_1a598_00000:\n",
      "  agent_timesteps_total: 5000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-07_22-46-15\n",
      "  done: false\n",
      "  episode_len_mean: 439.1818181818182\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: 0.0\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 11\n",
      "  experiment_id: a24d0318e6224d569c66a7bb0a3b8f0b\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy: {}\n",
      "    learner_queue:\n",
      "      size_count: 3\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_agent_steps_sampled: 5000\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 2\n",
      "    num_weight_broadcasts: 1\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 145350.868\n",
      "      learner_grad_time_ms: 96.527\n",
      "      learner_load_time_ms: 22.654\n",
      "      learner_load_wait_time_ms: 118753.925\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.2016611295681\n",
      "    ram_util_percent: 81.39999999999998\n",
      "  pid: 11153\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03852748408536307\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 82.48068823696008\n",
      "    mean_inference_ms: 1.3960875462262154\n",
      "    mean_raw_obs_processing_ms: 0.236213271631919\n",
      "  time_since_restore: 536.4432215690613\n",
      "  time_this_iter_s: 210.96398496627808\n",
      "  time_total_s: 536.4432215690613\n",
      "  timers:\n",
      "    sample_throughput: 28.066\n",
      "    sample_time_ms: 178152.289\n",
      "  timestamp: 1633646775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 2\n",
      "  trial_id: 1a598_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.7/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/8.05 GiB heap, 0.0/4.03 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/IMPALA_2021-10-07_22-37-07<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_my_env_1a598_00000</td><td>RUNNING </td><td>192.168.3.5:11153</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         536.443</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">           439.182</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_my_env_1a598_00000:\n",
      "  agent_timesteps_total: 5400\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-07_22-47-03\n",
      "  done: false\n",
      "  episode_len_mean: 432.6923076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.7692307692307693\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 13\n",
      "  experiment_id: a24d0318e6224d569c66a7bb0a3b8f0b\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy: {}\n",
      "    learner_queue:\n",
      "      size_count: 3\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_agent_steps_sampled: 5400\n",
      "    num_steps_sampled: 5400\n",
      "    num_steps_trained: 3\n",
      "    num_weight_broadcasts: 1\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 145350.868\n",
      "      learner_grad_time_ms: 96.527\n",
      "      learner_load_time_ms: 22.654\n",
      "      learner_load_wait_time_ms: 118753.925\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.85217391304347\n",
      "    ram_util_percent: 81.22608695652173\n",
      "  pid: 11153\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.038510852711322416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 79.72540470778682\n",
      "    mean_inference_ms: 1.394102451857974\n",
      "    mean_raw_obs_processing_ms: 0.23823803174264852\n",
      "  time_since_restore: 584.8809943199158\n",
      "  time_this_iter_s: 48.43777275085449\n",
      "  time_total_s: 584.8809943199158\n",
      "  timers:\n",
      "    sample_throughput: 28.066\n",
      "    sample_time_ms: 178152.289\n",
      "  timestamp: 1633646823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5400\n",
      "  training_iteration: 3\n",
      "  trial_id: 1a598_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/8.05 GiB heap, 0.0/4.03 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/IMPALA_2021-10-07_22-37-07<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_my_env_1a598_00000</td><td>RUNNING </td><td>192.168.3.5:11153</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         584.881</td><td style=\"text-align: right;\">5400</td><td style=\"text-align: right;\">-0.769231</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">           432.692</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 22:47:03,621\tERROR trial_runner.py:773 -- Trial IMPALA_my_env_1a598_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 739, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 746, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\", line 1621, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(timeout): \u001b[36mray::IMPALA.train_buffered()\u001b[39m (pid=11153, ip=192.168.3.5, repr=IMPALA)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 648, in train\n",
      "    raise e\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 637, in train\n",
      "    result = Trainable.train(self)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trainable.py\", line 237, in train\n",
      "    result = self.step()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 193, in step\n",
      "    res = next(self.train_exec_impl)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "    return next(self.built_iterator)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 1075, in build_union\n",
      "    item = next(it)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "    return next(self.built_iterator)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
      "    item = next(it)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 551, in base_iterator\n",
      "    batch = ray.get(obj_ref)\n",
      "ray.exceptions.RayTaskError(timeout): \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=11150, ip=192.168.3.5, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f6e05427fd0>)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 1157, in par_iter_next_batch\n",
      "    batch.append(self.par_iter_next())\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 346, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 744, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 101, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 231, in get_data\n",
      "    item = next(self.rollout_provider)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 615, in _env_runner\n",
      "    sample_collector=sample_collector,\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 940, in _process_observations\n",
      "    env_id)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/env/base_env.py\", line 370, in try_reset\n",
      "    return {_DUMMY_AGENT_ID: self.vector_env.reset_at(env_id)}\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/env/vector_env.py\", line 167, in reset_at\n",
      "    return self.envs[index].reset()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/core.py\", line 237, in reset\n",
      "    return self.env.reset(**kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/core.py\", line 237, in reset\n",
      "    return self.env.reset(**kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/core.py\", line 264, in reset\n",
      "    observation = self.env.reset(**kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/wrappers/time_limit.py\", line 25, in reset\n",
      "    return self.env.reset(**kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/iglu/env.py\", line 107, in reset\n",
      "    obs = self.real_reset()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/iglu/env.py\", line 127, in real_reset\n",
      "    obs = super().reset()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/minerl_patched-0.1.0-py3.7-linux-x86_64.egg/minerl_patched/env/_singleagent.py\", line 23, in reset\n",
      "    multi_obs = super().reset()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/minerl_patched-0.1.0-py3.7-linux-x86_64.egg/minerl_patched/env/_multiagent.py\", line 456, in reset\n",
      "    self._setup_instances()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/minerl_patched-0.1.0-py3.7-linux-x86_64.egg/minerl_patched/env/_multiagent.py\", line 571, in _setup_instances\n",
      "    self._TO_MOVE_quit_current_episode(instance)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/minerl_patched-0.1.0-py3.7-linux-x86_64.egg/minerl_patched/env/_multiagent.py\", line 767, in _TO_MOVE_quit_current_episode\n",
      "    reply = comms.recv_message(instance.client_socket)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/minerl_patched-0.1.0-py3.7-linux-x86_64.egg/minerl_patched/env/comms.py\", line 63, in recv_message\n",
      "    lengthbuf = recvall(sock, 4)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/minerl_patched-0.1.0-py3.7-linux-x86_64.egg/minerl_patched/env/comms.py\", line 73, in recvall\n",
      "    newbuf = sock.recv(count)\n",
      "socket.timeout: timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for IMPALA_my_env_1a598_00000:\n",
      "  agent_timesteps_total: 5400\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-07_22-47-03\n",
      "  done: false\n",
      "  episode_len_mean: 432.6923076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.7692307692307693\n",
      "  episode_reward_min: -10.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 13\n",
      "  experiment_id: a24d0318e6224d569c66a7bb0a3b8f0b\n",
      "  experiment_tag: '0'\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy: {}\n",
      "    learner_queue:\n",
      "      size_count: 3\n",
      "      size_mean: 0.0\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      size_std: 0.0\n",
      "    num_agent_steps_sampled: 5400\n",
      "    num_steps_sampled: 5400\n",
      "    num_steps_trained: 3\n",
      "    num_weight_broadcasts: 1\n",
      "    timing_breakdown:\n",
      "      learner_dequeue_time_ms: 145350.868\n",
      "      learner_grad_time_ms: 96.527\n",
      "      learner_load_time_ms: 22.654\n",
      "      learner_load_wait_time_ms: 118753.925\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.85217391304347\n",
      "    ram_util_percent: 81.22608695652173\n",
      "  pid: 11153\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.038510852711322416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 79.72540470778682\n",
      "    mean_inference_ms: 1.394102451857974\n",
      "    mean_raw_obs_processing_ms: 0.23823803174264852\n",
      "  time_since_restore: 584.8809943199158\n",
      "  time_this_iter_s: 48.43777275085449\n",
      "  time_total_s: 584.8809943199158\n",
      "  timers:\n",
      "    sample_throughput: 28.066\n",
      "    sample_time_ms: 178152.289\n",
      "  timestamp: 1633646823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5400\n",
      "  training_iteration: 3\n",
      "  trial_id: 1a598_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11366<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/IGLU-Minecraft/wandb/run-20211007_223708-1a598_00000/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/IGLU-Minecraft/wandb/run-20211007_223708-1a598_00000/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>agent_timesteps_total</td><td>5400</td></tr><tr><td>episode_len_mean</td><td>432.69231</td></tr><tr><td>episode_reward_max</td><td>0.0</td></tr><tr><td>episode_reward_mean</td><td>-0.76923</td></tr><tr><td>episode_reward_min</td><td>-10.0</td></tr><tr><td>episodes_this_iter</td><td>2</td></tr><tr><td>episodes_total</td><td>13</td></tr><tr><td>info/learner_queue/size_count</td><td>3</td></tr><tr><td>info/learner_queue/size_mean</td><td>0.0</td></tr><tr><td>info/learner_queue/size_std</td><td>0.0</td></tr><tr><td>info/num_agent_steps_sampled</td><td>5400</td></tr><tr><td>info/num_steps_sampled</td><td>5400</td></tr><tr><td>info/num_steps_trained</td><td>3</td></tr><tr><td>info/num_weight_broadcasts</td><td>1</td></tr><tr><td>info/timing_breakdown/learner_dequeue_time_ms</td><td>145350.868</td></tr><tr><td>info/timing_breakdown/learner_grad_time_ms</td><td>96.527</td></tr><tr><td>info/timing_breakdown/learner_load_time_ms</td><td>22.654</td></tr><tr><td>info/timing_breakdown/learner_load_wait_time_ms</td><td>118753.925</td></tr><tr><td>iterations_since_restore</td><td>3</td></tr><tr><td>num_healthy_workers</td><td>3</td></tr><tr><td>perf/cpu_util_percent</td><td>78.85217</td></tr><tr><td>perf/ram_util_percent</td><td>81.22609</td></tr><tr><td>sampler_perf/mean_action_processing_ms</td><td>0.03851</td></tr><tr><td>sampler_perf/mean_env_render_ms</td><td>0.0</td></tr><tr><td>sampler_perf/mean_env_wait_ms</td><td>79.7254</td></tr><tr><td>sampler_perf/mean_inference_ms</td><td>1.3941</td></tr><tr><td>sampler_perf/mean_raw_obs_processing_ms</td><td>0.23824</td></tr><tr><td>time_since_restore</td><td>584.88099</td></tr><tr><td>time_this_iter_s</td><td>48.43777</td></tr><tr><td>time_total_s</td><td>584.88099</td></tr><tr><td>timers/sample_throughput</td><td>28.066</td></tr><tr><td>timers/sample_time_ms</td><td>178152.289</td></tr><tr><td>timestamp</td><td>1633646823</td></tr><tr><td>timesteps_since_restore</td><td>0</td></tr><tr><td>timesteps_total</td><td>5400</td></tr><tr><td>training_iteration</td><td>3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>agent_timesteps_total</td><td>▁▇█</td></tr><tr><td>episode_len_mean</td><td>█▆▁</td></tr><tr><td>episode_reward_max</td><td>▁▁▁</td></tr><tr><td>episode_reward_mean</td><td>██▁</td></tr><tr><td>episode_reward_min</td><td>██▁</td></tr><tr><td>episodes_this_iter</td><td>▆█▁</td></tr><tr><td>episodes_total</td><td>▁▆█</td></tr><tr><td>info/learner_queue/size_count</td><td>▁██</td></tr><tr><td>info/learner_queue/size_mean</td><td>▁▁▁</td></tr><tr><td>info/learner_queue/size_std</td><td>▁▁▁</td></tr><tr><td>info/num_agent_steps_sampled</td><td>▁▇█</td></tr><tr><td>info/num_steps_sampled</td><td>▁▇█</td></tr><tr><td>info/num_steps_trained</td><td>▁▅█</td></tr><tr><td>info/num_weight_broadcasts</td><td>▁▁</td></tr><tr><td>info/timing_breakdown/learner_dequeue_time_ms</td><td>▁▁▁</td></tr><tr><td>info/timing_breakdown/learner_grad_time_ms</td><td>▁██</td></tr><tr><td>info/timing_breakdown/learner_load_time_ms</td><td>▁▁▁</td></tr><tr><td>info/timing_breakdown/learner_load_wait_time_ms</td><td>█▁▁</td></tr><tr><td>iterations_since_restore</td><td>▁▅█</td></tr><tr><td>num_healthy_workers</td><td>▁▁▁</td></tr><tr><td>perf/cpu_util_percent</td><td>▁█▇</td></tr><tr><td>perf/ram_util_percent</td><td>▁██</td></tr><tr><td>sampler_perf/mean_action_processing_ms</td><td>▁█▅</td></tr><tr><td>sampler_perf/mean_env_render_ms</td><td>▁▁▁</td></tr><tr><td>sampler_perf/mean_env_wait_ms</td><td>█▂▁</td></tr><tr><td>sampler_perf/mean_inference_ms</td><td>█▂▁</td></tr><tr><td>sampler_perf/mean_raw_obs_processing_ms</td><td>▄▁█</td></tr><tr><td>time_since_restore</td><td>▁▇█</td></tr><tr><td>time_this_iter_s</td><td>█▅▁</td></tr><tr><td>time_total_s</td><td>▁▇█</td></tr><tr><td>timers/sample_throughput</td><td>█▁▁</td></tr><tr><td>timers/sample_time_ms</td><td>▁██</td></tr><tr><td>timestamp</td><td>▁▇█</td></tr><tr><td>timesteps_since_restore</td><td>▁▁▁</td></tr><tr><td>timesteps_total</td><td>▁▇█</td></tr><tr><td>training_iteration</td><td>▁▅█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">IMPALA C32 pretrained (AnnaCNN) (3 noops after placement)</strong>: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/1a598_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/1a598_00000</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 22:47:08,021\tWARNING util.py:164 -- The `process_trial` operation took 4.400 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.5/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/8.05 GiB heap, 0.0/4.03 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/IMPALA_2021-10-07_22-37-07<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_my_env_1a598_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         584.881</td><td style=\"text-align: right;\">5400</td><td style=\"text-align: right;\">-0.769231</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">           432.692</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>IMPALA_my_env_1a598_00000</td><td style=\"text-align: right;\">           1</td><td>/root/ray_results/IMPALA_2021-10-07_22-37-07/IMPALA_my_env_1a598_00000_0_2021-10-07_22-37-07/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [IMPALA_my_env_1a598_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11039/3657108822.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         },\n\u001b[0;32m---> 37\u001b[0;31m         loggers=[WandbLogger])\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [IMPALA_my_env_1a598_00000])"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(ImpalaTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             #\"sgd_minibatch_size\": 256,\n",
    "             #\"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             #\"lambda\": 0.95,\n",
    "             \"train_batch_size\": 5000,\n",
    "             \"grad_clip\": 100.0,\n",
    "             \"rollout_fragment_length\": 100,\n",
    "             # Number of passes to make over each train batch.\n",
    "             \"num_sgd_iter\": 5,\n",
    "             \"num_multi_gpu_tower_stacks\": 1,\n",
    "             \"replay_proportion\": 1.0,\n",
    "             \"replay_buffer_num_slots\": 100,\n",
    "             #\"minibatch_buffer_size\": 10,\n",
    "             \"learner_queue_size\": 32,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"IMPALA C32 pretrained (AnnaCNN) (3 noops after placement)\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
