{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            #nn.ELU(),\n",
    "        )\n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        target_features = target_features.reshape(target_features.shape[0], -1)\n",
    "        features = torch.cat([visual_features, target_features], dim=1)\n",
    "        features = self.policy_network(features)\n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=250)\n",
    "    env.update_taskset(TaskSet(preset=['C12']))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 21:29:18,085\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "\u001b[2m\u001b[36m(pid=97382)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97382)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2021-11-13 21:29:19,713\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[2m\u001b[36m(pid=97382)\u001b[0m 2021-11-13 21:29:21,589\tWARNING ppo.py:143 -- `train_batch_size` (1000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 333.\n",
      "\u001b[2m\u001b[36m(pid=97382)\u001b[0m 2021-11-13 21:29:21,589\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=97382)\u001b[0m 2021-11-13 21:29:21,589\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id f147d_00000 but id c1ec9_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97382)\u001b[0m 2021-11-13 21:29:27,377\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO MultiTask (C12) pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/c1ec9_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/c1ec9_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211113_212922-c1ec9_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 1998\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-31-01\n",
      "  done: false\n",
      "  episode_len_mean: 101.22222222222223\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.82\n",
      "  episode_reward_mean: -0.6011111111111115\n",
      "  episode_reward_min: -1.1400000000000008\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 18\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.882840056646438\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005703404819647301\n",
      "          policy_loss: 0.16548543302785781\n",
      "          total_loss: 0.1672038088951792\n",
      "          vf_explained_var: -0.32715457677841187\n",
      "          vf_loss: 0.02940609449565056\n",
      "    num_agent_steps_sampled: 1998\n",
      "    num_agent_steps_trained: 1998\n",
      "    num_steps_sampled: 1998\n",
      "    num_steps_trained: 1998\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.65820895522388\n",
      "    ram_util_percent: 33.52014925373134\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428365956182065\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 126.99843191731162\n",
      "    mean_inference_ms: 2.6091111415270145\n",
      "    mean_raw_obs_processing_ms: 0.6317650300749894\n",
      "  time_since_restore: 93.6059455871582\n",
      "  time_this_iter_s: 93.6059455871582\n",
      "  time_total_s: 93.6059455871582\n",
      "  timers:\n",
      "    learn_throughput: 1056.461\n",
      "    learn_time_ms: 1891.221\n",
      "    load_throughput: 58979.909\n",
      "    load_time_ms: 33.876\n",
      "    sample_throughput: 21.799\n",
      "    sample_time_ms: 91653.57\n",
      "    update_time_ms: 16.391\n",
      "  timestamp: 1636839061\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1998\n",
      "  training_iteration: 1\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         93.6059</td><td style=\"text-align: right;\">1998</td><td style=\"text-align: right;\">-0.601111</td><td style=\"text-align: right;\">                2.82</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           101.222</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 3996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-31-33\n",
      "  done: false\n",
      "  episode_len_mean: 99.46153846153847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.7500000000000036\n",
      "  episode_reward_mean: -0.4725641025641029\n",
      "  episode_reward_min: -1.1400000000000008\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 39\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.878673170861744\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005560556773412848\n",
      "          policy_loss: 0.05986297102201553\n",
      "          total_loss: 0.06258175199230512\n",
      "          vf_explained_var: 0.003969042561948299\n",
      "          vf_loss: 0.030393400350363836\n",
      "    num_agent_steps_sampled: 3996\n",
      "    num_agent_steps_trained: 3996\n",
      "    num_steps_sampled: 3996\n",
      "    num_steps_trained: 3996\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.21914893617024\n",
      "    ram_util_percent: 39.0127659574468\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04546752276611366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 103.76456222617409\n",
      "    mean_inference_ms: 2.5914551994730153\n",
      "    mean_raw_obs_processing_ms: 0.6768379054091225\n",
      "  time_since_restore: 126.1284589767456\n",
      "  time_this_iter_s: 32.5225133895874\n",
      "  time_total_s: 126.1284589767456\n",
      "  timers:\n",
      "    learn_throughput: 1085.586\n",
      "    learn_time_ms: 1840.48\n",
      "    load_throughput: 63592.498\n",
      "    load_time_ms: 31.419\n",
      "    sample_throughput: 32.667\n",
      "    sample_time_ms: 61163.397\n",
      "    update_time_ms: 18.315\n",
      "  timestamp: 1636839093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3996\n",
      "  training_iteration: 2\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         126.128</td><td style=\"text-align: right;\">3996</td><td style=\"text-align: right;\">-0.472564</td><td style=\"text-align: right;\">                4.75</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           99.4615</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 5994\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-32-06\n",
      "  done: false\n",
      "  episode_len_mean: 99.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.7500000000000036\n",
      "  episode_reward_mean: -0.597166666666667\n",
      "  episode_reward_min: -1.1400000000000008\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 60\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.869972423144749\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010543064373076068\n",
      "          policy_loss: -0.035259030706116135\n",
      "          total_loss: -0.006898064184046927\n",
      "          vf_explained_var: 0.19810587167739868\n",
      "          vf_loss: 0.054952078466747135\n",
      "    num_agent_steps_sampled: 5994\n",
      "    num_agent_steps_trained: 5994\n",
      "    num_steps_sampled: 5994\n",
      "    num_steps_trained: 5994\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.96521739130432\n",
      "    ram_util_percent: 39.076086956521735\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046255365704409544\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 91.59355705225002\n",
      "    mean_inference_ms: 2.564029179582773\n",
      "    mean_raw_obs_processing_ms: 0.6808499607684512\n",
      "  time_since_restore: 158.6381278038025\n",
      "  time_this_iter_s: 32.509668827056885\n",
      "  time_total_s: 158.6381278038025\n",
      "  timers:\n",
      "    learn_throughput: 1098.617\n",
      "    learn_time_ms: 1818.651\n",
      "    load_throughput: 62746.388\n",
      "    load_time_ms: 31.842\n",
      "    sample_throughput: 39.464\n",
      "    sample_time_ms: 50628.653\n",
      "    update_time_ms: 18.789\n",
      "  timestamp: 1636839126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5994\n",
      "  training_iteration: 3\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         158.638</td><td style=\"text-align: right;\">5994</td><td style=\"text-align: right;\">-0.597167</td><td style=\"text-align: right;\">                4.75</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">             99.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 7992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-32-40\n",
      "  done: false\n",
      "  episode_len_mean: 99.3974358974359\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.380000000000006\n",
      "  episode_reward_mean: 0.09307692307692357\n",
      "  episode_reward_min: -1.1400000000000008\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 78\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.8304984501429966\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009921468008821436\n",
      "          policy_loss: -0.0056156604506430174\n",
      "          total_loss: 0.520181911048435\n",
      "          vf_explained_var: 0.32595294713974\n",
      "          vf_loss: 0.552118263854867\n",
      "    num_agent_steps_sampled: 7992\n",
      "    num_agent_steps_trained: 7992\n",
      "    num_steps_sampled: 7992\n",
      "    num_steps_trained: 7992\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.87142857142857\n",
      "    ram_util_percent: 39.04489795918367\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04625782608617186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 84.82026891043253\n",
      "    mean_inference_ms: 2.5456562346663767\n",
      "    mean_raw_obs_processing_ms: 0.7136280990099595\n",
      "  time_since_restore: 192.43152332305908\n",
      "  time_this_iter_s: 33.79339551925659\n",
      "  time_total_s: 192.43152332305908\n",
      "  timers:\n",
      "    learn_throughput: 1100.451\n",
      "    learn_time_ms: 1815.619\n",
      "    load_throughput: 61925.473\n",
      "    load_time_ms: 32.265\n",
      "    sample_throughput: 43.483\n",
      "    sample_time_ms: 45949.17\n",
      "    update_time_ms: 22.479\n",
      "  timestamp: 1636839160\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7992\n",
      "  training_iteration: 4\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         192.432</td><td style=\"text-align: right;\">7992</td><td style=\"text-align: right;\">0.0930769</td><td style=\"text-align: right;\">                6.38</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           99.3974</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 9990\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-33-06\n",
      "  done: false\n",
      "  episode_len_mean: 98.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.590000000000008\n",
      "  episode_reward_mean: 0.6711000000000013\n",
      "  episode_reward_min: -1.1400000000000008\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 100\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.811806241671244\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011438386647242367\n",
      "          policy_loss: -0.01165941542103177\n",
      "          total_loss: 0.4895619119916643\n",
      "          vf_explained_var: 0.5742881298065186\n",
      "          vf_loss: 0.5270517118629955\n",
      "    num_agent_steps_sampled: 9990\n",
      "    num_agent_steps_trained: 9990\n",
      "    num_steps_sampled: 9990\n",
      "    num_steps_trained: 9990\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.08648648648649\n",
      "    ram_util_percent: 38.967567567567556\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04614370756621115\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 78.49484766971128\n",
      "    mean_inference_ms: 2.5296530059228917\n",
      "    mean_raw_obs_processing_ms: 0.7375829937212183\n",
      "  time_since_restore: 218.48336911201477\n",
      "  time_this_iter_s: 26.05184578895569\n",
      "  time_total_s: 218.48336911201477\n",
      "  timers:\n",
      "    learn_throughput: 1092.35\n",
      "    learn_time_ms: 1829.084\n",
      "    load_throughput: 61454.238\n",
      "    load_time_ms: 32.512\n",
      "    sample_throughput: 48.05\n",
      "    sample_time_ms: 41581.667\n",
      "    update_time_ms: 21.149\n",
      "  timestamp: 1636839186\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9990\n",
      "  training_iteration: 5\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         218.483</td><td style=\"text-align: right;\">9990</td><td style=\"text-align: right;\">  0.6711</td><td style=\"text-align: right;\">                6.59</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">             98.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 11988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-33-30\n",
      "  done: false\n",
      "  episode_len_mean: 98.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.590000000000008\n",
      "  episode_reward_mean: 1.3642000000000025\n",
      "  episode_reward_min: -1.1200000000000008\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 120\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7578937905175347\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01130056646144069\n",
      "          policy_loss: -0.013157294335819426\n",
      "          total_loss: 0.4043581335140126\n",
      "          vf_explained_var: 0.6490393280982971\n",
      "          vf_loss: 0.4428342506289482\n",
      "    num_agent_steps_sampled: 11988\n",
      "    num_agent_steps_trained: 11988\n",
      "    num_steps_sampled: 11988\n",
      "    num_steps_trained: 11988\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.07714285714286\n",
      "    ram_util_percent: 39.145714285714284\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04634670981462156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 64.36459685317227\n",
      "    mean_inference_ms: 2.501873978901965\n",
      "    mean_raw_obs_processing_ms: 0.7726526498952364\n",
      "  time_since_restore: 243.0773937702179\n",
      "  time_this_iter_s: 24.594024658203125\n",
      "  time_total_s: 243.0773937702179\n",
      "  timers:\n",
      "    learn_throughput: 1088.561\n",
      "    learn_time_ms: 1835.45\n",
      "    load_throughput: 51147.031\n",
      "    load_time_ms: 39.064\n",
      "    sample_throughput: 52.005\n",
      "    sample_time_ms: 38419.528\n",
      "    update_time_ms: 23.798\n",
      "  timestamp: 1636839210\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11988\n",
      "  training_iteration: 6\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         243.077</td><td style=\"text-align: right;\">11988</td><td style=\"text-align: right;\">  1.3642</td><td style=\"text-align: right;\">                6.59</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">             98.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 13986\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-33-56\n",
      "  done: false\n",
      "  episode_len_mean: 97.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.79000000000001\n",
      "  episode_reward_mean: 2.3392000000000044\n",
      "  episode_reward_min: -1.1200000000000008\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 141\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.706659454391116\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014662390953454209\n",
      "          policy_loss: -0.026703608319872903\n",
      "          total_loss: 0.46968294225987933\n",
      "          vf_explained_var: 0.6787059903144836\n",
      "          vf_loss: 0.5205206707119941\n",
      "    num_agent_steps_sampled: 13986\n",
      "    num_agent_steps_trained: 13986\n",
      "    num_steps_sampled: 13986\n",
      "    num_steps_trained: 13986\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.14324324324323\n",
      "    ram_util_percent: 39.275675675675686\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04597758084275512\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 57.30375238429049\n",
      "    mean_inference_ms: 2.4782199514272936\n",
      "    mean_raw_obs_processing_ms: 0.7923175055556791\n",
      "  time_since_restore: 269.03309655189514\n",
      "  time_this_iter_s: 25.955702781677246\n",
      "  time_total_s: 269.03309655189514\n",
      "  timers:\n",
      "    learn_throughput: 1082.566\n",
      "    learn_time_ms: 1845.615\n",
      "    load_throughput: 47437.378\n",
      "    load_time_ms: 42.119\n",
      "    sample_throughput: 54.959\n",
      "    sample_time_ms: 36354.212\n",
      "    update_time_ms: 23.017\n",
      "  timestamp: 1636839236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13986\n",
      "  training_iteration: 7\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         269.033</td><td style=\"text-align: right;\">13986</td><td style=\"text-align: right;\">  2.3392</td><td style=\"text-align: right;\">                6.79</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">             97.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 15984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-34-23\n",
      "  done: false\n",
      "  episode_len_mean: 96.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.990000000000009\n",
      "  episode_reward_mean: 3.303100000000007\n",
      "  episode_reward_min: -1.1200000000000008\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 163\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.679888422148568\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010000597339444027\n",
      "          policy_loss: 0.014961325164352144\n",
      "          total_loss: 0.4654313227250462\n",
      "          vf_explained_var: 0.7398209571838379\n",
      "          vf_loss: 0.4752687643681254\n",
      "    num_agent_steps_sampled: 15984\n",
      "    num_agent_steps_trained: 15984\n",
      "    num_steps_sampled: 15984\n",
      "    num_steps_trained: 15984\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.15263157894738\n",
      "    ram_util_percent: 39.29473684210527\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04547667640724154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 52.66390962474046\n",
      "    mean_inference_ms: 2.4671556299889077\n",
      "    mean_raw_obs_processing_ms: 0.8060429061202737\n",
      "  time_since_restore: 295.84694385528564\n",
      "  time_this_iter_s: 26.813847303390503\n",
      "  time_total_s: 295.84694385528564\n",
      "  timers:\n",
      "    learn_throughput: 1072.968\n",
      "    learn_time_ms: 1862.125\n",
      "    load_throughput: 44289.959\n",
      "    load_time_ms: 45.112\n",
      "    sample_throughput: 57.245\n",
      "    sample_time_ms: 34902.782\n",
      "    update_time_ms: 22.591\n",
      "  timestamp: 1636839263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15984\n",
      "  training_iteration: 8\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         295.847</td><td style=\"text-align: right;\">15984</td><td style=\"text-align: right;\">  3.3031</td><td style=\"text-align: right;\">                6.99</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">             96.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 17982\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-34-49\n",
      "  done: false\n",
      "  episode_len_mean: 95.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.990000000000009\n",
      "  episode_reward_mean: 3.7790000000000084\n",
      "  episode_reward_min: -0.9500000000000006\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 184\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.674108133997236\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010272174737145045\n",
      "          policy_loss: 0.005929579514832724\n",
      "          total_loss: 0.40065486207604406\n",
      "          vf_explained_var: 0.8071668148040771\n",
      "          vf_loss: 0.41941193079664596\n",
      "    num_agent_steps_sampled: 17982\n",
      "    num_agent_steps_trained: 17982\n",
      "    num_steps_sampled: 17982\n",
      "    num_steps_trained: 17982\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.06486486486487\n",
      "    ram_util_percent: 39.24324324324324\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04522685739023663\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 49.4929684778828\n",
      "    mean_inference_ms: 2.4630995715256274\n",
      "    mean_raw_obs_processing_ms: 0.7965363474099922\n",
      "  time_since_restore: 321.3037486076355\n",
      "  time_this_iter_s: 25.456804752349854\n",
      "  time_total_s: 321.3037486076355\n",
      "  timers:\n",
      "    learn_throughput: 1078.626\n",
      "    learn_time_ms: 1852.357\n",
      "    load_throughput: 45284.667\n",
      "    load_time_ms: 44.121\n",
      "    sample_throughput: 59.377\n",
      "    sample_time_ms: 33649.287\n",
      "    update_time_ms: 21.852\n",
      "  timestamp: 1636839289\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17982\n",
      "  training_iteration: 9\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         321.304</td><td style=\"text-align: right;\">17982</td><td style=\"text-align: right;\">   3.779</td><td style=\"text-align: right;\">                6.99</td><td style=\"text-align: right;\">               -0.95</td><td style=\"text-align: right;\">             95.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 19980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-35-16\n",
      "  done: false\n",
      "  episode_len_mean: 94.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.990000000000009\n",
      "  episode_reward_mean: 4.03010000000001\n",
      "  episode_reward_min: 0.7399999999999993\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 206\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6297016881761097\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009827202918365996\n",
      "          policy_loss: -0.016747807427531198\n",
      "          total_loss: 0.4128625229710624\n",
      "          vf_explained_var: 0.8076090216636658\n",
      "          vf_loss: 0.45394190968502135\n",
      "    num_agent_steps_sampled: 19980\n",
      "    num_agent_steps_trained: 19980\n",
      "    num_steps_sampled: 19980\n",
      "    num_steps_trained: 19980\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.9578947368421\n",
      "    ram_util_percent: 39.23947368421052\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04527911377997164\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 47.014698332642986\n",
      "    mean_inference_ms: 2.460455720242925\n",
      "    mean_raw_obs_processing_ms: 0.7932634779230482\n",
      "  time_since_restore: 348.13161158561707\n",
      "  time_this_iter_s: 26.827862977981567\n",
      "  time_total_s: 348.13161158561707\n",
      "  timers:\n",
      "    learn_throughput: 1081.787\n",
      "    learn_time_ms: 1846.945\n",
      "    load_throughput: 42824.063\n",
      "    load_time_ms: 46.656\n",
      "    sample_throughput: 60.956\n",
      "    sample_time_ms: 32777.699\n",
      "    update_time_ms: 21.441\n",
      "  timestamp: 1636839316\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19980\n",
      "  training_iteration: 10\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         348.132</td><td style=\"text-align: right;\">19980</td><td style=\"text-align: right;\">  4.0301</td><td style=\"text-align: right;\">                6.99</td><td style=\"text-align: right;\">                0.74</td><td style=\"text-align: right;\">             94.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 21978\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-35-42\n",
      "  done: false\n",
      "  episode_len_mean: 94.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.990000000000009\n",
      "  episode_reward_mean: 4.359100000000011\n",
      "  episode_reward_min: 0.9600000000000022\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 227\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.566334101131984\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009784010922343956\n",
      "          policy_loss: -0.008979354550441106\n",
      "          total_loss: 0.47313478894176936\n",
      "          vf_explained_var: 0.8128864169120789\n",
      "          vf_loss: 0.5058206854122026\n",
      "    num_agent_steps_sampled: 21978\n",
      "    num_agent_steps_trained: 21978\n",
      "    num_steps_sampled: 21978\n",
      "    num_steps_trained: 21978\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.01315789473685\n",
      "    ram_util_percent: 39.17105263157894\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04553397592406612\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.369651564780355\n",
      "    mean_inference_ms: 2.4605812841209036\n",
      "    mean_raw_obs_processing_ms: 0.7904108955079064\n",
      "  time_since_restore: 374.67700695991516\n",
      "  time_this_iter_s: 26.545395374298096\n",
      "  time_total_s: 374.67700695991516\n",
      "  timers:\n",
      "    learn_throughput: 1084.026\n",
      "    learn_time_ms: 1843.13\n",
      "    load_throughput: 42784.97\n",
      "    load_time_ms: 46.699\n",
      "    sample_throughput: 76.625\n",
      "    sample_time_ms: 26075.193\n",
      "    update_time_ms: 21.922\n",
      "  timestamp: 1636839342\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21978\n",
      "  training_iteration: 11\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         374.677</td><td style=\"text-align: right;\">21978</td><td style=\"text-align: right;\">  4.3591</td><td style=\"text-align: right;\">                6.99</td><td style=\"text-align: right;\">                0.96</td><td style=\"text-align: right;\">             94.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 23976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-36-09\n",
      "  done: false\n",
      "  episode_len_mean: 93.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.990000000000009\n",
      "  episode_reward_mean: 4.528600000000012\n",
      "  episode_reward_min: 0.9600000000000022\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 248\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5478057759148736\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009920251516571084\n",
      "          policy_loss: -0.015570498594925517\n",
      "          total_loss: 0.4577688075247265\n",
      "          vf_explained_var: 0.8042890429496765\n",
      "          vf_loss: 0.4968333112342017\n",
      "    num_agent_steps_sampled: 23976\n",
      "    num_agent_steps_trained: 23976\n",
      "    num_steps_sampled: 23976\n",
      "    num_steps_trained: 23976\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.0421052631579\n",
      "    ram_util_percent: 39.136842105263156\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04579470074680818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 44.037441070649365\n",
      "    mean_inference_ms: 2.460540984833206\n",
      "    mean_raw_obs_processing_ms: 0.788531905698341\n",
      "  time_since_restore: 401.69457507133484\n",
      "  time_this_iter_s: 27.017568111419678\n",
      "  time_total_s: 401.69457507133484\n",
      "  timers:\n",
      "    learn_throughput: 1081.567\n",
      "    learn_time_ms: 1847.319\n",
      "    load_throughput: 42263.933\n",
      "    load_time_ms: 47.274\n",
      "    sample_throughput: 78.29\n",
      "    sample_time_ms: 25520.57\n",
      "    update_time_ms: 21.481\n",
      "  timestamp: 1636839369\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 23976\n",
      "  training_iteration: 12\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         401.695</td><td style=\"text-align: right;\">23976</td><td style=\"text-align: right;\">  4.5286</td><td style=\"text-align: right;\">                6.99</td><td style=\"text-align: right;\">                0.96</td><td style=\"text-align: right;\">             93.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 25974\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-36-35\n",
      "  done: false\n",
      "  episode_len_mean: 94.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.760000000000004\n",
      "  episode_reward_mean: 4.703100000000013\n",
      "  episode_reward_min: 0.9600000000000022\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 268\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.519694992474147\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009893422050303757\n",
      "          policy_loss: -0.03157525990335714\n",
      "          total_loss: 0.5100091284584432\n",
      "          vf_explained_var: 0.7804846167564392\n",
      "          vf_loss: 0.5648026558614913\n",
      "    num_agent_steps_sampled: 25974\n",
      "    num_agent_steps_trained: 25974\n",
      "    num_steps_sampled: 25974\n",
      "    num_steps_trained: 25974\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.56842105263159\n",
      "    ram_util_percent: 39.13947368421052\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045911602940093194\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.97943513463522\n",
      "    mean_inference_ms: 2.4597539995594495\n",
      "    mean_raw_obs_processing_ms: 0.7871031899210876\n",
      "  time_since_restore: 427.6701292991638\n",
      "  time_this_iter_s: 25.97555422782898\n",
      "  time_total_s: 427.6701292991638\n",
      "  timers:\n",
      "    learn_throughput: 1078.585\n",
      "    learn_time_ms: 1852.427\n",
      "    load_throughput: 40667.726\n",
      "    load_time_ms: 49.13\n",
      "    sample_throughput: 80.008\n",
      "    sample_time_ms: 24972.656\n",
      "    update_time_ms: 20.541\n",
      "  timestamp: 1636839395\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25974\n",
      "  training_iteration: 13\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">          427.67</td><td style=\"text-align: right;\">25974</td><td style=\"text-align: right;\">  4.7031</td><td style=\"text-align: right;\">                6.76</td><td style=\"text-align: right;\">                0.96</td><td style=\"text-align: right;\">             94.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 27972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-36-58\n",
      "  done: false\n",
      "  episode_len_mean: 95.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.760000000000004\n",
      "  episode_reward_mean: 4.669800000000013\n",
      "  episode_reward_min: 0.9600000000000022\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 288\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5486324707667034\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008276939229526565\n",
      "          policy_loss: -0.02077431029507092\n",
      "          total_loss: 0.4885985729062841\n",
      "          vf_explained_var: 0.810821533203125\n",
      "          vf_loss: 0.53320381911028\n",
      "    num_agent_steps_sampled: 27972\n",
      "    num_agent_steps_trained: 27972\n",
      "    num_steps_sampled: 27972\n",
      "    num_steps_trained: 27972\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.60625\n",
      "    ram_util_percent: 35.353125000000006\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.046087253157645475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.0339532481253\n",
      "    mean_inference_ms: 2.4580813574777824\n",
      "    mean_raw_obs_processing_ms: 0.7832882420577215\n",
      "  time_since_restore: 450.4415590763092\n",
      "  time_this_iter_s: 22.771429777145386\n",
      "  time_total_s: 450.4415590763092\n",
      "  timers:\n",
      "    learn_throughput: 1079.661\n",
      "    learn_time_ms: 1850.581\n",
      "    load_throughput: 40457.473\n",
      "    load_time_ms: 49.385\n",
      "    sample_throughput: 83.687\n",
      "    sample_time_ms: 23874.632\n",
      "    update_time_ms: 17.897\n",
      "  timestamp: 1636839418\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27972\n",
      "  training_iteration: 14\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 16.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         450.442</td><td style=\"text-align: right;\">27972</td><td style=\"text-align: right;\">  4.6698</td><td style=\"text-align: right;\">                6.76</td><td style=\"text-align: right;\">                0.96</td><td style=\"text-align: right;\">             95.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 29970\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-37-21\n",
      "  done: false\n",
      "  episode_len_mean: 97.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.360000000000015\n",
      "  episode_reward_mean: 5.042300000000014\n",
      "  episode_reward_min: 2.2300000000000098\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 309\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5178912457965668\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008670977281085455\n",
      "          policy_loss: -0.010298847176489375\n",
      "          total_loss: 0.522636164582911\n",
      "          vf_explained_var: 0.7854509353637695\n",
      "          vf_loss: 0.5563797234069734\n",
      "    num_agent_steps_sampled: 29970\n",
      "    num_agent_steps_trained: 29970\n",
      "    num_steps_sampled: 29970\n",
      "    num_steps_trained: 29970\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.21212121212122\n",
      "    ram_util_percent: 34.45757575757575\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04596710767722812\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.129708476422536\n",
      "    mean_inference_ms: 2.456572548691945\n",
      "    mean_raw_obs_processing_ms: 0.7778334386201489\n",
      "  time_since_restore: 473.82765769958496\n",
      "  time_this_iter_s: 23.386098623275757\n",
      "  time_total_s: 473.82765769958496\n",
      "  timers:\n",
      "    learn_throughput: 1083.592\n",
      "    learn_time_ms: 1843.867\n",
      "    load_throughput: 40467.3\n",
      "    load_time_ms: 49.373\n",
      "    sample_throughput: 84.609\n",
      "    sample_time_ms: 23614.629\n",
      "    update_time_ms: 17.619\n",
      "  timestamp: 1636839441\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29970\n",
      "  training_iteration: 15\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 16.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         473.828</td><td style=\"text-align: right;\">29970</td><td style=\"text-align: right;\">  5.0423</td><td style=\"text-align: right;\">               12.36</td><td style=\"text-align: right;\">                2.23</td><td style=\"text-align: right;\">             97.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 31968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-37-44\n",
      "  done: false\n",
      "  episode_len_mean: 99.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.360000000000015\n",
      "  episode_reward_mean: 5.047900000000015\n",
      "  episode_reward_min: 2.2700000000000156\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 328\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.480460218020848\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007375718710702233\n",
      "          policy_loss: -0.03663729881601674\n",
      "          total_loss: 0.3109915445957865\n",
      "          vf_explained_var: 0.8462395668029785\n",
      "          vf_loss: 0.3709583030570121\n",
      "    num_agent_steps_sampled: 31968\n",
      "    num_agent_steps_trained: 31968\n",
      "    num_steps_sampled: 31968\n",
      "    num_steps_trained: 31968\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.3121212121212\n",
      "    ram_util_percent: 34.539393939393946\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04573035294686119\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.30695295813859\n",
      "    mean_inference_ms: 2.4541259476809816\n",
      "    mean_raw_obs_processing_ms: 0.7745176054481361\n",
      "  time_since_restore: 496.6355233192444\n",
      "  time_this_iter_s: 22.807865619659424\n",
      "  time_total_s: 496.6355233192444\n",
      "  timers:\n",
      "    learn_throughput: 1088.576\n",
      "    learn_time_ms: 1835.425\n",
      "    load_throughput: 43907.586\n",
      "    load_time_ms: 45.505\n",
      "    sample_throughput: 85.199\n",
      "    sample_time_ms: 23450.939\n",
      "    update_time_ms: 14.749\n",
      "  timestamp: 1636839464\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 31968\n",
      "  training_iteration: 16\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 16.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         496.636</td><td style=\"text-align: right;\">31968</td><td style=\"text-align: right;\">  5.0479</td><td style=\"text-align: right;\">               12.36</td><td style=\"text-align: right;\">                2.27</td><td style=\"text-align: right;\">             99.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 33966\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-38-07\n",
      "  done: false\n",
      "  episode_len_mean: 99.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.360000000000015\n",
      "  episode_reward_mean: 5.176400000000016\n",
      "  episode_reward_min: 2.1800000000000117\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 346\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.4604553813026064\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010763841822640185\n",
      "          policy_loss: -0.006218980447877021\n",
      "          total_loss: 0.4575322930301939\n",
      "          vf_explained_var: 0.8304415941238403\n",
      "          vf_loss: 0.48620306281816394\n",
      "    num_agent_steps_sampled: 33966\n",
      "    num_agent_steps_trained: 33966\n",
      "    num_steps_sampled: 33966\n",
      "    num_steps_trained: 33966\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.57272727272728\n",
      "    ram_util_percent: 31.96969696969696\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0455796946118251\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 39.5950296279761\n",
      "    mean_inference_ms: 2.4532687344136033\n",
      "    mean_raw_obs_processing_ms: 0.7680168369144593\n",
      "  time_since_restore: 519.8052525520325\n",
      "  time_this_iter_s: 23.169729232788086\n",
      "  time_total_s: 519.8052525520325\n",
      "  timers:\n",
      "    learn_throughput: 1095.132\n",
      "    learn_time_ms: 1824.437\n",
      "    load_throughput: 46377.397\n",
      "    load_time_ms: 43.081\n",
      "    sample_throughput: 86.172\n",
      "    sample_time_ms: 23186.14\n",
      "    update_time_ms: 14.088\n",
      "  timestamp: 1636839487\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 33966\n",
      "  training_iteration: 17\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         519.805</td><td style=\"text-align: right;\">33966</td><td style=\"text-align: right;\">  5.1764</td><td style=\"text-align: right;\">               12.36</td><td style=\"text-align: right;\">                2.18</td><td style=\"text-align: right;\">             99.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 35964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-38-52\n",
      "  done: false\n",
      "  episode_len_mean: 99.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.360000000000015\n",
      "  episode_reward_mean: 5.022000000000016\n",
      "  episode_reward_min: -0.15\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 370\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.4607850494838894\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008753717701278054\n",
      "          policy_loss: -0.011789269603434063\n",
      "          total_loss: 0.5987747496082669\n",
      "          vf_explained_var: 0.7473449110984802\n",
      "          vf_loss: 0.6334211294140134\n",
      "    num_agent_steps_sampled: 35964\n",
      "    num_agent_steps_trained: 35964\n",
      "    num_steps_sampled: 35964\n",
      "    num_steps_trained: 35964\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.0796875\n",
      "    ram_util_percent: 27.8921875\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04548451924825257\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 38.743213741138504\n",
      "    mean_inference_ms: 2.452141850417369\n",
      "    mean_raw_obs_processing_ms: 1.1146676875845842\n",
      "  time_since_restore: 564.4198176860809\n",
      "  time_this_iter_s: 44.61456513404846\n",
      "  time_total_s: 564.4198176860809\n",
      "  timers:\n",
      "    learn_throughput: 1105.948\n",
      "    learn_time_ms: 1806.596\n",
      "    load_throughput: 50104.418\n",
      "    load_time_ms: 39.877\n",
      "    sample_throughput: 79.957\n",
      "    sample_time_ms: 24988.374\n",
      "    update_time_ms: 12.746\n",
      "  timestamp: 1636839532\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35964\n",
      "  training_iteration: 18\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">          564.42</td><td style=\"text-align: right;\">35964</td><td style=\"text-align: right;\">   5.022</td><td style=\"text-align: right;\">               12.36</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             99.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 37962\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-39-17\n",
      "  done: false\n",
      "  episode_len_mean: 99.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.360000000000015\n",
      "  episode_reward_mean: 5.205400000000017\n",
      "  episode_reward_min: -0.15\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 388\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.4415252560660954\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0119952764801665\n",
      "          policy_loss: -0.027045181500060217\n",
      "          total_loss: 0.40284756019356704\n",
      "          vf_explained_var: 0.8170909881591797\n",
      "          vf_loss: 0.4519089400058701\n",
      "    num_agent_steps_sampled: 37962\n",
      "    num_agent_steps_trained: 37962\n",
      "    num_steps_sampled: 37962\n",
      "    num_steps_trained: 37962\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11714285714284\n",
      "    ram_util_percent: 29.33714285714286\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04539690688632225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 38.20096722617668\n",
      "    mean_inference_ms: 2.4510676533368585\n",
      "    mean_raw_obs_processing_ms: 1.3629362313604907\n",
      "  time_since_restore: 589.156744480133\n",
      "  time_this_iter_s: 24.736926794052124\n",
      "  time_total_s: 589.156744480133\n",
      "  timers:\n",
      "    learn_throughput: 1100.665\n",
      "    learn_time_ms: 1815.267\n",
      "    load_throughput: 50072.833\n",
      "    load_time_ms: 39.902\n",
      "    sample_throughput: 80.213\n",
      "    sample_time_ms: 24908.54\n",
      "    update_time_ms: 12.005\n",
      "  timestamp: 1636839557\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 37962\n",
      "  training_iteration: 19\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         589.157</td><td style=\"text-align: right;\">37962</td><td style=\"text-align: right;\">  5.2054</td><td style=\"text-align: right;\">               12.36</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             99.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 39960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-39-42\n",
      "  done: false\n",
      "  episode_len_mean: 99.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.230000000000018\n",
      "  episode_reward_mean: 5.151900000000017\n",
      "  episode_reward_min: -0.15\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 408\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.4050423769723803\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009994801099675989\n",
      "          policy_loss: 0.00885747651613894\n",
      "          total_loss: 0.35337225826723234\n",
      "          vf_explained_var: 0.852358341217041\n",
      "          vf_loss: 0.3665662453997703\n",
      "    num_agent_steps_sampled: 39960\n",
      "    num_agent_steps_trained: 39960\n",
      "    num_steps_sampled: 39960\n",
      "    num_steps_trained: 39960\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88571428571429\n",
      "    ram_util_percent: 29.908571428571427\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04543653347508049\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 37.702597005982696\n",
      "    mean_inference_ms: 2.4504330602885847\n",
      "    mean_raw_obs_processing_ms: 1.6240960504454391\n",
      "  time_since_restore: 613.7872207164764\n",
      "  time_this_iter_s: 24.630476236343384\n",
      "  time_total_s: 613.7872207164764\n",
      "  timers:\n",
      "    learn_throughput: 1096.792\n",
      "    learn_time_ms: 1821.676\n",
      "    load_throughput: 54629.461\n",
      "    load_time_ms: 36.574\n",
      "    sample_throughput: 80.937\n",
      "    sample_time_ms: 24685.906\n",
      "    update_time_ms: 11.595\n",
      "  timestamp: 1636839582\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39960\n",
      "  training_iteration: 20\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         613.787</td><td style=\"text-align: right;\">39960</td><td style=\"text-align: right;\">  5.1519</td><td style=\"text-align: right;\">               10.23</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             99.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 41958\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-40-06\n",
      "  done: false\n",
      "  episode_len_mean: 99.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.230000000000018\n",
      "  episode_reward_mean: 5.235600000000017\n",
      "  episode_reward_min: -0.15\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 428\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.3866292646953036\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010569713830983117\n",
      "          policy_loss: -0.066588300448798\n",
      "          total_loss: 0.28426548191124484\n",
      "          vf_explained_var: 0.8414488434791565\n",
      "          vf_loss: 0.3726061315763564\n",
      "    num_agent_steps_sampled: 41958\n",
      "    num_agent_steps_trained: 41958\n",
      "    num_steps_sampled: 41958\n",
      "    num_steps_trained: 41958\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.74722222222222\n",
      "    ram_util_percent: 30.058333333333337\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04547551684783699\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 37.27645720988745\n",
      "    mean_inference_ms: 2.4501525120684895\n",
      "    mean_raw_obs_processing_ms: 1.8735394746244167\n",
      "  time_since_restore: 638.3709483146667\n",
      "  time_this_iter_s: 24.583727598190308\n",
      "  time_total_s: 638.3709483146667\n",
      "  timers:\n",
      "    learn_throughput: 1102.403\n",
      "    learn_time_ms: 1812.404\n",
      "    load_throughput: 54729.036\n",
      "    load_time_ms: 36.507\n",
      "    sample_throughput: 81.553\n",
      "    sample_time_ms: 24499.391\n",
      "    update_time_ms: 11.067\n",
      "  timestamp: 1636839606\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 41958\n",
      "  training_iteration: 21\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         638.371</td><td style=\"text-align: right;\">41958</td><td style=\"text-align: right;\">  5.2356</td><td style=\"text-align: right;\">               10.23</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             99.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 43956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-40-30\n",
      "  done: false\n",
      "  episode_len_mean: 99.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.230000000000018\n",
      "  episode_reward_mean: 5.1689000000000185\n",
      "  episode_reward_min: -0.15\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 449\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.3594072580337526\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012280513917090057\n",
      "          policy_loss: -0.009734727690617244\n",
      "          total_loss: 0.3554318061009759\n",
      "          vf_explained_var: 0.8700714111328125\n",
      "          vf_loss: 0.3863044994927588\n",
      "    num_agent_steps_sampled: 43956\n",
      "    num_agent_steps_trained: 43956\n",
      "    num_steps_sampled: 43956\n",
      "    num_steps_trained: 43956\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16764705882353\n",
      "    ram_util_percent: 30.079411764705885\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04555277016835449\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.93349601972977\n",
      "    mean_inference_ms: 2.4502849199862538\n",
      "    mean_raw_obs_processing_ms: 2.0788731583504254\n",
      "  time_since_restore: 662.3648693561554\n",
      "  time_this_iter_s: 23.993921041488647\n",
      "  time_total_s: 662.3648693561554\n",
      "  timers:\n",
      "    learn_throughput: 1104.486\n",
      "    learn_time_ms: 1808.987\n",
      "    load_throughput: 54944.26\n",
      "    load_time_ms: 36.364\n",
      "    sample_throughput: 82.559\n",
      "    sample_time_ms: 24200.843\n",
      "    update_time_ms: 10.575\n",
      "  timestamp: 1636839630\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 43956\n",
      "  training_iteration: 22\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         662.365</td><td style=\"text-align: right;\">43956</td><td style=\"text-align: right;\">  5.1689</td><td style=\"text-align: right;\">               10.23</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             99.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 45954\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-40-53\n",
      "  done: false\n",
      "  episode_len_mean: 100.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.230000000000018\n",
      "  episode_reward_mean: 5.4810000000000185\n",
      "  episode_reward_min: 2.1200000000000188\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 467\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.326967293875558\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009912723590650336\n",
      "          policy_loss: -0.044150541598598166\n",
      "          total_loss: 0.36696852433184785\n",
      "          vf_explained_var: 0.8323751091957092\n",
      "          vf_loss: 0.4324061919535909\n",
      "    num_agent_steps_sampled: 45954\n",
      "    num_agent_steps_trained: 45954\n",
      "    num_steps_sampled: 45954\n",
      "    num_steps_trained: 45954\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90625\n",
      "    ram_util_percent: 30.184375000000003\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045494651948810354\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.59538069357602\n",
      "    mean_inference_ms: 2.449538959638717\n",
      "    mean_raw_obs_processing_ms: 2.019271060838768\n",
      "  time_since_restore: 685.252111196518\n",
      "  time_this_iter_s: 22.88724184036255\n",
      "  time_total_s: 685.252111196518\n",
      "  timers:\n",
      "    learn_throughput: 1106.186\n",
      "    learn_time_ms: 1806.206\n",
      "    load_throughput: 57687.08\n",
      "    load_time_ms: 34.635\n",
      "    sample_throughput: 83.609\n",
      "    sample_time_ms: 23897.017\n",
      "    update_time_ms: 10.245\n",
      "  timestamp: 1636839653\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45954\n",
      "  training_iteration: 23\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         685.252</td><td style=\"text-align: right;\">45954</td><td style=\"text-align: right;\">   5.481</td><td style=\"text-align: right;\">               10.23</td><td style=\"text-align: right;\">                2.12</td><td style=\"text-align: right;\">             100.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 47952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-41-16\n",
      "  done: false\n",
      "  episode_len_mean: 100.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000017\n",
      "  episode_reward_mean: 5.572500000000019\n",
      "  episode_reward_min: 2.4600000000000155\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 488\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.3350787196840557\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013640002317765498\n",
      "          policy_loss: -0.05110659074215662\n",
      "          total_loss: 0.36989814889218126\n",
      "          vf_explained_var: 0.8353806138038635\n",
      "          vf_loss: 0.44162752699284324\n",
      "    num_agent_steps_sampled: 47952\n",
      "    num_agent_steps_trained: 47952\n",
      "    num_steps_sampled: 47952\n",
      "    num_steps_trained: 47952\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.27058823529411\n",
      "    ram_util_percent: 30.247058823529414\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045493970921485376\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.19954649426327\n",
      "    mean_inference_ms: 2.448873972554658\n",
      "    mean_raw_obs_processing_ms: 1.952771922198903\n",
      "  time_since_restore: 708.481365442276\n",
      "  time_this_iter_s: 23.229254245758057\n",
      "  time_total_s: 708.481365442276\n",
      "  timers:\n",
      "    learn_throughput: 1107.215\n",
      "    learn_time_ms: 1804.527\n",
      "    load_throughput: 58059.609\n",
      "    load_time_ms: 34.413\n",
      "    sample_throughput: 83.444\n",
      "    sample_time_ms: 23944.156\n",
      "    update_time_ms: 10.775\n",
      "  timestamp: 1636839676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 47952\n",
      "  training_iteration: 24\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         708.481</td><td style=\"text-align: right;\">47952</td><td style=\"text-align: right;\">  5.5725</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            100.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 49950\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-41-39\n",
      "  done: false\n",
      "  episode_len_mean: 100.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000017\n",
      "  episode_reward_mean: 5.667500000000018\n",
      "  episode_reward_min: 2.4600000000000155\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 507\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.356444097700573\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010378470414637539\n",
      "          policy_loss: -0.06722512328553767\n",
      "          total_loss: 0.30292990761143823\n",
      "          vf_explained_var: 0.8523162603378296\n",
      "          vf_loss: 0.3916437790507362\n",
      "    num_agent_steps_sampled: 49950\n",
      "    num_agent_steps_trained: 49950\n",
      "    num_steps_sampled: 49950\n",
      "    num_steps_trained: 49950\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84545454545454\n",
      "    ram_util_percent: 30.321212121212117\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045395714202756655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.884659175534864\n",
      "    mean_inference_ms: 2.448448608105173\n",
      "    mean_raw_obs_processing_ms: 1.899507609865246\n",
      "  time_since_restore: 731.530903339386\n",
      "  time_this_iter_s: 23.049537897109985\n",
      "  time_total_s: 731.530903339386\n",
      "  timers:\n",
      "    learn_throughput: 1109.431\n",
      "    learn_time_ms: 1800.923\n",
      "    load_throughput: 58933.703\n",
      "    load_time_ms: 33.903\n",
      "    sample_throughput: 83.551\n",
      "    sample_time_ms: 23913.476\n",
      "    update_time_ms: 12.292\n",
      "  timestamp: 1636839699\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 49950\n",
      "  training_iteration: 25\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         731.531</td><td style=\"text-align: right;\">49950</td><td style=\"text-align: right;\">  5.6675</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            100.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 51948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-42-03\n",
      "  done: false\n",
      "  episode_len_mean: 100.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000017\n",
      "  episode_reward_mean: 5.709200000000019\n",
      "  episode_reward_min: 2.4600000000000155\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 527\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.22615560009366\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010876461193898226\n",
      "          policy_loss: 0.03580805379010382\n",
      "          total_loss: 0.329451625226509\n",
      "          vf_explained_var: 0.8735321164131165\n",
      "          vf_loss: 0.3137298315763474\n",
      "    num_agent_steps_sampled: 51948\n",
      "    num_agent_steps_trained: 51948\n",
      "    num_steps_sampled: 51948\n",
      "    num_steps_trained: 51948\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77941176470588\n",
      "    ram_util_percent: 30.408823529411766\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04535054192546301\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.57316402517266\n",
      "    mean_inference_ms: 2.4483028936492537\n",
      "    mean_raw_obs_processing_ms: 1.8460847702440037\n",
      "  time_since_restore: 755.3677616119385\n",
      "  time_this_iter_s: 23.83685827255249\n",
      "  time_total_s: 755.3677616119385\n",
      "  timers:\n",
      "    learn_throughput: 1109.686\n",
      "    learn_time_ms: 1800.509\n",
      "    load_throughput: 58380.393\n",
      "    load_time_ms: 34.224\n",
      "    sample_throughput: 83.193\n",
      "    sample_time_ms: 24016.359\n",
      "    update_time_ms: 12.585\n",
      "  timestamp: 1636839723\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 51948\n",
      "  training_iteration: 26\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         755.368</td><td style=\"text-align: right;\">51948</td><td style=\"text-align: right;\">  5.7092</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            100.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 53946\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-42-27\n",
      "  done: false\n",
      "  episode_len_mean: 100.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000017\n",
      "  episode_reward_mean: 5.92750000000002\n",
      "  episode_reward_min: 2.6400000000000183\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 548\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.287757693018232\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012124861658591116\n",
      "          policy_loss: -0.047380413221461436\n",
      "          total_loss: 0.39520905942079565\n",
      "          vf_explained_var: 0.8263121247291565\n",
      "          vf_loss: 0.4630420730937095\n",
      "    num_agent_steps_sampled: 53946\n",
      "    num_agent_steps_trained: 53946\n",
      "    num_steps_sampled: 53946\n",
      "    num_steps_trained: 53946\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97272727272727\n",
      "    ram_util_percent: 30.369696969696967\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045278651737580146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.25698155248875\n",
      "    mean_inference_ms: 2.4479255803676376\n",
      "    mean_raw_obs_processing_ms: 1.795349919261478\n",
      "  time_since_restore: 778.8999552726746\n",
      "  time_this_iter_s: 23.532193660736084\n",
      "  time_total_s: 778.8999552726746\n",
      "  timers:\n",
      "    learn_throughput: 1110.49\n",
      "    learn_time_ms: 1799.206\n",
      "    load_throughput: 58761.095\n",
      "    load_time_ms: 34.002\n",
      "    sample_throughput: 83.062\n",
      "    sample_time_ms: 24054.276\n",
      "    update_time_ms: 12.733\n",
      "  timestamp: 1636839747\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 53946\n",
      "  training_iteration: 27\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">           778.9</td><td style=\"text-align: right;\">53946</td><td style=\"text-align: right;\">  5.9275</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">            100.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 55944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-42-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000017\n",
      "  episode_reward_mean: 5.85860000000002\n",
      "  episode_reward_min: 2.6400000000000183\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 567\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.2799507504417784\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009121437369209756\n",
      "          policy_loss: 0.00758086166211537\n",
      "          total_loss: 0.2887851867647398\n",
      "          vf_explained_var: 0.883094072341919\n",
      "          vf_loss: 0.30217954367399213\n",
      "    num_agent_steps_sampled: 55944\n",
      "    num_agent_steps_trained: 55944\n",
      "    num_steps_sampled: 55944\n",
      "    num_steps_trained: 55944\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.63939393939394\n",
      "    ram_util_percent: 30.427272727272726\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04521249773115587\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.98215188410246\n",
      "    mean_inference_ms: 2.447347893728204\n",
      "    mean_raw_obs_processing_ms: 1.7533050313307936\n",
      "  time_since_restore: 801.6680891513824\n",
      "  time_this_iter_s: 22.768133878707886\n",
      "  time_total_s: 801.6680891513824\n",
      "  timers:\n",
      "    learn_throughput: 1112.891\n",
      "    learn_time_ms: 1795.324\n",
      "    load_throughput: 58276.341\n",
      "    load_time_ms: 34.285\n",
      "    sample_throughput: 91.347\n",
      "    sample_time_ms: 21872.567\n",
      "    update_time_ms: 13.202\n",
      "  timestamp: 1636839770\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 55944\n",
      "  training_iteration: 28\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         801.668</td><td style=\"text-align: right;\">55944</td><td style=\"text-align: right;\">  5.8586</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">             100.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 57942\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-43-12\n",
      "  done: false\n",
      "  episode_len_mean: 101.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.180000000000017\n",
      "  episode_reward_mean: 5.797500000000021\n",
      "  episode_reward_min: 2.6400000000000183\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 586\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.253344862801688\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01051790001270669\n",
      "          policy_loss: -0.022880421915934198\n",
      "          total_loss: 0.390043277861107\n",
      "          vf_explained_var: 0.8290706276893616\n",
      "          vf_loss: 0.43335356797490804\n",
      "    num_agent_steps_sampled: 57942\n",
      "    num_agent_steps_trained: 57942\n",
      "    num_steps_sampled: 57942\n",
      "    num_steps_trained: 57942\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.78750000000001\n",
      "    ram_util_percent: 30.409374999999997\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045149438727414226\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.738900040862326\n",
      "    mean_inference_ms: 2.447292749094194\n",
      "    mean_raw_obs_processing_ms: 1.713950854888164\n",
      "  time_since_restore: 824.4092893600464\n",
      "  time_this_iter_s: 22.74120020866394\n",
      "  time_total_s: 824.4092893600464\n",
      "  timers:\n",
      "    learn_throughput: 1114.917\n",
      "    learn_time_ms: 1792.061\n",
      "    load_throughput: 58591.829\n",
      "    load_time_ms: 34.1\n",
      "    sample_throughput: 92.175\n",
      "    sample_time_ms: 21676.234\n",
      "    update_time_ms: 13.3\n",
      "  timestamp: 1636839792\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 57942\n",
      "  training_iteration: 29\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         824.409</td><td style=\"text-align: right;\">57942</td><td style=\"text-align: right;\">  5.7975</td><td style=\"text-align: right;\">               10.18</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">            101.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 59940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-43-36\n",
      "  done: false\n",
      "  episode_len_mean: 101.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.35000000000002\n",
      "  episode_reward_mean: 5.97190000000002\n",
      "  episode_reward_min: 2.6400000000000183\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 606\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.206914116087414\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012791359058644524\n",
      "          policy_loss: 0.010566581005141849\n",
      "          total_loss: 0.45577174350619315\n",
      "          vf_explained_var: 0.853949248790741\n",
      "          vf_loss: 0.46471603001867023\n",
      "    num_agent_steps_sampled: 59940\n",
      "    num_agent_steps_trained: 59940\n",
      "    num_steps_sampled: 59940\n",
      "    num_steps_trained: 59940\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.13823529411765\n",
      "    ram_util_percent: 30.385294117647057\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04509926472366793\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.48676472118732\n",
      "    mean_inference_ms: 2.447348540412957\n",
      "    mean_raw_obs_processing_ms: 1.6748234312414416\n",
      "  time_since_restore: 847.8392851352692\n",
      "  time_this_iter_s: 23.42999577522278\n",
      "  time_total_s: 847.8392851352692\n",
      "  timers:\n",
      "    learn_throughput: 1119.834\n",
      "    learn_time_ms: 1784.193\n",
      "    load_throughput: 58812.478\n",
      "    load_time_ms: 33.972\n",
      "    sample_throughput: 92.652\n",
      "    sample_time_ms: 21564.481\n",
      "    update_time_ms: 13.292\n",
      "  timestamp: 1636839816\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59940\n",
      "  training_iteration: 30\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         847.839</td><td style=\"text-align: right;\">59940</td><td style=\"text-align: right;\">  5.9719</td><td style=\"text-align: right;\">               14.35</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">            101.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 61938\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-43-59\n",
      "  done: false\n",
      "  episode_len_mean: 102.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.35000000000002\n",
      "  episode_reward_mean: 6.2725000000000195\n",
      "  episode_reward_min: 3.3900000000000245\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 624\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.223039882523673\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013395267183018063\n",
      "          policy_loss: -0.05143552449132715\n",
      "          total_loss: 0.3994637977154482\n",
      "          vf_explained_var: 0.8367322683334351\n",
      "          vf_loss: 0.4704506659791583\n",
      "    num_agent_steps_sampled: 61938\n",
      "    num_agent_steps_trained: 61938\n",
      "    num_steps_sampled: 61938\n",
      "    num_steps_trained: 61938\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.34545454545454\n",
      "    ram_util_percent: 30.442424242424238\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0450571548963022\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.277286604279944\n",
      "    mean_inference_ms: 2.4473794399355437\n",
      "    mean_raw_obs_processing_ms: 1.6427855630281685\n",
      "  time_since_restore: 870.9012105464935\n",
      "  time_this_iter_s: 23.061925411224365\n",
      "  time_total_s: 870.9012105464935\n",
      "  timers:\n",
      "    learn_throughput: 1115.878\n",
      "    learn_time_ms: 1790.519\n",
      "    load_throughput: 58736.095\n",
      "    load_time_ms: 34.017\n",
      "    sample_throughput: 93.34\n",
      "    sample_time_ms: 21405.695\n",
      "    update_time_ms: 13.424\n",
      "  timestamp: 1636839839\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 61938\n",
      "  training_iteration: 31\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         870.901</td><td style=\"text-align: right;\">61938</td><td style=\"text-align: right;\">  6.2725</td><td style=\"text-align: right;\">               14.35</td><td style=\"text-align: right;\">                3.39</td><td style=\"text-align: right;\">            102.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 63936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-44-23\n",
      "  done: false\n",
      "  episode_len_mean: 103.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.35000000000002\n",
      "  episode_reward_mean: 6.302900000000019\n",
      "  episode_reward_min: 3.3900000000000245\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 644\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.165848616191319\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013245639300085151\n",
      "          policy_loss: -0.022923911096794265\n",
      "          total_loss: 0.4228241551135268\n",
      "          vf_explained_var: 0.8276990652084351\n",
      "          vf_loss: 0.464757424451056\n",
      "    num_agent_steps_sampled: 63936\n",
      "    num_agent_steps_trained: 63936\n",
      "    num_steps_sampled: 63936\n",
      "    num_steps_trained: 63936\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99705882352941\n",
      "    ram_util_percent: 30.585294117647063\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04505799000386218\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.05971314856763\n",
      "    mean_inference_ms: 2.4473404244080474\n",
      "    mean_raw_obs_processing_ms: 1.6086986155931173\n",
      "  time_since_restore: 895.1697504520416\n",
      "  time_this_iter_s: 24.268539905548096\n",
      "  time_total_s: 895.1697504520416\n",
      "  timers:\n",
      "    learn_throughput: 1118.515\n",
      "    learn_time_ms: 1786.297\n",
      "    load_throughput: 58040.629\n",
      "    load_time_ms: 34.424\n",
      "    sample_throughput: 93.2\n",
      "    sample_time_ms: 21437.854\n",
      "    update_time_ms: 12.733\n",
      "  timestamp: 1636839863\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 63936\n",
      "  training_iteration: 32\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">          895.17</td><td style=\"text-align: right;\">63936</td><td style=\"text-align: right;\">  6.3029</td><td style=\"text-align: right;\">               14.35</td><td style=\"text-align: right;\">                3.39</td><td style=\"text-align: right;\">            103.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 65934\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-44-47\n",
      "  done: false\n",
      "  episode_len_mean: 102.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.35000000000002\n",
      "  episode_reward_mean: 6.522700000000019\n",
      "  episode_reward_min: 3.3900000000000245\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 664\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1413143441790625\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012360721057669763\n",
      "          policy_loss: -0.06393946464217845\n",
      "          total_loss: 0.20303927895923454\n",
      "          vf_explained_var: 0.917038083076477\n",
      "          vf_loss: 0.2859197423571632\n",
      "    num_agent_steps_sampled: 65934\n",
      "    num_agent_steps_trained: 65934\n",
      "    num_steps_sampled: 65934\n",
      "    num_steps_trained: 65934\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9205882352941\n",
      "    ram_util_percent: 30.570588235294114\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04509862655198971\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.85063571344656\n",
      "    mean_inference_ms: 2.447793641889806\n",
      "    mean_raw_obs_processing_ms: 1.576517133567283\n",
      "  time_since_restore: 918.5856924057007\n",
      "  time_this_iter_s: 23.415941953659058\n",
      "  time_total_s: 918.5856924057007\n",
      "  timers:\n",
      "    learn_throughput: 1109.129\n",
      "    learn_time_ms: 1801.414\n",
      "    load_throughput: 56921.635\n",
      "    load_time_ms: 35.101\n",
      "    sample_throughput: 93.049\n",
      "    sample_time_ms: 21472.647\n",
      "    update_time_ms: 14.732\n",
      "  timestamp: 1636839887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 65934\n",
      "  training_iteration: 33\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         918.586</td><td style=\"text-align: right;\">65934</td><td style=\"text-align: right;\">  6.5227</td><td style=\"text-align: right;\">               14.35</td><td style=\"text-align: right;\">                3.39</td><td style=\"text-align: right;\">            102.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 67932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-45-10\n",
      "  done: false\n",
      "  episode_len_mean: 102.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.35000000000002\n",
      "  episode_reward_mean: 6.683100000000019\n",
      "  episode_reward_min: 3.44000000000001\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 685\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.215674268631708\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012666681914419472\n",
      "          policy_loss: -0.05070006031365622\n",
      "          total_loss: 0.3505895922936144\n",
      "          vf_explained_var: 0.868750274181366\n",
      "          vf_loss: 0.42091305561008907\n",
      "    num_agent_steps_sampled: 67932\n",
      "    num_agent_steps_trained: 67932\n",
      "    num_steps_sampled: 67932\n",
      "    num_steps_trained: 67932\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00588235294116\n",
      "    ram_util_percent: 30.594117647058823\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04514612074437114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.65188866880165\n",
      "    mean_inference_ms: 2.448278735268176\n",
      "    mean_raw_obs_processing_ms: 1.546220394630323\n",
      "  time_since_restore: 942.2648799419403\n",
      "  time_this_iter_s: 23.679187536239624\n",
      "  time_total_s: 942.2648799419403\n",
      "  timers:\n",
      "    learn_throughput: 1110.57\n",
      "    learn_time_ms: 1799.076\n",
      "    load_throughput: 56674.686\n",
      "    load_time_ms: 35.254\n",
      "    sample_throughput: 92.847\n",
      "    sample_time_ms: 21519.223\n",
      "    update_time_ms: 15.159\n",
      "  timestamp: 1636839910\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 67932\n",
      "  training_iteration: 34\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         942.265</td><td style=\"text-align: right;\">67932</td><td style=\"text-align: right;\">  6.6831</td><td style=\"text-align: right;\">               14.35</td><td style=\"text-align: right;\">                3.44</td><td style=\"text-align: right;\">            102.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 69930\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-45-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.52000000000002\n",
      "  episode_reward_mean: 6.621500000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 704\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.2597378208523704\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014719511475148222\n",
      "          policy_loss: -0.010406661601293655\n",
      "          total_loss: 0.47844268935067313\n",
      "          vf_explained_var: 0.8472881317138672\n",
      "          vf_loss: 0.5085028210920947\n",
      "    num_agent_steps_sampled: 69930\n",
      "    num_agent_steps_trained: 69930\n",
      "    num_steps_sampled: 69930\n",
      "    num_steps_trained: 69930\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.09464285714286\n",
      "    ram_util_percent: 30.573214285714283\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04516738404808162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.5018107601499\n",
      "    mean_inference_ms: 2.44851811425065\n",
      "    mean_raw_obs_processing_ms: 1.5712210736124188\n",
      "  time_since_restore: 982.0396337509155\n",
      "  time_this_iter_s: 39.77475380897522\n",
      "  time_total_s: 982.0396337509155\n",
      "  timers:\n",
      "    learn_throughput: 1111.03\n",
      "    learn_time_ms: 1798.331\n",
      "    load_throughput: 55787.089\n",
      "    load_time_ms: 35.815\n",
      "    sample_throughput: 86.142\n",
      "    sample_time_ms: 23194.276\n",
      "    update_time_ms: 12.952\n",
      "  timestamp: 1636839950\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69930\n",
      "  training_iteration: 35\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">          982.04</td><td style=\"text-align: right;\">69930</td><td style=\"text-align: right;\">  6.6215</td><td style=\"text-align: right;\">               10.52</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            100.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 71928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-46-46\n",
      "  done: false\n",
      "  episode_len_mean: 98.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.95000000000002\n",
      "  episode_reward_mean: 6.69190000000002\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 726\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1538316896983556\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013106778795015036\n",
      "          policy_loss: -0.04740572777532396\n",
      "          total_loss: 0.6014426598236674\n",
      "          vf_explained_var: 0.838639497756958\n",
      "          vf_loss: 0.6677653463113875\n",
      "    num_agent_steps_sampled: 71928\n",
      "    num_agent_steps_trained: 71928\n",
      "    num_steps_sampled: 71928\n",
      "    num_steps_trained: 71928\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.34875\n",
      "    ram_util_percent: 30.167499999999997\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045192766387962637\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.3405391893863\n",
      "    mean_inference_ms: 2.4485278024037664\n",
      "    mean_raw_obs_processing_ms: 1.6995868027451884\n",
      "  time_since_restore: 1038.0106196403503\n",
      "  time_this_iter_s: 55.970985889434814\n",
      "  time_total_s: 1038.0106196403503\n",
      "  timers:\n",
      "    learn_throughput: 1112.229\n",
      "    learn_time_ms: 1796.393\n",
      "    load_throughput: 55902.826\n",
      "    load_time_ms: 35.741\n",
      "    sample_throughput: 75.652\n",
      "    sample_time_ms: 26410.281\n",
      "    update_time_ms: 12.619\n",
      "  timestamp: 1636840006\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 71928\n",
      "  training_iteration: 36\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         1038.01</td><td style=\"text-align: right;\">71928</td><td style=\"text-align: right;\">  6.6919</td><td style=\"text-align: right;\">               13.95</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">              98.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 73926\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-47-11\n",
      "  done: false\n",
      "  episode_len_mean: 98.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.95000000000002\n",
      "  episode_reward_mean: 7.125400000000019\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 747\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1714624155135382\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01239845241823041\n",
      "          policy_loss: -0.019307865025032133\n",
      "          total_loss: 0.428766608415615\n",
      "          vf_explained_var: 0.8756886720657349\n",
      "          vf_loss: 0.4673094034194946\n",
      "    num_agent_steps_sampled: 73926\n",
      "    num_agent_steps_trained: 73926\n",
      "    num_steps_sampled: 73926\n",
      "    num_steps_trained: 73926\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77714285714283\n",
      "    ram_util_percent: 29.908571428571427\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04516313836698501\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.197488312169384\n",
      "    mean_inference_ms: 2.4483431738857453\n",
      "    mean_raw_obs_processing_ms: 1.8204254588531483\n",
      "  time_since_restore: 1062.3640444278717\n",
      "  time_this_iter_s: 24.353424787521362\n",
      "  time_total_s: 1062.3640444278717\n",
      "  timers:\n",
      "    learn_throughput: 1113.413\n",
      "    learn_time_ms: 1794.482\n",
      "    load_throughput: 55590.879\n",
      "    load_time_ms: 35.941\n",
      "    sample_throughput: 75.412\n",
      "    sample_time_ms: 26494.466\n",
      "    update_time_ms: 12.341\n",
      "  timestamp: 1636840031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 73926\n",
      "  training_iteration: 37\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         1062.36</td><td style=\"text-align: right;\">73926</td><td style=\"text-align: right;\">  7.1254</td><td style=\"text-align: right;\">               13.95</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             98.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 75924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-47-34\n",
      "  done: false\n",
      "  episode_len_mean: 98.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.46000000000002\n",
      "  episode_reward_mean: 7.308200000000019\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 765\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1315475480897086\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015857734824745735\n",
      "          policy_loss: -0.028750535153916904\n",
      "          total_loss: 0.5389289518197378\n",
      "          vf_explained_var: 0.8449329733848572\n",
      "          vf_loss: 0.5858234115299724\n",
      "    num_agent_steps_sampled: 75924\n",
      "    num_agent_steps_trained: 75924\n",
      "    num_steps_sampled: 75924\n",
      "    num_steps_trained: 75924\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.44999999999999\n",
      "    ram_util_percent: 30.16176470588235\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04509772176973184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.077710922462074\n",
      "    mean_inference_ms: 2.447300285407771\n",
      "    mean_raw_obs_processing_ms: 1.9222180461132141\n",
      "  time_since_restore: 1086.0009870529175\n",
      "  time_this_iter_s: 23.636942625045776\n",
      "  time_total_s: 1086.0009870529175\n",
      "  timers:\n",
      "    learn_throughput: 1113.471\n",
      "    learn_time_ms: 1794.389\n",
      "    load_throughput: 55608.622\n",
      "    load_time_ms: 35.93\n",
      "    sample_throughput: 75.166\n",
      "    sample_time_ms: 26581.233\n",
      "    update_time_ms: 12.736\n",
      "  timestamp: 1636840054\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 75924\n",
      "  training_iteration: 38\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">            1086</td><td style=\"text-align: right;\">75924</td><td style=\"text-align: right;\">  7.3082</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             98.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 77922\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-47-59\n",
      "  done: false\n",
      "  episode_len_mean: 97.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.46000000000002\n",
      "  episode_reward_mean: 7.721300000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 786\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.064345473902566\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011214653417578825\n",
      "          policy_loss: -0.04236576690205506\n",
      "          total_loss: 0.47134813361224676\n",
      "          vf_explained_var: 0.8747237324714661\n",
      "          vf_loss: 0.5321144228889829\n",
      "    num_agent_steps_sampled: 77922\n",
      "    num_agent_steps_trained: 77922\n",
      "    num_steps_sampled: 77922\n",
      "    num_steps_trained: 77922\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.36944444444444\n",
      "    ram_util_percent: 30.32222222222222\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04503821457623757\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.9509707148552\n",
      "    mean_inference_ms: 2.4465639144995834\n",
      "    mean_raw_obs_processing_ms: 2.0303868314365343\n",
      "  time_since_restore: 1110.9867634773254\n",
      "  time_this_iter_s: 24.98577642440796\n",
      "  time_total_s: 1110.9867634773254\n",
      "  timers:\n",
      "    learn_throughput: 1114.634\n",
      "    learn_time_ms: 1792.516\n",
      "    load_throughput: 55772.758\n",
      "    load_time_ms: 35.824\n",
      "    sample_throughput: 74.53\n",
      "    sample_time_ms: 26807.843\n",
      "    update_time_ms: 12.601\n",
      "  timestamp: 1636840079\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 77922\n",
      "  training_iteration: 39\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         1110.99</td><td style=\"text-align: right;\">77922</td><td style=\"text-align: right;\">  7.7213</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             97.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 79920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-48-23\n",
      "  done: false\n",
      "  episode_len_mean: 97.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.460000000000015\n",
      "  episode_reward_mean: 8.061300000000019\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 807\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0811310535385497\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013505505481622113\n",
      "          policy_loss: 0.008054204568976448\n",
      "          total_loss: 0.5953687170431727\n",
      "          vf_explained_var: 0.8839794397354126\n",
      "          vf_loss: 0.6054247186297462\n",
      "    num_agent_steps_sampled: 79920\n",
      "    num_agent_steps_trained: 79920\n",
      "    num_steps_sampled: 79920\n",
      "    num_steps_trained: 79920\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.18484848484849\n",
      "    ram_util_percent: 30.57272727272727\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04500329620271483\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.84174054206626\n",
      "    mean_inference_ms: 2.446345151204405\n",
      "    mean_raw_obs_processing_ms: 2.0789521989106943\n",
      "  time_since_restore: 1134.644476890564\n",
      "  time_this_iter_s: 23.657713413238525\n",
      "  time_total_s: 1134.644476890564\n",
      "  timers:\n",
      "    learn_throughput: 1116.695\n",
      "    learn_time_ms: 1789.208\n",
      "    load_throughput: 55911.591\n",
      "    load_time_ms: 35.735\n",
      "    sample_throughput: 74.458\n",
      "    sample_time_ms: 26833.887\n",
      "    update_time_ms: 12.592\n",
      "  timestamp: 1636840103\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79920\n",
      "  training_iteration: 40\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         1134.64</td><td style=\"text-align: right;\">79920</td><td style=\"text-align: right;\">  8.0613</td><td style=\"text-align: right;\">               16.46</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             97.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 81918\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-48-46\n",
      "  done: false\n",
      "  episode_len_mean: 98.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.460000000000015\n",
      "  episode_reward_mean: 8.510200000000019\n",
      "  episode_reward_min: 3.9500000000000224\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 827\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1464827685129073\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010095882892295125\n",
      "          policy_loss: -0.010805136302397364\n",
      "          total_loss: 0.5121090232793774\n",
      "          vf_explained_var: 0.8780866861343384\n",
      "          vf_loss: 0.5423598075196856\n",
      "    num_agent_steps_sampled: 81918\n",
      "    num_agent_steps_trained: 81918\n",
      "    num_steps_sampled: 81918\n",
      "    num_steps_trained: 81918\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.32727272727271\n",
      "    ram_util_percent: 30.724242424242423\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04493699070518401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.727967041370796\n",
      "    mean_inference_ms: 2.445654094502237\n",
      "    mean_raw_obs_processing_ms: 2.0431416073137916\n",
      "  time_since_restore: 1157.4474618434906\n",
      "  time_this_iter_s: 22.802984952926636\n",
      "  time_total_s: 1157.4474618434906\n",
      "  timers:\n",
      "    learn_throughput: 1121.035\n",
      "    learn_time_ms: 1782.281\n",
      "    load_throughput: 55847.28\n",
      "    load_time_ms: 35.776\n",
      "    sample_throughput: 74.509\n",
      "    sample_time_ms: 26815.557\n",
      "    update_time_ms: 12.175\n",
      "  timestamp: 1636840126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 81918\n",
      "  training_iteration: 41\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         1157.45</td><td style=\"text-align: right;\">81918</td><td style=\"text-align: right;\">  8.5102</td><td style=\"text-align: right;\">               16.46</td><td style=\"text-align: right;\">                3.95</td><td style=\"text-align: right;\">             98.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 83916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-49-10\n",
      "  done: false\n",
      "  episode_len_mean: 98.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.460000000000015\n",
      "  episode_reward_mean: 8.570000000000018\n",
      "  episode_reward_min: 3.9500000000000224\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 847\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0686467778115047\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01022427188789296\n",
      "          policy_loss: -0.013151278187121664\n",
      "          total_loss: 0.4305997407862118\n",
      "          vf_explained_var: 0.915442168712616\n",
      "          vf_loss: 0.4623926331599553\n",
      "    num_agent_steps_sampled: 83916\n",
      "    num_agent_steps_trained: 83916\n",
      "    num_steps_sampled: 83916\n",
      "    num_steps_trained: 83916\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.30000000000001\n",
      "    ram_util_percent: 30.8\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04487286237671959\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.62376702720403\n",
      "    mean_inference_ms: 2.4449476430207753\n",
      "    mean_raw_obs_processing_ms: 2.0087157201978907\n",
      "  time_since_restore: 1181.1319320201874\n",
      "  time_this_iter_s: 23.684470176696777\n",
      "  time_total_s: 1181.1319320201874\n",
      "  timers:\n",
      "    learn_throughput: 1118.047\n",
      "    learn_time_ms: 1787.044\n",
      "    load_throughput: 56427.248\n",
      "    load_time_ms: 35.408\n",
      "    sample_throughput: 74.685\n",
      "    sample_time_ms: 26752.495\n",
      "    update_time_ms: 12.459\n",
      "  timestamp: 1636840150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 83916\n",
      "  training_iteration: 42\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         1181.13</td><td style=\"text-align: right;\">83916</td><td style=\"text-align: right;\">    8.57</td><td style=\"text-align: right;\">               16.46</td><td style=\"text-align: right;\">                3.95</td><td style=\"text-align: right;\">             98.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 85914\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-49-34\n",
      "  done: false\n",
      "  episode_len_mean: 98.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.460000000000015\n",
      "  episode_reward_mean: 9.079700000000019\n",
      "  episode_reward_min: 4.630000000000015\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 867\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.048621946857089\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012956297944678986\n",
      "          policy_loss: -0.028654830441588446\n",
      "          total_loss: 0.4890399945101568\n",
      "          vf_explained_var: 0.9115848541259766\n",
      "          vf_loss: 0.5355897863705953\n",
      "    num_agent_steps_sampled: 85914\n",
      "    num_agent_steps_trained: 85914\n",
      "    num_steps_sampled: 85914\n",
      "    num_steps_trained: 85914\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.25882352941176\n",
      "    ram_util_percent: 30.829411764705885\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04485622215089236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.53284532279687\n",
      "    mean_inference_ms: 2.4447518906525887\n",
      "    mean_raw_obs_processing_ms: 1.9762753213597894\n",
      "  time_since_restore: 1205.2441773414612\n",
      "  time_this_iter_s: 24.112245321273804\n",
      "  time_total_s: 1205.2441773414612\n",
      "  timers:\n",
      "    learn_throughput: 1129.833\n",
      "    learn_time_ms: 1768.403\n",
      "    load_throughput: 57578.756\n",
      "    load_time_ms: 34.7\n",
      "    sample_throughput: 74.433\n",
      "    sample_time_ms: 26842.784\n",
      "    update_time_ms: 10.904\n",
      "  timestamp: 1636840174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 85914\n",
      "  training_iteration: 43\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         1205.24</td><td style=\"text-align: right;\">85914</td><td style=\"text-align: right;\">  9.0797</td><td style=\"text-align: right;\">               16.46</td><td style=\"text-align: right;\">                4.63</td><td style=\"text-align: right;\">             98.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 87912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-49-58\n",
      "  done: false\n",
      "  episode_len_mean: 99.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.460000000000015\n",
      "  episode_reward_mean: 9.188500000000019\n",
      "  episode_reward_min: 4.630000000000015\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 887\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0166887419564383\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012632427444844435\n",
      "          policy_loss: -0.034545144687096276\n",
      "          total_loss: 0.4466810532269024\n",
      "          vf_explained_var: 0.9166868925094604\n",
      "          vf_loss: 0.4988665967470124\n",
      "    num_agent_steps_sampled: 87912\n",
      "    num_agent_steps_trained: 87912\n",
      "    num_steps_sampled: 87912\n",
      "    num_steps_trained: 87912\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72000000000001\n",
      "    ram_util_percent: 30.897142857142853\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04482011757535591\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.444182342629844\n",
      "    mean_inference_ms: 2.443902548163057\n",
      "    mean_raw_obs_processing_ms: 1.9456934288189314\n",
      "  time_since_restore: 1229.4810285568237\n",
      "  time_this_iter_s: 24.23685121536255\n",
      "  time_total_s: 1229.4810285568237\n",
      "  timers:\n",
      "    learn_throughput: 1118.3\n",
      "    learn_time_ms: 1786.641\n",
      "    load_throughput: 58684.352\n",
      "    load_time_ms: 34.047\n",
      "    sample_throughput: 74.326\n",
      "    sample_time_ms: 26881.495\n",
      "    update_time_ms: 10.39\n",
      "  timestamp: 1636840198\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 87912\n",
      "  training_iteration: 44\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         1229.48</td><td style=\"text-align: right;\">87912</td><td style=\"text-align: right;\">  9.1885</td><td style=\"text-align: right;\">               16.46</td><td style=\"text-align: right;\">                4.63</td><td style=\"text-align: right;\">             99.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 89910\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-50-22\n",
      "  done: false\n",
      "  episode_len_mean: 99.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.960000000000015\n",
      "  episode_reward_mean: 9.471100000000018\n",
      "  episode_reward_min: 4.630000000000015\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 907\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9679873914945694\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014778833888478834\n",
      "          policy_loss: -0.09830938027728171\n",
      "          total_loss: 0.44313295801125824\n",
      "          vf_explained_var: 0.9086946249008179\n",
      "          vf_loss: 0.5581664445144789\n",
      "    num_agent_steps_sampled: 89910\n",
      "    num_agent_steps_trained: 89910\n",
      "    num_steps_sampled: 89910\n",
      "    num_steps_trained: 89910\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.05588235294118\n",
      "    ram_util_percent: 30.967647058823527\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04478076989918114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.349792272304896\n",
      "    mean_inference_ms: 2.443297973305836\n",
      "    mean_raw_obs_processing_ms: 1.9162177498540314\n",
      "  time_since_restore: 1253.2645118236542\n",
      "  time_this_iter_s: 23.783483266830444\n",
      "  time_total_s: 1253.2645118236542\n",
      "  timers:\n",
      "    learn_throughput: 1117.399\n",
      "    learn_time_ms: 1788.08\n",
      "    load_throughput: 58275.692\n",
      "    load_time_ms: 34.285\n",
      "    sample_throughput: 79.036\n",
      "    sample_time_ms: 25279.567\n",
      "    update_time_ms: 11.242\n",
      "  timestamp: 1636840222\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89910\n",
      "  training_iteration: 45\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         1253.26</td><td style=\"text-align: right;\">89910</td><td style=\"text-align: right;\">  9.4711</td><td style=\"text-align: right;\">               14.96</td><td style=\"text-align: right;\">                4.63</td><td style=\"text-align: right;\">             99.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 91908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-50-45\n",
      "  done: false\n",
      "  episode_len_mean: 100.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.960000000000015\n",
      "  episode_reward_mean: 9.610800000000019\n",
      "  episode_reward_min: 0.7499999999999991\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 926\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9951680949756077\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015030189551314356\n",
      "          policy_loss: -0.04139558186843282\n",
      "          total_loss: 0.3450906290096186\n",
      "          vf_explained_var: 0.9335429668426514\n",
      "          vf_loss: 0.403431856348401\n",
      "    num_agent_steps_sampled: 91908\n",
      "    num_agent_steps_trained: 91908\n",
      "    num_steps_sampled: 91908\n",
      "    num_steps_trained: 91908\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.20303030303032\n",
      "    ram_util_percent: 30.930303030303033\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044744506065176194\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.274688080720004\n",
      "    mean_inference_ms: 2.442702532572303\n",
      "    mean_raw_obs_processing_ms: 1.889149508368011\n",
      "  time_since_restore: 1276.8606333732605\n",
      "  time_this_iter_s: 23.596121549606323\n",
      "  time_total_s: 1276.8606333732605\n",
      "  timers:\n",
      "    learn_throughput: 1116.91\n",
      "    learn_time_ms: 1788.864\n",
      "    load_throughput: 58213.23\n",
      "    load_time_ms: 34.322\n",
      "    sample_throughput: 90.657\n",
      "    sample_time_ms: 22039.09\n",
      "    update_time_ms: 12.789\n",
      "  timestamp: 1636840245\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 91908\n",
      "  training_iteration: 46\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         1276.86</td><td style=\"text-align: right;\">91908</td><td style=\"text-align: right;\">  9.6108</td><td style=\"text-align: right;\">               14.96</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">            100.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 93906\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-51-09\n",
      "  done: false\n",
      "  episode_len_mean: 100.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.960000000000015\n",
      "  episode_reward_mean: 9.81280000000002\n",
      "  episode_reward_min: 0.7499999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 946\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9446950554847717\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.027832933045832352\n",
      "          policy_loss: -0.003910987540369942\n",
      "          total_loss: 0.4592363591261563\n",
      "          vf_explained_var: 0.931538999080658\n",
      "          vf_loss: 0.4770277087177549\n",
      "    num_agent_steps_sampled: 93906\n",
      "    num_agent_steps_trained: 93906\n",
      "    num_steps_sampled: 93906\n",
      "    num_steps_trained: 93906\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11470588235295\n",
      "    ram_util_percent: 30.923529411764708\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04472887327560738\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.18900755456588\n",
      "    mean_inference_ms: 2.442286091189946\n",
      "    mean_raw_obs_processing_ms: 1.861318521863368\n",
      "  time_since_restore: 1300.5289697647095\n",
      "  time_this_iter_s: 23.668336391448975\n",
      "  time_total_s: 1300.5289697647095\n",
      "  timers:\n",
      "    learn_throughput: 1117.473\n",
      "    learn_time_ms: 1787.962\n",
      "    load_throughput: 57985.168\n",
      "    load_time_ms: 34.457\n",
      "    sample_throughput: 90.936\n",
      "    sample_time_ms: 21971.612\n",
      "    update_time_ms: 12.165\n",
      "  timestamp: 1636840269\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 93906\n",
      "  training_iteration: 47\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         1300.53</td><td style=\"text-align: right;\">93906</td><td style=\"text-align: right;\">  9.8128</td><td style=\"text-align: right;\">               14.96</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">            100.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 95904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-51-32\n",
      "  done: false\n",
      "  episode_len_mean: 100.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.960000000000015\n",
      "  episode_reward_mean: 9.889800000000019\n",
      "  episode_reward_min: 0.7499999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 966\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.012054267383757\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016390518253093393\n",
      "          policy_loss: 0.02939922386514289\n",
      "          total_loss: 0.47891050222374143\n",
      "          vf_explained_var: 0.9373710751533508\n",
      "          vf_loss: 0.46471466493038904\n",
      "    num_agent_steps_sampled: 95904\n",
      "    num_agent_steps_trained: 95904\n",
      "    num_steps_sampled: 95904\n",
      "    num_steps_trained: 95904\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6818181818182\n",
      "    ram_util_percent: 30.921212121212122\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04470898081549803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.107603050925725\n",
      "    mean_inference_ms: 2.4420125742739276\n",
      "    mean_raw_obs_processing_ms: 1.8345554847067758\n",
      "  time_since_restore: 1323.572509765625\n",
      "  time_this_iter_s: 23.043540000915527\n",
      "  time_total_s: 1323.572509765625\n",
      "  timers:\n",
      "    learn_throughput: 1117.659\n",
      "    learn_time_ms: 1787.666\n",
      "    load_throughput: 58511.606\n",
      "    load_time_ms: 34.147\n",
      "    sample_throughput: 91.176\n",
      "    sample_time_ms: 21913.716\n",
      "    update_time_ms: 11.404\n",
      "  timestamp: 1636840292\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 95904\n",
      "  training_iteration: 48\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         1323.57</td><td style=\"text-align: right;\">95904</td><td style=\"text-align: right;\">  9.8898</td><td style=\"text-align: right;\">               14.96</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">            100.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 97902\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-51-55\n",
      "  done: false\n",
      "  episode_len_mean: 102.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.579999999999988\n",
      "  episode_reward_mean: 10.317100000000018\n",
      "  episode_reward_min: 0.7499999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 986\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.005710151649657\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0168506960699954\n",
      "          policy_loss: -0.04903369453691301\n",
      "          total_loss: 0.3583350877854086\n",
      "          vf_explained_var: 0.9539857506752014\n",
      "          vf_loss: 0.4223706740708578\n",
      "    num_agent_steps_sampled: 97902\n",
      "    num_agent_steps_trained: 97902\n",
      "    num_steps_sampled: 97902\n",
      "    num_steps_trained: 97902\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66666666666667\n",
      "    ram_util_percent: 30.918181818181818\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04468550610900962\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.015382622697445\n",
      "    mean_inference_ms: 2.4414752669576045\n",
      "    mean_raw_obs_processing_ms: 1.8093156402031005\n",
      "  time_since_restore: 1346.2582113742828\n",
      "  time_this_iter_s: 22.685701608657837\n",
      "  time_total_s: 1346.2582113742828\n",
      "  timers:\n",
      "    learn_throughput: 1120.661\n",
      "    learn_time_ms: 1782.876\n",
      "    load_throughput: 58277.84\n",
      "    load_time_ms: 34.284\n",
      "    sample_throughput: 92.125\n",
      "    sample_time_ms: 21687.926\n",
      "    update_time_ms: 11.898\n",
      "  timestamp: 1636840315\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 97902\n",
      "  training_iteration: 49\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         1346.26</td><td style=\"text-align: right;\">97902</td><td style=\"text-align: right;\"> 10.3171</td><td style=\"text-align: right;\">               16.58</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">            102.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 99900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-52-17\n",
      "  done: false\n",
      "  episode_len_mean: 103.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.579999999999988\n",
      "  episode_reward_mean: 10.481700000000021\n",
      "  episode_reward_min: 0.7499999999999991\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1004\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9971751905622936\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010432108442718132\n",
      "          policy_loss: -0.08750912676609698\n",
      "          total_loss: 0.2918745179084085\n",
      "          vf_explained_var: 0.9508228302001953\n",
      "          vf_loss: 0.3962257669440338\n",
      "    num_agent_steps_sampled: 99900\n",
      "    num_agent_steps_trained: 99900\n",
      "    num_steps_sampled: 99900\n",
      "    num_steps_trained: 99900\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84193548387097\n",
      "    ram_util_percent: 30.912903225806446\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04466345508448057\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.935736637087075\n",
      "    mean_inference_ms: 2.4410189913824802\n",
      "    mean_raw_obs_processing_ms: 1.7872295076426954\n",
      "  time_since_restore: 1368.2696497440338\n",
      "  time_this_iter_s: 22.011438369750977\n",
      "  time_total_s: 1368.2696497440338\n",
      "  timers:\n",
      "    learn_throughput: 1118.816\n",
      "    learn_time_ms: 1785.816\n",
      "    load_throughput: 58596.049\n",
      "    load_time_ms: 34.098\n",
      "    sample_throughput: 92.841\n",
      "    sample_time_ms: 21520.721\n",
      "    update_time_ms: 11.682\n",
      "  timestamp: 1636840337\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99900\n",
      "  training_iteration: 50\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         1368.27</td><td style=\"text-align: right;\">99900</td><td style=\"text-align: right;\"> 10.4817</td><td style=\"text-align: right;\">               16.58</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">            103.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 101898\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-52-39\n",
      "  done: false\n",
      "  episode_len_mean: 104.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.579999999999988\n",
      "  episode_reward_mean: 10.956900000000017\n",
      "  episode_reward_min: 3.4600000000000097\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1022\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9686478132293337\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009381469613467436\n",
      "          policy_loss: -0.008493452572396823\n",
      "          total_loss: 0.3636843596895536\n",
      "          vf_explained_var: 0.9585323333740234\n",
      "          vf_loss: 0.38904985111384166\n",
      "    num_agent_steps_sampled: 101898\n",
      "    num_agent_steps_trained: 101898\n",
      "    num_steps_sampled: 101898\n",
      "    num_steps_trained: 101898\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.059375\n",
      "    ram_util_percent: 30.896875\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044646087492143216\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.844502204334585\n",
      "    mean_inference_ms: 2.4405227488346033\n",
      "    mean_raw_obs_processing_ms: 1.765508684141082\n",
      "  time_since_restore: 1390.384205341339\n",
      "  time_this_iter_s: 22.114555597305298\n",
      "  time_total_s: 1390.384205341339\n",
      "  timers:\n",
      "    learn_throughput: 1117.474\n",
      "    learn_time_ms: 1787.96\n",
      "    load_throughput: 58870.485\n",
      "    load_time_ms: 33.939\n",
      "    sample_throughput: 93.148\n",
      "    sample_time_ms: 21449.678\n",
      "    update_time_ms: 11.841\n",
      "  timestamp: 1636840359\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 101898\n",
      "  training_iteration: 51\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         1390.38</td><td style=\"text-align: right;\">101898</td><td style=\"text-align: right;\"> 10.9569</td><td style=\"text-align: right;\">               16.58</td><td style=\"text-align: right;\">                3.46</td><td style=\"text-align: right;\">            104.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 103896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-53-01\n",
      "  done: false\n",
      "  episode_len_mean: 105.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.579999999999988\n",
      "  episode_reward_mean: 11.31800000000002\n",
      "  episode_reward_min: 7.070000000000013\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1040\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.002624391941797\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01054113614840447\n",
      "          policy_loss: -0.03129929084153402\n",
      "          total_loss: 0.34779087911315615\n",
      "          vf_explained_var: 0.9602723717689514\n",
      "          vf_loss: 0.39595407254639126\n",
      "    num_agent_steps_sampled: 103896\n",
      "    num_agent_steps_trained: 103896\n",
      "    num_steps_sampled: 103896\n",
      "    num_steps_trained: 103896\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84193548387098\n",
      "    ram_util_percent: 30.841935483870966\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04461991211492511\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.756117868453966\n",
      "    mean_inference_ms: 2.440150117247574\n",
      "    mean_raw_obs_processing_ms: 1.74416964244474\n",
      "  time_since_restore: 1412.661173582077\n",
      "  time_this_iter_s: 22.276968240737915\n",
      "  time_total_s: 1412.661173582077\n",
      "  timers:\n",
      "    learn_throughput: 1118.51\n",
      "    learn_time_ms: 1786.305\n",
      "    load_throughput: 59038.746\n",
      "    load_time_ms: 33.842\n",
      "    sample_throughput: 93.759\n",
      "    sample_time_ms: 21309.935\n",
      "    update_time_ms: 12.529\n",
      "  timestamp: 1636840381\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 103896\n",
      "  training_iteration: 52\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         1412.66</td><td style=\"text-align: right;\">103896</td><td style=\"text-align: right;\">  11.318</td><td style=\"text-align: right;\">               16.58</td><td style=\"text-align: right;\">                7.07</td><td style=\"text-align: right;\">            105.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 105894\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-53-40\n",
      "  done: false\n",
      "  episode_len_mean: 105.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.589999999999986\n",
      "  episode_reward_mean: 11.608300000000016\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1060\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9286688117753892\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014041773168410588\n",
      "          policy_loss: 0.015964301409465927\n",
      "          total_loss: 0.7691049462273007\n",
      "          vf_explained_var: 0.9292076230049133\n",
      "          vf_loss: 0.7682147937871161\n",
      "    num_agent_steps_sampled: 105894\n",
      "    num_agent_steps_trained: 105894\n",
      "    num_steps_sampled: 105894\n",
      "    num_steps_trained: 105894\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.90714285714284\n",
      "    ram_util_percent: 30.532142857142855\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04458112378650471\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.651494564386553\n",
      "    mean_inference_ms: 2.439389631980964\n",
      "    mean_raw_obs_processing_ms: 1.7542811730538657\n",
      "  time_since_restore: 1451.3145666122437\n",
      "  time_this_iter_s: 38.653393030166626\n",
      "  time_total_s: 1451.3145666122437\n",
      "  timers:\n",
      "    learn_throughput: 1119.594\n",
      "    learn_time_ms: 1784.576\n",
      "    load_throughput: 58968.413\n",
      "    load_time_ms: 33.883\n",
      "    sample_throughput: 87.764\n",
      "    sample_time_ms: 22765.571\n",
      "    update_time_ms: 12.843\n",
      "  timestamp: 1636840420\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 105894\n",
      "  training_iteration: 53\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         1451.31</td><td style=\"text-align: right;\">105894</td><td style=\"text-align: right;\"> 11.6083</td><td style=\"text-align: right;\">               16.59</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            105.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 107892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-54-35\n",
      "  done: false\n",
      "  episode_len_mean: 104.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.700000000000014\n",
      "  episode_reward_mean: 11.778400000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1080\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9058170261837186\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015898508982469892\n",
      "          policy_loss: -0.06640237750751632\n",
      "          total_loss: 0.7704279189663273\n",
      "          vf_explained_var: 0.9123910069465637\n",
      "          vf_loss: 0.85111890598422\n",
      "    num_agent_steps_sampled: 107892\n",
      "    num_agent_steps_trained: 107892\n",
      "    num_steps_sampled: 107892\n",
      "    num_steps_trained: 107892\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.31153846153846\n",
      "    ram_util_percent: 30.334615384615383\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04455447078934181\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.54922884160824\n",
      "    mean_inference_ms: 2.4392555758645424\n",
      "    mean_raw_obs_processing_ms: 1.8231384837311793\n",
      "  time_since_restore: 1505.9243094921112\n",
      "  time_this_iter_s: 54.609742879867554\n",
      "  time_total_s: 1505.9243094921112\n",
      "  timers:\n",
      "    learn_throughput: 1130.339\n",
      "    learn_time_ms: 1767.611\n",
      "    load_throughput: 58310.686\n",
      "    load_time_ms: 34.265\n",
      "    sample_throughput: 77.382\n",
      "    sample_time_ms: 25820.012\n",
      "    update_time_ms: 12.277\n",
      "  timestamp: 1636840475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 107892\n",
      "  training_iteration: 54\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         1505.92</td><td style=\"text-align: right;\">107892</td><td style=\"text-align: right;\"> 11.7784</td><td style=\"text-align: right;\">                16.7</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            104.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 109890\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-54-58\n",
      "  done: false\n",
      "  episode_len_mean: 104.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.869999999999983\n",
      "  episode_reward_mean: 12.163700000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1099\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9428518624532791\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014978119109153368\n",
      "          policy_loss: -0.06931650596005576\n",
      "          total_loss: 0.34688504434944617\n",
      "          vf_explained_var: 0.953303337097168\n",
      "          vf_loss: 0.4311366311851002\n",
      "    num_agent_steps_sampled: 109890\n",
      "    num_agent_steps_trained: 109890\n",
      "    num_steps_sampled: 109890\n",
      "    num_steps_trained: 109890\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.64242424242424\n",
      "    ram_util_percent: 29.88484848484849\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0445196013924307\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.456921812840484\n",
      "    mean_inference_ms: 2.438792530475483\n",
      "    mean_raw_obs_processing_ms: 1.8881221919175863\n",
      "  time_since_restore: 1529.0409700870514\n",
      "  time_this_iter_s: 23.116660594940186\n",
      "  time_total_s: 1529.0409700870514\n",
      "  timers:\n",
      "    learn_throughput: 1130.51\n",
      "    learn_time_ms: 1767.345\n",
      "    load_throughput: 58335.0\n",
      "    load_time_ms: 34.25\n",
      "    sample_throughput: 77.585\n",
      "    sample_time_ms: 25752.296\n",
      "    update_time_ms: 13.597\n",
      "  timestamp: 1636840498\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109890\n",
      "  training_iteration: 55\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         1529.04</td><td style=\"text-align: right;\">109890</td><td style=\"text-align: right;\"> 12.1637</td><td style=\"text-align: right;\">               16.87</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            104.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 111888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 105.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.869999999999983\n",
      "  episode_reward_mean: 12.164000000000014\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1118\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.909884478364672\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012747264172949116\n",
      "          policy_loss: -0.09826074632860365\n",
      "          total_loss: 0.4259021386415476\n",
      "          vf_explained_var: 0.9488880038261414\n",
      "          vf_loss: 0.5394375527188892\n",
      "    num_agent_steps_sampled: 111888\n",
      "    num_agent_steps_trained: 111888\n",
      "    num_steps_sampled: 111888\n",
      "    num_steps_trained: 111888\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.67741935483872\n",
      "    ram_util_percent: 30.13548387096774\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04448839686445869\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.36809225758452\n",
      "    mean_inference_ms: 2.4384750346800406\n",
      "    mean_raw_obs_processing_ms: 1.9526090145704103\n",
      "  time_since_restore: 1551.345113992691\n",
      "  time_this_iter_s: 22.30414390563965\n",
      "  time_total_s: 1551.345113992691\n",
      "  timers:\n",
      "    learn_throughput: 1130.613\n",
      "    learn_time_ms: 1767.183\n",
      "    load_throughput: 58612.729\n",
      "    load_time_ms: 34.088\n",
      "    sample_throughput: 77.972\n",
      "    sample_time_ms: 25624.633\n",
      "    update_time_ms: 12.572\n",
      "  timestamp: 1636840520\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 111888\n",
      "  training_iteration: 56\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         1551.35</td><td style=\"text-align: right;\">111888</td><td style=\"text-align: right;\">  12.164</td><td style=\"text-align: right;\">               16.87</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            105.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 113886\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 105.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.869999999999983\n",
      "  episode_reward_mean: 12.465300000000015\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1136\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8733776643162683\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013008140038830622\n",
      "          policy_loss: -0.01724286602721328\n",
      "          total_loss: 0.4357307063593041\n",
      "          vf_explained_var: 0.9518299102783203\n",
      "          vf_loss: 0.46780490279197695\n",
      "    num_agent_steps_sampled: 113886\n",
      "    num_agent_steps_trained: 113886\n",
      "    num_steps_sampled: 113886\n",
      "    num_steps_trained: 113886\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.40625\n",
      "    ram_util_percent: 30.359375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044465668842382004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.287778937133663\n",
      "    mean_inference_ms: 2.4381572709513164\n",
      "    mean_raw_obs_processing_ms: 2.0131944790531406\n",
      "  time_since_restore: 1573.7001614570618\n",
      "  time_this_iter_s: 22.355047464370728\n",
      "  time_total_s: 1573.7001614570618\n",
      "  timers:\n",
      "    learn_throughput: 1129.484\n",
      "    learn_time_ms: 1768.95\n",
      "    load_throughput: 58903.34\n",
      "    load_time_ms: 33.92\n",
      "    sample_throughput: 78.384\n",
      "    sample_time_ms: 25489.866\n",
      "    update_time_ms: 14.575\n",
      "  timestamp: 1636840543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 113886\n",
      "  training_iteration: 57\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">          1573.7</td><td style=\"text-align: right;\">113886</td><td style=\"text-align: right;\"> 12.4653</td><td style=\"text-align: right;\">               16.87</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            105.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 115884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-56-04\n",
      "  done: false\n",
      "  episode_len_mean: 106.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.729999999999976\n",
      "  episode_reward_mean: 12.974600000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1154\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8543750927561806\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01443908043521821\n",
      "          policy_loss: -0.04882249395762171\n",
      "          total_loss: 0.5150115792240415\n",
      "          vf_explained_var: 0.9487152695655823\n",
      "          vf_loss: 0.5780461020412899\n",
      "    num_agent_steps_sampled: 115884\n",
      "    num_agent_steps_trained: 115884\n",
      "    num_steps_sampled: 115884\n",
      "    num_steps_trained: 115884\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.50967741935483\n",
      "    ram_util_percent: 30.583870967741937\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04444796734235389\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.211765465013663\n",
      "    mean_inference_ms: 2.438096199345544\n",
      "    mean_raw_obs_processing_ms: 2.0401907954813536\n",
      "  time_since_restore: 1595.1497466564178\n",
      "  time_this_iter_s: 21.44958519935608\n",
      "  time_total_s: 1595.1497466564178\n",
      "  timers:\n",
      "    learn_throughput: 1128.979\n",
      "    learn_time_ms: 1769.74\n",
      "    load_throughput: 58962.024\n",
      "    load_time_ms: 33.886\n",
      "    sample_throughput: 78.878\n",
      "    sample_time_ms: 25330.106\n",
      "    update_time_ms: 14.325\n",
      "  timestamp: 1636840564\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 115884\n",
      "  training_iteration: 58\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         1595.15</td><td style=\"text-align: right;\">115884</td><td style=\"text-align: right;\"> 12.9746</td><td style=\"text-align: right;\">               18.73</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            106.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 117882\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-56-27\n",
      "  done: false\n",
      "  episode_len_mean: 106.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.729999999999976\n",
      "  episode_reward_mean: 13.250000000000009\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1173\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8141720334688822\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01916765816200174\n",
      "          policy_loss: -0.028323547630792572\n",
      "          total_loss: 0.5817268801941758\n",
      "          vf_explained_var: 0.9451218247413635\n",
      "          vf_loss: 0.6224418479771842\n",
      "    num_agent_steps_sampled: 117882\n",
      "    num_agent_steps_trained: 117882\n",
      "    num_steps_sampled: 117882\n",
      "    num_steps_trained: 117882\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77878787878788\n",
      "    ram_util_percent: 30.74848484848485\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044418192232137346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.128810402952777\n",
      "    mean_inference_ms: 2.4375463813291587\n",
      "    mean_raw_obs_processing_ms: 2.0429073356095593\n",
      "  time_since_restore: 1618.2847998142242\n",
      "  time_this_iter_s: 23.135053157806396\n",
      "  time_total_s: 1618.2847998142242\n",
      "  timers:\n",
      "    learn_throughput: 1129.096\n",
      "    learn_time_ms: 1769.557\n",
      "    load_throughput: 59389.575\n",
      "    load_time_ms: 33.642\n",
      "    sample_throughput: 78.736\n",
      "    sample_time_ms: 25375.951\n",
      "    update_time_ms: 13.77\n",
      "  timestamp: 1636840587\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 117882\n",
      "  training_iteration: 59\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         1618.28</td><td style=\"text-align: right;\">117882</td><td style=\"text-align: right;\">   13.25</td><td style=\"text-align: right;\">               18.73</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            106.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 119880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-56-49\n",
      "  done: false\n",
      "  episode_len_mean: 108.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.759999999999966\n",
      "  episode_reward_mean: 13.487200000000007\n",
      "  episode_reward_min: 5.150000000000011\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1191\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8754095577058338\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013200535261240506\n",
      "          policy_loss: -0.030827534730945315\n",
      "          total_loss: 0.5188736442299117\n",
      "          vf_explained_var: 0.954889178276062\n",
      "          vf_loss: 0.5644951121438118\n",
      "    num_agent_steps_sampled: 119880\n",
      "    num_agent_steps_trained: 119880\n",
      "    num_steps_sampled: 119880\n",
      "    num_steps_trained: 119880\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14193548387097\n",
      "    ram_util_percent: 30.835483870967742\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04441665438725699\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.04352896625708\n",
      "    mean_inference_ms: 2.437714146291354\n",
      "    mean_raw_obs_processing_ms: 2.0191227708705326\n",
      "  time_since_restore: 1640.1495444774628\n",
      "  time_this_iter_s: 21.864744663238525\n",
      "  time_total_s: 1640.1495444774628\n",
      "  timers:\n",
      "    learn_throughput: 1130.164\n",
      "    learn_time_ms: 1767.885\n",
      "    load_throughput: 59075.037\n",
      "    load_time_ms: 33.821\n",
      "    sample_throughput: 78.778\n",
      "    sample_time_ms: 25362.49\n",
      "    update_time_ms: 14.085\n",
      "  timestamp: 1636840609\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119880\n",
      "  training_iteration: 60\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         1640.15</td><td style=\"text-align: right;\">119880</td><td style=\"text-align: right;\"> 13.4872</td><td style=\"text-align: right;\">               18.76</td><td style=\"text-align: right;\">                5.15</td><td style=\"text-align: right;\">            108.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 121878\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-57-11\n",
      "  done: false\n",
      "  episode_len_mean: 108.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.429999999999932\n",
      "  episode_reward_mean: 13.871200000000009\n",
      "  episode_reward_min: 5.150000000000011\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1210\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8498177255902972\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011111849992017567\n",
      "          policy_loss: -0.06558809677759807\n",
      "          total_loss: 0.44231886624225547\n",
      "          vf_explained_var: 0.9614323377609253\n",
      "          vf_loss: 0.5230715839635758\n",
      "    num_agent_steps_sampled: 121878\n",
      "    num_agent_steps_trained: 121878\n",
      "    num_steps_sampled: 121878\n",
      "    num_steps_trained: 121878\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.35806451612903\n",
      "    ram_util_percent: 30.899999999999995\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044394370989721814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.963797520433488\n",
      "    mean_inference_ms: 2.437414498627139\n",
      "    mean_raw_obs_processing_ms: 1.9952903529463806\n",
      "  time_since_restore: 1661.813711643219\n",
      "  time_this_iter_s: 21.664167165756226\n",
      "  time_total_s: 1661.813711643219\n",
      "  timers:\n",
      "    learn_throughput: 1128.559\n",
      "    learn_time_ms: 1770.4\n",
      "    load_throughput: 58738.154\n",
      "    load_time_ms: 34.015\n",
      "    sample_throughput: 78.928\n",
      "    sample_time_ms: 25314.252\n",
      "    update_time_ms: 14.27\n",
      "  timestamp: 1636840631\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 121878\n",
      "  training_iteration: 61\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         1661.81</td><td style=\"text-align: right;\">121878</td><td style=\"text-align: right;\"> 13.8712</td><td style=\"text-align: right;\">               20.43</td><td style=\"text-align: right;\">                5.15</td><td style=\"text-align: right;\">            108.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 123876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-57-33\n",
      "  done: false\n",
      "  episode_len_mean: 109.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.429999999999932\n",
      "  episode_reward_mean: 14.0146\n",
      "  episode_reward_min: 5.150000000000011\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 1226\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8438412013508025\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01267909554854274\n",
      "          policy_loss: -0.01157809208546366\n",
      "          total_loss: 0.5453249134478115\n",
      "          vf_explained_var: 0.9588461518287659\n",
      "          vf_loss: 0.5715376856071609\n",
      "    num_agent_steps_sampled: 123876\n",
      "    num_agent_steps_trained: 123876\n",
      "    num_steps_sampled: 123876\n",
      "    num_steps_trained: 123876\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6625\n",
      "    ram_util_percent: 31.0\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04440362386079258\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.886326179658827\n",
      "    mean_inference_ms: 2.4377071819240985\n",
      "    mean_raw_obs_processing_ms: 1.9748026172485305\n",
      "  time_since_restore: 1683.678575515747\n",
      "  time_this_iter_s: 21.864863872528076\n",
      "  time_total_s: 1683.678575515747\n",
      "  timers:\n",
      "    learn_throughput: 1130.255\n",
      "    learn_time_ms: 1767.742\n",
      "    load_throughput: 58553.469\n",
      "    load_time_ms: 34.123\n",
      "    sample_throughput: 79.051\n",
      "    sample_time_ms: 25274.876\n",
      "    update_time_ms: 14.703\n",
      "  timestamp: 1636840653\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 123876\n",
      "  training_iteration: 62\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         1683.68</td><td style=\"text-align: right;\">123876</td><td style=\"text-align: right;\"> 14.0146</td><td style=\"text-align: right;\">               20.43</td><td style=\"text-align: right;\">                5.15</td><td style=\"text-align: right;\">            109.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 125874\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-57-56\n",
      "  done: false\n",
      "  episode_len_mean: 109.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.429999999999932\n",
      "  episode_reward_mean: 14.0461\n",
      "  episode_reward_min: 5.150000000000011\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1245\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8244810047603788\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014611875299244135\n",
      "          policy_loss: -0.05834969498571895\n",
      "          total_loss: 0.5557149478012607\n",
      "          vf_explained_var: 0.9485534429550171\n",
      "          vf_loss: 0.627925888981138\n",
      "    num_agent_steps_sampled: 125874\n",
      "    num_agent_steps_trained: 125874\n",
      "    num_steps_sampled: 125874\n",
      "    num_steps_trained: 125874\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.23030303030302\n",
      "    ram_util_percent: 30.98787878787879\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044375502308653635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.809234126022165\n",
      "    mean_inference_ms: 2.4373323874696813\n",
      "    mean_raw_obs_processing_ms: 1.951996470353257\n",
      "  time_since_restore: 1706.8044352531433\n",
      "  time_this_iter_s: 23.12585973739624\n",
      "  time_total_s: 1706.8044352531433\n",
      "  timers:\n",
      "    learn_throughput: 1127.381\n",
      "    learn_time_ms: 1772.249\n",
      "    load_throughput: 58736.425\n",
      "    load_time_ms: 34.016\n",
      "    sample_throughput: 84.241\n",
      "    sample_time_ms: 23717.745\n",
      "    update_time_ms: 14.778\n",
      "  timestamp: 1636840676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 125874\n",
      "  training_iteration: 63\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">          1706.8</td><td style=\"text-align: right;\">125874</td><td style=\"text-align: right;\"> 14.0461</td><td style=\"text-align: right;\">               20.43</td><td style=\"text-align: right;\">                5.15</td><td style=\"text-align: right;\">            109.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 127872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-58-19\n",
      "  done: false\n",
      "  episode_len_mean: 109.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.429999999999932\n",
      "  episode_reward_mean: 13.894099999999998\n",
      "  episode_reward_min: 1.940000000000019\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1263\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8103798457554408\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016037312845530203\n",
      "          policy_loss: -0.04926043835779031\n",
      "          total_loss: 0.8421541409123512\n",
      "          vf_explained_var: 0.9247145652770996\n",
      "          vf_loss: 0.9047071923102651\n",
      "    num_agent_steps_sampled: 127872\n",
      "    num_agent_steps_trained: 127872\n",
      "    num_steps_sampled: 127872\n",
      "    num_steps_trained: 127872\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.15625\n",
      "    ram_util_percent: 31.053125\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437985487801292\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.733248720992297\n",
      "    mean_inference_ms: 2.437716662712889\n",
      "    mean_raw_obs_processing_ms: 1.9305224041167182\n",
      "  time_since_restore: 1729.376289844513\n",
      "  time_this_iter_s: 22.57185459136963\n",
      "  time_total_s: 1729.376289844513\n",
      "  timers:\n",
      "    learn_throughput: 1127.955\n",
      "    learn_time_ms: 1771.348\n",
      "    load_throughput: 58741.159\n",
      "    load_time_ms: 34.014\n",
      "    sample_throughput: 97.395\n",
      "    sample_time_ms: 20514.316\n",
      "    update_time_ms: 15.534\n",
      "  timestamp: 1636840699\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 127872\n",
      "  training_iteration: 64\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         1729.38</td><td style=\"text-align: right;\">127872</td><td style=\"text-align: right;\"> 13.8941</td><td style=\"text-align: right;\">               20.43</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">            109.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 129870\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-58-41\n",
      "  done: false\n",
      "  episode_len_mean: 110.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.429999999999932\n",
      "  episode_reward_mean: 13.5632\n",
      "  episode_reward_min: 1.940000000000019\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1282\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8859296094803584\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017045966771120465\n",
      "          policy_loss: -0.009073559620550701\n",
      "          total_loss: 0.7267533628181333\n",
      "          vf_explained_var: 0.9327951073646545\n",
      "          vf_loss: 0.7495724351633163\n",
      "    num_agent_steps_sampled: 129870\n",
      "    num_agent_steps_trained: 129870\n",
      "    num_steps_sampled: 129870\n",
      "    num_steps_trained: 129870\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.58125\n",
      "    ram_util_percent: 31.03125\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044359146147339726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.65933342743122\n",
      "    mean_inference_ms: 2.4374274469398456\n",
      "    mean_raw_obs_processing_ms: 1.9090752772402473\n",
      "  time_since_restore: 1751.716999053955\n",
      "  time_this_iter_s: 22.34070920944214\n",
      "  time_total_s: 1751.716999053955\n",
      "  timers:\n",
      "    learn_throughput: 1127.148\n",
      "    learn_time_ms: 1772.616\n",
      "    load_throughput: 59147.879\n",
      "    load_time_ms: 33.78\n",
      "    sample_throughput: 97.759\n",
      "    sample_time_ms: 20437.946\n",
      "    update_time_ms: 13.386\n",
      "  timestamp: 1636840721\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129870\n",
      "  training_iteration: 65\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         1751.72</td><td style=\"text-align: right;\">129870</td><td style=\"text-align: right;\"> 13.5632</td><td style=\"text-align: right;\">               20.43</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">            110.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 131868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-59-03\n",
      "  done: false\n",
      "  episode_len_mean: 110.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.429999999999932\n",
      "  episode_reward_mean: 13.886999999999999\n",
      "  episode_reward_min: 1.940000000000019\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1299\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8500871754827954\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01021945883259825\n",
      "          policy_loss: -0.05555999188550881\n",
      "          total_loss: 0.44098224427018845\n",
      "          vf_explained_var: 0.9560024738311768\n",
      "          vf_loss: 0.5119772693940572\n",
      "    num_agent_steps_sampled: 131868\n",
      "    num_agent_steps_trained: 131868\n",
      "    num_steps_sampled: 131868\n",
      "    num_steps_trained: 131868\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.39354838709677\n",
      "    ram_util_percent: 31.0741935483871\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434768518739113\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.591279149963086\n",
      "    mean_inference_ms: 2.43733876288166\n",
      "    mean_raw_obs_processing_ms: 1.8903199514789202\n",
      "  time_since_restore: 1773.6561732292175\n",
      "  time_this_iter_s: 21.93917417526245\n",
      "  time_total_s: 1773.6561732292175\n",
      "  timers:\n",
      "    learn_throughput: 1126.07\n",
      "    learn_time_ms: 1774.312\n",
      "    load_throughput: 58944.398\n",
      "    load_time_ms: 33.896\n",
      "    sample_throughput: 97.945\n",
      "    sample_time_ms: 20399.297\n",
      "    update_time_ms: 13.743\n",
      "  timestamp: 1636840743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 131868\n",
      "  training_iteration: 66\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         1773.66</td><td style=\"text-align: right;\">131868</td><td style=\"text-align: right;\">  13.887</td><td style=\"text-align: right;\">               20.43</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">            110.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 133866\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-59-25\n",
      "  done: false\n",
      "  episode_len_mean: 110.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.839999999999982\n",
      "  episode_reward_mean: 14.09229999999999\n",
      "  episode_reward_min: 1.940000000000019\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1316\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8686426804179237\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011648627068183075\n",
      "          policy_loss: -0.08041211147570894\n",
      "          total_loss: 0.3604199135942118\n",
      "          vf_explained_var: 0.9657325148582458\n",
      "          vf_loss: 0.45602386324178606\n",
      "    num_agent_steps_sampled: 133866\n",
      "    num_agent_steps_trained: 133866\n",
      "    num_steps_sampled: 133866\n",
      "    num_steps_trained: 133866\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.65806451612903\n",
      "    ram_util_percent: 31.03870967741936\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433672801951918\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.51707540010646\n",
      "    mean_inference_ms: 2.437333230258558\n",
      "    mean_raw_obs_processing_ms: 1.8715350365836156\n",
      "  time_since_restore: 1795.2817115783691\n",
      "  time_this_iter_s: 21.62553834915161\n",
      "  time_total_s: 1795.2817115783691\n",
      "  timers:\n",
      "    learn_throughput: 1125.917\n",
      "    learn_time_ms: 1774.553\n",
      "    load_throughput: 59006.695\n",
      "    load_time_ms: 33.861\n",
      "    sample_throughput: 98.289\n",
      "    sample_time_ms: 20327.843\n",
      "    update_time_ms: 12.009\n",
      "  timestamp: 1636840765\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 133866\n",
      "  training_iteration: 67\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         1795.28</td><td style=\"text-align: right;\">133866</td><td style=\"text-align: right;\"> 14.0923</td><td style=\"text-align: right;\">               18.84</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">            110.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 135864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_21-59-47\n",
      "  done: false\n",
      "  episode_len_mean: 110.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.929999999999968\n",
      "  episode_reward_mean: 14.573399999999987\n",
      "  episode_reward_min: 1.940000000000019\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1336\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7921964378583999\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01204349857856998\n",
      "          policy_loss: -0.008813671412922088\n",
      "          total_loss: 0.6196134351548694\n",
      "          vf_explained_var: 0.9592212438583374\n",
      "          vf_loss: 0.6427360249417169\n",
      "    num_agent_steps_sampled: 135864\n",
      "    num_agent_steps_trained: 135864\n",
      "    num_steps_sampled: 135864\n",
      "    num_steps_trained: 135864\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.234375\n",
      "    ram_util_percent: 31.025\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431382130387087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.447938508055785\n",
      "    mean_inference_ms: 2.437640666113947\n",
      "    mean_raw_obs_processing_ms: 1.8510396217503993\n",
      "  time_since_restore: 1817.7056303024292\n",
      "  time_this_iter_s: 22.42391872406006\n",
      "  time_total_s: 1817.7056303024292\n",
      "  timers:\n",
      "    learn_throughput: 1125.677\n",
      "    learn_time_ms: 1774.931\n",
      "    load_throughput: 58833.205\n",
      "    load_time_ms: 33.96\n",
      "    sample_throughput: 97.832\n",
      "    sample_time_ms: 20422.78\n",
      "    update_time_ms: 13.936\n",
      "  timestamp: 1636840787\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 135864\n",
      "  training_iteration: 68\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         1817.71</td><td style=\"text-align: right;\">135864</td><td style=\"text-align: right;\"> 14.5734</td><td style=\"text-align: right;\">               18.93</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">            110.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 137862\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-00-11\n",
      "  done: false\n",
      "  episode_len_mean: 109.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.929999999999968\n",
      "  episode_reward_mean: 15.159399999999982\n",
      "  episode_reward_min: 1.940000000000019\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1354\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.821025740532648\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011585952133837736\n",
      "          policy_loss: -0.026929066791420892\n",
      "          total_loss: 0.391136464387888\n",
      "          vf_explained_var: 0.971234142780304\n",
      "          vf_loss: 0.43280000388622286\n",
      "    num_agent_steps_sampled: 137862\n",
      "    num_agent_steps_trained: 137862\n",
      "    num_steps_sampled: 137862\n",
      "    num_steps_trained: 137862\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08823529411765\n",
      "    ram_util_percent: 31.138235294117642\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430269318926703\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.386846241829307\n",
      "    mean_inference_ms: 2.437813260779305\n",
      "    mean_raw_obs_processing_ms: 1.8334877492416797\n",
      "  time_since_restore: 1841.3616313934326\n",
      "  time_this_iter_s: 23.656001091003418\n",
      "  time_total_s: 1841.3616313934326\n",
      "  timers:\n",
      "    learn_throughput: 1109.605\n",
      "    learn_time_ms: 1800.64\n",
      "    load_throughput: 58112.351\n",
      "    load_time_ms: 34.382\n",
      "    sample_throughput: 97.713\n",
      "    sample_time_ms: 20447.727\n",
      "    update_time_ms: 14.568\n",
      "  timestamp: 1636840811\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 137862\n",
      "  training_iteration: 69\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         1841.36</td><td style=\"text-align: right;\">137862</td><td style=\"text-align: right;\"> 15.1594</td><td style=\"text-align: right;\">               18.93</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">            109.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 139860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-00-34\n",
      "  done: false\n",
      "  episode_len_mean: 109.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.789999999999946\n",
      "  episode_reward_mean: 15.708599999999976\n",
      "  episode_reward_min: 7.890000000000024\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1373\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8742527479217166\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010933333701677804\n",
      "          policy_loss: 0.02700618931225368\n",
      "          total_loss: 0.6021633629287992\n",
      "          vf_explained_var: 0.9630308151245117\n",
      "          vf_loss: 0.5906197032758168\n",
      "    num_agent_steps_sampled: 139860\n",
      "    num_agent_steps_trained: 139860\n",
      "    num_steps_sampled: 139860\n",
      "    num_steps_trained: 139860\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.203125\n",
      "    ram_util_percent: 31.30625\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430699901415643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.32910544207898\n",
      "    mean_inference_ms: 2.438169721729259\n",
      "    mean_raw_obs_processing_ms: 1.8157564491167464\n",
      "  time_since_restore: 1864.2178428173065\n",
      "  time_this_iter_s: 22.8562114238739\n",
      "  time_total_s: 1864.2178428173065\n",
      "  timers:\n",
      "    learn_throughput: 1109.66\n",
      "    learn_time_ms: 1800.551\n",
      "    load_throughput: 59002.375\n",
      "    load_time_ms: 33.863\n",
      "    sample_throughput: 97.24\n",
      "    sample_time_ms: 20547.113\n",
      "    update_time_ms: 15.001\n",
      "  timestamp: 1636840834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 139860\n",
      "  training_iteration: 70\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         1864.22</td><td style=\"text-align: right;\">139860</td><td style=\"text-align: right;\"> 15.7086</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">                7.89</td><td style=\"text-align: right;\">            109.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 141858\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-00-57\n",
      "  done: false\n",
      "  episode_len_mean: 108.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.789999999999946\n",
      "  episode_reward_mean: 16.002299999999977\n",
      "  episode_reward_min: 8.21000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1391\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7753831187884013\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014639347125546888\n",
      "          policy_loss: 0.02907737823469298\n",
      "          total_loss: 0.437026486687717\n",
      "          vf_explained_var: 0.9749583005905151\n",
      "          vf_loss: 0.42131114133766717\n",
      "    num_agent_steps_sampled: 141858\n",
      "    num_agent_steps_trained: 141858\n",
      "    num_steps_sampled: 141858\n",
      "    num_steps_trained: 141858\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7205882352941\n",
      "    ram_util_percent: 31.25\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432953094177517\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.276506519820114\n",
      "    mean_inference_ms: 2.4388131528073584\n",
      "    mean_raw_obs_processing_ms: 1.7990737703470898\n",
      "  time_since_restore: 1887.3995289802551\n",
      "  time_this_iter_s: 23.18168616294861\n",
      "  time_total_s: 1887.3995289802551\n",
      "  timers:\n",
      "    learn_throughput: 1110.899\n",
      "    learn_time_ms: 1798.544\n",
      "    load_throughput: 59555.614\n",
      "    load_time_ms: 33.548\n",
      "    sample_throughput: 96.51\n",
      "    sample_time_ms: 20702.603\n",
      "    update_time_ms: 13.926\n",
      "  timestamp: 1636840857\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 141858\n",
      "  training_iteration: 71\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">          1887.4</td><td style=\"text-align: right;\">141858</td><td style=\"text-align: right;\"> 16.0023</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">                8.21</td><td style=\"text-align: right;\">            108.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 143856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-01-20\n",
      "  done: false\n",
      "  episode_len_mean: 107.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.789999999999946\n",
      "  episode_reward_mean: 16.06929999999997\n",
      "  episode_reward_min: 8.21000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1411\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8172982914107187\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01034252843307333\n",
      "          policy_loss: -0.12201774840553602\n",
      "          total_loss: 0.4468080009378138\n",
      "          vf_explained_var: 0.9663057327270508\n",
      "          vf_loss: 0.583895969532785\n",
      "    num_agent_steps_sampled: 143856\n",
      "    num_agent_steps_trained: 143856\n",
      "    num_steps_sampled: 143856\n",
      "    num_steps_trained: 143856\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.80000000000001\n",
      "    ram_util_percent: 31.30625\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432362093616723\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.23164710884484\n",
      "    mean_inference_ms: 2.439101730465305\n",
      "    mean_raw_obs_processing_ms: 1.7819728580493597\n",
      "  time_since_restore: 1910.3253164291382\n",
      "  time_this_iter_s: 22.925787448883057\n",
      "  time_total_s: 1910.3253164291382\n",
      "  timers:\n",
      "    learn_throughput: 1109.622\n",
      "    learn_time_ms: 1800.613\n",
      "    load_throughput: 58408.51\n",
      "    load_time_ms: 34.207\n",
      "    sample_throughput: 96.034\n",
      "    sample_time_ms: 20805.048\n",
      "    update_time_ms: 14.9\n",
      "  timestamp: 1636840880\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 143856\n",
      "  training_iteration: 72\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         1910.33</td><td style=\"text-align: right;\">143856</td><td style=\"text-align: right;\"> 16.0693</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">                8.21</td><td style=\"text-align: right;\">            107.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 145854\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-02-11\n",
      "  done: false\n",
      "  episode_len_mean: 106.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.789999999999946\n",
      "  episode_reward_mean: 16.046999999999972\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1430\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7662285231408619\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011125788104461064\n",
      "          policy_loss: 0.0022801146266006288\n",
      "          total_loss: 0.8733092515152835\n",
      "          vf_explained_var: 0.9521196484565735\n",
      "          vf_loss: 0.8853536918049767\n",
      "    num_agent_steps_sampled: 145854\n",
      "    num_agent_steps_trained: 145854\n",
      "    num_steps_sampled: 145854\n",
      "    num_steps_trained: 145854\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.86575342465754\n",
      "    ram_util_percent: 31.26986301369863\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044322942892684354\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.183831137747653\n",
      "    mean_inference_ms: 2.439074499496958\n",
      "    mean_raw_obs_processing_ms: 1.81049798046518\n",
      "  time_since_restore: 1961.5333149433136\n",
      "  time_this_iter_s: 51.207998514175415\n",
      "  time_total_s: 1961.5333149433136\n",
      "  timers:\n",
      "    learn_throughput: 1110.553\n",
      "    learn_time_ms: 1799.104\n",
      "    load_throughput: 58606.048\n",
      "    load_time_ms: 34.092\n",
      "    sample_throughput: 84.604\n",
      "    sample_time_ms: 23615.964\n",
      "    update_time_ms: 13.907\n",
      "  timestamp: 1636840931\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 145854\n",
      "  training_iteration: 73\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         1961.53</td><td style=\"text-align: right;\">145854</td><td style=\"text-align: right;\">  16.047</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             106.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 147852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-02-50\n",
      "  done: false\n",
      "  episode_len_mean: 105.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.789999999999946\n",
      "  episode_reward_mean: 16.035399999999967\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1449\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7458575288454692\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00986137397715217\n",
      "          policy_loss: -0.021404257647338366\n",
      "          total_loss: 1.0076447784545877\n",
      "          vf_explained_var: 0.9427377581596375\n",
      "          vf_loss: 1.043549187694277\n",
      "    num_agent_steps_sampled: 147852\n",
      "    num_agent_steps_trained: 147852\n",
      "    num_steps_sampled: 147852\n",
      "    num_steps_trained: 147852\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.51607142857142\n",
      "    ram_util_percent: 30.712500000000002\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433144299923514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.1364736310222\n",
      "    mean_inference_ms: 2.439132022677763\n",
      "    mean_raw_obs_processing_ms: 1.8585939703888463\n",
      "  time_since_restore: 2000.3533141613007\n",
      "  time_this_iter_s: 38.81999921798706\n",
      "  time_total_s: 2000.3533141613007\n",
      "  timers:\n",
      "    learn_throughput: 1106.784\n",
      "    learn_time_ms: 1805.231\n",
      "    load_throughput: 58509.318\n",
      "    load_time_ms: 34.148\n",
      "    sample_throughput: 79.182\n",
      "    sample_time_ms: 25232.944\n",
      "    update_time_ms: 15.334\n",
      "  timestamp: 1636840970\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 147852\n",
      "  training_iteration: 74\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         2000.35</td><td style=\"text-align: right;\">147852</td><td style=\"text-align: right;\"> 16.0354</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            105.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 149850\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-03-14\n",
      "  done: false\n",
      "  episode_len_mean: 104.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.789999999999946\n",
      "  episode_reward_mean: 16.22099999999996\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1467\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.73950069972447\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010102733463068957\n",
      "          policy_loss: 0.025000469776846113\n",
      "          total_loss: 0.5291260911950043\n",
      "          vf_explained_var: 0.9702696204185486\n",
      "          vf_loss: 0.5184898108243943\n",
      "    num_agent_steps_sampled: 149850\n",
      "    num_agent_steps_trained: 149850\n",
      "    num_steps_sampled: 149850\n",
      "    num_steps_trained: 149850\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.21176470588235\n",
      "    ram_util_percent: 30.8\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044310360761126634\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.10017874463106\n",
      "    mean_inference_ms: 2.439178041394417\n",
      "    mean_raw_obs_processing_ms: 1.9036421863561048\n",
      "  time_since_restore: 2024.0600712299347\n",
      "  time_this_iter_s: 23.706757068634033\n",
      "  time_total_s: 2024.0600712299347\n",
      "  timers:\n",
      "    learn_throughput: 1099.098\n",
      "    learn_time_ms: 1817.854\n",
      "    load_throughput: 58227.387\n",
      "    load_time_ms: 34.314\n",
      "    sample_throughput: 78.798\n",
      "    sample_time_ms: 25356.081\n",
      "    update_time_ms: 15.967\n",
      "  timestamp: 1636840994\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 149850\n",
      "  training_iteration: 75\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         2024.06</td><td style=\"text-align: right;\">149850</td><td style=\"text-align: right;\">  16.221</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            104.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 151848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-03-36\n",
      "  done: false\n",
      "  episode_len_mean: 105.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.81999999999994\n",
      "  episode_reward_mean: 16.346499999999963\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1485\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7162161838440668\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.018113779360524634\n",
      "          policy_loss: 0.006635627540804091\n",
      "          total_loss: 0.5062316156391586\n",
      "          vf_explained_var: 0.9744072556495667\n",
      "          vf_loss: 0.5113240144792057\n",
      "    num_agent_steps_sampled: 151848\n",
      "    num_agent_steps_trained: 151848\n",
      "    num_steps_sampled: 151848\n",
      "    num_steps_trained: 151848\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.421875\n",
      "    ram_util_percent: 31.109375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428671160964547\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.06005316387457\n",
      "    mean_inference_ms: 2.439049378931232\n",
      "    mean_raw_obs_processing_ms: 1.9481226140029633\n",
      "  time_since_restore: 2046.646010875702\n",
      "  time_this_iter_s: 22.585939645767212\n",
      "  time_total_s: 2046.646010875702\n",
      "  timers:\n",
      "    learn_throughput: 1099.005\n",
      "    learn_time_ms: 1818.009\n",
      "    load_throughput: 58014.471\n",
      "    load_time_ms: 34.44\n",
      "    sample_throughput: 78.597\n",
      "    sample_time_ms: 25420.896\n",
      "    update_time_ms: 15.718\n",
      "  timestamp: 1636841016\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 151848\n",
      "  training_iteration: 76\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         2046.65</td><td style=\"text-align: right;\">151848</td><td style=\"text-align: right;\"> 16.3465</td><td style=\"text-align: right;\">               20.82</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            105.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 153846\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-03-59\n",
      "  done: false\n",
      "  episode_len_mean: 105.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.81999999999994\n",
      "  episode_reward_mean: 16.465899999999962\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1506\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6781271162487212\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01101572010217289\n",
      "          policy_loss: -0.02873067671344394\n",
      "          total_loss: 0.5291785389805833\n",
      "          vf_explained_var: 0.9742415547370911\n",
      "          vf_loss: 0.5713857703975269\n",
      "    num_agent_steps_sampled: 153846\n",
      "    num_agent_steps_trained: 153846\n",
      "    num_steps_sampled: 153846\n",
      "    num_steps_trained: 153846\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.89393939393939\n",
      "    ram_util_percent: 31.254545454545458\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044269015374249834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.013991955774685\n",
      "    mean_inference_ms: 2.4389315457788\n",
      "    mean_raw_obs_processing_ms: 1.9998630849121628\n",
      "  time_since_restore: 2069.7520582675934\n",
      "  time_this_iter_s: 23.10604739189148\n",
      "  time_total_s: 2069.7520582675934\n",
      "  timers:\n",
      "    learn_throughput: 1099.055\n",
      "    learn_time_ms: 1817.926\n",
      "    load_throughput: 58237.948\n",
      "    load_time_ms: 34.308\n",
      "    sample_throughput: 78.141\n",
      "    sample_time_ms: 25569.162\n",
      "    update_time_ms: 15.757\n",
      "  timestamp: 1636841039\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 153846\n",
      "  training_iteration: 77\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         2069.75</td><td style=\"text-align: right;\">153846</td><td style=\"text-align: right;\"> 16.4659</td><td style=\"text-align: right;\">               20.82</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            105.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 155844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-04-22\n",
      "  done: false\n",
      "  episode_len_mean: 106.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.859999999999957\n",
      "  episode_reward_mean: 16.94699999999996\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1524\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.658703096707662\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010575411363749792\n",
      "          policy_loss: -0.033163808108795254\n",
      "          total_loss: 0.3603851248022346\n",
      "          vf_explained_var: 0.9779025316238403\n",
      "          vf_loss: 0.4069633393060593\n",
      "    num_agent_steps_sampled: 155844\n",
      "    num_agent_steps_trained: 155844\n",
      "    num_steps_sampled: 155844\n",
      "    num_steps_trained: 155844\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.29375\n",
      "    ram_util_percent: 31.43125\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425864802446009\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.984260373336557\n",
      "    mean_inference_ms: 2.439066263962812\n",
      "    mean_raw_obs_processing_ms: 2.020197201173882\n",
      "  time_since_restore: 2092.1058769226074\n",
      "  time_this_iter_s: 22.353818655014038\n",
      "  time_total_s: 2092.1058769226074\n",
      "  timers:\n",
      "    learn_throughput: 1097.341\n",
      "    learn_time_ms: 1820.766\n",
      "    load_throughput: 58629.788\n",
      "    load_time_ms: 34.078\n",
      "    sample_throughput: 78.167\n",
      "    sample_time_ms: 25560.635\n",
      "    update_time_ms: 14.688\n",
      "  timestamp: 1636841062\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 155844\n",
      "  training_iteration: 78\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         2092.11</td><td style=\"text-align: right;\">155844</td><td style=\"text-align: right;\">  16.947</td><td style=\"text-align: right;\">               20.86</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            106.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 157842\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-04-44\n",
      "  done: false\n",
      "  episode_len_mean: 108.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.859999999999957\n",
      "  episode_reward_mean: 17.42029999999995\n",
      "  episode_reward_min: 11.780000000000022\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1542\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7207683988979885\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012002077051425981\n",
      "          policy_loss: -0.06273158526136761\n",
      "          total_loss: 0.4332795441061968\n",
      "          vf_explained_var: 0.9737151861190796\n",
      "          vf_loss: 0.509618189008463\n",
      "    num_agent_steps_sampled: 157842\n",
      "    num_agent_steps_trained: 157842\n",
      "    num_steps_sampled: 157842\n",
      "    num_steps_trained: 157842\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95806451612903\n",
      "    ram_util_percent: 31.58064516129033\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044245280229763505\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.950381818278\n",
      "    mean_inference_ms: 2.439100507383591\n",
      "    mean_raw_obs_processing_ms: 2.0028894218432844\n",
      "  time_since_restore: 2113.93634223938\n",
      "  time_this_iter_s: 21.83046531677246\n",
      "  time_total_s: 2113.93634223938\n",
      "  timers:\n",
      "    learn_throughput: 1112.537\n",
      "    learn_time_ms: 1795.895\n",
      "    load_throughput: 58922.35\n",
      "    load_time_ms: 33.909\n",
      "    sample_throughput: 78.65\n",
      "    sample_time_ms: 25403.564\n",
      "    update_time_ms: 14.604\n",
      "  timestamp: 1636841084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 157842\n",
      "  training_iteration: 79\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         2113.94</td><td style=\"text-align: right;\">157842</td><td style=\"text-align: right;\"> 17.4203</td><td style=\"text-align: right;\">               20.86</td><td style=\"text-align: right;\">               11.78</td><td style=\"text-align: right;\">            108.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 159840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-05-06\n",
      "  done: false\n",
      "  episode_len_mean: 109.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.859999999999957\n",
      "  episode_reward_mean: 17.54189999999995\n",
      "  episode_reward_min: 11.780000000000022\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1559\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6983579964864821\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013086715188312071\n",
      "          policy_loss: -0.027625643852211182\n",
      "          total_loss: 0.5877295117692224\n",
      "          vf_explained_var: 0.9740790128707886\n",
      "          vf_loss: 0.6284127264505341\n",
      "    num_agent_steps_sampled: 159840\n",
      "    num_agent_steps_trained: 159840\n",
      "    num_steps_sampled: 159840\n",
      "    num_steps_trained: 159840\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.4875\n",
      "    ram_util_percent: 31.69375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044238565182947484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.909511733085154\n",
      "    mean_inference_ms: 2.4391107093772444\n",
      "    mean_raw_obs_processing_ms: 1.9866858395789302\n",
      "  time_since_restore: 2136.0508918762207\n",
      "  time_this_iter_s: 22.11454963684082\n",
      "  time_total_s: 2136.0508918762207\n",
      "  timers:\n",
      "    learn_throughput: 1112.503\n",
      "    learn_time_ms: 1795.95\n",
      "    load_throughput: 58100.949\n",
      "    load_time_ms: 34.388\n",
      "    sample_throughput: 78.881\n",
      "    sample_time_ms: 25329.259\n",
      "    update_time_ms: 14.207\n",
      "  timestamp: 1636841106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159840\n",
      "  training_iteration: 80\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2136.05</td><td style=\"text-align: right;\">159840</td><td style=\"text-align: right;\"> 17.5419</td><td style=\"text-align: right;\">               20.86</td><td style=\"text-align: right;\">               11.78</td><td style=\"text-align: right;\">            109.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 161838\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-05-28\n",
      "  done: false\n",
      "  episode_len_mean: 110.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.859999999999957\n",
      "  episode_reward_mean: 17.68599999999995\n",
      "  episode_reward_min: 10.300000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1577\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.699652373790741\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010149490428813952\n",
      "          policy_loss: -0.028372498459759213\n",
      "          total_loss: 0.45921505549922587\n",
      "          vf_explained_var: 0.9759918451309204\n",
      "          vf_loss: 0.5015392311272167\n",
      "    num_agent_steps_sampled: 161838\n",
      "    num_agent_steps_trained: 161838\n",
      "    num_steps_sampled: 161838\n",
      "    num_steps_trained: 161838\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.35624999999999\n",
      "    ram_util_percent: 31.69375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044227159890046594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.868170106043728\n",
      "    mean_inference_ms: 2.4390666303373094\n",
      "    mean_raw_obs_processing_ms: 1.96997587300742\n",
      "  time_since_restore: 2158.552452802658\n",
      "  time_this_iter_s: 22.501560926437378\n",
      "  time_total_s: 2158.552452802658\n",
      "  timers:\n",
      "    learn_throughput: 1113.203\n",
      "    learn_time_ms: 1794.822\n",
      "    load_throughput: 56496.331\n",
      "    load_time_ms: 35.365\n",
      "    sample_throughput: 79.1\n",
      "    sample_time_ms: 25259.008\n",
      "    update_time_ms: 16.634\n",
      "  timestamp: 1636841128\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 161838\n",
      "  training_iteration: 81\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         2158.55</td><td style=\"text-align: right;\">161838</td><td style=\"text-align: right;\">  17.686</td><td style=\"text-align: right;\">               20.86</td><td style=\"text-align: right;\">                10.3</td><td style=\"text-align: right;\">            110.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 163836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-05-50\n",
      "  done: false\n",
      "  episode_len_mean: 110.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.859999999999957\n",
      "  episode_reward_mean: 17.884499999999942\n",
      "  episode_reward_min: 10.300000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1595\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6811317897978284\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009583615844240759\n",
      "          policy_loss: -0.008329885098196212\n",
      "          total_loss: 0.45870009644755294\n",
      "          vf_explained_var: 0.9769161939620972\n",
      "          vf_loss: 0.4809662149066017\n",
      "    num_agent_steps_sampled: 163836\n",
      "    num_agent_steps_trained: 163836\n",
      "    num_steps_sampled: 163836\n",
      "    num_steps_trained: 163836\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.9741935483871\n",
      "    ram_util_percent: 31.76451612903226\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422061541857518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.82278652544752\n",
      "    mean_inference_ms: 2.439175486405772\n",
      "    mean_raw_obs_processing_ms: 1.9533753148518316\n",
      "  time_since_restore: 2180.1928372383118\n",
      "  time_this_iter_s: 21.640384435653687\n",
      "  time_total_s: 2180.1928372383118\n",
      "  timers:\n",
      "    learn_throughput: 1113.378\n",
      "    learn_time_ms: 1794.539\n",
      "    load_throughput: 57066.449\n",
      "    load_time_ms: 35.012\n",
      "    sample_throughput: 79.497\n",
      "    sample_time_ms: 25132.963\n",
      "    update_time_ms: 15.087\n",
      "  timestamp: 1636841150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 163836\n",
      "  training_iteration: 82\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         2180.19</td><td style=\"text-align: right;\">163836</td><td style=\"text-align: right;\"> 17.8845</td><td style=\"text-align: right;\">               20.86</td><td style=\"text-align: right;\">                10.3</td><td style=\"text-align: right;\">             110.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 165834\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-06-12\n",
      "  done: false\n",
      "  episode_len_mean: 110.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.85999999999994\n",
      "  episode_reward_mean: 17.729299999999945\n",
      "  episode_reward_min: 9.470000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1613\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6904172460238138\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010373251023614579\n",
      "          policy_loss: -0.00014343183665048507\n",
      "          total_loss: 0.4445294025753226\n",
      "          vf_explained_var: 0.9809646606445312\n",
      "          vf_loss: 0.458465031853744\n",
      "    num_agent_steps_sampled: 165834\n",
      "    num_agent_steps_trained: 165834\n",
      "    num_steps_sampled: 165834\n",
      "    num_steps_trained: 165834\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.48064516129033\n",
      "    ram_util_percent: 31.725806451612904\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04420963549906377\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.772754158038342\n",
      "    mean_inference_ms: 2.439096526672365\n",
      "    mean_raw_obs_processing_ms: 1.9366538513167446\n",
      "  time_since_restore: 2202.2048749923706\n",
      "  time_this_iter_s: 22.012037754058838\n",
      "  time_total_s: 2202.2048749923706\n",
      "  timers:\n",
      "    learn_throughput: 1113.795\n",
      "    learn_time_ms: 1793.867\n",
      "    load_throughput: 56783.864\n",
      "    load_time_ms: 35.186\n",
      "    sample_throughput: 89.948\n",
      "    sample_time_ms: 22212.936\n",
      "    update_time_ms: 15.73\n",
      "  timestamp: 1636841172\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 165834\n",
      "  training_iteration: 83\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">          2202.2</td><td style=\"text-align: right;\">165834</td><td style=\"text-align: right;\"> 17.7293</td><td style=\"text-align: right;\">               20.86</td><td style=\"text-align: right;\">                9.47</td><td style=\"text-align: right;\">            110.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 167832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-06-35\n",
      "  done: false\n",
      "  episode_len_mean: 110.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.85999999999994\n",
      "  episode_reward_mean: 17.78169999999994\n",
      "  episode_reward_min: 9.470000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1631\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6412416900907243\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013338606762541769\n",
      "          policy_loss: 0.009395441377446766\n",
      "          total_loss: 0.6029155730890731\n",
      "          vf_explained_var: 0.9729859828948975\n",
      "          vf_loss: 0.6059309645068078\n",
      "    num_agent_steps_sampled: 167832\n",
      "    num_agent_steps_trained: 167832\n",
      "    num_steps_sampled: 167832\n",
      "    num_steps_trained: 167832\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.71212121212122\n",
      "    ram_util_percent: 31.75454545454545\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04419634275333402\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.72904700014661\n",
      "    mean_inference_ms: 2.438966651780649\n",
      "    mean_raw_obs_processing_ms: 1.920492611426657\n",
      "  time_since_restore: 2224.9370622634888\n",
      "  time_this_iter_s: 22.732187271118164\n",
      "  time_total_s: 2224.9370622634888\n",
      "  timers:\n",
      "    learn_throughput: 1116.68\n",
      "    learn_time_ms: 1789.232\n",
      "    load_throughput: 56585.597\n",
      "    load_time_ms: 35.309\n",
      "    sample_throughput: 96.939\n",
      "    sample_time_ms: 20610.866\n",
      "    update_time_ms: 13.422\n",
      "  timestamp: 1636841195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 167832\n",
      "  training_iteration: 84\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         2224.94</td><td style=\"text-align: right;\">167832</td><td style=\"text-align: right;\"> 17.7817</td><td style=\"text-align: right;\">               20.86</td><td style=\"text-align: right;\">                9.47</td><td style=\"text-align: right;\">            110.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 169830\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-06-57\n",
      "  done: false\n",
      "  episode_len_mean: 111.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.67999999999995\n",
      "  episode_reward_mean: 17.905799999999935\n",
      "  episode_reward_min: 9.470000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1649\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6653145284879776\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012412244953913694\n",
      "          policy_loss: 0.009585922459761302\n",
      "          total_loss: 0.4620588656780975\n",
      "          vf_explained_var: 0.9803516268730164\n",
      "          vf_loss: 0.4654024131241299\n",
      "    num_agent_steps_sampled: 169830\n",
      "    num_agent_steps_trained: 169830\n",
      "    num_steps_sampled: 169830\n",
      "    num_steps_trained: 169830\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.26774193548387\n",
      "    ram_util_percent: 31.745161290322578\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0441851641943121\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.686544961588133\n",
      "    mean_inference_ms: 2.438905987222488\n",
      "    mean_raw_obs_processing_ms: 1.9048208457172047\n",
      "  time_since_restore: 2246.8325278759003\n",
      "  time_this_iter_s: 21.8954656124115\n",
      "  time_total_s: 2246.8325278759003\n",
      "  timers:\n",
      "    learn_throughput: 1126.729\n",
      "    learn_time_ms: 1773.274\n",
      "    load_throughput: 56947.629\n",
      "    load_time_ms: 35.085\n",
      "    sample_throughput: 97.718\n",
      "    sample_time_ms: 20446.581\n",
      "    update_time_ms: 12.933\n",
      "  timestamp: 1636841217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169830\n",
      "  training_iteration: 85\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         2246.83</td><td style=\"text-align: right;\">169830</td><td style=\"text-align: right;\"> 17.9058</td><td style=\"text-align: right;\">               20.68</td><td style=\"text-align: right;\">                9.47</td><td style=\"text-align: right;\">            111.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 171828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-07-19\n",
      "  done: false\n",
      "  episode_len_mean: 111.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.67999999999995\n",
      "  episode_reward_mean: 17.94969999999994\n",
      "  episode_reward_min: 9.470000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1667\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6158346306710016\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011185788028411602\n",
      "          policy_loss: 0.008360119376863753\n",
      "          total_loss: 0.3971852244010993\n",
      "          vf_explained_var: 0.9799082279205322\n",
      "          vf_loss: 0.4016277162092073\n",
      "    num_agent_steps_sampled: 171828\n",
      "    num_agent_steps_trained: 171828\n",
      "    num_steps_sampled: 171828\n",
      "    num_steps_trained: 171828\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.640625\n",
      "    ram_util_percent: 31.73125\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04416716485828803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.649622603408996\n",
      "    mean_inference_ms: 2.4387971740852645\n",
      "    mean_raw_obs_processing_ms: 1.8898256765542032\n",
      "  time_since_restore: 2269.077793598175\n",
      "  time_this_iter_s: 22.24526572227478\n",
      "  time_total_s: 2269.077793598175\n",
      "  timers:\n",
      "    learn_throughput: 1126.04\n",
      "    learn_time_ms: 1774.36\n",
      "    load_throughput: 57465.99\n",
      "    load_time_ms: 34.768\n",
      "    sample_throughput: 97.883\n",
      "    sample_time_ms: 20412.205\n",
      "    update_time_ms: 12.409\n",
      "  timestamp: 1636841239\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 171828\n",
      "  training_iteration: 86\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         2269.08</td><td style=\"text-align: right;\">171828</td><td style=\"text-align: right;\"> 17.9497</td><td style=\"text-align: right;\">               20.68</td><td style=\"text-align: right;\">                9.47</td><td style=\"text-align: right;\">            111.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 173826\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-07-41\n",
      "  done: false\n",
      "  episode_len_mean: 110.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.78999999999995\n",
      "  episode_reward_mean: 18.119999999999937\n",
      "  episode_reward_min: 9.470000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1685\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6272864693687075\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010317403862244032\n",
      "          policy_loss: 0.035961571974413735\n",
      "          total_loss: 0.45120665438118435\n",
      "          vf_explained_var: 0.9771029949188232\n",
      "          vf_loss: 0.42842272541352683\n",
      "    num_agent_steps_sampled: 173826\n",
      "    num_agent_steps_trained: 173826\n",
      "    num_steps_sampled: 173826\n",
      "    num_steps_trained: 173826\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5875\n",
      "    ram_util_percent: 31.728125\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04415127967120583\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.610564921007946\n",
      "    mean_inference_ms: 2.438669999978528\n",
      "    mean_raw_obs_processing_ms: 1.8751310867887003\n",
      "  time_since_restore: 2291.5536012649536\n",
      "  time_this_iter_s: 22.475807666778564\n",
      "  time_total_s: 2291.5536012649536\n",
      "  timers:\n",
      "    learn_throughput: 1124.403\n",
      "    learn_time_ms: 1776.943\n",
      "    load_throughput: 57585.521\n",
      "    load_time_ms: 34.696\n",
      "    sample_throughput: 98.201\n",
      "    sample_time_ms: 20345.981\n",
      "    update_time_ms: 13.124\n",
      "  timestamp: 1636841261\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 173826\n",
      "  training_iteration: 87\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         2291.55</td><td style=\"text-align: right;\">173826</td><td style=\"text-align: right;\">   18.12</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">                9.47</td><td style=\"text-align: right;\">            110.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 175824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-08-04\n",
      "  done: false\n",
      "  episode_len_mean: 110.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.78999999999995\n",
      "  episode_reward_mean: 18.26089999999994\n",
      "  episode_reward_min: 9.470000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1703\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6301525632540386\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011007087087960889\n",
      "          policy_loss: -0.038515881519942056\n",
      "          total_loss: 0.3406763289655958\n",
      "          vf_explained_var: 0.9807603359222412\n",
      "          vf_loss: 0.3921916091016361\n",
      "    num_agent_steps_sampled: 175824\n",
      "    num_agent_steps_trained: 175824\n",
      "    num_steps_sampled: 175824\n",
      "    num_steps_trained: 175824\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.575\n",
      "    ram_util_percent: 31.675\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04413497542630444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.57469940673367\n",
      "    mean_inference_ms: 2.4384538724072002\n",
      "    mean_raw_obs_processing_ms: 1.8608677872049861\n",
      "  time_since_restore: 2314.3551557064056\n",
      "  time_this_iter_s: 22.801554441452026\n",
      "  time_total_s: 2314.3551557064056\n",
      "  timers:\n",
      "    learn_throughput: 1125.984\n",
      "    learn_time_ms: 1774.447\n",
      "    load_throughput: 56847.421\n",
      "    load_time_ms: 35.147\n",
      "    sample_throughput: 97.981\n",
      "    sample_time_ms: 20391.674\n",
      "    update_time_ms: 14.129\n",
      "  timestamp: 1636841284\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 175824\n",
      "  training_iteration: 88\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         2314.36</td><td style=\"text-align: right;\">175824</td><td style=\"text-align: right;\"> 18.2609</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">                9.47</td><td style=\"text-align: right;\">            110.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 177822\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-08-26\n",
      "  done: false\n",
      "  episode_len_mean: 110.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.78999999999995\n",
      "  episode_reward_mean: 18.504299999999937\n",
      "  episode_reward_min: 11.730000000000022\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1722\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5636804399036226\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010983583863145093\n",
      "          policy_loss: -0.022884496301412583\n",
      "          total_loss: 0.44435096212795805\n",
      "          vf_explained_var: 0.9767658114433289\n",
      "          vf_loss: 0.4795771909611566\n",
      "    num_agent_steps_sampled: 177822\n",
      "    num_agent_steps_trained: 177822\n",
      "    num_steps_sampled: 177822\n",
      "    num_steps_trained: 177822\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.55\n",
      "    ram_util_percent: 31.65625\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044108463603741176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.539687920668275\n",
      "    mean_inference_ms: 2.4380647649646554\n",
      "    mean_raw_obs_processing_ms: 1.8463786877890564\n",
      "  time_since_restore: 2336.523030757904\n",
      "  time_this_iter_s: 22.167875051498413\n",
      "  time_total_s: 2336.523030757904\n",
      "  timers:\n",
      "    learn_throughput: 1126.108\n",
      "    learn_time_ms: 1774.253\n",
      "    load_throughput: 57355.157\n",
      "    load_time_ms: 34.836\n",
      "    sample_throughput: 97.816\n",
      "    sample_time_ms: 20426.034\n",
      "    update_time_ms: 14.046\n",
      "  timestamp: 1636841306\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 177822\n",
      "  training_iteration: 89\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         2336.52</td><td style=\"text-align: right;\">177822</td><td style=\"text-align: right;\"> 18.5043</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">               11.73</td><td style=\"text-align: right;\">            110.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 179820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-08-49\n",
      "  done: false\n",
      "  episode_len_mean: 110.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.78999999999995\n",
      "  episode_reward_mean: 18.562999999999935\n",
      "  episode_reward_min: 14.06000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1740\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6445948123931884\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01734739193024358\n",
      "          policy_loss: 0.003134311842066901\n",
      "          total_loss: 0.5362420300376557\n",
      "          vf_explained_var: 0.9774152636528015\n",
      "          vf_loss: 0.54434945193075\n",
      "    num_agent_steps_sampled: 179820\n",
      "    num_agent_steps_trained: 179820\n",
      "    num_steps_sampled: 179820\n",
      "    num_steps_trained: 179820\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.859375\n",
      "    ram_util_percent: 31.625\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044093527390202406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.506247285809046\n",
      "    mean_inference_ms: 2.438074222831045\n",
      "    mean_raw_obs_processing_ms: 1.83282270754685\n",
      "  time_since_restore: 2358.6355657577515\n",
      "  time_this_iter_s: 22.112534999847412\n",
      "  time_total_s: 2358.6355657577515\n",
      "  timers:\n",
      "    learn_throughput: 1124.81\n",
      "    learn_time_ms: 1776.3\n",
      "    load_throughput: 57102.261\n",
      "    load_time_ms: 34.99\n",
      "    sample_throughput: 97.828\n",
      "    sample_time_ms: 20423.512\n",
      "    update_time_ms: 13.816\n",
      "  timestamp: 1636841329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179820\n",
      "  training_iteration: 90\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         2358.64</td><td style=\"text-align: right;\">179820</td><td style=\"text-align: right;\">  18.563</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">               14.06</td><td style=\"text-align: right;\">            110.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 181818\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-09-11\n",
      "  done: false\n",
      "  episode_len_mean: 109.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.78999999999995\n",
      "  episode_reward_mean: 18.543999999999933\n",
      "  episode_reward_min: 14.050000000000022\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1759\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5570055132820493\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009947780976052336\n",
      "          policy_loss: -0.0413735456764698\n",
      "          total_loss: 0.3479982505951609\n",
      "          vf_explained_var: 0.9814622402191162\n",
      "          vf_loss: 0.40195751761396725\n",
      "    num_agent_steps_sampled: 181818\n",
      "    num_agent_steps_trained: 181818\n",
      "    num_steps_sampled: 181818\n",
      "    num_steps_trained: 181818\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.453125\n",
      "    ram_util_percent: 31.637500000000003\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044067087255497996\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.476269925565003\n",
      "    mean_inference_ms: 2.4376524698828828\n",
      "    mean_raw_obs_processing_ms: 1.8191701620043892\n",
      "  time_since_restore: 2381.3628220558167\n",
      "  time_this_iter_s: 22.727256298065186\n",
      "  time_total_s: 2381.3628220558167\n",
      "  timers:\n",
      "    learn_throughput: 1124.687\n",
      "    learn_time_ms: 1776.495\n",
      "    load_throughput: 58099.579\n",
      "    load_time_ms: 34.389\n",
      "    sample_throughput: 97.706\n",
      "    sample_time_ms: 20449.054\n",
      "    update_time_ms: 11.257\n",
      "  timestamp: 1636841351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 181818\n",
      "  training_iteration: 91\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         2381.36</td><td style=\"text-align: right;\">181818</td><td style=\"text-align: right;\">  18.544</td><td style=\"text-align: right;\">               20.79</td><td style=\"text-align: right;\">               14.05</td><td style=\"text-align: right;\">            109.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 183816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-09-51\n",
      "  done: false\n",
      "  episode_len_mean: 107.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.759999999999927\n",
      "  episode_reward_mean: 18.44069999999994\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1778\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.507086197535197\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013447636193266607\n",
      "          policy_loss: -0.04189669347944714\n",
      "          total_loss: 0.9921809265301341\n",
      "          vf_explained_var: 0.9524948000907898\n",
      "          vf_loss: 1.045114207409677\n",
      "    num_agent_steps_sampled: 183816\n",
      "    num_agent_steps_trained: 183816\n",
      "    num_steps_sampled: 183816\n",
      "    num_steps_trained: 183816\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.64736842105262\n",
      "    ram_util_percent: 31.61578947368421\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04405151462594402\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.45032640971117\n",
      "    mean_inference_ms: 2.4372079296570224\n",
      "    mean_raw_obs_processing_ms: 1.824982121649726\n",
      "  time_since_restore: 2420.956634283066\n",
      "  time_this_iter_s: 39.593812227249146\n",
      "  time_total_s: 2420.956634283066\n",
      "  timers:\n",
      "    learn_throughput: 1121.122\n",
      "    learn_time_ms: 1782.144\n",
      "    load_throughput: 58062.988\n",
      "    load_time_ms: 34.411\n",
      "    sample_throughput: 89.846\n",
      "    sample_time_ms: 22238.055\n",
      "    update_time_ms: 11.674\n",
      "  timestamp: 1636841391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 183816\n",
      "  training_iteration: 92\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         2420.96</td><td style=\"text-align: right;\">183816</td><td style=\"text-align: right;\"> 18.4407</td><td style=\"text-align: right;\">               20.76</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             107.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 185814\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 106.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.759999999999927\n",
      "  episode_reward_mean: 18.05069999999994\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1798\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6271198119435992\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010149403134017436\n",
      "          policy_loss: 0.007362799044875872\n",
      "          total_loss: 1.1681991689261937\n",
      "          vf_explained_var: 0.9494108557701111\n",
      "          vf_loss: 1.1740627219989186\n",
      "    num_agent_steps_sampled: 185814\n",
      "    num_agent_steps_trained: 185814\n",
      "    num_steps_sampled: 185814\n",
      "    num_steps_trained: 185814\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.35694444444445\n",
      "    ram_util_percent: 31.345833333333335\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044038709599873195\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.415938244331866\n",
      "    mean_inference_ms: 2.4368670508618164\n",
      "    mean_raw_obs_processing_ms: 1.8646966051160723\n",
      "  time_since_restore: 2471.758380651474\n",
      "  time_this_iter_s: 50.8017463684082\n",
      "  time_total_s: 2471.758380651474\n",
      "  timers:\n",
      "    learn_throughput: 1120.207\n",
      "    learn_time_ms: 1783.599\n",
      "    load_throughput: 57523.581\n",
      "    load_time_ms: 34.734\n",
      "    sample_throughput: 79.553\n",
      "    sample_time_ms: 25115.409\n",
      "    update_time_ms: 11.553\n",
      "  timestamp: 1636841442\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 185814\n",
      "  training_iteration: 93\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         2471.76</td><td style=\"text-align: right;\">185814</td><td style=\"text-align: right;\"> 18.0507</td><td style=\"text-align: right;\">               20.76</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            106.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 187812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-11-05\n",
      "  done: false\n",
      "  episode_len_mean: 106.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.689999999999962\n",
      "  episode_reward_mean: 17.820899999999934\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1816\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.587763362271445\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.019369949315071282\n",
      "          policy_loss: -0.017171752701203028\n",
      "          total_loss: 0.4551731254905462\n",
      "          vf_explained_var: 0.9803612232208252\n",
      "          vf_loss: 0.4824115271369616\n",
      "    num_agent_steps_sampled: 187812\n",
      "    num_agent_steps_trained: 187812\n",
      "    num_steps_sampled: 187812\n",
      "    num_steps_trained: 187812\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.81470588235295\n",
      "    ram_util_percent: 31.205882352941178\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044034964928204794\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.38717270462329\n",
      "    mean_inference_ms: 2.4367383995032434\n",
      "    mean_raw_obs_processing_ms: 1.9002854073860322\n",
      "  time_since_restore: 2495.129469394684\n",
      "  time_this_iter_s: 23.37108874320984\n",
      "  time_total_s: 2495.129469394684\n",
      "  timers:\n",
      "    learn_throughput: 1121.43\n",
      "    learn_time_ms: 1781.653\n",
      "    load_throughput: 56882.264\n",
      "    load_time_ms: 35.125\n",
      "    sample_throughput: 79.348\n",
      "    sample_time_ms: 25180.293\n",
      "    update_time_ms: 12.298\n",
      "  timestamp: 1636841465\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 187812\n",
      "  training_iteration: 94\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         2495.13</td><td style=\"text-align: right;\">187812</td><td style=\"text-align: right;\"> 17.8209</td><td style=\"text-align: right;\">               20.69</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            106.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 189810\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-11-27\n",
      "  done: false\n",
      "  episode_len_mean: 106.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999943\n",
      "  episode_reward_mean: 17.910999999999934\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1834\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5484186677705674\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010369657202405683\n",
      "          policy_loss: 0.011159782626089595\n",
      "          total_loss: 0.34946475965636115\n",
      "          vf_explained_var: 0.9848112463951111\n",
      "          vf_loss: 0.3506782669041838\n",
      "    num_agent_steps_sampled: 189810\n",
      "    num_agent_steps_trained: 189810\n",
      "    num_steps_sampled: 189810\n",
      "    num_steps_trained: 189810\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.75806451612905\n",
      "    ram_util_percent: 31.42903225806451\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04402175235134123\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.358101107695024\n",
      "    mean_inference_ms: 2.4362250102670067\n",
      "    mean_raw_obs_processing_ms: 1.9356545930396576\n",
      "  time_since_restore: 2517.378712415695\n",
      "  time_this_iter_s: 22.249243021011353\n",
      "  time_total_s: 2517.378712415695\n",
      "  timers:\n",
      "    learn_throughput: 1121.542\n",
      "    learn_time_ms: 1781.476\n",
      "    load_throughput: 56549.742\n",
      "    load_time_ms: 35.332\n",
      "    sample_throughput: 79.236\n",
      "    sample_time_ms: 25215.912\n",
      "    update_time_ms: 11.892\n",
      "  timestamp: 1636841487\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189810\n",
      "  training_iteration: 95\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         2517.38</td><td style=\"text-align: right;\">189810</td><td style=\"text-align: right;\">  17.911</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            106.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 191808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-11-49\n",
      "  done: false\n",
      "  episode_len_mean: 106.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999943\n",
      "  episode_reward_mean: 17.996399999999934\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1853\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5677674770355225\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013673470481801\n",
      "          policy_loss: -0.06141674064454578\n",
      "          total_loss: 0.2899356407778604\n",
      "          vf_explained_var: 0.9847626686096191\n",
      "          vf_loss: 0.3629280169095312\n",
      "    num_agent_steps_sampled: 191808\n",
      "    num_agent_steps_trained: 191808\n",
      "    num_steps_sampled: 191808\n",
      "    num_steps_trained: 191808\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.909375\n",
      "    ram_util_percent: 31.484375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04401668036959934\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.32470166913518\n",
      "    mean_inference_ms: 2.4361086148457423\n",
      "    mean_raw_obs_processing_ms: 1.9725067441105946\n",
      "  time_since_restore: 2539.2673552036285\n",
      "  time_this_iter_s: 21.88864278793335\n",
      "  time_total_s: 2539.2673552036285\n",
      "  timers:\n",
      "    learn_throughput: 1122.423\n",
      "    learn_time_ms: 1780.077\n",
      "    load_throughput: 56537.381\n",
      "    load_time_ms: 35.339\n",
      "    sample_throughput: 79.343\n",
      "    sample_time_ms: 25181.672\n",
      "    update_time_ms: 12.019\n",
      "  timestamp: 1636841509\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 191808\n",
      "  training_iteration: 96\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         2539.27</td><td style=\"text-align: right;\">191808</td><td style=\"text-align: right;\"> 17.9964</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            106.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 193806\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-12-12\n",
      "  done: false\n",
      "  episode_len_mean: 107.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999943\n",
      "  episode_reward_mean: 18.30919999999993\n",
      "  episode_reward_min: 1.94\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1871\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5282579109782264\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015040780546745038\n",
      "          policy_loss: -0.02141638029189337\n",
      "          total_loss: 0.23592339061378015\n",
      "          vf_explained_var: 0.9892106056213379\n",
      "          vf_loss: 0.2681101145488875\n",
      "    num_agent_steps_sampled: 193806\n",
      "    num_agent_steps_trained: 193806\n",
      "    num_steps_sampled: 193806\n",
      "    num_steps_trained: 193806\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.60967741935484\n",
      "    ram_util_percent: 31.53225806451613\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400650904508144\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.29105442669368\n",
      "    mean_inference_ms: 2.4360075056519226\n",
      "    mean_raw_obs_processing_ms: 1.988076060475837\n",
      "  time_since_restore: 2561.421773672104\n",
      "  time_this_iter_s: 22.154418468475342\n",
      "  time_total_s: 2561.421773672104\n",
      "  timers:\n",
      "    learn_throughput: 1123.338\n",
      "    learn_time_ms: 1778.627\n",
      "    load_throughput: 56397.362\n",
      "    load_time_ms: 35.427\n",
      "    sample_throughput: 79.44\n",
      "    sample_time_ms: 25150.996\n",
      "    update_time_ms: 11.391\n",
      "  timestamp: 1636841532\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 193806\n",
      "  training_iteration: 97\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         2561.42</td><td style=\"text-align: right;\">193806</td><td style=\"text-align: right;\"> 18.3092</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">            107.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 195804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-12-33\n",
      "  done: false\n",
      "  episode_len_mean: 108.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999943\n",
      "  episode_reward_mean: 18.49389999999993\n",
      "  episode_reward_min: 1.94\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1889\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5954686068353199\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00869668973079626\n",
      "          policy_loss: -0.0515350211056925\n",
      "          total_loss: 0.18329534337279343\n",
      "          vf_explained_var: 0.9904111623764038\n",
      "          vf_loss: 0.24817604191956066\n",
      "    num_agent_steps_sampled: 195804\n",
      "    num_agent_steps_trained: 195804\n",
      "    num_steps_sampled: 195804\n",
      "    num_steps_trained: 195804\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84516129032258\n",
      "    ram_util_percent: 31.629032258064516\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399140804313318\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.259886517457367\n",
      "    mean_inference_ms: 2.4357959698977742\n",
      "    mean_raw_obs_processing_ms: 1.9928671199990953\n",
      "  time_since_restore: 2582.83873963356\n",
      "  time_this_iter_s: 21.4169659614563\n",
      "  time_total_s: 2582.83873963356\n",
      "  timers:\n",
      "    learn_throughput: 1124.439\n",
      "    learn_time_ms: 1776.887\n",
      "    load_throughput: 56859.069\n",
      "    load_time_ms: 35.14\n",
      "    sample_throughput: 79.873\n",
      "    sample_time_ms: 25014.677\n",
      "    update_time_ms: 11.03\n",
      "  timestamp: 1636841553\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 195804\n",
      "  training_iteration: 98\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         2582.84</td><td style=\"text-align: right;\">195804</td><td style=\"text-align: right;\"> 18.4939</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">            108.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 197802\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-12-55\n",
      "  done: false\n",
      "  episode_len_mean: 109.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999943\n",
      "  episode_reward_mean: 18.943299999999926\n",
      "  episode_reward_min: 9.630000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1907\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4782796553203037\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013192113647766693\n",
      "          policy_loss: -0.0025401452822344643\n",
      "          total_loss: 0.2685438723968608\n",
      "          vf_explained_var: 0.9900880455970764\n",
      "          vf_loss: 0.28190918295156386\n",
      "    num_agent_steps_sampled: 197802\n",
      "    num_agent_steps_trained: 197802\n",
      "    num_steps_sampled: 197802\n",
      "    num_steps_trained: 197802\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.840625\n",
      "    ram_util_percent: 31.771875\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043979767042948016\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.226574303326753\n",
      "    mean_inference_ms: 2.4357270596950142\n",
      "    mean_raw_obs_processing_ms: 1.9789521041950793\n",
      "  time_since_restore: 2605.070199728012\n",
      "  time_this_iter_s: 22.231460094451904\n",
      "  time_total_s: 2605.070199728012\n",
      "  timers:\n",
      "    learn_throughput: 1123.661\n",
      "    learn_time_ms: 1778.116\n",
      "    load_throughput: 56256.411\n",
      "    load_time_ms: 35.516\n",
      "    sample_throughput: 79.861\n",
      "    sample_time_ms: 25018.564\n",
      "    update_time_ms: 11.708\n",
      "  timestamp: 1636841575\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 197802\n",
      "  training_iteration: 99\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         2605.07</td><td style=\"text-align: right;\">197802</td><td style=\"text-align: right;\"> 18.9433</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">                9.63</td><td style=\"text-align: right;\">            109.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 199800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-13-18\n",
      "  done: false\n",
      "  episode_len_mean: 109.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.909999999999926\n",
      "  episode_reward_mean: 19.276699999999927\n",
      "  episode_reward_min: 12.960000000000015\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1925\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5269197901089986\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009688930504033699\n",
      "          policy_loss: -0.042059803452520146\n",
      "          total_loss: 0.16226651954154173\n",
      "          vf_explained_var: 0.9917386770248413\n",
      "          vf_loss: 0.21668884051697596\n",
      "    num_agent_steps_sampled: 199800\n",
      "    num_agent_steps_trained: 199800\n",
      "    num_steps_sampled: 199800\n",
      "    num_steps_trained: 199800\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.41612903225808\n",
      "    ram_util_percent: 31.806451612903224\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04397036133720303\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.196509021585992\n",
      "    mean_inference_ms: 2.4356070578111524\n",
      "    mean_raw_obs_processing_ms: 1.9652495472443479\n",
      "  time_since_restore: 2627.294408082962\n",
      "  time_this_iter_s: 22.22420835494995\n",
      "  time_total_s: 2627.294408082962\n",
      "  timers:\n",
      "    learn_throughput: 1123.587\n",
      "    learn_time_ms: 1778.233\n",
      "    load_throughput: 56410.346\n",
      "    load_time_ms: 35.419\n",
      "    sample_throughput: 79.825\n",
      "    sample_time_ms: 25029.891\n",
      "    update_time_ms: 11.607\n",
      "  timestamp: 1636841598\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199800\n",
      "  training_iteration: 100\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         2627.29</td><td style=\"text-align: right;\">199800</td><td style=\"text-align: right;\"> 19.2767</td><td style=\"text-align: right;\">               20.91</td><td style=\"text-align: right;\">               12.96</td><td style=\"text-align: right;\">            109.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 201798\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-13-40\n",
      "  done: false\n",
      "  episode_len_mean: 109.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.909999999999926\n",
      "  episode_reward_mean: 19.34339999999992\n",
      "  episode_reward_min: 11.890000000000025\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1944\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.52400822752998\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016878669145814703\n",
      "          policy_loss: 0.011668770902213596\n",
      "          total_loss: 0.38363510964970504\n",
      "          vf_explained_var: 0.9859105944633484\n",
      "          vf_loss: 0.38214282020926477\n",
      "    num_agent_steps_sampled: 201798\n",
      "    num_agent_steps_trained: 201798\n",
      "    num_steps_sampled: 201798\n",
      "    num_steps_trained: 201798\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.19375\n",
      "    ram_util_percent: 31.86875\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04395947614838379\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.165834530437373\n",
      "    mean_inference_ms: 2.4353184302513258\n",
      "    mean_raw_obs_processing_ms: 1.9513249078966914\n",
      "  time_since_restore: 2649.4906005859375\n",
      "  time_this_iter_s: 22.196192502975464\n",
      "  time_total_s: 2649.4906005859375\n",
      "  timers:\n",
      "    learn_throughput: 1124.677\n",
      "    learn_time_ms: 1776.51\n",
      "    load_throughput: 56657.481\n",
      "    load_time_ms: 35.265\n",
      "    sample_throughput: 79.992\n",
      "    sample_time_ms: 24977.415\n",
      "    update_time_ms: 12.874\n",
      "  timestamp: 1636841620\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 201798\n",
      "  training_iteration: 101\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         2649.49</td><td style=\"text-align: right;\">201798</td><td style=\"text-align: right;\"> 19.3434</td><td style=\"text-align: right;\">               20.91</td><td style=\"text-align: right;\">               11.89</td><td style=\"text-align: right;\">            109.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 203796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 108.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999968\n",
      "  episode_reward_mean: 19.24699999999992\n",
      "  episode_reward_min: 9.70000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1962\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4870219798315139\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01152914193653896\n",
      "          policy_loss: -0.03231454566121102\n",
      "          total_loss: 0.34802953935272635\n",
      "          vf_explained_var: 0.9847089648246765\n",
      "          vf_loss: 0.39175556263043765\n",
      "    num_agent_steps_sampled: 203796\n",
      "    num_agent_steps_trained: 203796\n",
      "    num_steps_sampled: 203796\n",
      "    num_steps_trained: 203796\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.53030303030305\n",
      "    ram_util_percent: 31.90606060606061\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043966524596848446\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.135480538240234\n",
      "    mean_inference_ms: 2.435206370638125\n",
      "    mean_raw_obs_processing_ms: 1.9382043265685291\n",
      "  time_since_restore: 2672.2179498672485\n",
      "  time_this_iter_s: 22.727349281311035\n",
      "  time_total_s: 2672.2179498672485\n",
      "  timers:\n",
      "    learn_throughput: 1126.818\n",
      "    learn_time_ms: 1773.134\n",
      "    load_throughput: 57225.909\n",
      "    load_time_ms: 34.914\n",
      "    sample_throughput: 85.768\n",
      "    sample_time_ms: 23295.354\n",
      "    update_time_ms: 12.137\n",
      "  timestamp: 1636841643\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 203796\n",
      "  training_iteration: 102\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         2672.22</td><td style=\"text-align: right;\">203796</td><td style=\"text-align: right;\">  19.247</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">                 9.7</td><td style=\"text-align: right;\">             108.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 205794\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-14-25\n",
      "  done: false\n",
      "  episode_len_mean: 109.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999968\n",
      "  episode_reward_mean: 19.29759999999992\n",
      "  episode_reward_min: 9.70000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1980\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.554200349535261\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009580686095933265\n",
      "          policy_loss: 0.008197527325579098\n",
      "          total_loss: 0.159075866338043\n",
      "          vf_explained_var: 0.9943326115608215\n",
      "          vf_loss: 0.1635461386115778\n",
      "    num_agent_steps_sampled: 205794\n",
      "    num_agent_steps_trained: 205794\n",
      "    num_steps_sampled: 205794\n",
      "    num_steps_trained: 205794\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9875\n",
      "    ram_util_percent: 31.903125000000003\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04397332440458305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.106619491727134\n",
      "    mean_inference_ms: 2.435126953704233\n",
      "    mean_raw_obs_processing_ms: 1.9253612646116058\n",
      "  time_since_restore: 2694.6912813186646\n",
      "  time_this_iter_s: 22.473331451416016\n",
      "  time_total_s: 2694.6912813186646\n",
      "  timers:\n",
      "    learn_throughput: 1127.573\n",
      "    learn_time_ms: 1771.948\n",
      "    load_throughput: 57790.99\n",
      "    load_time_ms: 34.573\n",
      "    sample_throughput: 97.632\n",
      "    sample_time_ms: 20464.69\n",
      "    update_time_ms: 11.763\n",
      "  timestamp: 1636841665\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 205794\n",
      "  training_iteration: 103\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         2694.69</td><td style=\"text-align: right;\">205794</td><td style=\"text-align: right;\"> 19.2976</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">                 9.7</td><td style=\"text-align: right;\">            109.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 207792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-14-47\n",
      "  done: false\n",
      "  episode_len_mean: 108.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999968\n",
      "  episode_reward_mean: 19.406199999999924\n",
      "  episode_reward_min: 9.70000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1999\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5240440380005609\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00912114228493261\n",
      "          policy_loss: -0.06000282986178285\n",
      "          total_loss: 0.09438596131900946\n",
      "          vf_explained_var: 0.9943873286247253\n",
      "          vf_loss: 0.1668928872616518\n",
      "    num_agent_steps_sampled: 207792\n",
      "    num_agent_steps_trained: 207792\n",
      "    num_steps_sampled: 207792\n",
      "    num_steps_trained: 207792\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9967741935484\n",
      "    ram_util_percent: 31.89354838709677\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04397854819968774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.08099064400183\n",
      "    mean_inference_ms: 2.434837298979505\n",
      "    mean_raw_obs_processing_ms: 1.9123115604019574\n",
      "  time_since_restore: 2716.7486777305603\n",
      "  time_this_iter_s: 22.057396411895752\n",
      "  time_total_s: 2716.7486777305603\n",
      "  timers:\n",
      "    learn_throughput: 1126.424\n",
      "    learn_time_ms: 1773.755\n",
      "    load_throughput: 58575.693\n",
      "    load_time_ms: 34.11\n",
      "    sample_throughput: 98.27\n",
      "    sample_time_ms: 20331.731\n",
      "    update_time_ms: 12.171\n",
      "  timestamp: 1636841687\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 207792\n",
      "  training_iteration: 104\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         2716.75</td><td style=\"text-align: right;\">207792</td><td style=\"text-align: right;\"> 19.4062</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">                 9.7</td><td style=\"text-align: right;\">            108.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 209790\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-15-08\n",
      "  done: false\n",
      "  episode_len_mean: 109.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999968\n",
      "  episode_reward_mean: 19.383399999999924\n",
      "  episode_reward_min: 9.70000000000002\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2016\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5985376250176202\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01393891516686539\n",
      "          policy_loss: 0.018402711018210366\n",
      "          total_loss: 0.3349499130178066\n",
      "          vf_explained_var: 0.9890633821487427\n",
      "          vf_loss: 0.32835090522255217\n",
      "    num_agent_steps_sampled: 209790\n",
      "    num_agent_steps_trained: 209790\n",
      "    num_steps_sampled: 209790\n",
      "    num_steps_trained: 209790\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97\n",
      "    ram_util_percent: 31.89999999999999\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04398731568007071\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.05193554447189\n",
      "    mean_inference_ms: 2.4350120520656886\n",
      "    mean_raw_obs_processing_ms: 1.9006944623553366\n",
      "  time_since_restore: 2737.680439710617\n",
      "  time_this_iter_s: 20.931761980056763\n",
      "  time_total_s: 2737.680439710617\n",
      "  timers:\n",
      "    learn_throughput: 1126.685\n",
      "    learn_time_ms: 1773.344\n",
      "    load_throughput: 58759.076\n",
      "    load_time_ms: 34.003\n",
      "    sample_throughput: 98.913\n",
      "    sample_time_ms: 20199.479\n",
      "    update_time_ms: 12.868\n",
      "  timestamp: 1636841708\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209790\n",
      "  training_iteration: 105\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         2737.68</td><td style=\"text-align: right;\">209790</td><td style=\"text-align: right;\"> 19.3834</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">                 9.7</td><td style=\"text-align: right;\">            109.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 211788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-15-31\n",
      "  done: false\n",
      "  episode_len_mean: 110.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999968\n",
      "  episode_reward_mean: 19.37099999999992\n",
      "  episode_reward_min: 9.70000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2035\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4817906691914513\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010879107619977546\n",
      "          policy_loss: 0.0037458151312811036\n",
      "          total_loss: 0.3545135883348329\n",
      "          vf_explained_var: 0.9862349629402161\n",
      "          vf_loss: 0.3623219486503374\n",
      "    num_agent_steps_sampled: 211788\n",
      "    num_agent_steps_trained: 211788\n",
      "    num_steps_sampled: 211788\n",
      "    num_steps_trained: 211788\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.70303030303032\n",
      "    ram_util_percent: 31.881818181818186\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399450686776032\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.024582265381465\n",
      "    mean_inference_ms: 2.4349849606984026\n",
      "    mean_raw_obs_processing_ms: 1.8880748839050492\n",
      "  time_since_restore: 2760.541560649872\n",
      "  time_this_iter_s: 22.86112093925476\n",
      "  time_total_s: 2760.541560649872\n",
      "  timers:\n",
      "    learn_throughput: 1126.439\n",
      "    learn_time_ms: 1773.732\n",
      "    load_throughput: 59093.116\n",
      "    load_time_ms: 33.811\n",
      "    sample_throughput: 98.439\n",
      "    sample_time_ms: 20296.762\n",
      "    update_time_ms: 12.616\n",
      "  timestamp: 1636841731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 211788\n",
      "  training_iteration: 106\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         2760.54</td><td style=\"text-align: right;\">211788</td><td style=\"text-align: right;\">  19.371</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">                 9.7</td><td style=\"text-align: right;\">            110.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 213786\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-15-53\n",
      "  done: false\n",
      "  episode_len_mean: 110.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999968\n",
      "  episode_reward_mean: 19.549199999999917\n",
      "  episode_reward_min: 13.890000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2053\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5107008054142907\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01004050987229074\n",
      "          policy_loss: -0.03623255267739296\n",
      "          total_loss: 0.14373347308664094\n",
      "          vf_explained_var: 0.9927672147750854\n",
      "          vf_loss: 0.19206087557332857\n",
      "    num_agent_steps_sampled: 213786\n",
      "    num_agent_steps_trained: 213786\n",
      "    num_steps_sampled: 213786\n",
      "    num_steps_trained: 213786\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.74687500000002\n",
      "    ram_util_percent: 31.859375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044000582201860323\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.998736497700346\n",
      "    mean_inference_ms: 2.4349832258907163\n",
      "    mean_raw_obs_processing_ms: 1.8762459061009273\n",
      "  time_since_restore: 2782.8552775382996\n",
      "  time_this_iter_s: 22.313716888427734\n",
      "  time_total_s: 2782.8552775382996\n",
      "  timers:\n",
      "    learn_throughput: 1126.559\n",
      "    learn_time_ms: 1773.543\n",
      "    load_throughput: 59066.626\n",
      "    load_time_ms: 33.826\n",
      "    sample_throughput: 98.356\n",
      "    sample_time_ms: 20313.98\n",
      "    update_time_ms: 12.18\n",
      "  timestamp: 1636841753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 213786\n",
      "  training_iteration: 107\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         2782.86</td><td style=\"text-align: right;\">213786</td><td style=\"text-align: right;\"> 19.5492</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">               13.89</td><td style=\"text-align: right;\">            110.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 215784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-16-15\n",
      "  done: false\n",
      "  episode_len_mean: 110.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.73999999999992\n",
      "  episode_reward_mean: 19.479899999999915\n",
      "  episode_reward_min: 13.890000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2071\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5195326702935354\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010093859801959718\n",
      "          policy_loss: -0.01603868692403748\n",
      "          total_loss: 0.18660244890266942\n",
      "          vf_explained_var: 0.9919371008872986\n",
      "          vf_loss: 0.2148083054593631\n",
      "    num_agent_steps_sampled: 215784\n",
      "    num_agent_steps_trained: 215784\n",
      "    num_steps_sampled: 215784\n",
      "    num_steps_trained: 215784\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73548387096774\n",
      "    ram_util_percent: 31.835483870967742\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400766390556132\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.971736767052533\n",
      "    mean_inference_ms: 2.4349315618351586\n",
      "    mean_raw_obs_processing_ms: 1.8647136842063798\n",
      "  time_since_restore: 2804.473775625229\n",
      "  time_this_iter_s: 21.61849808692932\n",
      "  time_total_s: 2804.473775625229\n",
      "  timers:\n",
      "    learn_throughput: 1125.315\n",
      "    learn_time_ms: 1775.503\n",
      "    load_throughput: 58711.035\n",
      "    load_time_ms: 34.031\n",
      "    sample_throughput: 98.263\n",
      "    sample_time_ms: 20333.098\n",
      "    update_time_ms: 11.421\n",
      "  timestamp: 1636841775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 215784\n",
      "  training_iteration: 108\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         2804.47</td><td style=\"text-align: right;\">215784</td><td style=\"text-align: right;\"> 19.4799</td><td style=\"text-align: right;\">               20.74</td><td style=\"text-align: right;\">               13.89</td><td style=\"text-align: right;\">            110.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 217782\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-16-37\n",
      "  done: false\n",
      "  episode_len_mean: 110.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999936\n",
      "  episode_reward_mean: 19.464999999999918\n",
      "  episode_reward_min: 13.890000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2089\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.491561802228292\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009141465747854714\n",
      "          policy_loss: -0.02100204144205366\n",
      "          total_loss: 0.14567583020599115\n",
      "          vf_explained_var: 0.9940244555473328\n",
      "          vf_loss: 0.17885104996107873\n",
      "    num_agent_steps_sampled: 217782\n",
      "    num_agent_steps_trained: 217782\n",
      "    num_steps_sampled: 217782\n",
      "    num_steps_trained: 217782\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99032258064514\n",
      "    ram_util_percent: 31.84516129032258\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04401399039533441\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.941921899584692\n",
      "    mean_inference_ms: 2.435025012371426\n",
      "    mean_raw_obs_processing_ms: 1.8532394353505675\n",
      "  time_since_restore: 2826.8170807361603\n",
      "  time_this_iter_s: 22.343305110931396\n",
      "  time_total_s: 2826.8170807361603\n",
      "  timers:\n",
      "    learn_throughput: 1127.749\n",
      "    learn_time_ms: 1771.67\n",
      "    load_throughput: 59120.965\n",
      "    load_time_ms: 33.795\n",
      "    sample_throughput: 98.186\n",
      "    sample_time_ms: 20349.063\n",
      "    update_time_ms: 10.883\n",
      "  timestamp: 1636841797\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 217782\n",
      "  training_iteration: 109\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         2826.82</td><td style=\"text-align: right;\">217782</td><td style=\"text-align: right;\">  19.465</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">               13.89</td><td style=\"text-align: right;\">            110.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 219780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-17-00\n",
      "  done: false\n",
      "  episode_len_mean: 109.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999936\n",
      "  episode_reward_mean: 19.284899999999922\n",
      "  episode_reward_min: 11.870000000000022\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2107\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4964484731356302\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.021917364156590825\n",
      "          policy_loss: 0.015585773314038912\n",
      "          total_loss: 0.5038386098242231\n",
      "          vf_explained_var: 0.9821887016296387\n",
      "          vf_loss: 0.49664211386726015\n",
      "    num_agent_steps_sampled: 219780\n",
      "    num_agent_steps_trained: 219780\n",
      "    num_steps_sampled: 219780\n",
      "    num_steps_trained: 219780\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69999999999999\n",
      "    ram_util_percent: 31.818181818181817\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04401646411646366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.920715370158042\n",
      "    mean_inference_ms: 2.4347209399133267\n",
      "    mean_raw_obs_processing_ms: 1.8421111243429307\n",
      "  time_since_restore: 2849.4469532966614\n",
      "  time_this_iter_s: 22.6298725605011\n",
      "  time_total_s: 2849.4469532966614\n",
      "  timers:\n",
      "    learn_throughput: 1128.885\n",
      "    learn_time_ms: 1769.887\n",
      "    load_throughput: 59079.91\n",
      "    load_time_ms: 33.819\n",
      "    sample_throughput: 97.979\n",
      "    sample_time_ms: 20392.162\n",
      "    update_time_ms: 10.455\n",
      "  timestamp: 1636841820\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219780\n",
      "  training_iteration: 110\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         2849.45</td><td style=\"text-align: right;\">219780</td><td style=\"text-align: right;\"> 19.2849</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">               11.87</td><td style=\"text-align: right;\">             109.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 221778\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-17-38\n",
      "  done: false\n",
      "  episode_len_mean: 108.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999936\n",
      "  episode_reward_mean: 19.12289999999992\n",
      "  episode_reward_min: -0.16000000000000003\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2126\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5449711703118825\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013335161404729116\n",
      "          policy_loss: -0.013617381524472009\n",
      "          total_loss: 0.9061789330095052\n",
      "          vf_explained_var: 0.9664522409439087\n",
      "          vf_loss: 0.9292452128160568\n",
      "    num_agent_steps_sampled: 221778\n",
      "    num_agent_steps_trained: 221778\n",
      "    num_steps_sampled: 221778\n",
      "    num_steps_trained: 221778\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.43148148148148\n",
      "    ram_util_percent: 31.775925925925918\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04402131478031588\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.894903970149315\n",
      "    mean_inference_ms: 2.4345211316530726\n",
      "    mean_raw_obs_processing_ms: 1.846984319328798\n",
      "  time_since_restore: 2887.1647539138794\n",
      "  time_this_iter_s: 37.71780061721802\n",
      "  time_total_s: 2887.1647539138794\n",
      "  timers:\n",
      "    learn_throughput: 1128.091\n",
      "    learn_time_ms: 1771.134\n",
      "    load_throughput: 59119.964\n",
      "    load_time_ms: 33.796\n",
      "    sample_throughput: 91.054\n",
      "    sample_time_ms: 21943.031\n",
      "    update_time_ms: 10.298\n",
      "  timestamp: 1636841858\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 221778\n",
      "  training_iteration: 111\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         2887.16</td><td style=\"text-align: right;\">221778</td><td style=\"text-align: right;\"> 19.1229</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">               -0.16</td><td style=\"text-align: right;\">            108.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 223776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-18-15\n",
      "  done: false\n",
      "  episode_len_mean: 107.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999936\n",
      "  episode_reward_mean: 18.78529999999992\n",
      "  episode_reward_min: -0.16000000000000003\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2145\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5275387236050197\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012263872481979512\n",
      "          policy_loss: -0.01457340351882435\n",
      "          total_loss: 0.3166519745652165\n",
      "          vf_explained_var: 0.9884583353996277\n",
      "          vf_loss: 0.34098202383943965\n",
      "    num_agent_steps_sampled: 223776\n",
      "    num_agent_steps_trained: 223776\n",
      "    num_steps_sampled: 223776\n",
      "    num_steps_trained: 223776\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.29807692307692\n",
      "    ram_util_percent: 31.738461538461536\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0440241042390333\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.868043465904428\n",
      "    mean_inference_ms: 2.434267827908304\n",
      "    mean_raw_obs_processing_ms: 1.865600248680024\n",
      "  time_since_restore: 2924.0252346992493\n",
      "  time_this_iter_s: 36.86048078536987\n",
      "  time_total_s: 2924.0252346992493\n",
      "  timers:\n",
      "    learn_throughput: 1130.304\n",
      "    learn_time_ms: 1767.666\n",
      "    load_throughput: 59034.171\n",
      "    load_time_ms: 33.845\n",
      "    sample_throughput: 85.532\n",
      "    sample_time_ms: 23359.574\n",
      "    update_time_ms: 10.301\n",
      "  timestamp: 1636841895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 223776\n",
      "  training_iteration: 112\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         2924.03</td><td style=\"text-align: right;\">223776</td><td style=\"text-align: right;\"> 18.7853</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">               -0.16</td><td style=\"text-align: right;\">             107.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 225774\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-18-52\n",
      "  done: false\n",
      "  episode_len_mean: 106.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999936\n",
      "  episode_reward_mean: 18.166699999999924\n",
      "  episode_reward_min: -0.16000000000000003\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2164\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5534823394957042\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01479493187675393\n",
      "          policy_loss: -0.039361762148993354\n",
      "          total_loss: 1.0276805518549823\n",
      "          vf_explained_var: 0.9555119276046753\n",
      "          vf_loss: 1.0759194061869666\n",
      "    num_agent_steps_sampled: 225774\n",
      "    num_agent_steps_trained: 225774\n",
      "    num_steps_sampled: 225774\n",
      "    num_steps_trained: 225774\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.10740740740741\n",
      "    ram_util_percent: 31.34814814814815\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0440094487336256\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.841034535725722\n",
      "    mean_inference_ms: 2.433990884127664\n",
      "    mean_raw_obs_processing_ms: 1.8973509008331064\n",
      "  time_since_restore: 2961.7117664813995\n",
      "  time_this_iter_s: 37.68653178215027\n",
      "  time_total_s: 2961.7117664813995\n",
      "  timers:\n",
      "    learn_throughput: 1129.528\n",
      "    learn_time_ms: 1768.88\n",
      "    load_throughput: 58636.064\n",
      "    load_time_ms: 34.075\n",
      "    sample_throughput: 80.312\n",
      "    sample_time_ms: 24878.02\n",
      "    update_time_ms: 11.514\n",
      "  timestamp: 1636841932\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 225774\n",
      "  training_iteration: 113\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         2961.71</td><td style=\"text-align: right;\">225774</td><td style=\"text-align: right;\"> 18.1667</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">               -0.16</td><td style=\"text-align: right;\">            106.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 227772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-19-14\n",
      "  done: false\n",
      "  episode_len_mean: 107.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.749999999999936\n",
      "  episode_reward_mean: 18.053599999999925\n",
      "  episode_reward_min: -0.16000000000000003\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2181\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6349083048956734\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009524544940234525\n",
      "          policy_loss: -0.032600074421082224\n",
      "          total_loss: 0.29666149026403826\n",
      "          vf_explained_var: 0.9875156283378601\n",
      "          vf_loss: 0.3413245990517594\n",
      "    num_agent_steps_sampled: 227772\n",
      "    num_agent_steps_trained: 227772\n",
      "    num_steps_sampled: 227772\n",
      "    num_steps_trained: 227772\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.58666666666664\n",
      "    ram_util_percent: 31.52\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399816706442958\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.815749612850514\n",
      "    mean_inference_ms: 2.4337762772975604\n",
      "    mean_raw_obs_processing_ms: 1.925662266976782\n",
      "  time_since_restore: 2983.02312707901\n",
      "  time_this_iter_s: 21.311360597610474\n",
      "  time_total_s: 2983.02312707901\n",
      "  timers:\n",
      "    learn_throughput: 1130.032\n",
      "    learn_time_ms: 1768.092\n",
      "    load_throughput: 58626.424\n",
      "    load_time_ms: 34.08\n",
      "    sample_throughput: 80.547\n",
      "    sample_time_ms: 24805.51\n",
      "    update_time_ms: 10.267\n",
      "  timestamp: 1636841954\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 227772\n",
      "  training_iteration: 114\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         2983.02</td><td style=\"text-align: right;\">227772</td><td style=\"text-align: right;\"> 18.0536</td><td style=\"text-align: right;\">               20.75</td><td style=\"text-align: right;\">               -0.16</td><td style=\"text-align: right;\">            107.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 229770\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-19-36\n",
      "  done: false\n",
      "  episode_len_mean: 108.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.98999999999995\n",
      "  episode_reward_mean: 18.260699999999925\n",
      "  episode_reward_min: -0.16000000000000003\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2200\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5143906792004904\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009062073921756085\n",
      "          policy_loss: 0.0021644574723073415\n",
      "          total_loss: 0.17499771015275092\n",
      "          vf_explained_var: 0.9925483465194702\n",
      "          vf_loss: 0.183899228452217\n",
      "    num_agent_steps_sampled: 229770\n",
      "    num_agent_steps_trained: 229770\n",
      "    num_steps_sampled: 229770\n",
      "    num_steps_trained: 229770\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.696875\n",
      "    ram_util_percent: 31.646875\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043988924154951724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.789355112314546\n",
      "    mean_inference_ms: 2.433512072659572\n",
      "    mean_raw_obs_processing_ms: 1.9571084965575927\n",
      "  time_since_restore: 3005.3022077083588\n",
      "  time_this_iter_s: 22.279080629348755\n",
      "  time_total_s: 3005.3022077083588\n",
      "  timers:\n",
      "    learn_throughput: 1129.254\n",
      "    learn_time_ms: 1769.309\n",
      "    load_throughput: 58758.911\n",
      "    load_time_ms: 34.003\n",
      "    sample_throughput: 80.112\n",
      "    sample_time_ms: 24940.034\n",
      "    update_time_ms: 9.663\n",
      "  timestamp: 1636841976\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229770\n",
      "  training_iteration: 115\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">          3005.3</td><td style=\"text-align: right;\">229770</td><td style=\"text-align: right;\"> 18.2607</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               -0.16</td><td style=\"text-align: right;\">            108.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 231768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-19-58\n",
      "  done: false\n",
      "  episode_len_mean: 108.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.98999999999995\n",
      "  episode_reward_mean: 18.46749999999992\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2218\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5020466781797863\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012626670340362764\n",
      "          policy_loss: 0.002509334186712901\n",
      "          total_loss: 0.3957965216998543\n",
      "          vf_explained_var: 0.9829823970794678\n",
      "          vf_loss: 0.40262565275742895\n",
      "    num_agent_steps_sampled: 231768\n",
      "    num_agent_steps_trained: 231768\n",
      "    num_steps_sampled: 231768\n",
      "    num_steps_trained: 231768\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89375\n",
      "    ram_util_percent: 31.709375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043983241787734155\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.758171323105124\n",
      "    mean_inference_ms: 2.4335748195190545\n",
      "    mean_raw_obs_processing_ms: 1.9702236300820624\n",
      "  time_since_restore: 3027.3871083259583\n",
      "  time_this_iter_s: 22.084900617599487\n",
      "  time_total_s: 3027.3871083259583\n",
      "  timers:\n",
      "    learn_throughput: 1131.075\n",
      "    learn_time_ms: 1766.461\n",
      "    load_throughput: 58363.52\n",
      "    load_time_ms: 34.234\n",
      "    sample_throughput: 80.358\n",
      "    sample_time_ms: 24863.612\n",
      "    update_time_ms: 11.28\n",
      "  timestamp: 1636841998\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 231768\n",
      "  training_iteration: 116\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         3027.39</td><td style=\"text-align: right;\">231768</td><td style=\"text-align: right;\"> 18.4675</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            108.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 233766\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-20-21\n",
      "  done: false\n",
      "  episode_len_mean: 109.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.98999999999995\n",
      "  episode_reward_mean: 18.50469999999992\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2236\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5083488208906992\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010085599964105926\n",
      "          policy_loss: -0.004934478976896831\n",
      "          total_loss: 0.20735932698562032\n",
      "          vf_explained_var: 0.9915047883987427\n",
      "          vf_loss: 0.22283877309943947\n",
      "    num_agent_steps_sampled: 233766\n",
      "    num_agent_steps_trained: 233766\n",
      "    num_steps_sampled: 233766\n",
      "    num_steps_trained: 233766\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59375\n",
      "    ram_util_percent: 31.706249999999997\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04397557163651461\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.732580888262728\n",
      "    mean_inference_ms: 2.4334166067904444\n",
      "    mean_raw_obs_processing_ms: 1.9856889609749373\n",
      "  time_since_restore: 3049.7862050533295\n",
      "  time_this_iter_s: 22.399096727371216\n",
      "  time_total_s: 3049.7862050533295\n",
      "  timers:\n",
      "    learn_throughput: 1131.747\n",
      "    learn_time_ms: 1765.412\n",
      "    load_throughput: 58403.34\n",
      "    load_time_ms: 34.21\n",
      "    sample_throughput: 80.331\n",
      "    sample_time_ms: 24872.153\n",
      "    update_time_ms: 12.095\n",
      "  timestamp: 1636842021\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 233766\n",
      "  training_iteration: 117\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         3049.79</td><td style=\"text-align: right;\">233766</td><td style=\"text-align: right;\"> 18.5047</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            109.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 235764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-20-44\n",
      "  done: false\n",
      "  episode_len_mean: 109.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.98999999999995\n",
      "  episode_reward_mean: 19.249999999999922\n",
      "  episode_reward_min: 10.150000000000022\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2256\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5384069045384725\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013439117001188095\n",
      "          policy_loss: -0.01774112568015144\n",
      "          total_loss: 0.20153091260719866\n",
      "          vf_explained_var: 0.9917030930519104\n",
      "          vf_loss: 0.2286085070776088\n",
      "    num_agent_steps_sampled: 235764\n",
      "    num_agent_steps_trained: 235764\n",
      "    num_steps_sampled: 235764\n",
      "    num_steps_trained: 235764\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6969696969697\n",
      "    ram_util_percent: 31.745454545454542\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04396802882057841\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.71352204409193\n",
      "    mean_inference_ms: 2.4331280061023572\n",
      "    mean_raw_obs_processing_ms: 1.9775605410601964\n",
      "  time_since_restore: 3072.978886127472\n",
      "  time_this_iter_s: 23.192681074142456\n",
      "  time_total_s: 3072.978886127472\n",
      "  timers:\n",
      "    learn_throughput: 1132.336\n",
      "    learn_time_ms: 1764.494\n",
      "    load_throughput: 58046.056\n",
      "    load_time_ms: 34.421\n",
      "    sample_throughput: 79.825\n",
      "    sample_time_ms: 25029.844\n",
      "    update_time_ms: 12.511\n",
      "  timestamp: 1636842044\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 235764\n",
      "  training_iteration: 118\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         3072.98</td><td style=\"text-align: right;\">235764</td><td style=\"text-align: right;\">   19.25</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               10.15</td><td style=\"text-align: right;\">            109.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 237762\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-21-05\n",
      "  done: false\n",
      "  episode_len_mean: 109.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.98999999999995\n",
      "  episode_reward_mean: 19.43149999999992\n",
      "  episode_reward_min: 10.150000000000022\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2274\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.524208843140375\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010151442130571075\n",
      "          policy_loss: -0.004857290731299491\n",
      "          total_loss: 0.29001633652064596\n",
      "          vf_explained_var: 0.9889280200004578\n",
      "          vf_loss: 0.3055475642638547\n",
      "    num_agent_steps_sampled: 237762\n",
      "    num_agent_steps_trained: 237762\n",
      "    num_steps_sampled: 237762\n",
      "    num_steps_trained: 237762\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.84516129032258\n",
      "    ram_util_percent: 31.812903225806455\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043965067001595644\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.69273166306781\n",
      "    mean_inference_ms: 2.4330308916388863\n",
      "    mean_raw_obs_processing_ms: 1.96633287641496\n",
      "  time_since_restore: 3094.605268716812\n",
      "  time_this_iter_s: 21.62638258934021\n",
      "  time_total_s: 3094.605268716812\n",
      "  timers:\n",
      "    learn_throughput: 1130.84\n",
      "    learn_time_ms: 1766.828\n",
      "    load_throughput: 57562.817\n",
      "    load_time_ms: 34.71\n",
      "    sample_throughput: 80.065\n",
      "    sample_time_ms: 24954.576\n",
      "    update_time_ms: 13.363\n",
      "  timestamp: 1636842065\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 237762\n",
      "  training_iteration: 119\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         3094.61</td><td style=\"text-align: right;\">237762</td><td style=\"text-align: right;\"> 19.4315</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               10.15</td><td style=\"text-align: right;\">            109.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 239760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 108.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.98999999999995\n",
      "  episode_reward_mean: 19.531699999999923\n",
      "  episode_reward_min: 10.150000000000022\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2292\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4931646233513243\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014903703654213722\n",
      "          policy_loss: -0.013004407180207116\n",
      "          total_loss: 0.27586420301702763\n",
      "          vf_explained_var: 0.9906978011131287\n",
      "          vf_loss: 0.2970935911649749\n",
      "    num_agent_steps_sampled: 239760\n",
      "    num_agent_steps_trained: 239760\n",
      "    num_steps_sampled: 239760\n",
      "    num_steps_trained: 239760\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99032258064516\n",
      "    ram_util_percent: 31.85806451612903\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04396069702014991\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.673328684155628\n",
      "    mean_inference_ms: 2.4329326588731783\n",
      "    mean_raw_obs_processing_ms: 1.955370552581369\n",
      "  time_since_restore: 3116.296493768692\n",
      "  time_this_iter_s: 21.691225051879883\n",
      "  time_total_s: 3116.296493768692\n",
      "  timers:\n",
      "    learn_throughput: 1131.148\n",
      "    learn_time_ms: 1766.347\n",
      "    load_throughput: 57705.551\n",
      "    load_time_ms: 34.624\n",
      "    sample_throughput: 80.368\n",
      "    sample_time_ms: 24860.745\n",
      "    update_time_ms: 13.837\n",
      "  timestamp: 1636842087\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239760\n",
      "  training_iteration: 120\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">          3116.3</td><td style=\"text-align: right;\">239760</td><td style=\"text-align: right;\"> 19.5317</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               10.15</td><td style=\"text-align: right;\">            108.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 241758\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-21-49\n",
      "  done: false\n",
      "  episode_len_mean: 108.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.979999999999993\n",
      "  episode_reward_mean: 19.56229999999992\n",
      "  episode_reward_min: 10.150000000000022\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2310\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4994326074918112\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009817733914353505\n",
      "          policy_loss: -0.01700183575352033\n",
      "          total_loss: 0.1425496319308877\n",
      "          vf_explained_var: 0.9944119453430176\n",
      "          vf_loss: 0.17012781112321784\n",
      "    num_agent_steps_sampled: 241758\n",
      "    num_agent_steps_trained: 241758\n",
      "    num_steps_sampled: 241758\n",
      "    num_steps_trained: 241758\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.60322580645163\n",
      "    ram_util_percent: 31.912903225806446\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04395387677231802\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.650160899215024\n",
      "    mean_inference_ms: 2.432921583807038\n",
      "    mean_raw_obs_processing_ms: 1.9442558513551962\n",
      "  time_since_restore: 3137.8997893333435\n",
      "  time_this_iter_s: 21.60329556465149\n",
      "  time_total_s: 3137.8997893333435\n",
      "  timers:\n",
      "    learn_throughput: 1132.756\n",
      "    learn_time_ms: 1763.84\n",
      "    load_throughput: 57721.807\n",
      "    load_time_ms: 34.614\n",
      "    sample_throughput: 85.926\n",
      "    sample_time_ms: 23252.67\n",
      "    update_time_ms: 13.149\n",
      "  timestamp: 1636842109\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 241758\n",
      "  training_iteration: 121\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">          3137.9</td><td style=\"text-align: right;\">241758</td><td style=\"text-align: right;\"> 19.5623</td><td style=\"text-align: right;\">               20.98</td><td style=\"text-align: right;\">               10.15</td><td style=\"text-align: right;\">            108.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 243756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-22-12\n",
      "  done: false\n",
      "  episode_len_mean: 107.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.809999999999935\n",
      "  episode_reward_mean: 19.632399999999922\n",
      "  episode_reward_min: 10.610000000000017\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2330\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3920848261742365\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014479340405241958\n",
      "          policy_loss: -0.02699862601501601\n",
      "          total_loss: 0.17728773423780997\n",
      "          vf_explained_var: 0.9929279685020447\n",
      "          vf_loss: 0.21169150464591527\n",
      "    num_agent_steps_sampled: 243756\n",
      "    num_agent_steps_trained: 243756\n",
      "    num_steps_sampled: 243756\n",
      "    num_steps_trained: 243756\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.13333333333334\n",
      "    ram_util_percent: 31.933333333333334\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043958840746728595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.63404550747578\n",
      "    mean_inference_ms: 2.432624954243341\n",
      "    mean_raw_obs_processing_ms: 1.9326907287576547\n",
      "  time_since_restore: 3160.955115556717\n",
      "  time_this_iter_s: 23.055326223373413\n",
      "  time_total_s: 3160.955115556717\n",
      "  timers:\n",
      "    learn_throughput: 1132.902\n",
      "    learn_time_ms: 1763.613\n",
      "    load_throughput: 57227.863\n",
      "    load_time_ms: 34.913\n",
      "    sample_throughput: 91.347\n",
      "    sample_time_ms: 21872.59\n",
      "    update_time_ms: 12.637\n",
      "  timestamp: 1636842132\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 243756\n",
      "  training_iteration: 122\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         3160.96</td><td style=\"text-align: right;\">243756</td><td style=\"text-align: right;\"> 19.6324</td><td style=\"text-align: right;\">               20.81</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">            107.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 245754\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-22-34\n",
      "  done: false\n",
      "  episode_len_mean: 106.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.799999999999947\n",
      "  episode_reward_mean: 19.790999999999922\n",
      "  episode_reward_min: 10.610000000000017\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2348\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.502209522610619\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008689813120419896\n",
      "          policy_loss: -0.025553224164815175\n",
      "          total_loss: 0.03623930842039131\n",
      "          vf_explained_var: 0.9973798394203186\n",
      "          vf_loss: 0.07290421275510675\n",
      "    num_agent_steps_sampled: 245754\n",
      "    num_agent_steps_trained: 245754\n",
      "    num_steps_sampled: 245754\n",
      "    num_steps_trained: 245754\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.80967741935481\n",
      "    ram_util_percent: 31.93870967741935\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04397049343606724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.612813130331503\n",
      "    mean_inference_ms: 2.432725413308299\n",
      "    mean_raw_obs_processing_ms: 1.9221468670165094\n",
      "  time_since_restore: 3182.9523828029633\n",
      "  time_this_iter_s: 21.997267246246338\n",
      "  time_total_s: 3182.9523828029633\n",
      "  timers:\n",
      "    learn_throughput: 1129.463\n",
      "    learn_time_ms: 1768.983\n",
      "    load_throughput: 58174.718\n",
      "    load_time_ms: 34.345\n",
      "    sample_throughput: 98.422\n",
      "    sample_time_ms: 20300.378\n",
      "    update_time_ms: 11.264\n",
      "  timestamp: 1636842154\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 245754\n",
      "  training_iteration: 123\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         3182.95</td><td style=\"text-align: right;\">245754</td><td style=\"text-align: right;\">  19.791</td><td style=\"text-align: right;\">                20.8</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">            106.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 247752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-22-57\n",
      "  done: false\n",
      "  episode_len_mean: 105.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.799999999999947\n",
      "  episode_reward_mean: 20.042499999999926\n",
      "  episode_reward_min: 12.21000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2369\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4411815121060325\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010718750226878973\n",
      "          policy_loss: 0.006464650730292002\n",
      "          total_loss: 0.22534533532425052\n",
      "          vf_explained_var: 0.992734432220459\n",
      "          vf_loss: 0.2284690615144514\n",
      "    num_agent_steps_sampled: 247752\n",
      "    num_agent_steps_trained: 247752\n",
      "    num_steps_sampled: 247752\n",
      "    num_steps_trained: 247752\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.82121212121211\n",
      "    ram_util_percent: 31.96060606060606\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04398766634455585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.59419351295024\n",
      "    mean_inference_ms: 2.432603492342565\n",
      "    mean_raw_obs_processing_ms: 1.9103710373849325\n",
      "  time_since_restore: 3206.2191200256348\n",
      "  time_this_iter_s: 23.26673722267151\n",
      "  time_total_s: 3206.2191200256348\n",
      "  timers:\n",
      "    learn_throughput: 1126.586\n",
      "    learn_time_ms: 1773.499\n",
      "    load_throughput: 58238.312\n",
      "    load_time_ms: 34.307\n",
      "    sample_throughput: 97.523\n",
      "    sample_time_ms: 20487.528\n",
      "    update_time_ms: 13.689\n",
      "  timestamp: 1636842177\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 247752\n",
      "  training_iteration: 124\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         3206.22</td><td style=\"text-align: right;\">247752</td><td style=\"text-align: right;\"> 20.0425</td><td style=\"text-align: right;\">                20.8</td><td style=\"text-align: right;\">               12.21</td><td style=\"text-align: right;\">             105.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 249750\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-23-20\n",
      "  done: false\n",
      "  episode_len_mean: 104.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999993\n",
      "  episode_reward_mean: 19.949599999999922\n",
      "  episode_reward_min: 12.21000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2388\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4270416327885218\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017678336058853335\n",
      "          policy_loss: -0.004761469257729394\n",
      "          total_loss: 0.40543773239921954\n",
      "          vf_explained_var: 0.9851447939872742\n",
      "          vf_loss: 0.41651436409779957\n",
      "    num_agent_steps_sampled: 249750\n",
      "    num_agent_steps_trained: 249750\n",
      "    num_steps_sampled: 249750\n",
      "    num_steps_trained: 249750\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.4818181818182\n",
      "    ram_util_percent: 31.933333333333337\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400150069330364\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.58231613710195\n",
      "    mean_inference_ms: 2.4325225019417385\n",
      "    mean_raw_obs_processing_ms: 1.900206496992428\n",
      "  time_since_restore: 3229.314322948456\n",
      "  time_this_iter_s: 23.095202922821045\n",
      "  time_total_s: 3229.314322948456\n",
      "  timers:\n",
      "    learn_throughput: 1126.989\n",
      "    learn_time_ms: 1772.865\n",
      "    load_throughput: 57811.641\n",
      "    load_time_ms: 34.561\n",
      "    sample_throughput: 97.144\n",
      "    sample_time_ms: 20567.368\n",
      "    update_time_ms: 15.432\n",
      "  timestamp: 1636842200\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249750\n",
      "  training_iteration: 125\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         3229.31</td><td style=\"text-align: right;\">249750</td><td style=\"text-align: right;\"> 19.9496</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">               12.21</td><td style=\"text-align: right;\">            104.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 251748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-23-43\n",
      "  done: false\n",
      "  episode_len_mean: 103.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999993\n",
      "  episode_reward_mean: 19.88269999999993\n",
      "  episode_reward_min: 13.100000000000012\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2407\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4407541030929203\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01090299134072459\n",
      "          policy_loss: 0.0050749129482678\n",
      "          total_loss: 0.21391154231414908\n",
      "          vf_explained_var: 0.9918326139450073\n",
      "          vf_loss: 0.21833782313125474\n",
      "    num_agent_steps_sampled: 251748\n",
      "    num_agent_steps_trained: 251748\n",
      "    num_steps_sampled: 251748\n",
      "    num_steps_trained: 251748\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.740625\n",
      "    ram_util_percent: 31.915625\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04401574462860267\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.57115842064306\n",
      "    mean_inference_ms: 2.432556556715358\n",
      "    mean_raw_obs_processing_ms: 1.890282769559481\n",
      "  time_since_restore: 3251.6940631866455\n",
      "  time_this_iter_s: 22.379740238189697\n",
      "  time_total_s: 3251.6940631866455\n",
      "  timers:\n",
      "    learn_throughput: 1125.797\n",
      "    learn_time_ms: 1774.742\n",
      "    load_throughput: 57398.016\n",
      "    load_time_ms: 34.81\n",
      "    sample_throughput: 97.013\n",
      "    sample_time_ms: 20595.162\n",
      "    update_time_ms: 14.659\n",
      "  timestamp: 1636842223\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 251748\n",
      "  training_iteration: 126\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         3251.69</td><td style=\"text-align: right;\">251748</td><td style=\"text-align: right;\"> 19.8827</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">                13.1</td><td style=\"text-align: right;\">            103.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 253746\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-24-07\n",
      "  done: false\n",
      "  episode_len_mean: 104.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999993\n",
      "  episode_reward_mean: 19.92159999999993\n",
      "  episode_reward_min: 13.100000000000012\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2426\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4794186137971423\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011634560688950035\n",
      "          policy_loss: -0.007013310953265145\n",
      "          total_loss: 0.254790579305873\n",
      "          vf_explained_var: 0.9901389479637146\n",
      "          vf_loss: 0.2713625287725812\n",
      "    num_agent_steps_sampled: 253746\n",
      "    num_agent_steps_trained: 253746\n",
      "    num_steps_sampled: 253746\n",
      "    num_steps_trained: 253746\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69117647058823\n",
      "    ram_util_percent: 31.914705882352944\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04401923927358659\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.561552599116666\n",
      "    mean_inference_ms: 2.4327645180734394\n",
      "    mean_raw_obs_processing_ms: 1.8806002045427435\n",
      "  time_since_restore: 3275.5486924648285\n",
      "  time_this_iter_s: 23.854629278182983\n",
      "  time_total_s: 3275.5486924648285\n",
      "  timers:\n",
      "    learn_throughput: 1126.403\n",
      "    learn_time_ms: 1773.787\n",
      "    load_throughput: 57757.254\n",
      "    load_time_ms: 34.593\n",
      "    sample_throughput: 96.326\n",
      "    sample_time_ms: 20742.091\n",
      "    update_time_ms: 14.582\n",
      "  timestamp: 1636842247\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 253746\n",
      "  training_iteration: 127\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         3275.55</td><td style=\"text-align: right;\">253746</td><td style=\"text-align: right;\"> 19.9216</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">                13.1</td><td style=\"text-align: right;\">            104.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 255744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-24-30\n",
      "  done: false\n",
      "  episode_len_mean: 103.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999993\n",
      "  episode_reward_mean: 19.907999999999927\n",
      "  episode_reward_min: 13.100000000000012\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2446\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.443952248777662\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0070316469196924575\n",
      "          policy_loss: -0.04285572540192377\n",
      "          total_loss: 0.06569482772832826\n",
      "          vf_explained_var: 0.995838463306427\n",
      "          vf_loss: 0.11982583740637416\n",
      "    num_agent_steps_sampled: 255744\n",
      "    num_agent_steps_trained: 255744\n",
      "    num_steps_sampled: 255744\n",
      "    num_steps_trained: 255744\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.40588235294118\n",
      "    ram_util_percent: 31.93823529411765\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04401880640225525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.555806538769783\n",
      "    mean_inference_ms: 2.4327126942309096\n",
      "    mean_raw_obs_processing_ms: 1.8707723958815063\n",
      "  time_since_restore: 3299.1906287670135\n",
      "  time_this_iter_s: 23.64193630218506\n",
      "  time_total_s: 3299.1906287670135\n",
      "  timers:\n",
      "    learn_throughput: 1126.048\n",
      "    learn_time_ms: 1774.346\n",
      "    load_throughput: 58421.825\n",
      "    load_time_ms: 34.2\n",
      "    sample_throughput: 96.12\n",
      "    sample_time_ms: 20786.601\n",
      "    update_time_ms: 14.837\n",
      "  timestamp: 1636842270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 255744\n",
      "  training_iteration: 128\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         3299.19</td><td style=\"text-align: right;\">255744</td><td style=\"text-align: right;\">  19.908</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">                13.1</td><td style=\"text-align: right;\">             103.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 257742\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-24-53\n",
      "  done: false\n",
      "  episode_len_mean: 104.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.929999999999993\n",
      "  episode_reward_mean: 19.970599999999926\n",
      "  episode_reward_min: 13.100000000000012\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2463\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4773752695038205\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00893591520736963\n",
      "          policy_loss: -0.03763970902100915\n",
      "          total_loss: 0.029747545976369152\n",
      "          vf_explained_var: 0.9974457025527954\n",
      "          vf_loss: 0.07813984577854474\n",
      "    num_agent_steps_sampled: 257742\n",
      "    num_agent_steps_trained: 257742\n",
      "    num_steps_sampled: 257742\n",
      "    num_steps_trained: 257742\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92812500000001\n",
      "    ram_util_percent: 31.94375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044008413691335416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.54955721809107\n",
      "    mean_inference_ms: 2.4329339592383272\n",
      "    mean_raw_obs_processing_ms: 1.862340878721778\n",
      "  time_since_restore: 3321.5153226852417\n",
      "  time_this_iter_s: 22.32469391822815\n",
      "  time_total_s: 3321.5153226852417\n",
      "  timers:\n",
      "    learn_throughput: 1123.665\n",
      "    learn_time_ms: 1778.11\n",
      "    load_throughput: 58459.645\n",
      "    load_time_ms: 34.177\n",
      "    sample_throughput: 95.814\n",
      "    sample_time_ms: 20852.943\n",
      "    update_time_ms: 14.215\n",
      "  timestamp: 1636842293\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 257742\n",
      "  training_iteration: 129\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         3321.52</td><td style=\"text-align: right;\">257742</td><td style=\"text-align: right;\"> 19.9706</td><td style=\"text-align: right;\">               20.93</td><td style=\"text-align: right;\">                13.1</td><td style=\"text-align: right;\">            104.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 259740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-25-31\n",
      "  done: false\n",
      "  episode_len_mean: 104.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.86999999999993\n",
      "  episode_reward_mean: 19.882399999999926\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2483\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.47362033923467\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007859472641667111\n",
      "          policy_loss: 7.50169867560977e-05\n",
      "          total_loss: 0.5247792783636778\n",
      "          vf_explained_var: 0.9818253517150879\n",
      "          vf_loss: 0.5359037049824283\n",
      "    num_agent_steps_sampled: 259740\n",
      "    num_agent_steps_trained: 259740\n",
      "    num_steps_sampled: 259740\n",
      "    num_steps_trained: 259740\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.03148148148148\n",
      "    ram_util_percent: 31.85185185185185\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400280743664885\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.53984105283881\n",
      "    mean_inference_ms: 2.432805863662714\n",
      "    mean_raw_obs_processing_ms: 1.8675958714811447\n",
      "  time_since_restore: 3359.457156896591\n",
      "  time_this_iter_s: 37.94183421134949\n",
      "  time_total_s: 3359.457156896591\n",
      "  timers:\n",
      "    learn_throughput: 1115.141\n",
      "    learn_time_ms: 1791.702\n",
      "    load_throughput: 58660.321\n",
      "    load_time_ms: 34.061\n",
      "    sample_throughput: 88.941\n",
      "    sample_time_ms: 22464.445\n",
      "    update_time_ms: 14.509\n",
      "  timestamp: 1636842331\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259740\n",
      "  training_iteration: 130\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         3359.46</td><td style=\"text-align: right;\">259740</td><td style=\"text-align: right;\"> 19.8824</td><td style=\"text-align: right;\">               20.87</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">            104.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 261738\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-26-11\n",
      "  done: false\n",
      "  episode_len_mean: 103.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.959999999999937\n",
      "  episode_reward_mean: 19.833299999999923\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2504\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.395833402588254\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008643012064885842\n",
      "          policy_loss: 0.003463817210424514\n",
      "          total_loss: 0.7729129164790114\n",
      "          vf_explained_var: 0.9744617342948914\n",
      "          vf_loss: 0.7795181223767854\n",
      "    num_agent_steps_sampled: 261738\n",
      "    num_agent_steps_trained: 261738\n",
      "    num_steps_sampled: 261738\n",
      "    num_steps_trained: 261738\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.28245614035087\n",
      "    ram_util_percent: 31.668421052631576\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044004657361375765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.53104108315119\n",
      "    mean_inference_ms: 2.432891620407946\n",
      "    mean_raw_obs_processing_ms: 1.883559907671269\n",
      "  time_since_restore: 3399.507611989975\n",
      "  time_this_iter_s: 40.05045509338379\n",
      "  time_total_s: 3399.507611989975\n",
      "  timers:\n",
      "    learn_throughput: 1113.458\n",
      "    learn_time_ms: 1794.41\n",
      "    load_throughput: 57505.858\n",
      "    load_time_ms: 34.744\n",
      "    sample_throughput: 82.206\n",
      "    sample_time_ms: 24304.709\n",
      "    update_time_ms: 15.397\n",
      "  timestamp: 1636842371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 261738\n",
      "  training_iteration: 131\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         3399.51</td><td style=\"text-align: right;\">261738</td><td style=\"text-align: right;\"> 19.8333</td><td style=\"text-align: right;\">               20.96</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">            103.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 263736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-26-51\n",
      "  done: false\n",
      "  episode_len_mean: 102.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.959999999999937\n",
      "  episode_reward_mean: 19.680899999999923\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2524\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4830123560769217\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00846247285470421\n",
      "          policy_loss: 0.003449346391218049\n",
      "          total_loss: 0.8458544768725655\n",
      "          vf_explained_var: 0.9703235626220703\n",
      "          vf_loss: 0.8534271473153716\n",
      "    num_agent_steps_sampled: 263736\n",
      "    num_agent_steps_trained: 263736\n",
      "    num_steps_sampled: 263736\n",
      "    num_steps_trained: 263736\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.39827586206896\n",
      "    ram_util_percent: 31.412068965517243\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400220542695493\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.527295194905626\n",
      "    mean_inference_ms: 2.432802479848307\n",
      "    mean_raw_obs_processing_ms: 1.9113653838568831\n",
      "  time_since_restore: 3439.6503591537476\n",
      "  time_this_iter_s: 40.14274716377258\n",
      "  time_total_s: 3439.6503591537476\n",
      "  timers:\n",
      "    learn_throughput: 1112.285\n",
      "    learn_time_ms: 1796.302\n",
      "    load_throughput: 58584.006\n",
      "    load_time_ms: 34.105\n",
      "    sample_throughput: 76.814\n",
      "    sample_time_ms: 26010.717\n",
      "    update_time_ms: 16.748\n",
      "  timestamp: 1636842411\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 263736\n",
      "  training_iteration: 132\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         3439.65</td><td style=\"text-align: right;\">263736</td><td style=\"text-align: right;\"> 19.6809</td><td style=\"text-align: right;\">               20.96</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            102.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 265734\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-27-14\n",
      "  done: false\n",
      "  episode_len_mean: 102.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.959999999999937\n",
      "  episode_reward_mean: 19.61679999999992\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2542\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4718613721075513\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007181482541403291\n",
      "          policy_loss: -0.06267304789452326\n",
      "          total_loss: 0.039278995068300335\n",
      "          vf_explained_var: 0.9967717528343201\n",
      "          vf_loss: 0.1134389881222021\n",
      "    num_agent_steps_sampled: 265734\n",
      "    num_agent_steps_trained: 265734\n",
      "    num_steps_sampled: 265734\n",
      "    num_steps_trained: 265734\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69999999999999\n",
      "    ram_util_percent: 31.512121212121215\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044000915436344386\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.522182350489018\n",
      "    mean_inference_ms: 2.432957564301623\n",
      "    mean_raw_obs_processing_ms: 1.9360298609679267\n",
      "  time_since_restore: 3462.938835144043\n",
      "  time_this_iter_s: 23.28847599029541\n",
      "  time_total_s: 3462.938835144043\n",
      "  timers:\n",
      "    learn_throughput: 1113.639\n",
      "    learn_time_ms: 1794.118\n",
      "    load_throughput: 57218.525\n",
      "    load_time_ms: 34.919\n",
      "    sample_throughput: 76.434\n",
      "    sample_time_ms: 26140.211\n",
      "    update_time_ms: 17.817\n",
      "  timestamp: 1636842434\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 265734\n",
      "  training_iteration: 133\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         3462.94</td><td style=\"text-align: right;\">265734</td><td style=\"text-align: right;\"> 19.6168</td><td style=\"text-align: right;\">               20.96</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            102.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 267732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-27-37\n",
      "  done: false\n",
      "  episode_len_mean: 102.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.959999999999937\n",
      "  episode_reward_mean: 19.564499999999924\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2562\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4297635084106808\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010319891628256833\n",
      "          policy_loss: -0.047169186600617\n",
      "          total_loss: 0.07249586558235543\n",
      "          vf_explained_var: 0.9957345128059387\n",
      "          vf_loss: 0.1293187372209061\n",
      "    num_agent_steps_sampled: 267732\n",
      "    num_agent_steps_trained: 267732\n",
      "    num_steps_sampled: 267732\n",
      "    num_steps_trained: 267732\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.39375000000001\n",
      "    ram_util_percent: 31.69375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400767405795591\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.51654991324134\n",
      "    mean_inference_ms: 2.4329532548330195\n",
      "    mean_raw_obs_processing_ms: 1.9634120008163607\n",
      "  time_since_restore: 3485.3149993419647\n",
      "  time_this_iter_s: 22.376164197921753\n",
      "  time_total_s: 3485.3149993419647\n",
      "  timers:\n",
      "    learn_throughput: 1115.359\n",
      "    learn_time_ms: 1791.351\n",
      "    load_throughput: 56480.871\n",
      "    load_time_ms: 35.375\n",
      "    sample_throughput: 76.681\n",
      "    sample_time_ms: 26055.834\n",
      "    update_time_ms: 17.01\n",
      "  timestamp: 1636842457\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 267732\n",
      "  training_iteration: 134\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         3485.31</td><td style=\"text-align: right;\">267732</td><td style=\"text-align: right;\"> 19.5645</td><td style=\"text-align: right;\">               20.96</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            102.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 269730\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-27-59\n",
      "  done: false\n",
      "  episode_len_mean: 103.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.959999999999937\n",
      "  episode_reward_mean: 19.69879999999992\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2580\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4687679767608643\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011881254250337713\n",
      "          policy_loss: -0.006997346871399454\n",
      "          total_loss: 0.1187701811393102\n",
      "          vf_explained_var: 0.9954066872596741\n",
      "          vf_loss: 0.13510864602313155\n",
      "    num_agent_steps_sampled: 269730\n",
      "    num_agent_steps_trained: 269730\n",
      "    num_steps_sampled: 269730\n",
      "    num_steps_trained: 269730\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00625\n",
      "    ram_util_percent: 31.80625\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044007319837805134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.512182888252074\n",
      "    mean_inference_ms: 2.433226992317011\n",
      "    mean_raw_obs_processing_ms: 1.9727670640873674\n",
      "  time_since_restore: 3507.816740989685\n",
      "  time_this_iter_s: 22.501741647720337\n",
      "  time_total_s: 3507.816740989685\n",
      "  timers:\n",
      "    learn_throughput: 1113.75\n",
      "    learn_time_ms: 1793.939\n",
      "    load_throughput: 57120.632\n",
      "    load_time_ms: 34.979\n",
      "    sample_throughput: 76.861\n",
      "    sample_time_ms: 25994.821\n",
      "    update_time_ms: 16.82\n",
      "  timestamp: 1636842479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269730\n",
      "  training_iteration: 135\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         3507.82</td><td style=\"text-align: right;\">269730</td><td style=\"text-align: right;\"> 19.6988</td><td style=\"text-align: right;\">               20.96</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            103.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 271728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-28-21\n",
      "  done: false\n",
      "  episode_len_mean: 105.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.969999999999924\n",
      "  episode_reward_mean: 19.736499999999914\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2598\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.458115824063619\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009429831215961807\n",
      "          policy_loss: -0.00421953478029796\n",
      "          total_loss: 0.12218629313366754\n",
      "          vf_explained_var: 0.9956430792808533\n",
      "          vf_loss: 0.13674356234925134\n",
      "    num_agent_steps_sampled: 271728\n",
      "    num_agent_steps_trained: 271728\n",
      "    num_steps_sampled: 271728\n",
      "    num_steps_trained: 271728\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.55625\n",
      "    ram_util_percent: 31.903125000000003\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044001979192881964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.506758259384434\n",
      "    mean_inference_ms: 2.43312296858237\n",
      "    mean_raw_obs_processing_ms: 1.9821843494809213\n",
      "  time_since_restore: 3529.7798249721527\n",
      "  time_this_iter_s: 21.96308398246765\n",
      "  time_total_s: 3529.7798249721527\n",
      "  timers:\n",
      "    learn_throughput: 1114.654\n",
      "    learn_time_ms: 1792.485\n",
      "    load_throughput: 57918.682\n",
      "    load_time_ms: 34.497\n",
      "    sample_throughput: 76.979\n",
      "    sample_time_ms: 25955.161\n",
      "    update_time_ms: 16.856\n",
      "  timestamp: 1636842501\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 271728\n",
      "  training_iteration: 136\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         3529.78</td><td style=\"text-align: right;\">271728</td><td style=\"text-align: right;\"> 19.7365</td><td style=\"text-align: right;\">               20.97</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            105.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 273726\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-28-43\n",
      "  done: false\n",
      "  episode_len_mean: 108.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.969999999999924\n",
      "  episode_reward_mean: 20.043199999999914\n",
      "  episode_reward_min: 16.219999999999914\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2616\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.428591177577064\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007642887988449502\n",
      "          policy_loss: -0.0244752447165194\n",
      "          total_loss: 0.0652734353162703\n",
      "          vf_explained_var: 0.9968636631965637\n",
      "          vf_loss: 0.10059529095888138\n",
      "    num_agent_steps_sampled: 273726\n",
      "    num_agent_steps_trained: 273726\n",
      "    num_steps_sampled: 273726\n",
      "    num_steps_trained: 273726\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.15806451612902\n",
      "    ram_util_percent: 31.932258064516123\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400226991776323\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.493833286508437\n",
      "    mean_inference_ms: 2.4332331033734516\n",
      "    mean_raw_obs_processing_ms: 1.9724822554924755\n",
      "  time_since_restore: 3551.6753237247467\n",
      "  time_this_iter_s: 21.895498752593994\n",
      "  time_total_s: 3551.6753237247467\n",
      "  timers:\n",
      "    learn_throughput: 1115.381\n",
      "    learn_time_ms: 1791.316\n",
      "    load_throughput: 57981.677\n",
      "    load_time_ms: 34.459\n",
      "    sample_throughput: 77.56\n",
      "    sample_time_ms: 25760.606\n",
      "    update_time_ms: 16.616\n",
      "  timestamp: 1636842523\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 273726\n",
      "  training_iteration: 137\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         3551.68</td><td style=\"text-align: right;\">273726</td><td style=\"text-align: right;\"> 20.0432</td><td style=\"text-align: right;\">               20.97</td><td style=\"text-align: right;\">               16.22</td><td style=\"text-align: right;\">            108.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 275724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-29-06\n",
      "  done: false\n",
      "  episode_len_mean: 107.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.969999999999924\n",
      "  episode_reward_mean: 19.95609999999991\n",
      "  episode_reward_min: 13.190000000000012\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2634\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4174760177021934\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.019509521419876497\n",
      "          policy_loss: -0.020533596440440133\n",
      "          total_loss: 0.2670450445796762\n",
      "          vf_explained_var: 0.9903086423873901\n",
      "          vf_loss: 0.2929741162984144\n",
      "    num_agent_steps_sampled: 275724\n",
      "    num_agent_steps_trained: 275724\n",
      "    num_steps_sampled: 275724\n",
      "    num_steps_trained: 275724\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.334375\n",
      "    ram_util_percent: 32.046875\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043997901012416206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.48101455396544\n",
      "    mean_inference_ms: 2.4331691506658824\n",
      "    mean_raw_obs_processing_ms: 1.962844718948887\n",
      "  time_since_restore: 3574.420177221298\n",
      "  time_this_iter_s: 22.744853496551514\n",
      "  time_total_s: 3574.420177221298\n",
      "  timers:\n",
      "    learn_throughput: 1105.846\n",
      "    learn_time_ms: 1806.762\n",
      "    load_throughput: 55695.621\n",
      "    load_time_ms: 35.874\n",
      "    sample_throughput: 77.878\n",
      "    sample_time_ms: 25655.544\n",
      "    update_time_ms: 15.218\n",
      "  timestamp: 1636842546\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 275724\n",
      "  training_iteration: 138\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         3574.42</td><td style=\"text-align: right;\">275724</td><td style=\"text-align: right;\"> 19.9561</td><td style=\"text-align: right;\">               20.97</td><td style=\"text-align: right;\">               13.19</td><td style=\"text-align: right;\">            107.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 277722\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 108.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.969999999999924\n",
      "  episode_reward_mean: 19.944599999999912\n",
      "  episode_reward_min: 13.190000000000012\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2653\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4204297394979568\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009581412769662167\n",
      "          policy_loss: -0.009748480823777972\n",
      "          total_loss: 0.13266465592065027\n",
      "          vf_explained_var: 0.9954839944839478\n",
      "          vf_loss: 0.15230579778906844\n",
      "    num_agent_steps_sampled: 277722\n",
      "    num_agent_steps_trained: 277722\n",
      "    num_steps_sampled: 277722\n",
      "    num_steps_trained: 277722\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.50303030303031\n",
      "    ram_util_percent: 32.13636363636363\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043987826782976\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.469505428157184\n",
      "    mean_inference_ms: 2.432921752245847\n",
      "    mean_raw_obs_processing_ms: 1.953033401446632\n",
      "  time_since_restore: 3597.3484225273132\n",
      "  time_this_iter_s: 22.928245306015015\n",
      "  time_total_s: 3597.3484225273132\n",
      "  timers:\n",
      "    learn_throughput: 1108.022\n",
      "    learn_time_ms: 1803.213\n",
      "    load_throughput: 56088.445\n",
      "    load_time_ms: 35.622\n",
      "    sample_throughput: 77.681\n",
      "    sample_time_ms: 25720.433\n",
      "    update_time_ms: 14.794\n",
      "  timestamp: 1636842569\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 277722\n",
      "  training_iteration: 139\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         3597.35</td><td style=\"text-align: right;\">277722</td><td style=\"text-align: right;\"> 19.9446</td><td style=\"text-align: right;\">               20.97</td><td style=\"text-align: right;\">               13.19</td><td style=\"text-align: right;\">            108.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 279720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-29-51\n",
      "  done: false\n",
      "  episode_len_mean: 108.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.969999999999924\n",
      "  episode_reward_mean: 19.88799999999991\n",
      "  episode_reward_min: 13.060000000000013\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2672\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4451126439230784\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01717443682989909\n",
      "          policy_loss: -0.0037448676480423835\n",
      "          total_loss: 0.18443434120466312\n",
      "          vf_explained_var: 0.9935789704322815\n",
      "          vf_loss: 0.19490184140879482\n",
      "    num_agent_steps_sampled: 279720\n",
      "    num_agent_steps_trained: 279720\n",
      "    num_steps_sampled: 279720\n",
      "    num_steps_trained: 279720\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.375\n",
      "    ram_util_percent: 32.128125\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04397967624178259\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.4537964458009\n",
      "    mean_inference_ms: 2.4328219850558934\n",
      "    mean_raw_obs_processing_ms: 1.9431357208015914\n",
      "  time_since_restore: 3619.604898929596\n",
      "  time_this_iter_s: 22.256476402282715\n",
      "  time_total_s: 3619.604898929596\n",
      "  timers:\n",
      "    learn_throughput: 1116.34\n",
      "    learn_time_ms: 1789.777\n",
      "    load_throughput: 55740.854\n",
      "    load_time_ms: 35.844\n",
      "    sample_throughput: 82.682\n",
      "    sample_time_ms: 24164.829\n",
      "    update_time_ms: 14.522\n",
      "  timestamp: 1636842591\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279720\n",
      "  training_iteration: 140\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">          3619.6</td><td style=\"text-align: right;\">279720</td><td style=\"text-align: right;\">  19.888</td><td style=\"text-align: right;\">               20.97</td><td style=\"text-align: right;\">               13.06</td><td style=\"text-align: right;\">            108.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 281718\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-30-14\n",
      "  done: false\n",
      "  episode_len_mean: 107.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.969999999999924\n",
      "  episode_reward_mean: 19.888299999999916\n",
      "  episode_reward_min: 13.060000000000013\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2690\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5144958070346288\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007229146325086325\n",
      "          policy_loss: -0.05451298760516303\n",
      "          total_loss: 0.10073054425773166\n",
      "          vf_explained_var: 0.9947423934936523\n",
      "          vf_loss: 0.1671353700437716\n",
      "    num_agent_steps_sampled: 281718\n",
      "    num_agent_steps_trained: 281718\n",
      "    num_steps_sampled: 281718\n",
      "    num_steps_trained: 281718\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.875\n",
      "    ram_util_percent: 32.128125\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043980617358441935\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.439642518466577\n",
      "    mean_inference_ms: 2.4327439789298766\n",
      "    mean_raw_obs_processing_ms: 1.9339099502567851\n",
      "  time_since_restore: 3641.9929962158203\n",
      "  time_this_iter_s: 22.388097286224365\n",
      "  time_total_s: 3641.9929962158203\n",
      "  timers:\n",
      "    learn_throughput: 1116.576\n",
      "    learn_time_ms: 1789.399\n",
      "    load_throughput: 56943.643\n",
      "    load_time_ms: 35.087\n",
      "    sample_throughput: 89.195\n",
      "    sample_time_ms: 22400.314\n",
      "    update_time_ms: 13.82\n",
      "  timestamp: 1636842614\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 281718\n",
      "  training_iteration: 141\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         3641.99</td><td style=\"text-align: right;\">281718</td><td style=\"text-align: right;\"> 19.8883</td><td style=\"text-align: right;\">               20.97</td><td style=\"text-align: right;\">               13.06</td><td style=\"text-align: right;\">            107.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 283716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-30-37\n",
      "  done: false\n",
      "  episode_len_mean: 106.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.91999999999992\n",
      "  episode_reward_mean: 19.742199999999915\n",
      "  episode_reward_min: 10.75000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2710\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3560237072762988\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015595962247373973\n",
      "          policy_loss: -0.00591961858528001\n",
      "          total_loss: 0.4426724749129443\n",
      "          vf_explained_var: 0.9834702014923096\n",
      "          vf_loss: 0.4551341507229067\n",
      "    num_agent_steps_sampled: 283716\n",
      "    num_agent_steps_trained: 283716\n",
      "    num_steps_sampled: 283716\n",
      "    num_steps_trained: 283716\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.46363636363637\n",
      "    ram_util_percent: 32.10909090909091\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043981151749393994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.429111858222704\n",
      "    mean_inference_ms: 2.4325153705931073\n",
      "    mean_raw_obs_processing_ms: 1.9241190107752195\n",
      "  time_since_restore: 3664.914292573929\n",
      "  time_this_iter_s: 22.92129635810852\n",
      "  time_total_s: 3664.914292573929\n",
      "  timers:\n",
      "    learn_throughput: 1116.926\n",
      "    learn_time_ms: 1788.839\n",
      "    load_throughput: 56403.815\n",
      "    load_time_ms: 35.423\n",
      "    sample_throughput: 96.619\n",
      "    sample_time_ms: 20679.227\n",
      "    update_time_ms: 13.34\n",
      "  timestamp: 1636842637\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 283716\n",
      "  training_iteration: 142\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         3664.91</td><td style=\"text-align: right;\">283716</td><td style=\"text-align: right;\"> 19.7422</td><td style=\"text-align: right;\">               20.92</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">            106.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 285714\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-31-00\n",
      "  done: false\n",
      "  episode_len_mean: 105.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.93999999999992\n",
      "  episode_reward_mean: 19.801499999999916\n",
      "  episode_reward_min: 10.75000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2729\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4233103718076434\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009407501801457883\n",
      "          policy_loss: 0.005880022510176613\n",
      "          total_loss: 0.18458108408820062\n",
      "          vf_explained_var: 0.9934036731719971\n",
      "          vf_loss: 0.18870078875195412\n",
      "    num_agent_steps_sampled: 285714\n",
      "    num_agent_steps_trained: 285714\n",
      "    num_steps_sampled: 285714\n",
      "    num_steps_trained: 285714\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94242424242425\n",
      "    ram_util_percent: 32.118181818181824\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043988687330032424\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.41961590828064\n",
      "    mean_inference_ms: 2.4324421787020625\n",
      "    mean_raw_obs_processing_ms: 1.915037245213278\n",
      "  time_since_restore: 3688.5659108161926\n",
      "  time_this_iter_s: 23.651618242263794\n",
      "  time_total_s: 3688.5659108161926\n",
      "  timers:\n",
      "    learn_throughput: 1119.338\n",
      "    learn_time_ms: 1784.983\n",
      "    load_throughput: 56745.798\n",
      "    load_time_ms: 35.21\n",
      "    sample_throughput: 96.437\n",
      "    sample_time_ms: 20718.291\n",
      "    update_time_ms: 14.23\n",
      "  timestamp: 1636842660\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 285714\n",
      "  training_iteration: 143\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         3688.57</td><td style=\"text-align: right;\">285714</td><td style=\"text-align: right;\"> 19.8015</td><td style=\"text-align: right;\">               20.94</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">            105.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 287712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-31-23\n",
      "  done: false\n",
      "  episode_len_mean: 105.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.93999999999992\n",
      "  episode_reward_mean: 19.92969999999992\n",
      "  episode_reward_min: 10.75000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2749\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4499386900947207\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009329008765877847\n",
      "          policy_loss: -0.014236152580096608\n",
      "          total_loss: 0.12212334958215555\n",
      "          vf_explained_var: 0.9952176213264465\n",
      "          vf_loss: 0.14666083456859702\n",
      "    num_agent_steps_sampled: 287712\n",
      "    num_agent_steps_trained: 287712\n",
      "    num_steps_sampled: 287712\n",
      "    num_steps_trained: 287712\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.646875\n",
      "    ram_util_percent: 32.11875\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400102017468422\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.408357556091303\n",
      "    mean_inference_ms: 2.4324755218128384\n",
      "    mean_raw_obs_processing_ms: 1.9057881179020497\n",
      "  time_since_restore: 3711.0642578601837\n",
      "  time_this_iter_s: 22.49834704399109\n",
      "  time_total_s: 3711.0642578601837\n",
      "  timers:\n",
      "    learn_throughput: 1119.823\n",
      "    learn_time_ms: 1784.21\n",
      "    load_throughput: 56995.5\n",
      "    load_time_ms: 35.055\n",
      "    sample_throughput: 96.369\n",
      "    sample_time_ms: 20732.758\n",
      "    update_time_ms: 12.756\n",
      "  timestamp: 1636842683\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 287712\n",
      "  training_iteration: 144\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         3711.06</td><td style=\"text-align: right;\">287712</td><td style=\"text-align: right;\"> 19.9297</td><td style=\"text-align: right;\">               20.94</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">            105.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 289710\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-31-46\n",
      "  done: false\n",
      "  episode_len_mean: 104.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.93999999999992\n",
      "  episode_reward_mean: 20.01589999999992\n",
      "  episode_reward_min: 10.75000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2768\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.442285514445532\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008135640927465552\n",
      "          policy_loss: -0.0516893308609724\n",
      "          total_loss: 0.10572472480790955\n",
      "          vf_explained_var: 0.9942545294761658\n",
      "          vf_loss: 0.16817587186538038\n",
      "    num_agent_steps_sampled: 289710\n",
      "    num_agent_steps_trained: 289710\n",
      "    num_steps_sampled: 289710\n",
      "    num_steps_trained: 289710\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59696969696971\n",
      "    ram_util_percent: 32.124242424242425\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400761370922483\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.40158887406993\n",
      "    mean_inference_ms: 2.432457296169787\n",
      "    mean_raw_obs_processing_ms: 1.8971310999344069\n",
      "  time_since_restore: 3734.077461242676\n",
      "  time_this_iter_s: 23.013203382492065\n",
      "  time_total_s: 3734.077461242676\n",
      "  timers:\n",
      "    learn_throughput: 1119.864\n",
      "    learn_time_ms: 1784.145\n",
      "    load_throughput: 56259.735\n",
      "    load_time_ms: 35.514\n",
      "    sample_throughput: 96.131\n",
      "    sample_time_ms: 20784.096\n",
      "    update_time_ms: 12.42\n",
      "  timestamp: 1636842706\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289710\n",
      "  training_iteration: 145\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         3734.08</td><td style=\"text-align: right;\">289710</td><td style=\"text-align: right;\"> 20.0159</td><td style=\"text-align: right;\">               20.94</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">            104.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 291708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-32-11\n",
      "  done: false\n",
      "  episode_len_mean: 102.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.989999999999924\n",
      "  episode_reward_mean: 19.952299999999923\n",
      "  episode_reward_min: 10.75000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2788\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3230297258922032\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011768585003536006\n",
      "          policy_loss: -0.011525622329541615\n",
      "          total_loss: 0.11277125593097437\n",
      "          vf_explained_var: 0.9958009123802185\n",
      "          vf_loss: 0.13223131204999627\n",
      "    num_agent_steps_sampled: 291708\n",
      "    num_agent_steps_trained: 291708\n",
      "    num_steps_sampled: 291708\n",
      "    num_steps_trained: 291708\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.31111111111109\n",
      "    ram_util_percent: 32.08611111111111\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04401251996773424\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.398899896140556\n",
      "    mean_inference_ms: 2.432389083875847\n",
      "    mean_raw_obs_processing_ms: 1.8883542815847967\n",
      "  time_since_restore: 3759.1496131420135\n",
      "  time_this_iter_s: 25.07215189933777\n",
      "  time_total_s: 3759.1496131420135\n",
      "  timers:\n",
      "    learn_throughput: 1119.01\n",
      "    learn_time_ms: 1785.506\n",
      "    load_throughput: 55818.377\n",
      "    load_time_ms: 35.795\n",
      "    sample_throughput: 94.727\n",
      "    sample_time_ms: 21092.205\n",
      "    update_time_ms: 13.632\n",
      "  timestamp: 1636842731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 291708\n",
      "  training_iteration: 146\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         3759.15</td><td style=\"text-align: right;\">291708</td><td style=\"text-align: right;\"> 19.9523</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">            102.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 293706\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-32-35\n",
      "  done: false\n",
      "  episode_len_mean: 102.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.989999999999924\n",
      "  episode_reward_mean: 20.141399999999916\n",
      "  episode_reward_min: 16.569999999999986\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2809\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.505369454338437\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010384160465186478\n",
      "          policy_loss: -0.013468626443119277\n",
      "          total_loss: 0.16391007987604964\n",
      "          vf_explained_var: 0.9938159584999084\n",
      "          vf_loss: 0.18775952701412496\n",
      "    num_agent_steps_sampled: 293706\n",
      "    num_agent_steps_trained: 293706\n",
      "    num_steps_sampled: 293706\n",
      "    num_steps_trained: 293706\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88529411764706\n",
      "    ram_util_percent: 32.07647058823529\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0440103781917873\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.398182422915887\n",
      "    mean_inference_ms: 2.4323446077701516\n",
      "    mean_raw_obs_processing_ms: 1.8794022030941713\n",
      "  time_since_restore: 3783.164162158966\n",
      "  time_this_iter_s: 24.014549016952515\n",
      "  time_total_s: 3783.164162158966\n",
      "  timers:\n",
      "    learn_throughput: 1117.558\n",
      "    learn_time_ms: 1787.827\n",
      "    load_throughput: 55412.637\n",
      "    load_time_ms: 36.057\n",
      "    sample_throughput: 93.799\n",
      "    sample_time_ms: 21300.91\n",
      "    update_time_ms: 13.929\n",
      "  timestamp: 1636842755\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 293706\n",
      "  training_iteration: 147\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         3783.16</td><td style=\"text-align: right;\">293706</td><td style=\"text-align: right;\"> 20.1414</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               16.57</td><td style=\"text-align: right;\">            102.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 295704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-32-58\n",
      "  done: false\n",
      "  episode_len_mean: 102.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.989999999999924\n",
      "  episode_reward_mean: 20.13569999999992\n",
      "  episode_reward_min: 17.059999999999956\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2827\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3822459044910613\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008536067691799433\n",
      "          policy_loss: -0.006016666335718972\n",
      "          total_loss: 0.14345451944640705\n",
      "          vf_explained_var: 0.9953513145446777\n",
      "          vf_loss: 0.1594524152754318\n",
      "    num_agent_steps_sampled: 295704\n",
      "    num_agent_steps_trained: 295704\n",
      "    num_steps_sampled: 295704\n",
      "    num_steps_trained: 295704\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90882352941176\n",
      "    ram_util_percent: 32.11176470588235\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0440059923425601\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.39765264968889\n",
      "    mean_inference_ms: 2.432322826428873\n",
      "    mean_raw_obs_processing_ms: 1.871825610474167\n",
      "  time_since_restore: 3806.6473064422607\n",
      "  time_this_iter_s: 23.483144283294678\n",
      "  time_total_s: 3806.6473064422607\n",
      "  timers:\n",
      "    learn_throughput: 1126.094\n",
      "    learn_time_ms: 1774.274\n",
      "    load_throughput: 57479.194\n",
      "    load_time_ms: 34.76\n",
      "    sample_throughput: 93.413\n",
      "    sample_time_ms: 21388.832\n",
      "    update_time_ms: 14.726\n",
      "  timestamp: 1636842778\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 295704\n",
      "  training_iteration: 148\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         3806.65</td><td style=\"text-align: right;\">295704</td><td style=\"text-align: right;\"> 20.1357</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               17.06</td><td style=\"text-align: right;\">            102.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 297702\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-33-37\n",
      "  done: false\n",
      "  episode_len_mean: 101.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.989999999999924\n",
      "  episode_reward_mean: 19.944699999999923\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 2849\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5028460911342076\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008926038346616696\n",
      "          policy_loss: -0.014178711417618962\n",
      "          total_loss: 0.7960593785691474\n",
      "          vf_explained_var: 0.974318265914917\n",
      "          vf_loss: 0.8212498385991369\n",
      "    num_agent_steps_sampled: 297702\n",
      "    num_agent_steps_trained: 297702\n",
      "    num_steps_sampled: 297702\n",
      "    num_steps_trained: 297702\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.17272727272726\n",
      "    ram_util_percent: 31.918181818181814\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0440049795538276\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.398996052765007\n",
      "    mean_inference_ms: 2.4321368205982994\n",
      "    mean_raw_obs_processing_ms: 1.8754864273776857\n",
      "  time_since_restore: 3845.029023170471\n",
      "  time_this_iter_s: 38.38171672821045\n",
      "  time_total_s: 3845.029023170471\n",
      "  timers:\n",
      "    learn_throughput: 1124.018\n",
      "    learn_time_ms: 1777.552\n",
      "    load_throughput: 57356.806\n",
      "    load_time_ms: 34.835\n",
      "    sample_throughput: 87.134\n",
      "    sample_time_ms: 22930.21\n",
      "    update_time_ms: 15.511\n",
      "  timestamp: 1636842817\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 297702\n",
      "  training_iteration: 149\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         3845.03</td><td style=\"text-align: right;\">297702</td><td style=\"text-align: right;\"> 19.9447</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            101.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 299700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-34-29\n",
      "  done: false\n",
      "  episode_len_mean: 98.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.989999999999924\n",
      "  episode_reward_mean: 19.529499999999924\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2869\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3619683418955122\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00870682856440214\n",
      "          policy_loss: 0.006282333674884978\n",
      "          total_loss: 1.4244752591675414\n",
      "          vf_explained_var: 0.952521026134491\n",
      "          vf_loss: 1.4278945510586103\n",
      "    num_agent_steps_sampled: 299700\n",
      "    num_agent_steps_trained: 299700\n",
      "    num_steps_sampled: 299700\n",
      "    num_steps_trained: 299700\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.0418918918919\n",
      "    ram_util_percent: 31.82567567567568\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400577170272965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.394803995862368\n",
      "    mean_inference_ms: 2.4322351453586317\n",
      "    mean_raw_obs_processing_ms: 1.8989929191424741\n",
      "  time_since_restore: 3897.249939918518\n",
      "  time_this_iter_s: 52.220916748046875\n",
      "  time_total_s: 3897.249939918518\n",
      "  timers:\n",
      "    learn_throughput: 1123.94\n",
      "    learn_time_ms: 1777.676\n",
      "    load_throughput: 57092.108\n",
      "    load_time_ms: 34.996\n",
      "    sample_throughput: 77.063\n",
      "    sample_time_ms: 25926.999\n",
      "    update_time_ms: 15.058\n",
      "  timestamp: 1636842869\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299700\n",
      "  training_iteration: 150\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         3897.25</td><td style=\"text-align: right;\">299700</td><td style=\"text-align: right;\"> 19.5295</td><td style=\"text-align: right;\">               20.99</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 301698\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-34-54\n",
      "  done: false\n",
      "  episode_len_mean: 98.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.969999999999928\n",
      "  episode_reward_mean: 19.469499999999925\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2890\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3285671722321284\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.03345914045605174\n",
      "          policy_loss: -0.005308990819113595\n",
      "          total_loss: 0.6687940300752719\n",
      "          vf_explained_var: 0.9764987826347351\n",
      "          vf_loss: 0.6723320808793817\n",
      "    num_agent_steps_sampled: 301698\n",
      "    num_agent_steps_trained: 301698\n",
      "    num_steps_sampled: 301698\n",
      "    num_steps_trained: 301698\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5\n",
      "    ram_util_percent: 31.65000000000001\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400451222758225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.39287455726876\n",
      "    mean_inference_ms: 2.4322397898707204\n",
      "    mean_raw_obs_processing_ms: 1.9237186725281428\n",
      "  time_since_restore: 3922.3769249916077\n",
      "  time_this_iter_s: 25.1269850730896\n",
      "  time_total_s: 3922.3769249916077\n",
      "  timers:\n",
      "    learn_throughput: 1124.634\n",
      "    learn_time_ms: 1776.578\n",
      "    load_throughput: 57187.483\n",
      "    load_time_ms: 34.938\n",
      "    sample_throughput: 76.253\n",
      "    sample_time_ms: 26202.347\n",
      "    update_time_ms: 15.096\n",
      "  timestamp: 1636842894\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 301698\n",
      "  training_iteration: 151\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         3922.38</td><td style=\"text-align: right;\">301698</td><td style=\"text-align: right;\"> 19.4695</td><td style=\"text-align: right;\">               20.97</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">              98.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 303696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-35-17\n",
      "  done: false\n",
      "  episode_len_mean: 98.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.969999999999928\n",
      "  episode_reward_mean: 19.502099999999924\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2909\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3896647674696787\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006074903508326303\n",
      "          policy_loss: -0.013153910317591258\n",
      "          total_loss: 0.08448522258549929\n",
      "          vf_explained_var: 0.9965959191322327\n",
      "          vf_loss: 0.10743522047109547\n",
      "    num_agent_steps_sampled: 303696\n",
      "    num_agent_steps_trained: 303696\n",
      "    num_steps_sampled: 303696\n",
      "    num_steps_trained: 303696\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.45757575757577\n",
      "    ram_util_percent: 31.796969696969697\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400029699581518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.394635300146128\n",
      "    mean_inference_ms: 2.432016852035687\n",
      "    mean_raw_obs_processing_ms: 1.9460393649271754\n",
      "  time_since_restore: 3945.1221554279327\n",
      "  time_this_iter_s: 22.745230436325073\n",
      "  time_total_s: 3945.1221554279327\n",
      "  timers:\n",
      "    learn_throughput: 1124.655\n",
      "    learn_time_ms: 1776.545\n",
      "    load_throughput: 57280.122\n",
      "    load_time_ms: 34.881\n",
      "    sample_throughput: 76.303\n",
      "    sample_time_ms: 26185.055\n",
      "    update_time_ms: 14.807\n",
      "  timestamp: 1636842917\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 303696\n",
      "  training_iteration: 152\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         3945.12</td><td style=\"text-align: right;\">303696</td><td style=\"text-align: right;\"> 19.5021</td><td style=\"text-align: right;\">               20.97</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 305694\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-35-41\n",
      "  done: false\n",
      "  episode_len_mean: 98.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.969999999999928\n",
      "  episode_reward_mean: 19.57169999999992\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2928\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.398242525827317\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0052019791631767055\n",
      "          policy_loss: -0.0250583733565041\n",
      "          total_loss: 0.08100513697025322\n",
      "          vf_explained_var: 0.9964128136634827\n",
      "          vf_loss: 0.11653459987470081\n",
      "    num_agent_steps_sampled: 305694\n",
      "    num_agent_steps_trained: 305694\n",
      "    num_steps_sampled: 305694\n",
      "    num_steps_trained: 305694\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1029411764706\n",
      "    ram_util_percent: 31.91764705882353\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399612565041428\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.39290581670687\n",
      "    mean_inference_ms: 2.4320102402820414\n",
      "    mean_raw_obs_processing_ms: 1.9667018587179195\n",
      "  time_since_restore: 3969.381278991699\n",
      "  time_this_iter_s: 24.25912356376648\n",
      "  time_total_s: 3969.381278991699\n",
      "  timers:\n",
      "    learn_throughput: 1119.415\n",
      "    learn_time_ms: 1784.86\n",
      "    load_throughput: 57927.971\n",
      "    load_time_ms: 34.491\n",
      "    sample_throughput: 76.145\n",
      "    sample_time_ms: 26239.558\n",
      "    update_time_ms: 13.043\n",
      "  timestamp: 1636842941\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 305694\n",
      "  training_iteration: 153\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         3969.38</td><td style=\"text-align: right;\">305694</td><td style=\"text-align: right;\"> 19.5717</td><td style=\"text-align: right;\">               20.97</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 307692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-36-05\n",
      "  done: false\n",
      "  episode_len_mean: 99.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.00999999999993\n",
      "  episode_reward_mean: 19.741899999999923\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2948\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.374011905420394\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008559342802883311\n",
      "          policy_loss: -0.0081199382742246\n",
      "          total_loss: 0.11611925035360314\n",
      "          vf_explained_var: 0.996049165725708\n",
      "          vf_loss: 0.13220175014187893\n",
      "    num_agent_steps_sampled: 307692\n",
      "    num_agent_steps_trained: 307692\n",
      "    num_steps_sampled: 307692\n",
      "    num_steps_trained: 307692\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59411764705882\n",
      "    ram_util_percent: 32.10294117647059\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399366109384518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.390294860538166\n",
      "    mean_inference_ms: 2.432185639867457\n",
      "    mean_raw_obs_processing_ms: 1.9787288730777401\n",
      "  time_since_restore: 3992.799338579178\n",
      "  time_this_iter_s: 23.418059587478638\n",
      "  time_total_s: 3992.799338579178\n",
      "  timers:\n",
      "    learn_throughput: 1120.061\n",
      "    learn_time_ms: 1783.832\n",
      "    load_throughput: 58374.171\n",
      "    load_time_ms: 34.227\n",
      "    sample_throughput: 75.876\n",
      "    sample_time_ms: 26332.576\n",
      "    update_time_ms: 13.34\n",
      "  timestamp: 1636842965\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 307692\n",
      "  training_iteration: 154\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">          3992.8</td><td style=\"text-align: right;\">307692</td><td style=\"text-align: right;\"> 19.7419</td><td style=\"text-align: right;\">               21.01</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 309690\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-36-27\n",
      "  done: false\n",
      "  episode_len_mean: 102.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.00999999999993\n",
      "  episode_reward_mean: 20.20779999999992\n",
      "  episode_reward_min: 3.47000000000001\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2966\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4262542900584994\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005163459531689584\n",
      "          policy_loss: -0.010697519539722375\n",
      "          total_loss: 0.009651535155162925\n",
      "          vf_explained_var: 0.9989943504333496\n",
      "          vf_loss: 0.031126263538109405\n",
      "    num_agent_steps_sampled: 309690\n",
      "    num_agent_steps_trained: 309690\n",
      "    num_steps_sampled: 309690\n",
      "    num_steps_trained: 309690\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.778125\n",
      "    ram_util_percent: 32.162499999999994\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399155117026165\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.390378589162452\n",
      "    mean_inference_ms: 2.43219878016465\n",
      "    mean_raw_obs_processing_ms: 1.9724580040228807\n",
      "  time_since_restore: 4014.9938740730286\n",
      "  time_this_iter_s: 22.194535493850708\n",
      "  time_total_s: 4014.9938740730286\n",
      "  timers:\n",
      "    learn_throughput: 1117.776\n",
      "    learn_time_ms: 1787.478\n",
      "    load_throughput: 59163.622\n",
      "    load_time_ms: 33.771\n",
      "    sample_throughput: 76.119\n",
      "    sample_time_ms: 26248.451\n",
      "    update_time_ms: 12.098\n",
      "  timestamp: 1636842987\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309690\n",
      "  training_iteration: 155\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         4014.99</td><td style=\"text-align: right;\">309690</td><td style=\"text-align: right;\"> 20.2078</td><td style=\"text-align: right;\">               21.01</td><td style=\"text-align: right;\">                3.47</td><td style=\"text-align: right;\">            102.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 311688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-36-50\n",
      "  done: false\n",
      "  episode_len_mean: 102.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.00999999999993\n",
      "  episode_reward_mean: 20.45749999999992\n",
      "  episode_reward_min: 16.74999999999993\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2987\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3589186872754777\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007797797041142543\n",
      "          policy_loss: -0.01511538422533444\n",
      "          total_loss: 0.062067973032771125\n",
      "          vf_explained_var: 0.9975245594978333\n",
      "          vf_loss: 0.08550903262304409\n",
      "    num_agent_steps_sampled: 311688\n",
      "    num_agent_steps_trained: 311688\n",
      "    num_steps_sampled: 311688\n",
      "    num_steps_trained: 311688\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85151515151514\n",
      "    ram_util_percent: 32.169696969696965\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399098470606335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.386921799888697\n",
      "    mean_inference_ms: 2.432396931760838\n",
      "    mean_raw_obs_processing_ms: 1.9633283265949188\n",
      "  time_since_restore: 4038.2203629016876\n",
      "  time_this_iter_s: 23.226488828659058\n",
      "  time_total_s: 4038.2203629016876\n",
      "  timers:\n",
      "    learn_throughput: 1118.112\n",
      "    learn_time_ms: 1786.941\n",
      "    load_throughput: 59259.051\n",
      "    load_time_ms: 33.716\n",
      "    sample_throughput: 76.651\n",
      "    sample_time_ms: 26066.217\n",
      "    update_time_ms: 10.248\n",
      "  timestamp: 1636843010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 311688\n",
      "  training_iteration: 156\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         4038.22</td><td style=\"text-align: right;\">311688</td><td style=\"text-align: right;\"> 20.4575</td><td style=\"text-align: right;\">               21.01</td><td style=\"text-align: right;\">               16.75</td><td style=\"text-align: right;\">            102.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 313686\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-37-14\n",
      "  done: false\n",
      "  episode_len_mean: 101.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999983\n",
      "  episode_reward_mean: 20.44689999999992\n",
      "  episode_reward_min: 16.74999999999993\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3007\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3823383785429455\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00871543947986223\n",
      "          policy_loss: -0.0020451033044429053\n",
      "          total_loss: 0.09031054052923407\n",
      "          vf_explained_var: 0.9968751668930054\n",
      "          vf_loss: 0.10029610710307246\n",
      "    num_agent_steps_sampled: 313686\n",
      "    num_agent_steps_trained: 313686\n",
      "    num_steps_sampled: 313686\n",
      "    num_steps_trained: 313686\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.68823529411765\n",
      "    ram_util_percent: 32.30294117647058\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399940035512067\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.38573376027367\n",
      "    mean_inference_ms: 2.432596591683433\n",
      "    mean_raw_obs_processing_ms: 1.9550142361952072\n",
      "  time_since_restore: 4062.2229499816895\n",
      "  time_this_iter_s: 24.00258708000183\n",
      "  time_total_s: 4062.2229499816895\n",
      "  timers:\n",
      "    learn_throughput: 1117.794\n",
      "    learn_time_ms: 1787.449\n",
      "    load_throughput: 59212.49\n",
      "    load_time_ms: 33.743\n",
      "    sample_throughput: 76.657\n",
      "    sample_time_ms: 26064.102\n",
      "    update_time_ms: 10.96\n",
      "  timestamp: 1636843034\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 313686\n",
      "  training_iteration: 157\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         4062.22</td><td style=\"text-align: right;\">313686</td><td style=\"text-align: right;\"> 20.4469</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">               16.75</td><td style=\"text-align: right;\">            101.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 315684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-37-38\n",
      "  done: false\n",
      "  episode_len_mean: 101.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999983\n",
      "  episode_reward_mean: 20.465699999999927\n",
      "  episode_reward_min: 16.74999999999993\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3027\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3694803504716782\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00676999676585796\n",
      "          policy_loss: -0.015287603198417595\n",
      "          total_loss: 0.024377276934683324\n",
      "          vf_explained_var: 0.9985120296478271\n",
      "          vf_loss: 0.04878993599808642\n",
      "    num_agent_steps_sampled: 315684\n",
      "    num_agent_steps_trained: 315684\n",
      "    num_steps_sampled: 315684\n",
      "    num_steps_trained: 315684\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73529411764706\n",
      "    ram_util_percent: 32.30000000000001\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400186911448555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.384658246404765\n",
      "    mean_inference_ms: 2.432754324478825\n",
      "    mean_raw_obs_processing_ms: 1.946682237564059\n",
      "  time_since_restore: 4085.859418153763\n",
      "  time_this_iter_s: 23.636468172073364\n",
      "  time_total_s: 4085.859418153763\n",
      "  timers:\n",
      "    learn_throughput: 1118.309\n",
      "    learn_time_ms: 1786.626\n",
      "    load_throughput: 59295.026\n",
      "    load_time_ms: 33.696\n",
      "    sample_throughput: 76.611\n",
      "    sample_time_ms: 26079.727\n",
      "    update_time_ms: 11.247\n",
      "  timestamp: 1636843058\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 315684\n",
      "  training_iteration: 158\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         4085.86</td><td style=\"text-align: right;\">315684</td><td style=\"text-align: right;\"> 20.4657</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">               16.75</td><td style=\"text-align: right;\">             101.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 317682\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-38-01\n",
      "  done: false\n",
      "  episode_len_mean: 101.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999983\n",
      "  episode_reward_mean: 20.557699999999922\n",
      "  episode_reward_min: 18.499999999999922\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3046\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.316752549012502\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00495821711327803\n",
      "          policy_loss: -0.0012207310114588055\n",
      "          total_loss: 0.03466607511398338\n",
      "          vf_explained_var: 0.9987621307373047\n",
      "          vf_loss: 0.04570753654198987\n",
      "    num_agent_steps_sampled: 317682\n",
      "    num_agent_steps_trained: 317682\n",
      "    num_steps_sampled: 317682\n",
      "    num_steps_trained: 317682\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.33333333333333\n",
      "    ram_util_percent: 32.369696969696975\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044001214852798835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.383613254667907\n",
      "    mean_inference_ms: 2.432879291873097\n",
      "    mean_raw_obs_processing_ms: 1.9388559981169238\n",
      "  time_since_restore: 4108.927247285843\n",
      "  time_this_iter_s: 23.067829132080078\n",
      "  time_total_s: 4108.927247285843\n",
      "  timers:\n",
      "    learn_throughput: 1119.615\n",
      "    learn_time_ms: 1784.541\n",
      "    load_throughput: 59303.208\n",
      "    load_time_ms: 33.691\n",
      "    sample_throughput: 81.382\n",
      "    sample_time_ms: 24550.869\n",
      "    update_time_ms: 10.863\n",
      "  timestamp: 1636843081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 317682\n",
      "  training_iteration: 159\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         4108.93</td><td style=\"text-align: right;\">317682</td><td style=\"text-align: right;\"> 20.5577</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">                18.5</td><td style=\"text-align: right;\">            101.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 319680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-38-24\n",
      "  done: false\n",
      "  episode_len_mean: 100.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999983\n",
      "  episode_reward_mean: 20.580899999999918\n",
      "  episode_reward_min: 18.499999999999922\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3066\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3375\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3981547355651855\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008466217819555073\n",
      "          policy_loss: -0.028122225634398916\n",
      "          total_loss: 0.02580568204146056\n",
      "          vf_explained_var: 0.997929036617279\n",
      "          vf_loss: 0.06505210508281986\n",
      "    num_agent_steps_sampled: 319680\n",
      "    num_agent_steps_trained: 319680\n",
      "    num_steps_sampled: 319680\n",
      "    num_steps_trained: 319680\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6939393939394\n",
      "    ram_util_percent: 32.369696969696975\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0440070211985603\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.38497386922268\n",
      "    mean_inference_ms: 2.432924106711189\n",
      "    mean_raw_obs_processing_ms: 1.9309447253056498\n",
      "  time_since_restore: 4131.949146270752\n",
      "  time_this_iter_s: 23.021898984909058\n",
      "  time_total_s: 4131.949146270752\n",
      "  timers:\n",
      "    learn_throughput: 1119.049\n",
      "    learn_time_ms: 1785.444\n",
      "    load_throughput: 59217.595\n",
      "    load_time_ms: 33.74\n",
      "    sample_throughput: 92.372\n",
      "    sample_time_ms: 21629.93\n",
      "    update_time_ms: 10.827\n",
      "  timestamp: 1636843104\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319680\n",
      "  training_iteration: 160\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         4131.95</td><td style=\"text-align: right;\">319680</td><td style=\"text-align: right;\"> 20.5809</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">                18.5</td><td style=\"text-align: right;\">            100.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 321678\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-38-47\n",
      "  done: false\n",
      "  episode_len_mean: 101.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999983\n",
      "  episode_reward_mean: 20.594799999999918\n",
      "  episode_reward_min: 18.499999999999922\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3086\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3375\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.348458542710259\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00869776568654809\n",
      "          policy_loss: -0.020856798351520583\n",
      "          total_loss: 0.01681611922880014\n",
      "          vf_explained_var: 0.9985589981079102\n",
      "          vf_loss: 0.048222006400603624\n",
      "    num_agent_steps_sampled: 321678\n",
      "    num_agent_steps_trained: 321678\n",
      "    num_steps_sampled: 321678\n",
      "    num_steps_trained: 321678\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.803125\n",
      "    ram_util_percent: 32.26875\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044010515803930096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.381990479893872\n",
      "    mean_inference_ms: 2.433091969332537\n",
      "    mean_raw_obs_processing_ms: 1.9229075004548968\n",
      "  time_since_restore: 4154.478413820267\n",
      "  time_this_iter_s: 22.52926754951477\n",
      "  time_total_s: 4154.478413820267\n",
      "  timers:\n",
      "    learn_throughput: 1118.832\n",
      "    learn_time_ms: 1785.791\n",
      "    load_throughput: 58677.696\n",
      "    load_time_ms: 34.05\n",
      "    sample_throughput: 93.497\n",
      "    sample_time_ms: 21369.748\n",
      "    update_time_ms: 10.722\n",
      "  timestamp: 1636843127\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 321678\n",
      "  training_iteration: 161\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         4154.48</td><td style=\"text-align: right;\">321678</td><td style=\"text-align: right;\"> 20.5948</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">                18.5</td><td style=\"text-align: right;\">            101.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 323676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-39-10\n",
      "  done: false\n",
      "  episode_len_mean: 101.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.029999999999934\n",
      "  episode_reward_mean: 20.63189999999992\n",
      "  episode_reward_min: 18.349999999999902\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3105\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3375\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3678115753900437\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014476133959284388\n",
      "          policy_loss: -0.005466752898480211\n",
      "          total_loss: 0.054629286245575975\n",
      "          vf_explained_var: 0.9978864192962646\n",
      "          vf_loss: 0.06888845897324028\n",
      "    num_agent_steps_sampled: 323676\n",
      "    num_agent_steps_trained: 323676\n",
      "    num_steps_sampled: 323676\n",
      "    num_steps_trained: 323676\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72424242424242\n",
      "    ram_util_percent: 32.28181818181818\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044009217845405645\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.376732092334578\n",
      "    mean_inference_ms: 2.4332059908036983\n",
      "    mean_raw_obs_processing_ms: 1.9151678467996598\n",
      "  time_since_restore: 4177.599861621857\n",
      "  time_this_iter_s: 23.121447801589966\n",
      "  time_total_s: 4177.599861621857\n",
      "  timers:\n",
      "    learn_throughput: 1119.332\n",
      "    learn_time_ms: 1784.993\n",
      "    load_throughput: 58663.524\n",
      "    load_time_ms: 34.059\n",
      "    sample_throughput: 93.332\n",
      "    sample_time_ms: 21407.41\n",
      "    update_time_ms: 11.649\n",
      "  timestamp: 1636843150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 323676\n",
      "  training_iteration: 162\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">          4177.6</td><td style=\"text-align: right;\">323676</td><td style=\"text-align: right;\"> 20.6319</td><td style=\"text-align: right;\">               21.03</td><td style=\"text-align: right;\">               18.35</td><td style=\"text-align: right;\">            101.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 325674\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-39-33\n",
      "  done: false\n",
      "  episode_len_mean: 101.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.029999999999934\n",
      "  episode_reward_mean: 20.513499999999922\n",
      "  episode_reward_min: 13.150000000000013\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3125\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3375\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2693477528435844\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.02182599377555639\n",
      "          policy_loss: 0.010055542187321754\n",
      "          total_loss: 0.1934844488189334\n",
      "          vf_explained_var: 0.9946568012237549\n",
      "          vf_loss: 0.18875611028855754\n",
      "    num_agent_steps_sampled: 325674\n",
      "    num_agent_steps_trained: 325674\n",
      "    num_steps_sampled: 325674\n",
      "    num_steps_trained: 325674\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.86969696969696\n",
      "    ram_util_percent: 32.233333333333334\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400994914640749\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.372673107747577\n",
      "    mean_inference_ms: 2.4331730490348438\n",
      "    mean_raw_obs_processing_ms: 1.9072422685995778\n",
      "  time_since_restore: 4201.12197637558\n",
      "  time_this_iter_s: 23.522114753723145\n",
      "  time_total_s: 4201.12197637558\n",
      "  timers:\n",
      "    learn_throughput: 1124.444\n",
      "    learn_time_ms: 1776.878\n",
      "    load_throughput: 57940.627\n",
      "    load_time_ms: 34.484\n",
      "    sample_throughput: 93.62\n",
      "    sample_time_ms: 21341.482\n",
      "    update_time_ms: 11.748\n",
      "  timestamp: 1636843173\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 325674\n",
      "  training_iteration: 163\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         4201.12</td><td style=\"text-align: right;\">325674</td><td style=\"text-align: right;\"> 20.5135</td><td style=\"text-align: right;\">               21.03</td><td style=\"text-align: right;\">               13.15</td><td style=\"text-align: right;\">             101.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 327672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-39-57\n",
      "  done: false\n",
      "  episode_len_mean: 101.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.029999999999934\n",
      "  episode_reward_mean: 20.457499999999925\n",
      "  episode_reward_min: 13.150000000000013\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3145\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3257936103003365\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008583491780898829\n",
      "          policy_loss: -0.05401546515169598\n",
      "          total_loss: 0.040824494936636514\n",
      "          vf_explained_var: 0.9969787001609802\n",
      "          vf_loss: 0.10375250367713826\n",
      "    num_agent_steps_sampled: 327672\n",
      "    num_agent_steps_trained: 327672\n",
      "    num_steps_sampled: 327672\n",
      "    num_steps_trained: 327672\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.26285714285714\n",
      "    ram_util_percent: 32.24857142857143\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044008029486824966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.370274293818103\n",
      "    mean_inference_ms: 2.4329739644570707\n",
      "    mean_raw_obs_processing_ms: 1.8996047364367377\n",
      "  time_since_restore: 4225.071641206741\n",
      "  time_this_iter_s: 23.9496648311615\n",
      "  time_total_s: 4225.071641206741\n",
      "  timers:\n",
      "    learn_throughput: 1122.91\n",
      "    learn_time_ms: 1779.306\n",
      "    load_throughput: 58047.946\n",
      "    load_time_ms: 34.42\n",
      "    sample_throughput: 93.401\n",
      "    sample_time_ms: 21391.668\n",
      "    update_time_ms: 12.036\n",
      "  timestamp: 1636843197\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 327672\n",
      "  training_iteration: 164\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         4225.07</td><td style=\"text-align: right;\">327672</td><td style=\"text-align: right;\"> 20.4575</td><td style=\"text-align: right;\">               21.03</td><td style=\"text-align: right;\">               13.15</td><td style=\"text-align: right;\">            101.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 329670\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-40-20\n",
      "  done: false\n",
      "  episode_len_mean: 101.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.029999999999934\n",
      "  episode_reward_mean: 20.41719999999992\n",
      "  episode_reward_min: 13.150000000000013\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3164\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2810634601683843\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008316951647038552\n",
      "          policy_loss: -0.003487581404901686\n",
      "          total_loss: 0.07516046153115374\n",
      "          vf_explained_var: 0.9973423480987549\n",
      "          vf_loss: 0.08724821879572811\n",
      "    num_agent_steps_sampled: 329670\n",
      "    num_agent_steps_trained: 329670\n",
      "    num_steps_sampled: 329670\n",
      "    num_steps_trained: 329670\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.709375\n",
      "    ram_util_percent: 32.212500000000006\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399767348549933\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.364883897861628\n",
      "    mean_inference_ms: 2.4328993469143168\n",
      "    mean_raw_obs_processing_ms: 1.8920842620854585\n",
      "  time_since_restore: 4248.053191900253\n",
      "  time_this_iter_s: 22.981550693511963\n",
      "  time_total_s: 4248.053191900253\n",
      "  timers:\n",
      "    learn_throughput: 1126.172\n",
      "    learn_time_ms: 1774.151\n",
      "    load_throughput: 57398.37\n",
      "    load_time_ms: 34.809\n",
      "    sample_throughput: 93.043\n",
      "    sample_time_ms: 21473.919\n",
      "    update_time_ms: 13.168\n",
      "  timestamp: 1636843220\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329670\n",
      "  training_iteration: 165\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         4248.05</td><td style=\"text-align: right;\">329670</td><td style=\"text-align: right;\"> 20.4172</td><td style=\"text-align: right;\">               21.03</td><td style=\"text-align: right;\">               13.15</td><td style=\"text-align: right;\">             101.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 331668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-40-44\n",
      "  done: false\n",
      "  episode_len_mean: 100.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.362499999999923\n",
      "  episode_reward_min: 13.150000000000013\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3185\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2186430198805673\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008442579907385112\n",
      "          policy_loss: -0.14789926870947792\n",
      "          total_loss: -0.09925967823891413\n",
      "          vf_explained_var: 0.9984161257743835\n",
      "          vf_loss: 0.05655196376056189\n",
      "    num_agent_steps_sampled: 331668\n",
      "    num_agent_steps_trained: 331668\n",
      "    num_steps_sampled: 331668\n",
      "    num_steps_trained: 331668\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.67428571428572\n",
      "    ram_util_percent: 32.19714285714286\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399844763961689\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.364044102239614\n",
      "    mean_inference_ms: 2.432591692687538\n",
      "    mean_raw_obs_processing_ms: 1.884239989822448\n",
      "  time_since_restore: 4272.121815443039\n",
      "  time_this_iter_s: 24.068623542785645\n",
      "  time_total_s: 4272.121815443039\n",
      "  timers:\n",
      "    learn_throughput: 1127.148\n",
      "    learn_time_ms: 1772.615\n",
      "    load_throughput: 57159.71\n",
      "    load_time_ms: 34.955\n",
      "    sample_throughput: 92.678\n",
      "    sample_time_ms: 21558.532\n",
      "    update_time_ms: 14.331\n",
      "  timestamp: 1636843244\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 331668\n",
      "  training_iteration: 166\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         4272.12</td><td style=\"text-align: right;\">331668</td><td style=\"text-align: right;\"> 20.3625</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               13.15</td><td style=\"text-align: right;\">            100.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 333666\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-41-24\n",
      "  done: false\n",
      "  episode_len_mean: 99.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.177699999999923\n",
      "  episode_reward_min: 1.95\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3206\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.287534487247467\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008765908742313125\n",
      "          policy_loss: -0.026357426760452135\n",
      "          total_loss: 0.6687409476842732\n",
      "          vf_explained_var: 0.979040265083313\n",
      "          vf_loss: 0.7035359886075769\n",
      "    num_agent_steps_sampled: 333666\n",
      "    num_agent_steps_trained: 333666\n",
      "    num_steps_sampled: 333666\n",
      "    num_steps_trained: 333666\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.10892857142858\n",
      "    ram_util_percent: 32.16428571428572\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399363514014409\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.365471150857537\n",
      "    mean_inference_ms: 2.432152629727766\n",
      "    mean_raw_obs_processing_ms: 1.8880884736767012\n",
      "  time_since_restore: 4311.21090388298\n",
      "  time_this_iter_s: 39.089088439941406\n",
      "  time_total_s: 4311.21090388298\n",
      "  timers:\n",
      "    learn_throughput: 1128.596\n",
      "    learn_time_ms: 1770.341\n",
      "    load_throughput: 56982.091\n",
      "    load_time_ms: 35.064\n",
      "    sample_throughput: 86.604\n",
      "    sample_time_ms: 23070.45\n",
      "    update_time_ms: 13.319\n",
      "  timestamp: 1636843284\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 333666\n",
      "  training_iteration: 167\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         4311.21</td><td style=\"text-align: right;\">333666</td><td style=\"text-align: right;\"> 20.1777</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">                1.95</td><td style=\"text-align: right;\">             99.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 335664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-42-18\n",
      "  done: false\n",
      "  episode_len_mean: 96.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 19.887799999999924\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 3228\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2947011067753746\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008653826586994368\n",
      "          policy_loss: 0.003493966277511347\n",
      "          total_loss: 1.3600781259792192\n",
      "          vf_explained_var: 0.9583820104598999\n",
      "          vf_loss: 1.3651501762015479\n",
      "    num_agent_steps_sampled: 335664\n",
      "    num_agent_steps_trained: 335664\n",
      "    num_steps_sampled: 335664\n",
      "    num_steps_trained: 335664\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.7012987012987\n",
      "    ram_util_percent: 32.03506493506493\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399966143593609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.35576037091919\n",
      "    mean_inference_ms: 2.4322491314674286\n",
      "    mean_raw_obs_processing_ms: 1.9123540493516376\n",
      "  time_since_restore: 4365.243108510971\n",
      "  time_this_iter_s: 54.03220462799072\n",
      "  time_total_s: 4365.243108510971\n",
      "  timers:\n",
      "    learn_throughput: 1128.987\n",
      "    learn_time_ms: 1769.729\n",
      "    load_throughput: 57208.564\n",
      "    load_time_ms: 34.925\n",
      "    sample_throughput: 76.517\n",
      "    sample_time_ms: 26111.735\n",
      "    update_time_ms: 12.127\n",
      "  timestamp: 1636843338\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 335664\n",
      "  training_iteration: 168\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         4365.24</td><td style=\"text-align: right;\">335664</td><td style=\"text-align: right;\"> 19.8878</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 337662\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-42-43\n",
      "  done: false\n",
      "  episode_len_mean: 96.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 19.97259999999993\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3248\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.339213095960163\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0065969255812754184\n",
      "          policy_loss: -0.01142680715946924\n",
      "          total_loss: 0.04748339792270036\n",
      "          vf_explained_var: 0.9980356693267822\n",
      "          vf_loss: 0.06896264212472099\n",
      "    num_agent_steps_sampled: 337662\n",
      "    num_agent_steps_trained: 337662\n",
      "    num_steps_sampled: 337662\n",
      "    num_steps_trained: 337662\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.51111111111112\n",
      "    ram_util_percent: 31.744444444444454\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399973759806173\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.35249838016911\n",
      "    mean_inference_ms: 2.432147436099377\n",
      "    mean_raw_obs_processing_ms: 1.934554731614076\n",
      "  time_since_restore: 4390.5930190086365\n",
      "  time_this_iter_s: 25.349910497665405\n",
      "  time_total_s: 4390.5930190086365\n",
      "  timers:\n",
      "    learn_throughput: 1129.868\n",
      "    learn_time_ms: 1768.348\n",
      "    load_throughput: 56674.609\n",
      "    load_time_ms: 35.254\n",
      "    sample_throughput: 75.849\n",
      "    sample_time_ms: 26341.975\n",
      "    update_time_ms: 11.121\n",
      "  timestamp: 1636843363\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 337662\n",
      "  training_iteration: 169\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         4390.59</td><td style=\"text-align: right;\">337662</td><td style=\"text-align: right;\"> 19.9726</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 339660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-43-07\n",
      "  done: false\n",
      "  episode_len_mean: 96.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999945\n",
      "  episode_reward_mean: 19.969199999999926\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3268\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3137082542691911\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00870614978758167\n",
      "          policy_loss: -0.02256171933951832\n",
      "          total_loss: 0.024108464341788066\n",
      "          vf_explained_var: 0.9984856247901917\n",
      "          vf_loss: 0.05539977884452258\n",
      "    num_agent_steps_sampled: 339660\n",
      "    num_agent_steps_trained: 339660\n",
      "    num_steps_sampled: 339660\n",
      "    num_steps_trained: 339660\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04117647058824\n",
      "    ram_util_percent: 31.879411764705885\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400065305621195\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.35270313686174\n",
      "    mean_inference_ms: 2.4319691515951343\n",
      "    mean_raw_obs_processing_ms: 1.9569250789288888\n",
      "  time_since_restore: 4414.361981868744\n",
      "  time_this_iter_s: 23.768962860107422\n",
      "  time_total_s: 4414.361981868744\n",
      "  timers:\n",
      "    learn_throughput: 1130.885\n",
      "    learn_time_ms: 1766.757\n",
      "    load_throughput: 57073.678\n",
      "    load_time_ms: 35.007\n",
      "    sample_throughput: 75.63\n",
      "    sample_time_ms: 26418.136\n",
      "    update_time_ms: 11.817\n",
      "  timestamp: 1636843387\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 339660\n",
      "  training_iteration: 170\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         4414.36</td><td style=\"text-align: right;\">339660</td><td style=\"text-align: right;\"> 19.9692</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 341658\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-43-30\n",
      "  done: false\n",
      "  episode_len_mean: 97.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999945\n",
      "  episode_reward_mean: 20.143999999999927\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3288\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3143966260410491\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006489989078548396\n",
      "          policy_loss: -0.0633042712208061\n",
      "          total_loss: -0.015842496257807526\n",
      "          vf_explained_var: 0.9982614517211914\n",
      "          vf_loss: 0.057320183963470515\n",
      "    num_agent_steps_sampled: 341658\n",
      "    num_agent_steps_trained: 341658\n",
      "    num_steps_sampled: 341658\n",
      "    num_steps_trained: 341658\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.63529411764705\n",
      "    ram_util_percent: 31.938235294117643\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043992778931645875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.35333958800712\n",
      "    mean_inference_ms: 2.431717828714657\n",
      "    mean_raw_obs_processing_ms: 1.9747204240655514\n",
      "  time_since_restore: 4437.872199773788\n",
      "  time_this_iter_s: 23.510217905044556\n",
      "  time_total_s: 4437.872199773788\n",
      "  timers:\n",
      "    learn_throughput: 1130.893\n",
      "    learn_time_ms: 1766.745\n",
      "    load_throughput: 57251.791\n",
      "    load_time_ms: 34.898\n",
      "    sample_throughput: 75.352\n",
      "    sample_time_ms: 26515.553\n",
      "    update_time_ms: 12.204\n",
      "  timestamp: 1636843410\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 341658\n",
      "  training_iteration: 171\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         4437.87</td><td style=\"text-align: right;\">341658</td><td style=\"text-align: right;\">  20.144</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 343656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-43-55\n",
      "  done: false\n",
      "  episode_len_mean: 97.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999945\n",
      "  episode_reward_mean: 20.21689999999993\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3309\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2666816081319536\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008040297830406152\n",
      "          policy_loss: -0.012806447205089387\n",
      "          total_loss: 0.003990137523838452\n",
      "          vf_explained_var: 0.999180257320404\n",
      "          vf_loss: 0.025393001531206424\n",
      "    num_agent_steps_sampled: 343656\n",
      "    num_agent_steps_trained: 343656\n",
      "    num_steps_sampled: 343656\n",
      "    num_steps_trained: 343656\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.51764705882353\n",
      "    ram_util_percent: 31.976470588235294\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04398857855753056\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.352292959989786\n",
      "    mean_inference_ms: 2.4318408697818983\n",
      "    mean_raw_obs_processing_ms: 1.9863187456733669\n",
      "  time_since_restore: 4462.2368812561035\n",
      "  time_this_iter_s: 24.364681482315063\n",
      "  time_total_s: 4462.2368812561035\n",
      "  timers:\n",
      "    learn_throughput: 1128.152\n",
      "    learn_time_ms: 1771.039\n",
      "    load_throughput: 58079.003\n",
      "    load_time_ms: 34.401\n",
      "    sample_throughput: 75.012\n",
      "    sample_time_ms: 26635.864\n",
      "    update_time_ms: 12.357\n",
      "  timestamp: 1636843435\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 343656\n",
      "  training_iteration: 172\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         4462.24</td><td style=\"text-align: right;\">343656</td><td style=\"text-align: right;\"> 20.2169</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 345654\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-44-19\n",
      "  done: false\n",
      "  episode_len_mean: 98.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999945\n",
      "  episode_reward_mean: 20.54109999999993\n",
      "  episode_reward_min: 16.65999999999994\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3330\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2245909940628779\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009193245711011216\n",
      "          policy_loss: -0.08317857666739396\n",
      "          total_loss: 0.024941209100541616\n",
      "          vf_explained_var: 0.9962674379348755\n",
      "          vf_loss: 0.1157116151370463\n",
      "    num_agent_steps_sampled: 345654\n",
      "    num_agent_steps_trained: 345654\n",
      "    num_steps_sampled: 345654\n",
      "    num_steps_trained: 345654\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99142857142859\n",
      "    ram_util_percent: 32.00285714285713\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04398523207546914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.360198538668065\n",
      "    mean_inference_ms: 2.4316426510677864\n",
      "    mean_raw_obs_processing_ms: 1.9786274918094398\n",
      "  time_since_restore: 4486.608633518219\n",
      "  time_this_iter_s: 24.37175226211548\n",
      "  time_total_s: 4486.608633518219\n",
      "  timers:\n",
      "    learn_throughput: 1128.48\n",
      "    learn_time_ms: 1770.524\n",
      "    load_throughput: 58276.381\n",
      "    load_time_ms: 34.285\n",
      "    sample_throughput: 74.771\n",
      "    sample_time_ms: 26721.413\n",
      "    update_time_ms: 12.627\n",
      "  timestamp: 1636843459\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 345654\n",
      "  training_iteration: 173\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         4486.61</td><td style=\"text-align: right;\">345654</td><td style=\"text-align: right;\"> 20.5411</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               16.66</td><td style=\"text-align: right;\">             98.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 347652\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-44-43\n",
      "  done: false\n",
      "  episode_len_mean: 97.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999945\n",
      "  episode_reward_mean: 20.560499999999923\n",
      "  episode_reward_min: 16.65999999999994\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3351\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3116822396005903\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008260089477838815\n",
      "          policy_loss: 0.005303994796815373\n",
      "          total_loss: 0.06130630191238154\n",
      "          vf_explained_var: 0.9982734322547913\n",
      "          vf_loss: 0.06493746124740157\n",
      "    num_agent_steps_sampled: 347652\n",
      "    num_agent_steps_trained: 347652\n",
      "    num_steps_sampled: 347652\n",
      "    num_steps_trained: 347652\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.3742857142857\n",
      "    ram_util_percent: 32.09428571428572\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04398460343016477\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.36467610063448\n",
      "    mean_inference_ms: 2.4316095964498095\n",
      "    mean_raw_obs_processing_ms: 1.9709577355914587\n",
      "  time_since_restore: 4510.6980130672455\n",
      "  time_this_iter_s: 24.08937954902649\n",
      "  time_total_s: 4510.6980130672455\n",
      "  timers:\n",
      "    learn_throughput: 1129.979\n",
      "    learn_time_ms: 1768.174\n",
      "    load_throughput: 58749.395\n",
      "    load_time_ms: 34.009\n",
      "    sample_throughput: 74.723\n",
      "    sample_time_ms: 26738.586\n",
      "    update_time_ms: 12.373\n",
      "  timestamp: 1636843483\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 347652\n",
      "  training_iteration: 174\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">          4510.7</td><td style=\"text-align: right;\">347652</td><td style=\"text-align: right;\"> 20.5605</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               16.66</td><td style=\"text-align: right;\">             97.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 349650\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-45-08\n",
      "  done: false\n",
      "  episode_len_mean: 96.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999945\n",
      "  episode_reward_mean: 20.55539999999992\n",
      "  episode_reward_min: 16.65999999999994\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3372\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.311709139460609\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011680251637837636\n",
      "          policy_loss: -0.021190035431867555\n",
      "          total_loss: 0.06707346308532924\n",
      "          vf_explained_var: 0.9972570538520813\n",
      "          vf_loss: 0.09546746115776755\n",
      "    num_agent_steps_sampled: 349650\n",
      "    num_agent_steps_trained: 349650\n",
      "    num_steps_sampled: 349650\n",
      "    num_steps_trained: 349650\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85882352941178\n",
      "    ram_util_percent: 32.14411764705883\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04398680821759216\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.366561921786435\n",
      "    mean_inference_ms: 2.4317532565758713\n",
      "    mean_raw_obs_processing_ms: 1.9633778880074708\n",
      "  time_since_restore: 4534.907606601715\n",
      "  time_this_iter_s: 24.209593534469604\n",
      "  time_total_s: 4534.907606601715\n",
      "  timers:\n",
      "    learn_throughput: 1130.213\n",
      "    learn_time_ms: 1767.808\n",
      "    load_throughput: 58918.373\n",
      "    load_time_ms: 33.911\n",
      "    sample_throughput: 74.38\n",
      "    sample_time_ms: 26862.17\n",
      "    update_time_ms: 12.267\n",
      "  timestamp: 1636843508\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 349650\n",
      "  training_iteration: 175\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         4534.91</td><td style=\"text-align: right;\">349650</td><td style=\"text-align: right;\"> 20.5554</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               16.66</td><td style=\"text-align: right;\">             96.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 351648\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-45-31\n",
      "  done: false\n",
      "  episode_len_mean: 96.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999945\n",
      "  episode_reward_mean: 20.649699999999925\n",
      "  episode_reward_min: 16.65999999999994\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3392\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3645168452035814\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0074949752683688906\n",
      "          policy_loss: -0.011281460452647437\n",
      "          total_loss: 0.017313913433324724\n",
      "          vf_explained_var: 0.9989679455757141\n",
      "          vf_loss: 0.0384462092737002\n",
      "    num_agent_steps_sampled: 351648\n",
      "    num_agent_steps_trained: 351648\n",
      "    num_steps_sampled: 351648\n",
      "    num_steps_trained: 351648\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77352941176471\n",
      "    ram_util_percent: 32.19411764705882\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04398357773887383\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.36940848842307\n",
      "    mean_inference_ms: 2.431799034803119\n",
      "    mean_raw_obs_processing_ms: 1.9563767058115906\n",
      "  time_since_restore: 4558.430883646011\n",
      "  time_this_iter_s: 23.523277044296265\n",
      "  time_total_s: 4558.430883646011\n",
      "  timers:\n",
      "    learn_throughput: 1130.354\n",
      "    learn_time_ms: 1767.588\n",
      "    load_throughput: 59020.285\n",
      "    load_time_ms: 33.853\n",
      "    sample_throughput: 74.528\n",
      "    sample_time_ms: 26808.817\n",
      "    update_time_ms: 11.398\n",
      "  timestamp: 1636843531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 351648\n",
      "  training_iteration: 176\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         4558.43</td><td style=\"text-align: right;\">351648</td><td style=\"text-align: right;\"> 20.6497</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               16.66</td><td style=\"text-align: right;\">             96.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 353646\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-45-55\n",
      "  done: false\n",
      "  episode_len_mean: 96.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999945\n",
      "  episode_reward_mean: 20.615099999999924\n",
      "  episode_reward_min: 16.65999999999994\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3412\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.276183269137428\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007163038155893254\n",
      "          policy_loss: -0.07573601016331287\n",
      "          total_loss: -0.05222421790517512\n",
      "          vf_explained_var: 0.9990706443786621\n",
      "          vf_loss: 0.03264733590407386\n",
      "    num_agent_steps_sampled: 353646\n",
      "    num_agent_steps_trained: 353646\n",
      "    num_steps_sampled: 353646\n",
      "    num_steps_trained: 353646\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.52121212121212\n",
      "    ram_util_percent: 32.22121212121212\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04398029627933427\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.374458449549856\n",
      "    mean_inference_ms: 2.431509410579476\n",
      "    mean_raw_obs_processing_ms: 1.9494518166163954\n",
      "  time_since_restore: 4581.778526306152\n",
      "  time_this_iter_s: 23.34764266014099\n",
      "  time_total_s: 4581.778526306152\n",
      "  timers:\n",
      "    learn_throughput: 1129.711\n",
      "    learn_time_ms: 1768.594\n",
      "    load_throughput: 59430.64\n",
      "    load_time_ms: 33.619\n",
      "    sample_throughput: 79.179\n",
      "    sample_time_ms: 25234.063\n",
      "    update_time_ms: 11.007\n",
      "  timestamp: 1636843555\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 353646\n",
      "  training_iteration: 177\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         4581.78</td><td style=\"text-align: right;\">353646</td><td style=\"text-align: right;\"> 20.6151</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               16.66</td><td style=\"text-align: right;\">             96.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 355644\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-46-17\n",
      "  done: false\n",
      "  episode_len_mean: 96.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999945\n",
      "  episode_reward_mean: 20.746599999999926\n",
      "  episode_reward_min: 18.629999999999924\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3433\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2962045612789335\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012391368320402486\n",
      "          policy_loss: -0.019479838900622867\n",
      "          total_loss: -0.013828646019101143\n",
      "          vf_explained_var: 0.9996328949928284\n",
      "          vf_loss: 0.012340107032408317\n",
      "    num_agent_steps_sampled: 355644\n",
      "    num_agent_steps_trained: 355644\n",
      "    num_steps_sampled: 355644\n",
      "    num_steps_trained: 355644\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.28181818181818\n",
      "    ram_util_percent: 32.236363636363635\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0439760054747072\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.37447354553469\n",
      "    mean_inference_ms: 2.4313942221477283\n",
      "    mean_raw_obs_processing_ms: 1.942067234095307\n",
      "  time_since_restore: 4604.609605073929\n",
      "  time_this_iter_s: 22.83107876777649\n",
      "  time_total_s: 4604.609605073929\n",
      "  timers:\n",
      "    learn_throughput: 1130.493\n",
      "    learn_time_ms: 1767.37\n",
      "    load_throughput: 59431.82\n",
      "    load_time_ms: 33.618\n",
      "    sample_throughput: 90.346\n",
      "    sample_time_ms: 22115.061\n",
      "    update_time_ms: 11.452\n",
      "  timestamp: 1636843577\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 355644\n",
      "  training_iteration: 178\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">         4604.61</td><td style=\"text-align: right;\">355644</td><td style=\"text-align: right;\"> 20.7466</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               18.63</td><td style=\"text-align: right;\">             96.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 357642\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-46-42\n",
      "  done: false\n",
      "  episode_len_mean: 96.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.75809999999992\n",
      "  episode_reward_min: 18.77999999999992\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3454\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2112001560983203\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007896384195369895\n",
      "          policy_loss: -0.022536731795186088\n",
      "          total_loss: 0.014284047626313709\n",
      "          vf_explained_var: 0.9986748099327087\n",
      "          vf_loss: 0.044935238616363636\n",
      "    num_agent_steps_sampled: 357642\n",
      "    num_agent_steps_trained: 357642\n",
      "    num_steps_sampled: 357642\n",
      "    num_steps_trained: 357642\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.41142857142856\n",
      "    ram_util_percent: 32.205714285714286\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04397739747885558\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.37543214445902\n",
      "    mean_inference_ms: 2.431291635596702\n",
      "    mean_raw_obs_processing_ms: 1.9347815764378202\n",
      "  time_since_restore: 4629.137527704239\n",
      "  time_this_iter_s: 24.52792263031006\n",
      "  time_total_s: 4629.137527704239\n",
      "  timers:\n",
      "    learn_throughput: 1128.545\n",
      "    learn_time_ms: 1770.422\n",
      "    load_throughput: 60212.934\n",
      "    load_time_ms: 33.182\n",
      "    sample_throughput: 90.697\n",
      "    sample_time_ms: 22029.498\n",
      "    update_time_ms: 12.018\n",
      "  timestamp: 1636843602\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 357642\n",
      "  training_iteration: 179\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         4629.14</td><td style=\"text-align: right;\">357642</td><td style=\"text-align: right;\"> 20.7581</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               18.78</td><td style=\"text-align: right;\">             96.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 359640\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-47-06\n",
      "  done: false\n",
      "  episode_len_mean: 96.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.089999999999957\n",
      "  episode_reward_mean: 20.747999999999923\n",
      "  episode_reward_min: 14.540000000000017\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3475\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2526274221284048\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012531667305806585\n",
      "          policy_loss: -0.003810825127930868\n",
      "          total_loss: 0.11581984205348861\n",
      "          vf_explained_var: 0.9967610836029053\n",
      "          vf_loss: 0.12581278620997355\n",
      "    num_agent_steps_sampled: 359640\n",
      "    num_agent_steps_trained: 359640\n",
      "    num_steps_sampled: 359640\n",
      "    num_steps_trained: 359640\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90882352941175\n",
      "    ram_util_percent: 32.19117647058823\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04397976717770308\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.37648384172069\n",
      "    mean_inference_ms: 2.4312137683654726\n",
      "    mean_raw_obs_processing_ms: 1.9276135261199097\n",
      "  time_since_restore: 4653.281370162964\n",
      "  time_this_iter_s: 24.143842458724976\n",
      "  time_total_s: 4653.281370162964\n",
      "  timers:\n",
      "    learn_throughput: 1129.084\n",
      "    learn_time_ms: 1769.577\n",
      "    load_throughput: 60423.584\n",
      "    load_time_ms: 33.067\n",
      "    sample_throughput: 90.541\n",
      "    sample_time_ms: 22067.4\n",
      "    update_time_ms: 12.348\n",
      "  timestamp: 1636843626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 359640\n",
      "  training_iteration: 180\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         4653.28</td><td style=\"text-align: right;\">359640</td><td style=\"text-align: right;\">  20.748</td><td style=\"text-align: right;\">               21.09</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">             96.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 361638\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-47-31\n",
      "  done: false\n",
      "  episode_len_mean: 95.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999937\n",
      "  episode_reward_mean: 20.697899999999933\n",
      "  episode_reward_min: 14.540000000000017\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3496\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.251318898087456\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012695651846603524\n",
      "          policy_loss: -0.003236741874189604\n",
      "          total_loss: 0.07454321945884398\n",
      "          vf_explained_var: 0.9975591897964478\n",
      "          vf_loss: 0.08386597605865626\n",
      "    num_agent_steps_sampled: 361638\n",
      "    num_agent_steps_trained: 361638\n",
      "    num_steps_sampled: 361638\n",
      "    num_steps_trained: 361638\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.18285714285715\n",
      "    ram_util_percent: 32.13428571428572\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043981762371952816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.380082996993195\n",
      "    mean_inference_ms: 2.4311084196341586\n",
      "    mean_raw_obs_processing_ms: 1.9206478573995134\n",
      "  time_since_restore: 4677.82253742218\n",
      "  time_this_iter_s: 24.54116725921631\n",
      "  time_total_s: 4677.82253742218\n",
      "  timers:\n",
      "    learn_throughput: 1129.638\n",
      "    learn_time_ms: 1768.707\n",
      "    load_throughput: 60550.149\n",
      "    load_time_ms: 32.997\n",
      "    sample_throughput: 90.112\n",
      "    sample_time_ms: 22172.349\n",
      "    update_time_ms: 11.677\n",
      "  timestamp: 1636843651\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 361638\n",
      "  training_iteration: 181\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         4677.82</td><td style=\"text-align: right;\">361638</td><td style=\"text-align: right;\"> 20.6979</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">             95.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 363636\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-47-55\n",
      "  done: false\n",
      "  episode_len_mean: 94.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999937\n",
      "  episode_reward_mean: 20.71399999999993\n",
      "  episode_reward_min: 14.540000000000017\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3517\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3489702968370347\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009737272639233885\n",
      "          policy_loss: 0.009661857624139104\n",
      "          total_loss: 0.05614241819296564\n",
      "          vf_explained_var: 0.9985034465789795\n",
      "          vf_loss: 0.05504076865368656\n",
      "    num_agent_steps_sampled: 363636\n",
      "    num_agent_steps_trained: 363636\n",
      "    num_steps_sampled: 363636\n",
      "    num_steps_trained: 363636\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73428571428569\n",
      "    ram_util_percent: 32.111428571428576\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043990719371277166\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.383526048329642\n",
      "    mean_inference_ms: 2.4312036140914985\n",
      "    mean_raw_obs_processing_ms: 1.9137012870621692\n",
      "  time_since_restore: 4702.286054134369\n",
      "  time_this_iter_s: 24.46351671218872\n",
      "  time_total_s: 4702.286054134369\n",
      "  timers:\n",
      "    learn_throughput: 1132.602\n",
      "    learn_time_ms: 1764.08\n",
      "    load_throughput: 59244.472\n",
      "    load_time_ms: 33.725\n",
      "    sample_throughput: 90.049\n",
      "    sample_time_ms: 22187.855\n",
      "    update_time_ms: 10.038\n",
      "  timestamp: 1636843675\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 363636\n",
      "  training_iteration: 182\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         4702.29</td><td style=\"text-align: right;\">363636</td><td style=\"text-align: right;\">  20.714</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">             94.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 365634\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-48-19\n",
      "  done: false\n",
      "  episode_len_mean: 93.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.09999999999994\n",
      "  episode_reward_mean: 20.714699999999933\n",
      "  episode_reward_min: 14.540000000000017\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3538\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.290966256459554\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009041866560473578\n",
      "          policy_loss: -0.04106490686535835\n",
      "          total_loss: -0.028260610261488527\n",
      "          vf_explained_var: 0.9994357228279114\n",
      "          vf_loss: 0.021136513791446175\n",
      "    num_agent_steps_sampled: 365634\n",
      "    num_agent_steps_trained: 365634\n",
      "    num_steps_sampled: 365634\n",
      "    num_steps_trained: 365634\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92285714285714\n",
      "    ram_util_percent: 32.11714285714286\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399846393465822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.391654535961603\n",
      "    mean_inference_ms: 2.4311364808123295\n",
      "    mean_raw_obs_processing_ms: 1.9070024520238533\n",
      "  time_since_restore: 4726.329119443893\n",
      "  time_this_iter_s: 24.043065309524536\n",
      "  time_total_s: 4726.329119443893\n",
      "  timers:\n",
      "    learn_throughput: 1133.967\n",
      "    learn_time_ms: 1761.955\n",
      "    load_throughput: 58843.616\n",
      "    load_time_ms: 33.954\n",
      "    sample_throughput: 90.174\n",
      "    sample_time_ms: 22157.143\n",
      "    update_time_ms: 9.865\n",
      "  timestamp: 1636843699\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 365634\n",
      "  training_iteration: 183\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         4726.33</td><td style=\"text-align: right;\">365634</td><td style=\"text-align: right;\"> 20.7147</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">             93.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 367632\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-48-58\n",
      "  done: false\n",
      "  episode_len_mean: 94.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.09999999999994\n",
      "  episode_reward_mean: 20.47839999999993\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 3560\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2620480588504246\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011093633881513739\n",
      "          policy_loss: -0.0036645737077508653\n",
      "          total_loss: 0.8059903232935106\n",
      "          vf_explained_var: 0.9767251014709473\n",
      "          vf_loss: 0.8166592191106506\n",
      "    num_agent_steps_sampled: 367632\n",
      "    num_agent_steps_trained: 367632\n",
      "    num_steps_sampled: 367632\n",
      "    num_steps_trained: 367632\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.39454545454545\n",
      "    ram_util_percent: 32.02363636363636\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400258856095636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.39835392086462\n",
      "    mean_inference_ms: 2.43106571877609\n",
      "    mean_raw_obs_processing_ms: 1.9106403343013258\n",
      "  time_since_restore: 4765.300085306168\n",
      "  time_this_iter_s: 38.97096586227417\n",
      "  time_total_s: 4765.300085306168\n",
      "  timers:\n",
      "    learn_throughput: 1133.557\n",
      "    learn_time_ms: 1762.593\n",
      "    load_throughput: 58003.148\n",
      "    load_time_ms: 34.446\n",
      "    sample_throughput: 84.506\n",
      "    sample_time_ms: 23643.296\n",
      "    update_time_ms: 10.562\n",
      "  timestamp: 1636843738\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 367632\n",
      "  training_iteration: 184\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">          4765.3</td><td style=\"text-align: right;\">367632</td><td style=\"text-align: right;\"> 20.4784</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             94.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 369630\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-49-39\n",
      "  done: false\n",
      "  episode_len_mean: 93.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.109999999999946\n",
      "  episode_reward_mean: 20.561999999999934\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3581\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2766052876199996\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009195606785842428\n",
      "          policy_loss: -0.052305108007221\n",
      "          total_loss: -0.017687808331989106\n",
      "          vf_explained_var: 0.9987440705299377\n",
      "          vf_loss: 0.04272807400806674\n",
      "    num_agent_steps_sampled: 369630\n",
      "    num_agent_steps_trained: 369630\n",
      "    num_steps_sampled: 369630\n",
      "    num_steps_trained: 369630\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.18305084745764\n",
      "    ram_util_percent: 31.867796610169496\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044004521144148406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.40463562324377\n",
      "    mean_inference_ms: 2.430983360074067\n",
      "    mean_raw_obs_processing_ms: 1.9229439368270653\n",
      "  time_since_restore: 4806.447000026703\n",
      "  time_this_iter_s: 41.14691472053528\n",
      "  time_total_s: 4806.447000026703\n",
      "  timers:\n",
      "    learn_throughput: 1131.253\n",
      "    learn_time_ms: 1766.183\n",
      "    load_throughput: 58133.515\n",
      "    load_time_ms: 34.369\n",
      "    sample_throughput: 78.867\n",
      "    sample_time_ms: 25333.945\n",
      "    update_time_ms: 9.883\n",
      "  timestamp: 1636843779\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 369630\n",
      "  training_iteration: 185\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         4806.45</td><td style=\"text-align: right;\">369630</td><td style=\"text-align: right;\">  20.562</td><td style=\"text-align: right;\">               21.11</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             93.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 371628\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-50-18\n",
      "  done: false\n",
      "  episode_len_mean: 93.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.109999999999946\n",
      "  episode_reward_mean: 20.414499999999933\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 3603\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2566814553169978\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007505065769859123\n",
      "          policy_loss: -0.0013893210994345801\n",
      "          total_loss: 0.5806777418369339\n",
      "          vf_explained_var: 0.982631266117096\n",
      "          vf_loss: 0.590834445550683\n",
      "    num_agent_steps_sampled: 371628\n",
      "    num_agent_steps_trained: 371628\n",
      "    num_steps_sampled: 371628\n",
      "    num_steps_trained: 371628\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.00545454545455\n",
      "    ram_util_percent: 31.827272727272728\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044007330471064456\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.40473678550508\n",
      "    mean_inference_ms: 2.431031289728741\n",
      "    mean_raw_obs_processing_ms: 1.9450721324382279\n",
      "  time_since_restore: 4844.629222869873\n",
      "  time_this_iter_s: 38.182222843170166\n",
      "  time_total_s: 4844.629222869873\n",
      "  timers:\n",
      "    learn_throughput: 1130.18\n",
      "    learn_time_ms: 1767.86\n",
      "    load_throughput: 57893.875\n",
      "    load_time_ms: 34.511\n",
      "    sample_throughput: 74.559\n",
      "    sample_time_ms: 26797.445\n",
      "    update_time_ms: 10.02\n",
      "  timestamp: 1636843818\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 371628\n",
      "  training_iteration: 186\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         4844.63</td><td style=\"text-align: right;\">371628</td><td style=\"text-align: right;\"> 20.4145</td><td style=\"text-align: right;\">               21.11</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             93.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 373626\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-50-42\n",
      "  done: false\n",
      "  episode_len_mean: 94.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.109999999999946\n",
      "  episode_reward_mean: 20.36489999999993\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3624\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3334094382467725\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01120022980245501\n",
      "          policy_loss: -0.0316352311166979\n",
      "          total_loss: 0.010821834206581116\n",
      "          vf_explained_var: 0.9987092614173889\n",
      "          vf_loss: 0.05012104308587455\n",
      "    num_agent_steps_sampled: 373626\n",
      "    num_agent_steps_trained: 373626\n",
      "    num_steps_sampled: 373626\n",
      "    num_steps_trained: 373626\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.91764705882352\n",
      "    ram_util_percent: 31.911764705882348\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400150093695743\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.40587932232599\n",
      "    mean_inference_ms: 2.4309317199268192\n",
      "    mean_raw_obs_processing_ms: 1.9662897494889915\n",
      "  time_since_restore: 4868.824680566788\n",
      "  time_this_iter_s: 24.195457696914673\n",
      "  time_total_s: 4868.824680566788\n",
      "  timers:\n",
      "    learn_throughput: 1130.909\n",
      "    learn_time_ms: 1766.72\n",
      "    load_throughput: 57805.779\n",
      "    load_time_ms: 34.564\n",
      "    sample_throughput: 74.323\n",
      "    sample_time_ms: 26882.572\n",
      "    update_time_ms: 10.87\n",
      "  timestamp: 1636843842\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 373626\n",
      "  training_iteration: 187\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         4868.82</td><td style=\"text-align: right;\">373626</td><td style=\"text-align: right;\"> 20.3649</td><td style=\"text-align: right;\">               21.11</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             94.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 375624\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-51-06\n",
      "  done: false\n",
      "  episode_len_mean: 95.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.109999999999946\n",
      "  episode_reward_mean: 20.58109999999993\n",
      "  episode_reward_min: 3.95\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3645\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2385528467950366\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015213636973150766\n",
      "          policy_loss: -0.002867768376710869\n",
      "          total_loss: 0.17454474124436578\n",
      "          vf_explained_var: 0.9955179691314697\n",
      "          vf_loss: 0.18209613077785997\n",
      "    num_agent_steps_sampled: 375624\n",
      "    num_agent_steps_trained: 375624\n",
      "    num_steps_sampled: 375624\n",
      "    num_steps_trained: 375624\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01714285714284\n",
      "    ram_util_percent: 31.954285714285717\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399626538262533\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.406880662691364\n",
      "    mean_inference_ms: 2.430843974649176\n",
      "    mean_raw_obs_processing_ms: 1.9781787542280274\n",
      "  time_since_restore: 4892.997520685196\n",
      "  time_this_iter_s: 24.172840118408203\n",
      "  time_total_s: 4892.997520685196\n",
      "  timers:\n",
      "    learn_throughput: 1127.406\n",
      "    learn_time_ms: 1772.21\n",
      "    load_throughput: 57927.69\n",
      "    load_time_ms: 34.491\n",
      "    sample_throughput: 73.969\n",
      "    sample_time_ms: 27011.408\n",
      "    update_time_ms: 10.507\n",
      "  timestamp: 1636843866\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 375624\n",
      "  training_iteration: 188\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">            4893</td><td style=\"text-align: right;\">375624</td><td style=\"text-align: right;\"> 20.5811</td><td style=\"text-align: right;\">               21.11</td><td style=\"text-align: right;\">                3.95</td><td style=\"text-align: right;\">              95.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 377622\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-51-30\n",
      "  done: false\n",
      "  episode_len_mean: 94.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.109999999999946\n",
      "  episode_reward_mean: 20.550299999999933\n",
      "  episode_reward_min: 3.95\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3666\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2298653880755106\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007297763353627201\n",
      "          policy_loss: 0.0015190112448873975\n",
      "          total_loss: 0.05831919241519201\n",
      "          vf_explained_var: 0.9981507062911987\n",
      "          vf_loss: 0.06540434125456072\n",
      "    num_agent_steps_sampled: 377622\n",
      "    num_agent_steps_trained: 377622\n",
      "    num_steps_sampled: 377622\n",
      "    num_steps_trained: 377622\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8058823529412\n",
      "    ram_util_percent: 31.970588235294116\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399348808131576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.408057227220016\n",
      "    mean_inference_ms: 2.430773376730155\n",
      "    mean_raw_obs_processing_ms: 1.9899782629109155\n",
      "  time_since_restore: 4917.142733097076\n",
      "  time_this_iter_s: 24.145212411880493\n",
      "  time_total_s: 4917.142733097076\n",
      "  timers:\n",
      "    learn_throughput: 1130.433\n",
      "    learn_time_ms: 1767.465\n",
      "    load_throughput: 57449.523\n",
      "    load_time_ms: 34.778\n",
      "    sample_throughput: 74.061\n",
      "    sample_time_ms: 26977.668\n",
      "    update_time_ms: 10.368\n",
      "  timestamp: 1636843890\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 377622\n",
      "  training_iteration: 189\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         4917.14</td><td style=\"text-align: right;\">377622</td><td style=\"text-align: right;\"> 20.5503</td><td style=\"text-align: right;\">               21.11</td><td style=\"text-align: right;\">                3.95</td><td style=\"text-align: right;\">             94.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 379620\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-51-53\n",
      "  done: false\n",
      "  episode_len_mean: 95.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.08999999999994\n",
      "  episode_reward_mean: 20.495699999999932\n",
      "  episode_reward_min: 3.95\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3687\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2626732048534213\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005239185883976442\n",
      "          policy_loss: -0.11023431633199965\n",
      "          total_loss: -0.07985838770511605\n",
      "          vf_explained_var: 0.9989000558853149\n",
      "          vf_loss: 0.04035032409065891\n",
      "    num_agent_steps_sampled: 379620\n",
      "    num_agent_steps_trained: 379620\n",
      "    num_steps_sampled: 379620\n",
      "    num_steps_trained: 379620\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.55454545454546\n",
      "    ram_util_percent: 32.05757575757576\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043991735874314604\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.408006951089224\n",
      "    mean_inference_ms: 2.4307110705642656\n",
      "    mean_raw_obs_processing_ms: 1.9921106901564054\n",
      "  time_since_restore: 4940.182586669922\n",
      "  time_this_iter_s: 23.03985357284546\n",
      "  time_total_s: 4940.182586669922\n",
      "  timers:\n",
      "    learn_throughput: 1129.579\n",
      "    learn_time_ms: 1768.8\n",
      "    load_throughput: 57312.206\n",
      "    load_time_ms: 34.862\n",
      "    sample_throughput: 74.366\n",
      "    sample_time_ms: 26867.06\n",
      "    update_time_ms: 9.155\n",
      "  timestamp: 1636843913\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 379620\n",
      "  training_iteration: 190\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   190</td><td style=\"text-align: right;\">         4940.18</td><td style=\"text-align: right;\">379620</td><td style=\"text-align: right;\"> 20.4957</td><td style=\"text-align: right;\">               21.09</td><td style=\"text-align: right;\">                3.95</td><td style=\"text-align: right;\">             95.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 381618\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-52-17\n",
      "  done: false\n",
      "  episode_len_mean: 96.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.08999999999994\n",
      "  episode_reward_mean: 20.584899999999926\n",
      "  episode_reward_min: 11.180000000000012\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3707\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2344542335896265\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.019354473223695556\n",
      "          policy_loss: -0.008001967005076863\n",
      "          total_loss: 0.11335815915039607\n",
      "          vf_explained_var: 0.9962284564971924\n",
      "          vf_loss: 0.12390647036511274\n",
      "    num_agent_steps_sampled: 381618\n",
      "    num_agent_steps_trained: 381618\n",
      "    num_steps_sampled: 381618\n",
      "    num_steps_trained: 381618\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.1470588235294\n",
      "    ram_util_percent: 32.13823529411765\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399850611820442\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.412548769435812\n",
      "    mean_inference_ms: 2.4304065166286333\n",
      "    mean_raw_obs_processing_ms: 1.9855952602311728\n",
      "  time_since_restore: 4964.049005270004\n",
      "  time_this_iter_s: 23.866418600082397\n",
      "  time_total_s: 4964.049005270004\n",
      "  timers:\n",
      "    learn_throughput: 1128.167\n",
      "    learn_time_ms: 1771.014\n",
      "    load_throughput: 57169.81\n",
      "    load_time_ms: 34.949\n",
      "    sample_throughput: 74.562\n",
      "    sample_time_ms: 26796.404\n",
      "    update_time_ms: 9.942\n",
      "  timestamp: 1636843937\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 381618\n",
      "  training_iteration: 191\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">         4964.05</td><td style=\"text-align: right;\">381618</td><td style=\"text-align: right;\"> 20.5849</td><td style=\"text-align: right;\">               21.09</td><td style=\"text-align: right;\">               11.18</td><td style=\"text-align: right;\">             96.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 383616\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-52-42\n",
      "  done: false\n",
      "  episode_len_mean: 95.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.08999999999994\n",
      "  episode_reward_mean: 20.619399999999928\n",
      "  episode_reward_min: 11.180000000000012\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 3729\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2021193791003455\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007548639189002064\n",
      "          policy_loss: -0.008800987713038921\n",
      "          total_loss: 0.03958701265177556\n",
      "          vf_explained_var: 0.998400866985321\n",
      "          vf_loss: 0.05658769528159783\n",
      "    num_agent_steps_sampled: 383616\n",
      "    num_agent_steps_trained: 383616\n",
      "    num_steps_sampled: 383616\n",
      "    num_steps_trained: 383616\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66571428571429\n",
      "    ram_util_percent: 32.177142857142854\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0439997055454565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.414046075346434\n",
      "    mean_inference_ms: 2.430499789561633\n",
      "    mean_raw_obs_processing_ms: 1.978547465078414\n",
      "  time_since_restore: 4988.738532543182\n",
      "  time_this_iter_s: 24.6895272731781\n",
      "  time_total_s: 4988.738532543182\n",
      "  timers:\n",
      "    learn_throughput: 1128.065\n",
      "    learn_time_ms: 1771.175\n",
      "    load_throughput: 56991.275\n",
      "    load_time_ms: 35.058\n",
      "    sample_throughput: 74.504\n",
      "    sample_time_ms: 26817.45\n",
      "    update_time_ms: 11.119\n",
      "  timestamp: 1636843962\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 383616\n",
      "  training_iteration: 192\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">         4988.74</td><td style=\"text-align: right;\">383616</td><td style=\"text-align: right;\"> 20.6194</td><td style=\"text-align: right;\">               21.09</td><td style=\"text-align: right;\">               11.18</td><td style=\"text-align: right;\">             95.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 385614\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-53-06\n",
      "  done: false\n",
      "  episode_len_mean: 95.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.099999999999948\n",
      "  episode_reward_mean: 20.53679999999993\n",
      "  episode_reward_min: 11.180000000000012\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3749\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2293483172144208\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014679668697506433\n",
      "          policy_loss: 0.006424665876797267\n",
      "          total_loss: 0.12197813710996083\n",
      "          vf_explained_var: 0.9969422817230225\n",
      "          vf_loss: 0.12041537388715716\n",
      "    num_agent_steps_sampled: 385614\n",
      "    num_agent_steps_trained: 385614\n",
      "    num_steps_sampled: 385614\n",
      "    num_steps_trained: 385614\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.79142857142857\n",
      "    ram_util_percent: 32.282857142857154\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04400136839527868\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.41666855232644\n",
      "    mean_inference_ms: 2.430389883099116\n",
      "    mean_raw_obs_processing_ms: 1.971962030773089\n",
      "  time_since_restore: 5012.795397043228\n",
      "  time_this_iter_s: 24.056864500045776\n",
      "  time_total_s: 5012.795397043228\n",
      "  timers:\n",
      "    learn_throughput: 1128.774\n",
      "    learn_time_ms: 1770.062\n",
      "    load_throughput: 57326.516\n",
      "    load_time_ms: 34.853\n",
      "    sample_throughput: 74.496\n",
      "    sample_time_ms: 26820.1\n",
      "    update_time_ms: 10.779\n",
      "  timestamp: 1636843986\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 385614\n",
      "  training_iteration: 193\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">          5012.8</td><td style=\"text-align: right;\">385614</td><td style=\"text-align: right;\"> 20.5368</td><td style=\"text-align: right;\">                21.1</td><td style=\"text-align: right;\">               11.18</td><td style=\"text-align: right;\">             95.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 387612\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-53-31\n",
      "  done: false\n",
      "  episode_len_mean: 95.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.119999999999948\n",
      "  episode_reward_mean: 20.547099999999933\n",
      "  episode_reward_min: 11.180000000000012\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3770\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2448880638395037\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006138226270090878\n",
      "          policy_loss: 0.006634902111476376\n",
      "          total_loss: 0.024114970490336417\n",
      "          vf_explained_var: 0.9992703199386597\n",
      "          vf_loss: 0.026821471336075948\n",
      "    num_agent_steps_sampled: 387612\n",
      "    num_agent_steps_trained: 387612\n",
      "    num_steps_sampled: 387612\n",
      "    num_steps_trained: 387612\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87714285714286\n",
      "    ram_util_percent: 32.29428571428572\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04399805051275729\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.420748799580522\n",
      "    mean_inference_ms: 2.4302884858411757\n",
      "    mean_raw_obs_processing_ms: 1.9653282765906048\n",
      "  time_since_restore: 5037.360030174255\n",
      "  time_this_iter_s: 24.56463313102722\n",
      "  time_total_s: 5037.360030174255\n",
      "  timers:\n",
      "    learn_throughput: 1129.0\n",
      "    learn_time_ms: 1769.708\n",
      "    load_throughput: 58585.111\n",
      "    load_time_ms: 34.104\n",
      "    sample_throughput: 78.718\n",
      "    sample_time_ms: 25381.797\n",
      "    update_time_ms: 9.708\n",
      "  timestamp: 1636844011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 387612\n",
      "  training_iteration: 194\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">         5037.36</td><td style=\"text-align: right;\">387612</td><td style=\"text-align: right;\"> 20.5471</td><td style=\"text-align: right;\">               21.12</td><td style=\"text-align: right;\">               11.18</td><td style=\"text-align: right;\">              95.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 389610\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-53-54\n",
      "  done: false\n",
      "  episode_len_mean: 95.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.119999999999948\n",
      "  episode_reward_mean: 20.652799999999935\n",
      "  episode_reward_min: 12.790000000000015\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 3792\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2233990305945988\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009496242198408061\n",
      "          policy_loss: -0.005507788984548478\n",
      "          total_loss: 0.04041206325803484\n",
      "          vf_explained_var: 0.9984774589538574\n",
      "          vf_loss: 0.05334636791653576\n",
      "    num_agent_steps_sampled: 389610\n",
      "    num_agent_steps_trained: 389610\n",
      "    num_steps_sampled: 389610\n",
      "    num_steps_trained: 389610\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.47941176470589\n",
      "    ram_util_percent: 32.314705882352946\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044009573038206885\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.421219860807057\n",
      "    mean_inference_ms: 2.4304717258342565\n",
      "    mean_raw_obs_processing_ms: 1.9581337361301436\n",
      "  time_since_restore: 5061.014662027359\n",
      "  time_this_iter_s: 23.654631853103638\n",
      "  time_total_s: 5061.014662027359\n",
      "  timers:\n",
      "    learn_throughput: 1131.505\n",
      "    learn_time_ms: 1765.79\n",
      "    load_throughput: 58305.29\n",
      "    load_time_ms: 34.268\n",
      "    sample_throughput: 84.534\n",
      "    sample_time_ms: 23635.395\n",
      "    update_time_ms: 10.811\n",
      "  timestamp: 1636844034\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 389610\n",
      "  training_iteration: 195\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         5061.01</td><td style=\"text-align: right;\">389610</td><td style=\"text-align: right;\"> 20.6528</td><td style=\"text-align: right;\">               21.12</td><td style=\"text-align: right;\">               12.79</td><td style=\"text-align: right;\">             95.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 391608\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-54-19\n",
      "  done: false\n",
      "  episode_len_mean: 94.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.119999999999948\n",
      "  episode_reward_mean: 20.58019999999993\n",
      "  episode_reward_min: 12.790000000000015\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3813\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2396707250958396\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012656572571900308\n",
      "          policy_loss: 0.0020966202730224245\n",
      "          total_loss: 0.11522797124371642\n",
      "          vf_explained_var: 0.99701988697052\n",
      "          vf_loss: 0.11912067103244009\n",
      "    num_agent_steps_sampled: 391608\n",
      "    num_agent_steps_trained: 391608\n",
      "    num_steps_sampled: 391608\n",
      "    num_steps_trained: 391608\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.08285714285715\n",
      "    ram_util_percent: 32.28\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04401004635797461\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.424262662810598\n",
      "    mean_inference_ms: 2.430600425435752\n",
      "    mean_raw_obs_processing_ms: 1.9516022607951613\n",
      "  time_since_restore: 5085.461674690247\n",
      "  time_this_iter_s: 24.447012662887573\n",
      "  time_total_s: 5085.461674690247\n",
      "  timers:\n",
      "    learn_throughput: 1130.954\n",
      "    learn_time_ms: 1766.65\n",
      "    load_throughput: 58906.528\n",
      "    load_time_ms: 33.918\n",
      "    sample_throughput: 89.752\n",
      "    sample_time_ms: 22261.442\n",
      "    update_time_ms: 11.107\n",
      "  timestamp: 1636844059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 391608\n",
      "  training_iteration: 196\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   196</td><td style=\"text-align: right;\">         5085.46</td><td style=\"text-align: right;\">391608</td><td style=\"text-align: right;\"> 20.5802</td><td style=\"text-align: right;\">               21.12</td><td style=\"text-align: right;\">               12.79</td><td style=\"text-align: right;\">             94.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 393606\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-54-43\n",
      "  done: false\n",
      "  episode_len_mean: 94.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.119999999999948\n",
      "  episode_reward_mean: 20.56909999999993\n",
      "  episode_reward_min: 12.790000000000015\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3834\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2546740117527189\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006076281719002376\n",
      "          policy_loss: 0.008064871352343333\n",
      "          total_loss: 0.10189049967697689\n",
      "          vf_explained_var: 0.9971746802330017\n",
      "          vf_loss: 0.10329624481853984\n",
      "    num_agent_steps_sampled: 393606\n",
      "    num_agent_steps_trained: 393606\n",
      "    num_steps_sampled: 393606\n",
      "    num_steps_trained: 393606\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94117647058825\n",
      "    ram_util_percent: 32.25882352941176\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04401683385918286\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.428494397628388\n",
      "    mean_inference_ms: 2.430474856864876\n",
      "    mean_raw_obs_processing_ms: 1.944879964653896\n",
      "  time_since_restore: 5109.269906759262\n",
      "  time_this_iter_s: 23.808232069015503\n",
      "  time_total_s: 5109.269906759262\n",
      "  timers:\n",
      "    learn_throughput: 1130.107\n",
      "    learn_time_ms: 1767.974\n",
      "    load_throughput: 58827.052\n",
      "    load_time_ms: 33.964\n",
      "    sample_throughput: 89.911\n",
      "    sample_time_ms: 22222.097\n",
      "    update_time_ms: 10.415\n",
      "  timestamp: 1636844083\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 393606\n",
      "  training_iteration: 197\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">         5109.27</td><td style=\"text-align: right;\">393606</td><td style=\"text-align: right;\"> 20.5691</td><td style=\"text-align: right;\">               21.12</td><td style=\"text-align: right;\">               12.79</td><td style=\"text-align: right;\">             94.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 395604\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-55-07\n",
      "  done: false\n",
      "  episode_len_mean: 94.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.119999999999948\n",
      "  episode_reward_mean: 20.615999999999936\n",
      "  episode_reward_min: 16.739999999999924\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3855\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2694830627668472\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006935922830859735\n",
      "          policy_loss: -0.05411180935445286\n",
      "          total_loss: -0.009467691236308643\n",
      "          vf_explained_var: 0.9984966516494751\n",
      "          vf_loss: 0.05382763885538138\n",
      "    num_agent_steps_sampled: 395604\n",
      "    num_agent_steps_trained: 395604\n",
      "    num_steps_sampled: 395604\n",
      "    num_steps_trained: 395604\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.78823529411764\n",
      "    ram_util_percent: 32.26176470588236\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04403209344065474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.43133185834581\n",
      "    mean_inference_ms: 2.430573298959265\n",
      "    mean_raw_obs_processing_ms: 1.93852447902523\n",
      "  time_since_restore: 5133.370729446411\n",
      "  time_this_iter_s: 24.100822687149048\n",
      "  time_total_s: 5133.370729446411\n",
      "  timers:\n",
      "    learn_throughput: 1133.162\n",
      "    learn_time_ms: 1763.208\n",
      "    load_throughput: 58608.548\n",
      "    load_time_ms: 34.091\n",
      "    sample_throughput: 89.924\n",
      "    sample_time_ms: 22218.809\n",
      "    update_time_ms: 11.246\n",
      "  timestamp: 1636844107\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 395604\n",
      "  training_iteration: 198\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   198</td><td style=\"text-align: right;\">         5133.37</td><td style=\"text-align: right;\">395604</td><td style=\"text-align: right;\">  20.616</td><td style=\"text-align: right;\">               21.12</td><td style=\"text-align: right;\">               16.74</td><td style=\"text-align: right;\">             94.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 397602\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-55-30\n",
      "  done: false\n",
      "  episode_len_mean: 94.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.109999999999946\n",
      "  episode_reward_mean: 20.612899999999932\n",
      "  episode_reward_min: 16.739999999999924\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3876\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2911335394496009\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009472799024342175\n",
      "          policy_loss: -0.01951264606877452\n",
      "          total_loss: 0.02179146393956173\n",
      "          vf_explained_var: 0.9984651803970337\n",
      "          vf_loss: 0.04941983928549148\n",
      "    num_agent_steps_sampled: 397602\n",
      "    num_agent_steps_trained: 397602\n",
      "    num_steps_sampled: 397602\n",
      "    num_steps_trained: 397602\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89411764705882\n",
      "    ram_util_percent: 32.235294117647065\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04405802643673904\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.433079146148508\n",
      "    mean_inference_ms: 2.4306251050689136\n",
      "    mean_raw_obs_processing_ms: 1.9319983574922142\n",
      "  time_since_restore: 5157.042680263519\n",
      "  time_this_iter_s: 23.671950817108154\n",
      "  time_total_s: 5157.042680263519\n",
      "  timers:\n",
      "    learn_throughput: 1129.953\n",
      "    learn_time_ms: 1768.215\n",
      "    load_throughput: 60074.98\n",
      "    load_time_ms: 33.258\n",
      "    sample_throughput: 90.132\n",
      "    sample_time_ms: 22167.408\n",
      "    update_time_ms: 11.164\n",
      "  timestamp: 1636844130\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 397602\n",
      "  training_iteration: 199\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">         5157.04</td><td style=\"text-align: right;\">397602</td><td style=\"text-align: right;\"> 20.6129</td><td style=\"text-align: right;\">               21.11</td><td style=\"text-align: right;\">               16.74</td><td style=\"text-align: right;\">             94.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 399600\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-55-55\n",
      "  done: false\n",
      "  episode_len_mean: 95.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.109999999999946\n",
      "  episode_reward_mean: 20.60509999999993\n",
      "  episode_reward_min: 16.739999999999924\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3897\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2909392192250206\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008634652440178496\n",
      "          policy_loss: -0.04359191230365208\n",
      "          total_loss: 0.06558879690156097\n",
      "          vf_explained_var: 0.9967056512832642\n",
      "          vf_loss: 0.11771881075664645\n",
      "    num_agent_steps_sampled: 399600\n",
      "    num_agent_steps_trained: 399600\n",
      "    num_steps_sampled: 399600\n",
      "    num_steps_trained: 399600\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.83142857142859\n",
      "    ram_util_percent: 32.245714285714286\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04407327871618306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.43857473967324\n",
      "    mean_inference_ms: 2.430371058275092\n",
      "    mean_raw_obs_processing_ms: 1.9258512995207522\n",
      "  time_since_restore: 5181.498399019241\n",
      "  time_this_iter_s: 24.455718755722046\n",
      "  time_total_s: 5181.498399019241\n",
      "  timers:\n",
      "    learn_throughput: 1128.596\n",
      "    learn_time_ms: 1770.341\n",
      "    load_throughput: 60164.172\n",
      "    load_time_ms: 33.209\n",
      "    sample_throughput: 89.57\n",
      "    sample_time_ms: 22306.673\n",
      "    update_time_ms: 11.441\n",
      "  timestamp: 1636844155\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 399600\n",
      "  training_iteration: 200\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">          5181.5</td><td style=\"text-align: right;\">399600</td><td style=\"text-align: right;\"> 20.6051</td><td style=\"text-align: right;\">               21.11</td><td style=\"text-align: right;\">               16.74</td><td style=\"text-align: right;\">             95.47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 401598\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-56-33\n",
      "  done: false\n",
      "  episode_len_mean: 94.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.109999999999946\n",
      "  episode_reward_mean: 20.41469999999993\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 3919\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2814939936002097\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007592132735880148\n",
      "          policy_loss: -0.011625124585060846\n",
      "          total_loss: 0.7841971338327441\n",
      "          vf_explained_var: 0.9740095138549805\n",
      "          vf_loss: 0.8047936881049758\n",
      "    num_agent_steps_sampled: 401598\n",
      "    num_agent_steps_trained: 401598\n",
      "    num_steps_sampled: 401598\n",
      "    num_steps_trained: 401598\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.04\n",
      "    ram_util_percent: 32.16363636363636\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04409610508161341\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.440432505511616\n",
      "    mean_inference_ms: 2.4302474891819696\n",
      "    mean_raw_obs_processing_ms: 1.928551996423669\n",
      "  time_since_restore: 5219.769389867783\n",
      "  time_this_iter_s: 38.27099084854126\n",
      "  time_total_s: 5219.769389867783\n",
      "  timers:\n",
      "    learn_throughput: 1130.568\n",
      "    learn_time_ms: 1767.253\n",
      "    load_throughput: 60385.357\n",
      "    load_time_ms: 33.087\n",
      "    sample_throughput: 84.127\n",
      "    sample_time_ms: 23749.693\n",
      "    update_time_ms: 11.672\n",
      "  timestamp: 1636844193\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 401598\n",
      "  training_iteration: 201\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         5219.77</td><td style=\"text-align: right;\">401598</td><td style=\"text-align: right;\"> 20.4147</td><td style=\"text-align: right;\">               21.11</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             94.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 403596\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-57-28\n",
      "  done: false\n",
      "  episode_len_mean: 93.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.039999999999935\n",
      "  episode_reward_mean: 20.070599999999928\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 3942\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.248496541522798\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0026579919280527798\n",
      "          policy_loss: 0.011007638727980001\n",
      "          total_loss: 1.1432408090880406\n",
      "          vf_explained_var: 0.964552640914917\n",
      "          vf_loss: 1.1433725338606608\n",
      "    num_agent_steps_sampled: 403596\n",
      "    num_agent_steps_trained: 403596\n",
      "    num_steps_sampled: 403596\n",
      "    num_steps_trained: 403596\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.0922077922078\n",
      "    ram_util_percent: 31.949350649350656\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04411770437141815\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.44124381693532\n",
      "    mean_inference_ms: 2.43016285623321\n",
      "    mean_raw_obs_processing_ms: 1.9498919051395394\n",
      "  time_since_restore: 5274.2913184165955\n",
      "  time_this_iter_s: 54.521928548812866\n",
      "  time_total_s: 5274.2913184165955\n",
      "  timers:\n",
      "    learn_throughput: 1130.825\n",
      "    learn_time_ms: 1766.852\n",
      "    load_throughput: 61163.145\n",
      "    load_time_ms: 32.667\n",
      "    sample_throughput: 74.734\n",
      "    sample_time_ms: 26734.837\n",
      "    update_time_ms: 10.652\n",
      "  timestamp: 1636844248\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 403596\n",
      "  training_iteration: 202\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   202</td><td style=\"text-align: right;\">         5274.29</td><td style=\"text-align: right;\">403596</td><td style=\"text-align: right;\"> 20.0706</td><td style=\"text-align: right;\">               21.04</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             93.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 405594\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-57-53\n",
      "  done: false\n",
      "  episode_len_mean: 92.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.079999999999977\n",
      "  episode_reward_mean: 20.033699999999932\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3963\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.278113271508898\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006296365942425197\n",
      "          policy_loss: -0.08171697333455086\n",
      "          total_loss: -0.04421087469284733\n",
      "          vf_explained_var: 0.9985867738723755\n",
      "          vf_loss: 0.04869346393804465\n",
      "    num_agent_steps_sampled: 405594\n",
      "    num_agent_steps_trained: 405594\n",
      "    num_steps_sampled: 405594\n",
      "    num_steps_trained: 405594\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12777777777777\n",
      "    ram_util_percent: 31.852777777777778\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04413247627055096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.444894609439615\n",
      "    mean_inference_ms: 2.429990743129888\n",
      "    mean_raw_obs_processing_ms: 1.9692733253909522\n",
      "  time_since_restore: 5299.5665056705475\n",
      "  time_this_iter_s: 25.275187253952026\n",
      "  time_total_s: 5299.5665056705475\n",
      "  timers:\n",
      "    learn_throughput: 1128.911\n",
      "    learn_time_ms: 1769.848\n",
      "    load_throughput: 61573.623\n",
      "    load_time_ms: 32.449\n",
      "    sample_throughput: 74.405\n",
      "    sample_time_ms: 26852.98\n",
      "    update_time_ms: 11.784\n",
      "  timestamp: 1636844273\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 405594\n",
      "  training_iteration: 203\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   203</td><td style=\"text-align: right;\">         5299.57</td><td style=\"text-align: right;\">405594</td><td style=\"text-align: right;\"> 20.0337</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             92.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 407592\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-58-18\n",
      "  done: false\n",
      "  episode_len_mean: 92.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.079999999999977\n",
      "  episode_reward_mean: 20.038799999999934\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3984\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.284692385083153\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008259326619109601\n",
      "          policy_loss: -0.015011522244839441\n",
      "          total_loss: 0.007843636065011933\n",
      "          vf_explained_var: 0.9990639686584473\n",
      "          vf_loss: 0.033611438587485325\n",
      "    num_agent_steps_sampled: 407592\n",
      "    num_agent_steps_trained: 407592\n",
      "    num_steps_sampled: 407592\n",
      "    num_steps_trained: 407592\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03055555555555\n",
      "    ram_util_percent: 31.977777777777774\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04414309131120038\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.450379424607007\n",
      "    mean_inference_ms: 2.4298298998681336\n",
      "    mean_raw_obs_processing_ms: 1.9885948679417962\n",
      "  time_since_restore: 5324.560972929001\n",
      "  time_this_iter_s: 24.99446725845337\n",
      "  time_total_s: 5324.560972929001\n",
      "  timers:\n",
      "    learn_throughput: 1127.429\n",
      "    learn_time_ms: 1772.173\n",
      "    load_throughput: 60979.203\n",
      "    load_time_ms: 32.765\n",
      "    sample_throughput: 74.296\n",
      "    sample_time_ms: 26892.424\n",
      "    update_time_ms: 12.437\n",
      "  timestamp: 1636844298\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 407592\n",
      "  training_iteration: 204\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">         5324.56</td><td style=\"text-align: right;\">407592</td><td style=\"text-align: right;\"> 20.0388</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             92.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 409590\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-58-42\n",
      "  done: false\n",
      "  episode_len_mean: 93.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.079999999999977\n",
      "  episode_reward_mean: 20.29149999999993\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4004\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.306741243884677\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014053190039910238\n",
      "          policy_loss: -0.0018182567542507535\n",
      "          total_loss: 0.0257154714848314\n",
      "          vf_explained_var: 0.9989262223243713\n",
      "          vf_loss: 0.03704392832393447\n",
      "    num_agent_steps_sampled: 409590\n",
      "    num_agent_steps_trained: 409590\n",
      "    num_steps_sampled: 409590\n",
      "    num_steps_trained: 409590\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6818181818182\n",
      "    ram_util_percent: 32.021212121212116\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04415551517106971\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.45279379006666\n",
      "    mean_inference_ms: 2.4298131127482816\n",
      "    mean_raw_obs_processing_ms: 1.9987176869494738\n",
      "  time_since_restore: 5347.921821594238\n",
      "  time_this_iter_s: 23.360848665237427\n",
      "  time_total_s: 5347.921821594238\n",
      "  timers:\n",
      "    learn_throughput: 1127.329\n",
      "    learn_time_ms: 1772.331\n",
      "    load_throughput: 61176.361\n",
      "    load_time_ms: 32.66\n",
      "    sample_throughput: 74.374\n",
      "    sample_time_ms: 26864.046\n",
      "    update_time_ms: 11.343\n",
      "  timestamp: 1636844322\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 409590\n",
      "  training_iteration: 205\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   205</td><td style=\"text-align: right;\">         5347.92</td><td style=\"text-align: right;\">409590</td><td style=\"text-align: right;\"> 20.2915</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             93.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 411588\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-59-05\n",
      "  done: false\n",
      "  episode_len_mean: 93.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.079999999999977\n",
      "  episode_reward_mean: 20.30729999999993\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4026\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.252884506611597\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012750960386963734\n",
      "          policy_loss: 0.0010858001719628062\n",
      "          total_loss: 0.06429730245089602\n",
      "          vf_explained_var: 0.9979372024536133\n",
      "          vf_loss: 0.07251276086040195\n",
      "    num_agent_steps_sampled: 411588\n",
      "    num_agent_steps_trained: 411588\n",
      "    num_steps_sampled: 411588\n",
      "    num_steps_trained: 411588\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.08857142857143\n",
      "    ram_util_percent: 32.06\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044158440801238256\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.45689262130989\n",
      "    mean_inference_ms: 2.4298335281554597\n",
      "    mean_raw_obs_processing_ms: 2.009769987743178\n",
      "  time_since_restore: 5371.791102647781\n",
      "  time_this_iter_s: 23.86928105354309\n",
      "  time_total_s: 5371.791102647781\n",
      "  timers:\n",
      "    learn_throughput: 1127.447\n",
      "    learn_time_ms: 1772.146\n",
      "    load_throughput: 60507.261\n",
      "    load_time_ms: 33.021\n",
      "    sample_throughput: 74.532\n",
      "    sample_time_ms: 26807.176\n",
      "    update_time_ms: 10.409\n",
      "  timestamp: 1636844345\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 411588\n",
      "  training_iteration: 206\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">         5371.79</td><td style=\"text-align: right;\">411588</td><td style=\"text-align: right;\"> 20.3073</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             93.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 413586\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-59-30\n",
      "  done: false\n",
      "  episode_len_mean: 95.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.079999999999977\n",
      "  episode_reward_mean: 20.67759999999993\n",
      "  episode_reward_min: 17.16000000000001\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4045\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2852584112258185\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00939681177043456\n",
      "          policy_loss: -0.008620868765172504\n",
      "          total_loss: 0.02080300815758251\n",
      "          vf_explained_var: 0.9989240169525146\n",
      "          vf_loss: 0.03989789232700353\n",
      "    num_agent_steps_sampled: 413586\n",
      "    num_agent_steps_trained: 413586\n",
      "    num_steps_sampled: 413586\n",
      "    num_steps_trained: 413586\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1029411764706\n",
      "    ram_util_percent: 32.129411764705885\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04414645198884352\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.46777632806168\n",
      "    mean_inference_ms: 2.429291909609756\n",
      "    mean_raw_obs_processing_ms: 2.0036869711084417\n",
      "  time_since_restore: 5395.939959526062\n",
      "  time_this_iter_s: 24.14885687828064\n",
      "  time_total_s: 5395.939959526062\n",
      "  timers:\n",
      "    learn_throughput: 1124.163\n",
      "    learn_time_ms: 1777.322\n",
      "    load_throughput: 60380.049\n",
      "    load_time_ms: 33.09\n",
      "    sample_throughput: 74.457\n",
      "    sample_time_ms: 26834.362\n",
      "    update_time_ms: 11.728\n",
      "  timestamp: 1636844370\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 413586\n",
      "  training_iteration: 207\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   207</td><td style=\"text-align: right;\">         5395.94</td><td style=\"text-align: right;\">413586</td><td style=\"text-align: right;\"> 20.6776</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">               17.16</td><td style=\"text-align: right;\">             95.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 415584\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_22-59-53\n",
      "  done: false\n",
      "  episode_len_mean: 96.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.724399999999925\n",
      "  episode_reward_min: 18.319999999999908\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4065\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2033189308075678\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014727071852304255\n",
      "          policy_loss: 0.001399781537197885\n",
      "          total_loss: 0.10306764138596398\n",
      "          vf_explained_var: 0.9965757131576538\n",
      "          vf_loss: 0.10997325941210702\n",
      "    num_agent_steps_sampled: 415584\n",
      "    num_agent_steps_trained: 415584\n",
      "    num_steps_sampled: 415584\n",
      "    num_steps_trained: 415584\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.46363636363637\n",
      "    ram_util_percent: 32.2060606060606\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04414170205903782\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.468811530311758\n",
      "    mean_inference_ms: 2.4293050793847657\n",
      "    mean_raw_obs_processing_ms: 1.9975144642852753\n",
      "  time_since_restore: 5418.9407460689545\n",
      "  time_this_iter_s: 23.000786542892456\n",
      "  time_total_s: 5418.9407460689545\n",
      "  timers:\n",
      "    learn_throughput: 1125.896\n",
      "    learn_time_ms: 1774.587\n",
      "    load_throughput: 59698.037\n",
      "    load_time_ms: 33.468\n",
      "    sample_throughput: 74.755\n",
      "    sample_time_ms: 26727.48\n",
      "    update_time_ms: 10.974\n",
      "  timestamp: 1636844393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 415584\n",
      "  training_iteration: 208\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">         5418.94</td><td style=\"text-align: right;\">415584</td><td style=\"text-align: right;\"> 20.7244</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               18.32</td><td style=\"text-align: right;\">             96.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 417582\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-00-16\n",
      "  done: false\n",
      "  episode_len_mean: 97.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.678199999999926\n",
      "  episode_reward_min: 16.839999999999947\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4086\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2769645004045396\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010768378282759365\n",
      "          policy_loss: -0.011039703534472556\n",
      "          total_loss: 0.025971368469652676\n",
      "          vf_explained_var: 0.9985650777816772\n",
      "          vf_loss: 0.04705497245969517\n",
      "    num_agent_steps_sampled: 417582\n",
      "    num_agent_steps_trained: 417582\n",
      "    num_steps_sampled: 417582\n",
      "    num_steps_trained: 417582\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79696969696968\n",
      "    ram_util_percent: 32.25757575757576\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04414794458223371\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.46784220915416\n",
      "    mean_inference_ms: 2.4293568855770182\n",
      "    mean_raw_obs_processing_ms: 1.9910819565925428\n",
      "  time_since_restore: 5442.210607051849\n",
      "  time_this_iter_s: 23.269860982894897\n",
      "  time_total_s: 5442.210607051849\n",
      "  timers:\n",
      "    learn_throughput: 1127.067\n",
      "    learn_time_ms: 1772.743\n",
      "    load_throughput: 58534.206\n",
      "    load_time_ms: 34.134\n",
      "    sample_throughput: 74.865\n",
      "    sample_time_ms: 26688.025\n",
      "    update_time_ms: 11.296\n",
      "  timestamp: 1636844416\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 417582\n",
      "  training_iteration: 209\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">         5442.21</td><td style=\"text-align: right;\">417582</td><td style=\"text-align: right;\"> 20.6782</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               16.84</td><td style=\"text-align: right;\">             97.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 419580\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-00-40\n",
      "  done: false\n",
      "  episode_len_mean: 97.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.647599999999926\n",
      "  episode_reward_min: 16.70999999999995\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4107\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3002895922887894\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01679548035699946\n",
      "          policy_loss: -0.010485743518386569\n",
      "          total_loss: 0.08628491730917068\n",
      "          vf_explained_var: 0.9969220757484436\n",
      "          vf_loss: 0.10552219813246103\n",
      "    num_agent_steps_sampled: 419580\n",
      "    num_agent_steps_trained: 419580\n",
      "    num_steps_sampled: 419580\n",
      "    num_steps_trained: 419580\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77058823529413\n",
      "    ram_util_percent: 32.27058823529412\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04415580659841146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.46662917269275\n",
      "    mean_inference_ms: 2.4294842400104577\n",
      "    mean_raw_obs_processing_ms: 1.9848821608626315\n",
      "  time_since_restore: 5466.176973581314\n",
      "  time_this_iter_s: 23.96636652946472\n",
      "  time_total_s: 5466.176973581314\n",
      "  timers:\n",
      "    learn_throughput: 1117.78\n",
      "    learn_time_ms: 1787.471\n",
      "    load_throughput: 58569.348\n",
      "    load_time_ms: 34.113\n",
      "    sample_throughput: 75.049\n",
      "    sample_time_ms: 26622.497\n",
      "    update_time_ms: 12.885\n",
      "  timestamp: 1636844440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 419580\n",
      "  training_iteration: 210\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   210</td><td style=\"text-align: right;\">         5466.18</td><td style=\"text-align: right;\">419580</td><td style=\"text-align: right;\"> 20.6476</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               16.71</td><td style=\"text-align: right;\">             97.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 421578\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-01-04\n",
      "  done: false\n",
      "  episode_len_mean: 97.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.47269999999993\n",
      "  episode_reward_min: 10.740000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4127\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3049848238627115\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.019989684120448367\n",
      "          policy_loss: -0.017935525342112495\n",
      "          total_loss: 0.4086260495529998\n",
      "          vf_explained_var: 0.9849757552146912\n",
      "          vf_loss: 0.4345515325221987\n",
      "    num_agent_steps_sampled: 421578\n",
      "    num_agent_steps_trained: 421578\n",
      "    num_steps_sampled: 421578\n",
      "    num_steps_trained: 421578\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85\n",
      "    ram_util_percent: 32.32352941176472\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044160896673359214\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.467863767589375\n",
      "    mean_inference_ms: 2.4293297595296948\n",
      "    mean_raw_obs_processing_ms: 1.9784845997560712\n",
      "  time_since_restore: 5489.632429122925\n",
      "  time_this_iter_s: 23.455455541610718\n",
      "  time_total_s: 5489.632429122925\n",
      "  timers:\n",
      "    learn_throughput: 1116.159\n",
      "    learn_time_ms: 1790.068\n",
      "    load_throughput: 59159.153\n",
      "    load_time_ms: 33.773\n",
      "    sample_throughput: 79.476\n",
      "    sample_time_ms: 25139.563\n",
      "    update_time_ms: 12.418\n",
      "  timestamp: 1636844464\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 421578\n",
      "  training_iteration: 211\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   211</td><td style=\"text-align: right;\">         5489.63</td><td style=\"text-align: right;\">421578</td><td style=\"text-align: right;\"> 20.4727</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">             97.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 423576\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-01-26\n",
      "  done: false\n",
      "  episode_len_mean: 97.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.517699999999927\n",
      "  episode_reward_min: 10.740000000000016\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4148\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2481354622613816\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011114490701591616\n",
      "          policy_loss: -0.029461252370050976\n",
      "          total_loss: -0.0007699346258526757\n",
      "          vf_explained_var: 0.9989082217216492\n",
      "          vf_loss: 0.038359318753438336\n",
      "    num_agent_steps_sampled: 423576\n",
      "    num_agent_steps_trained: 423576\n",
      "    num_steps_sampled: 423576\n",
      "    num_steps_trained: 423576\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.46666666666667\n",
      "    ram_util_percent: 32.31212121212121\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04417635970131025\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.462136327958305\n",
      "    mean_inference_ms: 2.4295872900976763\n",
      "    mean_raw_obs_processing_ms: 1.9723643307268701\n",
      "  time_since_restore: 5512.511325836182\n",
      "  time_this_iter_s: 22.878896713256836\n",
      "  time_total_s: 5512.511325836182\n",
      "  timers:\n",
      "    learn_throughput: 1115.002\n",
      "    learn_time_ms: 1791.925\n",
      "    load_throughput: 58961.526\n",
      "    load_time_ms: 33.887\n",
      "    sample_throughput: 90.93\n",
      "    sample_time_ms: 21973.044\n",
      "    update_time_ms: 12.622\n",
      "  timestamp: 1636844486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 423576\n",
      "  training_iteration: 212\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">         5512.51</td><td style=\"text-align: right;\">423576</td><td style=\"text-align: right;\"> 20.5177</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">             97.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 425574\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-01-51\n",
      "  done: false\n",
      "  episode_len_mean: 97.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.129999999999963\n",
      "  episode_reward_mean: 20.486799999999924\n",
      "  episode_reward_min: 10.740000000000016\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4169\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2319930757795061\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009269710960033734\n",
      "          policy_loss: -0.06782007566874936\n",
      "          total_loss: -0.009401091529677311\n",
      "          vf_explained_var: 0.9979977011680603\n",
      "          vf_loss: 0.06839252097443456\n",
      "    num_agent_steps_sampled: 425574\n",
      "    num_agent_steps_trained: 425574\n",
      "    num_steps_sampled: 425574\n",
      "    num_steps_trained: 425574\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.75142857142856\n",
      "    ram_util_percent: 32.322857142857146\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044184836067127586\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.461760079385023\n",
      "    mean_inference_ms: 2.4295779555335226\n",
      "    mean_raw_obs_processing_ms: 1.966272246621969\n",
      "  time_since_restore: 5537.523809909821\n",
      "  time_this_iter_s: 25.012484073638916\n",
      "  time_total_s: 5537.523809909821\n",
      "  timers:\n",
      "    learn_throughput: 1114.89\n",
      "    learn_time_ms: 1792.105\n",
      "    load_throughput: 59030.595\n",
      "    load_time_ms: 33.847\n",
      "    sample_throughput: 91.034\n",
      "    sample_time_ms: 21947.881\n",
      "    update_time_ms: 11.284\n",
      "  timestamp: 1636844511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 425574\n",
      "  training_iteration: 213\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   213</td><td style=\"text-align: right;\">         5537.52</td><td style=\"text-align: right;\">425574</td><td style=\"text-align: right;\"> 20.4868</td><td style=\"text-align: right;\">               21.13</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">             97.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 427572\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-02-16\n",
      "  done: false\n",
      "  episode_len_mean: 96.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.129999999999963\n",
      "  episode_reward_mean: 20.471299999999932\n",
      "  episode_reward_min: 10.740000000000016\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4190\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1966089770907447\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.018160965999105702\n",
      "          policy_loss: -0.004924264408293224\n",
      "          total_loss: 0.07283722591542062\n",
      "          vf_explained_var: 0.9976999759674072\n",
      "          vf_loss: 0.0851305842266551\n",
      "    num_agent_steps_sampled: 427572\n",
      "    num_agent_steps_trained: 427572\n",
      "    num_steps_sampled: 427572\n",
      "    num_steps_trained: 427572\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94000000000003\n",
      "    ram_util_percent: 32.291428571428575\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04418343744019507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.46283559810343\n",
      "    mean_inference_ms: 2.4295264445928457\n",
      "    mean_raw_obs_processing_ms: 1.960253573108992\n",
      "  time_since_restore: 5561.654281616211\n",
      "  time_this_iter_s: 24.13047170639038\n",
      "  time_total_s: 5561.654281616211\n",
      "  timers:\n",
      "    learn_throughput: 1115.342\n",
      "    learn_time_ms: 1791.379\n",
      "    load_throughput: 58437.265\n",
      "    load_time_ms: 34.191\n",
      "    sample_throughput: 91.396\n",
      "    sample_time_ms: 21860.944\n",
      "    update_time_ms: 12.133\n",
      "  timestamp: 1636844536\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 427572\n",
      "  training_iteration: 214\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   214</td><td style=\"text-align: right;\">         5561.65</td><td style=\"text-align: right;\">427572</td><td style=\"text-align: right;\"> 20.4713</td><td style=\"text-align: right;\">               21.13</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">             96.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 429570\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-02-40\n",
      "  done: false\n",
      "  episode_len_mean: 96.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.129999999999963\n",
      "  episode_reward_mean: 20.603999999999928\n",
      "  episode_reward_min: 10.740000000000016\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4211\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2874976776895068\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009057510788622719\n",
      "          policy_loss: -0.011562677579266684\n",
      "          total_loss: 0.0001419966242143086\n",
      "          vf_explained_var: 0.9993030428886414\n",
      "          vf_loss: 0.022286967720304217\n",
      "    num_agent_steps_sampled: 429570\n",
      "    num_agent_steps_trained: 429570\n",
      "    num_steps_sampled: 429570\n",
      "    num_steps_trained: 429570\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85882352941178\n",
      "    ram_util_percent: 32.25294117647059\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04418286986394227\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.4641052195763\n",
      "    mean_inference_ms: 2.429466114931763\n",
      "    mean_raw_obs_processing_ms: 1.9543191755901526\n",
      "  time_since_restore: 5585.913789272308\n",
      "  time_this_iter_s: 24.259507656097412\n",
      "  time_total_s: 5585.913789272308\n",
      "  timers:\n",
      "    learn_throughput: 1116.004\n",
      "    learn_time_ms: 1790.315\n",
      "    load_throughput: 58153.524\n",
      "    load_time_ms: 34.357\n",
      "    sample_throughput: 91.019\n",
      "    sample_time_ms: 21951.449\n",
      "    update_time_ms: 12.504\n",
      "  timestamp: 1636844560\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 429570\n",
      "  training_iteration: 215\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   215</td><td style=\"text-align: right;\">         5585.91</td><td style=\"text-align: right;\">429570</td><td style=\"text-align: right;\">  20.604</td><td style=\"text-align: right;\">               21.13</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">             96.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 431568\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-03-04\n",
      "  done: false\n",
      "  episode_len_mean: 96.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.129999999999963\n",
      "  episode_reward_mean: 20.746499999999926\n",
      "  episode_reward_min: 16.559999999999953\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4232\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3371946437018258\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008261226669106123\n",
      "          policy_loss: -0.029888963069589367\n",
      "          total_loss: -0.02291886315991481\n",
      "          vf_explained_var: 0.9994333386421204\n",
      "          vf_loss: 0.018250921925175047\n",
      "    num_agent_steps_sampled: 431568\n",
      "    num_agent_steps_trained: 431568\n",
      "    num_steps_sampled: 431568\n",
      "    num_steps_trained: 431568\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08611111111112\n",
      "    ram_util_percent: 32.25277777777778\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044184708316796835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.465642314087486\n",
      "    mean_inference_ms: 2.429538718481673\n",
      "    mean_raw_obs_processing_ms: 1.9486497746328693\n",
      "  time_since_restore: 5610.413044452667\n",
      "  time_this_iter_s: 24.499255180358887\n",
      "  time_total_s: 5610.413044452667\n",
      "  timers:\n",
      "    learn_throughput: 1116.23\n",
      "    learn_time_ms: 1789.954\n",
      "    load_throughput: 58833.205\n",
      "    load_time_ms: 33.96\n",
      "    sample_throughput: 90.757\n",
      "    sample_time_ms: 22014.728\n",
      "    update_time_ms: 12.699\n",
      "  timestamp: 1636844584\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 431568\n",
      "  training_iteration: 216\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   216</td><td style=\"text-align: right;\">         5610.41</td><td style=\"text-align: right;\">431568</td><td style=\"text-align: right;\"> 20.7465</td><td style=\"text-align: right;\">               21.13</td><td style=\"text-align: right;\">               16.56</td><td style=\"text-align: right;\">             96.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 433566\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-03-28\n",
      "  done: false\n",
      "  episode_len_mean: 95.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.129999999999963\n",
      "  episode_reward_mean: 20.78979999999993\n",
      "  episode_reward_min: 16.599999999999977\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4252\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2859829857235863\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015060631152203963\n",
      "          policy_loss: -0.022999151122002376\n",
      "          total_loss: 0.00030836258970555805\n",
      "          vf_explained_var: 0.99921715259552\n",
      "          vf_loss: 0.032355120004199094\n",
      "    num_agent_steps_sampled: 433566\n",
      "    num_agent_steps_trained: 433566\n",
      "    num_steps_sampled: 433566\n",
      "    num_steps_trained: 433566\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01176470588236\n",
      "    ram_util_percent: 32.23823529411764\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04418259244848446\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.46902866462428\n",
      "    mean_inference_ms: 2.4295164921913557\n",
      "    mean_raw_obs_processing_ms: 1.943137410288444\n",
      "  time_since_restore: 5634.32598233223\n",
      "  time_this_iter_s: 23.912937879562378\n",
      "  time_total_s: 5634.32598233223\n",
      "  timers:\n",
      "    learn_throughput: 1120.23\n",
      "    learn_time_ms: 1783.563\n",
      "    load_throughput: 59530.865\n",
      "    load_time_ms: 33.562\n",
      "    sample_throughput: 90.819\n",
      "    sample_time_ms: 21999.845\n",
      "    update_time_ms: 11.159\n",
      "  timestamp: 1636844608\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 433566\n",
      "  training_iteration: 217\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   217</td><td style=\"text-align: right;\">         5634.33</td><td style=\"text-align: right;\">433566</td><td style=\"text-align: right;\"> 20.7898</td><td style=\"text-align: right;\">               21.13</td><td style=\"text-align: right;\">                16.6</td><td style=\"text-align: right;\">             95.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 435564\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-04-08\n",
      "  done: false\n",
      "  episode_len_mean: 96.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999933\n",
      "  episode_reward_mean: 20.790599999999927\n",
      "  episode_reward_min: 16.959999999999933\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4271\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3088393177304949\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00915684656222889\n",
      "          policy_loss: -0.08540358719016825\n",
      "          total_loss: -0.0773405751834313\n",
      "          vf_explained_var: 0.9994468092918396\n",
      "          vf_loss: 0.01883357836687494\n",
      "    num_agent_steps_sampled: 435564\n",
      "    num_agent_steps_trained: 435564\n",
      "    num_steps_sampled: 435564\n",
      "    num_steps_trained: 435564\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.92678571428571\n",
      "    ram_util_percent: 32.1\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04417250857235329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.47594113027519\n",
      "    mean_inference_ms: 2.429198231655738\n",
      "    mean_raw_obs_processing_ms: 1.9454482309626604\n",
      "  time_since_restore: 5674.024097442627\n",
      "  time_this_iter_s: 39.69811511039734\n",
      "  time_total_s: 5674.024097442627\n",
      "  timers:\n",
      "    learn_throughput: 1116.797\n",
      "    learn_time_ms: 1789.045\n",
      "    load_throughput: 60152.253\n",
      "    load_time_ms: 33.216\n",
      "    sample_throughput: 84.429\n",
      "    sample_time_ms: 23664.806\n",
      "    update_time_ms: 11.076\n",
      "  timestamp: 1636844648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 435564\n",
      "  training_iteration: 218\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">         5674.02</td><td style=\"text-align: right;\">435564</td><td style=\"text-align: right;\"> 20.7906</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               16.96</td><td style=\"text-align: right;\">             96.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 437562\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-04-49\n",
      "  done: false\n",
      "  episode_len_mean: 96.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999933\n",
      "  episode_reward_mean: 20.612899999999925\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4293\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2058549097606115\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01239050014019572\n",
      "          policy_loss: 0.004866285342723131\n",
      "          total_loss: 0.8401114689008821\n",
      "          vf_explained_var: 0.9777026772499084\n",
      "          vf_loss: 0.8441673815959976\n",
      "    num_agent_steps_sampled: 437562\n",
      "    num_agent_steps_trained: 437562\n",
      "    num_steps_sampled: 437562\n",
      "    num_steps_trained: 437562\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.1457627118644\n",
      "    ram_util_percent: 31.89491525423729\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04416857592111964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.47653602767522\n",
      "    mean_inference_ms: 2.4292508642239583\n",
      "    mean_raw_obs_processing_ms: 1.956492546926044\n",
      "  time_since_restore: 5714.93799829483\n",
      "  time_this_iter_s: 40.91390085220337\n",
      "  time_total_s: 5714.93799829483\n",
      "  timers:\n",
      "    learn_throughput: 1115.702\n",
      "    learn_time_ms: 1790.801\n",
      "    load_throughput: 60414.001\n",
      "    load_time_ms: 33.072\n",
      "    sample_throughput: 78.574\n",
      "    sample_time_ms: 25428.214\n",
      "    update_time_ms: 10.714\n",
      "  timestamp: 1636844689\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 437562\n",
      "  training_iteration: 219\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   219</td><td style=\"text-align: right;\">         5714.94</td><td style=\"text-align: right;\">437562</td><td style=\"text-align: right;\"> 20.6129</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 439560\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-05-26\n",
      "  done: false\n",
      "  episode_len_mean: 96.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999933\n",
      "  episode_reward_mean: 20.378599999999928\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4312\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4140177283968245\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008696141384880885\n",
      "          policy_loss: -0.04563971232800257\n",
      "          total_loss: 0.11603626949446542\n",
      "          vf_explained_var: 0.9949465990066528\n",
      "          vf_loss: 0.1736149471918387\n",
      "    num_agent_steps_sampled: 439560\n",
      "    num_agent_steps_trained: 439560\n",
      "    num_steps_sampled: 439560\n",
      "    num_steps_trained: 439560\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.00754716981132\n",
      "    ram_util_percent: 31.84905660377358\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044159042028392964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.476826749926563\n",
      "    mean_inference_ms: 2.4291010301720593\n",
      "    mean_raw_obs_processing_ms: 1.9724518687033104\n",
      "  time_since_restore: 5752.175993919373\n",
      "  time_this_iter_s: 37.237995624542236\n",
      "  time_total_s: 5752.175993919373\n",
      "  timers:\n",
      "    learn_throughput: 1125.456\n",
      "    learn_time_ms: 1775.281\n",
      "    load_throughput: 60428.595\n",
      "    load_time_ms: 33.064\n",
      "    sample_throughput: 74.63\n",
      "    sample_time_ms: 26772.202\n",
      "    update_time_ms: 9.903\n",
      "  timestamp: 1636844726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 439560\n",
      "  training_iteration: 220\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   220</td><td style=\"text-align: right;\">         5752.18</td><td style=\"text-align: right;\">439560</td><td style=\"text-align: right;\"> 20.3786</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 441558\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-05-50\n",
      "  done: false\n",
      "  episode_len_mean: 98.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.029999999999944\n",
      "  episode_reward_mean: 20.321299999999923\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4333\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3316350374902999\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012336262417109702\n",
      "          policy_loss: -0.010524643593955607\n",
      "          total_loss: 0.022357244412636472\n",
      "          vf_explained_var: 0.9987398982048035\n",
      "          vf_loss: 0.043075622937508995\n",
      "    num_agent_steps_sampled: 441558\n",
      "    num_agent_steps_trained: 441558\n",
      "    num_steps_sampled: 441558\n",
      "    num_steps_trained: 441558\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7529411764706\n",
      "    ram_util_percent: 31.714705882352945\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04414888966585366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.474058988156475\n",
      "    mean_inference_ms: 2.428999050651159\n",
      "    mean_raw_obs_processing_ms: 1.9901701494436912\n",
      "  time_since_restore: 5775.899199485779\n",
      "  time_this_iter_s: 23.72320556640625\n",
      "  time_total_s: 5775.899199485779\n",
      "  timers:\n",
      "    learn_throughput: 1125.347\n",
      "    learn_time_ms: 1775.452\n",
      "    load_throughput: 59365.636\n",
      "    load_time_ms: 33.656\n",
      "    sample_throughput: 74.56\n",
      "    sample_time_ms: 26797.259\n",
      "    update_time_ms: 10.352\n",
      "  timestamp: 1636844750\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 441558\n",
      "  training_iteration: 221\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   221</td><td style=\"text-align: right;\">          5775.9</td><td style=\"text-align: right;\">441558</td><td style=\"text-align: right;\"> 20.3213</td><td style=\"text-align: right;\">               21.03</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 443556\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-06-13\n",
      "  done: false\n",
      "  episode_len_mean: 99.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.32549999999992\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4353\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3434124100775946\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009299920823413872\n",
      "          policy_loss: -0.006772984311516796\n",
      "          total_loss: 0.007073263744158404\n",
      "          vf_explained_var: 0.9992102980613708\n",
      "          vf_loss: 0.024926327517078746\n",
      "    num_agent_steps_sampled: 443556\n",
      "    num_agent_steps_trained: 443556\n",
      "    num_steps_sampled: 443556\n",
      "    num_steps_trained: 443556\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.703125\n",
      "    ram_util_percent: 31.8375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04414333504136162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.47000394455636\n",
      "    mean_inference_ms: 2.4289143494862744\n",
      "    mean_raw_obs_processing_ms: 2.0059091975307486\n",
      "  time_since_restore: 5798.544703245163\n",
      "  time_this_iter_s: 22.645503759384155\n",
      "  time_total_s: 5798.544703245163\n",
      "  timers:\n",
      "    learn_throughput: 1124.859\n",
      "    learn_time_ms: 1776.222\n",
      "    load_throughput: 57638.278\n",
      "    load_time_ms: 34.664\n",
      "    sample_throughput: 74.633\n",
      "    sample_time_ms: 26770.958\n",
      "    update_time_ms: 11.554\n",
      "  timestamp: 1636844773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 443556\n",
      "  training_iteration: 222\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   222</td><td style=\"text-align: right;\">         5798.54</td><td style=\"text-align: right;\">443556</td><td style=\"text-align: right;\"> 20.3255</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 445554\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-06-36\n",
      "  done: false\n",
      "  episode_len_mean: 99.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.332499999999918\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4372\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.315574053923289\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014020193717212465\n",
      "          policy_loss: -0.011960559759643816\n",
      "          total_loss: 0.0080210261401676\n",
      "          vf_explained_var: 0.9990760684013367\n",
      "          vf_loss: 0.029588462769364318\n",
      "    num_agent_steps_sampled: 445554\n",
      "    num_agent_steps_trained: 445554\n",
      "    num_steps_sampled: 445554\n",
      "    num_steps_trained: 445554\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73333333333335\n",
      "    ram_util_percent: 32.02424242424243\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044139191291923695\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.465279598305802\n",
      "    mean_inference_ms: 2.428822132968912\n",
      "    mean_raw_obs_processing_ms: 2.0140951787715\n",
      "  time_since_restore: 5821.338260889053\n",
      "  time_this_iter_s: 22.79355764389038\n",
      "  time_total_s: 5821.338260889053\n",
      "  timers:\n",
      "    learn_throughput: 1123.826\n",
      "    learn_time_ms: 1777.855\n",
      "    load_throughput: 57345.699\n",
      "    load_time_ms: 34.841\n",
      "    sample_throughput: 75.266\n",
      "    sample_time_ms: 26545.853\n",
      "    update_time_ms: 13.175\n",
      "  timestamp: 1636844796\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 445554\n",
      "  training_iteration: 223\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   223</td><td style=\"text-align: right;\">         5821.34</td><td style=\"text-align: right;\">445554</td><td style=\"text-align: right;\"> 20.3325</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 447552\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-06-58\n",
      "  done: false\n",
      "  episode_len_mean: 101.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.531999999999922\n",
      "  episode_reward_min: -0.01\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4391\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3056091694604783\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017426840072202892\n",
      "          policy_loss: -0.0074750275927640145\n",
      "          total_loss: 0.018008525186173973\n",
      "          vf_explained_var: 0.999004065990448\n",
      "          vf_loss: 0.034128477384469336\n",
      "    num_agent_steps_sampled: 447552\n",
      "    num_agent_steps_trained: 447552\n",
      "    num_steps_sampled: 447552\n",
      "    num_steps_trained: 447552\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95625\n",
      "    ram_util_percent: 32.1375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04413116265392104\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.46131278074651\n",
      "    mean_inference_ms: 2.428673248090682\n",
      "    mean_raw_obs_processing_ms: 2.016496672750559\n",
      "  time_since_restore: 5844.086426019669\n",
      "  time_this_iter_s: 22.748165130615234\n",
      "  time_total_s: 5844.086426019669\n",
      "  timers:\n",
      "    learn_throughput: 1125.713\n",
      "    learn_time_ms: 1774.874\n",
      "    load_throughput: 57357.787\n",
      "    load_time_ms: 34.834\n",
      "    sample_throughput: 75.65\n",
      "    sample_time_ms: 26411.205\n",
      "    update_time_ms: 12.787\n",
      "  timestamp: 1636844818\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 447552\n",
      "  training_iteration: 224\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">         5844.09</td><td style=\"text-align: right;\">447552</td><td style=\"text-align: right;\">  20.532</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               -0.01</td><td style=\"text-align: right;\">            101.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 449550\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-07-21\n",
      "  done: false\n",
      "  episode_len_mean: 101.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.68749999999992\n",
      "  episode_reward_min: 18.649999999999903\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4412\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2731538925852095\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01507803987971334\n",
      "          policy_loss: 0.01847659959679558\n",
      "          total_loss: 0.06735974454454013\n",
      "          vf_explained_var: 0.9983228445053101\n",
      "          vf_loss: 0.05779805531547893\n",
      "    num_agent_steps_sampled: 449550\n",
      "    num_agent_steps_trained: 449550\n",
      "    num_steps_sampled: 449550\n",
      "    num_steps_trained: 449550\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14242424242424\n",
      "    ram_util_percent: 32.242424242424235\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044124507297782306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.458667366392383\n",
      "    mean_inference_ms: 2.4285061766078853\n",
      "    mean_raw_obs_processing_ms: 2.009953337197768\n",
      "  time_since_restore: 5867.08780169487\n",
      "  time_this_iter_s: 23.001375675201416\n",
      "  time_total_s: 5867.08780169487\n",
      "  timers:\n",
      "    learn_throughput: 1126.251\n",
      "    learn_time_ms: 1774.028\n",
      "    load_throughput: 57442.081\n",
      "    load_time_ms: 34.783\n",
      "    sample_throughput: 76.009\n",
      "    sample_time_ms: 26286.404\n",
      "    update_time_ms: 12.558\n",
      "  timestamp: 1636844841\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 449550\n",
      "  training_iteration: 225\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   225</td><td style=\"text-align: right;\">         5867.09</td><td style=\"text-align: right;\">449550</td><td style=\"text-align: right;\"> 20.6875</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               18.65</td><td style=\"text-align: right;\">            101.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 451548\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-07-44\n",
      "  done: false\n",
      "  episode_len_mean: 101.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.68769999999992\n",
      "  episode_reward_min: 18.649999999999903\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4431\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.357738295055571\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008421629734432725\n",
      "          policy_loss: -0.08334778485198815\n",
      "          total_loss: -0.05183669321593784\n",
      "          vf_explained_var: 0.9988490343093872\n",
      "          vf_loss: 0.04295674853159913\n",
      "    num_agent_steps_sampled: 451548\n",
      "    num_agent_steps_trained: 451548\n",
      "    num_steps_sampled: 451548\n",
      "    num_steps_trained: 451548\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03125\n",
      "    ram_util_percent: 32.30625\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04412445717129122\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.452157265911854\n",
      "    mean_inference_ms: 2.42855559134814\n",
      "    mean_raw_obs_processing_ms: 2.0044101854212526\n",
      "  time_since_restore: 5889.157434463501\n",
      "  time_this_iter_s: 22.06963276863098\n",
      "  time_total_s: 5889.157434463501\n",
      "  timers:\n",
      "    learn_throughput: 1127.139\n",
      "    learn_time_ms: 1772.629\n",
      "    load_throughput: 57163.024\n",
      "    load_time_ms: 34.953\n",
      "    sample_throughput: 76.716\n",
      "    sample_time_ms: 26044.079\n",
      "    update_time_ms: 13.178\n",
      "  timestamp: 1636844864\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 451548\n",
      "  training_iteration: 226\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   226</td><td style=\"text-align: right;\">         5889.16</td><td style=\"text-align: right;\">451548</td><td style=\"text-align: right;\"> 20.6877</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">               18.65</td><td style=\"text-align: right;\">            101.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 453546\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-08-07\n",
      "  done: false\n",
      "  episode_len_mean: 101.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.05999999999994\n",
      "  episode_reward_mean: 20.65289999999992\n",
      "  episode_reward_min: 18.599999999999923\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4451\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2417373475574311\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014841322641662777\n",
      "          policy_loss: -0.020773185647669293\n",
      "          total_loss: 0.0276576511207081\n",
      "          vf_explained_var: 0.9983596801757812\n",
      "          vf_loss: 0.0570915018341371\n",
      "    num_agent_steps_sampled: 453546\n",
      "    num_agent_steps_trained: 453546\n",
      "    num_steps_sampled: 453546\n",
      "    num_steps_trained: 453546\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72727272727273\n",
      "    ram_util_percent: 32.33939393939395\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044114886483018305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.449720868200203\n",
      "    mean_inference_ms: 2.4283191062825162\n",
      "    mean_raw_obs_processing_ms: 1.9983251259105999\n",
      "  time_since_restore: 5912.183629989624\n",
      "  time_this_iter_s: 23.026195526123047\n",
      "  time_total_s: 5912.183629989624\n",
      "  timers:\n",
      "    learn_throughput: 1123.523\n",
      "    learn_time_ms: 1778.335\n",
      "    load_throughput: 56651.545\n",
      "    load_time_ms: 35.268\n",
      "    sample_throughput: 76.997\n",
      "    sample_time_ms: 25949.167\n",
      "    update_time_ms: 13.388\n",
      "  timestamp: 1636844887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 453546\n",
      "  training_iteration: 227\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   227</td><td style=\"text-align: right;\">         5912.18</td><td style=\"text-align: right;\">453546</td><td style=\"text-align: right;\"> 20.6529</td><td style=\"text-align: right;\">               21.06</td><td style=\"text-align: right;\">                18.6</td><td style=\"text-align: right;\">            101.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 455544\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-08-31\n",
      "  done: false\n",
      "  episode_len_mean: 99.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.089999999999943\n",
      "  episode_reward_mean: 20.671299999999924\n",
      "  episode_reward_min: 18.599999999999923\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4472\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2973827038492476\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01020211369499305\n",
      "          policy_loss: -0.02887563985728082\n",
      "          total_loss: -0.01799786411048401\n",
      "          vf_explained_var: 0.9993236660957336\n",
      "          vf_loss: 0.021269193559973722\n",
      "    num_agent_steps_sampled: 455544\n",
      "    num_agent_steps_trained: 455544\n",
      "    num_steps_sampled: 455544\n",
      "    num_steps_trained: 455544\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8\n",
      "    ram_util_percent: 32.314705882352946\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04411343462795041\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.44454368903598\n",
      "    mean_inference_ms: 2.4283580867940997\n",
      "    mean_raw_obs_processing_ms: 1.9918445646801421\n",
      "  time_since_restore: 5936.463872432709\n",
      "  time_this_iter_s: 24.280242443084717\n",
      "  time_total_s: 5936.463872432709\n",
      "  timers:\n",
      "    learn_throughput: 1127.137\n",
      "    learn_time_ms: 1772.633\n",
      "    load_throughput: 56724.902\n",
      "    load_time_ms: 35.223\n",
      "    sample_throughput: 81.844\n",
      "    sample_time_ms: 24412.434\n",
      "    update_time_ms: 13.789\n",
      "  timestamp: 1636844911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 455544\n",
      "  training_iteration: 228\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   228</td><td style=\"text-align: right;\">         5936.46</td><td style=\"text-align: right;\">455544</td><td style=\"text-align: right;\"> 20.6713</td><td style=\"text-align: right;\">               21.09</td><td style=\"text-align: right;\">                18.6</td><td style=\"text-align: right;\">             99.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 457542\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-08-54\n",
      "  done: false\n",
      "  episode_len_mean: 99.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.089999999999943\n",
      "  episode_reward_mean: 20.68219999999992\n",
      "  episode_reward_min: 18.589999999999904\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4491\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2606905676069713\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009887704825890279\n",
      "          policy_loss: 0.004901735555557977\n",
      "          total_loss: 0.01757663797054972\n",
      "          vf_explained_var: 0.9993243217468262\n",
      "          vf_loss: 0.022778983125906614\n",
      "    num_agent_steps_sampled: 457542\n",
      "    num_agent_steps_trained: 457542\n",
      "    num_steps_sampled: 457542\n",
      "    num_steps_trained: 457542\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.43235294117648\n",
      "    ram_util_percent: 32.347058823529416\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04410908973792964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.443088467503113\n",
      "    mean_inference_ms: 2.428187021882764\n",
      "    mean_raw_obs_processing_ms: 1.9860717632871814\n",
      "  time_since_restore: 5959.848482370377\n",
      "  time_this_iter_s: 23.384609937667847\n",
      "  time_total_s: 5959.848482370377\n",
      "  timers:\n",
      "    learn_throughput: 1129.433\n",
      "    learn_time_ms: 1769.029\n",
      "    load_throughput: 56147.632\n",
      "    load_time_ms: 35.585\n",
      "    sample_throughput: 88.162\n",
      "    sample_time_ms: 22662.765\n",
      "    update_time_ms: 13.563\n",
      "  timestamp: 1636844934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 457542\n",
      "  training_iteration: 229\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   229</td><td style=\"text-align: right;\">         5959.85</td><td style=\"text-align: right;\">457542</td><td style=\"text-align: right;\"> 20.6822</td><td style=\"text-align: right;\">               21.09</td><td style=\"text-align: right;\">               18.59</td><td style=\"text-align: right;\">             99.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 459540\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-09-17\n",
      "  done: false\n",
      "  episode_len_mean: 99.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.089999999999943\n",
      "  episode_reward_mean: 20.73489999999993\n",
      "  episode_reward_min: 18.589999999999904\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4512\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.260521541890644\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01166047707321839\n",
      "          policy_loss: -0.020866529093611808\n",
      "          total_loss: 0.01200519407256728\n",
      "          vf_explained_var: 0.9987995028495789\n",
      "          vf_loss: 0.04252538402742218\n",
      "    num_agent_steps_sampled: 459540\n",
      "    num_agent_steps_trained: 459540\n",
      "    num_steps_sampled: 459540\n",
      "    num_steps_trained: 459540\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11818181818182\n",
      "    ram_util_percent: 32.357575757575766\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04410707401903997\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.440531622866338\n",
      "    mean_inference_ms: 2.428119036710502\n",
      "    mean_raw_obs_processing_ms: 1.979969900133738\n",
      "  time_since_restore: 5983.033723831177\n",
      "  time_this_iter_s: 23.18524146080017\n",
      "  time_total_s: 5983.033723831177\n",
      "  timers:\n",
      "    learn_throughput: 1122.741\n",
      "    learn_time_ms: 1779.574\n",
      "    load_throughput: 55944.251\n",
      "    load_time_ms: 35.714\n",
      "    sample_throughput: 94.033\n",
      "    sample_time_ms: 21247.766\n",
      "    update_time_ms: 12.469\n",
      "  timestamp: 1636844957\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 459540\n",
      "  training_iteration: 230\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">         5983.03</td><td style=\"text-align: right;\">459540</td><td style=\"text-align: right;\"> 20.7349</td><td style=\"text-align: right;\">               21.09</td><td style=\"text-align: right;\">               18.59</td><td style=\"text-align: right;\">             99.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 461538\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-09-41\n",
      "  done: false\n",
      "  episode_len_mean: 98.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.089999999999943\n",
      "  episode_reward_mean: 20.756599999999924\n",
      "  episode_reward_min: 18.589999999999904\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4533\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2493065658069793\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011435396003738859\n",
      "          policy_loss: -0.005194380702007385\n",
      "          total_loss: 0.018855198552565917\n",
      "          vf_explained_var: 0.9990575909614563\n",
      "          vf_loss: 0.03364806012250483\n",
      "    num_agent_steps_sampled: 461538\n",
      "    num_agent_steps_trained: 461538\n",
      "    num_steps_sampled: 461538\n",
      "    num_steps_trained: 461538\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96969696969697\n",
      "    ram_util_percent: 32.31515151515152\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04410714785659278\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.438578967842833\n",
      "    mean_inference_ms: 2.428119569964627\n",
      "    mean_raw_obs_processing_ms: 1.974268996406168\n",
      "  time_since_restore: 6006.531760692596\n",
      "  time_this_iter_s: 23.498036861419678\n",
      "  time_total_s: 6006.531760692596\n",
      "  timers:\n",
      "    learn_throughput: 1122.264\n",
      "    learn_time_ms: 1780.33\n",
      "    load_throughput: 56398.994\n",
      "    load_time_ms: 35.426\n",
      "    sample_throughput: 94.127\n",
      "    sample_time_ms: 21226.602\n",
      "    update_time_ms: 11.254\n",
      "  timestamp: 1636844981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 461538\n",
      "  training_iteration: 231\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   231</td><td style=\"text-align: right;\">         6006.53</td><td style=\"text-align: right;\">461538</td><td style=\"text-align: right;\"> 20.7566</td><td style=\"text-align: right;\">               21.09</td><td style=\"text-align: right;\">               18.59</td><td style=\"text-align: right;\">             98.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 463536\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-10-04\n",
      "  done: false\n",
      "  episode_len_mean: 98.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.089999999999943\n",
      "  episode_reward_mean: 20.770999999999926\n",
      "  episode_reward_min: 18.589999999999904\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4553\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1820445849781944\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014290345770257638\n",
      "          policy_loss: -0.0015040719970351173\n",
      "          total_loss: 0.042283247358032634\n",
      "          vf_explained_var: 0.99819016456604\n",
      "          vf_loss: 0.051990522328941594\n",
      "    num_agent_steps_sampled: 463536\n",
      "    num_agent_steps_trained: 463536\n",
      "    num_steps_sampled: 463536\n",
      "    num_steps_trained: 463536\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.13030303030304\n",
      "    ram_util_percent: 32.35454545454546\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0441082637534489\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.436199377190345\n",
      "    mean_inference_ms: 2.42814895397334\n",
      "    mean_raw_obs_processing_ms: 1.9685205803572081\n",
      "  time_since_restore: 6029.541605472565\n",
      "  time_this_iter_s: 23.00984477996826\n",
      "  time_total_s: 6029.541605472565\n",
      "  timers:\n",
      "    learn_throughput: 1124.089\n",
      "    learn_time_ms: 1777.439\n",
      "    load_throughput: 58146.14\n",
      "    load_time_ms: 34.362\n",
      "    sample_throughput: 93.944\n",
      "    sample_time_ms: 21268.047\n",
      "    update_time_ms: 10.165\n",
      "  timestamp: 1636845004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 463536\n",
      "  training_iteration: 232\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   232</td><td style=\"text-align: right;\">         6029.54</td><td style=\"text-align: right;\">463536</td><td style=\"text-align: right;\">  20.771</td><td style=\"text-align: right;\">               21.09</td><td style=\"text-align: right;\">               18.59</td><td style=\"text-align: right;\">             98.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 465534\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-10-28\n",
      "  done: false\n",
      "  episode_len_mean: 98.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.758599999999923\n",
      "  episode_reward_min: 18.589999999999904\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4574\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1965032654149192\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01231672811130073\n",
      "          policy_loss: -0.013104308325619925\n",
      "          total_loss: 0.00706722837473665\n",
      "          vf_explained_var: 0.9991607666015625\n",
      "          vf_loss: 0.029018898077663922\n",
      "    num_agent_steps_sampled: 465534\n",
      "    num_agent_steps_trained: 465534\n",
      "    num_steps_sampled: 465534\n",
      "    num_steps_trained: 465534\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.02058823529413\n",
      "    ram_util_percent: 32.32058823529412\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04410702057616647\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.435254660346395\n",
      "    mean_inference_ms: 2.4281310115593024\n",
      "    mean_raw_obs_processing_ms: 1.962735326615419\n",
      "  time_since_restore: 6053.479722261429\n",
      "  time_this_iter_s: 23.938116788864136\n",
      "  time_total_s: 6053.479722261429\n",
      "  timers:\n",
      "    learn_throughput: 1125.035\n",
      "    learn_time_ms: 1775.944\n",
      "    load_throughput: 58369.74\n",
      "    load_time_ms: 34.23\n",
      "    sample_throughput: 93.431\n",
      "    sample_time_ms: 21384.764\n",
      "    update_time_ms: 9.412\n",
      "  timestamp: 1636845028\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 465534\n",
      "  training_iteration: 233\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   233</td><td style=\"text-align: right;\">         6053.48</td><td style=\"text-align: right;\">465534</td><td style=\"text-align: right;\"> 20.7586</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               18.59</td><td style=\"text-align: right;\">             98.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 467532\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-10-51\n",
      "  done: false\n",
      "  episode_len_mean: 97.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.795099999999923\n",
      "  episode_reward_min: 18.709999999999944\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4595\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1747800852571215\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0142555414718198\n",
      "          policy_loss: -0.016909473424866085\n",
      "          total_loss: -0.018763662998874983\n",
      "          vf_explained_var: 0.9998218417167664\n",
      "          vf_loss: 0.006285176912899174\n",
      "    num_agent_steps_sampled: 467532\n",
      "    num_agent_steps_trained: 467532\n",
      "    num_steps_sampled: 467532\n",
      "    num_steps_trained: 467532\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84848484848484\n",
      "    ram_util_percent: 32.269696969696966\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04411167051530985\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.42991732600391\n",
      "    mean_inference_ms: 2.4284159326068306\n",
      "    mean_raw_obs_processing_ms: 1.9573658720896538\n",
      "  time_since_restore: 6076.638788461685\n",
      "  time_this_iter_s: 23.159066200256348\n",
      "  time_total_s: 6076.638788461685\n",
      "  timers:\n",
      "    learn_throughput: 1122.498\n",
      "    learn_time_ms: 1779.958\n",
      "    load_throughput: 58306.913\n",
      "    load_time_ms: 34.267\n",
      "    sample_throughput: 93.265\n",
      "    sample_time_ms: 21422.839\n",
      "    update_time_ms: 8.548\n",
      "  timestamp: 1636845051\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 467532\n",
      "  training_iteration: 234\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   234</td><td style=\"text-align: right;\">         6076.64</td><td style=\"text-align: right;\">467532</td><td style=\"text-align: right;\"> 20.7951</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               18.71</td><td style=\"text-align: right;\">             97.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 469530\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-11-32\n",
      "  done: false\n",
      "  episode_len_mean: 95.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.658299999999926\n",
      "  episode_reward_min: 1.94\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4617\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2230967328661964\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012966444451669046\n",
      "          policy_loss: 0.0005167641898705846\n",
      "          total_loss: 0.7318451044194045\n",
      "          vf_explained_var: 0.9782633185386658\n",
      "          vf_loss: 0.7402771619946829\n",
      "    num_agent_steps_sampled: 469530\n",
      "    num_agent_steps_trained: 469530\n",
      "    num_steps_sampled: 469530\n",
      "    num_steps_trained: 469530\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.93793103448279\n",
      "    ram_util_percent: 32.27413793103449\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04411076127190414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.428970667164013\n",
      "    mean_inference_ms: 2.428423035582842\n",
      "    mean_raw_obs_processing_ms: 1.9604227427649967\n",
      "  time_since_restore: 6116.967090845108\n",
      "  time_this_iter_s: 40.32830238342285\n",
      "  time_total_s: 6116.967090845108\n",
      "  timers:\n",
      "    learn_throughput: 1120.734\n",
      "    learn_time_ms: 1782.76\n",
      "    load_throughput: 58460.869\n",
      "    load_time_ms: 34.177\n",
      "    sample_throughput: 86.297\n",
      "    sample_time_ms: 23152.531\n",
      "    update_time_ms: 8.617\n",
      "  timestamp: 1636845092\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 469530\n",
      "  training_iteration: 235\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   235</td><td style=\"text-align: right;\">         6116.97</td><td style=\"text-align: right;\">469530</td><td style=\"text-align: right;\"> 20.6583</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">             95.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 471528\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-12-14\n",
      "  done: false\n",
      "  episode_len_mean: 93.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.344399999999936\n",
      "  episode_reward_min: 1.94\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4639\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.200727291334243\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.019206888404533357\n",
      "          policy_loss: -0.028390448895238694\n",
      "          total_loss: 0.1716547325785671\n",
      "          vf_explained_var: 0.9939673542976379\n",
      "          vf_loss: 0.2071907106254782\n",
      "    num_agent_steps_sampled: 471528\n",
      "    num_agent_steps_trained: 471528\n",
      "    num_steps_sampled: 471528\n",
      "    num_steps_trained: 471528\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.835\n",
      "    ram_util_percent: 32.18\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04410964890953647\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.429278267611824\n",
      "    mean_inference_ms: 2.428525346435436\n",
      "    mean_raw_obs_processing_ms: 1.9712291932046333\n",
      "  time_since_restore: 6159.082169532776\n",
      "  time_this_iter_s: 42.11507868766785\n",
      "  time_total_s: 6159.082169532776\n",
      "  timers:\n",
      "    learn_throughput: 1120.69\n",
      "    learn_time_ms: 1782.83\n",
      "    load_throughput: 58416.368\n",
      "    load_time_ms: 34.203\n",
      "    sample_throughput: 79.417\n",
      "    sample_time_ms: 25158.189\n",
      "    update_time_ms: 7.439\n",
      "  timestamp: 1636845134\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 471528\n",
      "  training_iteration: 236\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">         6159.08</td><td style=\"text-align: right;\">471528</td><td style=\"text-align: right;\"> 20.3444</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">             93.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 473526\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-12-54\n",
      "  done: false\n",
      "  episode_len_mean: 93.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999936\n",
      "  episode_reward_mean: 20.316899999999933\n",
      "  episode_reward_min: 1.94\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4660\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1991205780279068\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011346941912291492\n",
      "          policy_loss: 0.005604872533253261\n",
      "          total_loss: 0.06277174981577056\n",
      "          vf_explained_var: 0.9982219934463501\n",
      "          vf_loss: 0.06628589099716573\n",
      "    num_agent_steps_sampled: 473526\n",
      "    num_agent_steps_trained: 473526\n",
      "    num_steps_sampled: 473526\n",
      "    num_steps_trained: 473526\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.40172413793104\n",
      "    ram_util_percent: 32.0551724137931\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04410749412642957\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.42961941617131\n",
      "    mean_inference_ms: 2.42855959308793\n",
      "    mean_raw_obs_processing_ms: 1.989194411849812\n",
      "  time_since_restore: 6199.370717525482\n",
      "  time_this_iter_s: 40.2885479927063\n",
      "  time_total_s: 6199.370717525482\n",
      "  timers:\n",
      "    learn_throughput: 1123.55\n",
      "    learn_time_ms: 1778.292\n",
      "    load_throughput: 58029.817\n",
      "    load_time_ms: 34.431\n",
      "    sample_throughput: 74.309\n",
      "    sample_time_ms: 26887.601\n",
      "    update_time_ms: 8.143\n",
      "  timestamp: 1636845174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 473526\n",
      "  training_iteration: 237\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   237</td><td style=\"text-align: right;\">         6199.37</td><td style=\"text-align: right;\">473526</td><td style=\"text-align: right;\"> 20.3169</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">             93.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 475524\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-13-17\n",
      "  done: false\n",
      "  episode_len_mean: 93.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999936\n",
      "  episode_reward_mean: 20.28609999999993\n",
      "  episode_reward_min: 1.94\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4680\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3061660630362375\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00964103385457014\n",
      "          policy_loss: -0.049480897436539335\n",
      "          total_loss: -0.01254508596445833\n",
      "          vf_explained_var: 0.9985045790672302\n",
      "          vf_loss: 0.04755708406280194\n",
      "    num_agent_steps_sampled: 475524\n",
      "    num_agent_steps_trained: 475524\n",
      "    num_steps_sampled: 475524\n",
      "    num_steps_trained: 475524\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87272727272727\n",
      "    ram_util_percent: 31.948484848484853\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044103694780769996\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.43112000489596\n",
      "    mean_inference_ms: 2.4284829551448675\n",
      "    mean_raw_obs_processing_ms: 2.0060002232958087\n",
      "  time_since_restore: 6222.710769414902\n",
      "  time_this_iter_s: 23.340051889419556\n",
      "  time_total_s: 6222.710769414902\n",
      "  timers:\n",
      "    learn_throughput: 1122.474\n",
      "    learn_time_ms: 1779.997\n",
      "    load_throughput: 58209.55\n",
      "    load_time_ms: 34.324\n",
      "    sample_throughput: 74.575\n",
      "    sample_time_ms: 26791.998\n",
      "    update_time_ms: 8.114\n",
      "  timestamp: 1636845197\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 475524\n",
      "  training_iteration: 238\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   238</td><td style=\"text-align: right;\">         6222.71</td><td style=\"text-align: right;\">475524</td><td style=\"text-align: right;\"> 20.2861</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">             93.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 477522\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-13-41\n",
      "  done: false\n",
      "  episode_len_mean: 94.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999936\n",
      "  episode_reward_mean: 20.19189999999993\n",
      "  episode_reward_min: 1.94\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4701\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.344293216864268\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011474865216542788\n",
      "          policy_loss: -0.00036382703554062616\n",
      "          total_loss: 0.056756323238923434\n",
      "          vf_explained_var: 0.9982113838195801\n",
      "          vf_loss: 0.06765850718088803\n",
      "    num_agent_steps_sampled: 477522\n",
      "    num_agent_steps_trained: 477522\n",
      "    num_steps_sampled: 477522\n",
      "    num_steps_trained: 477522\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.74545454545455\n",
      "    ram_util_percent: 31.96363636363636\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044099506124485065\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.432680178317717\n",
      "    mean_inference_ms: 2.4283878992327095\n",
      "    mean_raw_obs_processing_ms: 2.016945270895057\n",
      "  time_since_restore: 6246.007185935974\n",
      "  time_this_iter_s: 23.296416521072388\n",
      "  time_total_s: 6246.007185935974\n",
      "  timers:\n",
      "    learn_throughput: 1121.389\n",
      "    learn_time_ms: 1781.718\n",
      "    load_throughput: 58978.166\n",
      "    load_time_ms: 33.877\n",
      "    sample_throughput: 74.604\n",
      "    sample_time_ms: 26781.252\n",
      "    update_time_ms: 8.807\n",
      "  timestamp: 1636845221\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 477522\n",
      "  training_iteration: 239\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   239</td><td style=\"text-align: right;\">         6246.01</td><td style=\"text-align: right;\">477522</td><td style=\"text-align: right;\"> 20.1919</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">             94.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 479520\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 96.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999936\n",
      "  episode_reward_mean: 20.453699999999927\n",
      "  episode_reward_min: 1.95\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4720\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.279663756347838\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014753006620893815\n",
      "          policy_loss: -0.0227176234126091\n",
      "          total_loss: -0.011668672341675986\n",
      "          vf_explained_var: 0.9993982315063477\n",
      "          vf_loss: 0.020111231862877808\n",
      "    num_agent_steps_sampled: 479520\n",
      "    num_agent_steps_trained: 479520\n",
      "    num_steps_sampled: 479520\n",
      "    num_steps_trained: 479520\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.65757575757577\n",
      "    ram_util_percent: 32.05151515151515\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04409453394803872\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.43681959134161\n",
      "    mean_inference_ms: 2.428035423383874\n",
      "    mean_raw_obs_processing_ms: 2.0269107358138543\n",
      "  time_since_restore: 6268.548468112946\n",
      "  time_this_iter_s: 22.541282176971436\n",
      "  time_total_s: 6268.548468112946\n",
      "  timers:\n",
      "    learn_throughput: 1128.938\n",
      "    learn_time_ms: 1769.805\n",
      "    load_throughput: 59026.021\n",
      "    load_time_ms: 33.849\n",
      "    sample_throughput: 74.752\n",
      "    sample_time_ms: 26728.47\n",
      "    update_time_ms: 9.1\n",
      "  timestamp: 1636845243\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 479520\n",
      "  training_iteration: 240\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   240</td><td style=\"text-align: right;\">         6268.55</td><td style=\"text-align: right;\">479520</td><td style=\"text-align: right;\"> 20.4537</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">                1.95</td><td style=\"text-align: right;\">             96.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 481518\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-14-27\n",
      "  done: false\n",
      "  episode_len_mean: 98.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.069999999999936\n",
      "  episode_reward_mean: 20.708999999999925\n",
      "  episode_reward_min: 16.579999999999927\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4741\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3609485211826506\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011390095363792712\n",
      "          policy_loss: 0.0003040900720017297\n",
      "          total_loss: 0.026849073295791944\n",
      "          vf_explained_var: 0.9989697933197021\n",
      "          vf_loss: 0.03727135203246559\n",
      "    num_agent_steps_sampled: 481518\n",
      "    num_agent_steps_trained: 481518\n",
      "    num_steps_sampled: 481518\n",
      "    num_steps_trained: 481518\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.39090909090909\n",
      "    ram_util_percent: 32.136363636363626\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04409327055806488\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.43570844159914\n",
      "    mean_inference_ms: 2.427854820782405\n",
      "    mean_raw_obs_processing_ms: 2.028801478725194\n",
      "  time_since_restore: 6291.71081161499\n",
      "  time_this_iter_s: 23.162343502044678\n",
      "  time_total_s: 6291.71081161499\n",
      "  timers:\n",
      "    learn_throughput: 1130.039\n",
      "    learn_time_ms: 1768.081\n",
      "    load_throughput: 58605.064\n",
      "    load_time_ms: 34.093\n",
      "    sample_throughput: 74.845\n",
      "    sample_time_ms: 26695.322\n",
      "    update_time_ms: 10.018\n",
      "  timestamp: 1636845267\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 481518\n",
      "  training_iteration: 241\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   241</td><td style=\"text-align: right;\">         6291.71</td><td style=\"text-align: right;\">481518</td><td style=\"text-align: right;\">  20.709</td><td style=\"text-align: right;\">               21.07</td><td style=\"text-align: right;\">               16.58</td><td style=\"text-align: right;\">             98.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 483516\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-14-48\n",
      "  done: false\n",
      "  episode_len_mean: 99.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.029999999999937\n",
      "  episode_reward_mean: 20.731199999999923\n",
      "  episode_reward_min: 16.579999999999927\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 4759\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.323291037763868\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010701032161935247\n",
      "          policy_loss: -0.013166098970742453\n",
      "          total_loss: 0.013649186154916173\n",
      "          vf_explained_var: 0.9988694190979004\n",
      "          vf_loss: 0.0373394992690356\n",
      "    num_agent_steps_sampled: 483516\n",
      "    num_agent_steps_trained: 483516\n",
      "    num_steps_sampled: 483516\n",
      "    num_steps_trained: 483516\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.67741935483873\n",
      "    ram_util_percent: 32.274193548387096\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04409115909453254\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.434901405863876\n",
      "    mean_inference_ms: 2.427640361735897\n",
      "    mean_raw_obs_processing_ms: 2.023586200531964\n",
      "  time_since_restore: 6313.56437587738\n",
      "  time_this_iter_s: 21.853564262390137\n",
      "  time_total_s: 6313.56437587738\n",
      "  timers:\n",
      "    learn_throughput: 1129.321\n",
      "    learn_time_ms: 1769.204\n",
      "    load_throughput: 58479.104\n",
      "    load_time_ms: 34.166\n",
      "    sample_throughput: 75.177\n",
      "    sample_time_ms: 26577.28\n",
      "    update_time_ms: 11.248\n",
      "  timestamp: 1636845288\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 483516\n",
      "  training_iteration: 242\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">         6313.56</td><td style=\"text-align: right;\">483516</td><td style=\"text-align: right;\"> 20.7312</td><td style=\"text-align: right;\">               21.03</td><td style=\"text-align: right;\">               16.58</td><td style=\"text-align: right;\">             99.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 485514\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-15-11\n",
      "  done: false\n",
      "  episode_len_mean: 99.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.039999999999935\n",
      "  episode_reward_mean: 20.723399999999923\n",
      "  episode_reward_min: 16.579999999999927\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4780\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3225820246196929\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007957456875727721\n",
      "          policy_loss: -0.07840678571235565\n",
      "          total_loss: -0.05254419680152621\n",
      "          vf_explained_var: 0.9990901350975037\n",
      "          vf_loss: 0.03707417724210592\n",
      "    num_agent_steps_sampled: 485514\n",
      "    num_agent_steps_trained: 485514\n",
      "    num_steps_sampled: 485514\n",
      "    num_steps_trained: 485514\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.446875\n",
      "    ram_util_percent: 32.33125\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044091683114238965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.430776442903507\n",
      "    mean_inference_ms: 2.4275498790428776\n",
      "    mean_raw_obs_processing_ms: 2.0174438009234135\n",
      "  time_since_restore: 6336.099753856659\n",
      "  time_this_iter_s: 22.535377979278564\n",
      "  time_total_s: 6336.099753856659\n",
      "  timers:\n",
      "    learn_throughput: 1130.307\n",
      "    learn_time_ms: 1767.661\n",
      "    load_throughput: 58215.535\n",
      "    load_time_ms: 34.321\n",
      "    sample_throughput: 75.575\n",
      "    sample_time_ms: 26437.483\n",
      "    update_time_ms: 12.302\n",
      "  timestamp: 1636845311\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 485514\n",
      "  training_iteration: 243\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   243</td><td style=\"text-align: right;\">          6336.1</td><td style=\"text-align: right;\">485514</td><td style=\"text-align: right;\"> 20.7234</td><td style=\"text-align: right;\">               21.04</td><td style=\"text-align: right;\">               16.58</td><td style=\"text-align: right;\">             99.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 487512\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-15-34\n",
      "  done: false\n",
      "  episode_len_mean: 100.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.039999999999935\n",
      "  episode_reward_mean: 20.763999999999918\n",
      "  episode_reward_min: 18.459999999999887\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4800\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3749241051219758\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009579684198102761\n",
      "          policy_loss: -0.02476291214781148\n",
      "          total_loss: -0.012389172400747026\n",
      "          vf_explained_var: 0.9993321299552917\n",
      "          vf_loss: 0.02369812183481242\n",
      "    num_agent_steps_sampled: 487512\n",
      "    num_agent_steps_trained: 487512\n",
      "    num_steps_sampled: 487512\n",
      "    num_steps_trained: 487512\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00909090909092\n",
      "    ram_util_percent: 32.375757575757575\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04408881262764014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.42718727912683\n",
      "    mean_inference_ms: 2.4274839163907713\n",
      "    mean_raw_obs_processing_ms: 2.011933794302911\n",
      "  time_since_restore: 6359.032405138016\n",
      "  time_this_iter_s: 22.93265128135681\n",
      "  time_total_s: 6359.032405138016\n",
      "  timers:\n",
      "    learn_throughput: 1120.176\n",
      "    learn_time_ms: 1783.649\n",
      "    load_throughput: 58678.846\n",
      "    load_time_ms: 34.05\n",
      "    sample_throughput: 75.684\n",
      "    sample_time_ms: 26399.398\n",
      "    update_time_ms: 12.025\n",
      "  timestamp: 1636845334\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 487512\n",
      "  training_iteration: 244\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   244</td><td style=\"text-align: right;\">         6359.03</td><td style=\"text-align: right;\">487512</td><td style=\"text-align: right;\">  20.764</td><td style=\"text-align: right;\">               21.04</td><td style=\"text-align: right;\">               18.46</td><td style=\"text-align: right;\">            100.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 489510\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-15-57\n",
      "  done: false\n",
      "  episode_len_mean: 100.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.72179999999992\n",
      "  episode_reward_min: 18.459999999999887\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4819\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3122726832117353\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014186951522014666\n",
      "          policy_loss: -0.0033743329700969514\n",
      "          total_loss: 0.025934548622795515\n",
      "          vf_explained_var: 0.9988930821418762\n",
      "          vf_loss: 0.038840535518136765\n",
      "    num_agent_steps_sampled: 489510\n",
      "    num_agent_steps_trained: 489510\n",
      "    num_steps_sampled: 489510\n",
      "    num_steps_trained: 489510\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01249999999999\n",
      "    ram_util_percent: 32.409375\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04409034893205813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.41898563514844\n",
      "    mean_inference_ms: 2.4276887952454382\n",
      "    mean_raw_obs_processing_ms: 2.0066602315702244\n",
      "  time_since_restore: 6381.856645584106\n",
      "  time_this_iter_s: 22.8242404460907\n",
      "  time_total_s: 6381.856645584106\n",
      "  timers:\n",
      "    learn_throughput: 1121.368\n",
      "    learn_time_ms: 1781.752\n",
      "    load_throughput: 58425.328\n",
      "    load_time_ms: 34.197\n",
      "    sample_throughput: 81.051\n",
      "    sample_time_ms: 24651.241\n",
      "    update_time_ms: 11.848\n",
      "  timestamp: 1636845357\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 489510\n",
      "  training_iteration: 245\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   245</td><td style=\"text-align: right;\">         6381.86</td><td style=\"text-align: right;\">489510</td><td style=\"text-align: right;\"> 20.7218</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               18.46</td><td style=\"text-align: right;\">             100.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 491508\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-16-19\n",
      "  done: false\n",
      "  episode_len_mean: 99.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.746499999999916\n",
      "  episode_reward_min: 18.459999999999887\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4840\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2901629090309144\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012144193604069913\n",
      "          policy_loss: -0.011719097662717105\n",
      "          total_loss: 0.007935264888441278\n",
      "          vf_explained_var: 0.9991973638534546\n",
      "          vf_loss: 0.029481991662067317\n",
      "    num_agent_steps_sampled: 491508\n",
      "    num_agent_steps_trained: 491508\n",
      "    num_steps_sampled: 491508\n",
      "    num_steps_trained: 491508\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.671875\n",
      "    ram_util_percent: 32.425\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04408709638433564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.412640490270622\n",
      "    mean_inference_ms: 2.4277427474757785\n",
      "    mean_raw_obs_processing_ms: 2.000805290426979\n",
      "  time_since_restore: 6403.90247631073\n",
      "  time_this_iter_s: 22.045830726623535\n",
      "  time_total_s: 6403.90247631073\n",
      "  timers:\n",
      "    learn_throughput: 1121.338\n",
      "    learn_time_ms: 1781.799\n",
      "    load_throughput: 58565.705\n",
      "    load_time_ms: 34.116\n",
      "    sample_throughput: 88.236\n",
      "    sample_time_ms: 22643.858\n",
      "    update_time_ms: 12.333\n",
      "  timestamp: 1636845379\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 491508\n",
      "  training_iteration: 246\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">          6403.9</td><td style=\"text-align: right;\">491508</td><td style=\"text-align: right;\"> 20.7465</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               18.46</td><td style=\"text-align: right;\">             99.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 493506\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-16-42\n",
      "  done: false\n",
      "  episode_len_mean: 98.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.782199999999925\n",
      "  episode_reward_min: 18.459999999999887\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4861\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.284473244916825\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012617092351927692\n",
      "          policy_loss: -0.01274563122008528\n",
      "          total_loss: -0.015371828756871677\n",
      "          vf_explained_var: 0.9997955560684204\n",
      "          vf_loss: 0.007024831731715018\n",
      "    num_agent_steps_sampled: 493506\n",
      "    num_agent_steps_trained: 493506\n",
      "    num_steps_sampled: 493506\n",
      "    num_steps_trained: 493506\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.2060606060606\n",
      "    ram_util_percent: 32.38787878787878\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04408615336788802\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.404782578709604\n",
      "    mean_inference_ms: 2.427952042999402\n",
      "    mean_raw_obs_processing_ms: 1.995205326310278\n",
      "  time_since_restore: 6427.275590181351\n",
      "  time_this_iter_s: 23.373113870620728\n",
      "  time_total_s: 6427.275590181351\n",
      "  timers:\n",
      "    learn_throughput: 1123.081\n",
      "    learn_time_ms: 1779.034\n",
      "    load_throughput: 58967.459\n",
      "    load_time_ms: 33.883\n",
      "    sample_throughput: 95.34\n",
      "    sample_time_ms: 20956.609\n",
      "    update_time_ms: 11.383\n",
      "  timestamp: 1636845402\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 493506\n",
      "  training_iteration: 247\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   247</td><td style=\"text-align: right;\">         6427.28</td><td style=\"text-align: right;\">493506</td><td style=\"text-align: right;\"> 20.7822</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               18.46</td><td style=\"text-align: right;\">             98.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 495504\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-17-05\n",
      "  done: false\n",
      "  episode_len_mean: 98.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.733099999999922\n",
      "  episode_reward_min: 14.55000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4881\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3273874095508031\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.018444023030030128\n",
      "          policy_loss: 0.002976304931300027\n",
      "          total_loss: 0.06324490464869\n",
      "          vf_explained_var: 0.9980639219284058\n",
      "          vf_loss: 0.06887383024829129\n",
      "    num_agent_steps_sampled: 495504\n",
      "    num_agent_steps_trained: 495504\n",
      "    num_steps_sampled: 495504\n",
      "    num_steps_trained: 495504\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88125\n",
      "    ram_util_percent: 32.365624999999994\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04408119683939327\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.40041632310214\n",
      "    mean_inference_ms: 2.427963268382774\n",
      "    mean_raw_obs_processing_ms: 1.9898264844581144\n",
      "  time_since_restore: 6449.84893488884\n",
      "  time_this_iter_s: 22.573344707489014\n",
      "  time_total_s: 6449.84893488884\n",
      "  timers:\n",
      "    learn_throughput: 1122.051\n",
      "    learn_time_ms: 1780.667\n",
      "    load_throughput: 58613.59\n",
      "    load_time_ms: 34.088\n",
      "    sample_throughput: 95.702\n",
      "    sample_time_ms: 20877.216\n",
      "    update_time_ms: 12.346\n",
      "  timestamp: 1636845425\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 495504\n",
      "  training_iteration: 248\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">         6449.85</td><td style=\"text-align: right;\">495504</td><td style=\"text-align: right;\"> 20.7331</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">             98.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 497502\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-17-27\n",
      "  done: false\n",
      "  episode_len_mean: 98.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.741399999999928\n",
      "  episode_reward_min: 14.55000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4900\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3322782465389797\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011269374006171526\n",
      "          policy_loss: -0.008409569235075088\n",
      "          total_loss: 0.037358125902357556\n",
      "          vf_explained_var: 0.9983753561973572\n",
      "          vf_loss: 0.05623791565054229\n",
      "    num_agent_steps_sampled: 497502\n",
      "    num_agent_steps_trained: 497502\n",
      "    num_steps_sampled: 497502\n",
      "    num_steps_trained: 497502\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59375\n",
      "    ram_util_percent: 32.35625\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044075907882560175\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.396712660215307\n",
      "    mean_inference_ms: 2.4278874382739546\n",
      "    mean_raw_obs_processing_ms: 1.9845490398643257\n",
      "  time_since_restore: 6471.938223838806\n",
      "  time_this_iter_s: 22.08928894996643\n",
      "  time_total_s: 6471.938223838806\n",
      "  timers:\n",
      "    learn_throughput: 1122.762\n",
      "    learn_time_ms: 1779.54\n",
      "    load_throughput: 58337.152\n",
      "    load_time_ms: 34.249\n",
      "    sample_throughput: 96.254\n",
      "    sample_time_ms: 20757.602\n",
      "    update_time_ms: 12.107\n",
      "  timestamp: 1636845447\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 497502\n",
      "  training_iteration: 249\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   249</td><td style=\"text-align: right;\">         6471.94</td><td style=\"text-align: right;\">497502</td><td style=\"text-align: right;\"> 20.7414</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">             98.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 499500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-17-51\n",
      "  done: false\n",
      "  episode_len_mean: 98.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.049999999999937\n",
      "  episode_reward_mean: 20.78359999999993\n",
      "  episode_reward_min: 14.55000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4921\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2484339941115605\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.018546765950736285\n",
      "          policy_loss: -0.017956489679359255\n",
      "          total_loss: 0.0050440182998066855\n",
      "          vf_explained_var: 0.9991536736488342\n",
      "          vf_loss: 0.030790197835969074\n",
      "    num_agent_steps_sampled: 499500\n",
      "    num_agent_steps_trained: 499500\n",
      "    num_steps_sampled: 499500\n",
      "    num_steps_trained: 499500\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.40294117647059\n",
      "    ram_util_percent: 32.332352941176474\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044069121180158294\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.391306283652074\n",
      "    mean_inference_ms: 2.4279840514524746\n",
      "    mean_raw_obs_processing_ms: 1.979290009039229\n",
      "  time_since_restore: 6495.607582092285\n",
      "  time_this_iter_s: 23.669358253479004\n",
      "  time_total_s: 6495.607582092285\n",
      "  timers:\n",
      "    learn_throughput: 1122.587\n",
      "    learn_time_ms: 1779.818\n",
      "    load_throughput: 58444.193\n",
      "    load_time_ms: 34.186\n",
      "    sample_throughput: 95.734\n",
      "    sample_time_ms: 20870.43\n",
      "    update_time_ms: 11.817\n",
      "  timestamp: 1636845471\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 499500\n",
      "  training_iteration: 250\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         6495.61</td><td style=\"text-align: right;\">499500</td><td style=\"text-align: right;\"> 20.7836</td><td style=\"text-align: right;\">               21.05</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">             98.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 501498\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-18-13\n",
      "  done: false\n",
      "  episode_len_mean: 98.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.07999999999994\n",
      "  episode_reward_mean: 20.80939999999993\n",
      "  episode_reward_min: 14.55000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4942\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3167400621232532\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015646985410088868\n",
      "          policy_loss: -0.031543408511649995\n",
      "          total_loss: -0.03384772173705555\n",
      "          vf_explained_var: 0.9997953772544861\n",
      "          vf_loss: 0.006902445902648781\n",
      "    num_agent_steps_sampled: 501498\n",
      "    num_agent_steps_trained: 501498\n",
      "    num_steps_sampled: 501498\n",
      "    num_steps_trained: 501498\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.38125\n",
      "    ram_util_percent: 32.321875000000006\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04406273340255653\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.387979453164007\n",
      "    mean_inference_ms: 2.427976551351459\n",
      "    mean_raw_obs_processing_ms: 1.9739905827733164\n",
      "  time_since_restore: 6518.089371204376\n",
      "  time_this_iter_s: 22.481789112091064\n",
      "  time_total_s: 6518.089371204376\n",
      "  timers:\n",
      "    learn_throughput: 1123.384\n",
      "    learn_time_ms: 1778.555\n",
      "    load_throughput: 58078.198\n",
      "    load_time_ms: 34.402\n",
      "    sample_throughput: 96.041\n",
      "    sample_time_ms: 20803.699\n",
      "    update_time_ms: 11.364\n",
      "  timestamp: 1636845493\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 501498\n",
      "  training_iteration: 251\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   251</td><td style=\"text-align: right;\">         6518.09</td><td style=\"text-align: right;\">501498</td><td style=\"text-align: right;\"> 20.8094</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">             98.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 503496\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-18-39\n",
      "  done: false\n",
      "  episode_len_mean: 98.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.07999999999994\n",
      "  episode_reward_mean: 20.790999999999922\n",
      "  episode_reward_min: 14.55000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4962\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3494889599936348\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010450608094652451\n",
      "          policy_loss: -0.018639817869379408\n",
      "          total_loss: -0.021719496395616305\n",
      "          vf_explained_var: 0.9997652173042297\n",
      "          vf_loss: 0.007769900234416127\n",
      "    num_agent_steps_sampled: 503496\n",
      "    num_agent_steps_trained: 503496\n",
      "    num_steps_sampled: 503496\n",
      "    num_steps_trained: 503496\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.45555555555553\n",
      "    ram_util_percent: 32.30277777777778\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04405666763018882\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.386751265558722\n",
      "    mean_inference_ms: 2.427963392083837\n",
      "    mean_raw_obs_processing_ms: 1.9689487810547137\n",
      "  time_since_restore: 6543.34659743309\n",
      "  time_this_iter_s: 25.25722622871399\n",
      "  time_total_s: 6543.34659743309\n",
      "  timers:\n",
      "    learn_throughput: 1125.073\n",
      "    learn_time_ms: 1775.885\n",
      "    load_throughput: 58278.246\n",
      "    load_time_ms: 34.284\n",
      "    sample_throughput: 94.479\n",
      "    sample_time_ms: 21147.477\n",
      "    update_time_ms: 10.788\n",
      "  timestamp: 1636845519\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 503496\n",
      "  training_iteration: 252\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   252</td><td style=\"text-align: right;\">         6543.35</td><td style=\"text-align: right;\">503496</td><td style=\"text-align: right;\">  20.791</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">             98.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97379)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 505494\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-19-19\n",
      "  done: false\n",
      "  episode_len_mean: 98.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.07999999999994\n",
      "  episode_reward_mean: 20.63099999999992\n",
      "  episode_reward_min: 1.94\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4982\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2613456538745336\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014889110294309373\n",
      "          policy_loss: 1.7660146667843774e-05\n",
      "          total_loss: 0.752892008193192\n",
      "          vf_explained_var: 0.9788253903388977\n",
      "          vf_loss: 0.7617189928623183\n",
      "    num_agent_steps_sampled: 505494\n",
      "    num_agent_steps_trained: 505494\n",
      "    num_steps_sampled: 505494\n",
      "    num_steps_trained: 505494\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.17413793103451\n",
      "    ram_util_percent: 32.25689655172413\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044046848449191926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.390297972809776\n",
      "    mean_inference_ms: 2.427652270721021\n",
      "    mean_raw_obs_processing_ms: 1.9718573267809012\n",
      "  time_since_restore: 6584.060171365738\n",
      "  time_this_iter_s: 40.713573932647705\n",
      "  time_total_s: 6584.060171365738\n",
      "  timers:\n",
      "    learn_throughput: 1123.34\n",
      "    learn_time_ms: 1778.624\n",
      "    load_throughput: 58608.056\n",
      "    load_time_ms: 34.091\n",
      "    sample_throughput: 87.004\n",
      "    sample_time_ms: 22964.384\n",
      "    update_time_ms: 8.893\n",
      "  timestamp: 1636845559\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 505494\n",
      "  training_iteration: 253\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   253</td><td style=\"text-align: right;\">         6584.06</td><td style=\"text-align: right;\">505494</td><td style=\"text-align: right;\">  20.631</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">             98.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97375)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 507492\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-19-59\n",
      "  done: false\n",
      "  episode_len_mean: 97.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.07999999999994\n",
      "  episode_reward_mean: 20.42709999999992\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 5004\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3304259964397975\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006856749182977698\n",
      "          policy_loss: 4.055843289409365e-05\n",
      "          total_loss: 0.7725613987173087\n",
      "          vf_explained_var: 0.9780187010765076\n",
      "          vf_loss: 0.7840895112958692\n",
      "    num_agent_steps_sampled: 507492\n",
      "    num_agent_steps_trained: 507492\n",
      "    num_steps_sampled: 507492\n",
      "    num_steps_trained: 507492\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.98392857142858\n",
      "    ram_util_percent: 32.13928571428572\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0440473127913765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.38450188809047\n",
      "    mean_inference_ms: 2.42796674114598\n",
      "    mean_raw_obs_processing_ms: 1.9819082567037025\n",
      "  time_since_restore: 6623.426293134689\n",
      "  time_this_iter_s: 39.366121768951416\n",
      "  time_total_s: 6623.426293134689\n",
      "  timers:\n",
      "    learn_throughput: 1134.692\n",
      "    learn_time_ms: 1760.83\n",
      "    load_throughput: 59402.962\n",
      "    load_time_ms: 33.635\n",
      "    sample_throughput: 81.137\n",
      "    sample_time_ms: 24625.09\n",
      "    update_time_ms: 9.472\n",
      "  timestamp: 1636845599\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 507492\n",
      "  training_iteration: 254\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">         6623.43</td><td style=\"text-align: right;\">507492</td><td style=\"text-align: right;\"> 20.4271</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=97370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c1ec9_00000:\n",
      "  agent_timesteps_total: 509490\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-13_23-20-37\n",
      "  done: false\n",
      "  episode_len_mean: 97.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.07999999999994\n",
      "  episode_reward_mean: 20.21819999999992\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5024\n",
      "  experiment_id: 3471556cf6b5442e8ddf461993f1dbed\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3472122016407195\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.004030742534568872\n",
      "          policy_loss: 0.00155059899247828\n",
      "          total_loss: 0.6336043970304586\n",
      "          vf_explained_var: 0.981549084186554\n",
      "          vf_loss: 0.6445056505856059\n",
      "    num_agent_steps_sampled: 509490\n",
      "    num_agent_steps_trained: 509490\n",
      "    num_steps_sampled: 509490\n",
      "    num_steps_trained: 509490\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.07636363636364\n",
      "    ram_util_percent: 32.01272727272728\n",
      "  pid: 97382\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04404305127062292\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.383810939824507\n",
      "    mean_inference_ms: 2.427901995296226\n",
      "    mean_raw_obs_processing_ms: 1.996562271012898\n",
      "  time_since_restore: 6661.893795251846\n",
      "  time_this_iter_s: 38.46750211715698\n",
      "  time_total_s: 6661.893795251846\n",
      "  timers:\n",
      "    learn_throughput: 1130.416\n",
      "    learn_time_ms: 1767.492\n",
      "    load_throughput: 59755.972\n",
      "    load_time_ms: 33.436\n",
      "    sample_throughput: 76.309\n",
      "    sample_time_ms: 26182.994\n",
      "    update_time_ms: 9.409\n",
      "  timestamp: 1636845637\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 509490\n",
      "  training_iteration: 255\n",
      "  trial_id: c1ec9_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.86 GiB heap, 0.0/11.93 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/C12/PPO_2021-11-13_21-29-17<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c1ec9_00000</td><td>RUNNING </td><td>192.168.3.5:97382</td><td style=\"text-align: right;\">   255</td><td style=\"text-align: right;\">         6661.89</td><td style=\"text-align: right;\">509490</td><td style=\"text-align: right;\"> 20.2182</td><td style=\"text-align: right;\">               21.08</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 256,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 1000,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO MultiTask (C12) pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/C12\",\n",
    "        keep_checkpoints_num=50,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True,\n",
    "        #restore=\"/IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_20-28-45/PPO_my_env_78cf0_00000_0_2021-11-08_20-28-45/checkpoint_000050/checkpoint-50\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
