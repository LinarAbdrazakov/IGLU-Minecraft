{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf11610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dim_feedforward=None, activation=nn.ELU):\n",
    "        super().__init__()\n",
    "        if dim_feedforward is None:\n",
    "            dim_feedforward = 4 * d_model\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, dropout=0.0, batch_first=True)\n",
    "        # Implementation of feedforward model\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.activation = activation()\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        src = query\n",
    "        src2 = self.self_attn(query=query, key=key, value=value)[0]\n",
    "        src = src + src2\n",
    "        src2 = self.linear2(self.activation(self.linear1(src2)))\n",
    "        src = src + src2\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49072be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionNet(nn.Module):\n",
    "    def __init__(self, d_model=8, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.img_preproc = nn.Sequential(\n",
    "            nn.Linear(512, 2048),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        self.target_cross_attn_1 = TransformerEncoderLayer(d_model=d_model, num_heads=num_heads)\n",
    "        self.img_cross_attn_1 = TransformerEncoderLayer(d_model=d_model, num_heads=num_heads)\n",
    "        self.conv_1 = nn.Conv3d(d_model, 2 * d_model, kernel_size=3, stride=1)\n",
    "        self.act_1 = nn.ELU()\n",
    "        \n",
    "        self.target_cross_attn_2 = TransformerEncoderLayer(d_model=2 * d_model, num_heads=num_heads)\n",
    "        self.img_cross_attn_2 = TransformerEncoderLayer(d_model=2 * d_model, num_heads=num_heads)\n",
    "        self.conv_2 = nn.Conv3d(2 * d_model, 4 * d_model, kernel_size=3, stride=1)\n",
    "        self.act_2 = nn.ELU()\n",
    "        \n",
    "        self.target_cross_attn_3 = TransformerEncoderLayer(d_model=4 * d_model, num_heads=num_heads)\n",
    "        self.img_cross_attn_3 = TransformerEncoderLayer(d_model=4 * d_model, num_heads=num_heads)\n",
    "        self.conv_3 = nn.Conv3d(4 * d_model, 8 * d_model, kernel_size=3, stride=1)\n",
    "        self.act_3 = nn.ELU()\n",
    "        \n",
    "        self.target_cross_attn_4 = TransformerEncoderLayer(d_model=8 * d_model, num_heads=num_heads)\n",
    "        self.img_cross_attn_4 = TransformerEncoderLayer(d_model=8 * d_model, num_heads=num_heads)\n",
    "        self.conv_4 = nn.Conv3d(8 * d_model, 16 * d_model, kernel_size=3, stride=1)\n",
    "        self.act_4 = nn.ELU()\n",
    "        \n",
    "        self.max_pool = nn.MaxPool3d(kernel_size=(1, 3, 3))\n",
    "        \n",
    "        \n",
    "    def forward(self, target, img_features):\n",
    "        batch_size = target.shape[0]\n",
    "        \n",
    "        img_features = self.img_preproc(img_features)\n",
    "        \n",
    "        # layer 1\n",
    "        target = target.permute(0, 2, 3, 4, 1).reshape(batch_size, 9*11*11, 8)\n",
    "        img = img_features.reshape(batch_size, 256, 8)\n",
    "        target_1 = self.target_cross_attn_1(query=target, key=img, value=img)\n",
    "        img_1 = self.img_cross_attn_1(query=img, key=target, value=target)\n",
    "        target_1 = target_1.reshape(batch_size, 9, 11, 11, 8).permute(0, 4, 1, 2, 3)\n",
    "        target_1 = self.act_1(self.conv_1(target_1))\n",
    "        img_1 = img_1.reshape(batch_size, 2048)\n",
    "        \n",
    "        # layer 2\n",
    "        target_1 = target_1.permute(0, 2, 3, 4, 1).reshape(batch_size, 7*9*9, 16)\n",
    "        img_1 = img_1.reshape(batch_size, 128, 16)\n",
    "        target_2 = self.target_cross_attn_2(query=target_1, key=img_1, value=img_1)\n",
    "        img_2 = self.img_cross_attn_2(query=img_1, key=target_1, value=target_1)\n",
    "        target_2 = target_2.reshape(batch_size, 7, 9, 9, 16).permute(0, 4, 1, 2, 3)\n",
    "        target_2 = self.act_2(self.conv_2(target_2))\n",
    "        img_2 = img_2.reshape(batch_size, 2048)\n",
    "        \n",
    "        # layer 3\n",
    "        target_2 = target_2.permute(0, 2, 3, 4, 1).reshape(batch_size, 5*7*7, 32)\n",
    "        img_2 = img_2.reshape(batch_size, 64, 32)\n",
    "        target_3 = self.target_cross_attn_3(query=target_2, key=img_2, value=img_2)\n",
    "        img_3 = self.img_cross_attn_3(query=img_2, key=target_2, value=target_2)\n",
    "        target_3 = target_3.reshape(batch_size, 5, 7, 7, 32).permute(0, 4, 1, 2, 3)\n",
    "        target_3 = self.act_3(self.conv_3(target_3))\n",
    "        img_3 = img_3.reshape(batch_size, 2048)\n",
    "        \n",
    "        # layer 4\n",
    "        target_3 = target_3.permute(0, 2, 3, 4, 1).reshape(batch_size, 3*5*5, 64)\n",
    "        img_3 = img_3.reshape(batch_size, 32, 64)\n",
    "        target_4 = self.target_cross_attn_4(query=target_3, key=img_3, value=img_3)\n",
    "        img_4 = self.img_cross_attn_4(query=img_3, key=target_3, value=target_3)\n",
    "        target_4 = target_4.reshape(batch_size, 3, 5, 5, 64).permute(0, 4, 1, 2, 3)\n",
    "        target_4 = self.act_4(self.conv_4(target_4))\n",
    "        img_4 = img_4.reshape(batch_size, 2048)\n",
    "        \n",
    "        \n",
    "        target_4 = self.max_pool(target_4)\n",
    "        \n",
    "        features = target_4.reshape(batch_size, -1)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 8, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 128 \n",
    "        self.policy_network = FusionNet()\n",
    "        \n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        \n",
    "        features = self.policy_network(target_features, visual_features)\n",
    "        \n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "tasks = []\n",
    "for i in range(1,156):\n",
    "    if ('C'+str(i)) == 'C38': continue\n",
    "    tasks.append('C'+str(i))\n",
    "    \n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "            \n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=250)\n",
    "    env.update_taskset(TaskSet(preset=tasks))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-11-14 14:38:42,674\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-11-14 14:38:42,686\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id 04314_00000 but id 907c1_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO All Tasks pretrained (visual pretrained AngelaCNN + CrossAttn) (3 noops after placement) r: -0.01 div10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/907c1_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/907c1_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211114_143843-907c1_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:46,158\tWARNING ppo.py:143 -- `train_batch_size` (5000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1666.\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:46,158\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:46,158\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:54,731\tINFO trainable.py:109 -- Trainable.setup took 11.081 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:54,732\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 9996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_14-45-00\n",
      "  done: false\n",
      "  episode_len_mean: 99.03030303030303\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.700000000000003\n",
      "  episode_reward_mean: -0.5804040404040409\n",
      "  episode_reward_min: -1.450000000000001\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 99\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.8841074453459847\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.004704763754277773\n",
      "          policy_loss: -0.011509279726853228\n",
      "          total_loss: 0.040411061462030835\n",
      "          vf_explained_var: -0.3121291697025299\n",
      "          vf_loss: 0.07982046209319503\n",
      "    num_agent_steps_sampled: 9996\n",
      "    num_agent_steps_trained: 9996\n",
      "    num_steps_sampled: 9996\n",
      "    num_steps_trained: 9996\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.29311663479925\n",
      "    ram_util_percent: 36.19923518164437\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048040997947451015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 54.80254200747374\n",
      "    mean_inference_ms: 8.617984758566491\n",
      "    mean_raw_obs_processing_ms: 0.6844258234493492\n",
      "  time_since_restore: 366.175776720047\n",
      "  time_this_iter_s: 366.175776720047\n",
      "  time_total_s: 366.175776720047\n",
      "  timers:\n",
      "    learn_throughput: 69.004\n",
      "    learn_time_ms: 144860.804\n",
      "    load_throughput: 90078.577\n",
      "    load_time_ms: 110.97\n",
      "    sample_throughput: 45.195\n",
      "    sample_time_ms: 221172.685\n",
      "    update_time_ms: 6.99\n",
      "  timestamp: 1636901100\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9996\n",
      "  training_iteration: 1\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         366.176</td><td style=\"text-align: right;\">9996</td><td style=\"text-align: right;\">-0.580404</td><td style=\"text-align: right;\">                 4.7</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           99.0303</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 19992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_14-49-26\n",
      "  done: false\n",
      "  episode_len_mean: 100.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.930000000000001\n",
      "  episode_reward_mean: -0.7361000000000005\n",
      "  episode_reward_min: -1.6000000000000008\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 199\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.872266720400916\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007915726438018678\n",
      "          policy_loss: -0.01592555729767833\n",
      "          total_loss: 0.020403559366241098\n",
      "          vf_explained_var: -0.07412627339363098\n",
      "          vf_loss: 0.06426021011280589\n",
      "    num_agent_steps_sampled: 19992\n",
      "    num_agent_steps_trained: 19992\n",
      "    num_steps_sampled: 19992\n",
      "    num_steps_trained: 19992\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.08968253968254\n",
      "    ram_util_percent: 40.81851851851852\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04867785010942372\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.47225888152813\n",
      "    mean_inference_ms: 8.619138654693119\n",
      "    mean_raw_obs_processing_ms: 0.638052561546034\n",
      "  time_since_restore: 631.5633075237274\n",
      "  time_this_iter_s: 265.3875308036804\n",
      "  time_total_s: 631.5633075237274\n",
      "  timers:\n",
      "    learn_throughput: 69.022\n",
      "    learn_time_ms: 144823.626\n",
      "    load_throughput: 77629.367\n",
      "    load_time_ms: 128.766\n",
      "    sample_throughput: 58.525\n",
      "    sample_time_ms: 170799.002\n",
      "    update_time_ms: 6.011\n",
      "  timestamp: 1636901366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19992\n",
      "  training_iteration: 2\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         631.563</td><td style=\"text-align: right;\">19992</td><td style=\"text-align: right;\"> -0.7361</td><td style=\"text-align: right;\">                4.93</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">            100.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 29988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_14-53-56\n",
      "  done: false\n",
      "  episode_len_mean: 100.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.730000000000006\n",
      "  episode_reward_mean: 0.15750000000000042\n",
      "  episode_reward_min: -1.730000000000001\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 298\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.839373106528551\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010519051259605366\n",
      "          policy_loss: -0.021232346243137478\n",
      "          total_loss: 0.18197832048749232\n",
      "          vf_explained_var: 0.0877896323800087\n",
      "          vf_loss: 0.23055249153393614\n",
      "    num_agent_steps_sampled: 29988\n",
      "    num_agent_steps_trained: 29988\n",
      "    num_steps_sampled: 29988\n",
      "    num_steps_trained: 29988\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.06217616580311\n",
      "    ram_util_percent: 40.70233160621762\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0489545428098754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.15415495292398\n",
      "    mean_inference_ms: 8.614063839239552\n",
      "    mean_raw_obs_processing_ms: 0.6406829489778322\n",
      "  time_since_restore: 901.4337737560272\n",
      "  time_this_iter_s: 269.8704662322998\n",
      "  time_total_s: 901.4337737560272\n",
      "  timers:\n",
      "    learn_throughput: 68.998\n",
      "    learn_time_ms: 144872.798\n",
      "    load_throughput: 77825.559\n",
      "    load_time_ms: 128.441\n",
      "    sample_throughput: 64.306\n",
      "    sample_time_ms: 155445.109\n",
      "    update_time_ms: 7.823\n",
      "  timestamp: 1636901636\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29988\n",
      "  training_iteration: 3\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         901.434</td><td style=\"text-align: right;\">29988</td><td style=\"text-align: right;\">  0.1575</td><td style=\"text-align: right;\">                4.73</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">            100.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 39984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_14-58-51\n",
      "  done: false\n",
      "  episode_len_mean: 97.14563106796116\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.710000000000005\n",
      "  episode_reward_mean: 0.5757281553398065\n",
      "  episode_reward_min: -1.8300000000000007\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 401\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.811861156194638\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011586275796279816\n",
      "          policy_loss: -0.02427993158284479\n",
      "          total_loss: 0.2371059584005489\n",
      "          vf_explained_var: 0.19990791380405426\n",
      "          vf_loss: 0.28834587312820886\n",
      "    num_agent_steps_sampled: 39984\n",
      "    num_agent_steps_trained: 39984\n",
      "    num_steps_sampled: 39984\n",
      "    num_steps_trained: 39984\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02238095238094\n",
      "    ram_util_percent: 41.01547619047619\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04883012843662368\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.46164447990399\n",
      "    mean_inference_ms: 8.624421217838952\n",
      "    mean_raw_obs_processing_ms: 2.0787208793923577\n",
      "  time_since_restore: 1196.4260656833649\n",
      "  time_this_iter_s: 294.99229192733765\n",
      "  time_total_s: 1196.4260656833649\n",
      "  timers:\n",
      "    learn_throughput: 68.979\n",
      "    learn_time_ms: 144914.323\n",
      "    load_throughput: 80463.214\n",
      "    load_time_ms: 124.231\n",
      "    sample_throughput: 64.893\n",
      "    sample_time_ms: 154037.368\n",
      "    update_time_ms: 8.52\n",
      "  timestamp: 1636901931\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39984\n",
      "  training_iteration: 4\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         1196.43</td><td style=\"text-align: right;\">39984</td><td style=\"text-align: right;\">0.575728</td><td style=\"text-align: right;\">                4.71</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           97.1456</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 49980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-03-31\n",
      "  done: false\n",
      "  episode_len_mean: 97.65686274509804\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.530000000000014\n",
      "  episode_reward_mean: 1.14294117647059\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 503\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7914847830421903\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01291240033164486\n",
      "          policy_loss: -0.02431462747721463\n",
      "          total_loss: 0.38614972693065547\n",
      "          vf_explained_var: 0.2639394998550415\n",
      "          vf_loss: 0.437087961875348\n",
      "    num_agent_steps_sampled: 49980\n",
      "    num_agent_steps_trained: 49980\n",
      "    num_steps_sampled: 49980\n",
      "    num_steps_trained: 49980\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.069\n",
      "    ram_util_percent: 41.44325\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048508938984994664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.69086700701841\n",
      "    mean_inference_ms: 8.608214583256773\n",
      "    mean_raw_obs_processing_ms: 1.8056772685510314\n",
      "  time_since_restore: 1476.736932516098\n",
      "  time_this_iter_s: 280.31086683273315\n",
      "  time_total_s: 1476.736932516098\n",
      "  timers:\n",
      "    learn_throughput: 68.975\n",
      "    learn_time_ms: 144922.973\n",
      "    load_throughput: 82016.697\n",
      "    load_time_ms: 121.878\n",
      "    sample_throughput: 66.518\n",
      "    sample_time_ms: 150274.483\n",
      "    update_time_ms: 7.833\n",
      "  timestamp: 1636902211\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 49980\n",
      "  training_iteration: 5\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1476.74</td><td style=\"text-align: right;\">49980</td><td style=\"text-align: right;\"> 1.14294</td><td style=\"text-align: right;\">                8.53</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           97.6569</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 59976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-08-10\n",
      "  done: false\n",
      "  episode_len_mean: 99.87128712871286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.260000000000012\n",
      "  episode_reward_mean: 1.2247524752475272\n",
      "  episode_reward_min: -1.9499999999999995\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 604\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7712131653076564\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012632949608454996\n",
      "          policy_loss: -0.02826809365159044\n",
      "          total_loss: 0.3065449736855176\n",
      "          vf_explained_var: 0.37885403633117676\n",
      "          vf_loss: 0.36126190269541025\n",
      "    num_agent_steps_sampled: 59976\n",
      "    num_agent_steps_trained: 59976\n",
      "    num_steps_sampled: 59976\n",
      "    num_steps_trained: 59976\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19673366834172\n",
      "    ram_util_percent: 41.28241206030152\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048629714266874194\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.12024447685897\n",
      "    mean_inference_ms: 8.599174633906923\n",
      "    mean_raw_obs_processing_ms: 1.6262490555701368\n",
      "  time_since_restore: 1755.4120795726776\n",
      "  time_this_iter_s: 278.6751470565796\n",
      "  time_total_s: 1755.4120795726776\n",
      "  timers:\n",
      "    learn_throughput: 68.971\n",
      "    learn_time_ms: 144931.076\n",
      "    load_throughput: 83109.746\n",
      "    load_time_ms: 120.275\n",
      "    sample_throughput: 67.775\n",
      "    sample_time_ms: 147489.082\n",
      "    update_time_ms: 9.357\n",
      "  timestamp: 1636902490\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59976\n",
      "  training_iteration: 6\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         1755.41</td><td style=\"text-align: right;\">59976</td><td style=\"text-align: right;\"> 1.22475</td><td style=\"text-align: right;\">               10.26</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           99.8713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 69972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-13-05\n",
      "  done: false\n",
      "  episode_len_mean: 100.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.530000000000015\n",
      "  episode_reward_mean: 1.2506000000000028\n",
      "  episode_reward_min: -1.9600000000000009\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 703\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.747085771805201\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019294186270850836\n",
      "          policy_loss: -0.034431641933341056\n",
      "          total_loss: 0.2905691921695048\n",
      "          vf_explained_var: 0.4129098951816559\n",
      "          vf_loss: 0.35054227306117486\n",
      "    num_agent_steps_sampled: 69972\n",
      "    num_agent_steps_trained: 69972\n",
      "    num_steps_sampled: 69972\n",
      "    num_steps_trained: 69972\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.92280285035629\n",
      "    ram_util_percent: 41.083847980997625\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048729713562477156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.712074190558006\n",
      "    mean_inference_ms: 8.588028029135184\n",
      "    mean_raw_obs_processing_ms: 1.7324583329550924\n",
      "  time_since_restore: 2050.596774339676\n",
      "  time_this_iter_s: 295.1846947669983\n",
      "  time_total_s: 2050.596774339676\n",
      "  timers:\n",
      "    learn_throughput: 68.97\n",
      "    learn_time_ms: 144932.616\n",
      "    load_throughput: 83843.662\n",
      "    load_time_ms: 119.222\n",
      "    sample_throughput: 67.603\n",
      "    sample_time_ms: 147863.097\n",
      "    update_time_ms: 8.765\n",
      "  timestamp: 1636902785\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69972\n",
      "  training_iteration: 7\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">          2050.6</td><td style=\"text-align: right;\">69972</td><td style=\"text-align: right;\">  1.2506</td><td style=\"text-align: right;\">                6.53</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">            100.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 79968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-18-05\n",
      "  done: false\n",
      "  episode_len_mean: 99.54455445544555\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.820000000000013\n",
      "  episode_reward_mean: 0.9281188118811902\n",
      "  episode_reward_min: -1.9200000000000013\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 804\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.716490948302114\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0277014662107412\n",
      "          policy_loss: -0.038532258618352376\n",
      "          total_loss: 0.23172735154517313\n",
      "          vf_explained_var: 0.5254629254341125\n",
      "          vf_loss: 0.2946543720467255\n",
      "    num_agent_steps_sampled: 79968\n",
      "    num_agent_steps_trained: 79968\n",
      "    num_steps_sampled: 79968\n",
      "    num_steps_trained: 79968\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.38648018648017\n",
      "    ram_util_percent: 41.68857808857809\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048801743160853124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.49751144878873\n",
      "    mean_inference_ms: 8.577275307009673\n",
      "    mean_raw_obs_processing_ms: 2.0538957283971824\n",
      "  time_since_restore: 2350.985038995743\n",
      "  time_this_iter_s: 300.3882646560669\n",
      "  time_total_s: 2350.985038995743\n",
      "  timers:\n",
      "    learn_throughput: 68.972\n",
      "    learn_time_ms: 144928.161\n",
      "    load_throughput: 84556.906\n",
      "    load_time_ms: 118.216\n",
      "    sample_throughput: 67.178\n",
      "    sample_time_ms: 148799.699\n",
      "    update_time_ms: 9.468\n",
      "  timestamp: 1636903085\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79968\n",
      "  training_iteration: 8\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         2350.99</td><td style=\"text-align: right;\">79968</td><td style=\"text-align: right;\">0.928119</td><td style=\"text-align: right;\">                4.82</td><td style=\"text-align: right;\">               -1.92</td><td style=\"text-align: right;\">           99.5446</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 89964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-22-46\n",
      "  done: false\n",
      "  episode_len_mean: 101.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.870000000000013\n",
      "  episode_reward_mean: 0.8922000000000024\n",
      "  episode_reward_min: -2.05\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 902\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.15\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6958542383634128\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.029198183727480908\n",
      "          policy_loss: -0.03811441195261084\n",
      "          total_loss: 0.21304377028439989\n",
      "          vf_explained_var: 0.549401044845581\n",
      "          vf_loss: 0.2737369965594739\n",
      "    num_agent_steps_sampled: 89964\n",
      "    num_agent_steps_trained: 89964\n",
      "    num_steps_sampled: 89964\n",
      "    num_steps_trained: 89964\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.20049999999999\n",
      "    ram_util_percent: 41.924\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049055570381558\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.26280427151571\n",
      "    mean_inference_ms: 8.573797281309385\n",
      "    mean_raw_obs_processing_ms: 1.9045449643858905\n",
      "  time_since_restore: 2631.3918561935425\n",
      "  time_this_iter_s: 280.4068171977997\n",
      "  time_total_s: 2631.3918561935425\n",
      "  timers:\n",
      "    learn_throughput: 68.967\n",
      "    learn_time_ms: 144937.857\n",
      "    load_throughput: 84930.654\n",
      "    load_time_ms: 117.696\n",
      "    sample_throughput: 67.864\n",
      "    sample_time_ms: 147293.923\n",
      "    update_time_ms: 10.254\n",
      "  timestamp: 1636903366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89964\n",
      "  training_iteration: 9\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         2631.39</td><td style=\"text-align: right;\">89964</td><td style=\"text-align: right;\">  0.8922</td><td style=\"text-align: right;\">                6.87</td><td style=\"text-align: right;\">               -2.05</td><td style=\"text-align: right;\">            101.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 99960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-27-31\n",
      "  done: false\n",
      "  episode_len_mean: 98.76470588235294\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.750000000000012\n",
      "  episode_reward_mean: 1.419803921568631\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 1004\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22500000000000006\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6617645257558578\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.03276358538475574\n",
      "          policy_loss: -0.044040175498678134\n",
      "          total_loss: 0.23528799822327132\n",
      "          vf_explained_var: 0.5880103707313538\n",
      "          vf_loss: 0.2985740117099868\n",
      "    num_agent_steps_sampled: 99960\n",
      "    num_agent_steps_trained: 99960\n",
      "    num_steps_sampled: 99960\n",
      "    num_steps_trained: 99960\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19533169533169\n",
      "    ram_util_percent: 41.73710073710075\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04897665824090076\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.19138504417229\n",
      "    mean_inference_ms: 8.573704299616555\n",
      "    mean_raw_obs_processing_ms: 1.7865184073053881\n",
      "  time_since_restore: 2916.8921689987183\n",
      "  time_this_iter_s: 285.5003128051758\n",
      "  time_total_s: 2916.8921689987183\n",
      "  timers:\n",
      "    learn_throughput: 68.968\n",
      "    learn_time_ms: 144937.401\n",
      "    load_throughput: 85215.981\n",
      "    load_time_ms: 117.302\n",
      "    sample_throughput: 68.182\n",
      "    sample_time_ms: 146608.041\n",
      "    update_time_ms: 9.715\n",
      "  timestamp: 1636903651\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99960\n",
      "  training_iteration: 10\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2916.89</td><td style=\"text-align: right;\">99960</td><td style=\"text-align: right;\">  1.4198</td><td style=\"text-align: right;\">                8.75</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           98.7647</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 109956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-32-35\n",
      "  done: false\n",
      "  episode_len_mean: 95.24038461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.360000000000014\n",
      "  episode_reward_mean: 1.7176923076923116\n",
      "  episode_reward_min: -1.6100000000000005\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1108\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.33749999999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6492050871889816\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.029999021829840426\n",
      "          policy_loss: -0.04716765971070267\n",
      "          total_loss: 0.20583039400322983\n",
      "          vf_explained_var: 0.6615533828735352\n",
      "          vf_loss: 0.2693654337563576\n",
      "    num_agent_steps_sampled: 109956\n",
      "    num_agent_steps_trained: 109956\n",
      "    num_steps_sampled: 109956\n",
      "    num_steps_trained: 109956\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77188940092167\n",
      "    ram_util_percent: 41.89447004608295\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04882698525532606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.197213567963544\n",
      "    mean_inference_ms: 8.570099426404301\n",
      "    mean_raw_obs_processing_ms: 2.1624070340749975\n",
      "  time_since_restore: 3220.9023168087006\n",
      "  time_this_iter_s: 304.0101478099823\n",
      "  time_total_s: 3220.9023168087006\n",
      "  timers:\n",
      "    learn_throughput: 68.965\n",
      "    learn_time_ms: 144942.148\n",
      "    load_throughput: 85090.317\n",
      "    load_time_ms: 117.475\n",
      "    sample_throughput: 71.203\n",
      "    sample_time_ms: 140387.578\n",
      "    update_time_ms: 9.845\n",
      "  timestamp: 1636903955\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109956\n",
      "  training_iteration: 11\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">          3220.9</td><td style=\"text-align: right;\">109956</td><td style=\"text-align: right;\"> 1.71769</td><td style=\"text-align: right;\">                8.36</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           95.2404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 119952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-37-24\n",
      "  done: false\n",
      "  episode_len_mean: 96.23076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.760000000000005\n",
      "  episode_reward_mean: 1.5182692307692345\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1212\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6219841663654035\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.028015319427843768\n",
      "          policy_loss: -0.046292343868826254\n",
      "          total_loss: 0.19925196828304703\n",
      "          vf_explained_var: 0.6058682203292847\n",
      "          vf_loss: 0.2575813973823992\n",
      "    num_agent_steps_sampled: 119952\n",
      "    num_agent_steps_trained: 119952\n",
      "    num_steps_sampled: 119952\n",
      "    num_steps_trained: 119952\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.16739659367397\n",
      "    ram_util_percent: 42.03892944038929\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048669129132758955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.158868558636556\n",
      "    mean_inference_ms: 8.567346658839769\n",
      "    mean_raw_obs_processing_ms: 2.0428828252453366\n",
      "  time_since_restore: 3509.0462403297424\n",
      "  time_this_iter_s: 288.14392352104187\n",
      "  time_total_s: 3509.0462403297424\n",
      "  timers:\n",
      "    learn_throughput: 68.958\n",
      "    learn_time_ms: 144957.433\n",
      "    load_throughput: 87658.39\n",
      "    load_time_ms: 114.034\n",
      "    sample_throughput: 70.072\n",
      "    sample_time_ms: 142652.339\n",
      "    update_time_ms: 9.893\n",
      "  timestamp: 1636904244\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119952\n",
      "  training_iteration: 12\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         3509.05</td><td style=\"text-align: right;\">119952</td><td style=\"text-align: right;\"> 1.51827</td><td style=\"text-align: right;\">                8.76</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           96.2308</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 129948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-42-11\n",
      "  done: false\n",
      "  episode_len_mean: 96.58653846153847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.190000000000015\n",
      "  episode_reward_mean: 1.6795192307692342\n",
      "  episode_reward_min: -2.1100000000000003\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1316\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6332171709109575\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.024243443993249278\n",
      "          policy_loss: -0.050442353914627154\n",
      "          total_loss: 0.24711239260569628\n",
      "          vf_explained_var: 0.5755695104598999\n",
      "          vf_loss: 0.3054770540095802\n",
      "    num_agent_steps_sampled: 129948\n",
      "    num_agent_steps_trained: 129948\n",
      "    num_steps_sampled: 129948\n",
      "    num_steps_trained: 129948\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.28146341463413\n",
      "    ram_util_percent: 41.979756097560966\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04860948067547906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.14700498734259\n",
      "    mean_inference_ms: 8.56368565995646\n",
      "    mean_raw_obs_processing_ms: 1.9397280796199097\n",
      "  time_since_restore: 3796.481033563614\n",
      "  time_this_iter_s: 287.43479323387146\n",
      "  time_total_s: 3796.481033563614\n",
      "  timers:\n",
      "    learn_throughput: 68.962\n",
      "    learn_time_ms: 144949.684\n",
      "    load_throughput: 88833.697\n",
      "    load_time_ms: 112.525\n",
      "    sample_throughput: 69.215\n",
      "    sample_time_ms: 144419.032\n",
      "    update_time_ms: 9.839\n",
      "  timestamp: 1636904531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129948\n",
      "  training_iteration: 13\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         3796.48</td><td style=\"text-align: right;\">129948</td><td style=\"text-align: right;\"> 1.67952</td><td style=\"text-align: right;\">               10.19</td><td style=\"text-align: right;\">               -2.11</td><td style=\"text-align: right;\">           96.5865</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 139944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-47-16\n",
      "  done: false\n",
      "  episode_len_mean: 95.20192307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.870000000000012\n",
      "  episode_reward_mean: 1.2180769230769264\n",
      "  episode_reward_min: -1.8100000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1420\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.614535803468818\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02094004718509212\n",
      "          policy_loss: -0.049892968075891206\n",
      "          total_loss: 0.17042035843667566\n",
      "          vf_explained_var: 0.6678788661956787\n",
      "          vf_loss: 0.2226066606091415\n",
      "    num_agent_steps_sampled: 139944\n",
      "    num_agent_steps_trained: 139944\n",
      "    num_steps_sampled: 139944\n",
      "    num_steps_trained: 139944\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13379310344827\n",
      "    ram_util_percent: 41.72390804597701\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048717008198523606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.1421603719103\n",
      "    mean_inference_ms: 8.557110879244933\n",
      "    mean_raw_obs_processing_ms: 2.0958057154007648\n",
      "  time_since_restore: 4101.065110206604\n",
      "  time_this_iter_s: 304.5840766429901\n",
      "  time_total_s: 4101.065110206604\n",
      "  timers:\n",
      "    learn_throughput: 68.967\n",
      "    learn_time_ms: 144938.28\n",
      "    load_throughput: 88774.316\n",
      "    load_time_ms: 112.6\n",
      "    sample_throughput: 68.753\n",
      "    sample_time_ms: 145390.371\n",
      "    update_time_ms: 9.474\n",
      "  timestamp: 1636904836\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 139944\n",
      "  training_iteration: 14\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         4101.07</td><td style=\"text-align: right;\">139944</td><td style=\"text-align: right;\"> 1.21808</td><td style=\"text-align: right;\">                6.87</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           95.2019</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 149940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-52-12\n",
      "  done: false\n",
      "  episode_len_mean: 95.82692307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.470000000000017\n",
      "  episode_reward_mean: 1.651826923076927\n",
      "  episode_reward_min: -1.7800000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1524\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.7085937500000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5801324088349302\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019684808400661603\n",
      "          policy_loss: -0.04797709975670227\n",
      "          total_loss: 0.19475129989958886\n",
      "          vf_explained_var: 0.7160896062850952\n",
      "          vf_loss: 0.23489638360647055\n",
      "    num_agent_steps_sampled: 149940\n",
      "    num_agent_steps_trained: 149940\n",
      "    num_steps_sampled: 149940\n",
      "    num_steps_trained: 149940\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.72434988179667\n",
      "    ram_util_percent: 42.04066193853427\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04873330308479576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.04914193007246\n",
      "    mean_inference_ms: 8.552553162331188\n",
      "    mean_raw_obs_processing_ms: 2.1135578021266253\n",
      "  time_since_restore: 4397.3837723731995\n",
      "  time_this_iter_s: 296.31866216659546\n",
      "  time_total_s: 4397.3837723731995\n",
      "  timers:\n",
      "    learn_throughput: 68.972\n",
      "    learn_time_ms: 144929.18\n",
      "    load_throughput: 88769.109\n",
      "    load_time_ms: 112.607\n",
      "    sample_throughput: 68.0\n",
      "    sample_time_ms: 147000.017\n",
      "    update_time_ms: 9.799\n",
      "  timestamp: 1636905132\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 149940\n",
      "  training_iteration: 15\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         4397.38</td><td style=\"text-align: right;\">149940</td><td style=\"text-align: right;\"> 1.65183</td><td style=\"text-align: right;\">                8.47</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           95.8269</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 159936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-56-54\n",
      "  done: false\n",
      "  episode_len_mean: 96.11428571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.81000000000001\n",
      "  episode_reward_mean: 1.754476190476195\n",
      "  episode_reward_min: -2.289999999999996\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 1629\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.7085937500000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5887092774749823\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01763131987004727\n",
      "          policy_loss: -0.05092837934055899\n",
      "          total_loss: 0.16808417862058322\n",
      "          vf_explained_var: 0.7048277258872986\n",
      "          vf_loss: 0.21477488728088892\n",
      "    num_agent_steps_sampled: 159936\n",
      "    num_agent_steps_trained: 159936\n",
      "    num_steps_sampled: 159936\n",
      "    num_steps_trained: 159936\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19925373134328\n",
      "    ram_util_percent: 41.921144278606974\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048715279889541\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00930927576109\n",
      "    mean_inference_ms: 8.550144080988598\n",
      "    mean_raw_obs_processing_ms: 2.024771814077573\n",
      "  time_since_restore: 4679.75058221817\n",
      "  time_this_iter_s: 282.3668098449707\n",
      "  time_total_s: 4679.75058221817\n",
      "  timers:\n",
      "    learn_throughput: 68.974\n",
      "    learn_time_ms: 144924.397\n",
      "    load_throughput: 88777.906\n",
      "    load_time_ms: 112.596\n",
      "    sample_throughput: 67.827\n",
      "    sample_time_ms: 147374.44\n",
      "    update_time_ms: 8.938\n",
      "  timestamp: 1636905414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159936\n",
      "  training_iteration: 16\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         4679.75</td><td style=\"text-align: right;\">159936</td><td style=\"text-align: right;\"> 1.75448</td><td style=\"text-align: right;\">                8.81</td><td style=\"text-align: right;\">               -2.29</td><td style=\"text-align: right;\">           96.1143</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 169932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-01-37\n",
      "  done: false\n",
      "  episode_len_mean: 96.94174757281553\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.64000000000002\n",
      "  episode_reward_mean: 1.5957281553398093\n",
      "  episode_reward_min: -1.9100000000000013\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 1732\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.7085937500000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.600336382429824\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015568854749177555\n",
      "          policy_loss: -0.056665287115491736\n",
      "          total_loss: 0.12470793101486838\n",
      "          vf_explained_var: 0.7119825482368469\n",
      "          vf_loss: 0.18077573356552956\n",
      "    num_agent_steps_sampled: 169932\n",
      "    num_agent_steps_trained: 169932\n",
      "    num_steps_sampled: 169932\n",
      "    num_steps_trained: 169932\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.18737623762375\n",
      "    ram_util_percent: 41.75297029702971\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048827430842570324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.972664698746314\n",
      "    mean_inference_ms: 8.550584879635956\n",
      "    mean_raw_obs_processing_ms: 1.9462665948106368\n",
      "  time_since_restore: 4962.586815834045\n",
      "  time_this_iter_s: 282.83623361587524\n",
      "  time_total_s: 4962.586815834045\n",
      "  timers:\n",
      "    learn_throughput: 68.974\n",
      "    learn_time_ms: 144923.26\n",
      "    load_throughput: 88795.731\n",
      "    load_time_ms: 112.573\n",
      "    sample_throughput: 68.4\n",
      "    sample_time_ms: 146140.928\n",
      "    update_time_ms: 9.108\n",
      "  timestamp: 1636905697\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169932\n",
      "  training_iteration: 17\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         4962.59</td><td style=\"text-align: right;\">169932</td><td style=\"text-align: right;\"> 1.59573</td><td style=\"text-align: right;\">                8.64</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           96.9417</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 179928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-06-39\n",
      "  done: false\n",
      "  episode_len_mean: 92.03669724770643\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.740000000000014\n",
      "  episode_reward_mean: 1.929816513761472\n",
      "  episode_reward_min: -1.7500000000000009\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 1841\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.7085937500000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5967230091747058\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.021757631094439362\n",
      "          policy_loss: -0.045536717239958356\n",
      "          total_loss: 0.2753134146675022\n",
      "          vf_explained_var: 0.6728546023368835\n",
      "          vf_loss: 0.30964240723838793\n",
      "    num_agent_steps_sampled: 179928\n",
      "    num_agent_steps_trained: 179928\n",
      "    num_steps_sampled: 179928\n",
      "    num_steps_trained: 179928\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.04372093023257\n",
      "    ram_util_percent: 42.28162790697676\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04896256002083444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.942299932403806\n",
      "    mean_inference_ms: 8.548981863142263\n",
      "    mean_raw_obs_processing_ms: 2.157976838707284\n",
      "  time_since_restore: 5264.191482543945\n",
      "  time_this_iter_s: 301.6046667098999\n",
      "  time_total_s: 5264.191482543945\n",
      "  timers:\n",
      "    learn_throughput: 68.975\n",
      "    learn_time_ms: 144921.625\n",
      "    load_throughput: 88628.878\n",
      "    load_time_ms: 112.785\n",
      "    sample_throughput: 68.342\n",
      "    sample_time_ms: 146263.324\n",
      "    update_time_ms: 9.332\n",
      "  timestamp: 1636905999\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179928\n",
      "  training_iteration: 18\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         5264.19</td><td style=\"text-align: right;\">179928</td><td style=\"text-align: right;\"> 1.92982</td><td style=\"text-align: right;\">                9.74</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           92.0367</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 189924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-11-47\n",
      "  done: false\n",
      "  episode_len_mean: 95.28571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.680000000000007\n",
      "  episode_reward_mean: 1.5261904761904797\n",
      "  episode_reward_min: -2.0900000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 1946\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5923866663223656\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014990808165429826\n",
      "          policy_loss: -0.05124915889424519\n",
      "          total_loss: 0.17733568799896882\n",
      "          vf_explained_var: 0.725115954875946\n",
      "          vf_loss: 0.21608891286489226\n",
      "    num_agent_steps_sampled: 189924\n",
      "    num_agent_steps_trained: 189924\n",
      "    num_steps_sampled: 189924\n",
      "    num_steps_trained: 189924\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.96068181818183\n",
      "    ram_util_percent: 42.778181818181814\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04888471737729681\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.8099601872348\n",
      "    mean_inference_ms: 8.54060254247935\n",
      "    mean_raw_obs_processing_ms: 2.268498181073895\n",
      "  time_since_restore: 5572.056156635284\n",
      "  time_this_iter_s: 307.8646740913391\n",
      "  time_total_s: 5572.056156635284\n",
      "  timers:\n",
      "    learn_throughput: 68.982\n",
      "    learn_time_ms: 144906.872\n",
      "    load_throughput: 88776.177\n",
      "    load_time_ms: 112.598\n",
      "    sample_throughput: 67.076\n",
      "    sample_time_ms: 149024.671\n",
      "    update_time_ms: 8.284\n",
      "  timestamp: 1636906307\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189924\n",
      "  training_iteration: 19\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         5572.06</td><td style=\"text-align: right;\">189924</td><td style=\"text-align: right;\"> 1.52619</td><td style=\"text-align: right;\">                8.68</td><td style=\"text-align: right;\">               -2.09</td><td style=\"text-align: right;\">           95.2857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 199920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-16-30\n",
      "  done: false\n",
      "  episode_len_mean: 96.14423076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.810000000000013\n",
      "  episode_reward_mean: 1.977019230769235\n",
      "  episode_reward_min: -1.660000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 2050\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5920385914990027\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014553636918623747\n",
      "          policy_loss: -0.050832802840731404\n",
      "          total_loss: 0.1898929063636714\n",
      "          vf_explained_var: 0.6800243258476257\n",
      "          vf_loss: 0.22934671548975266\n",
      "    num_agent_steps_sampled: 199920\n",
      "    num_agent_steps_trained: 199920\n",
      "    num_steps_sampled: 199920\n",
      "    num_steps_trained: 199920\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.28759305210919\n",
      "    ram_util_percent: 42.81414392059553\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04896685741431954\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.788861424352238\n",
      "    mean_inference_ms: 8.541263043997768\n",
      "    mean_raw_obs_processing_ms: 2.187163920747485\n",
      "  time_since_restore: 5854.993953227997\n",
      "  time_this_iter_s: 282.9377965927124\n",
      "  time_total_s: 5854.993953227997\n",
      "  timers:\n",
      "    learn_throughput: 68.984\n",
      "    learn_time_ms: 144904.044\n",
      "    load_throughput: 89007.124\n",
      "    load_time_ms: 112.306\n",
      "    sample_throughput: 67.19\n",
      "    sample_time_ms: 148771.383\n",
      "    update_time_ms: 8.286\n",
      "  timestamp: 1636906590\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199920\n",
      "  training_iteration: 20\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5854.99</td><td style=\"text-align: right;\">199920</td><td style=\"text-align: right;\"> 1.97702</td><td style=\"text-align: right;\">                8.81</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           96.1442</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 209916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-21-29\n",
      "  done: false\n",
      "  episode_len_mean: 95.3076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.690000000000014\n",
      "  episode_reward_mean: 1.4474038461538492\n",
      "  episode_reward_min: -2.229999999999996\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 2154\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.573831805612287\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01478891218465308\n",
      "          policy_loss: -0.054327342605106854\n",
      "          total_loss: 0.14469867380073245\n",
      "          vf_explained_var: 0.7236766219139099\n",
      "          vf_loss: 0.18686197163720225\n",
      "    num_agent_steps_sampled: 209916\n",
      "    num_agent_steps_trained: 209916\n",
      "    num_steps_sampled: 209916\n",
      "    num_steps_trained: 209916\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.55747663551404\n",
      "    ram_util_percent: 43.011214953271036\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048894985260995755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.73109892834176\n",
      "    mean_inference_ms: 8.537856472962542\n",
      "    mean_raw_obs_processing_ms: 2.2813711459380284\n",
      "  time_since_restore: 6154.497422218323\n",
      "  time_this_iter_s: 299.5034689903259\n",
      "  time_total_s: 6154.497422218323\n",
      "  timers:\n",
      "    learn_throughput: 68.985\n",
      "    learn_time_ms: 144901.947\n",
      "    load_throughput: 88904.469\n",
      "    load_time_ms: 112.435\n",
      "    sample_throughput: 67.394\n",
      "    sample_time_ms: 148322.668\n",
      "    update_time_ms: 8.039\n",
      "  timestamp: 1636906889\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209916\n",
      "  training_iteration: 21\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">          6154.5</td><td style=\"text-align: right;\">209916</td><td style=\"text-align: right;\">  1.4474</td><td style=\"text-align: right;\">               12.69</td><td style=\"text-align: right;\">               -2.23</td><td style=\"text-align: right;\">           95.3077</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 219912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-26-28\n",
      "  done: false\n",
      "  episode_len_mean: 94.97169811320755\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.540000000000015\n",
      "  episode_reward_mean: 1.9624528301886834\n",
      "  episode_reward_min: -1.9100000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2260\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.577983933738154\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016482307783089026\n",
      "          policy_loss: -0.05310742948920681\n",
      "          total_loss: 0.20362163194630326\n",
      "          vf_explained_var: 0.7068442702293396\n",
      "          vf_loss: 0.24026654987699456\n",
      "    num_agent_steps_sampled: 219912\n",
      "    num_agent_steps_trained: 219912\n",
      "    num_steps_sampled: 219912\n",
      "    num_steps_trained: 219912\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.39812206572769\n",
      "    ram_util_percent: 42.57723004694836\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0488423735717476\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.727136543193375\n",
      "    mean_inference_ms: 8.53698994459014\n",
      "    mean_raw_obs_processing_ms: 2.2839992332105767\n",
      "  time_since_restore: 6453.205862045288\n",
      "  time_this_iter_s: 298.70843982696533\n",
      "  time_total_s: 6453.205862045288\n",
      "  timers:\n",
      "    learn_throughput: 68.985\n",
      "    learn_time_ms: 144901.921\n",
      "    load_throughput: 88816.817\n",
      "    load_time_ms: 112.546\n",
      "    sample_throughput: 66.917\n",
      "    sample_time_ms: 149378.688\n",
      "    update_time_ms: 8.282\n",
      "  timestamp: 1636907188\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219912\n",
      "  training_iteration: 22\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         6453.21</td><td style=\"text-align: right;\">219912</td><td style=\"text-align: right;\"> 1.96245</td><td style=\"text-align: right;\">                8.54</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           94.9717</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 229908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-31-12\n",
      "  done: false\n",
      "  episode_len_mean: 94.78095238095239\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.540000000000017\n",
      "  episode_reward_mean: 1.8037142857142896\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 2365\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5670608746699797\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01626357898875941\n",
      "          policy_loss: -0.052882363696972655\n",
      "          total_loss: 0.20770867521452727\n",
      "          vf_explained_var: 0.7249283194541931\n",
      "          vf_loss: 0.24457987422664834\n",
      "    num_agent_steps_sampled: 229908\n",
      "    num_agent_steps_trained: 229908\n",
      "    num_steps_sampled: 229908\n",
      "    num_steps_trained: 229908\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.2074074074074\n",
      "    ram_util_percent: 42.440987654320985\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04890959637341081\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.729670841584344\n",
      "    mean_inference_ms: 8.537817662743795\n",
      "    mean_raw_obs_processing_ms: 2.2171668643479285\n",
      "  time_since_restore: 6737.408773183823\n",
      "  time_this_iter_s: 284.20291113853455\n",
      "  time_total_s: 6737.408773183823\n",
      "  timers:\n",
      "    learn_throughput: 68.984\n",
      "    learn_time_ms: 144902.262\n",
      "    load_throughput: 88577.591\n",
      "    load_time_ms: 112.85\n",
      "    sample_throughput: 67.063\n",
      "    sample_time_ms: 149054.808\n",
      "    update_time_ms: 8.415\n",
      "  timestamp: 1636907472\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229908\n",
      "  training_iteration: 23\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         6737.41</td><td style=\"text-align: right;\">229908</td><td style=\"text-align: right;\"> 1.80371</td><td style=\"text-align: right;\">                8.54</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">            94.781</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 239904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-35-57\n",
      "  done: false\n",
      "  episode_len_mean: 94.12264150943396\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.420000000000016\n",
      "  episode_reward_mean: 1.6654716981132118\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2471\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5606892810927495\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015767214697755196\n",
      "          policy_loss: -0.05150007929127568\n",
      "          total_loss: 0.16309441970163782\n",
      "          vf_explained_var: 0.7561711072921753\n",
      "          vf_loss: 0.19979174573722686\n",
      "    num_agent_steps_sampled: 239904\n",
      "    num_agent_steps_trained: 239904\n",
      "    num_steps_sampled: 239904\n",
      "    num_steps_trained: 239904\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.33243243243244\n",
      "    ram_util_percent: 42.23390663390664\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04888920662134338\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.742081616804587\n",
      "    mean_inference_ms: 8.538687908971912\n",
      "    mean_raw_obs_processing_ms: 2.1575968289570744\n",
      "  time_since_restore: 7022.313279867172\n",
      "  time_this_iter_s: 284.9045066833496\n",
      "  time_total_s: 7022.313279867172\n",
      "  timers:\n",
      "    learn_throughput: 68.986\n",
      "    learn_time_ms: 144898.75\n",
      "    load_throughput: 88529.672\n",
      "    load_time_ms: 112.911\n",
      "    sample_throughput: 67.959\n",
      "    sample_time_ms: 147089.655\n",
      "    update_time_ms: 9.008\n",
      "  timestamp: 1636907757\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239904\n",
      "  training_iteration: 24\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         7022.31</td><td style=\"text-align: right;\">239904</td><td style=\"text-align: right;\"> 1.66547</td><td style=\"text-align: right;\">               12.42</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           94.1226</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 249900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-41-11\n",
      "  done: false\n",
      "  episode_len_mean: 90.7909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.810000000000011\n",
      "  episode_reward_mean: 1.8768181818181864\n",
      "  episode_reward_min: -2.229999999999999\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 2581\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.584720910920037\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015708214264731103\n",
      "          policy_loss: -0.05371588069834134\n",
      "          total_loss: 0.19130616118737426\n",
      "          vf_explained_var: 0.7147061228752136\n",
      "          vf_loss: 0.23061081553674023\n",
      "    num_agent_steps_sampled: 249900\n",
      "    num_agent_steps_trained: 249900\n",
      "    num_steps_sampled: 249900\n",
      "    num_steps_trained: 249900\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13668903803132\n",
      "    ram_util_percent: 42.9268456375839\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048810650686508\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.704967210486476\n",
      "    mean_inference_ms: 8.530586720992407\n",
      "    mean_raw_obs_processing_ms: 2.2951102866435353\n",
      "  time_since_restore: 7335.724592208862\n",
      "  time_this_iter_s: 313.41131234169006\n",
      "  time_total_s: 7335.724592208862\n",
      "  timers:\n",
      "    learn_throughput: 68.984\n",
      "    learn_time_ms: 144903.24\n",
      "    load_throughput: 88557.646\n",
      "    load_time_ms: 112.876\n",
      "    sample_throughput: 67.18\n",
      "    sample_time_ms: 148794.808\n",
      "    update_time_ms: 8.679\n",
      "  timestamp: 1636908071\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249900\n",
      "  training_iteration: 25\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         7335.72</td><td style=\"text-align: right;\">249900</td><td style=\"text-align: right;\"> 1.87682</td><td style=\"text-align: right;\">               10.81</td><td style=\"text-align: right;\">               -2.23</td><td style=\"text-align: right;\">           90.7909</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 259896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-45-53\n",
      "  done: false\n",
      "  episode_len_mean: 95.88571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.820000000000014\n",
      "  episode_reward_mean: 1.9579047619047671\n",
      "  episode_reward_min: -2.0700000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 2686\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5596622325416303\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015764957250735318\n",
      "          policy_loss: -0.05896871415420603\n",
      "          total_loss: 0.16775916708537783\n",
      "          vf_explained_var: 0.7666202187538147\n",
      "          vf_loss: 0.21192064354371312\n",
      "    num_agent_steps_sampled: 259896\n",
      "    num_agent_steps_trained: 259896\n",
      "    num_steps_sampled: 259896\n",
      "    num_steps_trained: 259896\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.32009925558313\n",
      "    ram_util_percent: 43.011662531017365\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0488279991394578\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.68425807260318\n",
      "    mean_inference_ms: 8.530980418328635\n",
      "    mean_raw_obs_processing_ms: 2.233318414919613\n",
      "  time_since_restore: 7618.064697742462\n",
      "  time_this_iter_s: 282.34010553359985\n",
      "  time_total_s: 7618.064697742462\n",
      "  timers:\n",
      "    learn_throughput: 68.982\n",
      "    learn_time_ms: 144908.142\n",
      "    load_throughput: 88756.894\n",
      "    load_time_ms: 112.622\n",
      "    sample_throughput: 67.183\n",
      "    sample_time_ms: 148787.287\n",
      "    update_time_ms: 9.08\n",
      "  timestamp: 1636908353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259896\n",
      "  training_iteration: 26\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         7618.06</td><td style=\"text-align: right;\">259896</td><td style=\"text-align: right;\">  1.9579</td><td style=\"text-align: right;\">               10.82</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           95.8857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 269892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-51-04\n",
      "  done: false\n",
      "  episode_len_mean: 93.59433962264151\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.600000000000014\n",
      "  episode_reward_mean: 1.6884905660377398\n",
      "  episode_reward_min: -2.2199999999999993\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2792\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.573404266895392\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014795967476210993\n",
      "          policy_loss: -0.060399559496814366\n",
      "          total_loss: 0.1477896484070752\n",
      "          vf_explained_var: 0.7464619278907776\n",
      "          vf_loss: 0.1960028048023645\n",
      "    num_agent_steps_sampled: 269892\n",
      "    num_agent_steps_trained: 269892\n",
      "    num_steps_sampled: 269892\n",
      "    num_steps_trained: 269892\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.71328828828828\n",
      "    ram_util_percent: 42.867792792792784\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04882500022651797\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.67915529274574\n",
      "    mean_inference_ms: 8.528343266347715\n",
      "    mean_raw_obs_processing_ms: 2.2793117719688696\n",
      "  time_since_restore: 7929.0835156440735\n",
      "  time_this_iter_s: 311.0188179016113\n",
      "  time_total_s: 7929.0835156440735\n",
      "  timers:\n",
      "    learn_throughput: 68.982\n",
      "    learn_time_ms: 144908.135\n",
      "    load_throughput: 88721.002\n",
      "    load_time_ms: 112.668\n",
      "    sample_throughput: 65.934\n",
      "    sample_time_ms: 151605.73\n",
      "    update_time_ms: 9.316\n",
      "  timestamp: 1636908664\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269892\n",
      "  training_iteration: 27\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         7929.08</td><td style=\"text-align: right;\">269892</td><td style=\"text-align: right;\"> 1.68849</td><td style=\"text-align: right;\">                 6.6</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           93.5943</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 279888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-56-02\n",
      "  done: false\n",
      "  episode_len_mean: 93.71296296296296\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.010000000000014\n",
      "  episode_reward_mean: 2.0086111111111147\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 2900\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5691857629352146\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016589410967632265\n",
      "          policy_loss: -0.05413030481172933\n",
      "          total_loss: 0.18442133229751234\n",
      "          vf_explained_var: 0.7092527151107788\n",
      "          vf_loss: 0.22172664952758922\n",
      "    num_agent_steps_sampled: 279888\n",
      "    num_agent_steps_trained: 279888\n",
      "    num_steps_sampled: 279888\n",
      "    num_steps_trained: 279888\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.63655660377357\n",
      "    ram_util_percent: 42.94622641509433\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0488380641166758\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.666967672183496\n",
      "    mean_inference_ms: 8.525704026411947\n",
      "    mean_raw_obs_processing_ms: 2.2838915428529187\n",
      "  time_since_restore: 8226.582585334778\n",
      "  time_this_iter_s: 297.49906969070435\n",
      "  time_total_s: 8226.582585334778\n",
      "  timers:\n",
      "    learn_throughput: 68.979\n",
      "    learn_time_ms: 144913.193\n",
      "    load_throughput: 89395.341\n",
      "    load_time_ms: 111.818\n",
      "    sample_throughput: 66.115\n",
      "    sample_time_ms: 151190.521\n",
      "    update_time_ms: 10.068\n",
      "  timestamp: 1636908962\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279888\n",
      "  training_iteration: 28\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         8226.58</td><td style=\"text-align: right;\">279888</td><td style=\"text-align: right;\"> 2.00861</td><td style=\"text-align: right;\">               11.01</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">            93.713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 289884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-01-04\n",
      "  done: false\n",
      "  episode_len_mean: 94.14150943396227\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000013\n",
      "  episode_reward_mean: 1.8386792452830225\n",
      "  episode_reward_min: -2.2199999999999984\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 3006\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.582319697049948\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014526438856344704\n",
      "          policy_loss: -0.057790955503144836\n",
      "          total_loss: 0.1470491826777052\n",
      "          vf_explained_var: 0.7188235521316528\n",
      "          vf_loss: 0.19343366217759683\n",
      "    num_agent_steps_sampled: 289884\n",
      "    num_agent_steps_trained: 289884\n",
      "    num_steps_sampled: 289884\n",
      "    num_steps_trained: 289884\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.71157407407406\n",
      "    ram_util_percent: 42.25555555555556\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048825668668122026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.66498428129597\n",
      "    mean_inference_ms: 8.52369868920889\n",
      "    mean_raw_obs_processing_ms: 2.2884016912237355\n",
      "  time_since_restore: 8528.876385688782\n",
      "  time_this_iter_s: 302.2938003540039\n",
      "  time_total_s: 8528.876385688782\n",
      "  timers:\n",
      "    learn_throughput: 68.975\n",
      "    learn_time_ms: 144922.496\n",
      "    load_throughput: 89464.356\n",
      "    load_time_ms: 111.732\n",
      "    sample_throughput: 66.364\n",
      "    sample_time_ms: 150624.615\n",
      "    update_time_ms: 10.079\n",
      "  timestamp: 1636909264\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289884\n",
      "  training_iteration: 29\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         8528.88</td><td style=\"text-align: right;\">289884</td><td style=\"text-align: right;\"> 1.83868</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           94.1415</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 299880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-05-56\n",
      "  done: false\n",
      "  episode_len_mean: 94.60952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.810000000000011\n",
      "  episode_reward_mean: 1.920380952380957\n",
      "  episode_reward_min: -1.7000000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3111\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5851261117519475\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014818931295880404\n",
      "          policy_loss: -0.05378797799348831\n",
      "          total_loss: 0.16705890245831165\n",
      "          vf_explained_var: 0.7302387952804565\n",
      "          vf_loss: 0.2087188432383168\n",
      "    num_agent_steps_sampled: 299880\n",
      "    num_agent_steps_trained: 299880\n",
      "    num_steps_sampled: 299880\n",
      "    num_steps_trained: 299880\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.17139423076924\n",
      "    ram_util_percent: 42.28966346153846\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04887167426490818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.710770948682708\n",
      "    mean_inference_ms: 8.522498275860183\n",
      "    mean_raw_obs_processing_ms: 2.236919320991838\n",
      "  time_since_restore: 8820.881980657578\n",
      "  time_this_iter_s: 292.0055949687958\n",
      "  time_total_s: 8820.881980657578\n",
      "  timers:\n",
      "    learn_throughput: 68.975\n",
      "    learn_time_ms: 144921.83\n",
      "    load_throughput: 89216.204\n",
      "    load_time_ms: 112.042\n",
      "    sample_throughput: 65.967\n",
      "    sample_time_ms: 151530.718\n",
      "    update_time_ms: 10.876\n",
      "  timestamp: 1636909556\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299880\n",
      "  training_iteration: 30\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         8820.88</td><td style=\"text-align: right;\">299880</td><td style=\"text-align: right;\"> 1.92038</td><td style=\"text-align: right;\">                8.81</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           94.6095</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 309876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-11-07\n",
      "  done: false\n",
      "  episode_len_mean: 93.16822429906541\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 2.1513084112149574\n",
      "  episode_reward_min: -1.9000000000000012\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 3218\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5808543984706587\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016710962400869445\n",
      "          policy_loss: -0.05846476658510092\n",
      "          total_loss: 0.18203106402761787\n",
      "          vf_explained_var: 0.7445911169052124\n",
      "          vf_loss: 0.22347600632546166\n",
      "    num_agent_steps_sampled: 309876\n",
      "    num_agent_steps_trained: 309876\n",
      "    num_steps_sampled: 309876\n",
      "    num_steps_trained: 309876\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.60743243243243\n",
      "    ram_util_percent: 42.71283783783784\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04886948297200591\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.70361194755933\n",
      "    mean_inference_ms: 8.519236254174105\n",
      "    mean_raw_obs_processing_ms: 2.3009404779474694\n",
      "  time_since_restore: 9132.0304210186\n",
      "  time_this_iter_s: 311.14844036102295\n",
      "  time_total_s: 9132.0304210186\n",
      "  timers:\n",
      "    learn_throughput: 68.974\n",
      "    learn_time_ms: 144923.845\n",
      "    load_throughput: 89312.388\n",
      "    load_time_ms: 111.922\n",
      "    sample_throughput: 65.465\n",
      "    sample_time_ms: 152693.205\n",
      "    update_time_ms: 11.009\n",
      "  timestamp: 1636909867\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309876\n",
      "  training_iteration: 31\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         9132.03</td><td style=\"text-align: right;\">309876</td><td style=\"text-align: right;\"> 2.15131</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           93.1682</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 319872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-16-08\n",
      "  done: false\n",
      "  episode_len_mean: 94.80952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.830000000000014\n",
      "  episode_reward_mean: 1.5287619047619085\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3323\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5896173026826648\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014390020027995568\n",
      "          policy_loss: -0.06033985315201183\n",
      "          total_loss: 0.15838939999270008\n",
      "          vf_explained_var: 0.7431181073188782\n",
      "          vf_loss: 0.20774537968393575\n",
      "    num_agent_steps_sampled: 319872\n",
      "    num_agent_steps_trained: 319872\n",
      "    num_steps_sampled: 319872\n",
      "    num_steps_trained: 319872\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.67186046511627\n",
      "    ram_util_percent: 42.386046511627924\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04883839271778385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.700749947377492\n",
      "    mean_inference_ms: 8.516103906098545\n",
      "    mean_raw_obs_processing_ms: 2.3055876445285786\n",
      "  time_since_restore: 9433.009431362152\n",
      "  time_this_iter_s: 300.97901034355164\n",
      "  time_total_s: 9433.009431362152\n",
      "  timers:\n",
      "    learn_throughput: 68.977\n",
      "    learn_time_ms: 144916.973\n",
      "    load_throughput: 89452.407\n",
      "    load_time_ms: 111.747\n",
      "    sample_throughput: 65.365\n",
      "    sample_time_ms: 152925.043\n",
      "    update_time_ms: 11.778\n",
      "  timestamp: 1636910168\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319872\n",
      "  training_iteration: 32\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         9433.01</td><td style=\"text-align: right;\">319872</td><td style=\"text-align: right;\"> 1.52876</td><td style=\"text-align: right;\">                6.83</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           94.8095</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 329868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-21-05\n",
      "  done: false\n",
      "  episode_len_mean: 95.87619047619047\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.66000000000001\n",
      "  episode_reward_mean: 2.235238095238101\n",
      "  episode_reward_min: -1.9600000000000013\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3428\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5857653080907643\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01626686169534125\n",
      "          policy_loss: -0.057534125109768325\n",
      "          total_loss: 0.16942929432202036\n",
      "          vf_explained_var: 0.7877746820449829\n",
      "          vf_loss: 0.21113088652093567\n",
      "    num_agent_steps_sampled: 329868\n",
      "    num_agent_steps_trained: 329868\n",
      "    num_steps_sampled: 329868\n",
      "    num_steps_trained: 329868\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.76170212765956\n",
      "    ram_util_percent: 42.76548463356973\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04886492532875061\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.68623182503863\n",
      "    mean_inference_ms: 8.515036711779917\n",
      "    mean_raw_obs_processing_ms: 2.30564862022989\n",
      "  time_since_restore: 9729.387799739838\n",
      "  time_this_iter_s: 296.37836837768555\n",
      "  time_total_s: 9729.387799739838\n",
      "  timers:\n",
      "    learn_throughput: 68.976\n",
      "    learn_time_ms: 144920.192\n",
      "    load_throughput: 89718.75\n",
      "    load_time_ms: 111.415\n",
      "    sample_throughput: 64.85\n",
      "    sample_time_ms: 154140.419\n",
      "    update_time_ms: 11.028\n",
      "  timestamp: 1636910465\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329868\n",
      "  training_iteration: 33\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         9729.39</td><td style=\"text-align: right;\">329868</td><td style=\"text-align: right;\"> 2.23524</td><td style=\"text-align: right;\">                8.66</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">           95.8762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 339864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-26-12\n",
      "  done: false\n",
      "  episode_len_mean: 94.98095238095237\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.010000000000016\n",
      "  episode_reward_mean: 2.045428571428577\n",
      "  episode_reward_min: -1.7100000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3533\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.559666298291622\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016356336874932775\n",
      "          policy_loss: -0.062473083486478044\n",
      "          total_loss: 0.15810741582073462\n",
      "          vf_explained_var: 0.7880002856254578\n",
      "          vf_loss: 0.20425766033924417\n",
      "    num_agent_steps_sampled: 339864\n",
      "    num_agent_steps_trained: 339864\n",
      "    num_steps_sampled: 339864\n",
      "    num_steps_trained: 339864\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.96924829157176\n",
      "    ram_util_percent: 43.07152619589978\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04886373229816507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.72632117212596\n",
      "    mean_inference_ms: 8.519628934667146\n",
      "    mean_raw_obs_processing_ms: 2.3081132976695393\n",
      "  time_since_restore: 10037.028620004654\n",
      "  time_this_iter_s: 307.6408202648163\n",
      "  time_total_s: 10037.028620004654\n",
      "  timers:\n",
      "    learn_throughput: 68.863\n",
      "    learn_time_ms: 145158.184\n",
      "    load_throughput: 89599.127\n",
      "    load_time_ms: 111.564\n",
      "    sample_throughput: 64.005\n",
      "    sample_time_ms: 156176.518\n",
      "    update_time_ms: 10.366\n",
      "  timestamp: 1636910772\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 339864\n",
      "  training_iteration: 34\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">           10037</td><td style=\"text-align: right;\">339864</td><td style=\"text-align: right;\"> 2.04543</td><td style=\"text-align: right;\">                9.01</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">            94.981</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 349860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-31-16\n",
      "  done: false\n",
      "  episode_len_mean: 94.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.450000000000017\n",
      "  episode_reward_mean: 1.8481132075471747\n",
      "  episode_reward_min: -1.980000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 3639\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5613448188855097\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015348474480575422\n",
      "          policy_loss: -0.06234284111569261\n",
      "          total_loss: 0.12560899546389812\n",
      "          vf_explained_var: 0.7819280624389648\n",
      "          vf_loss: 0.1742288253039249\n",
      "    num_agent_steps_sampled: 349860\n",
      "    num_agent_steps_trained: 349860\n",
      "    num_steps_sampled: 349860\n",
      "    num_steps_trained: 349860\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.2189376443418\n",
      "    ram_util_percent: 43.187759815242494\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04886953306167206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.742332007160943\n",
      "    mean_inference_ms: 8.520152108928961\n",
      "    mean_raw_obs_processing_ms: 2.310027608875683\n",
      "  time_since_restore: 10340.603357076645\n",
      "  time_this_iter_s: 303.57473707199097\n",
      "  time_total_s: 10340.603357076645\n",
      "  timers:\n",
      "    learn_throughput: 68.707\n",
      "    learn_time_ms: 145486.316\n",
      "    load_throughput: 89521.052\n",
      "    load_time_ms: 111.661\n",
      "    sample_throughput: 64.548\n",
      "    sample_time_ms: 154861.349\n",
      "    update_time_ms: 11.729\n",
      "  timestamp: 1636911076\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 349860\n",
      "  training_iteration: 35\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         10340.6</td><td style=\"text-align: right;\">349860</td><td style=\"text-align: right;\"> 1.84811</td><td style=\"text-align: right;\">               10.45</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">              94.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 359856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-36-23\n",
      "  done: false\n",
      "  episode_len_mean: 96.14423076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.280000000000017\n",
      "  episode_reward_mean: 2.070480769230775\n",
      "  episode_reward_min: -2.259999999999998\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 3743\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.560037349941384\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01489954991172307\n",
      "          policy_loss: -0.06522251498849632\n",
      "          total_loss: 0.12923692465306091\n",
      "          vf_explained_var: 0.749926745891571\n",
      "          vf_loss: 0.1818738979104365\n",
      "    num_agent_steps_sampled: 359856\n",
      "    num_agent_steps_trained: 359856\n",
      "    num_steps_sampled: 359856\n",
      "    num_steps_trained: 359856\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.02648401826482\n",
      "    ram_util_percent: 43.43401826484019\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04893971521494434\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.76388744562911\n",
      "    mean_inference_ms: 8.530791553235272\n",
      "    mean_raw_obs_processing_ms: 2.3124122605578106\n",
      "  time_since_restore: 10647.575882434845\n",
      "  time_this_iter_s: 306.9725253582001\n",
      "  time_total_s: 10647.575882434845\n",
      "  timers:\n",
      "    learn_throughput: 68.645\n",
      "    learn_time_ms: 145618.675\n",
      "    load_throughput: 89114.183\n",
      "    load_time_ms: 112.171\n",
      "    sample_throughput: 63.592\n",
      "    sample_time_ms: 157190.599\n",
      "    update_time_ms: 12.402\n",
      "  timestamp: 1636911383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 359856\n",
      "  training_iteration: 36\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         10647.6</td><td style=\"text-align: right;\">359856</td><td style=\"text-align: right;\"> 2.07048</td><td style=\"text-align: right;\">               10.28</td><td style=\"text-align: right;\">               -2.26</td><td style=\"text-align: right;\">           96.1442</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 369852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-41-26\n",
      "  done: false\n",
      "  episode_len_mean: 95.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.750000000000018\n",
      "  episode_reward_mean: 2.5010476190476245\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3848\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5612338684562945\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016568342916479\n",
      "          policy_loss: -0.06030153909729969\n",
      "          total_loss: 0.1614219836365336\n",
      "          vf_explained_var: 0.8153680562973022\n",
      "          vf_loss: 0.2048730126924367\n",
      "    num_agent_steps_sampled: 369852\n",
      "    num_agent_steps_trained: 369852\n",
      "    num_steps_sampled: 369852\n",
      "    num_steps_trained: 369852\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.38240740740741\n",
      "    ram_util_percent: 43.244675925925925\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048943513906673584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.78717497354928\n",
      "    mean_inference_ms: 8.531339777946869\n",
      "    mean_raw_obs_processing_ms: 2.3179296092133823\n",
      "  time_since_restore: 10950.859977722168\n",
      "  time_this_iter_s: 303.284095287323\n",
      "  time_total_s: 10950.859977722168\n",
      "  timers:\n",
      "    learn_throughput: 68.613\n",
      "    learn_time_ms: 145687.649\n",
      "    load_throughput: 89176.221\n",
      "    load_time_ms: 112.093\n",
      "    sample_throughput: 63.935\n",
      "    sample_time_ms: 156347.379\n",
      "    update_time_ms: 12.726\n",
      "  timestamp: 1636911686\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 369852\n",
      "  training_iteration: 37\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         10950.9</td><td style=\"text-align: right;\">369852</td><td style=\"text-align: right;\"> 2.50105</td><td style=\"text-align: right;\">               12.75</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">                95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 379848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-46-27\n",
      "  done: false\n",
      "  episode_len_mean: 96.09615384615384\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.300000000000017\n",
      "  episode_reward_mean: 2.296923076923083\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 3952\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5830588850200686\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015432534270562591\n",
      "          policy_loss: -0.058273292255675437\n",
      "          total_loss: 0.15640810851791762\n",
      "          vf_explained_var: 0.8080220222473145\n",
      "          vf_loss: 0.20096009283676808\n",
      "    num_agent_steps_sampled: 379848\n",
      "    num_agent_steps_trained: 379848\n",
      "    num_steps_sampled: 379848\n",
      "    num_steps_trained: 379848\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.34139534883721\n",
      "    ram_util_percent: 43.47488372093022\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04895877933254744\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.77223478677487\n",
      "    mean_inference_ms: 8.533109157277158\n",
      "    mean_raw_obs_processing_ms: 2.3174960746591067\n",
      "  time_since_restore: 11251.740082979202\n",
      "  time_this_iter_s: 300.8801052570343\n",
      "  time_total_s: 11251.740082979202\n",
      "  timers:\n",
      "    learn_throughput: 68.43\n",
      "    learn_time_ms: 146075.219\n",
      "    load_throughput: 88389.394\n",
      "    load_time_ms: 113.09\n",
      "    sample_throughput: 63.955\n",
      "    sample_time_ms: 156297.771\n",
      "    update_time_ms: 11.561\n",
      "  timestamp: 1636911987\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 379848\n",
      "  training_iteration: 38\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         11251.7</td><td style=\"text-align: right;\">379848</td><td style=\"text-align: right;\"> 2.29692</td><td style=\"text-align: right;\">                10.3</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           96.0962</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 389844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-51-29\n",
      "  done: false\n",
      "  episode_len_mean: 97.25242718446601\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000017\n",
      "  episode_reward_mean: 1.9056310679611708\n",
      "  episode_reward_min: -2.149999999999998\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4055\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.583685732091594\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015040750830955197\n",
      "          policy_loss: -0.0636506521055459\n",
      "          total_loss: 0.13192660332076314\n",
      "          vf_explained_var: 0.7843947410583496\n",
      "          vf_loss: 0.18286631515520252\n",
      "    num_agent_steps_sampled: 389844\n",
      "    num_agent_steps_trained: 389844\n",
      "    num_steps_sampled: 389844\n",
      "    num_steps_trained: 389844\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.3306976744186\n",
      "    ram_util_percent: 43.78697674418605\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04899847505105046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.745378971826778\n",
      "    mean_inference_ms: 8.53316606419393\n",
      "    mean_raw_obs_processing_ms: 2.319049221778193\n",
      "  time_since_restore: 11553.516698598862\n",
      "  time_this_iter_s: 301.7766156196594\n",
      "  time_total_s: 11553.516698598862\n",
      "  timers:\n",
      "    learn_throughput: 68.22\n",
      "    learn_time_ms: 146526.816\n",
      "    load_throughput: 88181.775\n",
      "    load_time_ms: 113.357\n",
      "    sample_throughput: 64.162\n",
      "    sample_time_ms: 155793.606\n",
      "    update_time_ms: 12.197\n",
      "  timestamp: 1636912289\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 389844\n",
      "  training_iteration: 39\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         11553.5</td><td style=\"text-align: right;\">389844</td><td style=\"text-align: right;\"> 1.90563</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">               -2.15</td><td style=\"text-align: right;\">           97.2524</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 399840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-56-31\n",
      "  done: false\n",
      "  episode_len_mean: 96.0673076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000014\n",
      "  episode_reward_mean: 1.513173076923081\n",
      "  episode_reward_min: -2.079999999999999\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 4159\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.588281627903637\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013877036709522603\n",
      "          policy_loss: -0.06546299894873658\n",
      "          total_loss: 0.11415193341990822\n",
      "          vf_explained_var: 0.7516317367553711\n",
      "          vf_loss: 0.16993242299550365\n",
      "    num_agent_steps_sampled: 399840\n",
      "    num_agent_steps_trained: 399840\n",
      "    num_steps_sampled: 399840\n",
      "    num_steps_trained: 399840\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.81716937354987\n",
      "    ram_util_percent: 44.12088167053364\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04906340501891292\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.741606909159408\n",
      "    mean_inference_ms: 8.536938655470644\n",
      "    mean_raw_obs_processing_ms: 2.3719442956157413\n",
      "  time_since_restore: 11855.142507314682\n",
      "  time_this_iter_s: 301.6258087158203\n",
      "  time_total_s: 11855.142507314682\n",
      "  timers:\n",
      "    learn_throughput: 68.207\n",
      "    learn_time_ms: 146554.299\n",
      "    load_throughput: 87948.0\n",
      "    load_time_ms: 113.658\n",
      "    sample_throughput: 63.779\n",
      "    sample_time_ms: 156728.865\n",
      "    update_time_ms: 11.395\n",
      "  timestamp: 1636912591\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 399840\n",
      "  training_iteration: 40\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         11855.1</td><td style=\"text-align: right;\">399840</td><td style=\"text-align: right;\"> 1.51317</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">               -2.08</td><td style=\"text-align: right;\">           96.0673</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 409836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-01-29\n",
      "  done: false\n",
      "  episode_len_mean: 95.66666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.10000000000001\n",
      "  episode_reward_mean: 2.126857142857147\n",
      "  episode_reward_min: -2.1199999999999983\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 4264\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5762263618982755\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015821370600555343\n",
      "          policy_loss: -0.0641740671528153\n",
      "          total_loss: 0.12568211444597852\n",
      "          vf_explained_var: 0.8009827136993408\n",
      "          vf_loss: 0.17507000355503688\n",
      "    num_agent_steps_sampled: 409836\n",
      "    num_agent_steps_trained: 409836\n",
      "    num_steps_sampled: 409836\n",
      "    num_steps_trained: 409836\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.75835294117648\n",
      "    ram_util_percent: 43.86070588235294\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04906840319337418\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.723959688729735\n",
      "    mean_inference_ms: 8.536454108287314\n",
      "    mean_raw_obs_processing_ms: 2.3692361642927566\n",
      "  time_since_restore: 12153.170394659042\n",
      "  time_this_iter_s: 298.02788734436035\n",
      "  time_total_s: 12153.170394659042\n",
      "  timers:\n",
      "    learn_throughput: 68.195\n",
      "    learn_time_ms: 146580.259\n",
      "    load_throughput: 87903.911\n",
      "    load_time_ms: 113.715\n",
      "    sample_throughput: 64.328\n",
      "    sample_time_ms: 155390.816\n",
      "    update_time_ms: 11.594\n",
      "  timestamp: 1636912889\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 409836\n",
      "  training_iteration: 41\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         12153.2</td><td style=\"text-align: right;\">409836</td><td style=\"text-align: right;\"> 2.12686</td><td style=\"text-align: right;\">                11.1</td><td style=\"text-align: right;\">               -2.12</td><td style=\"text-align: right;\">           95.6667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 419832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-06-20\n",
      "  done: false\n",
      "  episode_len_mean: 98.89108910891089\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.680000000000014\n",
      "  episode_reward_mean: 1.9891089108910942\n",
      "  episode_reward_min: -2.0700000000000007\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 4365\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5894092527210204\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015754456086417484\n",
      "          policy_loss: -0.06015002717518717\n",
      "          total_loss: 0.13434963416483284\n",
      "          vf_explained_var: 0.7770410776138306\n",
      "          vf_loss: 0.18001680749221743\n",
      "    num_agent_steps_sampled: 419832\n",
      "    num_agent_steps_trained: 419832\n",
      "    num_steps_sampled: 419832\n",
      "    num_steps_trained: 419832\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.51514423076922\n",
      "    ram_util_percent: 43.46346153846154\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049064538878324813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.736112108972566\n",
      "    mean_inference_ms: 8.543317799201654\n",
      "    mean_raw_obs_processing_ms: 2.3324786821976957\n",
      "  time_since_restore: 12444.801079750061\n",
      "  time_this_iter_s: 291.6306850910187\n",
      "  time_total_s: 12444.801079750061\n",
      "  timers:\n",
      "    learn_throughput: 67.981\n",
      "    learn_time_ms: 147041.741\n",
      "    load_throughput: 87615.085\n",
      "    load_time_ms: 114.09\n",
      "    sample_throughput: 64.91\n",
      "    sample_time_ms: 153996.7\n",
      "    update_time_ms: 11.061\n",
      "  timestamp: 1636913180\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 419832\n",
      "  training_iteration: 42\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         12444.8</td><td style=\"text-align: right;\">419832</td><td style=\"text-align: right;\"> 1.98911</td><td style=\"text-align: right;\">                8.68</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           98.8911</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 429828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-11-11\n",
      "  done: false\n",
      "  episode_len_mean: 97.96078431372548\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.490000000000016\n",
      "  episode_reward_mean: 1.9486274509803974\n",
      "  episode_reward_min: -1.980000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 4467\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5749557081450765\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014576571356247278\n",
      "          policy_loss: -0.06364019793243363\n",
      "          total_loss: 0.11612465370756885\n",
      "          vf_explained_var: 0.8113839626312256\n",
      "          vf_loss: 0.16815625105658147\n",
      "    num_agent_steps_sampled: 429828\n",
      "    num_agent_steps_trained: 429828\n",
      "    num_steps_sampled: 429828\n",
      "    num_steps_trained: 429828\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.30337349397591\n",
      "    ram_util_percent: 43.53180722891565\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04909534211129701\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.747533177282566\n",
      "    mean_inference_ms: 8.547709964209842\n",
      "    mean_raw_obs_processing_ms: 2.2950724280810078\n",
      "  time_since_restore: 12735.39778828621\n",
      "  time_this_iter_s: 290.59670853614807\n",
      "  time_total_s: 12735.39778828621\n",
      "  timers:\n",
      "    learn_throughput: 67.833\n",
      "    learn_time_ms: 147362.717\n",
      "    load_throughput: 87441.619\n",
      "    load_time_ms: 114.316\n",
      "    sample_throughput: 65.292\n",
      "    sample_time_ms: 153096.33\n",
      "    update_time_ms: 11.671\n",
      "  timestamp: 1636913471\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 429828\n",
      "  training_iteration: 43\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         12735.4</td><td style=\"text-align: right;\">429828</td><td style=\"text-align: right;\"> 1.94863</td><td style=\"text-align: right;\">               10.49</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           97.9608</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 439824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-16-49\n",
      "  done: false\n",
      "  episode_len_mean: 94.95192307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.660000000000014\n",
      "  episode_reward_mean: 2.071250000000005\n",
      "  episode_reward_min: -2.219999999999998\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 4571\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5755681451569257\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015923553186511327\n",
      "          policy_loss: -0.06246066974798361\n",
      "          total_loss: 0.1371981978870164\n",
      "          vf_explained_var: 0.7613310813903809\n",
      "          vf_loss: 0.18460422446712468\n",
      "    num_agent_steps_sampled: 439824\n",
      "    num_agent_steps_trained: 439824\n",
      "    num_steps_sampled: 439824\n",
      "    num_steps_trained: 439824\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.38856548856549\n",
      "    ram_util_percent: 44.80270270270271\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04914223068893068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.792684726372542\n",
      "    mean_inference_ms: 8.557731930760403\n",
      "    mean_raw_obs_processing_ms: 2.372697059994338\n",
      "  time_since_restore: 13073.037734508514\n",
      "  time_this_iter_s: 337.6399462223053\n",
      "  time_total_s: 13073.037734508514\n",
      "  timers:\n",
      "    learn_throughput: 67.369\n",
      "    learn_time_ms: 148376.064\n",
      "    load_throughput: 87426.011\n",
      "    load_time_ms: 114.337\n",
      "    sample_throughput: 64.456\n",
      "    sample_time_ms: 155082.881\n",
      "    update_time_ms: 11.666\n",
      "  timestamp: 1636913809\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 439824\n",
      "  training_iteration: 44\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">           13073</td><td style=\"text-align: right;\">439824</td><td style=\"text-align: right;\"> 2.07125</td><td style=\"text-align: right;\">               12.66</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           94.9519</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 449820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-21-50\n",
      "  done: false\n",
      "  episode_len_mean: 98.46601941747574\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.680000000000016\n",
      "  episode_reward_mean: 2.037281553398064\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4674\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5734053449753005\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014926903928372641\n",
      "          policy_loss: -0.06521144844949818\n",
      "          total_loss: 0.11814858285256494\n",
      "          vf_explained_var: 0.7864267230033875\n",
      "          vf_loss: 0.17083806361223006\n",
      "    num_agent_steps_sampled: 449820\n",
      "    num_agent_steps_trained: 449820\n",
      "    num_steps_sampled: 449820\n",
      "    num_steps_trained: 449820\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.01832946635732\n",
      "    ram_util_percent: 45.44849187935035\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04918925606922543\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.82332653715503\n",
      "    mean_inference_ms: 8.569207988596082\n",
      "    mean_raw_obs_processing_ms: 2.338250950728623\n",
      "  time_since_restore: 13374.862491607666\n",
      "  time_this_iter_s: 301.8247570991516\n",
      "  time_total_s: 13374.862491607666\n",
      "  timers:\n",
      "    learn_throughput: 67.03\n",
      "    learn_time_ms: 149128.314\n",
      "    load_throughput: 87286.117\n",
      "    load_time_ms: 114.52\n",
      "    sample_throughput: 64.843\n",
      "    sample_time_ms: 154156.092\n",
      "    update_time_ms: 11.253\n",
      "  timestamp: 1636914110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 449820\n",
      "  training_iteration: 45\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         13374.9</td><td style=\"text-align: right;\">449820</td><td style=\"text-align: right;\"> 2.03728</td><td style=\"text-align: right;\">               10.68</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">            98.466</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 459816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-27-04\n",
      "  done: false\n",
      "  episode_len_mean: 96.67961165048544\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.010000000000012\n",
      "  episode_reward_mean: 2.4835922330097144\n",
      "  episode_reward_min: -1.880000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4777\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5662724315610705\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016925706331568768\n",
      "          policy_loss: -0.06522116734622381\n",
      "          total_loss: 0.1492521928722819\n",
      "          vf_explained_var: 0.7851283550262451\n",
      "          vf_loss: 0.1967573508524742\n",
      "    num_agent_steps_sampled: 459816\n",
      "    num_agent_steps_trained: 459816\n",
      "    num_steps_sampled: 459816\n",
      "    num_steps_trained: 459816\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.04933035714285\n",
      "    ram_util_percent: 45.75825892857143\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04919899375624564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.83953056126168\n",
      "    mean_inference_ms: 8.577840832410129\n",
      "    mean_raw_obs_processing_ms: 2.3440752378743097\n",
      "  time_since_restore: 13688.77789402008\n",
      "  time_this_iter_s: 313.91540241241455\n",
      "  time_total_s: 13688.77789402008\n",
      "  timers:\n",
      "    learn_throughput: 66.682\n",
      "    learn_time_ms: 149904.997\n",
      "    load_throughput: 87533.1\n",
      "    load_time_ms: 114.197\n",
      "    sample_throughput: 64.877\n",
      "    sample_time_ms: 154075.936\n",
      "    update_time_ms: 10.054\n",
      "  timestamp: 1636914424\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 459816\n",
      "  training_iteration: 46\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         13688.8</td><td style=\"text-align: right;\">459816</td><td style=\"text-align: right;\"> 2.48359</td><td style=\"text-align: right;\">               11.01</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           96.6796</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 469812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-32-27\n",
      "  done: false\n",
      "  episode_len_mean: 96.80582524271844\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.419999999999963\n",
      "  episode_reward_mean: 1.8071844660194212\n",
      "  episode_reward_min: -1.730000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4880\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.56159122693233\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016070698658833087\n",
      "          policy_loss: -0.06289070767119655\n",
      "          total_loss: 0.1547669149748185\n",
      "          vf_explained_var: 0.781723141670227\n",
      "          vf_loss: 0.20208609324609303\n",
      "    num_agent_steps_sampled: 469812\n",
      "    num_agent_steps_trained: 469812\n",
      "    num_steps_sampled: 469812\n",
      "    num_steps_trained: 469812\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.62152173913044\n",
      "    ram_util_percent: 45.963478260869564\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049254439897742704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.864394519960527\n",
      "    mean_inference_ms: 8.587617053691215\n",
      "    mean_raw_obs_processing_ms: 2.349871853557815\n",
      "  time_since_restore: 14010.928398132324\n",
      "  time_this_iter_s: 322.15050411224365\n",
      "  time_total_s: 14010.928398132324\n",
      "  timers:\n",
      "    learn_throughput: 66.032\n",
      "    learn_time_ms: 151380.126\n",
      "    load_throughput: 86571.244\n",
      "    load_time_ms: 115.466\n",
      "    sample_throughput: 64.705\n",
      "    sample_time_ms: 154486.345\n",
      "    update_time_ms: 9.619\n",
      "  timestamp: 1636914747\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 469812\n",
      "  training_iteration: 47\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         14010.9</td><td style=\"text-align: right;\">469812</td><td style=\"text-align: right;\"> 1.80718</td><td style=\"text-align: right;\">               16.42</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           96.8058</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 479808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-37-56\n",
      "  done: false\n",
      "  episode_len_mean: 96.96116504854369\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.470000000000013\n",
      "  episode_reward_mean: 2.2660194174757335\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4983\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.568333717696687\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016492835037834486\n",
      "          policy_loss: -0.0642034399163965\n",
      "          total_loss: 0.14482020382554486\n",
      "          vf_explained_var: 0.7662680149078369\n",
      "          vf_loss: 0.19243764904622213\n",
      "    num_agent_steps_sampled: 479808\n",
      "    num_agent_steps_trained: 479808\n",
      "    num_steps_sampled: 479808\n",
      "    num_steps_trained: 479808\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.2456289978678\n",
      "    ram_util_percent: 46.30852878464819\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04932749645386349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.898503397627103\n",
      "    mean_inference_ms: 8.603761304600464\n",
      "    mean_raw_obs_processing_ms: 2.401105200894955\n",
      "  time_since_restore: 14339.851336479187\n",
      "  time_this_iter_s: 328.9229383468628\n",
      "  time_total_s: 14339.851336479187\n",
      "  timers:\n",
      "    learn_throughput: 65.695\n",
      "    learn_time_ms: 152158.575\n",
      "    load_throughput: 86023.395\n",
      "    load_time_ms: 116.201\n",
      "    sample_throughput: 63.868\n",
      "    sample_time_ms: 156510.144\n",
      "    update_time_ms: 8.843\n",
      "  timestamp: 1636915076\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 479808\n",
      "  training_iteration: 48\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         14339.9</td><td style=\"text-align: right;\">479808</td><td style=\"text-align: right;\"> 2.26602</td><td style=\"text-align: right;\">               10.47</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           96.9612</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 489804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 96.64423076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.420000000000012\n",
      "  episode_reward_mean: 2.8210576923076993\n",
      "  episode_reward_min: -2.0099999999999993\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5087\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.555722782652602\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015873147133034112\n",
      "          policy_loss: -0.06911472527222692\n",
      "          total_loss: 0.11072130407421635\n",
      "          vf_explained_var: 0.8455419540405273\n",
      "          vf_loss: 0.16471211756300977\n",
      "    num_agent_steps_sampled: 489804\n",
      "    num_agent_steps_trained: 489804\n",
      "    num_steps_sampled: 489804\n",
      "    num_steps_trained: 489804\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.77943925233645\n",
      "    ram_util_percent: 44.48855140186915\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04935811786897092\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.92580082091255\n",
      "    mean_inference_ms: 8.610785251526229\n",
      "    mean_raw_obs_processing_ms: 2.366434419479308\n",
      "  time_since_restore: 14639.873039960861\n",
      "  time_this_iter_s: 300.0217034816742\n",
      "  time_total_s: 14639.873039960861\n",
      "  timers:\n",
      "    learn_throughput: 65.462\n",
      "    learn_time_ms: 152698.632\n",
      "    load_throughput: 85952.94\n",
      "    load_time_ms: 116.296\n",
      "    sample_throughput: 64.161\n",
      "    sample_time_ms: 155794.565\n",
      "    update_time_ms: 8.273\n",
      "  timestamp: 1636915376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 489804\n",
      "  training_iteration: 49\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         14639.9</td><td style=\"text-align: right;\">489804</td><td style=\"text-align: right;\"> 2.82106</td><td style=\"text-align: right;\">               12.42</td><td style=\"text-align: right;\">               -2.01</td><td style=\"text-align: right;\">           96.6442</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 499800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-47-52\n",
      "  done: false\n",
      "  episode_len_mean: 99.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.490000000000016\n",
      "  episode_reward_mean: 2.142900000000006\n",
      "  episode_reward_min: -1.830000000000001\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 5187\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.56054032765902\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01662307405462549\n",
      "          policy_loss: -0.06482438477767138\n",
      "          total_loss: 0.14611082546389065\n",
      "          vf_explained_var: 0.8170629739761353\n",
      "          vf_loss: 0.1939374939005217\n",
      "    num_agent_steps_sampled: 499800\n",
      "    num_agent_steps_trained: 499800\n",
      "    num_steps_sampled: 499800\n",
      "    num_steps_trained: 499800\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.5175355450237\n",
      "    ram_util_percent: 44.31184834123222\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0494112132181651\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.933962959389472\n",
      "    mean_inference_ms: 8.616737696864897\n",
      "    mean_raw_obs_processing_ms: 2.33184442216124\n",
      "  time_since_restore: 14935.961206674576\n",
      "  time_this_iter_s: 296.0881667137146\n",
      "  time_total_s: 14935.961206674576\n",
      "  timers:\n",
      "    learn_throughput: 65.125\n",
      "    learn_time_ms: 153490.586\n",
      "    load_throughput: 86311.15\n",
      "    load_time_ms: 115.814\n",
      "    sample_throughput: 64.72\n",
      "    sample_time_ms: 154448.833\n",
      "    update_time_ms: 8.853\n",
      "  timestamp: 1636915672\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 499800\n",
      "  training_iteration: 50\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">           14936</td><td style=\"text-align: right;\">499800</td><td style=\"text-align: right;\">  2.1429</td><td style=\"text-align: right;\">                8.49</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">             99.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 509796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-53-15\n",
      "  done: false\n",
      "  episode_len_mean: 94.64761904761905\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.9000000000000155\n",
      "  episode_reward_mean: 1.6574285714285755\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 5292\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5728517648501272\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015414993540687138\n",
      "          policy_loss: -0.06842817571252967\n",
      "          total_loss: 0.12108448853210793\n",
      "          vf_explained_var: 0.7387208938598633\n",
      "          vf_loss: 0.17573424040212526\n",
      "    num_agent_steps_sampled: 509796\n",
      "    num_agent_steps_trained: 509796\n",
      "    num_steps_sampled: 509796\n",
      "    num_steps_trained: 509796\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.67960954446855\n",
      "    ram_util_percent: 44.41496746203904\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049437682517371836\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.921063051859328\n",
      "    mean_inference_ms: 8.61918033738965\n",
      "    mean_raw_obs_processing_ms: 2.4034203493126176\n",
      "  time_since_restore: 15259.108875751495\n",
      "  time_this_iter_s: 323.14766907691956\n",
      "  time_total_s: 15259.108875751495\n",
      "  timers:\n",
      "    learn_throughput: 64.779\n",
      "    learn_time_ms: 154309.68\n",
      "    load_throughput: 86625.047\n",
      "    load_time_ms: 115.394\n",
      "    sample_throughput: 64.019\n",
      "    sample_time_ms: 156142.006\n",
      "    update_time_ms: 8.85\n",
      "  timestamp: 1636915995\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 509796\n",
      "  training_iteration: 51\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         15259.1</td><td style=\"text-align: right;\">509796</td><td style=\"text-align: right;\"> 1.65743</td><td style=\"text-align: right;\">                 6.9</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           94.6476</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 519792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-58-46\n",
      "  done: false\n",
      "  episode_len_mean: 97.41176470588235\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.060000000000013\n",
      "  episode_reward_mean: 2.326764705882358\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 5394\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5635588821182904\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01670597467390989\n",
      "          policy_loss: -0.06633417455750143\n",
      "          total_loss: 0.12356031411924423\n",
      "          vf_explained_var: 0.7999658584594727\n",
      "          vf_loss: 0.1727144927618245\n",
      "    num_agent_steps_sampled: 519792\n",
      "    num_agent_steps_trained: 519792\n",
      "    num_steps_sampled: 519792\n",
      "    num_steps_trained: 519792\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09386892177591\n",
      "    ram_util_percent: 44.61416490486258\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049483756821304174\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.888021883374293\n",
      "    mean_inference_ms: 8.619275987382176\n",
      "    mean_raw_obs_processing_ms: 2.46256475734667\n",
      "  time_since_restore: 15590.235189676285\n",
      "  time_this_iter_s: 331.12631392478943\n",
      "  time_total_s: 15590.235189676285\n",
      "  timers:\n",
      "    learn_throughput: 64.625\n",
      "    learn_time_ms: 154677.801\n",
      "    load_throughput: 86932.618\n",
      "    load_time_ms: 114.986\n",
      "    sample_throughput: 62.583\n",
      "    sample_time_ms: 159723.743\n",
      "    update_time_ms: 8.632\n",
      "  timestamp: 1636916326\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 519792\n",
      "  training_iteration: 52\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         15590.2</td><td style=\"text-align: right;\">519792</td><td style=\"text-align: right;\"> 2.32676</td><td style=\"text-align: right;\">               11.06</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           97.4118</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 529788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-03-44\n",
      "  done: false\n",
      "  episode_len_mean: 97.47572815533981\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.100000000000012\n",
      "  episode_reward_mean: 1.8826213592233056\n",
      "  episode_reward_min: -1.9400000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 5497\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5643992714392834\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01694179143524277\n",
      "          policy_loss: -0.0630826420421338\n",
      "          total_loss: 0.1367810504273193\n",
      "          vf_explained_var: 0.8140629529953003\n",
      "          vf_loss: 0.18208772794216171\n",
      "    num_agent_steps_sampled: 529788\n",
      "    num_agent_steps_trained: 529788\n",
      "    num_steps_sampled: 529788\n",
      "    num_steps_trained: 529788\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.52729411764706\n",
      "    ram_util_percent: 44.23223529411764\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049524567847285296\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.903917519596565\n",
      "    mean_inference_ms: 8.624880884040344\n",
      "    mean_raw_obs_processing_ms: 2.4252548229216804\n",
      "  time_since_restore: 15888.032472133636\n",
      "  time_this_iter_s: 297.7972824573517\n",
      "  time_total_s: 15888.032472133636\n",
      "  timers:\n",
      "    learn_throughput: 64.394\n",
      "    learn_time_ms: 155232.228\n",
      "    load_throughput: 87308.529\n",
      "    load_time_ms: 114.491\n",
      "    sample_throughput: 62.518\n",
      "    sample_time_ms: 159889.862\n",
      "    update_time_ms: 8.835\n",
      "  timestamp: 1636916624\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 529788\n",
      "  training_iteration: 53\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">           15888</td><td style=\"text-align: right;\">529788</td><td style=\"text-align: right;\"> 1.88262</td><td style=\"text-align: right;\">                 9.1</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           97.4757</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 539784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-08-40\n",
      "  done: false\n",
      "  episode_len_mean: 99.01960784313725\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.250000000000016\n",
      "  episode_reward_mean: 2.2787254901960847\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 5599\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5650242653667417\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015093052584488913\n",
      "          policy_loss: -0.07204266106908838\n",
      "          total_loss: 0.09134344308175402\n",
      "          vf_explained_var: 0.8394483327865601\n",
      "          vf_loss: 0.15035450451800392\n",
      "    num_agent_steps_sampled: 539784\n",
      "    num_agent_steps_trained: 539784\n",
      "    num_steps_sampled: 539784\n",
      "    num_steps_trained: 539784\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.52962085308057\n",
      "    ram_util_percent: 44.01753554502369\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049550848789506004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.91153129139135\n",
      "    mean_inference_ms: 8.629089182713464\n",
      "    mean_raw_obs_processing_ms: 2.3989403776454465\n",
      "  time_since_restore: 16184.078197956085\n",
      "  time_this_iter_s: 296.04572582244873\n",
      "  time_total_s: 16184.078197956085\n",
      "  timers:\n",
      "    learn_throughput: 64.558\n",
      "    learn_time_ms: 154838.244\n",
      "    load_throughput: 87303.62\n",
      "    load_time_ms: 114.497\n",
      "    sample_throughput: 64.026\n",
      "    sample_time_ms: 156124.158\n",
      "    update_time_ms: 8.862\n",
      "  timestamp: 1636916920\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 539784\n",
      "  training_iteration: 54\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         16184.1</td><td style=\"text-align: right;\">539784</td><td style=\"text-align: right;\"> 2.27873</td><td style=\"text-align: right;\">               10.25</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           99.0196</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 549780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-13-50\n",
      "  done: false\n",
      "  episode_len_mean: 95.25961538461539\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.240000000000014\n",
      "  episode_reward_mean: 1.8837500000000058\n",
      "  episode_reward_min: -2.11\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5703\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5664462346297046\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016794230592454523\n",
      "          policy_loss: -0.07028174814171134\n",
      "          total_loss: 0.11398230192219663\n",
      "          vf_explained_var: 0.8116009831428528\n",
      "          vf_loss: 0.16688673812617413\n",
      "    num_agent_steps_sampled: 549780\n",
      "    num_agent_steps_trained: 549780\n",
      "    num_steps_sampled: 549780\n",
      "    num_steps_trained: 549780\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.03755656108596\n",
      "    ram_util_percent: 44.42986425339367\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049548856152048584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.90868090438702\n",
      "    mean_inference_ms: 8.632359303178674\n",
      "    mean_raw_obs_processing_ms: 2.4306582868327813\n",
      "  time_since_restore: 16493.66888666153\n",
      "  time_this_iter_s: 309.59068870544434\n",
      "  time_total_s: 16493.66888666153\n",
      "  timers:\n",
      "    learn_throughput: 64.686\n",
      "    learn_time_ms: 154532.297\n",
      "    load_throughput: 87620.194\n",
      "    load_time_ms: 114.083\n",
      "    sample_throughput: 63.584\n",
      "    sample_time_ms: 157209.402\n",
      "    update_time_ms: 7.888\n",
      "  timestamp: 1636917230\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 549780\n",
      "  training_iteration: 55\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         16493.7</td><td style=\"text-align: right;\">549780</td><td style=\"text-align: right;\"> 1.88375</td><td style=\"text-align: right;\">                7.24</td><td style=\"text-align: right;\">               -2.11</td><td style=\"text-align: right;\">           95.2596</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 559776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-19-03\n",
      "  done: false\n",
      "  episode_len_mean: 95.75961538461539\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.310000000000016\n",
      "  episode_reward_mean: 2.2206730769230827\n",
      "  episode_reward_min: -1.9400000000000013\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5807\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.570980368822049\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01622199195330858\n",
      "          policy_loss: -0.06567862729987718\n",
      "          total_loss: 0.11127333860629453\n",
      "          vf_explained_var: 0.8532184958457947\n",
      "          vf_loss: 0.16108658016125998\n",
      "    num_agent_steps_sampled: 559776\n",
      "    num_agent_steps_trained: 559776\n",
      "    num_steps_sampled: 559776\n",
      "    num_steps_trained: 559776\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.03803131991052\n",
      "    ram_util_percent: 44.8986577181208\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049559445519021625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.924850294371446\n",
      "    mean_inference_ms: 8.635216354205518\n",
      "    mean_raw_obs_processing_ms: 2.4307190862833967\n",
      "  time_since_restore: 16807.177783489227\n",
      "  time_this_iter_s: 313.50889682769775\n",
      "  time_total_s: 16807.177783489227\n",
      "  timers:\n",
      "    learn_throughput: 64.709\n",
      "    learn_time_ms: 154476.728\n",
      "    load_throughput: 87290.933\n",
      "    load_time_ms: 114.514\n",
      "    sample_throughput: 63.578\n",
      "    sample_time_ms: 157223.176\n",
      "    update_time_ms: 8.458\n",
      "  timestamp: 1636917543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 559776\n",
      "  training_iteration: 56\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         16807.2</td><td style=\"text-align: right;\">559776</td><td style=\"text-align: right;\"> 2.22067</td><td style=\"text-align: right;\">               10.31</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           95.7596</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 569772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-24-16\n",
      "  done: false\n",
      "  episode_len_mean: 98.33980582524272\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.800000000000015\n",
      "  episode_reward_mean: 2.0951456310679664\n",
      "  episode_reward_min: -1.8800000000000012\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 5910\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5658853833491984\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01619378611772238\n",
      "          policy_loss: -0.06474879480516299\n",
      "          total_loss: 0.1200120730795221\n",
      "          vf_explained_var: 0.7873438000679016\n",
      "          vf_loss: 0.16891682003107336\n",
      "    num_agent_steps_sampled: 569772\n",
      "    num_agent_steps_trained: 569772\n",
      "    num_steps_sampled: 569772\n",
      "    num_steps_trained: 569772\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.05739910313903\n",
      "    ram_util_percent: 44.94663677130043\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0495489710393506\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93868799466182\n",
      "    mean_inference_ms: 8.637309900573626\n",
      "    mean_raw_obs_processing_ms: 2.4297802460926543\n",
      "  time_since_restore: 17119.756508350372\n",
      "  time_this_iter_s: 312.578724861145\n",
      "  time_total_s: 17119.756508350372\n",
      "  timers:\n",
      "    learn_throughput: 65.009\n",
      "    learn_time_ms: 153763.354\n",
      "    load_throughput: 88256.935\n",
      "    load_time_ms: 113.26\n",
      "    sample_throughput: 63.677\n",
      "    sample_time_ms: 156980.415\n",
      "    update_time_ms: 8.586\n",
      "  timestamp: 1636917856\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 569772\n",
      "  training_iteration: 57\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         17119.8</td><td style=\"text-align: right;\">569772</td><td style=\"text-align: right;\"> 2.09515</td><td style=\"text-align: right;\">                12.8</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           98.3398</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 579768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-29-31\n",
      "  done: false\n",
      "  episode_len_mean: 95.54368932038835\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.620000000000017\n",
      "  episode_reward_mean: 2.3000970873786466\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 6013\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5499601354965797\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015548596245024046\n",
      "          policy_loss: -0.06934854329452236\n",
      "          total_loss: 0.09234743708720765\n",
      "          vf_explained_var: 0.860692024230957\n",
      "          vf_loss: 0.14734623023054094\n",
      "    num_agent_steps_sampled: 579768\n",
      "    num_agent_steps_trained: 579768\n",
      "    num_steps_sampled: 579768\n",
      "    num_steps_trained: 579768\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.88222222222223\n",
      "    ram_util_percent: 44.93933333333333\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04954249066473287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.974997933096272\n",
      "    mean_inference_ms: 8.640398522128146\n",
      "    mean_raw_obs_processing_ms: 2.433387326553652\n",
      "  time_since_restore: 17435.230506420135\n",
      "  time_this_iter_s: 315.4739980697632\n",
      "  time_total_s: 17435.230506420135\n",
      "  timers:\n",
      "    learn_throughput: 65.162\n",
      "    learn_time_ms: 153403.458\n",
      "    load_throughput: 88761.63\n",
      "    load_time_ms: 112.616\n",
      "    sample_throughput: 64.078\n",
      "    sample_time_ms: 155996.733\n",
      "    update_time_ms: 9.937\n",
      "  timestamp: 1636918171\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 579768\n",
      "  training_iteration: 58\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         17435.2</td><td style=\"text-align: right;\">579768</td><td style=\"text-align: right;\">  2.3001</td><td style=\"text-align: right;\">                8.62</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           95.5437</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 589764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-35-11\n",
      "  done: false\n",
      "  episode_len_mean: 97.36893203883496\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.760000000000002\n",
      "  episode_reward_mean: 2.061650485436899\n",
      "  episode_reward_min: -1.7300000000000004\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 6116\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5746788846121893\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016106837603738735\n",
      "          policy_loss: -0.0678455212006234\n",
      "          total_loss: 0.12461793024140673\n",
      "          vf_explained_var: 0.7892800569534302\n",
      "          vf_loss: 0.17693017796796356\n",
      "    num_agent_steps_sampled: 589764\n",
      "    num_agent_steps_trained: 589764\n",
      "    num_steps_sampled: 589764\n",
      "    num_steps_trained: 589764\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.44742268041237\n",
      "    ram_util_percent: 44.64989690721649\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04953982911925703\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.971912492822337\n",
      "    mean_inference_ms: 8.64174595480943\n",
      "    mean_raw_obs_processing_ms: 2.490898304461661\n",
      "  time_since_restore: 17775.083691358566\n",
      "  time_this_iter_s: 339.8531849384308\n",
      "  time_total_s: 17775.083691358566\n",
      "  timers:\n",
      "    learn_throughput: 65.222\n",
      "    learn_time_ms: 153260.912\n",
      "    load_throughput: 88592.939\n",
      "    load_time_ms: 112.831\n",
      "    sample_throughput: 62.427\n",
      "    sample_time_ms: 160122.174\n",
      "    update_time_ms: 10.292\n",
      "  timestamp: 1636918511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 589764\n",
      "  training_iteration: 59\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         17775.1</td><td style=\"text-align: right;\">589764</td><td style=\"text-align: right;\"> 2.06165</td><td style=\"text-align: right;\">                9.76</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           97.3689</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 599760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 99.27450980392157\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.34000000000002\n",
      "  episode_reward_mean: 2.465294117647065\n",
      "  episode_reward_min: -2.0599999999999987\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 6218\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.577608354275043\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015623231323259202\n",
      "          policy_loss: -0.06602522920833057\n",
      "          total_loss: 0.08886749180328324\n",
      "          vf_explained_var: 0.8619842529296875\n",
      "          vf_loss: 0.14062817245522816\n",
      "    num_agent_steps_sampled: 599760\n",
      "    num_agent_steps_trained: 599760\n",
      "    num_steps_sampled: 599760\n",
      "    num_steps_trained: 599760\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.5525059665871\n",
      "    ram_util_percent: 44.44940334128879\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04959778455102987\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.969930552244186\n",
      "    mean_inference_ms: 8.646262780400864\n",
      "    mean_raw_obs_processing_ms: 2.457260151136393\n",
      "  time_since_restore: 18068.227132320404\n",
      "  time_this_iter_s: 293.14344096183777\n",
      "  time_total_s: 18068.227132320404\n",
      "  timers:\n",
      "    learn_throughput: 65.22\n",
      "    learn_time_ms: 153265.779\n",
      "    load_throughput: 88178.789\n",
      "    load_time_ms: 113.361\n",
      "    sample_throughput: 62.544\n",
      "    sample_time_ms: 159822.977\n",
      "    update_time_ms: 9.711\n",
      "  timestamp: 1636918804\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 599760\n",
      "  training_iteration: 60\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         18068.2</td><td style=\"text-align: right;\">599760</td><td style=\"text-align: right;\"> 2.46529</td><td style=\"text-align: right;\">               10.34</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           99.2745</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 609756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-45-01\n",
      "  done: false\n",
      "  episode_len_mean: 97.45098039215686\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.550000000000017\n",
      "  episode_reward_mean: 2.2210784313725553\n",
      "  episode_reward_min: -1.9000000000000008\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 6320\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5674553842626064\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015870046660469216\n",
      "          policy_loss: -0.06735056701641626\n",
      "          total_loss: 0.10089946897485508\n",
      "          vf_explained_var: 0.818464457988739\n",
      "          vf_loss: 0.153251397352602\n",
      "    num_agent_steps_sampled: 609756\n",
      "    num_agent_steps_trained: 609756\n",
      "    num_steps_sampled: 609756\n",
      "    num_steps_trained: 609756\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.4758865248227\n",
      "    ram_util_percent: 44.17659574468085\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04960037661888211\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.98235225389242\n",
      "    mean_inference_ms: 8.649880900322175\n",
      "    mean_raw_obs_processing_ms: 2.4291168089764836\n",
      "  time_since_restore: 18364.81714963913\n",
      "  time_this_iter_s: 296.5900173187256\n",
      "  time_total_s: 18364.81714963913\n",
      "  timers:\n",
      "    learn_throughput: 65.21\n",
      "    learn_time_ms: 153290.364\n",
      "    load_throughput: 88030.783\n",
      "    load_time_ms: 113.551\n",
      "    sample_throughput: 63.611\n",
      "    sample_time_ms: 157142.161\n",
      "    update_time_ms: 9.964\n",
      "  timestamp: 1636919101\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 609756\n",
      "  training_iteration: 61\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         18364.8</td><td style=\"text-align: right;\">609756</td><td style=\"text-align: right;\"> 2.22108</td><td style=\"text-align: right;\">                8.55</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">            97.451</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 619752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-50-28\n",
      "  done: false\n",
      "  episode_len_mean: 95.62857142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.980000000000013\n",
      "  episode_reward_mean: 2.142000000000006\n",
      "  episode_reward_min: -1.7700000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 6425\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5732113941102965\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014286047546309855\n",
      "          policy_loss: -0.06830767460135567\n",
      "          total_loss: 0.09491109809655154\n",
      "          vf_explained_var: 0.8274552226066589\n",
      "          vf_loss: 0.15233730995454467\n",
      "    num_agent_steps_sampled: 619752\n",
      "    num_agent_steps_trained: 619752\n",
      "    num_steps_sampled: 619752\n",
      "    num_steps_trained: 619752\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.5824034334764\n",
      "    ram_util_percent: 45.05472103004292\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049592700057605535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.97518673852784\n",
      "    mean_inference_ms: 8.650734602219922\n",
      "    mean_raw_obs_processing_ms: 2.485514868684583\n",
      "  time_since_restore: 18691.819765806198\n",
      "  time_this_iter_s: 327.0026161670685\n",
      "  time_total_s: 18691.819765806198\n",
      "  timers:\n",
      "    learn_throughput: 65.18\n",
      "    learn_time_ms: 153359.225\n",
      "    load_throughput: 87979.577\n",
      "    load_time_ms: 113.617\n",
      "    sample_throughput: 63.807\n",
      "    sample_time_ms: 156660.482\n",
      "    update_time_ms: 10.179\n",
      "  timestamp: 1636919428\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 619752\n",
      "  training_iteration: 62\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         18691.8</td><td style=\"text-align: right;\">619752</td><td style=\"text-align: right;\">   2.142</td><td style=\"text-align: right;\">                8.98</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           95.6286</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 629748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-55-37\n",
      "  done: false\n",
      "  episode_len_mean: 96.2135922330097\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.960000000000013\n",
      "  episode_reward_mean: 2.3939805825242777\n",
      "  episode_reward_min: -2.0600000000000005\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 6528\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.578381388819116\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016696693948290455\n",
      "          policy_loss: -0.06768832699570837\n",
      "          total_loss: 0.11273377570592297\n",
      "          vf_explained_var: 0.8134579062461853\n",
      "          vf_loss: 0.1634141177368852\n",
      "    num_agent_steps_sampled: 629748\n",
      "    num_agent_steps_trained: 629748\n",
      "    num_steps_sampled: 629748\n",
      "    num_steps_trained: 629748\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.89841269841271\n",
      "    ram_util_percent: 45.3954648526077\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04958947282369606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.97683766370287\n",
      "    mean_inference_ms: 8.65268105180966\n",
      "    mean_raw_obs_processing_ms: 2.4858379901978678\n",
      "  time_since_restore: 19000.697370052338\n",
      "  time_this_iter_s: 308.8776042461395\n",
      "  time_total_s: 19000.697370052338\n",
      "  timers:\n",
      "    learn_throughput: 65.224\n",
      "    learn_time_ms: 153257.264\n",
      "    load_throughput: 87702.893\n",
      "    load_time_ms: 113.976\n",
      "    sample_throughput: 63.318\n",
      "    sample_time_ms: 157869.851\n",
      "    update_time_ms: 10.262\n",
      "  timestamp: 1636919737\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 629748\n",
      "  training_iteration: 63\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         19000.7</td><td style=\"text-align: right;\">629748</td><td style=\"text-align: right;\"> 2.39398</td><td style=\"text-align: right;\">               10.96</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           96.2136</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 639744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-00-36\n",
      "  done: false\n",
      "  episode_len_mean: 96.27619047619048\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.750000000000016\n",
      "  episode_reward_mean: 2.2942857142857194\n",
      "  episode_reward_min: -2.05\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 6633\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5866217356461747\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015851836141782833\n",
      "          policy_loss: -0.06924217230696073\n",
      "          total_loss: 0.10923908247779578\n",
      "          vf_explained_var: 0.808504581451416\n",
      "          vf_loss: 0.1637209505865621\n",
      "    num_agent_steps_sampled: 639744\n",
      "    num_agent_steps_trained: 639744\n",
      "    num_steps_sampled: 639744\n",
      "    num_steps_trained: 639744\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.67564402810305\n",
      "    ram_util_percent: 44.90468384074941\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049614247531045125\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.993426403609515\n",
      "    mean_inference_ms: 8.656165848871424\n",
      "    mean_raw_obs_processing_ms: 2.4574508674028324\n",
      "  time_since_restore: 19299.734593153\n",
      "  time_this_iter_s: 299.03722310066223\n",
      "  time_total_s: 19299.734593153\n",
      "  timers:\n",
      "    learn_throughput: 65.225\n",
      "    learn_time_ms: 153254.034\n",
      "    load_throughput: 87781.411\n",
      "    load_time_ms: 113.874\n",
      "    sample_throughput: 63.197\n",
      "    sample_time_ms: 158171.648\n",
      "    update_time_ms: 11.173\n",
      "  timestamp: 1636920036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 639744\n",
      "  training_iteration: 64\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         19299.7</td><td style=\"text-align: right;\">639744</td><td style=\"text-align: right;\"> 2.29429</td><td style=\"text-align: right;\">               10.75</td><td style=\"text-align: right;\">               -2.05</td><td style=\"text-align: right;\">           96.2762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 649740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-05-46\n",
      "  done: false\n",
      "  episode_len_mean: 96.35922330097087\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.680000000000023\n",
      "  episode_reward_mean: 2.073883495145636\n",
      "  episode_reward_min: -1.9400000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 6736\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5912129587597317\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016258706446796167\n",
      "          policy_loss: -0.07003343247482155\n",
      "          total_loss: 0.0945149544148873\n",
      "          vf_explained_var: 0.8152331113815308\n",
      "          vf_loss: 0.14879123152384902\n",
      "    num_agent_steps_sampled: 649740\n",
      "    num_agent_steps_trained: 649740\n",
      "    num_steps_sampled: 649740\n",
      "    num_steps_trained: 649740\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.8265306122449\n",
      "    ram_util_percent: 44.584807256235834\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049625217930508614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.99626566417262\n",
      "    mean_inference_ms: 8.659193277234742\n",
      "    mean_raw_obs_processing_ms: 2.45824743842338\n",
      "  time_since_restore: 19609.288569927216\n",
      "  time_this_iter_s: 309.5539767742157\n",
      "  time_total_s: 19609.288569927216\n",
      "  timers:\n",
      "    learn_throughput: 65.207\n",
      "    learn_time_ms: 153297.166\n",
      "    load_throughput: 87612.925\n",
      "    load_time_ms: 114.093\n",
      "    sample_throughput: 63.217\n",
      "    sample_time_ms: 158122.903\n",
      "    update_time_ms: 13.089\n",
      "  timestamp: 1636920346\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 649740\n",
      "  training_iteration: 65\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         19609.3</td><td style=\"text-align: right;\">649740</td><td style=\"text-align: right;\"> 2.07388</td><td style=\"text-align: right;\">                9.68</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           96.3592</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 659736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-11-11\n",
      "  done: false\n",
      "  episode_len_mean: 96.06666666666666\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.680000000000009\n",
      "  episode_reward_mean: 1.9820000000000046\n",
      "  episode_reward_min: -2.2699999999999996\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 6841\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5786462116445232\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015405636741231805\n",
      "          policy_loss: -0.06927366828780748\n",
      "          total_loss: 0.0832186771879116\n",
      "          vf_explained_var: 0.7996466159820557\n",
      "          vf_loss: 0.13879584612476073\n",
      "    num_agent_steps_sampled: 659736\n",
      "    num_agent_steps_trained: 659736\n",
      "    num_steps_sampled: 659736\n",
      "    num_steps_trained: 659736\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.76745689655174\n",
      "    ram_util_percent: 44.59784482758621\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04963548097587359\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.990427947533654\n",
      "    mean_inference_ms: 8.661192328574817\n",
      "    mean_raw_obs_processing_ms: 2.4822480628264647\n",
      "  time_since_restore: 19934.30144381523\n",
      "  time_this_iter_s: 325.01287388801575\n",
      "  time_total_s: 19934.30144381523\n",
      "  timers:\n",
      "    learn_throughput: 65.186\n",
      "    learn_time_ms: 153345.409\n",
      "    load_throughput: 87243.615\n",
      "    load_time_ms: 114.576\n",
      "    sample_throughput: 62.779\n",
      "    sample_time_ms: 159224.29\n",
      "    update_time_ms: 13.08\n",
      "  timestamp: 1636920671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 659736\n",
      "  training_iteration: 66\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         19934.3</td><td style=\"text-align: right;\">659736</td><td style=\"text-align: right;\">   1.982</td><td style=\"text-align: right;\">                8.68</td><td style=\"text-align: right;\">               -2.27</td><td style=\"text-align: right;\">           96.0667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 669732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-16-10\n",
      "  done: false\n",
      "  episode_len_mean: 95.84466019417475\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.470000000000017\n",
      "  episode_reward_mean: 2.8654368932038907\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 6944\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.54894303012098\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017094502995786808\n",
      "          policy_loss: -0.06646150944706722\n",
      "          total_loss: 0.12670183853628353\n",
      "          vf_explained_var: 0.8057805299758911\n",
      "          vf_loss: 0.17484143747128228\n",
      "    num_agent_steps_sampled: 669732\n",
      "    num_agent_steps_trained: 669732\n",
      "    num_steps_sampled: 669732\n",
      "    num_steps_trained: 669732\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.75210280373831\n",
      "    ram_util_percent: 44.699999999999996\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049685405245819325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00862234182508\n",
      "    mean_inference_ms: 8.665057963600908\n",
      "    mean_raw_obs_processing_ms: 2.454483473833728\n",
      "  time_since_restore: 20233.954785108566\n",
      "  time_this_iter_s: 299.65334129333496\n",
      "  time_total_s: 20233.954785108566\n",
      "  timers:\n",
      "    learn_throughput: 65.166\n",
      "    learn_time_ms: 153392.231\n",
      "    load_throughput: 86485.579\n",
      "    load_time_ms: 115.58\n",
      "    sample_throughput: 63.312\n",
      "    sample_time_ms: 157883.912\n",
      "    update_time_ms: 13.204\n",
      "  timestamp: 1636920970\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 669732\n",
      "  training_iteration: 67\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">           20234</td><td style=\"text-align: right;\">669732</td><td style=\"text-align: right;\"> 2.86544</td><td style=\"text-align: right;\">               12.47</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           95.8447</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 679728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-21-23\n",
      "  done: false\n",
      "  episode_len_mean: 96.9126213592233\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.130000000000019\n",
      "  episode_reward_mean: 2.189611650485443\n",
      "  episode_reward_min: -1.9200000000000013\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 7047\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.592794686810583\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016309693196522163\n",
      "          policy_loss: -0.06459569484691939\n",
      "          total_loss: 0.10561659728718173\n",
      "          vf_explained_var: 0.8365724682807922\n",
      "          vf_loss: 0.15434027943704437\n",
      "    num_agent_steps_sampled: 679728\n",
      "    num_agent_steps_trained: 679728\n",
      "    num_steps_sampled: 679728\n",
      "    num_steps_trained: 679728\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.6786995515695\n",
      "    ram_util_percent: 44.6670403587444\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0496704000929712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01782336652821\n",
      "    mean_inference_ms: 8.667554358871044\n",
      "    mean_raw_obs_processing_ms: 2.4537231315015293\n",
      "  time_since_restore: 20546.586888313293\n",
      "  time_this_iter_s: 312.6321032047272\n",
      "  time_total_s: 20546.586888313293\n",
      "  timers:\n",
      "    learn_throughput: 65.159\n",
      "    learn_time_ms: 153409.536\n",
      "    load_throughput: 86041.878\n",
      "    load_time_ms: 116.176\n",
      "    sample_throughput: 63.433\n",
      "    sample_time_ms: 157583.037\n",
      "    update_time_ms: 12.139\n",
      "  timestamp: 1636921283\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 679728\n",
      "  training_iteration: 68\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         20546.6</td><td style=\"text-align: right;\">679728</td><td style=\"text-align: right;\"> 2.18961</td><td style=\"text-align: right;\">               10.13</td><td style=\"text-align: right;\">               -1.92</td><td style=\"text-align: right;\">           96.9126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 689724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-26-39\n",
      "  done: false\n",
      "  episode_len_mean: 95.01904761904763\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.380000000000017\n",
      "  episode_reward_mean: 1.9444761904761956\n",
      "  episode_reward_min: -1.930000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 7152\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5806669255607146\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015965262829195307\n",
      "          policy_loss: -0.07053364888549997\n",
      "          total_loss: 0.08779958554217195\n",
      "          vf_explained_var: 0.8480408191680908\n",
      "          vf_loss: 0.14322268257204157\n",
      "    num_agent_steps_sampled: 689724\n",
      "    num_agent_steps_trained: 689724\n",
      "    num_steps_sampled: 689724\n",
      "    num_steps_trained: 689724\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.79199999999999\n",
      "    ram_util_percent: 44.70333333333333\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04966516464819823\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.028092346468455\n",
      "    mean_inference_ms: 8.668817967924523\n",
      "    mean_raw_obs_processing_ms: 2.477771529211806\n",
      "  time_since_restore: 20862.179986953735\n",
      "  time_this_iter_s: 315.5930986404419\n",
      "  time_total_s: 20862.179986953735\n",
      "  timers:\n",
      "    learn_throughput: 65.146\n",
      "    learn_time_ms: 153440.704\n",
      "    load_throughput: 86422.542\n",
      "    load_time_ms: 115.664\n",
      "    sample_throughput: 64.438\n",
      "    sample_time_ms: 155126.342\n",
      "    update_time_ms: 12.363\n",
      "  timestamp: 1636921599\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 689724\n",
      "  training_iteration: 69\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         20862.2</td><td style=\"text-align: right;\">689724</td><td style=\"text-align: right;\"> 1.94448</td><td style=\"text-align: right;\">               10.38</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">            95.019</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 699720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-31-54\n",
      "  done: false\n",
      "  episode_len_mean: 95.49038461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.620000000000015\n",
      "  episode_reward_mean: 2.8697115384615453\n",
      "  episode_reward_min: -1.9400000000000004\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 7256\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.573420423320216\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01689436132807545\n",
      "          policy_loss: -0.06621135098413906\n",
      "          total_loss: 0.124009865651337\n",
      "          vf_explained_var: 0.8319177627563477\n",
      "          vf_loss: 0.172657021214692\n",
      "    num_agent_steps_sampled: 699720\n",
      "    num_agent_steps_trained: 699720\n",
      "    num_steps_sampled: 699720\n",
      "    num_steps_trained: 699720\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.72338530066816\n",
      "    ram_util_percent: 45.039866369710474\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049670957220137306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.03870843820463\n",
      "    mean_inference_ms: 8.669436372671468\n",
      "    mean_raw_obs_processing_ms: 2.503417663307837\n",
      "  time_since_restore: 21177.28887438774\n",
      "  time_this_iter_s: 315.10888743400574\n",
      "  time_total_s: 21177.28887438774\n",
      "  timers:\n",
      "    learn_throughput: 65.158\n",
      "    learn_time_ms: 153412.192\n",
      "    load_throughput: 86956.219\n",
      "    load_time_ms: 114.954\n",
      "    sample_throughput: 63.527\n",
      "    sample_time_ms: 157351.505\n",
      "    update_time_ms: 12.954\n",
      "  timestamp: 1636921914\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 699720\n",
      "  training_iteration: 70\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         21177.3</td><td style=\"text-align: right;\">699720</td><td style=\"text-align: right;\"> 2.86971</td><td style=\"text-align: right;\">               10.62</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           95.4904</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 709716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-36-57\n",
      "  done: false\n",
      "  episode_len_mean: 96.34285714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.03000000000002\n",
      "  episode_reward_mean: 2.502952380952388\n",
      "  episode_reward_min: -2.289999999999997\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 7361\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.569561297363705\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01693936905399794\n",
      "          policy_loss: -0.06582358897400972\n",
      "          total_loss: 0.12797118104102775\n",
      "          vf_explained_var: 0.8476150631904602\n",
      "          vf_loss: 0.17607663498403361\n",
      "    num_agent_steps_sampled: 709716\n",
      "    num_agent_steps_trained: 709716\n",
      "    num_steps_sampled: 709716\n",
      "    num_steps_trained: 709716\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.55898617511521\n",
      "    ram_util_percent: 44.73410138248848\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049686078568822865\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.06710956065961\n",
      "    mean_inference_ms: 8.671635268407446\n",
      "    mean_raw_obs_processing_ms: 2.4793912488778393\n",
      "  time_since_restore: 21480.945756196976\n",
      "  time_this_iter_s: 303.6568818092346\n",
      "  time_total_s: 21480.945756196976\n",
      "  timers:\n",
      "    learn_throughput: 65.176\n",
      "    learn_time_ms: 153369.651\n",
      "    load_throughput: 86700.122\n",
      "    load_time_ms: 115.294\n",
      "    sample_throughput: 63.226\n",
      "    sample_time_ms: 158100.466\n",
      "    update_time_ms: 12.896\n",
      "  timestamp: 1636922217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 709716\n",
      "  training_iteration: 71\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         21480.9</td><td style=\"text-align: right;\">709716</td><td style=\"text-align: right;\"> 2.50295</td><td style=\"text-align: right;\">               10.03</td><td style=\"text-align: right;\">               -2.29</td><td style=\"text-align: right;\">           96.3429</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 719712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-42-01\n",
      "  done: false\n",
      "  episode_len_mean: 96.69902912621359\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.000000000000013\n",
      "  episode_reward_mean: 2.4134951456310745\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 7464\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5836569475312516\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015586002035711635\n",
      "          policy_loss: -0.06949519178089805\n",
      "          total_loss: 0.10087147371079296\n",
      "          vf_explained_var: 0.8448976874351501\n",
      "          vf_loss: 0.15625801714909318\n",
      "    num_agent_steps_sampled: 719712\n",
      "    num_agent_steps_trained: 719712\n",
      "    num_steps_sampled: 719712\n",
      "    num_steps_trained: 719712\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.3974595842956\n",
      "    ram_util_percent: 44.52678983833718\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0496740735445023\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.088602859204954\n",
      "    mean_inference_ms: 8.674259571809626\n",
      "    mean_raw_obs_processing_ms: 2.454814081037139\n",
      "  time_since_restore: 21784.534470796585\n",
      "  time_this_iter_s: 303.5887145996094\n",
      "  time_total_s: 21784.534470796585\n",
      "  timers:\n",
      "    learn_throughput: 65.195\n",
      "    learn_time_ms: 153325.238\n",
      "    load_throughput: 86619.356\n",
      "    load_time_ms: 115.401\n",
      "    sample_throughput: 64.158\n",
      "    sample_time_ms: 155803.466\n",
      "    update_time_ms: 12.643\n",
      "  timestamp: 1636922521\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 719712\n",
      "  training_iteration: 72\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         21784.5</td><td style=\"text-align: right;\">719712</td><td style=\"text-align: right;\">  2.4135</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">            96.699</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 729708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-47-26\n",
      "  done: false\n",
      "  episode_len_mean: 95.05714285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.620000000000017\n",
      "  episode_reward_mean: 1.953809523809529\n",
      "  episode_reward_min: -2.499999999999997\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 7569\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5894199455905165\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014944076130111963\n",
      "          policy_loss: -0.07329953429766764\n",
      "          total_loss: 0.06880934273179334\n",
      "          vf_explained_var: 0.8559563159942627\n",
      "          vf_loss: 0.12970304465812876\n",
      "    num_agent_steps_sampled: 729708\n",
      "    num_agent_steps_trained: 729708\n",
      "    num_steps_sampled: 729708\n",
      "    num_steps_trained: 729708\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.58211206896553\n",
      "    ram_util_percent: 44.82823275862069\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04967783906871764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.07949470331627\n",
      "    mean_inference_ms: 8.674670074189466\n",
      "    mean_raw_obs_processing_ms: 2.4979455088245976\n",
      "  time_since_restore: 22109.702511548996\n",
      "  time_this_iter_s: 325.1680407524109\n",
      "  time_total_s: 22109.702511548996\n",
      "  timers:\n",
      "    learn_throughput: 65.189\n",
      "    learn_time_ms: 153339.378\n",
      "    load_throughput: 86732.603\n",
      "    load_time_ms: 115.251\n",
      "    sample_throughput: 63.5\n",
      "    sample_time_ms: 157418.468\n",
      "    update_time_ms: 12.408\n",
      "  timestamp: 1636922846\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 729708\n",
      "  training_iteration: 73\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         22109.7</td><td style=\"text-align: right;\">729708</td><td style=\"text-align: right;\"> 1.95381</td><td style=\"text-align: right;\">                8.62</td><td style=\"text-align: right;\">                -2.5</td><td style=\"text-align: right;\">           95.0571</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 739704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-52-24\n",
      "  done: false\n",
      "  episode_len_mean: 97.79611650485437\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.740000000000009\n",
      "  episode_reward_mean: 2.2873786407767054\n",
      "  episode_reward_min: -1.960000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 7672\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5809709360456874\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015426617190976915\n",
      "          policy_loss: -0.06953756326857286\n",
      "          total_loss: 0.08538246704464476\n",
      "          vf_explained_var: 0.8515567779541016\n",
      "          vf_loss: 0.141193008938661\n",
      "    num_agent_steps_sampled: 739704\n",
      "    num_agent_steps_trained: 739704\n",
      "    num_steps_sampled: 739704\n",
      "    num_steps_trained: 739704\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.38679245283019\n",
      "    ram_util_percent: 44.93773584905661\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04966119978479594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.088521616772795\n",
      "    mean_inference_ms: 8.677647116721253\n",
      "    mean_raw_obs_processing_ms: 2.477182460526178\n",
      "  time_since_restore: 22407.337065935135\n",
      "  time_this_iter_s: 297.6345543861389\n",
      "  time_total_s: 22407.337065935135\n",
      "  timers:\n",
      "    learn_throughput: 65.189\n",
      "    learn_time_ms: 153338.179\n",
      "    load_throughput: 86746.475\n",
      "    load_time_ms: 115.232\n",
      "    sample_throughput: 63.556\n",
      "    sample_time_ms: 157279.546\n",
      "    update_time_ms: 11.656\n",
      "  timestamp: 1636923144\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 739704\n",
      "  training_iteration: 74\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         22407.3</td><td style=\"text-align: right;\">739704</td><td style=\"text-align: right;\"> 2.28738</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">           97.7961</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 749700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_20-57-33\n",
      "  done: false\n",
      "  episode_len_mean: 95.85576923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.650000000000015\n",
      "  episode_reward_mean: 2.5858653846153907\n",
      "  episode_reward_min: -2.1199999999999983\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 7776\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5740628825293648\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017030476936525613\n",
      "          policy_loss: -0.06495091015250128\n",
      "          total_loss: 0.1271154412613688\n",
      "          vf_explained_var: 0.8299260139465332\n",
      "          vf_loss: 0.1741597313258765\n",
      "    num_agent_steps_sampled: 749700\n",
      "    num_agent_steps_trained: 749700\n",
      "    num_steps_sampled: 749700\n",
      "    num_steps_trained: 749700\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.06470588235295\n",
      "    ram_util_percent: 44.76990950226245\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04966549545315172\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.09260889535986\n",
      "    mean_inference_ms: 8.679938151173108\n",
      "    mean_raw_obs_processing_ms: 2.473276793885441\n",
      "  time_since_restore: 22716.649252414703\n",
      "  time_this_iter_s: 309.3121864795685\n",
      "  time_total_s: 22716.649252414703\n",
      "  timers:\n",
      "    learn_throughput: 65.191\n",
      "    learn_time_ms: 153333.342\n",
      "    load_throughput: 86931.392\n",
      "    load_time_ms: 114.987\n",
      "    sample_throughput: 63.563\n",
      "    sample_time_ms: 157261.908\n",
      "    update_time_ms: 10.1\n",
      "  timestamp: 1636923453\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 749700\n",
      "  training_iteration: 75\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         22716.6</td><td style=\"text-align: right;\">749700</td><td style=\"text-align: right;\"> 2.58587</td><td style=\"text-align: right;\">               10.65</td><td style=\"text-align: right;\">               -2.12</td><td style=\"text-align: right;\">           95.8558</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 759696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-02-59\n",
      "  done: false\n",
      "  episode_len_mean: 94.95283018867924\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.290000000000015\n",
      "  episode_reward_mean: 2.551886792452837\n",
      "  episode_reward_min: -1.930000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 7882\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5888608738907384\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01637651877262982\n",
      "          policy_loss: -0.06449037402167788\n",
      "          total_loss: 0.1243098045946059\n",
      "          vf_explained_var: 0.8341062664985657\n",
      "          vf_loss: 0.17271756246232262\n",
      "    num_agent_steps_sampled: 759696\n",
      "    num_agent_steps_trained: 759696\n",
      "    num_steps_sampled: 759696\n",
      "    num_steps_trained: 759696\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.59698924731184\n",
      "    ram_util_percent: 45.243655913978486\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049660988320583736\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08294267210556\n",
      "    mean_inference_ms: 8.680561547396374\n",
      "    mean_raw_obs_processing_ms: 2.499188675820497\n",
      "  time_since_restore: 23042.631106376648\n",
      "  time_this_iter_s: 325.9818539619446\n",
      "  time_total_s: 23042.631106376648\n",
      "  timers:\n",
      "    learn_throughput: 65.215\n",
      "    learn_time_ms: 153277.192\n",
      "    load_throughput: 87590.192\n",
      "    load_time_ms: 114.122\n",
      "    sample_throughput: 63.501\n",
      "    sample_time_ms: 157415.589\n",
      "    update_time_ms: 10.086\n",
      "  timestamp: 1636923779\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 759696\n",
      "  training_iteration: 76\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         23042.6</td><td style=\"text-align: right;\">759696</td><td style=\"text-align: right;\"> 2.55189</td><td style=\"text-align: right;\">               12.29</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">           94.9528</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 769692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-08-09\n",
      "  done: false\n",
      "  episode_len_mean: 97.11764705882354\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.760000000000021\n",
      "  episode_reward_mean: 2.3139215686274563\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 7984\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5692642295462456\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017557471939713954\n",
      "          policy_loss: -0.0669526539868317\n",
      "          total_loss: 0.11068879303633848\n",
      "          vf_explained_var: 0.8261582851409912\n",
      "          vf_loss: 0.1583362101756323\n",
      "    num_agent_steps_sampled: 769692\n",
      "    num_agent_steps_trained: 769692\n",
      "    num_steps_sampled: 769692\n",
      "    num_steps_trained: 769692\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.98506787330317\n",
      "    ram_util_percent: 44.84819004524887\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04963294239858719\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.0791216643719\n",
      "    mean_inference_ms: 8.681976802070405\n",
      "    mean_raw_obs_processing_ms: 2.500891626732185\n",
      "  time_since_restore: 23352.666955947876\n",
      "  time_this_iter_s: 310.035849571228\n",
      "  time_total_s: 23352.666955947876\n",
      "  timers:\n",
      "    learn_throughput: 65.217\n",
      "    learn_time_ms: 153273.631\n",
      "    load_throughput: 88036.994\n",
      "    load_time_ms: 113.543\n",
      "    sample_throughput: 63.083\n",
      "    sample_time_ms: 158457.261\n",
      "    update_time_ms: 10.305\n",
      "  timestamp: 1636924089\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 769692\n",
      "  training_iteration: 77\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         23352.7</td><td style=\"text-align: right;\">769692</td><td style=\"text-align: right;\"> 2.31392</td><td style=\"text-align: right;\">               13.76</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           97.1176</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 779688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-13-05\n",
      "  done: false\n",
      "  episode_len_mean: 97.7156862745098\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.660000000000013\n",
      "  episode_reward_mean: 2.457450980392163\n",
      "  episode_reward_min: -1.7300000000000006\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 8086\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5721633832678834\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015394110705207952\n",
      "          policy_loss: -0.06792275333562149\n",
      "          total_loss: 0.09927897583534065\n",
      "          vf_explained_var: 0.8573051691055298\n",
      "          vf_loss: 0.1534699418510382\n",
      "    num_agent_steps_sampled: 779688\n",
      "    num_agent_steps_trained: 779688\n",
      "    num_steps_sampled: 779688\n",
      "    num_steps_trained: 779688\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.65153664302602\n",
      "    ram_util_percent: 44.75390070921986\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04966788217313257\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08542113798037\n",
      "    mean_inference_ms: 8.684711053236205\n",
      "    mean_raw_obs_processing_ms: 2.4774277140715157\n",
      "  time_since_restore: 23648.765894174576\n",
      "  time_this_iter_s: 296.09893822669983\n",
      "  time_total_s: 23648.765894174576\n",
      "  timers:\n",
      "    learn_throughput: 65.242\n",
      "    learn_time_ms: 153215.095\n",
      "    load_throughput: 88847.214\n",
      "    load_time_ms: 112.508\n",
      "    sample_throughput: 63.724\n",
      "    sample_time_ms: 156863.597\n",
      "    update_time_ms: 10.429\n",
      "  timestamp: 1636924385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 779688\n",
      "  training_iteration: 78\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         23648.8</td><td style=\"text-align: right;\">779688</td><td style=\"text-align: right;\"> 2.45745</td><td style=\"text-align: right;\">               10.66</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           97.7157</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 789684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-18-34\n",
      "  done: false\n",
      "  episode_len_mean: 96.47115384615384\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.770000000000014\n",
      "  episode_reward_mean: 2.547980769230776\n",
      "  episode_reward_min: -1.5600000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 8190\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5671478144124023\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015829267860210976\n",
      "          policy_loss: -0.0702207419472054\n",
      "          total_loss: 0.09190415110892783\n",
      "          vf_explained_var: 0.8591721057891846\n",
      "          vf_loss: 0.14722768963298674\n",
      "    num_agent_steps_sampled: 789684\n",
      "    num_agent_steps_trained: 789684\n",
      "    num_steps_sampled: 789684\n",
      "    num_steps_trained: 789684\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.25534188034187\n",
      "    ram_util_percent: 44.72200854700854\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0496692397099422\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.085914913732154\n",
      "    mean_inference_ms: 8.68657104142379\n",
      "    mean_raw_obs_processing_ms: 2.4982891192799253\n",
      "  time_since_restore: 23977.109640836716\n",
      "  time_this_iter_s: 328.3437466621399\n",
      "  time_total_s: 23977.109640836716\n",
      "  timers:\n",
      "    learn_throughput: 65.252\n",
      "    learn_time_ms: 153191.629\n",
      "    load_throughput: 89023.812\n",
      "    load_time_ms: 112.285\n",
      "    sample_throughput: 63.202\n",
      "    sample_time_ms: 158160.665\n",
      "    update_time_ms: 11.296\n",
      "  timestamp: 1636924714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 789684\n",
      "  training_iteration: 79\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         23977.1</td><td style=\"text-align: right;\">789684</td><td style=\"text-align: right;\"> 2.54798</td><td style=\"text-align: right;\">                8.77</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           96.4712</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 799680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-23-56\n",
      "  done: false\n",
      "  episode_len_mean: 96.4368932038835\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.629999999999942\n",
      "  episode_reward_mean: 2.813592233009715\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 8293\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.542233043552464\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017930687494531028\n",
      "          policy_loss: -0.06433693567434183\n",
      "          total_loss: 0.14079008247209793\n",
      "          vf_explained_var: 0.8362500071525574\n",
      "          vf_loss: 0.1845949586492796\n",
      "    num_agent_steps_sampled: 799680\n",
      "    num_agent_steps_trained: 799680\n",
      "    num_steps_sampled: 799680\n",
      "    num_steps_trained: 799680\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.55531453362256\n",
      "    ram_util_percent: 44.68221258134492\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04966763899959356\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.07876208325042\n",
      "    mean_inference_ms: 8.686288405858647\n",
      "    mean_raw_obs_processing_ms: 2.5198473733611806\n",
      "  time_since_restore: 24299.671519756317\n",
      "  time_this_iter_s: 322.56187891960144\n",
      "  time_total_s: 24299.671519756317\n",
      "  timers:\n",
      "    learn_throughput: 65.244\n",
      "    learn_time_ms: 153210.552\n",
      "    load_throughput: 89003.666\n",
      "    load_time_ms: 112.31\n",
      "    sample_throughput: 62.913\n",
      "    sample_time_ms: 158886.992\n",
      "    update_time_ms: 11.113\n",
      "  timestamp: 1636925036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 799680\n",
      "  training_iteration: 80\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         24299.7</td><td style=\"text-align: right;\">799680</td><td style=\"text-align: right;\"> 2.81359</td><td style=\"text-align: right;\">               22.63</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           96.4369</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 809676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-28-53\n",
      "  done: false\n",
      "  episode_len_mean: 98.25490196078431\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.120000000000019\n",
      "  episode_reward_mean: 2.213823529411771\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 8395\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.576300395350171\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015227908517466587\n",
      "          policy_loss: -0.06967977848238288\n",
      "          total_loss: 0.08132910644317157\n",
      "          vf_explained_var: 0.8351843357086182\n",
      "          vf_loss: 0.13774442659794456\n",
      "    num_agent_steps_sampled: 809676\n",
      "    num_agent_steps_trained: 809676\n",
      "    num_steps_sampled: 809676\n",
      "    num_steps_trained: 809676\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.55971563981042\n",
      "    ram_util_percent: 44.764928909952616\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04968232869383152\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08547984621376\n",
      "    mean_inference_ms: 8.688959517357882\n",
      "    mean_raw_obs_processing_ms: 2.4968183403438546\n",
      "  time_since_restore: 24595.96600651741\n",
      "  time_this_iter_s: 296.29448676109314\n",
      "  time_total_s: 24595.96600651741\n",
      "  timers:\n",
      "    learn_throughput: 65.243\n",
      "    learn_time_ms: 153212.966\n",
      "    load_throughput: 89266.199\n",
      "    load_time_ms: 111.98\n",
      "    sample_throughput: 63.207\n",
      "    sample_time_ms: 158148.292\n",
      "    update_time_ms: 11.543\n",
      "  timestamp: 1636925333\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 809676\n",
      "  training_iteration: 81\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">           24596</td><td style=\"text-align: right;\">809676</td><td style=\"text-align: right;\"> 2.21382</td><td style=\"text-align: right;\">               10.12</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           98.2549</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 819672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-33-50\n",
      "  done: false\n",
      "  episode_len_mean: 98.3529411764706\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.840000000000016\n",
      "  episode_reward_mean: 2.4992156862745167\n",
      "  episode_reward_min: -2.2899999999999987\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 8497\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5757380476364724\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016510430015493755\n",
      "          policy_loss: -0.06827637946121713\n",
      "          total_loss: 0.1063622707922935\n",
      "          vf_explained_var: 0.8549844026565552\n",
      "          vf_loss: 0.1580816057144513\n",
      "    num_agent_steps_sampled: 819672\n",
      "    num_agent_steps_trained: 819672\n",
      "    num_steps_sampled: 819672\n",
      "    num_steps_trained: 819672\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.48917647058823\n",
      "    ram_util_percent: 44.64823529411765\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04967361935906565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.09458507919127\n",
      "    mean_inference_ms: 8.691394625659703\n",
      "    mean_raw_obs_processing_ms: 2.4753881113202376\n",
      "  time_since_restore: 24893.53790974617\n",
      "  time_this_iter_s: 297.57190322875977\n",
      "  time_total_s: 24893.53790974617\n",
      "  timers:\n",
      "    learn_throughput: 65.242\n",
      "    learn_time_ms: 153214.542\n",
      "    load_throughput: 89026.061\n",
      "    load_time_ms: 112.282\n",
      "    sample_throughput: 63.449\n",
      "    sample_time_ms: 157544.56\n",
      "    update_time_ms: 12.166\n",
      "  timestamp: 1636925630\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 819672\n",
      "  training_iteration: 82\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         24893.5</td><td style=\"text-align: right;\">819672</td><td style=\"text-align: right;\"> 2.49922</td><td style=\"text-align: right;\">               14.84</td><td style=\"text-align: right;\">               -2.29</td><td style=\"text-align: right;\">           98.3529</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 829668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-39-15\n",
      "  done: false\n",
      "  episode_len_mean: 97.59803921568627\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.210000000000022\n",
      "  episode_reward_mean: 2.425000000000007\n",
      "  episode_reward_min: -1.870000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 8599\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5728607325472383\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018110347992763513\n",
      "          policy_loss: -0.06310297990074525\n",
      "          total_loss: 0.1274685095506123\n",
      "          vf_explained_var: 0.8193308115005493\n",
      "          vf_loss: 0.16988525706319474\n",
      "    num_agent_steps_sampled: 829668\n",
      "    num_agent_steps_trained: 829668\n",
      "    num_steps_sampled: 829668\n",
      "    num_steps_trained: 829668\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.56155507559396\n",
      "    ram_util_percent: 44.95896328293737\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049686139079903734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08299480181345\n",
      "    mean_inference_ms: 8.692709252802329\n",
      "    mean_raw_obs_processing_ms: 2.493979456952112\n",
      "  time_since_restore: 25218.096555233\n",
      "  time_this_iter_s: 324.55864548683167\n",
      "  time_total_s: 25218.096555233\n",
      "  timers:\n",
      "    learn_throughput: 65.24\n",
      "    learn_time_ms: 153219.743\n",
      "    load_throughput: 88847.402\n",
      "    load_time_ms: 112.508\n",
      "    sample_throughput: 63.475\n",
      "    sample_time_ms: 157478.511\n",
      "    update_time_ms: 11.943\n",
      "  timestamp: 1636925955\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 829668\n",
      "  training_iteration: 83\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         25218.1</td><td style=\"text-align: right;\">829668</td><td style=\"text-align: right;\">   2.425</td><td style=\"text-align: right;\">               14.21</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">            97.598</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 839664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-44-25\n",
      "  done: false\n",
      "  episode_len_mean: 97.1470588235294\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.189999999999944\n",
      "  episode_reward_mean: 2.767647058823535\n",
      "  episode_reward_min: -2.32\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 8701\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5687695915882403\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015749921045689005\n",
      "          policy_loss: -0.0669032722337442\n",
      "          total_loss: 0.10493878967399335\n",
      "          vf_explained_var: 0.8510072827339172\n",
      "          vf_loss: 0.15716443417840598\n",
      "    num_agent_steps_sampled: 839664\n",
      "    num_agent_steps_trained: 839664\n",
      "    num_steps_sampled: 839664\n",
      "    num_steps_trained: 839664\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.07737556561086\n",
      "    ram_util_percent: 44.8237556561086\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04964484253357639\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08031232606563\n",
      "    mean_inference_ms: 8.693350787697312\n",
      "    mean_raw_obs_processing_ms: 2.495775678298985\n",
      "  time_since_restore: 25527.722447872162\n",
      "  time_this_iter_s: 309.62589263916016\n",
      "  time_total_s: 25527.722447872162\n",
      "  timers:\n",
      "    learn_throughput: 65.235\n",
      "    learn_time_ms: 153231.431\n",
      "    load_throughput: 89036.914\n",
      "    load_time_ms: 112.268\n",
      "    sample_throughput: 63.0\n",
      "    sample_time_ms: 158666.227\n",
      "    update_time_ms: 12.457\n",
      "  timestamp: 1636926265\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 839664\n",
      "  training_iteration: 84\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         25527.7</td><td style=\"text-align: right;\">839664</td><td style=\"text-align: right;\"> 2.76765</td><td style=\"text-align: right;\">               16.19</td><td style=\"text-align: right;\">               -2.32</td><td style=\"text-align: right;\">           97.1471</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 849660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-49-20\n",
      "  done: false\n",
      "  episode_len_mean: 98.71844660194175\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.190000000000017\n",
      "  episode_reward_mean: 2.6672815533980647\n",
      "  episode_reward_min: -2.3599999999999985\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 8804\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.557832327153948\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017148791912527415\n",
      "          policy_loss: -0.06969668572215347\n",
      "          total_loss: 0.10737228376122239\n",
      "          vf_explained_var: 0.8593811392784119\n",
      "          vf_loss: 0.1586968161042334\n",
      "    num_agent_steps_sampled: 849660\n",
      "    num_agent_steps_trained: 849660\n",
      "    num_steps_sampled: 849660\n",
      "    num_steps_trained: 849660\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.44703087885985\n",
      "    ram_util_percent: 44.75866983372922\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049645046463860254\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08305526774058\n",
      "    mean_inference_ms: 8.694832351711153\n",
      "    mean_raw_obs_processing_ms: 2.4762490227903076\n",
      "  time_since_restore: 25822.67025399208\n",
      "  time_this_iter_s: 294.9478061199188\n",
      "  time_total_s: 25822.67025399208\n",
      "  timers:\n",
      "    learn_throughput: 65.227\n",
      "    learn_time_ms: 153248.328\n",
      "    load_throughput: 88285.964\n",
      "    load_time_ms: 113.223\n",
      "    sample_throughput: 63.583\n",
      "    sample_time_ms: 157211.681\n",
      "    update_time_ms: 12.717\n",
      "  timestamp: 1636926560\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 849660\n",
      "  training_iteration: 85\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         25822.7</td><td style=\"text-align: right;\">849660</td><td style=\"text-align: right;\"> 2.66728</td><td style=\"text-align: right;\">               10.19</td><td style=\"text-align: right;\">               -2.36</td><td style=\"text-align: right;\">           98.7184</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 859656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-54-41\n",
      "  done: false\n",
      "  episode_len_mean: 97.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.480000000000018\n",
      "  episode_reward_mean: 2.560294117647065\n",
      "  episode_reward_min: -2.080000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 8906\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5740565224590464\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017358027171041977\n",
      "          policy_loss: -0.06816464244770125\n",
      "          total_loss: 0.11332297910036694\n",
      "          vf_explained_var: 0.8482249975204468\n",
      "          vf_loss: 0.1627414627510131\n",
      "    num_agent_steps_sampled: 859656\n",
      "    num_agent_steps_trained: 859656\n",
      "    num_steps_sampled: 859656\n",
      "    num_steps_trained: 859656\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.91899563318779\n",
      "    ram_util_percent: 45.036899563318784\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04963948991548358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.06681603547504\n",
      "    mean_inference_ms: 8.695248084952764\n",
      "    mean_raw_obs_processing_ms: 2.4972955070368665\n",
      "  time_since_restore: 26143.772039413452\n",
      "  time_this_iter_s: 321.10178542137146\n",
      "  time_total_s: 26143.772039413452\n",
      "  timers:\n",
      "    learn_throughput: 65.243\n",
      "    learn_time_ms: 153212.795\n",
      "    load_throughput: 87804.299\n",
      "    load_time_ms: 113.844\n",
      "    sample_throughput: 63.766\n",
      "    sample_time_ms: 156759.942\n",
      "    update_time_ms: 12.154\n",
      "  timestamp: 1636926881\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 859656\n",
      "  training_iteration: 86\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         26143.8</td><td style=\"text-align: right;\">859656</td><td style=\"text-align: right;\"> 2.56029</td><td style=\"text-align: right;\">               12.48</td><td style=\"text-align: right;\">               -2.08</td><td style=\"text-align: right;\">              97.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 869652\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_21-59-52\n",
      "  done: false\n",
      "  episode_len_mean: 96.45192307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.890000000000017\n",
      "  episode_reward_mean: 2.681057692307699\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 9010\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5707016948960786\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017455821024947207\n",
      "          policy_loss: -0.0617071521985862\n",
      "          total_loss: 0.12781486444764284\n",
      "          vf_explained_var: 0.8717349767684937\n",
      "          vf_loss: 0.1704916742224342\n",
      "    num_agent_steps_sampled: 869652\n",
      "    num_agent_steps_trained: 869652\n",
      "    num_steps_sampled: 869652\n",
      "    num_steps_trained: 869652\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.1231981981982\n",
      "    ram_util_percent: 44.898198198198195\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04961654224560826\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.06794154149888\n",
      "    mean_inference_ms: 8.695188558562181\n",
      "    mean_raw_obs_processing_ms: 2.5207937062142127\n",
      "  time_since_restore: 26455.300857782364\n",
      "  time_this_iter_s: 311.52881836891174\n",
      "  time_total_s: 26455.300857782364\n",
      "  timers:\n",
      "    learn_throughput: 65.247\n",
      "    learn_time_ms: 153203.301\n",
      "    load_throughput: 87964.699\n",
      "    load_time_ms: 113.636\n",
      "    sample_throughput: 63.701\n",
      "    sample_time_ms: 156919.462\n",
      "    update_time_ms: 11.802\n",
      "  timestamp: 1636927192\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 869652\n",
      "  training_iteration: 87\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         26455.3</td><td style=\"text-align: right;\">869652</td><td style=\"text-align: right;\"> 2.68106</td><td style=\"text-align: right;\">               12.89</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           96.4519</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 879648\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-04-47\n",
      "  done: false\n",
      "  episode_len_mean: 98.93069306930693\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.990000000000014\n",
      "  episode_reward_mean: 2.2758415841584223\n",
      "  episode_reward_min: -1.850000000000001\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 9111\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5768600191825475\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01751139285605878\n",
      "          policy_loss: -0.0619710557990604\n",
      "          total_loss: 0.11460953226758756\n",
      "          vf_explained_var: 0.8482249975204468\n",
      "          vf_loss: 0.15746940347708316\n",
      "    num_agent_steps_sampled: 879648\n",
      "    num_agent_steps_trained: 879648\n",
      "    num_steps_sampled: 879648\n",
      "    num_steps_trained: 879648\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.28761904761906\n",
      "    ram_util_percent: 45.04119047619047\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04964467912526724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.066887148273615\n",
      "    mean_inference_ms: 8.69814901857137\n",
      "    mean_raw_obs_processing_ms: 2.4942597578550845\n",
      "  time_since_restore: 26749.669974327087\n",
      "  time_this_iter_s: 294.3691165447235\n",
      "  time_total_s: 26749.669974327087\n",
      "  timers:\n",
      "    learn_throughput: 65.233\n",
      "    learn_time_ms: 153235.597\n",
      "    load_throughput: 87537.742\n",
      "    load_time_ms: 114.191\n",
      "    sample_throughput: 63.786\n",
      "    sample_time_ms: 156711.948\n",
      "    update_time_ms: 13.005\n",
      "  timestamp: 1636927487\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 879648\n",
      "  training_iteration: 88\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         26749.7</td><td style=\"text-align: right;\">879648</td><td style=\"text-align: right;\"> 2.27584</td><td style=\"text-align: right;\">               12.99</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           98.9307</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 889644\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-10-46\n",
      "  done: false\n",
      "  episode_len_mean: 96.24038461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.54000000000002\n",
      "  episode_reward_mean: 2.455961538461545\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 9215\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.564348385680435\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01576101692503799\n",
      "          policy_loss: -0.07024000239872939\n",
      "          total_loss: 0.07655023761813999\n",
      "          vf_explained_var: 0.8696361184120178\n",
      "          vf_loss: 0.13203996256328163\n",
      "    num_agent_steps_sampled: 889644\n",
      "    num_agent_steps_trained: 889644\n",
      "    num_steps_sampled: 889644\n",
      "    num_steps_trained: 889644\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.4263671875\n",
      "    ram_util_percent: 44.963671874999996\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04963935309052622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.04813418434231\n",
      "    mean_inference_ms: 8.696844236608056\n",
      "    mean_raw_obs_processing_ms: 2.5812162326119443\n",
      "  time_since_restore: 27108.565303325653\n",
      "  time_this_iter_s: 358.8953289985657\n",
      "  time_total_s: 27108.565303325653\n",
      "  timers:\n",
      "    learn_throughput: 65.227\n",
      "    learn_time_ms: 153248.54\n",
      "    load_throughput: 86461.947\n",
      "    load_time_ms: 115.612\n",
      "    sample_throughput: 62.571\n",
      "    sample_time_ms: 159755.327\n",
      "    update_time_ms: 11.351\n",
      "  timestamp: 1636927846\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 889644\n",
      "  training_iteration: 89\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         27108.6</td><td style=\"text-align: right;\">889644</td><td style=\"text-align: right;\"> 2.45596</td><td style=\"text-align: right;\">               12.54</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           96.2404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 899640\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-16-08\n",
      "  done: false\n",
      "  episode_len_mean: 98.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.480000000000018\n",
      "  episode_reward_mean: 2.4623000000000075\n",
      "  episode_reward_min: -1.8400000000000007\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 9315\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5845782755277096\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01680043074732781\n",
      "          policy_loss: -0.06690006933123287\n",
      "          total_loss: 0.10320671206563074\n",
      "          vf_explained_var: 0.8594282865524292\n",
      "          vf_loss: 0.152894898943014\n",
      "    num_agent_steps_sampled: 899640\n",
      "    num_agent_steps_trained: 899640\n",
      "    num_steps_sampled: 899640\n",
      "    num_steps_trained: 899640\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1745652173913\n",
      "    ram_util_percent: 44.51391304347825\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0496216700760087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.036742145436264\n",
      "    mean_inference_ms: 8.69811170907285\n",
      "    mean_raw_obs_processing_ms: 2.5919353818160875\n",
      "  time_since_restore: 27430.815552949905\n",
      "  time_this_iter_s: 322.2502496242523\n",
      "  time_total_s: 27430.815552949905\n",
      "  timers:\n",
      "    learn_throughput: 65.202\n",
      "    learn_time_ms: 153307.646\n",
      "    load_throughput: 85783.723\n",
      "    load_time_ms: 116.526\n",
      "    sample_throughput: 62.607\n",
      "    sample_time_ms: 159663.807\n",
      "    update_time_ms: 11.63\n",
      "  timestamp: 1636928168\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 899640\n",
      "  training_iteration: 90\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         27430.8</td><td style=\"text-align: right;\">899640</td><td style=\"text-align: right;\">  2.4623</td><td style=\"text-align: right;\">               10.48</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">             98.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 909636\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-21-14\n",
      "  done: false\n",
      "  episode_len_mean: 98.42718446601941\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.860000000000024\n",
      "  episode_reward_mean: 2.015339805825249\n",
      "  episode_reward_min: -2.579999999999995\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 9418\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5957183332524747\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015413261247941698\n",
      "          policy_loss: -0.0689446361353382\n",
      "          total_loss: 0.08624128452183791\n",
      "          vf_explained_var: 0.8533629179000854\n",
      "          vf_loss: 0.14164060089761057\n",
      "    num_agent_steps_sampled: 909636\n",
      "    num_agent_steps_trained: 909636\n",
      "    num_steps_sampled: 909636\n",
      "    num_steps_trained: 909636\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.25812356979405\n",
      "    ram_util_percent: 44.594050343249435\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04965228077774032\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.028796660744824\n",
      "    mean_inference_ms: 8.699635907966902\n",
      "    mean_raw_obs_processing_ms: 2.5879089716886474\n",
      "  time_since_restore: 27736.75697541237\n",
      "  time_this_iter_s: 305.9414224624634\n",
      "  time_total_s: 27736.75697541237\n",
      "  timers:\n",
      "    learn_throughput: 65.214\n",
      "    learn_time_ms: 153279.79\n",
      "    load_throughput: 85429.468\n",
      "    load_time_ms: 117.009\n",
      "    sample_throughput: 62.22\n",
      "    sample_time_ms: 160656.143\n",
      "    update_time_ms: 10.963\n",
      "  timestamp: 1636928474\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 909636\n",
      "  training_iteration: 91\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         27736.8</td><td style=\"text-align: right;\">909636</td><td style=\"text-align: right;\"> 2.01534</td><td style=\"text-align: right;\">               11.86</td><td style=\"text-align: right;\">               -2.58</td><td style=\"text-align: right;\">           98.4272</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 919632\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-26-10\n",
      "  done: false\n",
      "  episode_len_mean: 98.9009900990099\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.960000000000015\n",
      "  episode_reward_mean: 2.2839603960396104\n",
      "  episode_reward_min: -2.04\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 9519\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.584851366841895\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01635847197314503\n",
      "          policy_loss: -0.06598936820514181\n",
      "          total_loss: 0.08791989831285726\n",
      "          vf_explained_var: 0.8579880595207214\n",
      "          vf_loss: 0.13783280605044312\n",
      "    num_agent_steps_sampled: 919632\n",
      "    num_agent_steps_trained: 919632\n",
      "    num_steps_sampled: 919632\n",
      "    num_steps_trained: 919632\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.59549763033176\n",
      "    ram_util_percent: 44.53009478672985\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04967987802082483\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02831634715347\n",
      "    mean_inference_ms: 8.701800339745683\n",
      "    mean_raw_obs_processing_ms: 2.5647587566727035\n",
      "  time_since_restore: 28032.823939561844\n",
      "  time_this_iter_s: 296.0669641494751\n",
      "  time_total_s: 28032.823939561844\n",
      "  timers:\n",
      "    learn_throughput: 65.209\n",
      "    learn_time_ms: 153292.826\n",
      "    load_throughput: 85797.995\n",
      "    load_time_ms: 116.506\n",
      "    sample_throughput: 62.283\n",
      "    sample_time_ms: 160493.406\n",
      "    update_time_ms: 10.165\n",
      "  timestamp: 1636928770\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 919632\n",
      "  training_iteration: 92\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         28032.8</td><td style=\"text-align: right;\">919632</td><td style=\"text-align: right;\"> 2.28396</td><td style=\"text-align: right;\">               10.96</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">            98.901</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 929628\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-31-22\n",
      "  done: false\n",
      "  episode_len_mean: 97.01941747572816\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.24000000000002\n",
      "  episode_reward_mean: 2.09796116504855\n",
      "  episode_reward_min: -1.8100000000000007\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 9622\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.595285268013294\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015971026507441834\n",
      "          policy_loss: -0.07065385999834627\n",
      "          total_loss: 0.09907090146787083\n",
      "          vf_explained_var: 0.8052142858505249\n",
      "          vf_loss: 0.15474562108612214\n",
      "    num_agent_steps_sampled: 929628\n",
      "    num_agent_steps_trained: 929628\n",
      "    num_steps_sampled: 929628\n",
      "    num_steps_trained: 929628\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.9970786516854\n",
      "    ram_util_percent: 44.865617977528075\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04971170359317074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.029589013057844\n",
      "    mean_inference_ms: 8.702519817605609\n",
      "    mean_raw_obs_processing_ms: 2.5644465077352576\n",
      "  time_since_restore: 28344.381271123886\n",
      "  time_this_iter_s: 311.55733156204224\n",
      "  time_total_s: 28344.381271123886\n",
      "  timers:\n",
      "    learn_throughput: 65.19\n",
      "    learn_time_ms: 153335.587\n",
      "    load_throughput: 85964.748\n",
      "    load_time_ms: 116.28\n",
      "    sample_throughput: 62.808\n",
      "    sample_time_ms: 159150.633\n",
      "    update_time_ms: 10.832\n",
      "  timestamp: 1636929082\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 929628\n",
      "  training_iteration: 93\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         28344.4</td><td style=\"text-align: right;\">929628</td><td style=\"text-align: right;\"> 2.09796</td><td style=\"text-align: right;\">               12.24</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           97.0194</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 939624\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-37-03\n",
      "  done: false\n",
      "  episode_len_mean: 96.66990291262135\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.490000000000009\n",
      "  episode_reward_mean: 2.248155339805831\n",
      "  episode_reward_min: -2.3799999999999994\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 9725\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6164353105756972\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01700826016875829\n",
      "          policy_loss: -0.06726497000513168\n",
      "          total_loss: 0.09522544300167733\n",
      "          vf_explained_var: 0.8142836093902588\n",
      "          vf_loss: 0.14506445647392455\n",
      "    num_agent_steps_sampled: 939624\n",
      "    num_agent_steps_trained: 939624\n",
      "    num_steps_sampled: 939624\n",
      "    num_steps_trained: 939624\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.36878850102669\n",
      "    ram_util_percent: 45.06981519507186\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04972690908293418\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01597252336783\n",
      "    mean_inference_ms: 8.702660062041065\n",
      "    mean_raw_obs_processing_ms: 2.6485909398588934\n",
      "  time_since_restore: 28686.270411491394\n",
      "  time_this_iter_s: 341.88914036750793\n",
      "  time_total_s: 28686.270411491394\n",
      "  timers:\n",
      "    learn_throughput: 65.208\n",
      "    learn_time_ms: 153294.934\n",
      "    load_throughput: 85788.971\n",
      "    load_time_ms: 116.518\n",
      "    sample_throughput: 61.545\n",
      "    sample_time_ms: 162418.145\n",
      "    update_time_ms: 10.375\n",
      "  timestamp: 1636929423\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 939624\n",
      "  training_iteration: 94\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         28686.3</td><td style=\"text-align: right;\">939624</td><td style=\"text-align: right;\"> 2.24816</td><td style=\"text-align: right;\">                8.49</td><td style=\"text-align: right;\">               -2.38</td><td style=\"text-align: right;\">           96.6699</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 949620\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-42-00\n",
      "  done: false\n",
      "  episode_len_mean: 98.4059405940594\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.420000000000016\n",
      "  episode_reward_mean: 2.3959405940594123\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 9826\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5810883753320093\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016738624263761392\n",
      "          policy_loss: -0.0703035324278614\n",
      "          total_loss: 0.08957273646409059\n",
      "          vf_explained_var: 0.8462727069854736\n",
      "          vf_loss: 0.14278789040131065\n",
      "    num_agent_steps_sampled: 949620\n",
      "    num_agent_steps_trained: 949620\n",
      "    num_steps_sampled: 949620\n",
      "    num_steps_trained: 949620\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.50448113207545\n",
      "    ram_util_percent: 44.876415094339634\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04971813638292262\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.0252206326012\n",
      "    mean_inference_ms: 8.704801651432982\n",
      "    mean_raw_obs_processing_ms: 2.617688570258005\n",
      "  time_since_restore: 28983.274156570435\n",
      "  time_this_iter_s: 297.0037450790405\n",
      "  time_total_s: 28983.274156570435\n",
      "  timers:\n",
      "    learn_throughput: 65.197\n",
      "    learn_time_ms: 153319.603\n",
      "    load_throughput: 86464.586\n",
      "    load_time_ms: 115.608\n",
      "    sample_throughput: 61.476\n",
      "    sample_time_ms: 162600.293\n",
      "    update_time_ms: 10.201\n",
      "  timestamp: 1636929720\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 949620\n",
      "  training_iteration: 95\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         28983.3</td><td style=\"text-align: right;\">949620</td><td style=\"text-align: right;\"> 2.39594</td><td style=\"text-align: right;\">                8.42</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           98.4059</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 959616\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-47-09\n",
      "  done: false\n",
      "  episode_len_mean: 98.04901960784314\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.460000000000017\n",
      "  episode_reward_mean: 2.27176470588236\n",
      "  episode_reward_min: -1.8900000000000008\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 9928\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5890017088661845\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016004719514519133\n",
      "          policy_loss: -0.07137798365269206\n",
      "          total_loss: 0.08606006706742426\n",
      "          vf_explained_var: 0.8346642851829529\n",
      "          vf_loss: 0.14230972247150464\n",
      "    num_agent_steps_sampled: 959616\n",
      "    num_agent_steps_trained: 959616\n",
      "    num_steps_sampled: 959616\n",
      "    num_steps_trained: 959616\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.04522727272726\n",
      "    ram_util_percent: 44.66636363636363\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049726125307697495\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.025959348226756\n",
      "    mean_inference_ms: 8.705979597331003\n",
      "    mean_raw_obs_processing_ms: 2.619503687574671\n",
      "  time_since_restore: 29291.832412481308\n",
      "  time_this_iter_s: 308.5582559108734\n",
      "  time_total_s: 29291.832412481308\n",
      "  timers:\n",
      "    learn_throughput: 65.202\n",
      "    learn_time_ms: 153308.209\n",
      "    load_throughput: 86447.418\n",
      "    load_time_ms: 115.631\n",
      "    sample_throughput: 61.95\n",
      "    sample_time_ms: 161355.807\n",
      "    update_time_ms: 10.814\n",
      "  timestamp: 1636930029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 959616\n",
      "  training_iteration: 96\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         29291.8</td><td style=\"text-align: right;\">959616</td><td style=\"text-align: right;\"> 2.27176</td><td style=\"text-align: right;\">               10.46</td><td style=\"text-align: right;\">               -1.89</td><td style=\"text-align: right;\">            98.049</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 969612\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-52-18\n",
      "  done: false\n",
      "  episode_len_mean: 99.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.470000000000018\n",
      "  episode_reward_mean: 2.559600000000007\n",
      "  episode_reward_min: -2.129999999999998\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 10028\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5797832780414156\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01751043694433014\n",
      "          policy_loss: -0.06453033997080265\n",
      "          total_loss: 0.1088467560437882\n",
      "          vf_explained_var: 0.8536818623542786\n",
      "          vf_loss: 0.1542975958205887\n",
      "    num_agent_steps_sampled: 969612\n",
      "    num_agent_steps_trained: 969612\n",
      "    num_steps_sampled: 969612\n",
      "    num_steps_trained: 969612\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.93144796380089\n",
      "    ram_util_percent: 44.39547511312218\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0497292752693115\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.021110719978005\n",
      "    mean_inference_ms: 8.707024884027348\n",
      "    mean_raw_obs_processing_ms: 2.614970883340397\n",
      "  time_since_restore: 29600.981571912766\n",
      "  time_this_iter_s: 309.1491594314575\n",
      "  time_total_s: 29600.981571912766\n",
      "  timers:\n",
      "    learn_throughput: 65.197\n",
      "    learn_time_ms: 153320.93\n",
      "    load_throughput: 86765.45\n",
      "    load_time_ms: 115.207\n",
      "    sample_throughput: 62.046\n",
      "    sample_time_ms: 161105.99\n",
      "    update_time_ms: 10.944\n",
      "  timestamp: 1636930338\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 969612\n",
      "  training_iteration: 97\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">           29601</td><td style=\"text-align: right;\">969612</td><td style=\"text-align: right;\">  2.5596</td><td style=\"text-align: right;\">               12.47</td><td style=\"text-align: right;\">               -2.13</td><td style=\"text-align: right;\">             99.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 979608\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_22-57-28\n",
      "  done: false\n",
      "  episode_len_mean: 98.45098039215686\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.440000000000015\n",
      "  episode_reward_mean: 2.524019607843144\n",
      "  episode_reward_min: -2.1000000000000005\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 10130\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.596993138545599\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017426948336009603\n",
      "          policy_loss: -0.06627438539304795\n",
      "          total_loss: 0.11601057740915408\n",
      "          vf_explained_var: 0.8504003286361694\n",
      "          vf_loss: 0.16359153271485596\n",
      "    num_agent_steps_sampled: 979608\n",
      "    num_agent_steps_trained: 979608\n",
      "    num_steps_sampled: 979608\n",
      "    num_steps_trained: 979608\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.93642533936651\n",
      "    ram_util_percent: 44.79140271493212\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04972289705665755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01744764666108\n",
      "    mean_inference_ms: 8.707540178168353\n",
      "    mean_raw_obs_processing_ms: 2.6161769660513543\n",
      "  time_since_restore: 29910.9977850914\n",
      "  time_this_iter_s: 310.01621317863464\n",
      "  time_total_s: 29910.9977850914\n",
      "  timers:\n",
      "    learn_throughput: 65.191\n",
      "    learn_time_ms: 153334.629\n",
      "    load_throughput: 86609.586\n",
      "    load_time_ms: 115.414\n",
      "    sample_throughput: 61.454\n",
      "    sample_time_ms: 162657.906\n",
      "    update_time_ms: 9.584\n",
      "  timestamp: 1636930648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 979608\n",
      "  training_iteration: 98\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">           29911</td><td style=\"text-align: right;\">979608</td><td style=\"text-align: right;\"> 2.52402</td><td style=\"text-align: right;\">               12.44</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">            98.451</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 989604\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-02-25\n",
      "  done: false\n",
      "  episode_len_mean: 99.25490196078431\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.899999999999935\n",
      "  episode_reward_mean: 2.3698039215686326\n",
      "  episode_reward_min: -2.060000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 10232\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6018177914823224\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018115026934015843\n",
      "          policy_loss: -0.06303712310006794\n",
      "          total_loss: 0.11480996523422594\n",
      "          vf_explained_var: 0.8472806215286255\n",
      "          vf_loss: 0.15743843523634232\n",
      "    num_agent_steps_sampled: 989604\n",
      "    num_agent_steps_trained: 989604\n",
      "    num_steps_sampled: 989604\n",
      "    num_steps_trained: 989604\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.42482269503546\n",
      "    ram_util_percent: 44.558156028368785\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049732071842378184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.0207451247512\n",
      "    mean_inference_ms: 8.709474575826214\n",
      "    mean_raw_obs_processing_ms: 2.590447218626896\n",
      "  time_since_restore: 30207.60066819191\n",
      "  time_this_iter_s: 296.60288310050964\n",
      "  time_total_s: 30207.60066819191\n",
      "  timers:\n",
      "    learn_throughput: 65.22\n",
      "    learn_time_ms: 153266.62\n",
      "    load_throughput: 87497.697\n",
      "    load_time_ms: 114.243\n",
      "    sample_throughput: 63.874\n",
      "    sample_time_ms: 156496.598\n",
      "    update_time_ms: 10.361\n",
      "  timestamp: 1636930945\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 989604\n",
      "  training_iteration: 99\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         30207.6</td><td style=\"text-align: right;\">989604</td><td style=\"text-align: right;\">  2.3698</td><td style=\"text-align: right;\">                22.9</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           99.2549</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 999600\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-07-46\n",
      "  done: false\n",
      "  episode_len_mean: 97.15841584158416\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.53000000000001\n",
      "  episode_reward_mean: 2.259009900990105\n",
      "  episode_reward_min: -2.439999999999996\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 10333\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6016622639109945\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015700346235859957\n",
      "          policy_loss: -0.06839663633662793\n",
      "          total_loss: 0.08322221180503694\n",
      "          vf_explained_var: 0.8491207957267761\n",
      "          vf_loss: 0.13739720135569\n",
      "    num_agent_steps_sampled: 999600\n",
      "    num_agent_steps_trained: 999600\n",
      "    num_steps_sampled: 999600\n",
      "    num_steps_trained: 999600\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.4491266375546\n",
      "    ram_util_percent: 44.710917030567686\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04970814274823657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01338229291122\n",
      "    mean_inference_ms: 8.708915410575415\n",
      "    mean_raw_obs_processing_ms: 2.609335260703655\n",
      "  time_since_restore: 30528.69920015335\n",
      "  time_this_iter_s: 321.09853196144104\n",
      "  time_total_s: 30528.69920015335\n",
      "  timers:\n",
      "    learn_throughput: 65.232\n",
      "    learn_time_ms: 153237.099\n",
      "    load_throughput: 87730.714\n",
      "    load_time_ms: 113.94\n",
      "    sample_throughput: 63.909\n",
      "    sample_time_ms: 156410.312\n",
      "    update_time_ms: 11.073\n",
      "  timestamp: 1636931266\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 999600\n",
      "  training_iteration: 100\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         30528.7</td><td style=\"text-align: right;\">999600</td><td style=\"text-align: right;\"> 2.25901</td><td style=\"text-align: right;\">                8.53</td><td style=\"text-align: right;\">               -2.44</td><td style=\"text-align: right;\">           97.1584</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1009596\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-12-55\n",
      "  done: false\n",
      "  episode_len_mean: 98.59223300970874\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.64999999999999\n",
      "  episode_reward_mean: 2.520679611650492\n",
      "  episode_reward_min: -2.080000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 10436\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.59229332769019\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016310050364533174\n",
      "          policy_loss: -0.07001993228307264\n",
      "          total_loss: 0.09715427386287886\n",
      "          vf_explained_var: 0.851718008518219\n",
      "          vf_loss: 0.15129626535046367\n",
      "    num_agent_steps_sampled: 1009596\n",
      "    num_agent_steps_trained: 1009596\n",
      "    num_steps_sampled: 1009596\n",
      "    num_steps_trained: 1009596\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.87936507936509\n",
      "    ram_util_percent: 45.015192743764175\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04971551868813201\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01137070235455\n",
      "    mean_inference_ms: 8.709677843577344\n",
      "    mean_raw_obs_processing_ms: 2.61466293539389\n",
      "  time_since_restore: 30837.67964363098\n",
      "  time_this_iter_s: 308.9804434776306\n",
      "  time_total_s: 30837.67964363098\n",
      "  timers:\n",
      "    learn_throughput: 65.24\n",
      "    learn_time_ms: 153218.917\n",
      "    load_throughput: 87985.615\n",
      "    load_time_ms: 113.609\n",
      "    sample_throughput: 63.777\n",
      "    sample_time_ms: 156733.41\n",
      "    update_time_ms: 11.1\n",
      "  timestamp: 1636931575\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1009596\n",
      "  training_iteration: 101\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         30837.7</td><td style=\"text-align: right;\">1009596</td><td style=\"text-align: right;\"> 2.52068</td><td style=\"text-align: right;\">               16.65</td><td style=\"text-align: right;\">               -2.08</td><td style=\"text-align: right;\">           98.5922</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1019592\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-17-50\n",
      "  done: false\n",
      "  episode_len_mean: 99.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.530000000000015\n",
      "  episode_reward_mean: 2.7269000000000068\n",
      "  episode_reward_min: -2.259999999999998\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 10536\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.580098910922678\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0172789748065105\n",
      "          policy_loss: -0.06434996946133736\n",
      "          total_loss: 0.10918093767240007\n",
      "          vf_explained_var: 0.8457563519477844\n",
      "          vf_loss: 0.15504777417279397\n",
      "    num_agent_steps_sampled: 1019592\n",
      "    num_agent_steps_trained: 1019592\n",
      "    num_steps_sampled: 1019592\n",
      "    num_steps_trained: 1019592\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.65795724465558\n",
      "    ram_util_percent: 45.029453681710216\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04974366018662796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.013039349089084\n",
      "    mean_inference_ms: 8.712293301320631\n",
      "    mean_raw_obs_processing_ms: 2.5895923396795446\n",
      "  time_since_restore: 31132.531507730484\n",
      "  time_this_iter_s: 294.85186409950256\n",
      "  time_total_s: 31132.531507730484\n",
      "  timers:\n",
      "    learn_throughput: 65.245\n",
      "    learn_time_ms: 153207.917\n",
      "    load_throughput: 87671.349\n",
      "    load_time_ms: 114.017\n",
      "    sample_throughput: 63.823\n",
      "    sample_time_ms: 156621.878\n",
      "    update_time_ms: 11.401\n",
      "  timestamp: 1636931870\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1019592\n",
      "  training_iteration: 102\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         31132.5</td><td style=\"text-align: right;\">1019592</td><td style=\"text-align: right;\">  2.7269</td><td style=\"text-align: right;\">               10.53</td><td style=\"text-align: right;\">               -2.26</td><td style=\"text-align: right;\">             99.23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1029588\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-22-58\n",
      "  done: false\n",
      "  episode_len_mean: 97.9126213592233\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.399999999999935\n",
      "  episode_reward_mean: 2.994757281553404\n",
      "  episode_reward_min: -1.570000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 10639\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5662286679968873\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017435912234151963\n",
      "          policy_loss: -0.065328445756394\n",
      "          total_loss: 0.11622880914160966\n",
      "          vf_explained_var: 0.8582075834274292\n",
      "          vf_loss: 0.162533206340626\n",
      "    num_agent_steps_sampled: 1029588\n",
      "    num_agent_steps_trained: 1029588\n",
      "    num_steps_sampled: 1029588\n",
      "    num_steps_trained: 1029588\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.10364464692483\n",
      "    ram_util_percent: 44.85535307517084\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04972796436150431\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.007410793790626\n",
      "    mean_inference_ms: 8.712862287031287\n",
      "    mean_raw_obs_processing_ms: 2.5952941546172488\n",
      "  time_since_restore: 31440.075605154037\n",
      "  time_this_iter_s: 307.54409742355347\n",
      "  time_total_s: 31440.075605154037\n",
      "  timers:\n",
      "    learn_throughput: 65.247\n",
      "    learn_time_ms: 153201.416\n",
      "    load_throughput: 87110.167\n",
      "    load_time_ms: 114.751\n",
      "    sample_throughput: 63.984\n",
      "    sample_time_ms: 156227.242\n",
      "    update_time_ms: 10.659\n",
      "  timestamp: 1636932178\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1029588\n",
      "  training_iteration: 103\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         31440.1</td><td style=\"text-align: right;\">1029588</td><td style=\"text-align: right;\"> 2.99476</td><td style=\"text-align: right;\">                16.4</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           97.9126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1039584\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 95.60194174757281\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.820000000000018\n",
      "  episode_reward_mean: 2.4818446601941804\n",
      "  episode_reward_min: -2.2200000000000006\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 10742\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.595364976336813\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01574503400244446\n",
      "          policy_loss: -0.06996877217888195\n",
      "          total_loss: 0.07672035796806598\n",
      "          vf_explained_var: 0.8612208962440491\n",
      "          vf_loss: 0.1322899812613574\n",
      "    num_agent_steps_sampled: 1039584\n",
      "    num_agent_steps_trained: 1039584\n",
      "    num_steps_sampled: 1039584\n",
      "    num_steps_trained: 1039584\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.06644295302013\n",
      "    ram_util_percent: 44.65749440715884\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049726300643850106\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.013487086409036\n",
      "    mean_inference_ms: 8.714351676358712\n",
      "    mean_raw_obs_processing_ms: 2.585880650788012\n",
      "  time_since_restore: 31753.742298841476\n",
      "  time_this_iter_s: 313.66669368743896\n",
      "  time_total_s: 31753.742298841476\n",
      "  timers:\n",
      "    learn_throughput: 65.231\n",
      "    learn_time_ms: 153241.04\n",
      "    load_throughput: 86361.998\n",
      "    load_time_ms: 115.745\n",
      "    sample_throughput: 65.178\n",
      "    sample_time_ms: 153364.515\n",
      "    update_time_ms: 10.308\n",
      "  timestamp: 1636932491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1039584\n",
      "  training_iteration: 104\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         31753.7</td><td style=\"text-align: right;\">1039584</td><td style=\"text-align: right;\"> 2.48184</td><td style=\"text-align: right;\">               10.82</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           95.6019</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1049580\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-33-20\n",
      "  done: false\n",
      "  episode_len_mean: 98.64077669902913\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.710000000000015\n",
      "  episode_reward_mean: 2.5818446601941814\n",
      "  episode_reward_min: -2.3599999999999985\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 10845\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5815414428710937\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018894168293586942\n",
      "          policy_loss: -0.061319693681807855\n",
      "          total_loss: 0.14209294374076983\n",
      "          vf_explained_var: 0.8343311548233032\n",
      "          vf_loss: 0.1808043662056677\n",
      "    num_agent_steps_sampled: 1049580\n",
      "    num_agent_steps_trained: 1049580\n",
      "    num_steps_sampled: 1049580\n",
      "    num_steps_trained: 1049580\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.95477272727273\n",
      "    ram_util_percent: 44.9975\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049725151927942725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01477484920821\n",
      "    mean_inference_ms: 8.715122877653638\n",
      "    mean_raw_obs_processing_ms: 2.584105462527705\n",
      "  time_since_restore: 32062.339856147766\n",
      "  time_this_iter_s: 308.5975573062897\n",
      "  time_total_s: 32062.339856147766\n",
      "  timers:\n",
      "    learn_throughput: 65.227\n",
      "    learn_time_ms: 153250.377\n",
      "    load_throughput: 86543.795\n",
      "    load_time_ms: 115.502\n",
      "    sample_throughput: 64.693\n",
      "    sample_time_ms: 154514.551\n",
      "    update_time_ms: 10.268\n",
      "  timestamp: 1636932800\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1049580\n",
      "  training_iteration: 105\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         32062.3</td><td style=\"text-align: right;\">1049580</td><td style=\"text-align: right;\"> 2.58184</td><td style=\"text-align: right;\">               12.71</td><td style=\"text-align: right;\">               -2.36</td><td style=\"text-align: right;\">           98.6408</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1059576\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-38-15\n",
      "  done: false\n",
      "  episode_len_mean: 98.37623762376238\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 2.5181188118811937\n",
      "  episode_reward_min: -1.960000000000001\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 10946\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5777914026863553\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017749215225211536\n",
      "          policy_loss: -0.06398864379232255\n",
      "          total_loss: 0.1085162653380798\n",
      "          vf_explained_var: 0.8308896422386169\n",
      "          vf_loss: 0.1527935275561216\n",
      "    num_agent_steps_sampled: 1059576\n",
      "    num_agent_steps_trained: 1059576\n",
      "    num_steps_sampled: 1059576\n",
      "    num_steps_trained: 1059576\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.47725118483415\n",
      "    ram_util_percent: 44.621327014218004\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049728368050507864\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01924453813359\n",
      "    mean_inference_ms: 8.71655440556846\n",
      "    mean_raw_obs_processing_ms: 2.5733798642376198\n",
      "  time_since_restore: 32357.70332312584\n",
      "  time_this_iter_s: 295.3634669780731\n",
      "  time_total_s: 32357.70332312584\n",
      "  timers:\n",
      "    learn_throughput: 65.242\n",
      "    learn_time_ms: 153215.354\n",
      "    load_throughput: 87021.248\n",
      "    load_time_ms: 114.868\n",
      "    sample_throughput: 65.235\n",
      "    sample_time_ms: 153231.015\n",
      "    update_time_ms: 10.593\n",
      "  timestamp: 1636933095\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1059576\n",
      "  training_iteration: 106\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         32357.7</td><td style=\"text-align: right;\">1059576</td><td style=\"text-align: right;\"> 2.51812</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">           98.3762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1069572\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-43-38\n",
      "  done: false\n",
      "  episode_len_mean: 100.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.470000000000018\n",
      "  episode_reward_mean: 2.5002000000000066\n",
      "  episode_reward_min: -2.3099999999999987\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 11046\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5866337866864653\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016359674381960412\n",
      "          policy_loss: -0.06813534756000034\n",
      "          total_loss: 0.08062377471763355\n",
      "          vf_explained_var: 0.8361040949821472\n",
      "          vf_loss: 0.132697405701137\n",
      "    num_agent_steps_sampled: 1069572\n",
      "    num_agent_steps_trained: 1069572\n",
      "    num_steps_sampled: 1069572\n",
      "    num_steps_trained: 1069572\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.64413043478261\n",
      "    ram_util_percent: 44.63282608695653\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0496884527701949\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.011390018095334\n",
      "    mean_inference_ms: 8.715911393232126\n",
      "    mean_raw_obs_processing_ms: 2.594122715917846\n",
      "  time_since_restore: 32679.9562997818\n",
      "  time_this_iter_s: 322.2529766559601\n",
      "  time_total_s: 32679.9562997818\n",
      "  timers:\n",
      "    learn_throughput: 65.255\n",
      "    learn_time_ms: 153183.724\n",
      "    load_throughput: 86658.439\n",
      "    load_time_ms: 115.349\n",
      "    sample_throughput: 64.669\n",
      "    sample_time_ms: 154571.43\n",
      "    update_time_ms: 11.178\n",
      "  timestamp: 1636933418\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1069572\n",
      "  training_iteration: 107\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">           32680</td><td style=\"text-align: right;\">1069572</td><td style=\"text-align: right;\">  2.5002</td><td style=\"text-align: right;\">               12.47</td><td style=\"text-align: right;\">               -2.31</td><td style=\"text-align: right;\">            100.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1079568\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-49-04\n",
      "  done: false\n",
      "  episode_len_mean: 95.58653846153847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.180000000000021\n",
      "  episode_reward_mean: 2.069711538461544\n",
      "  episode_reward_min: -2.0500000000000003\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 11150\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.589951076161148\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0170610805577582\n",
      "          policy_loss: -0.06434753411807694\n",
      "          total_loss: 0.09668753942809044\n",
      "          vf_explained_var: 0.8596383333206177\n",
      "          vf_loss: 0.14320890220582613\n",
      "    num_agent_steps_sampled: 1079568\n",
      "    num_agent_steps_trained: 1079568\n",
      "    num_steps_sampled: 1079568\n",
      "    num_steps_trained: 1079568\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.61139784946238\n",
      "    ram_util_percent: 44.843440860215054\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04970236424212549\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.010957232682294\n",
      "    mean_inference_ms: 8.716415230969584\n",
      "    mean_raw_obs_processing_ms: 2.6196597165615385\n",
      "  time_since_restore: 33006.1644859314\n",
      "  time_this_iter_s: 326.20818614959717\n",
      "  time_total_s: 33006.1644859314\n",
      "  timers:\n",
      "    learn_throughput: 65.252\n",
      "    learn_time_ms: 153191.083\n",
      "    load_throughput: 87030.37\n",
      "    load_time_ms: 114.856\n",
      "    sample_throughput: 64.002\n",
      "    sample_time_ms: 156183.217\n",
      "    update_time_ms: 12.252\n",
      "  timestamp: 1636933744\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1079568\n",
      "  training_iteration: 108\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         33006.2</td><td style=\"text-align: right;\">1079568</td><td style=\"text-align: right;\"> 2.06971</td><td style=\"text-align: right;\">               10.18</td><td style=\"text-align: right;\">               -2.05</td><td style=\"text-align: right;\">           95.5865</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1089564\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-54-01\n",
      "  done: false\n",
      "  episode_len_mean: 98.34313725490196\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.849999999999916\n",
      "  episode_reward_mean: 2.4480392156862805\n",
      "  episode_reward_min: -1.6800000000000004\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 11252\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5891721107001997\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016502736914578636\n",
      "          policy_loss: -0.06466595971057366\n",
      "          total_loss: 0.09377982970048539\n",
      "          vf_explained_var: 0.8713749051094055\n",
      "          vf_loss: 0.14204280193035418\n",
      "    num_agent_steps_sampled: 1089564\n",
      "    num_agent_steps_trained: 1089564\n",
      "    num_steps_sampled: 1089564\n",
      "    num_steps_trained: 1089564\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.40448113207547\n",
      "    ram_util_percent: 45.20518867924529\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04970024381959531\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01426580407873\n",
      "    mean_inference_ms: 8.71829765118111\n",
      "    mean_raw_obs_processing_ms: 2.599222702010219\n",
      "  time_since_restore: 33303.19228577614\n",
      "  time_this_iter_s: 297.0277998447418\n",
      "  time_total_s: 33303.19228577614\n",
      "  timers:\n",
      "    learn_throughput: 65.242\n",
      "    learn_time_ms: 153214.487\n",
      "    load_throughput: 87025.673\n",
      "    load_time_ms: 114.863\n",
      "    sample_throughput: 63.994\n",
      "    sample_time_ms: 156202.28\n",
      "    update_time_ms: 11.883\n",
      "  timestamp: 1636934041\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1089564\n",
      "  training_iteration: 109\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         33303.2</td><td style=\"text-align: right;\">1089564</td><td style=\"text-align: right;\"> 2.44804</td><td style=\"text-align: right;\">               20.85</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           98.3431</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1099560\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_23-59-11\n",
      "  done: false\n",
      "  episode_len_mean: 98.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.37000000000002\n",
      "  episode_reward_mean: 2.4583000000000057\n",
      "  episode_reward_min: -2.319999999999998\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 11352\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.568427297294649\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01621665797669486\n",
      "          policy_loss: -0.07146694174625426\n",
      "          total_loss: 0.07634610066978405\n",
      "          vf_explained_var: 0.8448246717453003\n",
      "          vf_loss: 0.1319357954419385\n",
      "    num_agent_steps_sampled: 1099560\n",
      "    num_agent_steps_trained: 1099560\n",
      "    num_steps_sampled: 1099560\n",
      "    num_steps_trained: 1099560\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.04615384615384\n",
      "    ram_util_percent: 45.20565610859729\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04970806331601684\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.0154666630551\n",
      "    mean_inference_ms: 8.718497424014425\n",
      "    mean_raw_obs_processing_ms: 2.601147241242521\n",
      "  time_since_restore: 33612.79474043846\n",
      "  time_this_iter_s: 309.602454662323\n",
      "  time_total_s: 33612.79474043846\n",
      "  timers:\n",
      "    learn_throughput: 65.238\n",
      "    learn_time_ms: 153222.921\n",
      "    load_throughput: 87395.887\n",
      "    load_time_ms: 114.376\n",
      "    sample_throughput: 64.471\n",
      "    sample_time_ms: 155046.213\n",
      "    update_time_ms: 11.184\n",
      "  timestamp: 1636934351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1099560\n",
      "  training_iteration: 110\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         33612.8</td><td style=\"text-align: right;\">1099560</td><td style=\"text-align: right;\">  2.4583</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">               -2.32</td><td style=\"text-align: right;\">             98.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1109556\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-04-08\n",
      "  done: false\n",
      "  episode_len_mean: 98.68627450980392\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000017\n",
      "  episode_reward_mean: 2.58803921568628\n",
      "  episode_reward_min: -1.7000000000000006\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 11454\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5669390744633143\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017160094294662434\n",
      "          policy_loss: -0.06494401800764613\n",
      "          total_loss: 0.09666318509082955\n",
      "          vf_explained_var: 0.8670353889465332\n",
      "          vf_loss: 0.14329714927679071\n",
      "    num_agent_steps_sampled: 1109556\n",
      "    num_agent_steps_trained: 1109556\n",
      "    num_steps_sampled: 1109556\n",
      "    num_steps_trained: 1109556\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.47470449172577\n",
      "    ram_util_percent: 44.91394799054373\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049707320398960926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.020523208855465\n",
      "    mean_inference_ms: 8.719895062175818\n",
      "    mean_raw_obs_processing_ms: 2.5796155347934655\n",
      "  time_since_restore: 33909.72486805916\n",
      "  time_this_iter_s: 296.930127620697\n",
      "  time_total_s: 33909.72486805916\n",
      "  timers:\n",
      "    learn_throughput: 65.229\n",
      "    learn_time_ms: 153244.32\n",
      "    load_throughput: 87088.761\n",
      "    load_time_ms: 114.779\n",
      "    sample_throughput: 64.986\n",
      "    sample_time_ms: 153818.568\n",
      "    update_time_ms: 11.669\n",
      "  timestamp: 1636934648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1109556\n",
      "  training_iteration: 111\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         33909.7</td><td style=\"text-align: right;\">1109556</td><td style=\"text-align: right;\"> 2.58804</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           98.6863</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1119552\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-09-20\n",
      "  done: false\n",
      "  episode_len_mean: 97.51456310679612\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000017\n",
      "  episode_reward_mean: 2.0346601941747626\n",
      "  episode_reward_min: -1.8600000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 11557\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5853434305924634\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015496173986975744\n",
      "          policy_loss: -0.06810420788346958\n",
      "          total_loss: 0.07100668132034504\n",
      "          vf_explained_var: 0.8438402414321899\n",
      "          vf_loss: 0.1252493255914977\n",
      "    num_agent_steps_sampled: 1119552\n",
      "    num_agent_steps_trained: 1119552\n",
      "    num_steps_sampled: 1119552\n",
      "    num_steps_trained: 1119552\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.704932735426\n",
      "    ram_util_percent: 44.784080717488784\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04974267718350798\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02185787564628\n",
      "    mean_inference_ms: 8.720307073798102\n",
      "    mean_raw_obs_processing_ms: 2.598789502500027\n",
      "  time_since_restore: 34222.42150259018\n",
      "  time_this_iter_s: 312.6966345310211\n",
      "  time_total_s: 34222.42150259018\n",
      "  timers:\n",
      "    learn_throughput: 65.216\n",
      "    learn_time_ms: 153274.367\n",
      "    load_throughput: 87043.632\n",
      "    load_time_ms: 114.839\n",
      "    sample_throughput: 64.253\n",
      "    sample_time_ms: 155572.518\n",
      "    update_time_ms: 12.277\n",
      "  timestamp: 1636934960\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1119552\n",
      "  training_iteration: 112\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         34222.4</td><td style=\"text-align: right;\">1119552</td><td style=\"text-align: right;\"> 2.03466</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">               -1.86</td><td style=\"text-align: right;\">           97.5146</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1129548\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-14-46\n",
      "  done: false\n",
      "  episode_len_mean: 98.74257425742574\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.340000000000018\n",
      "  episode_reward_mean: 2.449900990099016\n",
      "  episode_reward_min: -1.9400000000000008\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 11658\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.602197876139584\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01824496251301579\n",
      "          policy_loss: -0.06270764992277847\n",
      "          total_loss: 0.11886917642062991\n",
      "          vf_explained_var: 0.8164681792259216\n",
      "          vf_loss: 0.16083896392598174\n",
      "    num_agent_steps_sampled: 1129548\n",
      "    num_agent_steps_trained: 1129548\n",
      "    num_steps_sampled: 1129548\n",
      "    num_steps_trained: 1129548\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.4077253218884\n",
      "    ram_util_percent: 44.79463519313304\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04974082268546739\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02374737423489\n",
      "    mean_inference_ms: 8.721610819120333\n",
      "    mean_raw_obs_processing_ms: 2.605237388999555\n",
      "  time_since_restore: 34548.34188437462\n",
      "  time_this_iter_s: 325.9203817844391\n",
      "  time_total_s: 34548.34188437462\n",
      "  timers:\n",
      "    learn_throughput: 65.22\n",
      "    learn_time_ms: 153266.128\n",
      "    load_throughput: 87366.257\n",
      "    load_time_ms: 114.415\n",
      "    sample_throughput: 63.5\n",
      "    sample_time_ms: 157417.784\n",
      "    update_time_ms: 12.467\n",
      "  timestamp: 1636935286\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1129548\n",
      "  training_iteration: 113\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         34548.3</td><td style=\"text-align: right;\">1129548</td><td style=\"text-align: right;\">  2.4499</td><td style=\"text-align: right;\">               10.34</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           98.7426</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1139544\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-19-59\n",
      "  done: false\n",
      "  episode_len_mean: 98.65346534653466\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.760000000000012\n",
      "  episode_reward_mean: 2.641881188118818\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 11759\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5781134154042626\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01680918668494258\n",
      "          policy_loss: -0.06884122703893063\n",
      "          total_loss: 0.08934708704821702\n",
      "          vf_explained_var: 0.8742937445640564\n",
      "          vf_loss: 0.1408893427373762\n",
      "    num_agent_steps_sampled: 1139544\n",
      "    num_agent_steps_trained: 1139544\n",
      "    num_steps_sampled: 1139544\n",
      "    num_steps_trained: 1139544\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.12309417040358\n",
      "    ram_util_percent: 45.01255605381166\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049746774915126614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02368114819284\n",
      "    mean_inference_ms: 8.722337083472636\n",
      "    mean_raw_obs_processing_ms: 2.6092695744210275\n",
      "  time_since_restore: 34861.1652135849\n",
      "  time_this_iter_s: 312.8233292102814\n",
      "  time_total_s: 34861.1652135849\n",
      "  timers:\n",
      "    learn_throughput: 65.235\n",
      "    learn_time_ms: 153229.897\n",
      "    load_throughput: 87783.23\n",
      "    load_time_ms: 113.871\n",
      "    sample_throughput: 63.519\n",
      "    sample_time_ms: 157369.063\n",
      "    update_time_ms: 13.619\n",
      "  timestamp: 1636935599\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1139544\n",
      "  training_iteration: 114\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         34861.2</td><td style=\"text-align: right;\">1139544</td><td style=\"text-align: right;\"> 2.64188</td><td style=\"text-align: right;\">               10.76</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           98.6535</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1149540\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-25-05\n",
      "  done: false\n",
      "  episode_len_mean: 99.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.520000000000017\n",
      "  episode_reward_mean: 2.2596000000000065\n",
      "  episode_reward_min: -2.11\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 11859\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5953127427997753\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016515480709775706\n",
      "          policy_loss: -0.0688974975508789\n",
      "          total_loss: 0.09158797917577127\n",
      "          vf_explained_var: 0.8850534558296204\n",
      "          vf_loss: 0.14411123484755173\n",
      "    num_agent_steps_sampled: 1149540\n",
      "    num_agent_steps_trained: 1149540\n",
      "    num_steps_sampled: 1149540\n",
      "    num_steps_trained: 1149540\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.82196796338673\n",
      "    ram_util_percent: 44.94553775743707\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04974304755060243\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01871700924829\n",
      "    mean_inference_ms: 8.723443684902772\n",
      "    mean_raw_obs_processing_ms: 2.60529976264115\n",
      "  time_since_restore: 35167.47646737099\n",
      "  time_this_iter_s: 306.31125378608704\n",
      "  time_total_s: 35167.47646737099\n",
      "  timers:\n",
      "    learn_throughput: 65.244\n",
      "    learn_time_ms: 153210.464\n",
      "    load_throughput: 87012.669\n",
      "    load_time_ms: 114.88\n",
      "    sample_throughput: 63.604\n",
      "    sample_time_ms: 157159.109\n",
      "    update_time_ms: 13.862\n",
      "  timestamp: 1636935905\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1149540\n",
      "  training_iteration: 115\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         35167.5</td><td style=\"text-align: right;\">1149540</td><td style=\"text-align: right;\">  2.2596</td><td style=\"text-align: right;\">               10.52</td><td style=\"text-align: right;\">               -2.11</td><td style=\"text-align: right;\">             99.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1159536\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-30-19\n",
      "  done: false\n",
      "  episode_len_mean: 98.58823529411765\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.030000000000012\n",
      "  episode_reward_mean: 2.6131372549019676\n",
      "  episode_reward_min: -2.070000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 11961\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.588864352356674\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017839263843168036\n",
      "          policy_loss: -0.06660985738301697\n",
      "          total_loss: 0.10328382134923123\n",
      "          vf_explained_var: 0.8519287109375\n",
      "          vf_loss: 0.15006224084486308\n",
      "    num_agent_steps_sampled: 1159536\n",
      "    num_agent_steps_trained: 1159536\n",
      "    num_steps_sampled: 1159536\n",
      "    num_steps_trained: 1159536\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.5993288590604\n",
      "    ram_util_percent: 44.96979865771812\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04973910100409279\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01849208383114\n",
      "    mean_inference_ms: 8.72444959677906\n",
      "    mean_raw_obs_processing_ms: 2.601762198585435\n",
      "  time_since_restore: 35480.90751814842\n",
      "  time_this_iter_s: 313.4310507774353\n",
      "  time_total_s: 35480.90751814842\n",
      "  timers:\n",
      "    learn_throughput: 65.231\n",
      "    learn_time_ms: 153240.859\n",
      "    load_throughput: 87192.958\n",
      "    load_time_ms: 114.642\n",
      "    sample_throughput: 62.894\n",
      "    sample_time_ms: 158935.196\n",
      "    update_time_ms: 13.942\n",
      "  timestamp: 1636936219\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1159536\n",
      "  training_iteration: 116\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         35480.9</td><td style=\"text-align: right;\">1159536</td><td style=\"text-align: right;\"> 2.61314</td><td style=\"text-align: right;\">               11.03</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           98.5882</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1169532\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-35-48\n",
      "  done: false\n",
      "  episode_len_mean: 95.86538461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.880000000000015\n",
      "  episode_reward_mean: 2.6829807692307757\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 12065\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.600360066157121\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017218391800279637\n",
      "          policy_loss: -0.06376424290629852\n",
      "          total_loss: 0.1178300187501133\n",
      "          vf_explained_var: 0.8292844295501709\n",
      "          vf_loss: 0.16346900790977553\n",
      "    num_agent_steps_sampled: 1169532\n",
      "    num_agent_steps_trained: 1169532\n",
      "    num_steps_sampled: 1169532\n",
      "    num_steps_trained: 1169532\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00574468085107\n",
      "    ram_util_percent: 44.90106382978724\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04972226040394058\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.010132085393785\n",
      "    mean_inference_ms: 8.723522985737079\n",
      "    mean_raw_obs_processing_ms: 2.637318297760558\n",
      "  time_since_restore: 35810.23458766937\n",
      "  time_this_iter_s: 329.3270695209503\n",
      "  time_total_s: 35810.23458766937\n",
      "  timers:\n",
      "    learn_throughput: 65.231\n",
      "    learn_time_ms: 153239.768\n",
      "    load_throughput: 87497.496\n",
      "    load_time_ms: 114.243\n",
      "    sample_throughput: 62.614\n",
      "    sample_time_ms: 159644.488\n",
      "    update_time_ms: 13.922\n",
      "  timestamp: 1636936548\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1169532\n",
      "  training_iteration: 117\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         35810.2</td><td style=\"text-align: right;\">1169532</td><td style=\"text-align: right;\"> 2.68298</td><td style=\"text-align: right;\">               10.88</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           95.8654</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1179528\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-41-01\n",
      "  done: false\n",
      "  episode_len_mean: 97.81553398058253\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.830000000000002\n",
      "  episode_reward_mean: 2.038737864077676\n",
      "  episode_reward_min: -1.870000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 12168\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6071134020120668\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017612580937226337\n",
      "          policy_loss: -0.06358339602374431\n",
      "          total_loss: 0.10643092292464441\n",
      "          vf_explained_var: 0.8637513518333435\n",
      "          vf_loss: 0.15094633609231592\n",
      "    num_agent_steps_sampled: 1179528\n",
      "    num_agent_steps_trained: 1179528\n",
      "    num_steps_sampled: 1179528\n",
      "    num_steps_trained: 1179528\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.69798657718121\n",
      "    ram_util_percent: 44.954586129753906\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04975184284778135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.010541621482034\n",
      "    mean_inference_ms: 8.72476686654696\n",
      "    mean_raw_obs_processing_ms: 2.6350919933236834\n",
      "  time_since_restore: 36123.135501384735\n",
      "  time_this_iter_s: 312.90091371536255\n",
      "  time_total_s: 36123.135501384735\n",
      "  timers:\n",
      "    learn_throughput: 65.22\n",
      "    learn_time_ms: 153265.169\n",
      "    load_throughput: 87837.392\n",
      "    load_time_ms: 113.801\n",
      "    sample_throughput: 63.15\n",
      "    sample_time_ms: 158289.066\n",
      "    update_time_ms: 13.733\n",
      "  timestamp: 1636936861\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1179528\n",
      "  training_iteration: 118\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         36123.1</td><td style=\"text-align: right;\">1179528</td><td style=\"text-align: right;\"> 2.03874</td><td style=\"text-align: right;\">                9.83</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">           97.8155</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1189524\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-45-56\n",
      "  done: false\n",
      "  episode_len_mean: 99.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.760000000000012\n",
      "  episode_reward_mean: 2.511900000000006\n",
      "  episode_reward_min: -1.7700000000000007\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 12267\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5948652057566193\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018633186181617235\n",
      "          policy_loss: -0.06338343634857183\n",
      "          total_loss: 0.10997998144589047\n",
      "          vf_explained_var: 0.8221212029457092\n",
      "          vf_loss: 0.151557252708122\n",
      "    num_agent_steps_sampled: 1189524\n",
      "    num_agent_steps_trained: 1189524\n",
      "    num_steps_sampled: 1189524\n",
      "    num_steps_trained: 1189524\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.39666666666668\n",
      "    ram_util_percent: 44.891666666666666\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04975296893192337\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.013908707003985\n",
      "    mean_inference_ms: 8.726509344765484\n",
      "    mean_raw_obs_processing_ms: 2.6136088192281473\n",
      "  time_since_restore: 36417.96410369873\n",
      "  time_this_iter_s: 294.82860231399536\n",
      "  time_total_s: 36417.96410369873\n",
      "  timers:\n",
      "    learn_throughput: 65.23\n",
      "    learn_time_ms: 153241.375\n",
      "    load_throughput: 87337.756\n",
      "    load_time_ms: 114.452\n",
      "    sample_throughput: 63.229\n",
      "    sample_time_ms: 158092.455\n",
      "    update_time_ms: 14.262\n",
      "  timestamp: 1636937156\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1189524\n",
      "  training_iteration: 119\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">           36418</td><td style=\"text-align: right;\">1189524</td><td style=\"text-align: right;\">  2.5119</td><td style=\"text-align: right;\">                8.76</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">             99.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1199520\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-50-52\n",
      "  done: false\n",
      "  episode_len_mean: 99.16831683168317\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.810000000000015\n",
      "  episode_reward_mean: 2.2886138613861435\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 12368\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6052775774246606\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016942326375182275\n",
      "          policy_loss: -0.06299854558215946\n",
      "          total_loss: 0.09010785841144239\n",
      "          vf_explained_var: 0.8294541239738464\n",
      "          vf_loss: 0.1357378523872417\n",
      "    num_agent_steps_sampled: 1199520\n",
      "    num_agent_steps_trained: 1199520\n",
      "    num_steps_sampled: 1199520\n",
      "    num_steps_trained: 1199520\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.59218009478673\n",
      "    ram_util_percent: 44.43744075829384\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04975754411774631\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01876030591614\n",
      "    mean_inference_ms: 8.727184239930578\n",
      "    mean_raw_obs_processing_ms: 2.599274320759068\n",
      "  time_since_restore: 36713.702360630035\n",
      "  time_this_iter_s: 295.73825693130493\n",
      "  time_total_s: 36713.702360630035\n",
      "  timers:\n",
      "    learn_throughput: 65.214\n",
      "    learn_time_ms: 153280.675\n",
      "    load_throughput: 87055.995\n",
      "    load_time_ms: 114.823\n",
      "    sample_throughput: 63.805\n",
      "    sample_time_ms: 156665.907\n",
      "    update_time_ms: 14.073\n",
      "  timestamp: 1636937452\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1199520\n",
      "  training_iteration: 120\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         36713.7</td><td style=\"text-align: right;\">1199520</td><td style=\"text-align: right;\"> 2.28861</td><td style=\"text-align: right;\">               14.81</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           99.1683</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1209516\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_00-56-00\n",
      "  done: false\n",
      "  episode_len_mean: 99.48514851485149\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.960000000000013\n",
      "  episode_reward_mean: 2.366930693069313\n",
      "  episode_reward_min: -2.2000000000000006\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 12469\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6083568137935083\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017333055365487092\n",
      "          policy_loss: -0.06268761141751057\n",
      "          total_loss: 0.09304099617820456\n",
      "          vf_explained_var: 0.8385345935821533\n",
      "          vf_loss: 0.13738945262928484\n",
      "    num_agent_steps_sampled: 1209516\n",
      "    num_agent_steps_trained: 1209516\n",
      "    num_steps_sampled: 1209516\n",
      "    num_steps_trained: 1209516\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.63795454545453\n",
      "    ram_util_percent: 44.82749999999999\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04976544793579338\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00775182347733\n",
      "    mean_inference_ms: 8.727945668483269\n",
      "    mean_raw_obs_processing_ms: 2.6135981919688707\n",
      "  time_since_restore: 37021.8975481987\n",
      "  time_this_iter_s: 308.19518756866455\n",
      "  time_total_s: 37021.8975481987\n",
      "  timers:\n",
      "    learn_throughput: 65.225\n",
      "    learn_time_ms: 153255.067\n",
      "    load_throughput: 87155.456\n",
      "    load_time_ms: 114.692\n",
      "    sample_throughput: 63.339\n",
      "    sample_time_ms: 157818.067\n",
      "    update_time_ms: 13.548\n",
      "  timestamp: 1636937760\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1209516\n",
      "  training_iteration: 121\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         37021.9</td><td style=\"text-align: right;\">1209516</td><td style=\"text-align: right;\"> 2.36693</td><td style=\"text-align: right;\">               10.96</td><td style=\"text-align: right;\">                -2.2</td><td style=\"text-align: right;\">           99.4851</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1219512\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-01-10\n",
      "  done: false\n",
      "  episode_len_mean: 100.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.550000000000018\n",
      "  episode_reward_mean: 2.342100000000006\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 12568\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6124513992896445\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017349045517535234\n",
      "          policy_loss: -0.06020720117669712\n",
      "          total_loss: 0.10589095451988471\n",
      "          vf_explained_var: 0.8350613117218018\n",
      "          vf_loss: 0.14775896508557101\n",
      "    num_agent_steps_sampled: 1219512\n",
      "    num_agent_steps_trained: 1219512\n",
      "    num_steps_sampled: 1219512\n",
      "    num_steps_trained: 1219512\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.58208616780044\n",
      "    ram_util_percent: 45.1421768707483\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049783863140315604\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.008510923192404\n",
      "    mean_inference_ms: 8.729437197132507\n",
      "    mean_raw_obs_processing_ms: 2.610180879194273\n",
      "  time_since_restore: 37331.36311650276\n",
      "  time_this_iter_s: 309.4655683040619\n",
      "  time_total_s: 37331.36311650276\n",
      "  timers:\n",
      "    learn_throughput: 65.24\n",
      "    learn_time_ms: 153219.035\n",
      "    load_throughput: 87261.047\n",
      "    load_time_ms: 114.553\n",
      "    sample_throughput: 63.454\n",
      "    sample_time_ms: 157532.504\n",
      "    update_time_ms: 12.84\n",
      "  timestamp: 1636938070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1219512\n",
      "  training_iteration: 122\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         37331.4</td><td style=\"text-align: right;\">1219512</td><td style=\"text-align: right;\">  2.3421</td><td style=\"text-align: right;\">               10.55</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">             100.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1229508\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-06-04\n",
      "  done: false\n",
      "  episode_len_mean: 99.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.480000000000018\n",
      "  episode_reward_mean: 2.873200000000007\n",
      "  episode_reward_min: -2.0300000000000007\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 12668\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.608261782185644\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01633254248038739\n",
      "          policy_loss: -0.06544352780239514\n",
      "          total_loss: 0.087674129067554\n",
      "          vf_explained_var: 0.855833888053894\n",
      "          vf_loss: 0.1373417567095568\n",
      "    num_agent_steps_sampled: 1229508\n",
      "    num_agent_steps_trained: 1229508\n",
      "    num_steps_sampled: 1229508\n",
      "    num_steps_trained: 1229508\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.34133016627078\n",
      "    ram_util_percent: 45.01116389548693\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049775918803366535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00935891454837\n",
      "    mean_inference_ms: 8.730233522456809\n",
      "    mean_raw_obs_processing_ms: 2.599385519575733\n",
      "  time_since_restore: 37625.86496567726\n",
      "  time_this_iter_s: 294.5018491744995\n",
      "  time_total_s: 37625.86496567726\n",
      "  timers:\n",
      "    learn_throughput: 65.238\n",
      "    learn_time_ms: 153223.38\n",
      "    load_throughput: 87569.116\n",
      "    load_time_ms: 114.15\n",
      "    sample_throughput: 64.746\n",
      "    sample_time_ms: 154386.903\n",
      "    update_time_ms: 12.919\n",
      "  timestamp: 1636938364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1229508\n",
      "  training_iteration: 123\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         37625.9</td><td style=\"text-align: right;\">1229508</td><td style=\"text-align: right;\">  2.8732</td><td style=\"text-align: right;\">               12.48</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">             99.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1239504\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-11-18\n",
      "  done: false\n",
      "  episode_len_mean: 96.6923076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.180000000000017\n",
      "  episode_reward_mean: 1.9314423076923133\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 12772\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6137132520349615\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015967303512150047\n",
      "          policy_loss: -0.06548812543201205\n",
      "          total_loss: 0.06981159141804609\n",
      "          vf_explained_var: 0.8839840888977051\n",
      "          vf_loss: 0.12051439886976384\n",
      "    num_agent_steps_sampled: 1239504\n",
      "    num_agent_steps_trained: 1239504\n",
      "    num_steps_sampled: 1239504\n",
      "    num_steps_trained: 1239504\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.92930648769575\n",
      "    ram_util_percent: 44.63333333333335\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04979728932070622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01013092327957\n",
      "    mean_inference_ms: 8.731017412919035\n",
      "    mean_raw_obs_processing_ms: 2.6042294232561334\n",
      "  time_since_restore: 37939.45467686653\n",
      "  time_this_iter_s: 313.58971118927\n",
      "  time_total_s: 37939.45467686653\n",
      "  timers:\n",
      "    learn_throughput: 65.253\n",
      "    learn_time_ms: 153187.24\n",
      "    load_throughput: 87787.219\n",
      "    load_time_ms: 113.866\n",
      "    sample_throughput: 64.699\n",
      "    sample_time_ms: 154500.402\n",
      "    update_time_ms: 12.38\n",
      "  timestamp: 1636938678\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1239504\n",
      "  training_iteration: 124\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         37939.5</td><td style=\"text-align: right;\">1239504</td><td style=\"text-align: right;\"> 1.93144</td><td style=\"text-align: right;\">                8.18</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           96.6923</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1249500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-16-13\n",
      "  done: false\n",
      "  episode_len_mean: 98.62745098039215\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.820000000000014\n",
      "  episode_reward_mean: 2.3911764705882423\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 12874\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.604096193904551\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017479444609215994\n",
      "          policy_loss: -0.05859993982932761\n",
      "          total_loss: 0.09610070897242388\n",
      "          vf_explained_var: 0.8691852688789368\n",
      "          vf_loss: 0.13594370762674282\n",
      "    num_agent_steps_sampled: 1249500\n",
      "    num_agent_steps_trained: 1249500\n",
      "    num_steps_sampled: 1249500\n",
      "    num_steps_trained: 1249500\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.46033254156771\n",
      "    ram_util_percent: 44.87862232779098\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04979110027542518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01224377997298\n",
      "    mean_inference_ms: 8.73171247089988\n",
      "    mean_raw_obs_processing_ms: 2.5954850151412714\n",
      "  time_since_restore: 38234.52378487587\n",
      "  time_this_iter_s: 295.0691080093384\n",
      "  time_total_s: 38234.52378487587\n",
      "  timers:\n",
      "    learn_throughput: 65.249\n",
      "    learn_time_ms: 153196.825\n",
      "    load_throughput: 88283.046\n",
      "    load_time_ms: 113.227\n",
      "    sample_throughput: 65.177\n",
      "    sample_time_ms: 153366.73\n",
      "    update_time_ms: 12.26\n",
      "  timestamp: 1636938973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1249500\n",
      "  training_iteration: 125\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         38234.5</td><td style=\"text-align: right;\">1249500</td><td style=\"text-align: right;\"> 2.39118</td><td style=\"text-align: right;\">                8.82</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           98.6275</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1259496\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-21-19\n",
      "  done: false\n",
      "  episode_len_mean: 99.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.900000000000018\n",
      "  episode_reward_mean: 2.451700000000006\n",
      "  episode_reward_min: -1.8300000000000007\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 12974\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.616882066033844\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016214119921373556\n",
      "          policy_loss: -0.06749549262368908\n",
      "          total_loss: 0.08027267845339564\n",
      "          vf_explained_var: 0.8333847522735596\n",
      "          vf_loss: 0.13238197697533502\n",
      "    num_agent_steps_sampled: 1259496\n",
      "    num_agent_steps_trained: 1259496\n",
      "    num_steps_sampled: 1259496\n",
      "    num_steps_trained: 1259496\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.95756880733946\n",
      "    ram_util_percent: 45.15160550458716\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049797308855759365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.004777482735484\n",
      "    mean_inference_ms: 8.732545386278812\n",
      "    mean_raw_obs_processing_ms: 2.596680800305925\n",
      "  time_since_restore: 38540.37949895859\n",
      "  time_this_iter_s: 305.8557140827179\n",
      "  time_total_s: 38540.37949895859\n",
      "  timers:\n",
      "    learn_throughput: 65.258\n",
      "    learn_time_ms: 153176.275\n",
      "    load_throughput: 87763.311\n",
      "    load_time_ms: 113.897\n",
      "    sample_throughput: 65.491\n",
      "    sample_time_ms: 152630.495\n",
      "    update_time_ms: 11.628\n",
      "  timestamp: 1636939279\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1259496\n",
      "  training_iteration: 126\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         38540.4</td><td style=\"text-align: right;\">1259496</td><td style=\"text-align: right;\">  2.4517</td><td style=\"text-align: right;\">                10.9</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">             99.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1269492\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-26-16\n",
      "  done: false\n",
      "  episode_len_mean: 98.13725490196079\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.520000000000012\n",
      "  episode_reward_mean: 2.244313725490202\n",
      "  episode_reward_min: -2.0799999999999987\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 13076\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6129688119276975\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017297562879548967\n",
      "          policy_loss: -0.065381052900647\n",
      "          total_loss: 0.08939508227352849\n",
      "          vf_explained_var: 0.8617384433746338\n",
      "          vf_loss: 0.13657406331597166\n",
      "    num_agent_steps_sampled: 1269492\n",
      "    num_agent_steps_trained: 1269492\n",
      "    num_steps_sampled: 1269492\n",
      "    num_steps_trained: 1269492\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.31388235294116\n",
      "    ram_util_percent: 45.15435294117647\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0497812892357357\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00917412701069\n",
      "    mean_inference_ms: 8.733588894155213\n",
      "    mean_raw_obs_processing_ms: 2.579983650615193\n",
      "  time_since_restore: 38837.623957157135\n",
      "  time_this_iter_s: 297.24445819854736\n",
      "  time_total_s: 38837.623957157135\n",
      "  timers:\n",
      "    learn_throughput: 65.263\n",
      "    learn_time_ms: 153166.006\n",
      "    load_throughput: 88126.799\n",
      "    load_time_ms: 113.427\n",
      "    sample_throughput: 66.892\n",
      "    sample_time_ms: 149433.949\n",
      "    update_time_ms: 10.721\n",
      "  timestamp: 1636939576\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1269492\n",
      "  training_iteration: 127\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         38837.6</td><td style=\"text-align: right;\">1269492</td><td style=\"text-align: right;\"> 2.24431</td><td style=\"text-align: right;\">               10.52</td><td style=\"text-align: right;\">               -2.08</td><td style=\"text-align: right;\">           98.1373</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1279488\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-31-27\n",
      "  done: false\n",
      "  episode_len_mean: 98.04901960784314\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.510000000000018\n",
      "  episode_reward_mean: 2.4436274509803977\n",
      "  episode_reward_min: -2.0900000000000007\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 13178\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6169697508852705\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015441692915214857\n",
      "          policy_loss: -0.06531632920950015\n",
      "          total_loss: 0.07963179954025162\n",
      "          vf_explained_var: 0.8769989013671875\n",
      "          vf_loss: 0.1315424564202977\n",
      "    num_agent_steps_sampled: 1279488\n",
      "    num_agent_steps_trained: 1279488\n",
      "    num_steps_sampled: 1279488\n",
      "    num_steps_trained: 1279488\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.9505643340858\n",
      "    ram_util_percent: 45.201805869074484\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04977544293800227\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00618689522922\n",
      "    mean_inference_ms: 8.73376949215951\n",
      "    mean_raw_obs_processing_ms: 2.586827071381581\n",
      "  time_since_restore: 39148.21759939194\n",
      "  time_this_iter_s: 310.59364223480225\n",
      "  time_total_s: 39148.21759939194\n",
      "  timers:\n",
      "    learn_throughput: 65.273\n",
      "    learn_time_ms: 153141.91\n",
      "    load_throughput: 87755.119\n",
      "    load_time_ms: 113.908\n",
      "    sample_throughput: 66.985\n",
      "    sample_time_ms: 149227.885\n",
      "    update_time_ms: 9.936\n",
      "  timestamp: 1636939887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1279488\n",
      "  training_iteration: 128\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         39148.2</td><td style=\"text-align: right;\">1279488</td><td style=\"text-align: right;\"> 2.44363</td><td style=\"text-align: right;\">               12.51</td><td style=\"text-align: right;\">               -2.09</td><td style=\"text-align: right;\">            98.049</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1289484\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-36-32\n",
      "  done: false\n",
      "  episode_len_mean: 99.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.270000000000017\n",
      "  episode_reward_mean: 2.0312000000000068\n",
      "  episode_reward_min: -2.279999999999999\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 13278\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6304624702176476\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016127933100337985\n",
      "          policy_loss: -0.06181645180202193\n",
      "          total_loss: 0.09285315143991198\n",
      "          vf_explained_var: 0.856195867061615\n",
      "          vf_loss: 0.13964009981196468\n",
      "    num_agent_steps_sampled: 1289484\n",
      "    num_agent_steps_trained: 1289484\n",
      "    num_steps_sampled: 1289484\n",
      "    num_steps_trained: 1289484\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.27110091743118\n",
      "    ram_util_percent: 45.19036697247708\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04976755225471962\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00417295721039\n",
      "    mean_inference_ms: 8.733885666348874\n",
      "    mean_raw_obs_processing_ms: 2.5930481735428157\n",
      "  time_since_restore: 39453.792565345764\n",
      "  time_this_iter_s: 305.5749659538269\n",
      "  time_total_s: 39453.792565345764\n",
      "  timers:\n",
      "    learn_throughput: 65.302\n",
      "    learn_time_ms: 153074.321\n",
      "    load_throughput: 87712.306\n",
      "    load_time_ms: 113.963\n",
      "    sample_throughput: 66.476\n",
      "    sample_time_ms: 150370.71\n",
      "    update_time_ms: 9.087\n",
      "  timestamp: 1636940192\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1289484\n",
      "  training_iteration: 129\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         39453.8</td><td style=\"text-align: right;\">1289484</td><td style=\"text-align: right;\">  2.0312</td><td style=\"text-align: right;\">                8.27</td><td style=\"text-align: right;\">               -2.28</td><td style=\"text-align: right;\">             99.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1299480\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-41-31\n",
      "  done: false\n",
      "  episode_len_mean: 98.95049504950495\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.770000000000016\n",
      "  episode_reward_mean: 2.4188118811881263\n",
      "  episode_reward_min: -1.960000000000001\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 13379\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6333629376867895\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017739664304850845\n",
      "          policy_loss: -0.06112696092543948\n",
      "          total_loss: 0.09738123807100914\n",
      "          vf_explained_var: 0.8725289106369019\n",
      "          vf_loss: 0.13937701075138825\n",
      "    num_agent_steps_sampled: 1299480\n",
      "    num_agent_steps_trained: 1299480\n",
      "    num_steps_sampled: 1299480\n",
      "    num_steps_trained: 1299480\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.53419203747075\n",
      "    ram_util_percent: 45.00023419203747\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04977521750204398\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.012903999323754\n",
      "    mean_inference_ms: 8.734670444902115\n",
      "    mean_raw_obs_processing_ms: 2.5801827135970523\n",
      "  time_since_restore: 39753.04821062088\n",
      "  time_this_iter_s: 299.25564527511597\n",
      "  time_total_s: 39753.04821062088\n",
      "  timers:\n",
      "    learn_throughput: 65.327\n",
      "    learn_time_ms: 153015.194\n",
      "    load_throughput: 87931.768\n",
      "    load_time_ms: 113.679\n",
      "    sample_throughput: 66.295\n",
      "    sample_time_ms: 150781.576\n",
      "    update_time_ms: 9.134\n",
      "  timestamp: 1636940491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1299480\n",
      "  training_iteration: 130\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">           39753</td><td style=\"text-align: right;\">1299480</td><td style=\"text-align: right;\"> 2.41881</td><td style=\"text-align: right;\">                8.77</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">           98.9505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1309476\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-46-39\n",
      "  done: false\n",
      "  episode_len_mean: 99.57425742574257\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.570000000000016\n",
      "  episode_reward_mean: 2.060000000000005\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 13480\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6447989916190124\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01678037737129894\n",
      "          policy_loss: -0.0624418323326251\n",
      "          total_loss: 0.0871041450347019\n",
      "          vf_explained_var: 0.8526861071586609\n",
      "          vf_loss: 0.1329876966197362\n",
      "    num_agent_steps_sampled: 1309476\n",
      "    num_agent_steps_trained: 1309476\n",
      "    num_steps_sampled: 1309476\n",
      "    num_steps_trained: 1309476\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.90820045558085\n",
      "    ram_util_percent: 44.79612756264237\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049784176448303394\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00696816208606\n",
      "    mean_inference_ms: 8.734769428071173\n",
      "    mean_raw_obs_processing_ms: 2.586860836126633\n",
      "  time_since_restore: 40061.02160072327\n",
      "  time_this_iter_s: 307.9733901023865\n",
      "  time_total_s: 40061.02160072327\n",
      "  timers:\n",
      "    learn_throughput: 65.325\n",
      "    learn_time_ms: 153020.254\n",
      "    load_throughput: 88133.32\n",
      "    load_time_ms: 113.419\n",
      "    sample_throughput: 66.306\n",
      "    sample_time_ms: 150755.858\n",
      "    update_time_ms: 8.758\n",
      "  timestamp: 1636940799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1309476\n",
      "  training_iteration: 131\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">           40061</td><td style=\"text-align: right;\">1309476</td><td style=\"text-align: right;\">    2.06</td><td style=\"text-align: right;\">               12.57</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           99.5743</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1319472\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-51-34\n",
      "  done: false\n",
      "  episode_len_mean: 100.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.430000000000016\n",
      "  episode_reward_mean: 2.7214000000000085\n",
      "  episode_reward_min: -1.8700000000000008\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 13578\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6142716000222754\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016493092099638833\n",
      "          policy_loss: -0.05876524340218076\n",
      "          total_loss: 0.11436910788751502\n",
      "          vf_explained_var: 0.8531970977783203\n",
      "          vf_loss: 0.15700707763759816\n",
      "    num_agent_steps_sampled: 1319472\n",
      "    num_agent_steps_trained: 1319472\n",
      "    num_steps_sampled: 1319472\n",
      "    num_steps_trained: 1319472\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.53166666666668\n",
      "    ram_util_percent: 44.854285714285716\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049808694362558796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00707315019663\n",
      "    mean_inference_ms: 8.736307662489516\n",
      "    mean_raw_obs_processing_ms: 2.566904707662326\n",
      "  time_since_restore: 40355.35064959526\n",
      "  time_this_iter_s: 294.329048871994\n",
      "  time_total_s: 40355.35064959526\n",
      "  timers:\n",
      "    learn_throughput: 65.337\n",
      "    learn_time_ms: 152990.738\n",
      "    load_throughput: 88679.267\n",
      "    load_time_ms: 112.721\n",
      "    sample_throughput: 66.965\n",
      "    sample_time_ms: 149271.617\n",
      "    update_time_ms: 9.255\n",
      "  timestamp: 1636941094\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1319472\n",
      "  training_iteration: 132\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         40355.4</td><td style=\"text-align: right;\">1319472</td><td style=\"text-align: right;\">  2.7214</td><td style=\"text-align: right;\">               12.43</td><td style=\"text-align: right;\">               -1.87</td><td style=\"text-align: right;\">            100.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1329468\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_01-56-41\n",
      "  done: false\n",
      "  episode_len_mean: 99.03921568627452\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.160000000000018\n",
      "  episode_reward_mean: 2.317549019607849\n",
      "  episode_reward_min: -2.290000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 13680\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6250116020186334\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015788259996502352\n",
      "          policy_loss: -0.06270693168362491\n",
      "          total_loss: 0.08965255485760032\n",
      "          vf_explained_var: 0.846373438835144\n",
      "          vf_loss: 0.1381460197464937\n",
      "    num_agent_steps_sampled: 1329468\n",
      "    num_agent_steps_trained: 1329468\n",
      "    num_steps_sampled: 1329468\n",
      "    num_steps_trained: 1329468\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.1628701594533\n",
      "    ram_util_percent: 45.12232346241458\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049809195939269406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00666569513817\n",
      "    mean_inference_ms: 8.7362001436457\n",
      "    mean_raw_obs_processing_ms: 2.5735405157861617\n",
      "  time_since_restore: 40662.97886919975\n",
      "  time_this_iter_s: 307.6282196044922\n",
      "  time_total_s: 40662.97886919975\n",
      "  timers:\n",
      "    learn_throughput: 65.342\n",
      "    learn_time_ms: 152980.77\n",
      "    load_throughput: 88399.271\n",
      "    load_time_ms: 113.078\n",
      "    sample_throughput: 66.377\n",
      "    sample_time_ms: 150594.428\n",
      "    update_time_ms: 8.818\n",
      "  timestamp: 1636941401\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1329468\n",
      "  training_iteration: 133\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">           40663</td><td style=\"text-align: right;\">1329468</td><td style=\"text-align: right;\"> 2.31755</td><td style=\"text-align: right;\">               12.16</td><td style=\"text-align: right;\">               -2.29</td><td style=\"text-align: right;\">           99.0392</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1339464\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-01-35\n",
      "  done: false\n",
      "  episode_len_mean: 101.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.31000000000002\n",
      "  episode_reward_mean: 2.4095000000000066\n",
      "  episode_reward_min: -1.770000000000001\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 13778\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.640960621833801\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014967099273682559\n",
      "          policy_loss: -0.06394343674620694\n",
      "          total_loss: 0.06478916503186537\n",
      "          vf_explained_var: 0.8625351786613464\n",
      "          vf_loss: 0.11678317009718117\n",
      "    num_agent_steps_sampled: 1339464\n",
      "    num_agent_steps_trained: 1339464\n",
      "    num_steps_sampled: 1339464\n",
      "    num_steps_trained: 1339464\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.41435406698564\n",
      "    ram_util_percent: 45.14425837320575\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04984435049877828\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00379772376327\n",
      "    mean_inference_ms: 8.738001387060407\n",
      "    mean_raw_obs_processing_ms: 2.5526454906845517\n",
      "  time_since_restore: 40956.32307648659\n",
      "  time_this_iter_s: 293.3442072868347\n",
      "  time_total_s: 40956.32307648659\n",
      "  timers:\n",
      "    learn_throughput: 65.346\n",
      "    learn_time_ms: 152971.146\n",
      "    load_throughput: 88229.15\n",
      "    load_time_ms: 113.296\n",
      "    sample_throughput: 67.277\n",
      "    sample_time_ms: 148579.375\n",
      "    update_time_ms: 8.85\n",
      "  timestamp: 1636941695\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1339464\n",
      "  training_iteration: 134\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         40956.3</td><td style=\"text-align: right;\">1339464</td><td style=\"text-align: right;\">  2.4095</td><td style=\"text-align: right;\">               14.31</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">            101.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1349460\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-06-44\n",
      "  done: false\n",
      "  episode_len_mean: 97.35922330097087\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.08000000000002\n",
      "  episode_reward_mean: 2.4791262135922394\n",
      "  episode_reward_min: -2.070000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 13881\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6332993226173596\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017267062886380462\n",
      "          policy_loss: -0.06331477536716396\n",
      "          total_loss: 0.08206274833004826\n",
      "          vf_explained_var: 0.8622965216636658\n",
      "          vf_loss: 0.1274569237186836\n",
      "    num_agent_steps_sampled: 1349460\n",
      "    num_agent_steps_trained: 1349460\n",
      "    num_steps_sampled: 1349460\n",
      "    num_steps_trained: 1349460\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.92737556561086\n",
      "    ram_util_percent: 45.233257918552034\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04981481475324113\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00183856255223\n",
      "    mean_inference_ms: 8.737625347944729\n",
      "    mean_raw_obs_processing_ms: 2.5683849082783103\n",
      "  time_since_restore: 41265.84335947037\n",
      "  time_this_iter_s: 309.5202829837799\n",
      "  time_total_s: 41265.84335947037\n",
      "  timers:\n",
      "    learn_throughput: 65.342\n",
      "    learn_time_ms: 152978.742\n",
      "    load_throughput: 87919.359\n",
      "    load_time_ms: 113.695\n",
      "    sample_throughput: 66.633\n",
      "    sample_time_ms: 150016.799\n",
      "    update_time_ms: 8.848\n",
      "  timestamp: 1636942004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1349460\n",
      "  training_iteration: 135\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         41265.8</td><td style=\"text-align: right;\">1349460</td><td style=\"text-align: right;\"> 2.47913</td><td style=\"text-align: right;\">               10.08</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           97.3592</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1359456\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-11-51\n",
      "  done: false\n",
      "  episode_len_mean: 98.66336633663366\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.840000000000016\n",
      "  episode_reward_mean: 2.316237623762382\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 13982\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6436784936831548\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016515959896868646\n",
      "          policy_loss: -0.05696920186846366\n",
      "          total_loss: 0.09437332079650308\n",
      "          vf_explained_var: 0.8419235348701477\n",
      "          vf_loss: 0.13545070975007983\n",
      "    num_agent_steps_sampled: 1359456\n",
      "    num_agent_steps_trained: 1359456\n",
      "    num_steps_sampled: 1359456\n",
      "    num_steps_trained: 1359456\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.11849315068491\n",
      "    ram_util_percent: 45.04223744292236\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0498085605556051\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.0004669857374\n",
      "    mean_inference_ms: 8.737599646197257\n",
      "    mean_raw_obs_processing_ms: 2.572836933598521\n",
      "  time_since_restore: 41572.771030426025\n",
      "  time_this_iter_s: 306.92767095565796\n",
      "  time_total_s: 41572.771030426025\n",
      "  timers:\n",
      "    learn_throughput: 65.339\n",
      "    learn_time_ms: 152986.141\n",
      "    load_throughput: 88597.619\n",
      "    load_time_ms: 112.825\n",
      "    sample_throughput: 66.588\n",
      "    sample_time_ms: 150117.133\n",
      "    update_time_ms: 8.727\n",
      "  timestamp: 1636942311\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1359456\n",
      "  training_iteration: 136\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         41572.8</td><td style=\"text-align: right;\">1359456</td><td style=\"text-align: right;\"> 2.31624</td><td style=\"text-align: right;\">               10.84</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           98.6634</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1369452\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-17-14\n",
      "  done: false\n",
      "  episode_len_mean: 97.28846153846153\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.670000000000014\n",
      "  episode_reward_mean: 2.6391346153846227\n",
      "  episode_reward_min: -1.8100000000000014\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 14086\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6433847593446065\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015786763480182008\n",
      "          policy_loss: -0.06069217091505853\n",
      "          total_loss: 0.0795315880053796\n",
      "          vf_explained_var: 0.8477365970611572\n",
      "          vf_loss: 0.12619785946499334\n",
      "    num_agent_steps_sampled: 1369452\n",
      "    num_agent_steps_trained: 1369452\n",
      "    num_steps_sampled: 1369452\n",
      "    num_steps_trained: 1369452\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.43934782608696\n",
      "    ram_util_percent: 45.01434782608696\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049811496708271515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.993164459293254\n",
      "    mean_inference_ms: 8.738217573953929\n",
      "    mean_raw_obs_processing_ms: 2.579740500989521\n",
      "  time_since_restore: 41895.61474061012\n",
      "  time_this_iter_s: 322.8437101840973\n",
      "  time_total_s: 41895.61474061012\n",
      "  timers:\n",
      "    learn_throughput: 65.357\n",
      "    learn_time_ms: 152943.672\n",
      "    load_throughput: 87227.787\n",
      "    load_time_ms: 114.597\n",
      "    sample_throughput: 65.454\n",
      "    sample_time_ms: 152716.863\n",
      "    update_time_ms: 9.749\n",
      "  timestamp: 1636942634\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1369452\n",
      "  training_iteration: 137\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         41895.6</td><td style=\"text-align: right;\">1369452</td><td style=\"text-align: right;\"> 2.63913</td><td style=\"text-align: right;\">               12.67</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           97.2885</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1379448\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-22-24\n",
      "  done: false\n",
      "  episode_len_mean: 97.68316831683168\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.850000000000014\n",
      "  episode_reward_mean: 2.400792079207928\n",
      "  episode_reward_min: -2.5299999999999967\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 14187\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.634322826577048\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01619134033535278\n",
      "          policy_loss: -0.06067008054775433\n",
      "          total_loss: 0.09525462332237353\n",
      "          vf_explained_var: 0.8336390852928162\n",
      "          vf_loss: 0.14077129922170414\n",
      "    num_agent_steps_sampled: 1379448\n",
      "    num_agent_steps_trained: 1379448\n",
      "    num_steps_sampled: 1379448\n",
      "    num_steps_trained: 1379448\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.11289592760181\n",
      "    ram_util_percent: 45.13642533936651\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049831426952910464\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.99405845553191\n",
      "    mean_inference_ms: 8.738582102101466\n",
      "    mean_raw_obs_processing_ms: 2.5786730701058915\n",
      "  time_since_restore: 42205.339945077896\n",
      "  time_this_iter_s: 309.72520446777344\n",
      "  time_total_s: 42205.339945077896\n",
      "  timers:\n",
      "    learn_throughput: 65.346\n",
      "    learn_time_ms: 152969.234\n",
      "    load_throughput: 87188.207\n",
      "    load_time_ms: 114.649\n",
      "    sample_throughput: 65.503\n",
      "    sample_time_ms: 152604.119\n",
      "    update_time_ms: 9.449\n",
      "  timestamp: 1636942944\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1379448\n",
      "  training_iteration: 138\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         42205.3</td><td style=\"text-align: right;\">1379448</td><td style=\"text-align: right;\"> 2.40079</td><td style=\"text-align: right;\">                8.85</td><td style=\"text-align: right;\">               -2.53</td><td style=\"text-align: right;\">           97.6832</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1389444\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-27-19\n",
      "  done: false\n",
      "  episode_len_mean: 100.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.330000000000013\n",
      "  episode_reward_mean: 2.988100000000008\n",
      "  episode_reward_min: -1.7500000000000009\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 14287\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6114696829746933\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018536299169466693\n",
      "          policy_loss: -0.05414630868591559\n",
      "          total_loss: 0.12755010642756062\n",
      "          vf_explained_var: 0.8577349781990051\n",
      "          vf_loss: 0.16030460601099408\n",
      "    num_agent_steps_sampled: 1389444\n",
      "    num_agent_steps_trained: 1389444\n",
      "    num_steps_sampled: 1389444\n",
      "    num_steps_trained: 1389444\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.32085308056871\n",
      "    ram_util_percent: 45.0824644549763\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0498537389100539\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.996391939740942\n",
      "    mean_inference_ms: 8.73936644195526\n",
      "    mean_raw_obs_processing_ms: 2.5638341342579305\n",
      "  time_since_restore: 42500.76642823219\n",
      "  time_this_iter_s: 295.4264831542969\n",
      "  time_total_s: 42500.76642823219\n",
      "  timers:\n",
      "    learn_throughput: 65.313\n",
      "    learn_time_ms: 153047.539\n",
      "    load_throughput: 87669.039\n",
      "    load_time_ms: 114.02\n",
      "    sample_throughput: 65.976\n",
      "    sample_time_ms: 151510.469\n",
      "    update_time_ms: 10.574\n",
      "  timestamp: 1636943239\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1389444\n",
      "  training_iteration: 139\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         42500.8</td><td style=\"text-align: right;\">1389444</td><td style=\"text-align: right;\">  2.9881</td><td style=\"text-align: right;\">               10.33</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">            100.23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1399440\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-32-28\n",
      "  done: false\n",
      "  episode_len_mean: 98.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.510000000000016\n",
      "  episode_reward_mean: 2.2027450980392214\n",
      "  episode_reward_min: -1.6700000000000006\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 14389\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.643448496272421\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016914277479628165\n",
      "          policy_loss: -0.06046926287265542\n",
      "          total_loss: 0.08528999078334269\n",
      "          vf_explained_var: 0.86700439453125\n",
      "          vf_loss: 0.12884429648765322\n",
      "    num_agent_steps_sampled: 1399440\n",
      "    num_agent_steps_trained: 1399440\n",
      "    num_steps_sampled: 1399440\n",
      "    num_steps_trained: 1399440\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.00045558086559\n",
      "    ram_util_percent: 45.102961275626434\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04983785801694932\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.99560515340437\n",
      "    mean_inference_ms: 8.739320139520784\n",
      "    mean_raw_obs_processing_ms: 2.5708588745153693\n",
      "  time_since_restore: 42808.82093477249\n",
      "  time_this_iter_s: 308.05450654029846\n",
      "  time_total_s: 42808.82093477249\n",
      "  timers:\n",
      "    learn_throughput: 65.311\n",
      "    learn_time_ms: 153051.419\n",
      "    load_throughput: 87757.488\n",
      "    load_time_ms: 113.905\n",
      "    sample_throughput: 65.596\n",
      "    sample_time_ms: 152386.767\n",
      "    update_time_ms: 10.626\n",
      "  timestamp: 1636943548\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1399440\n",
      "  training_iteration: 140\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         42808.8</td><td style=\"text-align: right;\">1399440</td><td style=\"text-align: right;\"> 2.20275</td><td style=\"text-align: right;\">               10.51</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">              98.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1409436\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-37-42\n",
      "  done: false\n",
      "  episode_len_mean: 98.30392156862744\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.710000000000013\n",
      "  episode_reward_mean: 2.3529411764705945\n",
      "  episode_reward_min: -1.5900000000000005\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 14491\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.638044575544504\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016372209362443865\n",
      "          policy_loss: -0.060495027879842074\n",
      "          total_loss: 0.0918713849503547\n",
      "          vf_explained_var: 0.8591356873512268\n",
      "          vf_loss: 0.13678667824516375\n",
      "    num_agent_steps_sampled: 1409436\n",
      "    num_agent_steps_trained: 1409436\n",
      "    num_steps_sampled: 1409436\n",
      "    num_steps_trained: 1409436\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.15812917594654\n",
      "    ram_util_percent: 45.03652561247216\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04984427560423947\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.001022524091674\n",
      "    mean_inference_ms: 8.739829767876076\n",
      "    mean_raw_obs_processing_ms: 2.5653692875501357\n",
      "  time_since_restore: 43123.18390083313\n",
      "  time_this_iter_s: 314.3629660606384\n",
      "  time_total_s: 43123.18390083313\n",
      "  timers:\n",
      "    learn_throughput: 65.306\n",
      "    learn_time_ms: 153065.045\n",
      "    load_throughput: 87424.753\n",
      "    load_time_ms: 114.338\n",
      "    sample_throughput: 65.328\n",
      "    sample_time_ms: 153011.393\n",
      "    update_time_ms: 10.832\n",
      "  timestamp: 1636943862\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1409436\n",
      "  training_iteration: 141\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         43123.2</td><td style=\"text-align: right;\">1409436</td><td style=\"text-align: right;\"> 2.35294</td><td style=\"text-align: right;\">                8.71</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           98.3039</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1419432\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-42-54\n",
      "  done: false\n",
      "  episode_len_mean: 97.92156862745098\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.490000000000018\n",
      "  episode_reward_mean: 2.1190196078431436\n",
      "  episode_reward_min: -2.0199999999999982\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 14593\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6488611731773766\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014764808897967939\n",
      "          policy_loss: -0.06362981705599997\n",
      "          total_loss: 0.07287089674351498\n",
      "          vf_explained_var: 0.8506547808647156\n",
      "          vf_loss: 0.1251487356546916\n",
      "    num_agent_steps_sampled: 1419432\n",
      "    num_agent_steps_trained: 1419432\n",
      "    num_steps_sampled: 1419432\n",
      "    num_steps_trained: 1419432\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.22876404494383\n",
      "    ram_util_percent: 45.28134831460674\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04985778561094613\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.004257753479365\n",
      "    mean_inference_ms: 8.740789669730043\n",
      "    mean_raw_obs_processing_ms: 2.560527425324953\n",
      "  time_since_restore: 43435.22076153755\n",
      "  time_this_iter_s: 312.036860704422\n",
      "  time_total_s: 43435.22076153755\n",
      "  timers:\n",
      "    learn_throughput: 65.292\n",
      "    learn_time_ms: 153096.469\n",
      "    load_throughput: 86586.709\n",
      "    load_time_ms: 115.445\n",
      "    sample_throughput: 64.595\n",
      "    sample_time_ms: 154749.66\n",
      "    update_time_ms: 10.789\n",
      "  timestamp: 1636944174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1419432\n",
      "  training_iteration: 142\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         43435.2</td><td style=\"text-align: right;\">1419432</td><td style=\"text-align: right;\"> 2.11902</td><td style=\"text-align: right;\">               10.49</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           97.9216</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1429428\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-48-09\n",
      "  done: false\n",
      "  episode_len_mean: 97.42718446601941\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.570000000000016\n",
      "  episode_reward_mean: 1.9612621359223352\n",
      "  episode_reward_min: -1.970000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 14696\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6445695796583455\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016428527520784306\n",
      "          policy_loss: -0.05893449045749556\n",
      "          total_loss: 0.08804027946809163\n",
      "          vf_explained_var: 0.8202545046806335\n",
      "          vf_loss: 0.13131594744104988\n",
      "    num_agent_steps_sampled: 1429428\n",
      "    num_agent_steps_trained: 1429428\n",
      "    num_steps_sampled: 1429428\n",
      "    num_steps_trained: 1429428\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.06703786191538\n",
      "    ram_util_percent: 45.152561247216035\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04987301222078504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01313620577724\n",
      "    mean_inference_ms: 8.740553761063499\n",
      "    mean_raw_obs_processing_ms: 2.5659623188865863\n",
      "  time_since_restore: 43749.93318128586\n",
      "  time_this_iter_s: 314.7124197483063\n",
      "  time_total_s: 43749.93318128586\n",
      "  timers:\n",
      "    learn_throughput: 65.308\n",
      "    learn_time_ms: 153060.234\n",
      "    load_throughput: 86835.984\n",
      "    load_time_ms: 115.114\n",
      "    sample_throughput: 64.285\n",
      "    sample_time_ms: 155494.697\n",
      "    update_time_ms: 10.751\n",
      "  timestamp: 1636944489\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1429428\n",
      "  training_iteration: 143\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         43749.9</td><td style=\"text-align: right;\">1429428</td><td style=\"text-align: right;\"> 1.96126</td><td style=\"text-align: right;\">                8.57</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           97.4272</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1439424\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-53-22\n",
      "  done: false\n",
      "  episode_len_mean: 98.1470588235294\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.790000000000019\n",
      "  episode_reward_mean: 2.754117647058831\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 14798\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.638786750165825\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016345783924156154\n",
      "          policy_loss: -0.05594563520131394\n",
      "          total_loss: 0.11456069933632627\n",
      "          vf_explained_var: 0.8249602913856506\n",
      "          vf_loss: 0.1550017465546759\n",
      "    num_agent_steps_sampled: 1439424\n",
      "    num_agent_steps_trained: 1439424\n",
      "    num_steps_sampled: 1439424\n",
      "    num_steps_trained: 1439424\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.12975391498881\n",
      "    ram_util_percent: 44.680984340044745\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049858710619195626\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01749995514589\n",
      "    mean_inference_ms: 8.740473154629868\n",
      "    mean_raw_obs_processing_ms: 2.567646356146825\n",
      "  time_since_restore: 44063.19525241852\n",
      "  time_this_iter_s: 313.2620711326599\n",
      "  time_total_s: 44063.19525241852\n",
      "  timers:\n",
      "    learn_throughput: 65.277\n",
      "    learn_time_ms: 153132.41\n",
      "    load_throughput: 87489.663\n",
      "    load_time_ms: 114.253\n",
      "    sample_throughput: 63.501\n",
      "    sample_time_ms: 157415.224\n",
      "    update_time_ms: 10.527\n",
      "  timestamp: 1636944802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1439424\n",
      "  training_iteration: 144\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         44063.2</td><td style=\"text-align: right;\">1439424</td><td style=\"text-align: right;\"> 2.75412</td><td style=\"text-align: right;\">               14.79</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           98.1471</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1449420\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_02-58-28\n",
      "  done: false\n",
      "  episode_len_mean: 98.67326732673267\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.310000000000016\n",
      "  episode_reward_mean: 2.604455445544562\n",
      "  episode_reward_min: -1.9100000000000008\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 14899\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.644463712741167\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016164827612134103\n",
      "          policy_loss: -0.0600340135793528\n",
      "          total_loss: 0.09261246295009032\n",
      "          vf_explained_var: 0.8611262440681458\n",
      "          vf_loss: 0.13766242982182875\n",
      "    num_agent_steps_sampled: 1449420\n",
      "    num_agent_steps_trained: 1449420\n",
      "    num_steps_sampled: 1449420\n",
      "    num_steps_trained: 1449420\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.93729977116705\n",
      "    ram_util_percent: 44.77391304347825\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049869071876052225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.011937202458846\n",
      "    mean_inference_ms: 8.74145259959384\n",
      "    mean_raw_obs_processing_ms: 2.5617036226508545\n",
      "  time_since_restore: 44369.357642650604\n",
      "  time_this_iter_s: 306.1623902320862\n",
      "  time_total_s: 44369.357642650604\n",
      "  timers:\n",
      "    learn_throughput: 65.301\n",
      "    learn_time_ms: 153074.873\n",
      "    load_throughput: 87867.95\n",
      "    load_time_ms: 113.762\n",
      "    sample_throughput: 63.613\n",
      "    sample_time_ms: 157137.801\n",
      "    update_time_ms: 10.271\n",
      "  timestamp: 1636945108\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1449420\n",
      "  training_iteration: 145\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         44369.4</td><td style=\"text-align: right;\">1449420</td><td style=\"text-align: right;\"> 2.60446</td><td style=\"text-align: right;\">               10.31</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           98.6733</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1459416\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-03-25\n",
      "  done: false\n",
      "  episode_len_mean: 97.06862745098039\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.390000000000017\n",
      "  episode_reward_mean: 2.277549019607849\n",
      "  episode_reward_min: -1.9700000000000009\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 15001\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6517691931153973\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01571332213451934\n",
      "          policy_loss: -0.06043560990474672\n",
      "          total_loss: 0.08543580148576034\n",
      "          vf_explained_var: 0.8269369006156921\n",
      "          vf_loss: 0.13211757791363912\n",
      "    num_agent_steps_sampled: 1459416\n",
      "    num_agent_steps_trained: 1459416\n",
      "    num_steps_sampled: 1459416\n",
      "    num_steps_trained: 1459416\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.39243498817967\n",
      "    ram_util_percent: 44.7855791962175\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986925090991769\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.015788955872445\n",
      "    mean_inference_ms: 8.742251842405269\n",
      "    mean_raw_obs_processing_ms: 2.5505708781429832\n",
      "  time_since_restore: 44665.623596429825\n",
      "  time_this_iter_s: 296.2659537792206\n",
      "  time_total_s: 44665.623596429825\n",
      "  timers:\n",
      "    learn_throughput: 65.269\n",
      "    learn_time_ms: 153151.424\n",
      "    load_throughput: 87222.888\n",
      "    load_time_ms: 114.603\n",
      "    sample_throughput: 64.079\n",
      "    sample_time_ms: 155994.19\n",
      "    update_time_ms: 10.211\n",
      "  timestamp: 1636945405\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1459416\n",
      "  training_iteration: 146\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         44665.6</td><td style=\"text-align: right;\">1459416</td><td style=\"text-align: right;\"> 2.27755</td><td style=\"text-align: right;\">               12.39</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           97.0686</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1469412\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-08-35\n",
      "  done: false\n",
      "  episode_len_mean: 98.28155339805825\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.29000000000002\n",
      "  episode_reward_mean: 2.2136893203883554\n",
      "  episode_reward_min: -2.0300000000000002\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 15104\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.666310532989665\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015359766896013377\n",
      "          policy_loss: -0.059973696179879014\n",
      "          total_loss: 0.07995316905375474\n",
      "          vf_explained_var: 0.8252037763595581\n",
      "          vf_loss: 0.1272245686310224\n",
      "    num_agent_steps_sampled: 1469412\n",
      "    num_agent_steps_trained: 1469412\n",
      "    num_steps_sampled: 1469412\n",
      "    num_steps_trained: 1469412\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.17013574660633\n",
      "    ram_util_percent: 45.16628959276018\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049874483931967424\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01504178238348\n",
      "    mean_inference_ms: 8.742721370160421\n",
      "    mean_raw_obs_processing_ms: 2.551509470535776\n",
      "  time_since_restore: 44975.821580171585\n",
      "  time_this_iter_s: 310.19798374176025\n",
      "  time_total_s: 44975.821580171585\n",
      "  timers:\n",
      "    learn_throughput: 65.241\n",
      "    learn_time_ms: 153217.389\n",
      "    load_throughput: 87158.88\n",
      "    load_time_ms: 114.687\n",
      "    sample_throughput: 64.63\n",
      "    sample_time_ms: 154663.934\n",
      "    update_time_ms: 9.525\n",
      "  timestamp: 1636945715\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1469412\n",
      "  training_iteration: 147\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         44975.8</td><td style=\"text-align: right;\">1469412</td><td style=\"text-align: right;\"> 2.21369</td><td style=\"text-align: right;\">                8.29</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">           98.2816</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1479408\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-13-48\n",
      "  done: false\n",
      "  episode_len_mean: 95.18446601941747\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.45000000000002\n",
      "  episode_reward_mean: 2.244951456310685\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 15207\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6478657573716253\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01772684030814817\n",
      "          policy_loss: -0.0555005941245482\n",
      "          total_loss: 0.09787127552434612\n",
      "          vf_explained_var: 0.8425770998001099\n",
      "          vf_loss: 0.1344185762449653\n",
      "    num_agent_steps_sampled: 1479408\n",
      "    num_agent_steps_trained: 1479408\n",
      "    num_steps_sampled: 1479408\n",
      "    num_steps_trained: 1479408\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.1145413870246\n",
      "    ram_util_percent: 45.017225950783\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986538596228058\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02782443684884\n",
      "    mean_inference_ms: 8.74283919187905\n",
      "    mean_raw_obs_processing_ms: 2.550551007863024\n",
      "  time_since_restore: 45288.88607335091\n",
      "  time_this_iter_s: 313.0644931793213\n",
      "  time_total_s: 45288.88607335091\n",
      "  timers:\n",
      "    learn_throughput: 65.279\n",
      "    learn_time_ms: 153126.391\n",
      "    load_throughput: 87417.772\n",
      "    load_time_ms: 114.347\n",
      "    sample_throughput: 64.453\n",
      "    sample_time_ms: 155088.918\n",
      "    update_time_ms: 9.833\n",
      "  timestamp: 1636946028\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1479408\n",
      "  training_iteration: 148\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         45288.9</td><td style=\"text-align: right;\">1479408</td><td style=\"text-align: right;\"> 2.24495</td><td style=\"text-align: right;\">               12.45</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           95.1845</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1489404\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-18-58\n",
      "  done: false\n",
      "  episode_len_mean: 99.24509803921569\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.670000000000014\n",
      "  episode_reward_mean: 1.7242156862745144\n",
      "  episode_reward_min: -1.9700000000000015\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 15309\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6680099297792483\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01372749997287528\n",
      "          policy_loss: -0.060835595334617375\n",
      "          total_loss: 0.06291287905023171\n",
      "          vf_explained_var: 0.8275153636932373\n",
      "          vf_loss: 0.115246493765352\n",
      "    num_agent_steps_sampled: 1489404\n",
      "    num_agent_steps_trained: 1489404\n",
      "    num_steps_sampled: 1489404\n",
      "    num_steps_trained: 1489404\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.21312217194571\n",
      "    ram_util_percent: 45.171266968325796\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986542765762545\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02644000835571\n",
      "    mean_inference_ms: 8.743416587373472\n",
      "    mean_raw_obs_processing_ms: 2.548138591436214\n",
      "  time_since_restore: 45598.46043109894\n",
      "  time_this_iter_s: 309.5743577480316\n",
      "  time_total_s: 45598.46043109894\n",
      "  timers:\n",
      "    learn_throughput: 65.261\n",
      "    learn_time_ms: 153169.448\n",
      "    load_throughput: 87433.395\n",
      "    load_time_ms: 114.327\n",
      "    sample_throughput: 63.888\n",
      "    sample_time_ms: 156461.099\n",
      "    update_time_ms: 9.198\n",
      "  timestamp: 1636946338\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1489404\n",
      "  training_iteration: 149\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         45598.5</td><td style=\"text-align: right;\">1489404</td><td style=\"text-align: right;\"> 1.72422</td><td style=\"text-align: right;\">                6.67</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           99.2451</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1499400\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-24-07\n",
      "  done: false\n",
      "  episode_len_mean: 98.32352941176471\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.060000000000015\n",
      "  episode_reward_mean: 2.3709803921568695\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 15411\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.647897693540296\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017346735539677558\n",
      "          policy_loss: -0.055328630198302683\n",
      "          total_loss: 0.10827566676765171\n",
      "          vf_explained_var: 0.8409123420715332\n",
      "          vf_loss: 0.14562548926084215\n",
      "    num_agent_steps_sampled: 1499400\n",
      "    num_agent_steps_trained: 1499400\n",
      "    num_steps_sampled: 1499400\n",
      "    num_steps_trained: 1499400\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.11632653061226\n",
      "    ram_util_percent: 45.22086167800453\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986345017576285\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02754757062799\n",
      "    mean_inference_ms: 8.743302376503676\n",
      "    mean_raw_obs_processing_ms: 2.5514139659263955\n",
      "  time_since_restore: 45907.434089660645\n",
      "  time_this_iter_s: 308.97365856170654\n",
      "  time_total_s: 45907.434089660645\n",
      "  timers:\n",
      "    learn_throughput: 65.272\n",
      "    learn_time_ms: 153144.148\n",
      "    load_throughput: 87020.814\n",
      "    load_time_ms: 114.869\n",
      "    sample_throughput: 63.841\n",
      "    sample_time_ms: 156577.404\n",
      "    update_time_ms: 9.404\n",
      "  timestamp: 1636946647\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1499400\n",
      "  training_iteration: 150\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         45907.4</td><td style=\"text-align: right;\">1499400</td><td style=\"text-align: right;\"> 2.37098</td><td style=\"text-align: right;\">               11.06</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           98.3235</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1509396\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-29-19\n",
      "  done: false\n",
      "  episode_len_mean: 96.62135922330097\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.910000000000014\n",
      "  episode_reward_mean: 2.5686407766990365\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 15514\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.648266530342591\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015940994939286385\n",
      "          policy_loss: -0.055783658735573484\n",
      "          total_loss: 0.11634699366747951\n",
      "          vf_explained_var: 0.8546465039253235\n",
      "          vf_loss: 0.1577582923297444\n",
      "    num_agent_steps_sampled: 1509396\n",
      "    num_agent_steps_trained: 1509396\n",
      "    num_steps_sampled: 1509396\n",
      "    num_steps_trained: 1509396\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.04977578475335\n",
      "    ram_util_percent: 45.0609865470852\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986054801301931\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.03351146482423\n",
      "    mean_inference_ms: 8.743855641381064\n",
      "    mean_raw_obs_processing_ms: 2.543250728564787\n",
      "  time_since_restore: 46220.290707588196\n",
      "  time_this_iter_s: 312.85661792755127\n",
      "  time_total_s: 46220.290707588196\n",
      "  timers:\n",
      "    learn_throughput: 65.252\n",
      "    learn_time_ms: 153191.611\n",
      "    load_throughput: 87277.74\n",
      "    load_time_ms: 114.531\n",
      "    sample_throughput: 63.922\n",
      "    sample_time_ms: 156378.041\n",
      "    update_time_ms: 10.471\n",
      "  timestamp: 1636946959\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1509396\n",
      "  training_iteration: 151\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         46220.3</td><td style=\"text-align: right;\">1509396</td><td style=\"text-align: right;\"> 2.56864</td><td style=\"text-align: right;\">               10.91</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           96.6214</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1519392\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-34-30\n",
      "  done: false\n",
      "  episode_len_mean: 98.41584158415841\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.000000000000021\n",
      "  episode_reward_mean: 2.2440594059406\n",
      "  episode_reward_min: -1.9700000000000004\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 15615\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.666720413346576\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015412557655425891\n",
      "          policy_loss: -0.05664537956094385\n",
      "          total_loss: 0.08537610845369661\n",
      "          vf_explained_var: 0.8296871185302734\n",
      "          vf_loss: 0.1291879940005895\n",
      "    num_agent_steps_sampled: 1519392\n",
      "    num_agent_steps_trained: 1519392\n",
      "    num_steps_sampled: 1519392\n",
      "    num_steps_trained: 1519392\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.00067720090294\n",
      "    ram_util_percent: 45.02392776523702\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049857927083114345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.032430834094406\n",
      "    mean_inference_ms: 8.744024852961479\n",
      "    mean_raw_obs_processing_ms: 2.5483207342681427\n",
      "  time_since_restore: 46531.07070565224\n",
      "  time_this_iter_s: 310.77999806404114\n",
      "  time_total_s: 46531.07070565224\n",
      "  timers:\n",
      "    learn_throughput: 65.253\n",
      "    learn_time_ms: 153189.135\n",
      "    load_throughput: 87487.4\n",
      "    load_time_ms: 114.256\n",
      "    sample_throughput: 63.972\n",
      "    sample_time_ms: 156255.611\n",
      "    update_time_ms: 9.682\n",
      "  timestamp: 1636947270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1519392\n",
      "  training_iteration: 152\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         46531.1</td><td style=\"text-align: right;\">1519392</td><td style=\"text-align: right;\"> 2.24406</td><td style=\"text-align: right;\">                  12</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           98.4158</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1529388\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-39-27\n",
      "  done: false\n",
      "  episode_len_mean: 98.17647058823529\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.580000000000013\n",
      "  episode_reward_mean: 2.1350980392156926\n",
      "  episode_reward_min: -2.489999999999999\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 15717\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6701439398985642\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01582845046979009\n",
      "          policy_loss: -0.055637894948530525\n",
      "          total_loss: 0.09180078469614825\n",
      "          vf_explained_var: 0.8443768620491028\n",
      "          vf_loss: 0.13357353215145631\n",
      "    num_agent_steps_sampled: 1529388\n",
      "    num_agent_steps_trained: 1529388\n",
      "    num_steps_sampled: 1529388\n",
      "    num_steps_trained: 1529388\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.5004716981132\n",
      "    ram_util_percent: 45.04669811320755\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0498660867048686\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.03759088262358\n",
      "    mean_inference_ms: 8.745478731387744\n",
      "    mean_raw_obs_processing_ms: 2.529834845207591\n",
      "  time_since_restore: 46828.28659105301\n",
      "  time_this_iter_s: 297.2158854007721\n",
      "  time_total_s: 46828.28659105301\n",
      "  timers:\n",
      "    learn_throughput: 65.24\n",
      "    learn_time_ms: 153220.047\n",
      "    load_throughput: 87487.728\n",
      "    load_time_ms: 114.256\n",
      "    sample_throughput: 64.71\n",
      "    sample_time_ms: 154474.735\n",
      "    update_time_ms: 10.124\n",
      "  timestamp: 1636947567\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1529388\n",
      "  training_iteration: 153\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         46828.3</td><td style=\"text-align: right;\">1529388</td><td style=\"text-align: right;\">  2.1351</td><td style=\"text-align: right;\">                8.58</td><td style=\"text-align: right;\">               -2.49</td><td style=\"text-align: right;\">           98.1765</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1539384\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-44-54\n",
      "  done: false\n",
      "  episode_len_mean: 95.625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.150000000000018\n",
      "  episode_reward_mean: 2.2299038461538516\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 15821\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.67065138725134\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016083413886862602\n",
      "          policy_loss: -0.054729240413946216\n",
      "          total_loss: 0.10139423697156051\n",
      "          vf_explained_var: 0.8547482490539551\n",
      "          vf_loss: 0.1416099614575187\n",
      "    num_agent_steps_sampled: 1539384\n",
      "    num_agent_steps_trained: 1539384\n",
      "    num_steps_sampled: 1539384\n",
      "    num_steps_trained: 1539384\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.29442060085836\n",
      "    ram_util_percent: 45.294206008583686\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04985461850311908\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.03994081460736\n",
      "    mean_inference_ms: 8.745081150360873\n",
      "    mean_raw_obs_processing_ms: 2.547262113018002\n",
      "  time_since_restore: 47154.689865112305\n",
      "  time_this_iter_s: 326.40327405929565\n",
      "  time_total_s: 47154.689865112305\n",
      "  timers:\n",
      "    learn_throughput: 65.228\n",
      "    learn_time_ms: 153246.438\n",
      "    load_throughput: 87079.717\n",
      "    load_time_ms: 114.791\n",
      "    sample_throughput: 64.175\n",
      "    sample_time_ms: 155762.021\n",
      "    update_time_ms: 10.205\n",
      "  timestamp: 1636947894\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1539384\n",
      "  training_iteration: 154\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         47154.7</td><td style=\"text-align: right;\">1539384</td><td style=\"text-align: right;\">  2.2299</td><td style=\"text-align: right;\">               10.15</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">            95.625</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1549380\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-49-55\n",
      "  done: false\n",
      "  episode_len_mean: 97.40384615384616\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.22000000000002\n",
      "  episode_reward_mean: 1.9691346153846205\n",
      "  episode_reward_min: -2.0100000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 15925\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6717346327936546\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01557255666392614\n",
      "          policy_loss: -0.052734150897520475\n",
      "          total_loss: 0.10457998621675513\n",
      "          vf_explained_var: 0.8180750012397766\n",
      "          vf_loss: 0.14412072443634144\n",
      "    num_agent_steps_sampled: 1549380\n",
      "    num_agent_steps_trained: 1549380\n",
      "    num_steps_sampled: 1549380\n",
      "    num_steps_trained: 1549380\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.57186046511629\n",
      "    ram_util_percent: 45.17255813953489\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04986339476801908\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.051405094525556\n",
      "    mean_inference_ms: 8.746200067323468\n",
      "    mean_raw_obs_processing_ms: 2.531508750160959\n",
      "  time_since_restore: 47455.99790978432\n",
      "  time_this_iter_s: 301.30804467201233\n",
      "  time_total_s: 47455.99790978432\n",
      "  timers:\n",
      "    learn_throughput: 65.215\n",
      "    learn_time_ms: 153278.002\n",
      "    load_throughput: 87303.911\n",
      "    load_time_ms: 114.497\n",
      "    sample_throughput: 64.389\n",
      "    sample_time_ms: 155244.033\n",
      "    update_time_ms: 11.133\n",
      "  timestamp: 1636948195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1549380\n",
      "  training_iteration: 155\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">           47456</td><td style=\"text-align: right;\">1549380</td><td style=\"text-align: right;\"> 1.96913</td><td style=\"text-align: right;\">               10.22</td><td style=\"text-align: right;\">               -2.01</td><td style=\"text-align: right;\">           97.4038</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1559376\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_03-55-06\n",
      "  done: false\n",
      "  episode_len_mean: 96.59223300970874\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.45000000000002\n",
      "  episode_reward_mean: 2.406213592233015\n",
      "  episode_reward_min: -1.7500000000000009\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 16028\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6633143810125497\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017918075306459297\n",
      "          policy_loss: -0.05015773027259697\n",
      "          total_loss: 0.10925060703387308\n",
      "          vf_explained_var: 0.8044214248657227\n",
      "          vf_loss: 0.1401194142185661\n",
      "    num_agent_steps_sampled: 1559376\n",
      "    num_agent_steps_trained: 1559376\n",
      "    num_steps_sampled: 1559376\n",
      "    num_steps_trained: 1559376\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.11286681715576\n",
      "    ram_util_percent: 45.207674943566595\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04987186863587547\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.0538218113745\n",
      "    mean_inference_ms: 8.7468126981373\n",
      "    mean_raw_obs_processing_ms: 2.530270824054644\n",
      "  time_since_restore: 47766.29452419281\n",
      "  time_this_iter_s: 310.29661440849304\n",
      "  time_total_s: 47766.29452419281\n",
      "  timers:\n",
      "    learn_throughput: 65.238\n",
      "    learn_time_ms: 153224.35\n",
      "    load_throughput: 87404.14\n",
      "    load_time_ms: 114.365\n",
      "    sample_throughput: 63.79\n",
      "    sample_time_ms: 156700.913\n",
      "    update_time_ms: 11.092\n",
      "  timestamp: 1636948506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1559376\n",
      "  training_iteration: 156\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         47766.3</td><td style=\"text-align: right;\">1559376</td><td style=\"text-align: right;\"> 2.40621</td><td style=\"text-align: right;\">               10.45</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           96.5922</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1569372\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-00-15\n",
      "  done: false\n",
      "  episode_len_mean: 96.33980582524272\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.690000000000015\n",
      "  episode_reward_mean: 2.0504854368932097\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 16131\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6707994643439594\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01524271862977992\n",
      "          policy_loss: -0.05227227007341372\n",
      "          total_loss: 0.09828401076344725\n",
      "          vf_explained_var: 0.8170406222343445\n",
      "          vf_loss: 0.1381988562977849\n",
      "    num_agent_steps_sampled: 1569372\n",
      "    num_agent_steps_trained: 1569372\n",
      "    num_steps_sampled: 1569372\n",
      "    num_steps_trained: 1569372\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.08956916099773\n",
      "    ram_util_percent: 45.34353741496598\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04984762372726218\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.05827139634196\n",
      "    mean_inference_ms: 8.746169441176155\n",
      "    mean_raw_obs_processing_ms: 2.5382771142541727\n",
      "  time_since_restore: 48075.74350190163\n",
      "  time_this_iter_s: 309.4489777088165\n",
      "  time_total_s: 48075.74350190163\n",
      "  timers:\n",
      "    learn_throughput: 65.239\n",
      "    learn_time_ms: 153220.654\n",
      "    load_throughput: 88222.225\n",
      "    load_time_ms: 113.305\n",
      "    sample_throughput: 63.819\n",
      "    sample_time_ms: 156631.664\n",
      "    update_time_ms: 10.795\n",
      "  timestamp: 1636948815\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1569372\n",
      "  training_iteration: 157\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         48075.7</td><td style=\"text-align: right;\">1569372</td><td style=\"text-align: right;\"> 2.05049</td><td style=\"text-align: right;\">               10.69</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           96.3398</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1579368\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-05-29\n",
      "  done: false\n",
      "  episode_len_mean: 95.47169811320755\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.590000000000018\n",
      "  episode_reward_mean: 1.9729245283018921\n",
      "  episode_reward_min: -2.0900000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 16237\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6773483406784186\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014241977035159316\n",
      "          policy_loss: -0.053444093183622275\n",
      "          total_loss: 0.06989882150664925\n",
      "          vf_explained_var: 0.8371768593788147\n",
      "          vf_loss: 0.11361576988138895\n",
      "    num_agent_steps_sampled: 1579368\n",
      "    num_agent_steps_trained: 1579368\n",
      "    num_steps_sampled: 1579368\n",
      "    num_steps_trained: 1579368\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.93051224944321\n",
      "    ram_util_percent: 45.13273942093541\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049860408929157315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.063359746627704\n",
      "    mean_inference_ms: 8.74698548610486\n",
      "    mean_raw_obs_processing_ms: 2.534051098446331\n",
      "  time_since_restore: 48389.93512225151\n",
      "  time_this_iter_s: 314.19162034988403\n",
      "  time_total_s: 48389.93512225151\n",
      "  timers:\n",
      "    learn_throughput: 65.227\n",
      "    learn_time_ms: 153250.573\n",
      "    load_throughput: 87946.303\n",
      "    load_time_ms: 113.66\n",
      "    sample_throughput: 63.785\n",
      "    sample_time_ms: 156714.029\n",
      "    update_time_ms: 10.839\n",
      "  timestamp: 1636949129\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1579368\n",
      "  training_iteration: 158\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         48389.9</td><td style=\"text-align: right;\">1579368</td><td style=\"text-align: right;\"> 1.97292</td><td style=\"text-align: right;\">                8.59</td><td style=\"text-align: right;\">               -2.09</td><td style=\"text-align: right;\">           95.4717</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1589364\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-10-39\n",
      "  done: false\n",
      "  episode_len_mean: 98.53465346534654\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.190000000000017\n",
      "  episode_reward_mean: 1.7317821782178269\n",
      "  episode_reward_min: -2.339999999999998\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 16338\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6777695166759004\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017859044554798063\n",
      "          policy_loss: -0.04990654591606277\n",
      "          total_loss: 0.11539947394536347\n",
      "          vf_explained_var: 0.8255412578582764\n",
      "          vf_loss: 0.14631293802084322\n",
      "    num_agent_steps_sampled: 1589364\n",
      "    num_agent_steps_trained: 1589364\n",
      "    num_steps_sampled: 1589364\n",
      "    num_steps_trained: 1589364\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.00068027210885\n",
      "    ram_util_percent: 45.24195011337868\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04983756910889407\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.06601916075561\n",
      "    mean_inference_ms: 8.746529954523304\n",
      "    mean_raw_obs_processing_ms: 2.5346161597750574\n",
      "  time_since_restore: 48699.152114868164\n",
      "  time_this_iter_s: 309.21699261665344\n",
      "  time_total_s: 48699.152114868164\n",
      "  timers:\n",
      "    learn_throughput: 65.22\n",
      "    learn_time_ms: 153265.272\n",
      "    load_throughput: 88103.317\n",
      "    load_time_ms: 113.458\n",
      "    sample_throughput: 63.805\n",
      "    sample_time_ms: 156664.06\n",
      "    update_time_ms: 10.848\n",
      "  timestamp: 1636949439\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1589364\n",
      "  training_iteration: 159\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         48699.2</td><td style=\"text-align: right;\">1589364</td><td style=\"text-align: right;\"> 1.73178</td><td style=\"text-align: right;\">               10.19</td><td style=\"text-align: right;\">               -2.34</td><td style=\"text-align: right;\">           98.5347</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1599360\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-15-56\n",
      "  done: false\n",
      "  episode_len_mean: 94.79047619047618\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.92000000000002\n",
      "  episode_reward_mean: 2.528000000000006\n",
      "  episode_reward_min: -1.8100000000000012\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 16443\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6633424263734082\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017729444599963368\n",
      "          policy_loss: -0.04914713422210616\n",
      "          total_loss: 0.11045354447649935\n",
      "          vf_explained_var: 0.8626063466072083\n",
      "          vf_loss: 0.14079547602977827\n",
      "    num_agent_steps_sampled: 1599360\n",
      "    num_agent_steps_trained: 1599360\n",
      "    num_steps_sampled: 1599360\n",
      "    num_steps_trained: 1599360\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.66747787610619\n",
      "    ram_util_percent: 44.895796460176996\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049881681204505854\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.06987575715398\n",
      "    mean_inference_ms: 8.747458668190072\n",
      "    mean_raw_obs_processing_ms: 2.5362116387155975\n",
      "  time_since_restore: 49016.33486318588\n",
      "  time_this_iter_s: 317.1827483177185\n",
      "  time_total_s: 49016.33486318588\n",
      "  timers:\n",
      "    learn_throughput: 65.209\n",
      "    learn_time_ms: 153291.255\n",
      "    load_throughput: 88537.935\n",
      "    load_time_ms: 112.901\n",
      "    sample_throughput: 63.483\n",
      "    sample_time_ms: 157460.337\n",
      "    update_time_ms: 10.478\n",
      "  timestamp: 1636949756\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1599360\n",
      "  training_iteration: 160\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         49016.3</td><td style=\"text-align: right;\">1599360</td><td style=\"text-align: right;\">   2.528</td><td style=\"text-align: right;\">               10.92</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           94.7905</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1609356\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-21-10\n",
      "  done: false\n",
      "  episode_len_mean: 96.28571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.100000000000016\n",
      "  episode_reward_mean: 2.614476190476197\n",
      "  episode_reward_min: -1.970000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 16548\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.657772961946634\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01745099114832472\n",
      "          policy_loss: -0.0448894127110879\n",
      "          total_loss: 0.15774467844977721\n",
      "          vf_explained_var: 0.8207930326461792\n",
      "          vf_loss: 0.18448684034813354\n",
      "    num_agent_steps_sampled: 1609356\n",
      "    num_agent_steps_trained: 1609356\n",
      "    num_steps_sampled: 1609356\n",
      "    num_steps_trained: 1609356\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.61450892857144\n",
      "    ram_util_percent: 45.15513392857143\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049859058766222084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.07579689660021\n",
      "    mean_inference_ms: 8.747540746978384\n",
      "    mean_raw_obs_processing_ms: 2.542571792317519\n",
      "  time_since_restore: 49330.22968673706\n",
      "  time_this_iter_s: 313.894823551178\n",
      "  time_total_s: 49330.22968673706\n",
      "  timers:\n",
      "    learn_throughput: 65.219\n",
      "    learn_time_ms: 153269.314\n",
      "    load_throughput: 89057.131\n",
      "    load_time_ms: 112.243\n",
      "    sample_throughput: 63.431\n",
      "    sample_time_ms: 157587.58\n",
      "    update_time_ms: 9.876\n",
      "  timestamp: 1636950070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1609356\n",
      "  training_iteration: 161\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         49330.2</td><td style=\"text-align: right;\">1609356</td><td style=\"text-align: right;\"> 2.61448</td><td style=\"text-align: right;\">                 9.1</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           96.2857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1619352\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-26-07\n",
      "  done: false\n",
      "  episode_len_mean: 97.9009900990099\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.110000000000017\n",
      "  episode_reward_mean: 1.8228712871287183\n",
      "  episode_reward_min: -2.1399999999999983\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 16649\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6843418926255316\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01522420576215756\n",
      "          policy_loss: -0.047472270148304796\n",
      "          total_loss: 0.11091215377633706\n",
      "          vf_explained_var: 0.8391638994216919\n",
      "          vf_loss: 0.146209868723447\n",
      "    num_agent_steps_sampled: 1619352\n",
      "    num_agent_steps_trained: 1619352\n",
      "    num_steps_sampled: 1619352\n",
      "    num_steps_trained: 1619352\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.43372641509436\n",
      "    ram_util_percent: 45.068396226415096\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04988845475350262\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.07505970981387\n",
      "    mean_inference_ms: 8.74837892581431\n",
      "    mean_raw_obs_processing_ms: 2.5303795779080764\n",
      "  time_since_restore: 49627.137662649155\n",
      "  time_this_iter_s: 296.9079759120941\n",
      "  time_total_s: 49627.137662649155\n",
      "  timers:\n",
      "    learn_throughput: 65.207\n",
      "    learn_time_ms: 153296.841\n",
      "    load_throughput: 89287.225\n",
      "    load_time_ms: 111.953\n",
      "    sample_throughput: 64.006\n",
      "    sample_time_ms: 156173.169\n",
      "    update_time_ms: 10.212\n",
      "  timestamp: 1636950367\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1619352\n",
      "  training_iteration: 162\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         49627.1</td><td style=\"text-align: right;\">1619352</td><td style=\"text-align: right;\"> 1.82287</td><td style=\"text-align: right;\">                8.11</td><td style=\"text-align: right;\">               -2.14</td><td style=\"text-align: right;\">            97.901</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1629348\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-31-18\n",
      "  done: false\n",
      "  episode_len_mean: 97.2621359223301\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.630000000000015\n",
      "  episode_reward_mean: 2.6081553398058324\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 16752\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6700237523796213\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015479973900780273\n",
      "          policy_loss: -0.05023588055474126\n",
      "          total_loss: 0.09365462246072344\n",
      "          vf_explained_var: 0.8695287704467773\n",
      "          vf_loss: 0.13091726150188562\n",
      "    num_agent_steps_sampled: 1629348\n",
      "    num_agent_steps_trained: 1629348\n",
      "    num_steps_sampled: 1629348\n",
      "    num_steps_trained: 1629348\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19076576576578\n",
      "    ram_util_percent: 45.26463963963964\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04989038836890508\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.078824693899165\n",
      "    mean_inference_ms: 8.748510653286429\n",
      "    mean_raw_obs_processing_ms: 2.528526415915707\n",
      "  time_since_restore: 49938.451382637024\n",
      "  time_this_iter_s: 311.31371998786926\n",
      "  time_total_s: 49938.451382637024\n",
      "  timers:\n",
      "    learn_throughput: 65.214\n",
      "    learn_time_ms: 153280.852\n",
      "    load_throughput: 88595.391\n",
      "    load_time_ms: 112.828\n",
      "    sample_throughput: 63.427\n",
      "    sample_time_ms: 157597.814\n",
      "    update_time_ms: 10.028\n",
      "  timestamp: 1636950678\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1629348\n",
      "  training_iteration: 163\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         49938.5</td><td style=\"text-align: right;\">1629348</td><td style=\"text-align: right;\"> 2.60816</td><td style=\"text-align: right;\">               10.63</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           97.2621</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1639344\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-36-15\n",
      "  done: false\n",
      "  episode_len_mean: 97.33333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.930000000000017\n",
      "  episode_reward_mean: 1.6498039215686322\n",
      "  episode_reward_min: -2.5099999999999945\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 16854\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6852055146143985\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014552617793940303\n",
      "          policy_loss: -0.046362864419531365\n",
      "          total_loss: 0.08904364732149829\n",
      "          vf_explained_var: 0.839133083820343\n",
      "          vf_loss: 0.12496179953559787\n",
      "    num_agent_steps_sampled: 1639344\n",
      "    num_agent_steps_trained: 1639344\n",
      "    num_steps_sampled: 1639344\n",
      "    num_steps_trained: 1639344\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.27334905660378\n",
      "    ram_util_percent: 45.14080188679245\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049914015142415995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.079916920430705\n",
      "    mean_inference_ms: 8.749718026234804\n",
      "    mean_raw_obs_processing_ms: 2.5168421728380306\n",
      "  time_since_restore: 50235.49457025528\n",
      "  time_this_iter_s: 297.0431876182556\n",
      "  time_total_s: 50235.49457025528\n",
      "  timers:\n",
      "    learn_throughput: 65.228\n",
      "    learn_time_ms: 153246.052\n",
      "    load_throughput: 88662.221\n",
      "    load_time_ms: 112.742\n",
      "    sample_throughput: 64.617\n",
      "    sample_time_ms: 154697.053\n",
      "    update_time_ms: 9.628\n",
      "  timestamp: 1636950975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1639344\n",
      "  training_iteration: 164\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         50235.5</td><td style=\"text-align: right;\">1639344</td><td style=\"text-align: right;\">  1.6498</td><td style=\"text-align: right;\">                8.93</td><td style=\"text-align: right;\">               -2.51</td><td style=\"text-align: right;\">           97.3333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1649340\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-41-29\n",
      "  done: false\n",
      "  episode_len_mean: 96.96153846153847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.970000000000008\n",
      "  episode_reward_mean: 2.240769230769237\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 16958\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.677355087109101\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01393336193583568\n",
      "          policy_loss: -0.04818287414546387\n",
      "          total_loss: 0.0969455013015809\n",
      "          vf_explained_var: 0.8405930995941162\n",
      "          vf_loss: 0.13619224504472163\n",
      "    num_agent_steps_sampled: 1649340\n",
      "    num_agent_steps_trained: 1649340\n",
      "    num_steps_sampled: 1649340\n",
      "    num_steps_trained: 1649340\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.67829977628635\n",
      "    ram_util_percent: 45.11700223713646\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04988593841412932\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.088415144417795\n",
      "    mean_inference_ms: 8.748816357840418\n",
      "    mean_raw_obs_processing_ms: 2.5323092766898934\n",
      "  time_since_restore: 50549.21834182739\n",
      "  time_this_iter_s: 313.72377157211304\n",
      "  time_total_s: 50549.21834182739\n",
      "  timers:\n",
      "    learn_throughput: 65.232\n",
      "    learn_time_ms: 153237.079\n",
      "    load_throughput: 88299.333\n",
      "    load_time_ms: 113.206\n",
      "    sample_throughput: 64.099\n",
      "    sample_time_ms: 155947.464\n",
      "    update_time_ms: 9.244\n",
      "  timestamp: 1636951289\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1649340\n",
      "  training_iteration: 165\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         50549.2</td><td style=\"text-align: right;\">1649340</td><td style=\"text-align: right;\"> 2.24077</td><td style=\"text-align: right;\">                8.97</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           96.9615</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1659336\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-46-43\n",
      "  done: false\n",
      "  episode_len_mean: 93.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.120000000000019\n",
      "  episode_reward_mean: 2.0096261682243037\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 17065\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.692927923263648\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013970216131683371\n",
      "          policy_loss: -0.05015668228117383\n",
      "          total_loss: 0.08016497890831123\n",
      "          vf_explained_var: 0.8394721150398254\n",
      "          vf_loss: 0.12144680491879455\n",
      "    num_agent_steps_sampled: 1659336\n",
      "    num_agent_steps_trained: 1659336\n",
      "    num_steps_sampled: 1659336\n",
      "    num_steps_trained: 1659336\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.02204899777283\n",
      "    ram_util_percent: 45.35412026726057\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0499213284891051\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.092341690746956\n",
      "    mean_inference_ms: 8.749729800314826\n",
      "    mean_raw_obs_processing_ms: 2.5287770750304075\n",
      "  time_since_restore: 50863.76222872734\n",
      "  time_this_iter_s: 314.5438868999481\n",
      "  time_total_s: 50863.76222872734\n",
      "  timers:\n",
      "    learn_throughput: 65.231\n",
      "    learn_time_ms: 153239.766\n",
      "    load_throughput: 88428.506\n",
      "    load_time_ms: 113.04\n",
      "    sample_throughput: 63.925\n",
      "    sample_time_ms: 156369.65\n",
      "    update_time_ms: 9.295\n",
      "  timestamp: 1636951603\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1659336\n",
      "  training_iteration: 166\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         50863.8</td><td style=\"text-align: right;\">1659336</td><td style=\"text-align: right;\"> 2.00963</td><td style=\"text-align: right;\">               12.12</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">                93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1669332\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-51-42\n",
      "  done: false\n",
      "  episode_len_mean: 96.32692307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.700000000000017\n",
      "  episode_reward_mean: 1.6870192307692358\n",
      "  episode_reward_min: -1.7700000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 17169\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7002117205888796\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013043768726890373\n",
      "          policy_loss: -0.0516253618706559\n",
      "          total_loss: 0.06443025214780664\n",
      "          vf_explained_var: 0.8406623005867004\n",
      "          vf_loss: 0.10962797958348106\n",
      "    num_agent_steps_sampled: 1669332\n",
      "    num_agent_steps_trained: 1669332\n",
      "    num_steps_sampled: 1669332\n",
      "    num_steps_trained: 1669332\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.58009367681498\n",
      "    ram_util_percent: 45.21639344262295\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049924263121488816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.10104248269248\n",
      "    mean_inference_ms: 8.750709308622062\n",
      "    mean_raw_obs_processing_ms: 2.5180929170520256\n",
      "  time_since_restore: 51162.50440263748\n",
      "  time_this_iter_s: 298.742173910141\n",
      "  time_total_s: 51162.50440263748\n",
      "  timers:\n",
      "    learn_throughput: 65.23\n",
      "    learn_time_ms: 153242.213\n",
      "    load_throughput: 88227.572\n",
      "    load_time_ms: 113.298\n",
      "    sample_throughput: 64.368\n",
      "    sample_time_ms: 155294.823\n",
      "    update_time_ms: 10.204\n",
      "  timestamp: 1636951902\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1669332\n",
      "  training_iteration: 167\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         51162.5</td><td style=\"text-align: right;\">1669332</td><td style=\"text-align: right;\"> 1.68702</td><td style=\"text-align: right;\">                 8.7</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           96.3269</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1679328\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_04-57-10\n",
      "  done: false\n",
      "  episode_len_mean: 95.54285714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.660000000000018\n",
      "  episode_reward_mean: 2.233619047619053\n",
      "  episode_reward_min: -1.950000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 17274\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.69010919882701\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01475636461622783\n",
      "          policy_loss: -0.04733016489423875\n",
      "          total_loss: 0.0941407330457567\n",
      "          vf_explained_var: 0.8566058874130249\n",
      "          vf_loss: 0.13055304229959974\n",
      "    num_agent_steps_sampled: 1679328\n",
      "    num_agent_steps_trained: 1679328\n",
      "    num_steps_sampled: 1679328\n",
      "    num_steps_trained: 1679328\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.0111111111111\n",
      "    ram_util_percent: 45.11688034188033\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049911151827038425\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.103928913855654\n",
      "    mean_inference_ms: 8.750290668306\n",
      "    mean_raw_obs_processing_ms: 2.542763600595603\n",
      "  time_since_restore: 51490.57404065132\n",
      "  time_this_iter_s: 328.0696380138397\n",
      "  time_total_s: 51490.57404065132\n",
      "  timers:\n",
      "    learn_throughput: 65.228\n",
      "    learn_time_ms: 153247.039\n",
      "    load_throughput: 88562.753\n",
      "    load_time_ms: 112.869\n",
      "    sample_throughput: 63.8\n",
      "    sample_time_ms: 156677.921\n",
      "    update_time_ms: 10.599\n",
      "  timestamp: 1636952230\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1679328\n",
      "  training_iteration: 168\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         51490.6</td><td style=\"text-align: right;\">1679328</td><td style=\"text-align: right;\"> 2.23362</td><td style=\"text-align: right;\">                8.66</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           95.5429</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1689324\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-02-26\n",
      "  done: false\n",
      "  episode_len_mean: 95.66346153846153\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.740000000000014\n",
      "  episode_reward_mean: 1.96288461538462\n",
      "  episode_reward_min: -1.6700000000000006\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 17378\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6884362156574544\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01529029107160133\n",
      "          policy_loss: -0.042989018317471206\n",
      "          total_loss: 0.13781777173400117\n",
      "          vf_explained_var: 0.817865788936615\n",
      "          vf_loss: 0.16850380930317263\n",
      "    num_agent_steps_sampled: 1689324\n",
      "    num_agent_steps_trained: 1689324\n",
      "    num_steps_sampled: 1689324\n",
      "    num_steps_trained: 1689324\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.65066666666667\n",
      "    ram_util_percent: 44.974444444444444\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04993601491617687\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.105711955816375\n",
      "    mean_inference_ms: 8.751642822590442\n",
      "    mean_raw_obs_processing_ms: 2.5331976860803915\n",
      "  time_since_restore: 51806.24875664711\n",
      "  time_this_iter_s: 315.6747159957886\n",
      "  time_total_s: 51806.24875664711\n",
      "  timers:\n",
      "    learn_throughput: 65.24\n",
      "    learn_time_ms: 153219.136\n",
      "    load_throughput: 88347.394\n",
      "    load_time_ms: 113.144\n",
      "    sample_throughput: 63.527\n",
      "    sample_time_ms: 157351.219\n",
      "    update_time_ms: 10.721\n",
      "  timestamp: 1636952546\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1689324\n",
      "  training_iteration: 169\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         51806.2</td><td style=\"text-align: right;\">1689324</td><td style=\"text-align: right;\"> 1.96288</td><td style=\"text-align: right;\">               10.74</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           95.6635</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1699320\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-07-40\n",
      "  done: false\n",
      "  episode_len_mean: 96.51428571428572\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.650000000000011\n",
      "  episode_reward_mean: 1.659428571428576\n",
      "  episode_reward_min: -1.9400000000000008\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 17483\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7087362022481414\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014448347540158852\n",
      "          policy_loss: -0.0458786404480696\n",
      "          total_loss: 0.10175247565449144\n",
      "          vf_explained_var: 0.8332725167274475\n",
      "          vf_loss: 0.13768894455602598\n",
      "    num_agent_steps_sampled: 1699320\n",
      "    num_agent_steps_trained: 1699320\n",
      "    num_steps_sampled: 1699320\n",
      "    num_steps_trained: 1699320\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.0872767857143\n",
      "    ram_util_percent: 45.1484375\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049916954374132044\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.112219153159856\n",
      "    mean_inference_ms: 8.750826174410431\n",
      "    mean_raw_obs_processing_ms: 2.5382520366912633\n",
      "  time_since_restore: 52120.584624528885\n",
      "  time_this_iter_s: 314.3358678817749\n",
      "  time_total_s: 52120.584624528885\n",
      "  timers:\n",
      "    learn_throughput: 65.234\n",
      "    learn_time_ms: 153234.126\n",
      "    load_throughput: 88143.344\n",
      "    load_time_ms: 113.406\n",
      "    sample_throughput: 63.648\n",
      "    sample_time_ms: 157051.146\n",
      "    update_time_ms: 10.397\n",
      "  timestamp: 1636952860\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1699320\n",
      "  training_iteration: 170\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         52120.6</td><td style=\"text-align: right;\">1699320</td><td style=\"text-align: right;\"> 1.65943</td><td style=\"text-align: right;\">                8.65</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           96.5143</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1709316\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-12-39\n",
      "  done: false\n",
      "  episode_len_mean: 96.24271844660194\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.850000000000017\n",
      "  episode_reward_mean: 2.2468932038835012\n",
      "  episode_reward_min: -2.04\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 17586\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6883023442366185\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014398109378077879\n",
      "          policy_loss: -0.048450497007713866\n",
      "          total_loss: 0.09671726363400618\n",
      "          vf_explained_var: 0.8388465046882629\n",
      "          vf_loss: 0.13515000524612256\n",
      "    num_agent_steps_sampled: 1709316\n",
      "    num_agent_steps_trained: 1709316\n",
      "    num_steps_sampled: 1709316\n",
      "    num_steps_trained: 1709316\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.59718969555036\n",
      "    ram_util_percent: 44.968384074941454\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04992593905180801\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.12087088488523\n",
      "    mean_inference_ms: 8.751452638098877\n",
      "    mean_raw_obs_processing_ms: 2.529219085516208\n",
      "  time_since_restore: 52419.565907239914\n",
      "  time_this_iter_s: 298.98128271102905\n",
      "  time_total_s: 52419.565907239914\n",
      "  timers:\n",
      "    learn_throughput: 65.248\n",
      "    learn_time_ms: 153200.778\n",
      "    load_throughput: 87484.771\n",
      "    load_time_ms: 114.26\n",
      "    sample_throughput: 64.245\n",
      "    sample_time_ms: 155592.285\n",
      "    update_time_ms: 10.039\n",
      "  timestamp: 1636953159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1709316\n",
      "  training_iteration: 171\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         52419.6</td><td style=\"text-align: right;\">1709316</td><td style=\"text-align: right;\"> 2.24689</td><td style=\"text-align: right;\">                8.85</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           96.2427</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1719312\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-17-53\n",
      "  done: false\n",
      "  episode_len_mean: 94.38095238095238\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.030000000000015\n",
      "  episode_reward_mean: 2.0555238095238146\n",
      "  episode_reward_min: -1.4100000000000008\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 17691\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.695082200694288\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015528293074602406\n",
      "          policy_loss: -0.04446330753823694\n",
      "          total_loss: 0.12314544930958594\n",
      "          vf_explained_var: 0.8283409476280212\n",
      "          vf_loss: 0.15476226411823535\n",
      "    num_agent_steps_sampled: 1719312\n",
      "    num_agent_steps_trained: 1719312\n",
      "    num_steps_sampled: 1719312\n",
      "    num_steps_trained: 1719312\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.04876957494407\n",
      "    ram_util_percent: 45.30805369127516\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049914154517025994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.12475200994905\n",
      "    mean_inference_ms: 8.751406310750847\n",
      "    mean_raw_obs_processing_ms: 2.5379691603194408\n",
      "  time_since_restore: 52732.71239733696\n",
      "  time_this_iter_s: 313.1464900970459\n",
      "  time_total_s: 52732.71239733696\n",
      "  timers:\n",
      "    learn_throughput: 65.265\n",
      "    learn_time_ms: 153161.006\n",
      "    load_throughput: 87813.972\n",
      "    load_time_ms: 113.832\n",
      "    sample_throughput: 63.565\n",
      "    sample_time_ms: 157256.285\n",
      "    update_time_ms: 9.889\n",
      "  timestamp: 1636953473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1719312\n",
      "  training_iteration: 172\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         52732.7</td><td style=\"text-align: right;\">1719312</td><td style=\"text-align: right;\"> 2.05552</td><td style=\"text-align: right;\">                9.03</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">            94.381</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1729308\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-23-06\n",
      "  done: false\n",
      "  episode_len_mean: 96.25961538461539\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.650000000000015\n",
      "  episode_reward_mean: 1.6908653846153887\n",
      "  episode_reward_min: -2.1599999999999997\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 17795\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.698863282876137\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013916835159242087\n",
      "          policy_loss: -0.04633315913060791\n",
      "          total_loss: 0.1036670283239303\n",
      "          vf_explained_var: 0.8012557625770569\n",
      "          vf_loss: 0.14132149475626649\n",
      "    num_agent_steps_sampled: 1729308\n",
      "    num_agent_steps_trained: 1729308\n",
      "    num_steps_sampled: 1729308\n",
      "    num_steps_trained: 1729308\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.60693512304252\n",
      "    ram_util_percent: 45.29910514541386\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04991022148534066\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.13227637415632\n",
      "    mean_inference_ms: 8.751609593757863\n",
      "    mean_raw_obs_processing_ms: 2.5396121001210377\n",
      "  time_since_restore: 53046.4295771122\n",
      "  time_this_iter_s: 313.71717977523804\n",
      "  time_total_s: 53046.4295771122\n",
      "  timers:\n",
      "    learn_throughput: 65.26\n",
      "    learn_time_ms: 153171.135\n",
      "    load_throughput: 87952.52\n",
      "    load_time_ms: 113.652\n",
      "    sample_throughput: 63.472\n",
      "    sample_time_ms: 157486.55\n",
      "    update_time_ms: 10.438\n",
      "  timestamp: 1636953786\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1729308\n",
      "  training_iteration: 173\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         53046.4</td><td style=\"text-align: right;\">1729308</td><td style=\"text-align: right;\"> 1.69087</td><td style=\"text-align: right;\">                8.65</td><td style=\"text-align: right;\">               -2.16</td><td style=\"text-align: right;\">           96.2596</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1739304\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-28-08\n",
      "  done: false\n",
      "  episode_len_mean: 95.47619047619048\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.380000000000017\n",
      "  episode_reward_mean: 1.649809523809528\n",
      "  episode_reward_min: -2.0300000000000002\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 17900\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6998901651455807\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013408248960417616\n",
      "          policy_loss: -0.048684746974235416\n",
      "          total_loss: 0.08589662567067605\n",
      "          vf_explained_var: 0.8152785301208496\n",
      "          vf_loss: 0.1272163987860211\n",
      "    num_agent_steps_sampled: 1739304\n",
      "    num_agent_steps_trained: 1739304\n",
      "    num_steps_sampled: 1739304\n",
      "    num_steps_trained: 1739304\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.50116009280742\n",
      "    ram_util_percent: 44.980742459396744\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0499096933649296\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.140594288161076\n",
      "    mean_inference_ms: 8.75238266079554\n",
      "    mean_raw_obs_processing_ms: 2.5271199601799217\n",
      "  time_since_restore: 53347.98454451561\n",
      "  time_this_iter_s: 301.55496740341187\n",
      "  time_total_s: 53347.98454451561\n",
      "  timers:\n",
      "    learn_throughput: 65.249\n",
      "    learn_time_ms: 153198.022\n",
      "    load_throughput: 88253.87\n",
      "    load_time_ms: 113.264\n",
      "    sample_throughput: 63.302\n",
      "    sample_time_ms: 157910.914\n",
      "    update_time_ms: 10.775\n",
      "  timestamp: 1636954088\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1739304\n",
      "  training_iteration: 174\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">           53348</td><td style=\"text-align: right;\">1739304</td><td style=\"text-align: right;\"> 1.64981</td><td style=\"text-align: right;\">               10.38</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">           95.4762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1749300\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-33-24\n",
      "  done: false\n",
      "  episode_len_mean: 94.34285714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.920000000000016\n",
      "  episode_reward_mean: 1.837523809523814\n",
      "  episode_reward_min: -1.570000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 18005\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6987675847151342\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015444938364259815\n",
      "          policy_loss: -0.04428247567664227\n",
      "          total_loss: 0.1233947399072349\n",
      "          vf_explained_var: 0.809515118598938\n",
      "          vf_loss: 0.15508120480932805\n",
      "    num_agent_steps_sampled: 1749300\n",
      "    num_agent_steps_trained: 1749300\n",
      "    num_steps_sampled: 1749300\n",
      "    num_steps_trained: 1749300\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.12711111111112\n",
      "    ram_util_percent: 44.83111111111109\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04992727115664343\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.14629013751739\n",
      "    mean_inference_ms: 8.753084265441823\n",
      "    mean_raw_obs_processing_ms: 2.536743523672592\n",
      "  time_since_restore: 53663.70890831947\n",
      "  time_this_iter_s: 315.7243638038635\n",
      "  time_total_s: 53663.70890831947\n",
      "  timers:\n",
      "    learn_throughput: 65.238\n",
      "    learn_time_ms: 153223.805\n",
      "    load_throughput: 87991.708\n",
      "    load_time_ms: 113.602\n",
      "    sample_throughput: 63.232\n",
      "    sample_time_ms: 158084.994\n",
      "    update_time_ms: 11.001\n",
      "  timestamp: 1636954404\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1749300\n",
      "  training_iteration: 175\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         53663.7</td><td style=\"text-align: right;\">1749300</td><td style=\"text-align: right;\"> 1.83752</td><td style=\"text-align: right;\">                8.92</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           94.3429</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1759296\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-38-38\n",
      "  done: false\n",
      "  episode_len_mean: 94.60747663551402\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.330000000000013\n",
      "  episode_reward_mean: 2.169532710280379\n",
      "  episode_reward_min: -1.7400000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 18112\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7002600885863997\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01491095682244499\n",
      "          policy_loss: -0.040073827732927524\n",
      "          total_loss: 0.13428883974392636\n",
      "          vf_explained_var: 0.8052354454994202\n",
      "          vf_loss: 0.16315011813337157\n",
      "    num_agent_steps_sampled: 1759296\n",
      "    num_agent_steps_trained: 1759296\n",
      "    num_steps_sampled: 1759296\n",
      "    num_steps_trained: 1759296\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.984855233853\n",
      "    ram_util_percent: 45.1924276169265\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049914231631917536\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.15364166963736\n",
      "    mean_inference_ms: 8.752854989795784\n",
      "    mean_raw_obs_processing_ms: 2.5341013082435966\n",
      "  time_since_restore: 53978.2396607399\n",
      "  time_this_iter_s: 314.5307524204254\n",
      "  time_total_s: 53978.2396607399\n",
      "  timers:\n",
      "    learn_throughput: 65.25\n",
      "    learn_time_ms: 153195.176\n",
      "    load_throughput: 87843.134\n",
      "    load_time_ms: 113.794\n",
      "    sample_throughput: 63.221\n",
      "    sample_time_ms: 158111.7\n",
      "    update_time_ms: 11.577\n",
      "  timestamp: 1636954718\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1759296\n",
      "  training_iteration: 176\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         53978.2</td><td style=\"text-align: right;\">1759296</td><td style=\"text-align: right;\"> 2.16953</td><td style=\"text-align: right;\">               11.33</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           94.6075</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1769292\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-43-36\n",
      "  done: false\n",
      "  episode_len_mean: 96.64077669902913\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.77000000000001\n",
      "  episode_reward_mean: 1.6683495145631109\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 18215\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7033377252073367\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013221105870651633\n",
      "          policy_loss: -0.040351420835965976\n",
      "          total_loss: 0.1155135274769213\n",
      "          vf_explained_var: 0.7823896408081055\n",
      "          vf_loss: 0.1490140785693995\n",
      "    num_agent_steps_sampled: 1769292\n",
      "    num_agent_steps_trained: 1769292\n",
      "    num_steps_sampled: 1769292\n",
      "    num_steps_trained: 1769292\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.51267605633801\n",
      "    ram_util_percent: 45.20657276995305\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049909854259064024\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.160785508254\n",
      "    mean_inference_ms: 8.753581569554342\n",
      "    mean_raw_obs_processing_ms: 2.5224476614048994\n",
      "  time_since_restore: 54276.50670385361\n",
      "  time_this_iter_s: 298.2670431137085\n",
      "  time_total_s: 54276.50670385361\n",
      "  timers:\n",
      "    learn_throughput: 65.25\n",
      "    learn_time_ms: 153195.524\n",
      "    load_throughput: 87690.768\n",
      "    load_time_ms: 113.991\n",
      "    sample_throughput: 63.24\n",
      "    sample_time_ms: 158064.704\n",
      "    update_time_ms: 11.178\n",
      "  timestamp: 1636955016\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1769292\n",
      "  training_iteration: 177\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         54276.5</td><td style=\"text-align: right;\">1769292</td><td style=\"text-align: right;\"> 1.66835</td><td style=\"text-align: right;\">                6.77</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           96.6408</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1779288\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-48-53\n",
      "  done: false\n",
      "  episode_len_mean: 93.59813084112149\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.570000000000014\n",
      "  episode_reward_mean: 1.75009345794393\n",
      "  episode_reward_min: -2.319999999999997\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 18322\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.706608591426132\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013595742087265588\n",
      "          policy_loss: -0.03970168535995623\n",
      "          total_loss: 0.12692261211281547\n",
      "          vf_explained_var: 0.807422935962677\n",
      "          vf_loss: 0.15884598447925324\n",
      "    num_agent_steps_sampled: 1779288\n",
      "    num_agent_steps_trained: 1779288\n",
      "    num_steps_sampled: 1779288\n",
      "    num_steps_trained: 1779288\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.80022222222222\n",
      "    ram_util_percent: 44.73377777777778\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049913126015015324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.170020385865605\n",
      "    mean_inference_ms: 8.753782756870722\n",
      "    mean_raw_obs_processing_ms: 2.526859942767143\n",
      "  time_since_restore: 54592.534435510635\n",
      "  time_this_iter_s: 316.0277316570282\n",
      "  time_total_s: 54592.534435510635\n",
      "  timers:\n",
      "    learn_throughput: 65.245\n",
      "    learn_time_ms: 153207.678\n",
      "    load_throughput: 87637.19\n",
      "    load_time_ms: 114.061\n",
      "    sample_throughput: 63.73\n",
      "    sample_time_ms: 156849.092\n",
      "    update_time_ms: 10.458\n",
      "  timestamp: 1636955333\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1779288\n",
      "  training_iteration: 178\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">         54592.5</td><td style=\"text-align: right;\">1779288</td><td style=\"text-align: right;\"> 1.75009</td><td style=\"text-align: right;\">                8.57</td><td style=\"text-align: right;\">               -2.32</td><td style=\"text-align: right;\">           93.5981</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1789284\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-54-03\n",
      "  done: false\n",
      "  episode_len_mean: 94.99056603773585\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.300000000000013\n",
      "  episode_reward_mean: 1.5838679245283052\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 18428\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7005785909473388\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013681009916752626\n",
      "          policy_loss: -0.041206150600670746\n",
      "          total_loss: 0.11093749763627146\n",
      "          vf_explained_var: 0.8049436211585999\n",
      "          vf_loss: 0.14408650341618837\n",
      "    num_agent_steps_sampled: 1789284\n",
      "    num_agent_steps_trained: 1789284\n",
      "    num_steps_sampled: 1789284\n",
      "    num_steps_trained: 1789284\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.05472972972974\n",
      "    ram_util_percent: 45.18445945945946\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0499196972180961\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.173138600835365\n",
      "    mean_inference_ms: 8.754496501077293\n",
      "    mean_raw_obs_processing_ms: 2.525277782275817\n",
      "  time_since_restore: 54903.45400261879\n",
      "  time_this_iter_s: 310.9195671081543\n",
      "  time_total_s: 54903.45400261879\n",
      "  timers:\n",
      "    learn_throughput: 65.25\n",
      "    learn_time_ms: 153195.545\n",
      "    load_throughput: 87794.646\n",
      "    load_time_ms: 113.857\n",
      "    sample_throughput: 63.919\n",
      "    sample_time_ms: 156386.021\n",
      "    update_time_ms: 10.515\n",
      "  timestamp: 1636955643\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1789284\n",
      "  training_iteration: 179\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         54903.5</td><td style=\"text-align: right;\">1789284</td><td style=\"text-align: right;\"> 1.58387</td><td style=\"text-align: right;\">                 8.3</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           94.9906</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1799280\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_05-59-16\n",
      "  done: false\n",
      "  episode_len_mean: 94.0754716981132\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.400000000000018\n",
      "  episode_reward_mean: 1.9339622641509475\n",
      "  episode_reward_min: -1.7400000000000007\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 18534\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.695444443388882\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014041867148565963\n",
      "          policy_loss: -0.0378744044349107\n",
      "          total_loss: 0.11135744919371592\n",
      "          vf_explained_var: 0.8235668540000916\n",
      "          vf_loss: 0.14019852890991247\n",
      "    num_agent_steps_sampled: 1799280\n",
      "    num_agent_steps_trained: 1799280\n",
      "    num_steps_sampled: 1799280\n",
      "    num_steps_trained: 1799280\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.04337078651685\n",
      "    ram_util_percent: 45.41595505617977\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994516209942694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.17697035463779\n",
      "    mean_inference_ms: 8.754827600646436\n",
      "    mean_raw_obs_processing_ms: 2.5214816413877097\n",
      "  time_since_restore: 55215.56523013115\n",
      "  time_this_iter_s: 312.1112275123596\n",
      "  time_total_s: 55215.56523013115\n",
      "  timers:\n",
      "    learn_throughput: 65.248\n",
      "    learn_time_ms: 153199.379\n",
      "    load_throughput: 87845.14\n",
      "    load_time_ms: 113.791\n",
      "    sample_throughput: 64.011\n",
      "    sample_time_ms: 156159.463\n",
      "    update_time_ms: 11.31\n",
      "  timestamp: 1636955956\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1799280\n",
      "  training_iteration: 180\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         55215.6</td><td style=\"text-align: right;\">1799280</td><td style=\"text-align: right;\"> 1.93396</td><td style=\"text-align: right;\">                 8.4</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           94.0755</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1809276\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-04-18\n",
      "  done: false\n",
      "  episode_len_mean: 94.0952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.950000000000015\n",
      "  episode_reward_mean: 1.7828571428571476\n",
      "  episode_reward_min: -2.2600000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 18639\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6931817199429897\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01274234332706189\n",
      "          policy_loss: -0.04178977719683232\n",
      "          total_loss: 0.09510139453774079\n",
      "          vf_explained_var: 0.8547006249427795\n",
      "          vf_loss: 0.13116575771600453\n",
      "    num_agent_steps_sampled: 1809276\n",
      "    num_agent_steps_trained: 1809276\n",
      "    num_steps_sampled: 1809276\n",
      "    num_steps_trained: 1809276\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.66388888888888\n",
      "    ram_util_percent: 45.30393518518518\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994023938699816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.189387282703294\n",
      "    mean_inference_ms: 8.754989860487653\n",
      "    mean_raw_obs_processing_ms: 2.5138265207521373\n",
      "  time_since_restore: 55517.836415052414\n",
      "  time_this_iter_s: 302.27118492126465\n",
      "  time_total_s: 55517.836415052414\n",
      "  timers:\n",
      "    learn_throughput: 65.234\n",
      "    learn_time_ms: 153233.242\n",
      "    load_throughput: 87799.665\n",
      "    load_time_ms: 113.85\n",
      "    sample_throughput: 63.891\n",
      "    sample_time_ms: 156454.366\n",
      "    update_time_ms: 11.667\n",
      "  timestamp: 1636956258\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1809276\n",
      "  training_iteration: 181\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         55517.8</td><td style=\"text-align: right;\">1809276</td><td style=\"text-align: right;\"> 1.78286</td><td style=\"text-align: right;\">                6.95</td><td style=\"text-align: right;\">               -2.26</td><td style=\"text-align: right;\">           94.0952</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1819272\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-09-48\n",
      "  done: false\n",
      "  episode_len_mean: 93.6822429906542\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.310000000000013\n",
      "  episode_reward_mean: 2.621214953271033\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 18746\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6713385768425773\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014727337304752473\n",
      "          policy_loss: -0.03590088413041244\n",
      "          total_loss: 0.15604573961100582\n",
      "          vf_explained_var: 0.8130940794944763\n",
      "          vf_loss: 0.18091545610362267\n",
      "    num_agent_steps_sampled: 1819272\n",
      "    num_agent_steps_trained: 1819272\n",
      "    num_steps_sampled: 1819272\n",
      "    num_steps_trained: 1819272\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.10276595744682\n",
      "    ram_util_percent: 45.271489361702116\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04993799389408793\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.19416049358873\n",
      "    mean_inference_ms: 8.755215210856205\n",
      "    mean_raw_obs_processing_ms: 2.5316603945375262\n",
      "  time_since_restore: 55847.613157987595\n",
      "  time_this_iter_s: 329.77674293518066\n",
      "  time_total_s: 55847.613157987595\n",
      "  timers:\n",
      "    learn_throughput: 65.214\n",
      "    learn_time_ms: 153279.199\n",
      "    load_throughput: 87544.45\n",
      "    load_time_ms: 114.182\n",
      "    sample_throughput: 63.237\n",
      "    sample_time_ms: 158070.834\n",
      "    update_time_ms: 12.396\n",
      "  timestamp: 1636956588\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1819272\n",
      "  training_iteration: 182\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         55847.6</td><td style=\"text-align: right;\">1819272</td><td style=\"text-align: right;\"> 2.62121</td><td style=\"text-align: right;\">               10.31</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           93.6822</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1829268\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-15-04\n",
      "  done: false\n",
      "  episode_len_mean: 94.4245283018868\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.640000000000015\n",
      "  episode_reward_mean: 1.7454716981132121\n",
      "  episode_reward_min: -1.6900000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 18852\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.692539406230307\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012356959826877423\n",
      "          policy_loss: -0.04352002210485247\n",
      "          total_loss: 0.11615642853017547\n",
      "          vf_explained_var: 0.7982430458068848\n",
      "          vf_loss: 0.15493230847124423\n",
      "    num_agent_steps_sampled: 1829268\n",
      "    num_agent_steps_trained: 1829268\n",
      "    num_steps_sampled: 1829268\n",
      "    num_steps_trained: 1829268\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.30731707317072\n",
      "    ram_util_percent: 45.53458980044347\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049950664035380114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.200462502636235\n",
      "    mean_inference_ms: 8.755610949255479\n",
      "    mean_raw_obs_processing_ms: 2.5334280459531664\n",
      "  time_since_restore: 56163.6077542305\n",
      "  time_this_iter_s: 315.99459624290466\n",
      "  time_total_s: 56163.6077542305\n",
      "  timers:\n",
      "    learn_throughput: 65.21\n",
      "    learn_time_ms: 153289.747\n",
      "    load_throughput: 88044.556\n",
      "    load_time_ms: 113.533\n",
      "    sample_throughput: 63.15\n",
      "    sample_time_ms: 158289.289\n",
      "    update_time_ms: 11.711\n",
      "  timestamp: 1636956904\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1829268\n",
      "  training_iteration: 183\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         56163.6</td><td style=\"text-align: right;\">1829268</td><td style=\"text-align: right;\"> 1.74547</td><td style=\"text-align: right;\">               10.64</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           94.4245</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1839264\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-20-06\n",
      "  done: false\n",
      "  episode_len_mean: 94.93333333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.910000000000009\n",
      "  episode_reward_mean: 1.6014285714285756\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 18957\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.689838569286542\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015354047813346912\n",
      "          policy_loss: -0.03607029224602649\n",
      "          total_loss: 0.14311708914728946\n",
      "          vf_explained_var: 0.7880058884620667\n",
      "          vf_loss: 0.1667350224378463\n",
      "    num_agent_steps_sampled: 1839264\n",
      "    num_agent_steps_trained: 1839264\n",
      "    num_steps_sampled: 1839264\n",
      "    num_steps_trained: 1839264\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.58217592592592\n",
      "    ram_util_percent: 45.02013888888888\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04993711631070325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.213123740002196\n",
      "    mean_inference_ms: 8.755996940760975\n",
      "    mean_raw_obs_processing_ms: 2.5225456655069394\n",
      "  time_since_restore: 56466.02653288841\n",
      "  time_this_iter_s: 302.4187786579132\n",
      "  time_total_s: 56466.02653288841\n",
      "  timers:\n",
      "    learn_throughput: 65.229\n",
      "    learn_time_ms: 153243.962\n",
      "    load_throughput: 87330.061\n",
      "    load_time_ms: 114.462\n",
      "    sample_throughput: 63.098\n",
      "    sample_time_ms: 158419.656\n",
      "    update_time_ms: 12.486\n",
      "  timestamp: 1636957206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1839264\n",
      "  training_iteration: 184\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">           56466</td><td style=\"text-align: right;\">1839264</td><td style=\"text-align: right;\"> 1.60143</td><td style=\"text-align: right;\">               12.91</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           94.9333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1849260\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-25-22\n",
      "  done: false\n",
      "  episode_len_mean: 92.52777777777777\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.300000000000017\n",
      "  episode_reward_mean: 1.804537037037041\n",
      "  episode_reward_min: -1.6600000000000006\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 19065\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6941362138487337\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012016901239338563\n",
      "          policy_loss: -0.04065592518299181\n",
      "          total_loss: 0.10194232124898933\n",
      "          vf_explained_var: 0.8336895108222961\n",
      "          vf_loss: 0.13874160482978018\n",
      "    num_agent_steps_sampled: 1849260\n",
      "    num_agent_steps_trained: 1849260\n",
      "    num_steps_sampled: 1849260\n",
      "    num_steps_trained: 1849260\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.22644444444445\n",
      "    ram_util_percent: 45.01800000000001\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04992762296884779\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.22579192930288\n",
      "    mean_inference_ms: 8.755809681012614\n",
      "    mean_raw_obs_processing_ms: 2.522117878425011\n",
      "  time_since_restore: 56781.97813153267\n",
      "  time_this_iter_s: 315.9515986442566\n",
      "  time_total_s: 56781.97813153267\n",
      "  timers:\n",
      "    learn_throughput: 65.237\n",
      "    learn_time_ms: 153225.977\n",
      "    load_throughput: 87945.491\n",
      "    load_time_ms: 113.661\n",
      "    sample_throughput: 63.082\n",
      "    sample_time_ms: 158461.265\n",
      "    update_time_ms: 11.891\n",
      "  timestamp: 1636957522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1849260\n",
      "  training_iteration: 185\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">           56782</td><td style=\"text-align: right;\">1849260</td><td style=\"text-align: right;\"> 1.80454</td><td style=\"text-align: right;\">                 8.3</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           92.5278</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1859256\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-30-51\n",
      "  done: false\n",
      "  episode_len_mean: 91.76146788990826\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.780000000000006\n",
      "  episode_reward_mean: 1.8811009174311966\n",
      "  episode_reward_min: -1.9200000000000004\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 19174\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.688537443601168\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013226124049630136\n",
      "          policy_loss: -0.03551212432038071\n",
      "          total_loss: 0.12978859172027526\n",
      "          vf_explained_var: 0.7720949053764343\n",
      "          vf_loss: 0.1582889812353712\n",
      "    num_agent_steps_sampled: 1859256\n",
      "    num_agent_steps_trained: 1859256\n",
      "    num_steps_sampled: 1859256\n",
      "    num_steps_trained: 1859256\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.91063829787234\n",
      "    ram_util_percent: 45.050851063829796\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049938209357892775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.228780651758974\n",
      "    mean_inference_ms: 8.755998700892299\n",
      "    mean_raw_obs_processing_ms: 2.5297691227892063\n",
      "  time_since_restore: 57110.882348537445\n",
      "  time_this_iter_s: 328.904217004776\n",
      "  time_total_s: 57110.882348537445\n",
      "  timers:\n",
      "    learn_throughput: 65.23\n",
      "    learn_time_ms: 153242.988\n",
      "    load_throughput: 88097.615\n",
      "    load_time_ms: 113.465\n",
      "    sample_throughput: 62.521\n",
      "    sample_time_ms: 159881.711\n",
      "    update_time_ms: 11.318\n",
      "  timestamp: 1636957851\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1859256\n",
      "  training_iteration: 186\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         57110.9</td><td style=\"text-align: right;\">1859256</td><td style=\"text-align: right;\">  1.8811</td><td style=\"text-align: right;\">                8.78</td><td style=\"text-align: right;\">               -1.92</td><td style=\"text-align: right;\">           91.7615</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1869252\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-35-54\n",
      "  done: false\n",
      "  episode_len_mean: 93.70093457943925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.950000000000012\n",
      "  episode_reward_mean: 2.208037383177575\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 19281\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6844311699908006\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014823811167750351\n",
      "          policy_loss: -0.037211848439600986\n",
      "          total_loss: 0.13583153590289318\n",
      "          vf_explained_var: 0.8330093026161194\n",
      "          vf_loss: 0.1618958898477702\n",
      "    num_agent_steps_sampled: 1869252\n",
      "    num_agent_steps_trained: 1869252\n",
      "    num_steps_sampled: 1869252\n",
      "    num_steps_trained: 1869252\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.52436194895591\n",
      "    ram_util_percent: 45.33132250580047\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994402506570581\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.2385239402621\n",
      "    mean_inference_ms: 8.756970592541787\n",
      "    mean_raw_obs_processing_ms: 2.52150238907025\n",
      "  time_since_restore: 57413.29250907898\n",
      "  time_this_iter_s: 302.4101605415344\n",
      "  time_total_s: 57413.29250907898\n",
      "  timers:\n",
      "    learn_throughput: 65.23\n",
      "    learn_time_ms: 153242.111\n",
      "    load_throughput: 88387.997\n",
      "    load_time_ms: 113.092\n",
      "    sample_throughput: 62.359\n",
      "    sample_time_ms: 160296.816\n",
      "    update_time_ms: 11.085\n",
      "  timestamp: 1636958154\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1869252\n",
      "  training_iteration: 187\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         57413.3</td><td style=\"text-align: right;\">1869252</td><td style=\"text-align: right;\"> 2.20804</td><td style=\"text-align: right;\">               10.95</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           93.7009</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1879248\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-40-55\n",
      "  done: false\n",
      "  episode_len_mean: 95.23809523809524\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.980000000000016\n",
      "  episode_reward_mean: 2.007333333333338\n",
      "  episode_reward_min: -2.180000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 19386\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6941974736686447\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013086967745562747\n",
      "          policy_loss: -0.03164814702776444\n",
      "          total_loss: 0.1515402190335509\n",
      "          vf_explained_var: 0.7987884283065796\n",
      "          vf_loss: 0.17658987454791417\n",
      "    num_agent_steps_sampled: 1879248\n",
      "    num_agent_steps_trained: 1879248\n",
      "    num_steps_sampled: 1879248\n",
      "    num_steps_trained: 1879248\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.63735498839908\n",
      "    ram_util_percent: 45.02088167053364\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04993762243600359\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.25103316109313\n",
      "    mean_inference_ms: 8.757136166266532\n",
      "    mean_raw_obs_processing_ms: 2.5130967560144604\n",
      "  time_since_restore: 57715.114332675934\n",
      "  time_this_iter_s: 301.82182359695435\n",
      "  time_total_s: 57715.114332675934\n",
      "  timers:\n",
      "    learn_throughput: 65.215\n",
      "    learn_time_ms: 153276.651\n",
      "    load_throughput: 88245.158\n",
      "    load_time_ms: 113.275\n",
      "    sample_throughput: 62.931\n",
      "    sample_time_ms: 158840.641\n",
      "    update_time_ms: 11.897\n",
      "  timestamp: 1636958455\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1879248\n",
      "  training_iteration: 188\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">         57715.1</td><td style=\"text-align: right;\">1879248</td><td style=\"text-align: right;\"> 2.00733</td><td style=\"text-align: right;\">               10.98</td><td style=\"text-align: right;\">               -2.18</td><td style=\"text-align: right;\">           95.2381</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1889244\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-46-23\n",
      "  done: false\n",
      "  episode_len_mean: 95.27619047619048\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.590000000000014\n",
      "  episode_reward_mean: 1.8961904761904806\n",
      "  episode_reward_min: -1.830000000000001\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 19491\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6853720917660966\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011618124777670135\n",
      "          policy_loss: -0.0385454811135896\n",
      "          total_loss: 0.12098815345213326\n",
      "          vf_explained_var: 0.8002918362617493\n",
      "          vf_loss: 0.15661137333143757\n",
      "    num_agent_steps_sampled: 1889244\n",
      "    num_agent_steps_trained: 1889244\n",
      "    num_steps_sampled: 1889244\n",
      "    num_steps_trained: 1889244\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.78736616702355\n",
      "    ram_util_percent: 45.026980728051406\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994792587822584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.25127685033305\n",
      "    mean_inference_ms: 8.757363196370896\n",
      "    mean_raw_obs_processing_ms: 2.518693917076533\n",
      "  time_since_restore: 58042.5059261322\n",
      "  time_this_iter_s: 327.3915934562683\n",
      "  time_total_s: 58042.5059261322\n",
      "  timers:\n",
      "    learn_throughput: 65.215\n",
      "    learn_time_ms: 153276.824\n",
      "    load_throughput: 88131.541\n",
      "    load_time_ms: 113.421\n",
      "    sample_throughput: 62.285\n",
      "    sample_time_ms: 160487.812\n",
      "    update_time_ms: 11.535\n",
      "  timestamp: 1636958783\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1889244\n",
      "  training_iteration: 189\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         58042.5</td><td style=\"text-align: right;\">1889244</td><td style=\"text-align: right;\"> 1.89619</td><td style=\"text-align: right;\">               12.59</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           95.2762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1899240\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-51-37\n",
      "  done: false\n",
      "  episode_len_mean: 92.46296296296296\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.890000000000015\n",
      "  episode_reward_mean: 1.7837962962963005\n",
      "  episode_reward_min: -2.219999999999998\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 19599\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.680754722081698\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013854994343077008\n",
      "          policy_loss: -0.035047712926076266\n",
      "          total_loss: 0.14078102607486975\n",
      "          vf_explained_var: 0.8092446327209473\n",
      "          vf_loss: 0.1671274517248902\n",
      "    num_agent_steps_sampled: 1899240\n",
      "    num_agent_steps_trained: 1899240\n",
      "    num_steps_sampled: 1899240\n",
      "    num_steps_trained: 1899240\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.20000000000002\n",
      "    ram_util_percent: 45.47209821428572\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04992609033292138\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.26012268123288\n",
      "    mean_inference_ms: 8.757067454979595\n",
      "    mean_raw_obs_processing_ms: 2.5212736306657493\n",
      "  time_since_restore: 58356.87239265442\n",
      "  time_this_iter_s: 314.3664665222168\n",
      "  time_total_s: 58356.87239265442\n",
      "  timers:\n",
      "    learn_throughput: 65.206\n",
      "    learn_time_ms: 153298.957\n",
      "    load_throughput: 88368.901\n",
      "    load_time_ms: 113.117\n",
      "    sample_throughput: 62.206\n",
      "    sample_time_ms: 160691.357\n",
      "    update_time_ms: 11.601\n",
      "  timestamp: 1636959097\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1899240\n",
      "  training_iteration: 190\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   190</td><td style=\"text-align: right;\">         58356.9</td><td style=\"text-align: right;\">1899240</td><td style=\"text-align: right;\">  1.7838</td><td style=\"text-align: right;\">                8.89</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">            92.463</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1909236\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_06-56-40\n",
      "  done: false\n",
      "  episode_len_mean: 93.17757009345794\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.92000000000001\n",
      "  episode_reward_mean: 1.9464485981308457\n",
      "  episode_reward_min: -1.8900000000000015\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 19706\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6989569941137592\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012407846414480587\n",
      "          policy_loss: -0.03813664168517432\n",
      "          total_loss: 0.11128183614987976\n",
      "          vf_explained_var: 0.8136828541755676\n",
      "          vf_loss: 0.14460809468649902\n",
      "    num_agent_steps_sampled: 1909236\n",
      "    num_agent_steps_trained: 1909236\n",
      "    num_steps_sampled: 1909236\n",
      "    num_steps_trained: 1909236\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.74572748267899\n",
      "    ram_util_percent: 45.38845265588914\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04991981912190958\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.27430691625843\n",
      "    mean_inference_ms: 8.757912181506503\n",
      "    mean_raw_obs_processing_ms: 2.510880860983383\n",
      "  time_since_restore: 58659.96586585045\n",
      "  time_this_iter_s: 303.09347319602966\n",
      "  time_total_s: 58659.96586585045\n",
      "  timers:\n",
      "    learn_throughput: 65.226\n",
      "    learn_time_ms: 153252.094\n",
      "    load_throughput: 88793.248\n",
      "    load_time_ms: 112.576\n",
      "    sample_throughput: 62.156\n",
      "    sample_time_ms: 160821.091\n",
      "    update_time_ms: 11.73\n",
      "  timestamp: 1636959400\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1909236\n",
      "  training_iteration: 191\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">           58660</td><td style=\"text-align: right;\">1909236</td><td style=\"text-align: right;\"> 1.94645</td><td style=\"text-align: right;\">               10.92</td><td style=\"text-align: right;\">               -1.89</td><td style=\"text-align: right;\">           93.1776</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1919232\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-02-17\n",
      "  done: false\n",
      "  episode_len_mean: 90.93636363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.650000000000013\n",
      "  episode_reward_mean: 1.818272727272732\n",
      "  episode_reward_min: -1.9000000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 19816\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.68623723250169\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01264562553413045\n",
      "          policy_loss: -0.033829121088656856\n",
      "          total_loss: 0.1363423188917466\n",
      "          vf_explained_var: 0.8159373998641968\n",
      "          vf_loss: 0.16462445688656827\n",
      "    num_agent_steps_sampled: 1919232\n",
      "    num_agent_steps_trained: 1919232\n",
      "    num_steps_sampled: 1919232\n",
      "    num_steps_trained: 1919232\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82708333333333\n",
      "    ram_util_percent: 45.18479166666667\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04992202354904206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.2879795056977\n",
      "    mean_inference_ms: 8.758274770770766\n",
      "    mean_raw_obs_processing_ms: 2.5230400051645336\n",
      "  time_since_restore: 58996.48646020889\n",
      "  time_this_iter_s: 336.5205943584442\n",
      "  time_total_s: 58996.48646020889\n",
      "  timers:\n",
      "    learn_throughput: 65.246\n",
      "    learn_time_ms: 153205.521\n",
      "    load_throughput: 88546.93\n",
      "    load_time_ms: 112.889\n",
      "    sample_throughput: 61.879\n",
      "    sample_time_ms: 161541.546\n",
      "    update_time_ms: 11.426\n",
      "  timestamp: 1636959737\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1919232\n",
      "  training_iteration: 192\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">         58996.5</td><td style=\"text-align: right;\">1919232</td><td style=\"text-align: right;\"> 1.81827</td><td style=\"text-align: right;\">                8.65</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           90.9364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1929228\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-07-36\n",
      "  done: false\n",
      "  episode_len_mean: 91.73394495412845\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.700000000000014\n",
      "  episode_reward_mean: 1.6755045871559666\n",
      "  episode_reward_min: -1.6900000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 19925\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6872639634670357\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01121147405519584\n",
      "          policy_loss: -0.03665609807253648\n",
      "          total_loss: 0.11934774573693355\n",
      "          vf_explained_var: 0.8065246343612671\n",
      "          vf_loss: 0.1541427015951779\n",
      "    num_agent_steps_sampled: 1929228\n",
      "    num_agent_steps_trained: 1929228\n",
      "    num_steps_sampled: 1929228\n",
      "    num_steps_trained: 1929228\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.60615384615386\n",
      "    ram_util_percent: 45.130329670329665\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04993222605423547\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.30125552683923\n",
      "    mean_inference_ms: 8.75912170924866\n",
      "    mean_raw_obs_processing_ms: 2.5185807682595507\n",
      "  time_since_restore: 59315.15116930008\n",
      "  time_this_iter_s: 318.6647090911865\n",
      "  time_total_s: 59315.15116930008\n",
      "  timers:\n",
      "    learn_throughput: 65.242\n",
      "    learn_time_ms: 153215.155\n",
      "    load_throughput: 88300.319\n",
      "    load_time_ms: 113.205\n",
      "    sample_throughput: 61.78\n",
      "    sample_time_ms: 161799.12\n",
      "    update_time_ms: 11.22\n",
      "  timestamp: 1636960056\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1929228\n",
      "  training_iteration: 193\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">         59315.2</td><td style=\"text-align: right;\">1929228</td><td style=\"text-align: right;\">  1.6755</td><td style=\"text-align: right;\">                 8.7</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           91.7339</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1939224\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-12-39\n",
      "  done: false\n",
      "  episode_len_mean: 92.68807339449542\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.110000000000015\n",
      "  episode_reward_mean: 1.7290825688073435\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 20034\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.686699948962937\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012237184712027048\n",
      "          policy_loss: -0.03380642011284064\n",
      "          total_loss: 0.15996845939025506\n",
      "          vf_explained_var: 0.7252193093299866\n",
      "          vf_loss: 0.1892793134228987\n",
      "    num_agent_steps_sampled: 1939224\n",
      "    num_agent_steps_trained: 1939224\n",
      "    num_steps_sampled: 1939224\n",
      "    num_steps_trained: 1939224\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.51412037037038\n",
      "    ram_util_percent: 44.9974537037037\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04991551263077184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.314701437666045\n",
      "    mean_inference_ms: 8.75941246822545\n",
      "    mean_raw_obs_processing_ms: 2.512581952023777\n",
      "  time_since_restore: 59618.4268450737\n",
      "  time_this_iter_s: 303.2756757736206\n",
      "  time_total_s: 59618.4268450737\n",
      "  timers:\n",
      "    learn_throughput: 65.247\n",
      "    learn_time_ms: 153202.907\n",
      "    load_throughput: 88748.646\n",
      "    load_time_ms: 112.633\n",
      "    sample_throughput: 61.743\n",
      "    sample_time_ms: 161898.019\n",
      "    update_time_ms: 10.984\n",
      "  timestamp: 1636960359\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1939224\n",
      "  training_iteration: 194\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">         59618.4</td><td style=\"text-align: right;\">1939224</td><td style=\"text-align: right;\"> 1.72908</td><td style=\"text-align: right;\">                9.11</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           92.6881</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1949220\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-17-56\n",
      "  done: false\n",
      "  episode_len_mean: 91.57407407407408\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.280000000000015\n",
      "  episode_reward_mean: 2.031944444444449\n",
      "  episode_reward_min: -1.6100000000000005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 20142\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6849928704082457\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012358975364353255\n",
      "          policy_loss: -0.03646064313251971\n",
      "          total_loss: 0.11847534002059609\n",
      "          vf_explained_var: 0.8372138142585754\n",
      "          vf_loss: 0.15011120951439963\n",
      "    num_agent_steps_sampled: 1949220\n",
      "    num_agent_steps_trained: 1949220\n",
      "    num_steps_sampled: 1949220\n",
      "    num_steps_trained: 1949220\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.24326710816777\n",
      "    ram_util_percent: 45.10662251655629\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049923906537051935\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.3246618219718\n",
      "    mean_inference_ms: 8.760060797984922\n",
      "    mean_raw_obs_processing_ms: 2.5117035331521516\n",
      "  time_since_restore: 59935.562885284424\n",
      "  time_this_iter_s: 317.1360402107239\n",
      "  time_total_s: 59935.562885284424\n",
      "  timers:\n",
      "    learn_throughput: 65.237\n",
      "    learn_time_ms: 153226.788\n",
      "    load_throughput: 88245.771\n",
      "    load_time_ms: 113.275\n",
      "    sample_throughput: 61.706\n",
      "    sample_time_ms: 161992.85\n",
      "    update_time_ms: 10.577\n",
      "  timestamp: 1636960676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1949220\n",
      "  training_iteration: 195\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         59935.6</td><td style=\"text-align: right;\">1949220</td><td style=\"text-align: right;\"> 2.03194</td><td style=\"text-align: right;\">               10.28</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           91.5741</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1959216\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-23-27\n",
      "  done: false\n",
      "  episode_len_mean: 91.01818181818182\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.930000000000012\n",
      "  episode_reward_mean: 1.7100000000000037\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 20252\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.68362658217422\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011310001333201694\n",
      "          policy_loss: -0.032173991434944746\n",
      "          total_loss: 0.15333277905781745\n",
      "          vf_explained_var: 0.7232828736305237\n",
      "          vf_loss: 0.18335674109462743\n",
      "    num_agent_steps_sampled: 1959216\n",
      "    num_agent_steps_trained: 1959216\n",
      "    num_steps_sampled: 1959216\n",
      "    num_steps_trained: 1959216\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.70741525423728\n",
      "    ram_util_percent: 45.17012711864407\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049924070242230514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.33023772590301\n",
      "    mean_inference_ms: 8.75976071686563\n",
      "    mean_raw_obs_processing_ms: 2.5199131429397736\n",
      "  time_since_restore: 60266.318702697754\n",
      "  time_this_iter_s: 330.7558174133301\n",
      "  time_total_s: 60266.318702697754\n",
      "  timers:\n",
      "    learn_throughput: 65.239\n",
      "    learn_time_ms: 153221.158\n",
      "    load_throughput: 87848.987\n",
      "    load_time_ms: 113.786\n",
      "    sample_throughput: 61.634\n",
      "    sample_time_ms: 162182.575\n",
      "    update_time_ms: 11.345\n",
      "  timestamp: 1636961007\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1959216\n",
      "  training_iteration: 196\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   196</td><td style=\"text-align: right;\">         60266.3</td><td style=\"text-align: right;\">1959216</td><td style=\"text-align: right;\">    1.71</td><td style=\"text-align: right;\">               10.93</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           91.0182</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1969212\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-28-32\n",
      "  done: false\n",
      "  episode_len_mean: 91.07272727272728\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.930000000000014\n",
      "  episode_reward_mean: 1.8711818181818216\n",
      "  episode_reward_min: -1.5000000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 20362\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.688730204411042\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010603491918449948\n",
      "          policy_loss: -0.033184400875057675\n",
      "          total_loss: 0.12783170231582167\n",
      "          vf_explained_var: 0.8144668936729431\n",
      "          vf_loss: 0.16072781562056934\n",
      "    num_agent_steps_sampled: 1969212\n",
      "    num_agent_steps_trained: 1969212\n",
      "    num_steps_sampled: 1969212\n",
      "    num_steps_trained: 1969212\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.95241379310346\n",
      "    ram_util_percent: 45.02206896551723\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049942895403954676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.343022891065765\n",
      "    mean_inference_ms: 8.760778542187088\n",
      "    mean_raw_obs_processing_ms: 2.5114920493730004\n",
      "  time_since_restore: 60571.66587662697\n",
      "  time_this_iter_s: 305.3471739292145\n",
      "  time_total_s: 60571.66587662697\n",
      "  timers:\n",
      "    learn_throughput: 65.241\n",
      "    learn_time_ms: 153217.296\n",
      "    load_throughput: 87611.442\n",
      "    load_time_ms: 114.095\n",
      "    sample_throughput: 61.522\n",
      "    sample_time_ms: 162478.874\n",
      "    update_time_ms: 11.626\n",
      "  timestamp: 1636961312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1969212\n",
      "  training_iteration: 197\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">         60571.7</td><td style=\"text-align: right;\">1969212</td><td style=\"text-align: right;\"> 1.87118</td><td style=\"text-align: right;\">               10.93</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           91.0727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1979208\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-33-37\n",
      "  done: false\n",
      "  episode_len_mean: 92.22222222222223\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.16000000000001\n",
      "  episode_reward_mean: 1.7817592592592628\n",
      "  episode_reward_min: -1.5800000000000007\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 20470\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6866557637850446\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012744283765759793\n",
      "          policy_loss: -0.03179497511293262\n",
      "          total_loss: 0.16014224726897783\n",
      "          vf_explained_var: 0.7432499527931213\n",
      "          vf_loss: 0.18614157455352445\n",
      "    num_agent_steps_sampled: 1979208\n",
      "    num_agent_steps_trained: 1979208\n",
      "    num_steps_sampled: 1979208\n",
      "    num_steps_trained: 1979208\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.5626728110599\n",
      "    ram_util_percent: 44.77880184331797\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04992833737911496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.35889056984232\n",
      "    mean_inference_ms: 8.760702117981806\n",
      "    mean_raw_obs_processing_ms: 2.5032743252247234\n",
      "  time_since_restore: 60875.8219203949\n",
      "  time_this_iter_s: 304.1560437679291\n",
      "  time_total_s: 60875.8219203949\n",
      "  timers:\n",
      "    learn_throughput: 65.231\n",
      "    learn_time_ms: 153240.631\n",
      "    load_throughput: 87768.823\n",
      "    load_time_ms: 113.89\n",
      "    sample_throughput: 61.442\n",
      "    sample_time_ms: 162689.451\n",
      "    update_time_ms: 11.231\n",
      "  timestamp: 1636961617\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1979208\n",
      "  training_iteration: 198\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   198</td><td style=\"text-align: right;\">         60875.8</td><td style=\"text-align: right;\">1979208</td><td style=\"text-align: right;\"> 1.78176</td><td style=\"text-align: right;\">               11.16</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           92.2222</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1989204\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-38-55\n",
      "  done: false\n",
      "  episode_len_mean: 91.46363636363637\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.610000000000014\n",
      "  episode_reward_mean: 1.8791818181818218\n",
      "  episode_reward_min: -1.8200000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 20580\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6949737307352897\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01065220953917905\n",
      "          policy_loss: -0.037213485120620546\n",
      "          total_loss: 0.12918703286375247\n",
      "          vf_explained_var: 0.8053334355354309\n",
      "          vf_loss: 0.16604980746379647\n",
      "    num_agent_steps_sampled: 1989204\n",
      "    num_agent_steps_trained: 1989204\n",
      "    num_steps_sampled: 1989204\n",
      "    num_steps_trained: 1989204\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.83678414096914\n",
      "    ram_util_percent: 45.257048458149775\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049935203974221805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.36572914099787\n",
      "    mean_inference_ms: 8.761186894383918\n",
      "    mean_raw_obs_processing_ms: 2.5183702613224477\n",
      "  time_since_restore: 61193.85548734665\n",
      "  time_this_iter_s: 318.0335669517517\n",
      "  time_total_s: 61193.85548734665\n",
      "  timers:\n",
      "    learn_throughput: 65.256\n",
      "    learn_time_ms: 153181.385\n",
      "    load_throughput: 86701.0\n",
      "    load_time_ms: 115.293\n",
      "    sample_throughput: 61.775\n",
      "    sample_time_ms: 161811.951\n",
      "    update_time_ms: 10.881\n",
      "  timestamp: 1636961935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1989204\n",
      "  training_iteration: 199\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">         61193.9</td><td style=\"text-align: right;\">1989204</td><td style=\"text-align: right;\"> 1.87918</td><td style=\"text-align: right;\">                8.61</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           91.4636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 1999200\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-44-11\n",
      "  done: false\n",
      "  episode_len_mean: 92.19444444444444\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.740000000000014\n",
      "  episode_reward_mean: 1.462592592592596\n",
      "  episode_reward_min: -1.8800000000000008\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 20688\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6938846096014366\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01126054516839455\n",
      "          policy_loss: -0.036225979080678435\n",
      "          total_loss: 0.1278529769054447\n",
      "          vf_explained_var: 0.7838162779808044\n",
      "          vf_loss: 0.1621582561144685\n",
      "    num_agent_steps_sampled: 1999200\n",
      "    num_agent_steps_trained: 1999200\n",
      "    num_steps_sampled: 1999200\n",
      "    num_steps_trained: 1999200\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.09070796460179\n",
      "    ram_util_percent: 45.696460176991145\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994744400108318\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.37413569433342\n",
      "    mean_inference_ms: 8.762121731015826\n",
      "    mean_raw_obs_processing_ms: 2.5122867687548793\n",
      "  time_since_restore: 61510.276814460754\n",
      "  time_this_iter_s: 316.4213271141052\n",
      "  time_total_s: 61510.276814460754\n",
      "  timers:\n",
      "    learn_throughput: 65.268\n",
      "    learn_time_ms: 153152.289\n",
      "    load_throughput: 86197.476\n",
      "    load_time_ms: 115.966\n",
      "    sample_throughput: 61.686\n",
      "    sample_time_ms: 162046.029\n",
      "    update_time_ms: 10.275\n",
      "  timestamp: 1636962251\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1999200\n",
      "  training_iteration: 200\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         61510.3</td><td style=\"text-align: right;\">1999200</td><td style=\"text-align: right;\"> 1.46259</td><td style=\"text-align: right;\">                8.74</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           92.1944</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2009196\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-49-15\n",
      "  done: false\n",
      "  episode_len_mean: 93.26168224299066\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.860000000000014\n",
      "  episode_reward_mean: 2.042990654205612\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 20795\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.683831733821804\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012558018271804614\n",
      "          policy_loss: -0.030690000764627613\n",
      "          total_loss: 0.1701810194326676\n",
      "          vf_explained_var: 0.7883574962615967\n",
      "          vf_loss: 0.19552451065367357\n",
      "    num_agent_steps_sampled: 2009196\n",
      "    num_agent_steps_trained: 2009196\n",
      "    num_steps_sampled: 2009196\n",
      "    num_steps_trained: 2009196\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.44549653579675\n",
      "    ram_util_percent: 45.689607390300225\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994846142867419\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.38672860360496\n",
      "    mean_inference_ms: 8.762582231049933\n",
      "    mean_raw_obs_processing_ms: 2.5025490750315167\n",
      "  time_since_restore: 61813.82745552063\n",
      "  time_this_iter_s: 303.5506410598755\n",
      "  time_total_s: 61813.82745552063\n",
      "  timers:\n",
      "    learn_throughput: 65.247\n",
      "    learn_time_ms: 153201.795\n",
      "    load_throughput: 86135.69\n",
      "    load_time_ms: 116.049\n",
      "    sample_throughput: 61.688\n",
      "    sample_time_ms: 162042.105\n",
      "    update_time_ms: 10.111\n",
      "  timestamp: 1636962555\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2009196\n",
      "  training_iteration: 201\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         61813.8</td><td style=\"text-align: right;\">2009196</td><td style=\"text-align: right;\"> 2.04299</td><td style=\"text-align: right;\">                8.86</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           93.2617</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2019192\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_07-54-47\n",
      "  done: false\n",
      "  episode_len_mean: 91.0909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.980000000000013\n",
      "  episode_reward_mean: 1.8910909090909127\n",
      "  episode_reward_min: -1.980000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 20905\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6775314137466952\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011190557916313527\n",
      "          policy_loss: -0.03020482259308999\n",
      "          total_loss: 0.1600366015277771\n",
      "          vf_explained_var: 0.7911524772644043\n",
      "          vf_loss: 0.18833656359989293\n",
      "    num_agent_steps_sampled: 2019192\n",
      "    num_agent_steps_trained: 2019192\n",
      "    num_steps_sampled: 2019192\n",
      "    num_steps_trained: 2019192\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.90105263157895\n",
      "    ram_util_percent: 45.61347368421053\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049947700656812415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.392027781688235\n",
      "    mean_inference_ms: 8.762390390210218\n",
      "    mean_raw_obs_processing_ms: 2.5148137182906267\n",
      "  time_since_restore: 62146.6654522419\n",
      "  time_this_iter_s: 332.8379967212677\n",
      "  time_total_s: 62146.6654522419\n",
      "  timers:\n",
      "    learn_throughput: 65.241\n",
      "    learn_time_ms: 153216.624\n",
      "    load_throughput: 85753.808\n",
      "    load_time_ms: 116.566\n",
      "    sample_throughput: 61.834\n",
      "    sample_time_ms: 161658.028\n",
      "    update_time_ms: 10.587\n",
      "  timestamp: 1636962887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2019192\n",
      "  training_iteration: 202\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   202</td><td style=\"text-align: right;\">         62146.7</td><td style=\"text-align: right;\">2019192</td><td style=\"text-align: right;\"> 1.89109</td><td style=\"text-align: right;\">                8.98</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           91.0909</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2029188\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-00-05\n",
      "  done: false\n",
      "  episode_len_mean: 91.69444444444444\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.870000000000014\n",
      "  episode_reward_mean: 1.5763888888888917\n",
      "  episode_reward_min: -1.780000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 21013\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6869826446231615\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011988438743278611\n",
      "          policy_loss: -0.03297267098250425\n",
      "          total_loss: 0.15763678165017347\n",
      "          vf_explained_var: 0.7558754682540894\n",
      "          vf_loss: 0.186754223678468\n",
      "    num_agent_steps_sampled: 2029188\n",
      "    num_agent_steps_trained: 2029188\n",
      "    num_steps_sampled: 2029188\n",
      "    num_steps_trained: 2029188\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.00618101545254\n",
      "    ram_util_percent: 45.38719646799116\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049947950429498185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.4000864605002\n",
      "    mean_inference_ms: 8.76305539900944\n",
      "    mean_raw_obs_processing_ms: 2.5096048512709994\n",
      "  time_since_restore: 62464.29005050659\n",
      "  time_this_iter_s: 317.6245982646942\n",
      "  time_total_s: 62464.29005050659\n",
      "  timers:\n",
      "    learn_throughput: 65.222\n",
      "    learn_time_ms: 153260.06\n",
      "    load_throughput: 85947.002\n",
      "    load_time_ms: 116.304\n",
      "    sample_throughput: 61.891\n",
      "    sample_time_ms: 161509.796\n",
      "    update_time_ms: 11.493\n",
      "  timestamp: 1636963205\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2029188\n",
      "  training_iteration: 203\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   203</td><td style=\"text-align: right;\">         62464.3</td><td style=\"text-align: right;\">2029188</td><td style=\"text-align: right;\"> 1.57639</td><td style=\"text-align: right;\">                6.87</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           91.6944</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2039184\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-05-10\n",
      "  done: false\n",
      "  episode_len_mean: 91.98181818181818\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.750000000000012\n",
      "  episode_reward_mean: 1.767000000000004\n",
      "  episode_reward_min: -1.8200000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 21123\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6899104084724037\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010858990622949816\n",
      "          policy_loss: -0.034923039622700366\n",
      "          total_loss: 0.14740730171473937\n",
      "          vf_explained_var: 0.7613874673843384\n",
      "          vf_loss: 0.1813990408148712\n",
      "    num_agent_steps_sampled: 2039184\n",
      "    num_agent_steps_trained: 2039184\n",
      "    num_steps_sampled: 2039184\n",
      "    num_steps_trained: 2039184\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.51862068965518\n",
      "    ram_util_percent: 45.00505747126436\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04995256969251801\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.41288008845555\n",
      "    mean_inference_ms: 8.764010071520804\n",
      "    mean_raw_obs_processing_ms: 2.5033762205121546\n",
      "  time_since_restore: 62769.410121679306\n",
      "  time_this_iter_s: 305.12007117271423\n",
      "  time_total_s: 62769.410121679306\n",
      "  timers:\n",
      "    learn_throughput: 65.241\n",
      "    learn_time_ms: 153215.788\n",
      "    load_throughput: 86027.649\n",
      "    load_time_ms: 116.195\n",
      "    sample_throughput: 61.803\n",
      "    sample_time_ms: 161739.05\n",
      "    update_time_ms: 10.935\n",
      "  timestamp: 1636963510\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2039184\n",
      "  training_iteration: 204\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">         62769.4</td><td style=\"text-align: right;\">2039184</td><td style=\"text-align: right;\">   1.767</td><td style=\"text-align: right;\">                6.75</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           91.9818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2049180\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-10-30\n",
      "  done: false\n",
      "  episode_len_mean: 89.86486486486487\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.510000000000016\n",
      "  episode_reward_mean: 2.018198198198201\n",
      "  episode_reward_min: -1.5800000000000007\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 21234\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.670743899161999\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01134497672296804\n",
      "          policy_loss: -0.0321560760283381\n",
      "          total_loss: 0.1505273237521959\n",
      "          vf_explained_var: 0.7856696844100952\n",
      "          vf_loss: 0.18031490427386174\n",
      "    num_agent_steps_sampled: 2049180\n",
      "    num_agent_steps_trained: 2049180\n",
      "    num_steps_sampled: 2049180\n",
      "    num_steps_trained: 2049180\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.45504385964912\n",
      "    ram_util_percent: 45.01754385964912\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04995373083821097\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.42503465916114\n",
      "    mean_inference_ms: 8.764209585458632\n",
      "    mean_raw_obs_processing_ms: 2.5044511813011168\n",
      "  time_since_restore: 63089.0615735054\n",
      "  time_this_iter_s: 319.6514518260956\n",
      "  time_total_s: 63089.0615735054\n",
      "  timers:\n",
      "    learn_throughput: 65.245\n",
      "    learn_time_ms: 153207.645\n",
      "    load_throughput: 85909.966\n",
      "    load_time_ms: 116.354\n",
      "    sample_throughput: 61.704\n",
      "    sample_time_ms: 161998.591\n",
      "    update_time_ms: 10.96\n",
      "  timestamp: 1636963830\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2049180\n",
      "  training_iteration: 205\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   205</td><td style=\"text-align: right;\">         63089.1</td><td style=\"text-align: right;\">2049180</td><td style=\"text-align: right;\">  2.0182</td><td style=\"text-align: right;\">               10.51</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           89.8649</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2059176\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-16-03\n",
      "  done: false\n",
      "  episode_len_mean: 90.09909909909909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.350000000000016\n",
      "  episode_reward_mean: 1.6234234234234268\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 21345\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.679066807286352\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010835755667733258\n",
      "          policy_loss: -0.03220146562044437\n",
      "          total_loss: 0.15344316678113726\n",
      "          vf_explained_var: 0.7809394598007202\n",
      "          vf_loss: 0.18466444427752468\n",
      "    num_agent_steps_sampled: 2059176\n",
      "    num_agent_steps_trained: 2059176\n",
      "    num_steps_sampled: 2059176\n",
      "    num_steps_trained: 2059176\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.82626050420168\n",
      "    ram_util_percent: 45.32142857142857\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049941758000908824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.43420274154292\n",
      "    mean_inference_ms: 8.763881433635555\n",
      "    mean_raw_obs_processing_ms: 2.5129869184123477\n",
      "  time_since_restore: 63422.1818113327\n",
      "  time_this_iter_s: 333.120237827301\n",
      "  time_total_s: 63422.1818113327\n",
      "  timers:\n",
      "    learn_throughput: 65.224\n",
      "    learn_time_ms: 153255.686\n",
      "    load_throughput: 86553.729\n",
      "    load_time_ms: 115.489\n",
      "    sample_throughput: 61.632\n",
      "    sample_time_ms: 162189.342\n",
      "    update_time_ms: 10.172\n",
      "  timestamp: 1636964163\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2059176\n",
      "  training_iteration: 206\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">         63422.2</td><td style=\"text-align: right;\">2059176</td><td style=\"text-align: right;\"> 1.62342</td><td style=\"text-align: right;\">                8.35</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           90.0991</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2069172\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-21-09\n",
      "  done: false\n",
      "  episode_len_mean: 90.30909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.360000000000014\n",
      "  episode_reward_mean: 1.5766363636363672\n",
      "  episode_reward_min: -1.7700000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 21455\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.665822522354941\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010469083275339025\n",
      "          policy_loss: -0.031113391953448838\n",
      "          total_loss: 0.1594943494695183\n",
      "          vf_explained_var: 0.7438340783119202\n",
      "          vf_loss: 0.19043485122119896\n",
      "    num_agent_steps_sampled: 2069172\n",
      "    num_agent_steps_trained: 2069172\n",
      "    num_steps_sampled: 2069172\n",
      "    num_steps_trained: 2069172\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.65458715596328\n",
      "    ram_util_percent: 45.420642201834866\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049947900726748824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.4486367027599\n",
      "    mean_inference_ms: 8.764173122442195\n",
      "    mean_raw_obs_processing_ms: 2.5065320320411337\n",
      "  time_since_restore: 63727.937073946\n",
      "  time_this_iter_s: 305.7552626132965\n",
      "  time_total_s: 63727.937073946\n",
      "  timers:\n",
      "    learn_throughput: 65.25\n",
      "    learn_time_ms: 153195.062\n",
      "    load_throughput: 87143.681\n",
      "    load_time_ms: 114.707\n",
      "    sample_throughput: 61.592\n",
      "    sample_time_ms: 162293.04\n",
      "    update_time_ms: 10.096\n",
      "  timestamp: 1636964469\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2069172\n",
      "  training_iteration: 207\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   207</td><td style=\"text-align: right;\">         63727.9</td><td style=\"text-align: right;\">2069172</td><td style=\"text-align: right;\"> 1.57664</td><td style=\"text-align: right;\">               10.36</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">           90.3091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2079168\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-26-27\n",
      "  done: false\n",
      "  episode_len_mean: 90.72072072072072\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.680000000000016\n",
      "  episode_reward_mean: 2.0318918918918967\n",
      "  episode_reward_min: -2.0099999999999993\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 21566\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.66404390752825\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011071580410232412\n",
      "          policy_loss: -0.028759032913332438\n",
      "          total_loss: 0.18419146534636552\n",
      "          vf_explained_var: 0.7781946063041687\n",
      "          vf_loss: 0.21121568868382493\n",
      "    num_agent_steps_sampled: 2079168\n",
      "    num_agent_steps_trained: 2079168\n",
      "    num_steps_sampled: 2079168\n",
      "    num_steps_trained: 2079168\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.34017660044151\n",
      "    ram_util_percent: 45.38918322295807\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04995023239747417\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.458999650995075\n",
      "    mean_inference_ms: 8.764848024613576\n",
      "    mean_raw_obs_processing_ms: 2.5051596604381485\n",
      "  time_since_restore: 64045.8749935627\n",
      "  time_this_iter_s: 317.9379196166992\n",
      "  time_total_s: 64045.8749935627\n",
      "  timers:\n",
      "    learn_throughput: 65.256\n",
      "    learn_time_ms: 153180.959\n",
      "    load_throughput: 87163.555\n",
      "    load_time_ms: 114.681\n",
      "    sample_throughput: 61.068\n",
      "    sample_time_ms: 163685.421\n",
      "    update_time_ms: 9.919\n",
      "  timestamp: 1636964787\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2079168\n",
      "  training_iteration: 208\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">         64045.9</td><td style=\"text-align: right;\">2079168</td><td style=\"text-align: right;\"> 2.03189</td><td style=\"text-align: right;\">                8.68</td><td style=\"text-align: right;\">               -2.01</td><td style=\"text-align: right;\">           90.7207</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2089164\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-32-02\n",
      "  done: false\n",
      "  episode_len_mean: 89.53571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.19000000000001\n",
      "  episode_reward_mean: 1.8714285714285743\n",
      "  episode_reward_min: -1.82\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 21678\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.667068792000795\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011249019172804364\n",
      "          policy_loss: -0.03122763892587943\n",
      "          total_loss: 0.161319716884476\n",
      "          vf_explained_var: 0.8083526492118835\n",
      "          vf_loss: 0.1903880381343775\n",
      "    num_agent_steps_sampled: 2089164\n",
      "    num_agent_steps_trained: 2089164\n",
      "    num_steps_sampled: 2089164\n",
      "    num_steps_trained: 2089164\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.64091858037578\n",
      "    ram_util_percent: 45.50605427974949\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994487516098207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.465821684770546\n",
      "    mean_inference_ms: 8.764577777057678\n",
      "    mean_raw_obs_processing_ms: 2.523119197578537\n",
      "  time_since_restore: 64381.03126645088\n",
      "  time_this_iter_s: 335.1562728881836\n",
      "  time_total_s: 64381.03126645088\n",
      "  timers:\n",
      "    learn_throughput: 65.236\n",
      "    learn_time_ms: 153228.137\n",
      "    load_throughput: 88014.78\n",
      "    load_time_ms: 113.572\n",
      "    sample_throughput: 60.453\n",
      "    sample_time_ms: 165350.463\n",
      "    update_time_ms: 10.755\n",
      "  timestamp: 1636965122\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2089164\n",
      "  training_iteration: 209\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">           64381</td><td style=\"text-align: right;\">2089164</td><td style=\"text-align: right;\"> 1.87143</td><td style=\"text-align: right;\">                9.19</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           89.5357</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2099160\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-37-07\n",
      "  done: false\n",
      "  episode_len_mean: 91.64220183486239\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.610000000000014\n",
      "  episode_reward_mean: 1.7315596330275265\n",
      "  episode_reward_min: -1.6200000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 21787\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.681338188892756\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009622087512669407\n",
      "          policy_loss: -0.03257231067579526\n",
      "          total_loss: 0.14422755106710472\n",
      "          vf_explained_var: 0.7939743399620056\n",
      "          vf_loss: 0.17895288610488622\n",
      "    num_agent_steps_sampled: 2099160\n",
      "    num_agent_steps_trained: 2099160\n",
      "    num_steps_sampled: 2099160\n",
      "    num_steps_trained: 2099160\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.6258064516129\n",
      "    ram_util_percent: 45.74700460829493\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994714112188005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.47840944747746\n",
      "    mean_inference_ms: 8.76536063704789\n",
      "    mean_raw_obs_processing_ms: 2.5117817883865428\n",
      "  time_since_restore: 64685.53667163849\n",
      "  time_this_iter_s: 304.5054051876068\n",
      "  time_total_s: 64685.53667163849\n",
      "  timers:\n",
      "    learn_throughput: 65.227\n",
      "    learn_time_ms: 153248.287\n",
      "    load_throughput: 88460.056\n",
      "    load_time_ms: 113.0\n",
      "    sample_throughput: 60.899\n",
      "    sample_time_ms: 164139.723\n",
      "    update_time_ms: 11.006\n",
      "  timestamp: 1636965427\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2099160\n",
      "  training_iteration: 210\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   210</td><td style=\"text-align: right;\">         64685.5</td><td style=\"text-align: right;\">2099160</td><td style=\"text-align: right;\"> 1.73156</td><td style=\"text-align: right;\">                8.61</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">           91.6422</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2109156\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-42-12\n",
      "  done: false\n",
      "  episode_len_mean: 92.01851851851852\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.090000000000009\n",
      "  episode_reward_mean: 2.017500000000004\n",
      "  episode_reward_min: -1.970000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 21895\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6754159572796943\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012907151090432303\n",
      "          policy_loss: -0.02884280165641481\n",
      "          total_loss: 0.20249086292739163\n",
      "          vf_explained_var: 0.7634546756744385\n",
      "          vf_loss: 0.22500820849449016\n",
      "    num_agent_steps_sampled: 2109156\n",
      "    num_agent_steps_trained: 2109156\n",
      "    num_steps_sampled: 2109156\n",
      "    num_steps_trained: 2109156\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.58436781609194\n",
      "    ram_util_percent: 45.64275862068966\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994187100107722\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.49162197365569\n",
      "    mean_inference_ms: 8.765636957710472\n",
      "    mean_raw_obs_processing_ms: 2.505453316774672\n",
      "  time_since_restore: 64990.497087955475\n",
      "  time_this_iter_s: 304.9604163169861\n",
      "  time_total_s: 64990.497087955475\n",
      "  timers:\n",
      "    learn_throughput: 65.21\n",
      "    learn_time_ms: 153290.452\n",
      "    load_throughput: 88846.272\n",
      "    load_time_ms: 112.509\n",
      "    sample_throughput: 60.863\n",
      "    sample_time_ms: 164238.288\n",
      "    update_time_ms: 11.824\n",
      "  timestamp: 1636965732\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2109156\n",
      "  training_iteration: 211\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   211</td><td style=\"text-align: right;\">         64990.5</td><td style=\"text-align: right;\">2109156</td><td style=\"text-align: right;\">  2.0175</td><td style=\"text-align: right;\">                9.09</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           92.0185</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2119152\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-47-32\n",
      "  done: false\n",
      "  episode_len_mean: 90.39090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.610000000000012\n",
      "  episode_reward_mean: 1.9736363636363676\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 22005\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6541533654571596\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011703755685281352\n",
      "          policy_loss: -0.03079819467284868\n",
      "          total_loss: 0.16605648581519658\n",
      "          vf_explained_var: 0.7810791730880737\n",
      "          vf_loss: 0.19340076966760442\n",
      "    num_agent_steps_sampled: 2119152\n",
      "    num_agent_steps_trained: 2119152\n",
      "    num_steps_sampled: 2119152\n",
      "    num_steps_trained: 2119152\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.83982494529539\n",
      "    ram_util_percent: 45.541137855579876\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04993702842451749\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.50242887096072\n",
      "    mean_inference_ms: 8.765709857063088\n",
      "    mean_raw_obs_processing_ms: 2.515549819415526\n",
      "  time_since_restore: 65310.451463222504\n",
      "  time_this_iter_s: 319.9543752670288\n",
      "  time_total_s: 65310.451463222504\n",
      "  timers:\n",
      "    learn_throughput: 65.242\n",
      "    learn_time_ms: 153215.05\n",
      "    load_throughput: 89372.721\n",
      "    load_time_ms: 111.846\n",
      "    sample_throughput: 61.315\n",
      "    sample_time_ms: 163027.277\n",
      "    update_time_ms: 11.196\n",
      "  timestamp: 1636966052\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2119152\n",
      "  training_iteration: 212\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">         65310.5</td><td style=\"text-align: right;\">2119152</td><td style=\"text-align: right;\"> 1.97364</td><td style=\"text-align: right;\">                8.61</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           90.3909</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2129148\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-52-50\n",
      "  done: false\n",
      "  episode_len_mean: 90.67567567567568\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.520000000000012\n",
      "  episode_reward_mean: 2.1023423423423466\n",
      "  episode_reward_min: -1.9900000000000009\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 22116\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6571500996239164\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01022178640866476\n",
      "          policy_loss: -0.03440222450110138\n",
      "          total_loss: 0.14834693115419492\n",
      "          vf_explained_var: 0.8094053864479065\n",
      "          vf_loss: 0.18312333634712247\n",
      "    num_agent_steps_sampled: 2129148\n",
      "    num_agent_steps_trained: 2129148\n",
      "    num_steps_sampled: 2129148\n",
      "    num_steps_trained: 2129148\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.03942731277533\n",
      "    ram_util_percent: 45.55198237885463\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049938981764114675\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.51055935988069\n",
      "    mean_inference_ms: 8.766270936076008\n",
      "    mean_raw_obs_processing_ms: 2.510166294019532\n",
      "  time_since_restore: 65629.16343998909\n",
      "  time_this_iter_s: 318.7119767665863\n",
      "  time_total_s: 65629.16343998909\n",
      "  timers:\n",
      "    learn_throughput: 65.253\n",
      "    learn_time_ms: 153188.1\n",
      "    load_throughput: 88883.623\n",
      "    load_time_ms: 112.462\n",
      "    sample_throughput: 61.264\n",
      "    sample_time_ms: 163162.739\n",
      "    update_time_ms: 10.635\n",
      "  timestamp: 1636966370\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2129148\n",
      "  training_iteration: 213\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   213</td><td style=\"text-align: right;\">         65629.2</td><td style=\"text-align: right;\">2129148</td><td style=\"text-align: right;\"> 2.10234</td><td style=\"text-align: right;\">               12.52</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           90.6757</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2139144\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_08-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 91.1559633027523\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.600000000000014\n",
      "  episode_reward_mean: 1.4143119266055078\n",
      "  episode_reward_min: -1.7000000000000006\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 22225\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.677157161276565\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009625145661582804\n",
      "          policy_loss: -0.031062986020150028\n",
      "          total_loss: 0.11763859732856607\n",
      "          vf_explained_var: 0.7552592158317566\n",
      "          vf_loss: 0.15080495919697942\n",
      "    num_agent_steps_sampled: 2139144\n",
      "    num_agent_steps_trained: 2139144\n",
      "    num_steps_sampled: 2139144\n",
      "    num_steps_trained: 2139144\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.64599542334096\n",
      "    ram_util_percent: 45.559725400457666\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0499515337656905\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.52296865056617\n",
      "    mean_inference_ms: 8.766777636694647\n",
      "    mean_raw_obs_processing_ms: 2.506258316321259\n",
      "  time_since_restore: 65935.35177993774\n",
      "  time_this_iter_s: 306.1883399486542\n",
      "  time_total_s: 65935.35177993774\n",
      "  timers:\n",
      "    learn_throughput: 65.232\n",
      "    learn_time_ms: 153237.335\n",
      "    load_throughput: 88333.247\n",
      "    load_time_ms: 113.162\n",
      "    sample_throughput: 61.243\n",
      "    sample_time_ms: 163218.737\n",
      "    update_time_ms: 11.6\n",
      "  timestamp: 1636966677\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2139144\n",
      "  training_iteration: 214\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   214</td><td style=\"text-align: right;\">         65935.4</td><td style=\"text-align: right;\">2139144</td><td style=\"text-align: right;\"> 1.41431</td><td style=\"text-align: right;\">                10.6</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">            91.156</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2149140\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-03-20\n",
      "  done: false\n",
      "  episode_len_mean: 90.51351351351352\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.850000000000014\n",
      "  episode_reward_mean: 1.9838738738738777\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 22336\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6622873172800765\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010674104621337673\n",
      "          policy_loss: -0.033326922965228045\n",
      "          total_loss: 0.16640277790924551\n",
      "          vf_explained_var: 0.736659049987793\n",
      "          vf_loss: 0.19899601120716678\n",
      "    num_agent_steps_sampled: 2149140\n",
      "    num_agent_steps_trained: 2149140\n",
      "    num_steps_sampled: 2149140\n",
      "    num_steps_trained: 2149140\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.1577922077922\n",
      "    ram_util_percent: 45.29718614718615\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994137988149268\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.535245234778806\n",
      "    mean_inference_ms: 8.76689335840911\n",
      "    mean_raw_obs_processing_ms: 2.512597151469557\n",
      "  time_since_restore: 66259.02838206291\n",
      "  time_this_iter_s: 323.67660212516785\n",
      "  time_total_s: 66259.02838206291\n",
      "  timers:\n",
      "    learn_throughput: 65.24\n",
      "    learn_time_ms: 153219.16\n",
      "    load_throughput: 88645.143\n",
      "    load_time_ms: 112.764\n",
      "    sample_throughput: 61.086\n",
      "    sample_time_ms: 163639.024\n",
      "    update_time_ms: 11.992\n",
      "  timestamp: 1636967000\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2149140\n",
      "  training_iteration: 215\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   215</td><td style=\"text-align: right;\">           66259</td><td style=\"text-align: right;\">2149140</td><td style=\"text-align: right;\"> 1.98387</td><td style=\"text-align: right;\">               10.85</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           90.5135</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2159136\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-08-39\n",
      "  done: false\n",
      "  episode_len_mean: 90.80909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.890000000000011\n",
      "  episode_reward_mean: 1.6804545454545492\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 22446\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.669182993713607\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010217388200850113\n",
      "          policy_loss: -0.03358774600455012\n",
      "          total_loss: 0.1573351514310791\n",
      "          vf_explained_var: 0.7234303951263428\n",
      "          vf_loss: 0.19142867979338854\n",
      "    num_agent_steps_sampled: 2159136\n",
      "    num_agent_steps_trained: 2159136\n",
      "    num_steps_sampled: 2159136\n",
      "    num_steps_trained: 2159136\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.28659340659341\n",
      "    ram_util_percent: 45.511868131868134\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0499530358391075\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.54269110494531\n",
      "    mean_inference_ms: 8.767830000435584\n",
      "    mean_raw_obs_processing_ms: 2.508518337763579\n",
      "  time_since_restore: 66577.80048179626\n",
      "  time_this_iter_s: 318.77209973335266\n",
      "  time_total_s: 66577.80048179626\n",
      "  timers:\n",
      "    learn_throughput: 65.231\n",
      "    learn_time_ms: 153240.726\n",
      "    load_throughput: 88454.289\n",
      "    load_time_ms: 113.008\n",
      "    sample_throughput: 61.635\n",
      "    sample_time_ms: 162181.859\n",
      "    update_time_ms: 11.846\n",
      "  timestamp: 1636967319\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2159136\n",
      "  training_iteration: 216\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   216</td><td style=\"text-align: right;\">         66577.8</td><td style=\"text-align: right;\">2159136</td><td style=\"text-align: right;\"> 1.68045</td><td style=\"text-align: right;\">                8.89</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           90.8091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2169132\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-13-46\n",
      "  done: false\n",
      "  episode_len_mean: 91.54128440366972\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.60000000000001\n",
      "  episode_reward_mean: 1.8648623853211048\n",
      "  episode_reward_min: -1.6700000000000008\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 22555\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6584719264609182\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010453423759049615\n",
      "          policy_loss: -0.033278805284928055\n",
      "          total_loss: 0.14977601814266836\n",
      "          vf_explained_var: 0.8031820058822632\n",
      "          vf_loss: 0.18284856086660528\n",
      "    num_agent_steps_sampled: 2169132\n",
      "    num_agent_steps_trained: 2169132\n",
      "    num_steps_sampled: 2169132\n",
      "    num_steps_trained: 2169132\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.53226544622426\n",
      "    ram_util_percent: 45.48009153318077\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04994720258049411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.55657469637681\n",
      "    mean_inference_ms: 8.768085982961075\n",
      "    mean_raw_obs_processing_ms: 2.505562247054426\n",
      "  time_since_restore: 66884.2513923645\n",
      "  time_this_iter_s: 306.4509105682373\n",
      "  time_total_s: 66884.2513923645\n",
      "  timers:\n",
      "    learn_throughput: 65.229\n",
      "    learn_time_ms: 153244.46\n",
      "    load_throughput: 87793.12\n",
      "    load_time_ms: 113.859\n",
      "    sample_throughput: 61.61\n",
      "    sample_time_ms: 162246.153\n",
      "    update_time_ms: 11.39\n",
      "  timestamp: 1636967626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2169132\n",
      "  training_iteration: 217\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   217</td><td style=\"text-align: right;\">         66884.3</td><td style=\"text-align: right;\">2169132</td><td style=\"text-align: right;\"> 1.86486</td><td style=\"text-align: right;\">                 8.6</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           91.5413</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2179128\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-19-06\n",
      "  done: false\n",
      "  episode_len_mean: 90.43243243243244\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.610000000000014\n",
      "  episode_reward_mean: 1.8299099099099136\n",
      "  episode_reward_min: -1.9300000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 22666\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6576466464588786\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010840674505228192\n",
      "          policy_loss: -0.034212669142338836\n",
      "          total_loss: 0.1649359533778177\n",
      "          vf_explained_var: 0.7498178482055664\n",
      "          vf_loss: 0.19794162650688146\n",
      "    num_agent_steps_sampled: 2179128\n",
      "    num_agent_steps_trained: 2179128\n",
      "    num_steps_sampled: 2179128\n",
      "    num_steps_trained: 2179128\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.03078602620087\n",
      "    ram_util_percent: 45.26986899563318\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04995764330077273\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.567419167617636\n",
      "    mean_inference_ms: 8.76852731653374\n",
      "    mean_raw_obs_processing_ms: 2.5122579722103873\n",
      "  time_since_restore: 67204.92059135437\n",
      "  time_this_iter_s: 320.66919898986816\n",
      "  time_total_s: 67204.92059135437\n",
      "  timers:\n",
      "    learn_throughput: 65.221\n",
      "    learn_time_ms: 153263.69\n",
      "    load_throughput: 87364.727\n",
      "    load_time_ms: 114.417\n",
      "    sample_throughput: 61.514\n",
      "    sample_time_ms: 162499.84\n",
      "    update_time_ms: 11.794\n",
      "  timestamp: 1636967946\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2179128\n",
      "  training_iteration: 218\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">         67204.9</td><td style=\"text-align: right;\">2179128</td><td style=\"text-align: right;\"> 1.82991</td><td style=\"text-align: right;\">               12.61</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">           90.4324</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2189124\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-24-41\n",
      "  done: false\n",
      "  episode_len_mean: 89.85585585585585\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.440000000000012\n",
      "  episode_reward_mean: 2.0928828828828867\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 22777\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.657847427099179\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011662191529346925\n",
      "          policy_loss: -0.029920019856335706\n",
      "          total_loss: 0.20628403775218843\n",
      "          vf_explained_var: 0.7585468888282776\n",
      "          vf_loss: 0.2328936114270463\n",
      "    num_agent_steps_sampled: 2189124\n",
      "    num_agent_steps_trained: 2189124\n",
      "    num_steps_sampled: 2189124\n",
      "    num_steps_trained: 2189124\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.5836820083682\n",
      "    ram_util_percent: 45.52259414225942\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04993418260405198\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.58166628534951\n",
      "    mean_inference_ms: 8.767980410607604\n",
      "    mean_raw_obs_processing_ms: 2.519370626292069\n",
      "  time_since_restore: 67539.9295706749\n",
      "  time_this_iter_s: 335.0089793205261\n",
      "  time_total_s: 67539.9295706749\n",
      "  timers:\n",
      "    learn_throughput: 65.208\n",
      "    learn_time_ms: 153294.54\n",
      "    load_throughput: 87450.191\n",
      "    load_time_ms: 114.305\n",
      "    sample_throughput: 61.531\n",
      "    sample_time_ms: 162453.742\n",
      "    update_time_ms: 11.939\n",
      "  timestamp: 1636968281\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2189124\n",
      "  training_iteration: 219\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   219</td><td style=\"text-align: right;\">         67539.9</td><td style=\"text-align: right;\">2189124</td><td style=\"text-align: right;\"> 2.09288</td><td style=\"text-align: right;\">               10.44</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           89.8559</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2199120\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-29-47\n",
      "  done: false\n",
      "  episode_len_mean: 91.24545454545455\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.910000000000013\n",
      "  episode_reward_mean: 1.4557272727272763\n",
      "  episode_reward_min: -1.7100000000000006\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 22887\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6588305961372507\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010326471682645921\n",
      "          policy_loss: -0.03306561791473347\n",
      "          total_loss: 0.15218492426837865\n",
      "          vf_explained_var: 0.7473633289337158\n",
      "          vf_loss: 0.18537323117001445\n",
      "    num_agent_steps_sampled: 2199120\n",
      "    num_agent_steps_trained: 2199120\n",
      "    num_steps_sampled: 2199120\n",
      "    num_steps_trained: 2199120\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.68646788990824\n",
      "    ram_util_percent: 45.31192660550459\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04996649224037306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.59174440515759\n",
      "    mean_inference_ms: 8.76944050625874\n",
      "    mean_raw_obs_processing_ms: 2.5108010074427396\n",
      "  time_since_restore: 67845.57938194275\n",
      "  time_this_iter_s: 305.6498112678528\n",
      "  time_total_s: 67845.57938194275\n",
      "  timers:\n",
      "    learn_throughput: 65.241\n",
      "    learn_time_ms: 153217.672\n",
      "    load_throughput: 87323.804\n",
      "    load_time_ms: 114.471\n",
      "    sample_throughput: 61.459\n",
      "    sample_time_ms: 162643.729\n",
      "    update_time_ms: 12.988\n",
      "  timestamp: 1636968587\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2199120\n",
      "  training_iteration: 220\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   220</td><td style=\"text-align: right;\">         67845.6</td><td style=\"text-align: right;\">2199120</td><td style=\"text-align: right;\"> 1.45573</td><td style=\"text-align: right;\">                8.91</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           91.2455</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2209116\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-34-55\n",
      "  done: false\n",
      "  episode_len_mean: 91.04587155963303\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.540000000000013\n",
      "  episode_reward_mean: 1.8864220183486275\n",
      "  episode_reward_min: -1.780000000000001\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 22996\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.658036321758205\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011318483982633942\n",
      "          policy_loss: -0.0322260540852355\n",
      "          total_loss: 0.14876301153204763\n",
      "          vf_explained_var: 0.8129165768623352\n",
      "          vf_loss: 0.17856139328219314\n",
      "    num_agent_steps_sampled: 2209116\n",
      "    num_agent_steps_trained: 2209116\n",
      "    num_steps_sampled: 2209116\n",
      "    num_steps_trained: 2209116\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.10795454545455\n",
      "    ram_util_percent: 45.14295454545455\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049953400237765455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.60978762929688\n",
      "    mean_inference_ms: 8.769692406286586\n",
      "    mean_raw_obs_processing_ms: 2.504792599904491\n",
      "  time_since_restore: 68153.99404382706\n",
      "  time_this_iter_s: 308.41466188430786\n",
      "  time_total_s: 68153.99404382706\n",
      "  timers:\n",
      "    learn_throughput: 65.244\n",
      "    learn_time_ms: 153209.763\n",
      "    load_throughput: 86785.637\n",
      "    load_time_ms: 115.18\n",
      "    sample_throughput: 61.327\n",
      "    sample_time_ms: 162995.955\n",
      "    update_time_ms: 12.749\n",
      "  timestamp: 1636968895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2209116\n",
      "  training_iteration: 221\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   221</td><td style=\"text-align: right;\">           68154</td><td style=\"text-align: right;\">2209116</td><td style=\"text-align: right;\"> 1.88642</td><td style=\"text-align: right;\">                8.54</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           91.0459</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2219112\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-40-31\n",
      "  done: false\n",
      "  episode_len_mean: 88.12280701754386\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.080000000000009\n",
      "  episode_reward_mean: 1.4207017543859675\n",
      "  episode_reward_min: -1.850000000000001\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 23110\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6526459677606566\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010779408968897548\n",
      "          policy_loss: -0.03278481591906812\n",
      "          total_loss: 0.14167192345803492\n",
      "          vf_explained_var: 0.7944818735122681\n",
      "          vf_loss: 0.17335675346752644\n",
      "    num_agent_steps_sampled: 2219112\n",
      "    num_agent_steps_trained: 2219112\n",
      "    num_steps_sampled: 2219112\n",
      "    num_steps_trained: 2219112\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.51276150627615\n",
      "    ram_util_percent: 45.55962343096233\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04997033136634643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.616379969450776\n",
      "    mean_inference_ms: 8.769890535355959\n",
      "    mean_raw_obs_processing_ms: 2.520350667210648\n",
      "  time_since_restore: 68489.1124958992\n",
      "  time_this_iter_s: 335.11845207214355\n",
      "  time_total_s: 68489.1124958992\n",
      "  timers:\n",
      "    learn_throughput: 65.222\n",
      "    learn_time_ms: 153260.052\n",
      "    load_throughput: 86183.461\n",
      "    load_time_ms: 115.985\n",
      "    sample_throughput: 60.781\n",
      "    sample_time_ms: 164460.231\n",
      "    update_time_ms: 13.059\n",
      "  timestamp: 1636969231\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2219112\n",
      "  training_iteration: 222\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   222</td><td style=\"text-align: right;\">         68489.1</td><td style=\"text-align: right;\">2219112</td><td style=\"text-align: right;\">  1.4207</td><td style=\"text-align: right;\">                9.08</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           88.1228</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2229108\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-45-38\n",
      "  done: false\n",
      "  episode_len_mean: 90.35135135135135\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.910000000000018\n",
      "  episode_reward_mean: 1.8961261261261297\n",
      "  episode_reward_min: -1.699999999999997\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 23221\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6453425745678762\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011695150764755958\n",
      "          policy_loss: -0.031289364746174754\n",
      "          total_loss: 0.16005969563395614\n",
      "          vf_explained_var: 0.7956774234771729\n",
      "          vf_loss: 0.18782909417158772\n",
      "    num_agent_steps_sampled: 2229108\n",
      "    num_agent_steps_trained: 2229108\n",
      "    num_steps_sampled: 2229108\n",
      "    num_steps_trained: 2229108\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.83858447488585\n",
      "    ram_util_percent: 45.717808219178096\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04996079282585158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.63234711855346\n",
      "    mean_inference_ms: 8.769937938062233\n",
      "    mean_raw_obs_processing_ms: 2.5124700468152596\n",
      "  time_since_restore: 68796.3101336956\n",
      "  time_this_iter_s: 307.197637796402\n",
      "  time_total_s: 68796.3101336956\n",
      "  timers:\n",
      "    learn_throughput: 65.218\n",
      "    learn_time_ms: 153270.599\n",
      "    load_throughput: 86157.355\n",
      "    load_time_ms: 116.02\n",
      "    sample_throughput: 61.213\n",
      "    sample_time_ms: 163298.194\n",
      "    update_time_ms: 13.37\n",
      "  timestamp: 1636969538\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2229108\n",
      "  training_iteration: 223\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   223</td><td style=\"text-align: right;\">         68796.3</td><td style=\"text-align: right;\">2229108</td><td style=\"text-align: right;\"> 1.89613</td><td style=\"text-align: right;\">               10.91</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           90.3514</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2239104\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-50-45\n",
      "  done: false\n",
      "  episode_len_mean: 90.57272727272728\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.090000000000009\n",
      "  episode_reward_mean: 1.653000000000004\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 23331\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.653941658826975\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011757761919655328\n",
      "          policy_loss: -0.029566756326259457\n",
      "          total_loss: 0.18872599160601186\n",
      "          vf_explained_var: 0.7812633514404297\n",
      "          vf_loss: 0.21469830710890617\n",
      "    num_agent_steps_sampled: 2239104\n",
      "    num_agent_steps_trained: 2239104\n",
      "    num_steps_sampled: 2239104\n",
      "    num_steps_trained: 2239104\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.5986332574032\n",
      "    ram_util_percent: 45.56127562642369\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04997803488947364\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.64347268367265\n",
      "    mean_inference_ms: 8.771047936762288\n",
      "    mean_raw_obs_processing_ms: 2.5040548802677614\n",
      "  time_since_restore: 69103.77583098412\n",
      "  time_this_iter_s: 307.4656972885132\n",
      "  time_total_s: 69103.77583098412\n",
      "  timers:\n",
      "    learn_throughput: 65.199\n",
      "    learn_time_ms: 153314.529\n",
      "    load_throughput: 86583.883\n",
      "    load_time_ms: 115.449\n",
      "    sample_throughput: 61.181\n",
      "    sample_time_ms: 163383.455\n",
      "    update_time_ms: 12.385\n",
      "  timestamp: 1636969845\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2239104\n",
      "  training_iteration: 224\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">         69103.8</td><td style=\"text-align: right;\">2239104</td><td style=\"text-align: right;\">   1.653</td><td style=\"text-align: right;\">                7.09</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           90.5727</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2249100\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_09-56-24\n",
      "  done: false\n",
      "  episode_len_mean: 88.91964285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.730000000000015\n",
      "  episode_reward_mean: 1.7843750000000038\n",
      "  episode_reward_min: -1.810000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 23443\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6540121246606874\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011392477553918397\n",
      "          policy_loss: -0.027510592587387715\n",
      "          total_loss: 0.18226634993090526\n",
      "          vf_explained_var: 0.7697514891624451\n",
      "          vf_loss: 0.2071193908396949\n",
      "    num_agent_steps_sampled: 2249100\n",
      "    num_agent_steps_trained: 2249100\n",
      "    num_steps_sampled: 2249100\n",
      "    num_steps_trained: 2249100\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.55942028985508\n",
      "    ram_util_percent: 45.285093167701866\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04997157335804784\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.65641059144796\n",
      "    mean_inference_ms: 8.77098054557594\n",
      "    mean_raw_obs_processing_ms: 2.5186261083616657\n",
      "  time_since_restore: 69442.38962435722\n",
      "  time_this_iter_s: 338.6137933731079\n",
      "  time_total_s: 69442.38962435722\n",
      "  timers:\n",
      "    learn_throughput: 65.225\n",
      "    learn_time_ms: 153253.023\n",
      "    load_throughput: 86351.841\n",
      "    load_time_ms: 115.759\n",
      "    sample_throughput: 60.604\n",
      "    sample_time_ms: 164938.437\n",
      "    update_time_ms: 12.489\n",
      "  timestamp: 1636970184\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2249100\n",
      "  training_iteration: 225\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   225</td><td style=\"text-align: right;\">         69442.4</td><td style=\"text-align: right;\">2249100</td><td style=\"text-align: right;\"> 1.78438</td><td style=\"text-align: right;\">               12.73</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           88.9196</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2259096\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-01-37\n",
      "  done: false\n",
      "  episode_len_mean: 90.38738738738739\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.860000000000012\n",
      "  episode_reward_mean: 2.0508108108108147\n",
      "  episode_reward_min: -1.8500000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 23554\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6524330833019354\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012439693256184261\n",
      "          policy_loss: -0.02818745534118806\n",
      "          total_loss: 0.18902719625486777\n",
      "          vf_explained_var: 0.7765949368476868\n",
      "          vf_loss: 0.21185740999495373\n",
      "    num_agent_steps_sampled: 2259096\n",
      "    num_agent_steps_trained: 2259096\n",
      "    num_steps_sampled: 2259096\n",
      "    num_steps_trained: 2259096\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.6535874439462\n",
      "    ram_util_percent: 45.31591928251122\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04995871351118763\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.67316044907194\n",
      "    mean_inference_ms: 8.770692981976607\n",
      "    mean_raw_obs_processing_ms: 2.51557636163437\n",
      "  time_since_restore: 69754.89149427414\n",
      "  time_this_iter_s: 312.5018699169159\n",
      "  time_total_s: 69754.89149427414\n",
      "  timers:\n",
      "    learn_throughput: 65.229\n",
      "    learn_time_ms: 153243.728\n",
      "    load_throughput: 86199.94\n",
      "    load_time_ms: 115.963\n",
      "    sample_throughput: 60.832\n",
      "    sample_time_ms: 164320.83\n",
      "    update_time_ms: 12.409\n",
      "  timestamp: 1636970497\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2259096\n",
      "  training_iteration: 226\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   226</td><td style=\"text-align: right;\">         69754.9</td><td style=\"text-align: right;\">2259096</td><td style=\"text-align: right;\"> 2.05081</td><td style=\"text-align: right;\">               12.86</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           90.3874</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2269092\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-06-48\n",
      "  done: false\n",
      "  episode_len_mean: 89.94594594594595\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.400000000000013\n",
      "  episode_reward_mean: 1.679639639639643\n",
      "  episode_reward_min: -1.9900000000000009\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 23665\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6518984347327144\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012069926304436535\n",
      "          policy_loss: -0.031060986337450962\n",
      "          total_loss: 0.1753795258827213\n",
      "          vf_explained_var: 0.765267550945282\n",
      "          vf_loss: 0.2020255962291207\n",
      "    num_agent_steps_sampled: 2269092\n",
      "    num_agent_steps_trained: 2269092\n",
      "    num_steps_sampled: 2269092\n",
      "    num_steps_trained: 2269092\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.70135135135133\n",
      "    ram_util_percent: 45.16734234234235\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04997747603581556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.69112299945435\n",
      "    mean_inference_ms: 8.771607809203012\n",
      "    mean_raw_obs_processing_ms: 2.5053273050191396\n",
      "  time_since_restore: 70065.90494585037\n",
      "  time_this_iter_s: 311.0134515762329\n",
      "  time_total_s: 70065.90494585037\n",
      "  timers:\n",
      "    learn_throughput: 65.211\n",
      "    learn_time_ms: 153286.441\n",
      "    load_throughput: 86086.081\n",
      "    load_time_ms: 116.116\n",
      "    sample_throughput: 60.68\n",
      "    sample_time_ms: 164734.325\n",
      "    update_time_ms: 12.582\n",
      "  timestamp: 1636970808\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2269092\n",
      "  training_iteration: 227\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   227</td><td style=\"text-align: right;\">         70065.9</td><td style=\"text-align: right;\">2269092</td><td style=\"text-align: right;\"> 1.67964</td><td style=\"text-align: right;\">                10.4</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           89.9459</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2279088\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-12-18\n",
      "  done: false\n",
      "  episode_len_mean: 89.24778761061947\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.730000000000011\n",
      "  episode_reward_mean: 1.8716814159292072\n",
      "  episode_reward_min: -1.6000000000000008\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 23778\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.64360246077562\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012718352069583041\n",
      "          policy_loss: -0.028110237033544188\n",
      "          total_loss: 0.18380273071666942\n",
      "          vf_explained_var: 0.7981483340263367\n",
      "          vf_loss: 0.20575324781159432\n",
      "    num_agent_steps_sampled: 2279088\n",
      "    num_agent_steps_trained: 2279088\n",
      "    num_steps_sampled: 2279088\n",
      "    num_steps_trained: 2279088\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.87133757961782\n",
      "    ram_util_percent: 45.167515923566874\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04996879370432128\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.7139954941352\n",
      "    mean_inference_ms: 8.77188540741456\n",
      "    mean_raw_obs_processing_ms: 2.506867997665124\n",
      "  time_since_restore: 70396.07019853592\n",
      "  time_this_iter_s: 330.1652526855469\n",
      "  time_total_s: 70396.07019853592\n",
      "  timers:\n",
      "    learn_throughput: 65.239\n",
      "    learn_time_ms: 153220.098\n",
      "    load_throughput: 86658.511\n",
      "    load_time_ms: 115.349\n",
      "    sample_throughput: 60.307\n",
      "    sample_time_ms: 165751.131\n",
      "    update_time_ms: 11.953\n",
      "  timestamp: 1636971138\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2279088\n",
      "  training_iteration: 228\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   228</td><td style=\"text-align: right;\">         70396.1</td><td style=\"text-align: right;\">2279088</td><td style=\"text-align: right;\"> 1.87168</td><td style=\"text-align: right;\">               10.73</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           89.2478</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2289084\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-17-46\n",
      "  done: false\n",
      "  episode_len_mean: 87.68141592920354\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.670000000000014\n",
      "  episode_reward_mean: 1.7923008849557558\n",
      "  episode_reward_min: -1.4700000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 23891\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6460152393732317\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011849079046206452\n",
      "          policy_loss: -0.02902691475310737\n",
      "          total_loss: 0.14801791804319278\n",
      "          vf_explained_var: 0.8044949769973755\n",
      "          vf_loss: 0.17313709217004286\n",
      "    num_agent_steps_sampled: 2289084\n",
      "    num_agent_steps_trained: 2289084\n",
      "    num_steps_sampled: 2289084\n",
      "    num_steps_trained: 2289084\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.0861407249467\n",
      "    ram_util_percent: 45.33965884861407\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049964765367515394\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.73246172817457\n",
      "    mean_inference_ms: 8.772333745951991\n",
      "    mean_raw_obs_processing_ms: 2.5116525673320105\n",
      "  time_since_restore: 70724.76240468025\n",
      "  time_this_iter_s: 328.6922061443329\n",
      "  time_total_s: 70724.76240468025\n",
      "  timers:\n",
      "    learn_throughput: 65.234\n",
      "    learn_time_ms: 153233.5\n",
      "    load_throughput: 86461.769\n",
      "    load_time_ms: 115.612\n",
      "    sample_throughput: 60.542\n",
      "    sample_time_ms: 165107.293\n",
      "    update_time_ms: 11.06\n",
      "  timestamp: 1636971466\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2289084\n",
      "  training_iteration: 229\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   229</td><td style=\"text-align: right;\">         70724.8</td><td style=\"text-align: right;\">2289084</td><td style=\"text-align: right;\">  1.7923</td><td style=\"text-align: right;\">                8.67</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           87.6814</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2299080\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-23-02\n",
      "  done: false\n",
      "  episode_len_mean: 90.35135135135135\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.720000000000013\n",
      "  episode_reward_mean: 1.783603603603607\n",
      "  episode_reward_min: -2.3199999999999976\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 24002\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6593215064105826\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011163198770953524\n",
      "          policy_loss: -0.031082759091121136\n",
      "          total_loss: 0.1333415869396562\n",
      "          vf_explained_var: 0.8143333792686462\n",
      "          vf_loss: 0.16240750373396864\n",
      "    num_agent_steps_sampled: 2299080\n",
      "    num_agent_steps_trained: 2299080\n",
      "    num_steps_sampled: 2299080\n",
      "    num_steps_trained: 2299080\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.8468888888889\n",
      "    ram_util_percent: 45.438444444444436\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04997669875847362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.75234730756811\n",
      "    mean_inference_ms: 8.772322411535617\n",
      "    mean_raw_obs_processing_ms: 2.5051511942316944\n",
      "  time_since_restore: 71040.69624471664\n",
      "  time_this_iter_s: 315.9338400363922\n",
      "  time_total_s: 71040.69624471664\n",
      "  timers:\n",
      "    learn_throughput: 65.216\n",
      "    learn_time_ms: 153276.034\n",
      "    load_throughput: 86801.682\n",
      "    load_time_ms: 115.159\n",
      "    sample_throughput: 60.183\n",
      "    sample_time_ms: 166094.109\n",
      "    update_time_ms: 9.837\n",
      "  timestamp: 1636971782\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2299080\n",
      "  training_iteration: 230\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">         71040.7</td><td style=\"text-align: right;\">2299080</td><td style=\"text-align: right;\">  1.7836</td><td style=\"text-align: right;\">               10.72</td><td style=\"text-align: right;\">               -2.32</td><td style=\"text-align: right;\">           90.3514</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2309076\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-28-32\n",
      "  done: false\n",
      "  episode_len_mean: 88.375\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.96000000000001\n",
      "  episode_reward_mean: 1.9856250000000035\n",
      "  episode_reward_min: -1.6800000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 24114\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.654501135328896\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011341997041112856\n",
      "          policy_loss: -0.030154584538048278\n",
      "          total_loss: 0.1340339279612208\n",
      "          vf_explained_var: 0.8076258301734924\n",
      "          vf_loss: 0.16166522659194202\n",
      "    num_agent_steps_sampled: 2309076\n",
      "    num_agent_steps_trained: 2309076\n",
      "    num_steps_sampled: 2309076\n",
      "    num_steps_trained: 2309076\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.33829787234042\n",
      "    ram_util_percent: 45.442127659574474\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04999730356041627\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.76737206809032\n",
      "    mean_inference_ms: 8.772816505340401\n",
      "    mean_raw_obs_processing_ms: 2.506587127487677\n",
      "  time_since_restore: 71369.99250817299\n",
      "  time_this_iter_s: 329.2962634563446\n",
      "  time_total_s: 71369.99250817299\n",
      "  timers:\n",
      "    learn_throughput: 65.218\n",
      "    learn_time_ms: 153269.801\n",
      "    load_throughput: 87004.128\n",
      "    load_time_ms: 114.891\n",
      "    sample_throughput: 59.433\n",
      "    sample_time_ms: 168190.515\n",
      "    update_time_ms: 8.736\n",
      "  timestamp: 1636972112\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2309076\n",
      "  training_iteration: 231\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   231</td><td style=\"text-align: right;\">           71370</td><td style=\"text-align: right;\">2309076</td><td style=\"text-align: right;\"> 1.98563</td><td style=\"text-align: right;\">                8.96</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">            88.375</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2319072\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-33-58\n",
      "  done: false\n",
      "  episode_len_mean: 88.15789473684211\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.120000000000012\n",
      "  episode_reward_mean: 1.8506140350877225\n",
      "  episode_reward_min: -2.0300000000000002\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 24228\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6450748051333632\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012056982266658654\n",
      "          policy_loss: -0.028523613469531903\n",
      "          total_loss: 0.17196409766259801\n",
      "          vf_explained_var: 0.7530379891395569\n",
      "          vf_loss: 0.19603773330887542\n",
      "    num_agent_steps_sampled: 2319072\n",
      "    num_agent_steps_trained: 2319072\n",
      "    num_steps_sampled: 2319072\n",
      "    num_steps_trained: 2319072\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.20322580645161\n",
      "    ram_util_percent: 45.342365591397844\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049997566087191726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.78284951706346\n",
      "    mean_inference_ms: 8.772815432193374\n",
      "    mean_raw_obs_processing_ms: 2.513329855353227\n",
      "  time_since_restore: 71696.04033589363\n",
      "  time_this_iter_s: 326.0478277206421\n",
      "  time_total_s: 71696.04033589363\n",
      "  timers:\n",
      "    learn_throughput: 65.198\n",
      "    learn_time_ms: 153316.554\n",
      "    load_throughput: 87044.789\n",
      "    load_time_ms: 114.837\n",
      "    sample_throughput: 59.771\n",
      "    sample_time_ms: 167237.845\n",
      "    update_time_ms: 8.149\n",
      "  timestamp: 1636972438\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2319072\n",
      "  training_iteration: 232\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   232</td><td style=\"text-align: right;\">           71696</td><td style=\"text-align: right;\">2319072</td><td style=\"text-align: right;\"> 1.85061</td><td style=\"text-align: right;\">               11.12</td><td style=\"text-align: right;\">               -2.03</td><td style=\"text-align: right;\">           88.1579</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2329068\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-39-09\n",
      "  done: false\n",
      "  episode_len_mean: 89.12389380530973\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.03000000000001\n",
      "  episode_reward_mean: 1.6509734513274366\n",
      "  episode_reward_min: -1.9300000000000013\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 24341\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6562488531455015\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011927809381293784\n",
      "          policy_loss: -0.0313569827677889\n",
      "          total_loss: 0.13911167976613611\n",
      "          vf_explained_var: 0.8020663857460022\n",
      "          vf_loss: 0.16646148129406138\n",
      "    num_agent_steps_sampled: 2329068\n",
      "    num_agent_steps_trained: 2329068\n",
      "    num_steps_sampled: 2329068\n",
      "    num_steps_trained: 2329068\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.81554054054054\n",
      "    ram_util_percent: 45.346846846846844\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002238058885928\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.799645112522576\n",
      "    mean_inference_ms: 8.77349520992595\n",
      "    mean_raw_obs_processing_ms: 2.505302526777938\n",
      "  time_since_restore: 72007.00007224083\n",
      "  time_this_iter_s: 310.9597363471985\n",
      "  time_total_s: 72007.00007224083\n",
      "  timers:\n",
      "    learn_throughput: 65.23\n",
      "    learn_time_ms: 153242.529\n",
      "    load_throughput: 87187.083\n",
      "    load_time_ms: 114.65\n",
      "    sample_throughput: 59.61\n",
      "    sample_time_ms: 167688.914\n",
      "    update_time_ms: 7.501\n",
      "  timestamp: 1636972749\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2329068\n",
      "  training_iteration: 233\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   233</td><td style=\"text-align: right;\">           72007</td><td style=\"text-align: right;\">2329068</td><td style=\"text-align: right;\"> 1.65097</td><td style=\"text-align: right;\">               11.03</td><td style=\"text-align: right;\">               -1.93</td><td style=\"text-align: right;\">           89.1239</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2339064\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-44-35\n",
      "  done: false\n",
      "  episode_len_mean: 88.05309734513274\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000012\n",
      "  episode_reward_mean: 1.905840707964605\n",
      "  episode_reward_min: -1.7300000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 24454\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.649885322089888\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012465925538268606\n",
      "          policy_loss: -0.026896913817279742\n",
      "          total_loss: 0.17411191137308557\n",
      "          vf_explained_var: 0.7849892377853394\n",
      "          vf_loss: 0.19555887477392825\n",
      "    num_agent_steps_sampled: 2339064\n",
      "    num_agent_steps_trained: 2339064\n",
      "    num_steps_sampled: 2339064\n",
      "    num_steps_trained: 2339064\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.30815450643776\n",
      "    ram_util_percent: 45.52725321888412\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0500065435399001\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.819396604238676\n",
      "    mean_inference_ms: 8.773057434371996\n",
      "    mean_raw_obs_processing_ms: 2.508222587702104\n",
      "  time_since_restore: 72333.58537817001\n",
      "  time_this_iter_s: 326.58530592918396\n",
      "  time_total_s: 72333.58537817001\n",
      "  timers:\n",
      "    learn_throughput: 65.234\n",
      "    learn_time_ms: 153233.063\n",
      "    load_throughput: 87164.878\n",
      "    load_time_ms: 114.679\n",
      "    sample_throughput: 58.935\n",
      "    sample_time_ms: 169609.324\n",
      "    update_time_ms: 8.242\n",
      "  timestamp: 1636973075\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2339064\n",
      "  training_iteration: 234\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   234</td><td style=\"text-align: right;\">         72333.6</td><td style=\"text-align: right;\">2339064</td><td style=\"text-align: right;\"> 1.90584</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           88.0531</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2349060\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-50-03\n",
      "  done: false\n",
      "  episode_len_mean: 87.38260869565218\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.380000000000013\n",
      "  episode_reward_mean: 1.5144347826086988\n",
      "  episode_reward_min: -1.7900000000000007\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 24569\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.641405443350474\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01012143927738127\n",
      "          policy_loss: -0.0306899503343062\n",
      "          total_loss: 0.13446826749743943\n",
      "          vf_explained_var: 0.7930272817611694\n",
      "          vf_loss: 0.1656321310830247\n",
      "    num_agent_steps_sampled: 2349060\n",
      "    num_agent_steps_trained: 2349060\n",
      "    num_steps_sampled: 2349060\n",
      "    num_steps_trained: 2349060\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.99871520342613\n",
      "    ram_util_percent: 45.28800856531049\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05000838869282437\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.83426783028427\n",
      "    mean_inference_ms: 8.772990144444432\n",
      "    mean_raw_obs_processing_ms: 2.514342772119755\n",
      "  time_since_restore: 72661.03941130638\n",
      "  time_this_iter_s: 327.4540331363678\n",
      "  time_total_s: 72661.03941130638\n",
      "  timers:\n",
      "    learn_throughput: 65.204\n",
      "    learn_time_ms: 153303.688\n",
      "    load_throughput: 87248.118\n",
      "    load_time_ms: 114.57\n",
      "    sample_throughput: 59.35\n",
      "    sample_time_ms: 168423.299\n",
      "    update_time_ms: 7.714\n",
      "  timestamp: 1636973403\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2349060\n",
      "  training_iteration: 235\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   235</td><td style=\"text-align: right;\">           72661</td><td style=\"text-align: right;\">2349060</td><td style=\"text-align: right;\"> 1.51443</td><td style=\"text-align: right;\">               10.38</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           87.3826</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2359056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-55-13\n",
      "  done: false\n",
      "  episode_len_mean: 88.20535714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.00000000000001\n",
      "  episode_reward_mean: 1.6202678571428604\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 24681\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6527406451029654\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011321802076842406\n",
      "          policy_loss: -0.029194947487762215\n",
      "          total_loss: 0.1582622453255945\n",
      "          vf_explained_var: 0.7944985032081604\n",
      "          vf_loss: 0.18496805912711553\n",
      "    num_agent_steps_sampled: 2359056\n",
      "    num_agent_steps_trained: 2359056\n",
      "    num_steps_sampled: 2359056\n",
      "    num_steps_trained: 2359056\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.67945823927765\n",
      "    ram_util_percent: 45.21715575620768\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05001892843867821\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.848985026841326\n",
      "    mean_inference_ms: 8.77354349821317\n",
      "    mean_raw_obs_processing_ms: 2.507292172672923\n",
      "  time_since_restore: 72971.34046936035\n",
      "  time_this_iter_s: 310.30105805397034\n",
      "  time_total_s: 72971.34046936035\n",
      "  timers:\n",
      "    learn_throughput: 65.221\n",
      "    learn_time_ms: 153263.115\n",
      "    load_throughput: 87656.814\n",
      "    load_time_ms: 114.036\n",
      "    sample_throughput: 59.413\n",
      "    sample_time_ms: 168244.746\n",
      "    update_time_ms: 7.776\n",
      "  timestamp: 1636973713\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2359056\n",
      "  training_iteration: 236\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">         72971.3</td><td style=\"text-align: right;\">2359056</td><td style=\"text-align: right;\"> 1.62027</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           88.2054</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2369052\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-00-40\n",
      "  done: false\n",
      "  episode_len_mean: 87.33043478260869\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.83000000000001\n",
      "  episode_reward_mean: 1.955478260869569\n",
      "  episode_reward_min: -1.9500000000000002\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 24796\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6506299001538856\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011723686809703456\n",
      "          policy_loss: -0.030580628593253275\n",
      "          total_loss: 0.1609732437098765\n",
      "          vf_explained_var: 0.7761337757110596\n",
      "          vf_loss: 0.1880136440631448\n",
      "    num_agent_steps_sampled: 2369052\n",
      "    num_agent_steps_trained: 2369052\n",
      "    num_steps_sampled: 2369052\n",
      "    num_steps_trained: 2369052\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.0087982832618\n",
      "    ram_util_percent: 45.01909871244636\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05000788469821198\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.86845575303583\n",
      "    mean_inference_ms: 8.773710643326464\n",
      "    mean_raw_obs_processing_ms: 2.506563114686573\n",
      "  time_since_restore: 73297.95271039009\n",
      "  time_this_iter_s: 326.6122410297394\n",
      "  time_total_s: 73297.95271039009\n",
      "  timers:\n",
      "    learn_throughput: 65.201\n",
      "    learn_time_ms: 153309.761\n",
      "    load_throughput: 88554.972\n",
      "    load_time_ms: 112.879\n",
      "    sample_throughput: 58.884\n",
      "    sample_time_ms: 169758.739\n",
      "    update_time_ms: 8.12\n",
      "  timestamp: 1636974040\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2369052\n",
      "  training_iteration: 237\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   237</td><td style=\"text-align: right;\">           73298</td><td style=\"text-align: right;\">2369052</td><td style=\"text-align: right;\"> 1.95548</td><td style=\"text-align: right;\">               10.83</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           87.3304</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2379048\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-06-19\n",
      "  done: false\n",
      "  episode_len_mean: 87.09649122807018\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.800000000000011\n",
      "  episode_reward_mean: 1.5634210526315817\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 24910\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6459532421878262\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010747087893226996\n",
      "          policy_loss: -0.03216171945469119\n",
      "          total_loss: 0.1273169338456395\n",
      "          vf_explained_var: 0.7957670092582703\n",
      "          vf_loss: 0.15839457561214193\n",
      "    num_agent_steps_sampled: 2379048\n",
      "    num_agent_steps_trained: 2379048\n",
      "    num_steps_sampled: 2379048\n",
      "    num_steps_trained: 2379048\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.7896480331263\n",
      "    ram_util_percent: 45.283850931677016\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050005547142976406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.88190654841276\n",
      "    mean_inference_ms: 8.774372774308985\n",
      "    mean_raw_obs_processing_ms: 2.510032337530271\n",
      "  time_since_restore: 73636.79513382912\n",
      "  time_this_iter_s: 338.8424234390259\n",
      "  time_total_s: 73636.79513382912\n",
      "  timers:\n",
      "    learn_throughput: 65.2\n",
      "    learn_time_ms: 153313.365\n",
      "    load_throughput: 87790.105\n",
      "    load_time_ms: 113.862\n",
      "    sample_throughput: 58.586\n",
      "    sample_time_ms: 170620.731\n",
      "    update_time_ms: 9.198\n",
      "  timestamp: 1636974379\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2379048\n",
      "  training_iteration: 238\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   238</td><td style=\"text-align: right;\">         73636.8</td><td style=\"text-align: right;\">2379048</td><td style=\"text-align: right;\"> 1.56342</td><td style=\"text-align: right;\">                 8.8</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           87.0965</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2389044\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-11-28\n",
      "  done: false\n",
      "  episode_len_mean: 88.62280701754386\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.010000000000012\n",
      "  episode_reward_mean: 1.8242982456140389\n",
      "  episode_reward_min: -2.04\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 25024\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.631339374057248\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011158141139029843\n",
      "          policy_loss: -0.030898395942874315\n",
      "          total_loss: 0.15124189208030828\n",
      "          vf_explained_var: 0.838036298751831\n",
      "          vf_loss: 0.17985658647659689\n",
      "    num_agent_steps_sampled: 2389044\n",
      "    num_agent_steps_trained: 2389044\n",
      "    num_steps_sampled: 2389044\n",
      "    num_steps_trained: 2389044\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.75000000000001\n",
      "    ram_util_percent: 45.50769230769231\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050002371423372806\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.89588044954387\n",
      "    mean_inference_ms: 8.774619383331384\n",
      "    mean_raw_obs_processing_ms: 2.505535933897423\n",
      "  time_since_restore: 73946.38966798782\n",
      "  time_this_iter_s: 309.59453415870667\n",
      "  time_total_s: 73946.38966798782\n",
      "  timers:\n",
      "    learn_throughput: 65.222\n",
      "    learn_time_ms: 153261.51\n",
      "    load_throughput: 88477.398\n",
      "    load_time_ms: 112.978\n",
      "    sample_throughput: 59.231\n",
      "    sample_time_ms: 168763.657\n",
      "    update_time_ms: 9.369\n",
      "  timestamp: 1636974688\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2389044\n",
      "  training_iteration: 239\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   239</td><td style=\"text-align: right;\">         73946.4</td><td style=\"text-align: right;\">2389044</td><td style=\"text-align: right;\">  1.8243</td><td style=\"text-align: right;\">                9.01</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           88.6228</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2399040\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-16-39\n",
      "  done: false\n",
      "  episode_len_mean: 88.17699115044248\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.44000000000001\n",
      "  episode_reward_mean: 1.8957522123893837\n",
      "  episode_reward_min: -1.990000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 25137\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.62363394621091\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011386584432271528\n",
      "          policy_loss: -0.026031264072904983\n",
      "          total_loss: 0.16586199912648553\n",
      "          vf_explained_var: 0.8225060701370239\n",
      "          vf_loss: 0.18894703201312796\n",
      "    num_agent_steps_sampled: 2399040\n",
      "    num_agent_steps_trained: 2399040\n",
      "    num_steps_sampled: 2399040\n",
      "    num_steps_trained: 2399040\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.66907449209931\n",
      "    ram_util_percent: 45.35011286681715\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05000051083303213\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.913952847732105\n",
      "    mean_inference_ms: 8.774852169062605\n",
      "    mean_raw_obs_processing_ms: 2.497608315174362\n",
      "  time_since_restore: 74257.01012539864\n",
      "  time_this_iter_s: 310.6204574108124\n",
      "  time_total_s: 74257.01012539864\n",
      "  timers:\n",
      "    learn_throughput: 65.216\n",
      "    learn_time_ms: 153276.239\n",
      "    load_throughput: 87797.606\n",
      "    load_time_ms: 113.853\n",
      "    sample_throughput: 59.423\n",
      "    sample_time_ms: 168217.618\n",
      "    update_time_ms: 9.396\n",
      "  timestamp: 1636974999\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2399040\n",
      "  training_iteration: 240\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   240</td><td style=\"text-align: right;\">           74257</td><td style=\"text-align: right;\">2399040</td><td style=\"text-align: right;\"> 1.89575</td><td style=\"text-align: right;\">                8.44</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">            88.177</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2409036\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-22-15\n",
      "  done: false\n",
      "  episode_len_mean: 86.47826086956522\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.08000000000001\n",
      "  episode_reward_mean: 1.8528695652173945\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 25252\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6365440408388774\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010559758652818562\n",
      "          policy_loss: -0.02859733449155863\n",
      "          total_loss: 0.17420829282914344\n",
      "          vf_explained_var: 0.7801810503005981\n",
      "          vf_loss: 0.2021075615929997\n",
      "    num_agent_steps_sampled: 2409036\n",
      "    num_agent_steps_trained: 2409036\n",
      "    num_steps_sampled: 2409036\n",
      "    num_steps_trained: 2409036\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.9275\n",
      "    ram_util_percent: 45.544583333333335\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05001126604952448\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.91943131246505\n",
      "    mean_inference_ms: 8.774707719761718\n",
      "    mean_raw_obs_processing_ms: 2.514215148418743\n",
      "  time_since_restore: 74593.07126760483\n",
      "  time_this_iter_s: 336.061142206192\n",
      "  time_total_s: 74593.07126760483\n",
      "  timers:\n",
      "    learn_throughput: 65.246\n",
      "    learn_time_ms: 153205.451\n",
      "    load_throughput: 87642.063\n",
      "    load_time_ms: 114.055\n",
      "    sample_throughput: 59.161\n",
      "    sample_time_ms: 168963.738\n",
      "    update_time_ms: 10.12\n",
      "  timestamp: 1636975335\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2409036\n",
      "  training_iteration: 241\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   241</td><td style=\"text-align: right;\">         74593.1</td><td style=\"text-align: right;\">2409036</td><td style=\"text-align: right;\"> 1.85287</td><td style=\"text-align: right;\">                9.08</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           86.4783</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2419032\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-27-25\n",
      "  done: false\n",
      "  episode_len_mean: 88.16666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.88000000000001\n",
      "  episode_reward_mean: 1.7587719298245645\n",
      "  episode_reward_min: -2.06\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 25366\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.644091232515808\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01064230205139964\n",
      "          policy_loss: -0.030646702191099908\n",
      "          total_loss: 0.1430841091940673\n",
      "          vf_explained_var: 0.7973304986953735\n",
      "          vf_loss: 0.17289666968445555\n",
      "    num_agent_steps_sampled: 2419032\n",
      "    num_agent_steps_trained: 2419032\n",
      "    num_steps_sampled: 2419032\n",
      "    num_steps_trained: 2419032\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.58303167420814\n",
      "    ram_util_percent: 45.98076923076923\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05000903968536725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93481334592474\n",
      "    mean_inference_ms: 8.775236965220971\n",
      "    mean_raw_obs_processing_ms: 2.5061985696772497\n",
      "  time_since_restore: 74902.80780792236\n",
      "  time_this_iter_s: 309.7365403175354\n",
      "  time_total_s: 74902.80780792236\n",
      "  timers:\n",
      "    learn_throughput: 65.255\n",
      "    learn_time_ms: 153183.993\n",
      "    load_throughput: 88401.937\n",
      "    load_time_ms: 113.074\n",
      "    sample_throughput: 59.73\n",
      "    sample_time_ms: 167353.66\n",
      "    update_time_ms: 11.217\n",
      "  timestamp: 1636975645\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2419032\n",
      "  training_iteration: 242\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">         74902.8</td><td style=\"text-align: right;\">2419032</td><td style=\"text-align: right;\"> 1.75877</td><td style=\"text-align: right;\">               10.88</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           88.1667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2429028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-32-37\n",
      "  done: false\n",
      "  episode_len_mean: 87.53097345132744\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.930000000000007\n",
      "  episode_reward_mean: 1.733451327433631\n",
      "  episode_reward_min: -1.7000000000000008\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 25479\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.634741476050809\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00989874946575064\n",
      "          policy_loss: -0.029474147369400558\n",
      "          total_loss: 0.12774666992541497\n",
      "          vf_explained_var: 0.8079569339752197\n",
      "          vf_loss: 0.15819882053412243\n",
      "    num_agent_steps_sampled: 2429028\n",
      "    num_agent_steps_trained: 2429028\n",
      "    num_steps_sampled: 2429028\n",
      "    num_steps_trained: 2429028\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.85146067415731\n",
      "    ram_util_percent: 45.84898876404494\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05000166106188446\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.95359529821555\n",
      "    mean_inference_ms: 8.775446376018964\n",
      "    mean_raw_obs_processing_ms: 2.5008915393378994\n",
      "  time_since_restore: 75214.50764632225\n",
      "  time_this_iter_s: 311.6998383998871\n",
      "  time_total_s: 75214.50764632225\n",
      "  timers:\n",
      "    learn_throughput: 65.226\n",
      "    learn_time_ms: 153251.179\n",
      "    load_throughput: 88851.074\n",
      "    load_time_ms: 112.503\n",
      "    sample_throughput: 59.728\n",
      "    sample_time_ms: 167359.967\n",
      "    update_time_ms: 11.999\n",
      "  timestamp: 1636975957\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2429028\n",
      "  training_iteration: 243\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   243</td><td style=\"text-align: right;\">         75214.5</td><td style=\"text-align: right;\">2429028</td><td style=\"text-align: right;\"> 1.73345</td><td style=\"text-align: right;\">                8.93</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">            87.531</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2439024\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-38-16\n",
      "  done: false\n",
      "  episode_len_mean: 85.63247863247864\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.050000000000011\n",
      "  episode_reward_mean: 1.4703418803418828\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 25596\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.639008881189884\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010725069779660881\n",
      "          policy_loss: -0.02907874949165007\n",
      "          total_loss: 0.16571167130222242\n",
      "          vf_explained_var: 0.7844575047492981\n",
      "          vf_loss: 0.19369332873954986\n",
      "    num_agent_steps_sampled: 2439024\n",
      "    num_agent_steps_trained: 2439024\n",
      "    num_steps_sampled: 2439024\n",
      "    num_steps_trained: 2439024\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.88409090909092\n",
      "    ram_util_percent: 45.71694214876032\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050014911493734014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.963014958632264\n",
      "    mean_inference_ms: 8.775567225355033\n",
      "    mean_raw_obs_processing_ms: 2.5135838347277253\n",
      "  time_since_restore: 75553.946611166\n",
      "  time_this_iter_s: 339.43896484375\n",
      "  time_total_s: 75553.946611166\n",
      "  timers:\n",
      "    learn_throughput: 65.237\n",
      "    learn_time_ms: 153226.805\n",
      "    load_throughput: 88609.772\n",
      "    load_time_ms: 112.809\n",
      "    sample_throughput: 59.264\n",
      "    sample_time_ms: 168670.213\n",
      "    update_time_ms: 11.643\n",
      "  timestamp: 1636976296\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2439024\n",
      "  training_iteration: 244\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   244</td><td style=\"text-align: right;\">         75553.9</td><td style=\"text-align: right;\">2439024</td><td style=\"text-align: right;\"> 1.47034</td><td style=\"text-align: right;\">                9.05</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           85.6325</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2449020\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-43-28\n",
      "  done: false\n",
      "  episode_len_mean: 86.02564102564102\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.85000000000001\n",
      "  episode_reward_mean: 1.409316239316242\n",
      "  episode_reward_min: -1.780000000000001\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 25713\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6178612855764536\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012185980742521476\n",
      "          policy_loss: -0.023282361360919525\n",
      "          total_loss: 0.1899687079581408\n",
      "          vf_explained_var: 0.7541118264198303\n",
      "          vf_loss: 0.208198345064496\n",
      "    num_agent_steps_sampled: 2449020\n",
      "    num_agent_steps_trained: 2449020\n",
      "    num_steps_sampled: 2449020\n",
      "    num_steps_trained: 2449020\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.67319819819822\n",
      "    ram_util_percent: 45.734459459459465\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05001770207254961\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97982031454772\n",
      "    mean_inference_ms: 8.7761798942534\n",
      "    mean_raw_obs_processing_ms: 2.5066686580210598\n",
      "  time_since_restore: 75865.59360384941\n",
      "  time_this_iter_s: 311.64699268341064\n",
      "  time_total_s: 75865.59360384941\n",
      "  timers:\n",
      "    learn_throughput: 65.217\n",
      "    learn_time_ms: 153273.331\n",
      "    load_throughput: 88905.223\n",
      "    load_time_ms: 112.434\n",
      "    sample_throughput: 59.841\n",
      "    sample_time_ms: 167042.486\n",
      "    update_time_ms: 12.624\n",
      "  timestamp: 1636976608\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2449020\n",
      "  training_iteration: 245\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   245</td><td style=\"text-align: right;\">         75865.6</td><td style=\"text-align: right;\">2449020</td><td style=\"text-align: right;\"> 1.40932</td><td style=\"text-align: right;\">                8.85</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           86.0256</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2459016\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-48-55\n",
      "  done: false\n",
      "  episode_len_mean: 86.48275862068965\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.470000000000013\n",
      "  episode_reward_mean: 1.6068103448275888\n",
      "  episode_reward_min: -1.7500000000000007\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 25829\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6323710578119655\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01041801121584602\n",
      "          policy_loss: -0.03110068201636657\n",
      "          total_loss: 0.12908310619875407\n",
      "          vf_explained_var: 0.8181443214416504\n",
      "          vf_loss: 0.15980727665611885\n",
      "    num_agent_steps_sampled: 2459016\n",
      "    num_agent_steps_trained: 2459016\n",
      "    num_steps_sampled: 2459016\n",
      "    num_steps_trained: 2459016\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.0203426124197\n",
      "    ram_util_percent: 45.53768736616702\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002635857398152\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.99527265240677\n",
      "    mean_inference_ms: 8.776830268192517\n",
      "    mean_raw_obs_processing_ms: 2.5088267937353854\n",
      "  time_since_restore: 76192.41982340813\n",
      "  time_this_iter_s: 326.8262195587158\n",
      "  time_total_s: 76192.41982340813\n",
      "  timers:\n",
      "    learn_throughput: 65.215\n",
      "    learn_time_ms: 153278.63\n",
      "    load_throughput: 88250.582\n",
      "    load_time_ms: 113.268\n",
      "    sample_throughput: 59.257\n",
      "    sample_time_ms: 168688.713\n",
      "    update_time_ms: 12.387\n",
      "  timestamp: 1636976935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2459016\n",
      "  training_iteration: 246\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">         76192.4</td><td style=\"text-align: right;\">2459016</td><td style=\"text-align: right;\"> 1.60681</td><td style=\"text-align: right;\">                8.47</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           86.4828</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2469012\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-54-21\n",
      "  done: false\n",
      "  episode_len_mean: 86.84347826086956\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.160000000000009\n",
      "  episode_reward_mean: 1.4323478260869587\n",
      "  episode_reward_min: -1.580000000000001\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 25944\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6336217732511016\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009846878923423168\n",
      "          policy_loss: -0.03185855535328643\n",
      "          total_loss: 0.13054088617259096\n",
      "          vf_explained_var: 0.7837375998497009\n",
      "          vf_loss: 0.16349918578998146\n",
      "    num_agent_steps_sampled: 2469012\n",
      "    num_agent_steps_trained: 2469012\n",
      "    num_steps_sampled: 2469012\n",
      "    num_steps_trained: 2469012\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.25268817204301\n",
      "    ram_util_percent: 45.32860215053764\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050010092219584794\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.012461655986\n",
      "    mean_inference_ms: 8.776751923821118\n",
      "    mean_raw_obs_processing_ms: 2.5120653609796957\n",
      "  time_since_restore: 76518.5431702137\n",
      "  time_this_iter_s: 326.1233468055725\n",
      "  time_total_s: 76518.5431702137\n",
      "  timers:\n",
      "    learn_throughput: 65.24\n",
      "    learn_time_ms: 153219.423\n",
      "    load_throughput: 87910.215\n",
      "    load_time_ms: 113.707\n",
      "    sample_throughput: 59.254\n",
      "    sample_time_ms: 168697.685\n",
      "    update_time_ms: 11.751\n",
      "  timestamp: 1636977261\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2469012\n",
      "  training_iteration: 247\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   247</td><td style=\"text-align: right;\">         76518.5</td><td style=\"text-align: right;\">2469012</td><td style=\"text-align: right;\"> 1.43235</td><td style=\"text-align: right;\">                9.16</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           86.8435</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2479008\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_11-59-32\n",
      "  done: false\n",
      "  episode_len_mean: 87.44736842105263\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.720000000000011\n",
      "  episode_reward_mean: 1.4648245614035116\n",
      "  episode_reward_min: -1.5900000000000007\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 26058\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6334678581637196\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011413207307092485\n",
      "          policy_loss: -0.026170334077448162\n",
      "          total_loss: 0.1948005879413273\n",
      "          vf_explained_var: 0.7343850135803223\n",
      "          vf_loss: 0.21805479989872656\n",
      "    num_agent_steps_sampled: 2479008\n",
      "    num_agent_steps_trained: 2479008\n",
      "    num_steps_sampled: 2479008\n",
      "    num_steps_trained: 2479008\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.69099099099098\n",
      "    ram_util_percent: 45.613738738738746\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002476650557139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.026117393177124\n",
      "    mean_inference_ms: 8.777434719476831\n",
      "    mean_raw_obs_processing_ms: 2.5069558708659674\n",
      "  time_since_restore: 76829.91148090363\n",
      "  time_this_iter_s: 311.36831068992615\n",
      "  time_total_s: 76829.91148090363\n",
      "  timers:\n",
      "    learn_throughput: 65.22\n",
      "    learn_time_ms: 153265.484\n",
      "    load_throughput: 88553.737\n",
      "    load_time_ms: 112.881\n",
      "    sample_throughput: 60.251\n",
      "    sample_time_ms: 165905.996\n",
      "    update_time_ms: 10.837\n",
      "  timestamp: 1636977572\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2479008\n",
      "  training_iteration: 248\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">         76829.9</td><td style=\"text-align: right;\">2479008</td><td style=\"text-align: right;\"> 1.46482</td><td style=\"text-align: right;\">               10.72</td><td style=\"text-align: right;\">               -1.59</td><td style=\"text-align: right;\">           87.4474</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2489004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-04-43\n",
      "  done: false\n",
      "  episode_len_mean: 87.06086956521739\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.02000000000001\n",
      "  episode_reward_mean: 1.365130434782611\n",
      "  episode_reward_min: -1.5100000000000005\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 26173\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6493920827523256\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010128202071693767\n",
      "          policy_loss: -0.02799018745461845\n",
      "          total_loss: 0.140984304006307\n",
      "          vf_explained_var: 0.7668563723564148\n",
      "          vf_loss: 0.16951093843811724\n",
      "    num_agent_steps_sampled: 2489004\n",
      "    num_agent_steps_trained: 2489004\n",
      "    num_steps_sampled: 2489004\n",
      "    num_steps_trained: 2489004\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.84436936936937\n",
      "    ram_util_percent: 45.50788288288288\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05004127132839082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03983887702417\n",
      "    mean_inference_ms: 8.778509800148694\n",
      "    mean_raw_obs_processing_ms: 2.498690726458021\n",
      "  time_since_restore: 77140.73517680168\n",
      "  time_this_iter_s: 310.82369589805603\n",
      "  time_total_s: 77140.73517680168\n",
      "  timers:\n",
      "    learn_throughput: 65.229\n",
      "    learn_time_ms: 153245.514\n",
      "    load_throughput: 88219.701\n",
      "    load_time_ms: 113.308\n",
      "    sample_throughput: 60.2\n",
      "    sample_time_ms: 166046.838\n",
      "    update_time_ms: 11.742\n",
      "  timestamp: 1636977883\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2489004\n",
      "  training_iteration: 249\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   249</td><td style=\"text-align: right;\">         77140.7</td><td style=\"text-align: right;\">2489004</td><td style=\"text-align: right;\"> 1.36513</td><td style=\"text-align: right;\">                7.02</td><td style=\"text-align: right;\">               -1.51</td><td style=\"text-align: right;\">           87.0609</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2499000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-10-23\n",
      "  done: false\n",
      "  episode_len_mean: 85.97435897435898\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.83000000000001\n",
      "  episode_reward_mean: 1.6005128205128234\n",
      "  episode_reward_min: -1.4800000000000009\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 26290\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.637380377859132\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011069564432496737\n",
      "          policy_loss: -0.023733392122607583\n",
      "          total_loss: 0.15994702677449418\n",
      "          vf_explained_var: 0.761166512966156\n",
      "          vf_loss: 0.18168414102262284\n",
      "    num_agent_steps_sampled: 2499000\n",
      "    num_agent_steps_trained: 2499000\n",
      "    num_steps_sampled: 2499000\n",
      "    num_steps_trained: 2499000\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.739793814433\n",
      "    ram_util_percent: 45.68886597938145\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050017386318124114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.052853958741935\n",
      "    mean_inference_ms: 8.777799451930461\n",
      "    mean_raw_obs_processing_ms: 2.5139957189477022\n",
      "  time_since_restore: 77480.60235786438\n",
      "  time_this_iter_s: 339.86718106269836\n",
      "  time_total_s: 77480.60235786438\n",
      "  timers:\n",
      "    learn_throughput: 65.219\n",
      "    learn_time_ms: 153269.23\n",
      "    load_throughput: 88065.121\n",
      "    load_time_ms: 113.507\n",
      "    sample_throughput: 59.166\n",
      "    sample_time_ms: 168947.627\n",
      "    update_time_ms: 11.342\n",
      "  timestamp: 1636978223\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2499000\n",
      "  training_iteration: 250\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         77480.6</td><td style=\"text-align: right;\">2499000</td><td style=\"text-align: right;\"> 1.60051</td><td style=\"text-align: right;\">               10.83</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           85.9744</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2508996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 87.36283185840708\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.550000000000011\n",
      "  episode_reward_mean: 1.489734513274339\n",
      "  episode_reward_min: -1.540000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 26403\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.627521690547976\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009327148951653545\n",
      "          policy_loss: -0.027782346076992714\n",
      "          total_loss: 0.14914790238611975\n",
      "          vf_explained_var: 0.7686508297920227\n",
      "          vf_loss: 0.17930100314701214\n",
      "    num_agent_steps_sampled: 2508996\n",
      "    num_agent_steps_trained: 2508996\n",
      "    num_steps_sampled: 2508996\n",
      "    num_steps_trained: 2508996\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.86473214285714\n",
      "    ram_util_percent: 45.934598214285714\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050029369048324675\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.069786097288016\n",
      "    mean_inference_ms: 8.778690495481694\n",
      "    mean_raw_obs_processing_ms: 2.506451358830672\n",
      "  time_since_restore: 77794.6811542511\n",
      "  time_this_iter_s: 314.07879638671875\n",
      "  time_total_s: 77794.6811542511\n",
      "  timers:\n",
      "    learn_throughput: 65.191\n",
      "    learn_time_ms: 153334.244\n",
      "    load_throughput: 87810.496\n",
      "    load_time_ms: 113.836\n",
      "    sample_throughput: 59.97\n",
      "    sample_time_ms: 166683.554\n",
      "    update_time_ms: 11.731\n",
      "  timestamp: 1636978537\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2508996\n",
      "  training_iteration: 251\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   251</td><td style=\"text-align: right;\">         77794.7</td><td style=\"text-align: right;\">2508996</td><td style=\"text-align: right;\"> 1.48973</td><td style=\"text-align: right;\">               10.55</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           87.3628</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2518992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-20-53\n",
      "  done: false\n",
      "  episode_len_mean: 86.93913043478261\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.96000000000001\n",
      "  episode_reward_mean: 1.5873043478260902\n",
      "  episode_reward_min: -1.7300000000000006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 26518\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.621834128942245\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009901118448169217\n",
      "          policy_loss: -0.026490317983950816\n",
      "          total_loss: 0.18723346169313623\n",
      "          vf_explained_var: 0.7628703713417053\n",
      "          vf_loss: 0.21456663743354\n",
      "    num_agent_steps_sampled: 2518992\n",
      "    num_agent_steps_trained: 2518992\n",
      "    num_steps_sampled: 2518992\n",
      "    num_steps_trained: 2518992\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.94700665188472\n",
      "    ram_util_percent: 45.849889135254976\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002284811645247\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.09000223272118\n",
      "    mean_inference_ms: 8.779036349647692\n",
      "    mean_raw_obs_processing_ms: 2.4988639190051734\n",
      "  time_since_restore: 78110.55033636093\n",
      "  time_this_iter_s: 315.86918210983276\n",
      "  time_total_s: 78110.55033636093\n",
      "  timers:\n",
      "    learn_throughput: 65.21\n",
      "    learn_time_ms: 153289.745\n",
      "    load_throughput: 87768.272\n",
      "    load_time_ms: 113.891\n",
      "    sample_throughput: 59.734\n",
      "    sample_time_ms: 167342.111\n",
      "    update_time_ms: 10.639\n",
      "  timestamp: 1636978853\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2518992\n",
      "  training_iteration: 252\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   252</td><td style=\"text-align: right;\">         78110.6</td><td style=\"text-align: right;\">2518992</td><td style=\"text-align: right;\">  1.5873</td><td style=\"text-align: right;\">               10.96</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           86.9391</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2528988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-26-39\n",
      "  done: false\n",
      "  episode_len_mean: 84.23529411764706\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.860000000000014\n",
      "  episode_reward_mean: 1.3506722689075654\n",
      "  episode_reward_min: -1.5700000000000007\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 26637\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6347233444197564\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009053479149059454\n",
      "          policy_loss: -0.026203331493366604\n",
      "          total_loss: 0.14950369015041515\n",
      "          vf_explained_var: 0.7477104663848877\n",
      "          vf_loss: 0.1788511789057595\n",
      "    num_agent_steps_sampled: 2528988\n",
      "    num_agent_steps_trained: 2528988\n",
      "    num_steps_sampled: 2528988\n",
      "    num_steps_trained: 2528988\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.56673427991886\n",
      "    ram_util_percent: 45.61257606490873\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002374979471032\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.10812302784053\n",
      "    mean_inference_ms: 8.778863212820816\n",
      "    mean_raw_obs_processing_ms: 2.5092578589572883\n",
      "  time_since_restore: 78456.27210044861\n",
      "  time_this_iter_s: 345.721764087677\n",
      "  time_total_s: 78456.27210044861\n",
      "  timers:\n",
      "    learn_throughput: 65.207\n",
      "    learn_time_ms: 153296.548\n",
      "    load_throughput: 87466.994\n",
      "    load_time_ms: 114.283\n",
      "    sample_throughput: 58.546\n",
      "    sample_time_ms: 170737.837\n",
      "    update_time_ms: 9.92\n",
      "  timestamp: 1636979199\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2528988\n",
      "  training_iteration: 253\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   253</td><td style=\"text-align: right;\">         78456.3</td><td style=\"text-align: right;\">2528988</td><td style=\"text-align: right;\"> 1.35067</td><td style=\"text-align: right;\">                6.86</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           84.2353</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2538984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-32-05\n",
      "  done: false\n",
      "  episode_len_mean: 84.91525423728814\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.940000000000006\n",
      "  episode_reward_mean: 1.4878813559322055\n",
      "  episode_reward_min: -1.5200000000000005\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 26755\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.638087547131074\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009212580554026614\n",
      "          policy_loss: -0.02643321452674289\n",
      "          total_loss: 0.15905161811532373\n",
      "          vf_explained_var: 0.7625764608383179\n",
      "          vf_loss: 0.18825487218295725\n",
      "    num_agent_steps_sampled: 2538984\n",
      "    num_agent_steps_trained: 2538984\n",
      "    num_steps_sampled: 2538984\n",
      "    num_steps_trained: 2538984\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.52086021505376\n",
      "    ram_util_percent: 45.966021505376354\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050033146629927305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.125153797935965\n",
      "    mean_inference_ms: 8.77952612571968\n",
      "    mean_raw_obs_processing_ms: 2.5062883772486506\n",
      "  time_since_restore: 78782.22840952873\n",
      "  time_this_iter_s: 325.9563090801239\n",
      "  time_total_s: 78782.22840952873\n",
      "  timers:\n",
      "    learn_throughput: 65.206\n",
      "    learn_time_ms: 153298.102\n",
      "    load_throughput: 87853.313\n",
      "    load_time_ms: 113.781\n",
      "    sample_throughput: 59.012\n",
      "    sample_time_ms: 169388.811\n",
      "    update_time_ms: 9.259\n",
      "  timestamp: 1636979525\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2538984\n",
      "  training_iteration: 254\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">         78782.2</td><td style=\"text-align: right;\">2538984</td><td style=\"text-align: right;\"> 1.48788</td><td style=\"text-align: right;\">                6.94</td><td style=\"text-align: right;\">               -1.52</td><td style=\"text-align: right;\">           84.9153</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2548980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-37-21\n",
      "  done: false\n",
      "  episode_len_mean: 85.73275862068965\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.76000000000001\n",
      "  episode_reward_mean: 1.9349137931034515\n",
      "  episode_reward_min: -1.4900000000000007\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 26871\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6326382245772924\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010428725591933845\n",
      "          policy_loss: -0.025206835012739667\n",
      "          total_loss: 0.16893128457073217\n",
      "          vf_explained_var: 0.7673203945159912\n",
      "          vf_loss: 0.19373681916114993\n",
      "    num_agent_steps_sampled: 2548980\n",
      "    num_agent_steps_trained: 2548980\n",
      "    num_steps_sampled: 2548980\n",
      "    num_steps_trained: 2548980\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.80931263858093\n",
      "    ram_util_percent: 46.031042128603104\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050037876923291515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.1451865374021\n",
      "    mean_inference_ms: 8.780123330439038\n",
      "    mean_raw_obs_processing_ms: 2.500639929324428\n",
      "  time_since_restore: 79098.22186636925\n",
      "  time_this_iter_s: 315.99345684051514\n",
      "  time_total_s: 79098.22186636925\n",
      "  timers:\n",
      "    learn_throughput: 65.236\n",
      "    learn_time_ms: 153229.083\n",
      "    load_throughput: 87587.447\n",
      "    load_time_ms: 114.126\n",
      "    sample_throughput: 58.837\n",
      "    sample_time_ms: 169892.416\n",
      "    update_time_ms: 8.686\n",
      "  timestamp: 1636979841\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2548980\n",
      "  training_iteration: 255\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   255</td><td style=\"text-align: right;\">         79098.2</td><td style=\"text-align: right;\">2548980</td><td style=\"text-align: right;\"> 1.93491</td><td style=\"text-align: right;\">                8.76</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">           85.7328</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2558976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-42-49\n",
      "  done: false\n",
      "  episode_len_mean: 86.00862068965517\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.93000000000001\n",
      "  episode_reward_mean: 1.1462931034482775\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 26987\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6483892988954856\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008915657832584507\n",
      "          policy_loss: -0.02468048595688027\n",
      "          total_loss: 0.17093174945539197\n",
      "          vf_explained_var: 0.6841185688972473\n",
      "          vf_loss: 0.1992462740960316\n",
      "    num_agent_steps_sampled: 2558976\n",
      "    num_agent_steps_trained: 2558976\n",
      "    num_steps_sampled: 2558976\n",
      "    num_steps_trained: 2558976\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.71663113006396\n",
      "    ram_util_percent: 46.00149253731344\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002903784719096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.16220181397991\n",
      "    mean_inference_ms: 8.779949039734298\n",
      "    mean_raw_obs_processing_ms: 2.5030124535017277\n",
      "  time_since_restore: 79426.8130414486\n",
      "  time_this_iter_s: 328.5911750793457\n",
      "  time_total_s: 79426.8130414486\n",
      "  timers:\n",
      "    learn_throughput: 65.224\n",
      "    learn_time_ms: 153256.608\n",
      "    load_throughput: 87716.178\n",
      "    load_time_ms: 113.958\n",
      "    sample_throughput: 58.786\n",
      "    sample_time_ms: 170040.8\n",
      "    update_time_ms: 9.538\n",
      "  timestamp: 1636980169\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2558976\n",
      "  training_iteration: 256\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   256</td><td style=\"text-align: right;\">         79426.8</td><td style=\"text-align: right;\">2558976</td><td style=\"text-align: right;\"> 1.14629</td><td style=\"text-align: right;\">                8.93</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           86.0086</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2568972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-48-21\n",
      "  done: false\n",
      "  episode_len_mean: 84.60504201680672\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.680000000000009\n",
      "  episode_reward_mean: 1.0680672268907583\n",
      "  episode_reward_min: -1.5400000000000005\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 27106\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6489769437374213\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007736202720376755\n",
      "          policy_loss: -0.028781280918524433\n",
      "          total_loss: 0.11685740710634133\n",
      "          vf_explained_var: 0.7416872382164001\n",
      "          vf_loss: 0.15230141546672735\n",
      "    num_agent_steps_sampled: 2568972\n",
      "    num_agent_steps_trained: 2568972\n",
      "    num_steps_sampled: 2568972\n",
      "    num_steps_trained: 2568972\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.39957716701903\n",
      "    ram_util_percent: 45.69090909090908\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003147516376047\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.18070375092038\n",
      "    mean_inference_ms: 8.779644029519527\n",
      "    mean_raw_obs_processing_ms: 2.5119190201333894\n",
      "  time_since_restore: 79758.48452210426\n",
      "  time_this_iter_s: 331.67148065567017\n",
      "  time_total_s: 79758.48452210426\n",
      "  timers:\n",
      "    learn_throughput: 65.226\n",
      "    learn_time_ms: 153251.537\n",
      "    load_throughput: 87706.214\n",
      "    load_time_ms: 113.971\n",
      "    sample_throughput: 58.593\n",
      "    sample_time_ms: 170601.576\n",
      "    update_time_ms: 10.558\n",
      "  timestamp: 1636980501\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2568972\n",
      "  training_iteration: 257\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   257</td><td style=\"text-align: right;\">         79758.5</td><td style=\"text-align: right;\">2568972</td><td style=\"text-align: right;\"> 1.06807</td><td style=\"text-align: right;\">                8.68</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">            84.605</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2578968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-53-57\n",
      "  done: false\n",
      "  episode_len_mean: 85.23076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.520000000000003\n",
      "  episode_reward_mean: 1.2157264957264977\n",
      "  episode_reward_min: -1.6200000000000006\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 27223\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6387551018315505\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008919324733480515\n",
      "          policy_loss: -0.02840602370814826\n",
      "          total_loss: 0.14069728072390406\n",
      "          vf_explained_var: 0.7738164663314819\n",
      "          vf_loss: 0.1726316014953499\n",
      "    num_agent_steps_sampled: 2578968\n",
      "    num_agent_steps_trained: 2578968\n",
      "    num_steps_sampled: 2578968\n",
      "    num_steps_trained: 2578968\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.74572025052191\n",
      "    ram_util_percent: 45.63235908141964\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05004907345021496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.19162320008901\n",
      "    mean_inference_ms: 8.780516984673314\n",
      "    mean_raw_obs_processing_ms: 2.5124470834483112\n",
      "  time_since_restore: 80094.0900375843\n",
      "  time_this_iter_s: 335.6055154800415\n",
      "  time_total_s: 80094.0900375843\n",
      "  timers:\n",
      "    learn_throughput: 65.218\n",
      "    learn_time_ms: 153271.494\n",
      "    load_throughput: 87274.416\n",
      "    load_time_ms: 114.535\n",
      "    sample_throughput: 57.779\n",
      "    sample_time_ms: 173004.801\n",
      "    update_time_ms: 10.523\n",
      "  timestamp: 1636980837\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2578968\n",
      "  training_iteration: 258\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   258</td><td style=\"text-align: right;\">         80094.1</td><td style=\"text-align: right;\">2578968</td><td style=\"text-align: right;\"> 1.21573</td><td style=\"text-align: right;\">                5.52</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">           85.2308</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2588964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_12-59-24\n",
      "  done: false\n",
      "  episode_len_mean: 85.82758620689656\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.080000000000011\n",
      "  episode_reward_mean: 1.1710344827586228\n",
      "  episode_reward_min: -1.5400000000000007\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 27339\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6458326080925443\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008836880701137651\n",
      "          policy_loss: -0.02910631640981405\n",
      "          total_loss: 0.14049801304419007\n",
      "          vf_explained_var: 0.7599718570709229\n",
      "          vf_loss: 0.17341469665392278\n",
      "    num_agent_steps_sampled: 2588964\n",
      "    num_agent_steps_trained: 2588964\n",
      "    num_steps_sampled: 2588964\n",
      "    num_steps_trained: 2588964\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.52210300429185\n",
      "    ram_util_percent: 45.75901287553648\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050058461805743124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.20369776713512\n",
      "    mean_inference_ms: 8.781051744308\n",
      "    mean_raw_obs_processing_ms: 2.512036226736735\n",
      "  time_since_restore: 80420.81230282784\n",
      "  time_this_iter_s: 326.7222652435303\n",
      "  time_total_s: 80420.81230282784\n",
      "  timers:\n",
      "    learn_throughput: 65.177\n",
      "    learn_time_ms: 153366.261\n",
      "    load_throughput: 87096.631\n",
      "    load_time_ms: 114.769\n",
      "    sample_throughput: 57.284\n",
      "    sample_time_ms: 174499.478\n",
      "    update_time_ms: 10.288\n",
      "  timestamp: 1636981164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2588964\n",
      "  training_iteration: 259\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   259</td><td style=\"text-align: right;\">         80420.8</td><td style=\"text-align: right;\">2588964</td><td style=\"text-align: right;\"> 1.17103</td><td style=\"text-align: right;\">                7.08</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           85.8276</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2598960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-04-50\n",
      "  done: false\n",
      "  episode_len_mean: 85.16101694915254\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.070000000000009\n",
      "  episode_reward_mean: 1.1777118644067817\n",
      "  episode_reward_min: -1.7200000000000006\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 27457\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.641521811587179\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00992242189536037\n",
      "          policy_loss: -0.027290682152359403\n",
      "          total_loss: 0.1567142799568291\n",
      "          vf_explained_var: 0.7501871585845947\n",
      "          vf_loss: 0.18499009866758975\n",
      "    num_agent_steps_sampled: 2598960\n",
      "    num_agent_steps_trained: 2598960\n",
      "    num_steps_sampled: 2598960\n",
      "    num_steps_trained: 2598960\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.4087982832618\n",
      "    ram_util_percent: 45.46437768240344\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05004117455025365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.22090153370466\n",
      "    mean_inference_ms: 8.780748415059612\n",
      "    mean_raw_obs_processing_ms: 2.5134426913786876\n",
      "  time_since_restore: 80747.6848783493\n",
      "  time_this_iter_s: 326.8725755214691\n",
      "  time_total_s: 80747.6848783493\n",
      "  timers:\n",
      "    learn_throughput: 65.22\n",
      "    learn_time_ms: 153265.885\n",
      "    load_throughput: 87332.044\n",
      "    load_time_ms: 114.46\n",
      "    sample_throughput: 57.68\n",
      "    sample_time_ms: 173300.981\n",
      "    update_time_ms: 10.204\n",
      "  timestamp: 1636981490\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2598960\n",
      "  training_iteration: 260\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   260</td><td style=\"text-align: right;\">         80747.7</td><td style=\"text-align: right;\">2598960</td><td style=\"text-align: right;\"> 1.17771</td><td style=\"text-align: right;\">                7.07</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">            85.161</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2608956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-10-15\n",
      "  done: false\n",
      "  episode_len_mean: 86.86086956521739\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.870000000000013\n",
      "  episode_reward_mean: 1.1041739130434802\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 27572\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6454858977570495\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008561959170400719\n",
      "          policy_loss: -0.026230009480053162\n",
      "          total_loss: 0.13000617576643633\n",
      "          vf_explained_var: 0.744498610496521\n",
      "          vf_loss: 0.1607476795740967\n",
      "    num_agent_steps_sampled: 2608956\n",
      "    num_agent_steps_trained: 2608956\n",
      "    num_steps_sampled: 2608956\n",
      "    num_steps_trained: 2608956\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.38383620689655\n",
      "    ram_util_percent: 45.40495689655172\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050036647628165454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.23453357213253\n",
      "    mean_inference_ms: 8.781020564025933\n",
      "    mean_raw_obs_processing_ms: 2.5131304748864465\n",
      "  time_since_restore: 81072.64832019806\n",
      "  time_this_iter_s: 324.9634418487549\n",
      "  time_total_s: 81072.64832019806\n",
      "  timers:\n",
      "    learn_throughput: 65.219\n",
      "    learn_time_ms: 153268.744\n",
      "    load_throughput: 87047.03\n",
      "    load_time_ms: 114.834\n",
      "    sample_throughput: 57.321\n",
      "    sample_time_ms: 174387.499\n",
      "    update_time_ms: 9.777\n",
      "  timestamp: 1636981815\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2608956\n",
      "  training_iteration: 261\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   261</td><td style=\"text-align: right;\">         81072.6</td><td style=\"text-align: right;\">2608956</td><td style=\"text-align: right;\"> 1.10417</td><td style=\"text-align: right;\">               10.87</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           86.8609</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2618952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-15-40\n",
      "  done: false\n",
      "  episode_len_mean: 86.47826086956522\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.790000000000015\n",
      "  episode_reward_mean: 1.399739130434785\n",
      "  episode_reward_min: -1.890000000000001\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 27687\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.640854958183745\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010113473824574875\n",
      "          policy_loss: -0.022881260376550958\n",
      "          total_loss: 0.17692897932158194\n",
      "          vf_explained_var: 0.7025955319404602\n",
      "          vf_loss: 0.20029906312672374\n",
      "    num_agent_steps_sampled: 2618952\n",
      "    num_agent_steps_trained: 2618952\n",
      "    num_steps_sampled: 2618952\n",
      "    num_steps_trained: 2618952\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.39330453563716\n",
      "    ram_util_percent: 45.754643628509726\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05004287219380684\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.24484526012434\n",
      "    mean_inference_ms: 8.781550982131215\n",
      "    mean_raw_obs_processing_ms: 2.513415891558889\n",
      "  time_since_restore: 81397.18566441536\n",
      "  time_this_iter_s: 324.5373442173004\n",
      "  time_total_s: 81397.18566441536\n",
      "  timers:\n",
      "    learn_throughput: 65.207\n",
      "    learn_time_ms: 153296.91\n",
      "    load_throughput: 86891.378\n",
      "    load_time_ms: 115.04\n",
      "    sample_throughput: 57.046\n",
      "    sample_time_ms: 175226.323\n",
      "    update_time_ms: 9.907\n",
      "  timestamp: 1636982140\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2618952\n",
      "  training_iteration: 262\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   262</td><td style=\"text-align: right;\">         81397.2</td><td style=\"text-align: right;\">2618952</td><td style=\"text-align: right;\"> 1.39974</td><td style=\"text-align: right;\">               10.79</td><td style=\"text-align: right;\">               -1.89</td><td style=\"text-align: right;\">           86.4783</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2628948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-21-04\n",
      "  done: false\n",
      "  episode_len_mean: 86.61739130434782\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.300000000000008\n",
      "  episode_reward_mean: 1.6140869565217422\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 27802\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6346249342983605\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008766038871906913\n",
      "          policy_loss: -0.02728924648040253\n",
      "          total_loss: 0.16783025055232212\n",
      "          vf_explained_var: 0.7837172746658325\n",
      "          vf_loss: 0.19899934763208224\n",
      "    num_agent_steps_sampled: 2628948\n",
      "    num_agent_steps_trained: 2628948\n",
      "    num_steps_sampled: 2628948\n",
      "    num_steps_trained: 2628948\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.35151515151514\n",
      "    ram_util_percent: 45.28917748917748\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050033421589574474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.25891561138148\n",
      "    mean_inference_ms: 8.781609878455352\n",
      "    mean_raw_obs_processing_ms: 2.513060959290814\n",
      "  time_since_restore: 81721.10279893875\n",
      "  time_this_iter_s: 323.9171345233917\n",
      "  time_total_s: 81721.10279893875\n",
      "  timers:\n",
      "    learn_throughput: 65.222\n",
      "    learn_time_ms: 153261.614\n",
      "    load_throughput: 86971.93\n",
      "    load_time_ms: 114.934\n",
      "    sample_throughput: 57.753\n",
      "    sample_time_ms: 173080.495\n",
      "    update_time_ms: 10.404\n",
      "  timestamp: 1636982464\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2628948\n",
      "  training_iteration: 263\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   263</td><td style=\"text-align: right;\">         81721.1</td><td style=\"text-align: right;\">2628948</td><td style=\"text-align: right;\"> 1.61409</td><td style=\"text-align: right;\">                 7.3</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           86.6174</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2638944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-26-31\n",
      "  done: false\n",
      "  episode_len_mean: 87.89565217391305\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.580000000000014\n",
      "  episode_reward_mean: 1.4779130434782635\n",
      "  episode_reward_min: -1.5600000000000005\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 27917\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.652084029535962\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009080640682260808\n",
      "          policy_loss: -0.024087362026429585\n",
      "          total_loss: 0.1636632930777935\n",
      "          vf_explained_var: 0.7617142796516418\n",
      "          vf_loss: 0.19099880666074018\n",
      "    num_agent_steps_sampled: 2638944\n",
      "    num_agent_steps_trained: 2638944\n",
      "    num_steps_sampled: 2638944\n",
      "    num_steps_trained: 2638944\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.73304721030043\n",
      "    ram_util_percent: 45.19549356223175\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05004846838598449\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.26995252686101\n",
      "    mean_inference_ms: 8.78268377280243\n",
      "    mean_raw_obs_processing_ms: 2.510928546960813\n",
      "  time_since_restore: 82047.80084466934\n",
      "  time_this_iter_s: 326.6980457305908\n",
      "  time_total_s: 82047.80084466934\n",
      "  timers:\n",
      "    learn_throughput: 65.198\n",
      "    learn_time_ms: 153317.65\n",
      "    load_throughput: 87020.868\n",
      "    load_time_ms: 114.869\n",
      "    sample_throughput: 57.748\n",
      "    sample_time_ms: 173098.357\n",
      "    update_time_ms: 10.998\n",
      "  timestamp: 1636982791\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2638944\n",
      "  training_iteration: 264\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   264</td><td style=\"text-align: right;\">         82047.8</td><td style=\"text-align: right;\">2638944</td><td style=\"text-align: right;\"> 1.47791</td><td style=\"text-align: right;\">                8.58</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           87.8957</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2648940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-31-59\n",
      "  done: false\n",
      "  episode_len_mean: 85.64655172413794\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.980000000000011\n",
      "  episode_reward_mean: 1.2911206896551748\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 28033\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6437322450499248\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009118208508342844\n",
      "          policy_loss: -0.02584015873985158\n",
      "          total_loss: 0.16570463622363013\n",
      "          vf_explained_var: 0.7229458689689636\n",
      "          vf_loss: 0.19461314721494657\n",
      "    num_agent_steps_sampled: 2648940\n",
      "    num_agent_steps_trained: 2648940\n",
      "    num_steps_sampled: 2648940\n",
      "    num_steps_trained: 2648940\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.31471215351812\n",
      "    ram_util_percent: 45.664179104477604\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003786348507994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.285975956422945\n",
      "    mean_inference_ms: 8.782613173260057\n",
      "    mean_raw_obs_processing_ms: 2.5137219336327616\n",
      "  time_since_restore: 82376.27766942978\n",
      "  time_this_iter_s: 328.476824760437\n",
      "  time_total_s: 82376.27766942978\n",
      "  timers:\n",
      "    learn_throughput: 65.202\n",
      "    learn_time_ms: 153309.197\n",
      "    load_throughput: 86888.731\n",
      "    load_time_ms: 115.044\n",
      "    sample_throughput: 57.331\n",
      "    sample_time_ms: 174355.26\n",
      "    update_time_ms: 10.942\n",
      "  timestamp: 1636983119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2648940\n",
      "  training_iteration: 265\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   265</td><td style=\"text-align: right;\">         82376.3</td><td style=\"text-align: right;\">2648940</td><td style=\"text-align: right;\"> 1.29112</td><td style=\"text-align: right;\">                8.98</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           85.6466</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2658936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-37-24\n",
      "  done: false\n",
      "  episode_len_mean: 85.33050847457628\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.83000000000001\n",
      "  episode_reward_mean: 1.3920338983050866\n",
      "  episode_reward_min: -1.570000000000001\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 28151\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.645597881027776\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008966438670844096\n",
      "          policy_loss: -0.022185656011231944\n",
      "          total_loss: 0.1647712188339036\n",
      "          vf_explained_var: 0.7309871912002563\n",
      "          vf_loss: 0.1904328529428468\n",
      "    num_agent_steps_sampled: 2658936\n",
      "    num_agent_steps_trained: 2658936\n",
      "    num_steps_sampled: 2658936\n",
      "    num_steps_trained: 2658936\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.3665948275862\n",
      "    ram_util_percent: 45.30646551724137\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050038719254576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.29923605534957\n",
      "    mean_inference_ms: 8.782820961791204\n",
      "    mean_raw_obs_processing_ms: 2.5131315936863086\n",
      "  time_since_restore: 82701.30370402336\n",
      "  time_this_iter_s: 325.02603459358215\n",
      "  time_total_s: 82701.30370402336\n",
      "  timers:\n",
      "    learn_throughput: 65.216\n",
      "    learn_time_ms: 153274.677\n",
      "    load_throughput: 86910.092\n",
      "    load_time_ms: 115.015\n",
      "    sample_throughput: 57.437\n",
      "    sample_time_ms: 174033.993\n",
      "    update_time_ms: 10.601\n",
      "  timestamp: 1636983444\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2658936\n",
      "  training_iteration: 266\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   266</td><td style=\"text-align: right;\">         82701.3</td><td style=\"text-align: right;\">2658936</td><td style=\"text-align: right;\"> 1.39203</td><td style=\"text-align: right;\">                8.83</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           85.3305</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2668932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-42-37\n",
      "  done: false\n",
      "  episode_len_mean: 86.64347826086957\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.670000000000012\n",
      "  episode_reward_mean: 1.1806086956521762\n",
      "  episode_reward_min: -1.810000000000001\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 28266\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6478407051828174\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007209761324082638\n",
      "          policy_loss: -0.027376808671471783\n",
      "          total_loss: 0.14489067554191296\n",
      "          vf_explained_var: 0.691409707069397\n",
      "          vf_loss: 0.18026806111288313\n",
      "    num_agent_steps_sampled: 2668932\n",
      "    num_agent_steps_trained: 2668932\n",
      "    num_steps_sampled: 2668932\n",
      "    num_steps_trained: 2668932\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.65505617977529\n",
      "    ram_util_percent: 45.25977528089887\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050036729725876715\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.313264162949025\n",
      "    mean_inference_ms: 8.783410494501533\n",
      "    mean_raw_obs_processing_ms: 2.5067648750924096\n",
      "  time_since_restore: 83013.52039694786\n",
      "  time_this_iter_s: 312.2166929244995\n",
      "  time_total_s: 83013.52039694786\n",
      "  timers:\n",
      "    learn_throughput: 65.203\n",
      "    learn_time_ms: 153305.647\n",
      "    load_throughput: 86645.222\n",
      "    load_time_ms: 115.367\n",
      "    sample_throughput: 58.097\n",
      "    sample_time_ms: 172057.823\n",
      "    update_time_ms: 9.597\n",
      "  timestamp: 1636983757\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2668932\n",
      "  training_iteration: 267\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   267</td><td style=\"text-align: right;\">         83013.5</td><td style=\"text-align: right;\">2668932</td><td style=\"text-align: right;\"> 1.18061</td><td style=\"text-align: right;\">                8.67</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           86.6435</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2678928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-48-06\n",
      "  done: false\n",
      "  episode_len_mean: 84.5677966101695\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.310000000000009\n",
      "  episode_reward_mean: 1.1567796610169516\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 28384\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.643009383352394\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009220980028598112\n",
      "          policy_loss: -0.02761271005958064\n",
      "          total_loss: 0.16280735388485731\n",
      "          vf_explained_var: 0.7190642356872559\n",
      "          vf_loss: 0.19321779511096832\n",
      "    num_agent_steps_sampled: 2678928\n",
      "    num_agent_steps_trained: 2678928\n",
      "    num_steps_sampled: 2678928\n",
      "    num_steps_trained: 2678928\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.25010615711253\n",
      "    ram_util_percent: 45.825053078556266\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05005994453305161\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.32380500674516\n",
      "    mean_inference_ms: 8.784428237623407\n",
      "    mean_raw_obs_processing_ms: 2.5110084745123107\n",
      "  time_since_restore: 83343.18406677246\n",
      "  time_this_iter_s: 329.6636698246002\n",
      "  time_total_s: 83343.18406677246\n",
      "  timers:\n",
      "    learn_throughput: 65.235\n",
      "    learn_time_ms: 153229.772\n",
      "    load_throughput: 86414.17\n",
      "    load_time_ms: 115.675\n",
      "    sample_throughput: 58.273\n",
      "    sample_time_ms: 171538.636\n",
      "    update_time_ms: 10.185\n",
      "  timestamp: 1636984086\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2678928\n",
      "  training_iteration: 268\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   268</td><td style=\"text-align: right;\">         83343.2</td><td style=\"text-align: right;\">2678928</td><td style=\"text-align: right;\"> 1.15678</td><td style=\"text-align: right;\">                6.31</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           84.5678</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2688924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-53-35\n",
      "  done: false\n",
      "  episode_len_mean: 85.68376068376068\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.06000000000001\n",
      "  episode_reward_mean: 1.6535897435897464\n",
      "  episode_reward_min: -1.5500000000000005\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 28501\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.643094083794162\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00893370058504085\n",
      "          policy_loss: -0.02355088953876024\n",
      "          total_loss: 0.17153580566653265\n",
      "          vf_explained_var: 0.7416312098503113\n",
      "          vf_loss: 0.19862153940101784\n",
      "    num_agent_steps_sampled: 2688924\n",
      "    num_agent_steps_trained: 2688924\n",
      "    num_steps_sampled: 2688924\n",
      "    num_steps_trained: 2688924\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.29935897435898\n",
      "    ram_util_percent: 45.782051282051285\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003655248535865\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.34198358381696\n",
      "    mean_inference_ms: 8.784372208676754\n",
      "    mean_raw_obs_processing_ms: 2.5123218318998566\n",
      "  time_since_restore: 83671.66260266304\n",
      "  time_this_iter_s: 328.4785358905792\n",
      "  time_total_s: 83671.66260266304\n",
      "  timers:\n",
      "    learn_throughput: 65.254\n",
      "    learn_time_ms: 153185.637\n",
      "    load_throughput: 86785.044\n",
      "    load_time_ms: 115.181\n",
      "    sample_throughput: 58.197\n",
      "    sample_time_ms: 171760.56\n",
      "    update_time_ms: 9.331\n",
      "  timestamp: 1636984415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2688924\n",
      "  training_iteration: 269\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   269</td><td style=\"text-align: right;\">         83671.7</td><td style=\"text-align: right;\">2688924</td><td style=\"text-align: right;\"> 1.65359</td><td style=\"text-align: right;\">               11.06</td><td style=\"text-align: right;\">               -1.55</td><td style=\"text-align: right;\">           85.6838</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2698920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_13-58-49\n",
      "  done: false\n",
      "  episode_len_mean: 86.52173913043478\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.030000000000012\n",
      "  episode_reward_mean: 1.1364347826086973\n",
      "  episode_reward_min: -1.6700000000000008\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 28616\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6438130296193636\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007571887831626839\n",
      "          policy_loss: -0.02475499921502211\n",
      "          total_loss: 0.14728871751377662\n",
      "          vf_explained_var: 0.6598328351974487\n",
      "          vf_loss: 0.17907592666407043\n",
      "    num_agent_steps_sampled: 2698920\n",
      "    num_agent_steps_trained: 2698920\n",
      "    num_steps_sampled: 2698920\n",
      "    num_steps_trained: 2698920\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.67572383073495\n",
      "    ram_util_percent: 45.77706013363029\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050036365437941085\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.356788048254174\n",
      "    mean_inference_ms: 8.78488111412473\n",
      "    mean_raw_obs_processing_ms: 2.5066998743669466\n",
      "  time_since_restore: 83986.06321120262\n",
      "  time_this_iter_s: 314.4006085395813\n",
      "  time_total_s: 83986.06321120262\n",
      "  timers:\n",
      "    learn_throughput: 65.222\n",
      "    learn_time_ms: 153261.091\n",
      "    load_throughput: 86876.434\n",
      "    load_time_ms: 115.06\n",
      "    sample_throughput: 58.649\n",
      "    sample_time_ms: 170436.34\n",
      "    update_time_ms: 11.051\n",
      "  timestamp: 1636984729\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2698920\n",
      "  training_iteration: 270\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   270</td><td style=\"text-align: right;\">         83986.1</td><td style=\"text-align: right;\">2698920</td><td style=\"text-align: right;\"> 1.13643</td><td style=\"text-align: right;\">                7.03</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           86.5217</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2708916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-04-16\n",
      "  done: false\n",
      "  episode_len_mean: 85.57758620689656\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.04000000000001\n",
      "  episode_reward_mean: 1.4262068965517263\n",
      "  episode_reward_min: -1.5500000000000007\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 28732\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6535858661700518\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008437856207631643\n",
      "          policy_loss: -0.02524915392645913\n",
      "          total_loss: 0.18889733914357537\n",
      "          vf_explained_var: 0.6948834657669067\n",
      "          vf_loss: 0.21905704891054423\n",
      "    num_agent_steps_sampled: 2708916\n",
      "    num_agent_steps_trained: 2708916\n",
      "    num_steps_sampled: 2708916\n",
      "    num_steps_trained: 2708916\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19656652360514\n",
      "    ram_util_percent: 45.80515021459228\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050042769889639134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.369205139332955\n",
      "    mean_inference_ms: 8.785410282973546\n",
      "    mean_raw_obs_processing_ms: 2.5113260477639674\n",
      "  time_since_restore: 84312.59956359863\n",
      "  time_this_iter_s: 326.53635239601135\n",
      "  time_total_s: 84312.59956359863\n",
      "  timers:\n",
      "    learn_throughput: 65.239\n",
      "    learn_time_ms: 153222.351\n",
      "    load_throughput: 86837.981\n",
      "    load_time_ms: 115.111\n",
      "    sample_throughput: 58.582\n",
      "    sample_time_ms: 170631.808\n",
      "    update_time_ms: 11.059\n",
      "  timestamp: 1636985056\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2708916\n",
      "  training_iteration: 271\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   271</td><td style=\"text-align: right;\">         84312.6</td><td style=\"text-align: right;\">2708916</td><td style=\"text-align: right;\"> 1.42621</td><td style=\"text-align: right;\">                9.04</td><td style=\"text-align: right;\">               -1.55</td><td style=\"text-align: right;\">           85.5776</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2718912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-09-42\n",
      "  done: false\n",
      "  episode_len_mean: 85.54237288135593\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.540000000000013\n",
      "  episode_reward_mean: 1.3242372881355957\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 28850\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6581233399546043\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007289699131455469\n",
      "          policy_loss: -0.026457348755664297\n",
      "          total_loss: 0.12961676756843415\n",
      "          vf_explained_var: 0.7848790287971497\n",
      "          vf_loss: 0.1639726482761594\n",
      "    num_agent_steps_sampled: 2718912\n",
      "    num_agent_steps_trained: 2718912\n",
      "    num_steps_sampled: 2718912\n",
      "    num_steps_trained: 2718912\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.32510729613733\n",
      "    ram_util_percent: 45.7332618025751\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050022865553873176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.38405970155174\n",
      "    mean_inference_ms: 8.78518559988664\n",
      "    mean_raw_obs_processing_ms: 2.513073025459505\n",
      "  time_since_restore: 84639.13880777359\n",
      "  time_this_iter_s: 326.5392441749573\n",
      "  time_total_s: 84639.13880777359\n",
      "  timers:\n",
      "    learn_throughput: 65.219\n",
      "    learn_time_ms: 153268.351\n",
      "    load_throughput: 86756.778\n",
      "    load_time_ms: 115.219\n",
      "    sample_throughput: 58.53\n",
      "    sample_time_ms: 170785.272\n",
      "    update_time_ms: 11.243\n",
      "  timestamp: 1636985382\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2718912\n",
      "  training_iteration: 272\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   272</td><td style=\"text-align: right;\">         84639.1</td><td style=\"text-align: right;\">2718912</td><td style=\"text-align: right;\"> 1.32424</td><td style=\"text-align: right;\">                8.54</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           85.5424</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2728908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-14-56\n",
      "  done: false\n",
      "  episode_len_mean: 87.35652173913043\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.750000000000012\n",
      "  episode_reward_mean: 1.7440000000000027\n",
      "  episode_reward_min: -2.040000000000001\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 28965\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.633692502262246\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008115675319528682\n",
      "          policy_loss: -0.023516894798948723\n",
      "          total_loss: 0.19848748730957252\n",
      "          vf_explained_var: 0.7509570717811584\n",
      "          vf_loss: 0.22754171922779046\n",
      "    num_agent_steps_sampled: 2728908\n",
      "    num_agent_steps_trained: 2728908\n",
      "    num_steps_sampled: 2728908\n",
      "    num_steps_trained: 2728908\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.9096196868009\n",
      "    ram_util_percent: 45.76286353467562\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0500266687333158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.39926612504742\n",
      "    mean_inference_ms: 8.78575062511138\n",
      "    mean_raw_obs_processing_ms: 2.5069167485675656\n",
      "  time_since_restore: 84952.63112950325\n",
      "  time_this_iter_s: 313.49232172966003\n",
      "  time_total_s: 84952.63112950325\n",
      "  timers:\n",
      "    learn_throughput: 65.211\n",
      "    learn_time_ms: 153288.174\n",
      "    load_throughput: 86217.861\n",
      "    load_time_ms: 115.939\n",
      "    sample_throughput: 58.896\n",
      "    sample_time_ms: 169722.883\n",
      "    update_time_ms: 10.657\n",
      "  timestamp: 1636985696\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2728908\n",
      "  training_iteration: 273\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   273</td><td style=\"text-align: right;\">         84952.6</td><td style=\"text-align: right;\">2728908</td><td style=\"text-align: right;\">   1.744</td><td style=\"text-align: right;\">                8.75</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           87.3565</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2738904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-20-37\n",
      "  done: false\n",
      "  episode_len_mean: 84.50847457627118\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.98000000000001\n",
      "  episode_reward_mean: 1.4718644067796636\n",
      "  episode_reward_min: -1.6900000000000008\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 29083\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6404890484280057\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007717549115560125\n",
      "          policy_loss: -0.02634730879535787\n",
      "          total_loss: 0.16516920406745475\n",
      "          vf_explained_var: 0.7416377067565918\n",
      "          vf_loss: 0.1981421693514746\n",
      "    num_agent_steps_sampled: 2738904\n",
      "    num_agent_steps_trained: 2738904\n",
      "    num_steps_sampled: 2738904\n",
      "    num_steps_trained: 2738904\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.87515400410678\n",
      "    ram_util_percent: 45.9305954825462\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05005677150696399\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.40690990416826\n",
      "    mean_inference_ms: 8.786726515879058\n",
      "    mean_raw_obs_processing_ms: 2.511819945974569\n",
      "  time_since_restore: 85293.77497005463\n",
      "  time_this_iter_s: 341.14384055137634\n",
      "  time_total_s: 85293.77497005463\n",
      "  timers:\n",
      "    learn_throughput: 65.249\n",
      "    learn_time_ms: 153198.206\n",
      "    load_throughput: 85602.113\n",
      "    load_time_ms: 116.773\n",
      "    sample_throughput: 58.368\n",
      "    sample_time_ms: 171257.001\n",
      "    update_time_ms: 10.557\n",
      "  timestamp: 1636986037\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2738904\n",
      "  training_iteration: 274\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   274</td><td style=\"text-align: right;\">         85293.8</td><td style=\"text-align: right;\">2738904</td><td style=\"text-align: right;\"> 1.47186</td><td style=\"text-align: right;\">                8.98</td><td style=\"text-align: right;\">               -1.69</td><td style=\"text-align: right;\">           84.5085</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2748900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-26-04\n",
      "  done: false\n",
      "  episode_len_mean: 87.28947368421052\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.100000000000008\n",
      "  episode_reward_mean: 1.283070175438599\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 29197\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.648998099310785\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007675435547069578\n",
      "          policy_loss: -0.024495643448944275\n",
      "          total_loss: 0.16356362443831232\n",
      "          vf_explained_var: 0.6829280853271484\n",
      "          vf_loss: 0.19487794691808202\n",
      "    num_agent_steps_sampled: 2748900\n",
      "    num_agent_steps_trained: 2748900\n",
      "    num_steps_sampled: 2748900\n",
      "    num_steps_trained: 2748900\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.33982869379014\n",
      "    ram_util_percent: 45.656745182012855\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002610752471872\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.42244011155719\n",
      "    mean_inference_ms: 8.786155353008843\n",
      "    mean_raw_obs_processing_ms: 2.512825426161116\n",
      "  time_since_restore: 85621.07486462593\n",
      "  time_this_iter_s: 327.2998945713043\n",
      "  time_total_s: 85621.07486462593\n",
      "  timers:\n",
      "    learn_throughput: 65.23\n",
      "    learn_time_ms: 153242.155\n",
      "    load_throughput: 85941.294\n",
      "    load_time_ms: 116.312\n",
      "    sample_throughput: 58.424\n",
      "    sample_time_ms: 171094.817\n",
      "    update_time_ms: 11.353\n",
      "  timestamp: 1636986364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2748900\n",
      "  training_iteration: 275\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   275</td><td style=\"text-align: right;\">         85621.1</td><td style=\"text-align: right;\">2748900</td><td style=\"text-align: right;\"> 1.28307</td><td style=\"text-align: right;\">                 7.1</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           87.2895</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2758896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-31-15\n",
      "  done: false\n",
      "  episode_len_mean: 87.58771929824562\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.440000000000015\n",
      "  episode_reward_mean: 1.554035087719301\n",
      "  episode_reward_min: -1.9500000000000008\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 29311\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6497742221905636\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.009236735315462666\n",
      "          policy_loss: -0.022060937829649983\n",
      "          total_loss: 0.1859455789765741\n",
      "          vf_explained_var: 0.7365950345993042\n",
      "          vf_loss: 0.21083151726529767\n",
      "    num_agent_steps_sampled: 2758896\n",
      "    num_agent_steps_trained: 2758896\n",
      "    num_steps_sampled: 2758896\n",
      "    num_steps_trained: 2758896\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.6846501128668\n",
      "    ram_util_percent: 45.61038374717834\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003760163999059\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.43307316970595\n",
      "    mean_inference_ms: 8.787071710192173\n",
      "    mean_raw_obs_processing_ms: 2.506705232465221\n",
      "  time_since_restore: 85931.6150522232\n",
      "  time_this_iter_s: 310.5401875972748\n",
      "  time_total_s: 85931.6150522232\n",
      "  timers:\n",
      "    learn_throughput: 65.233\n",
      "    learn_time_ms: 153236.147\n",
      "    load_throughput: 86105.369\n",
      "    load_time_ms: 116.09\n",
      "    sample_throughput: 58.92\n",
      "    sample_time_ms: 169652.381\n",
      "    update_time_ms: 10.917\n",
      "  timestamp: 1636986675\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2758896\n",
      "  training_iteration: 276\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   276</td><td style=\"text-align: right;\">         85931.6</td><td style=\"text-align: right;\">2758896</td><td style=\"text-align: right;\"> 1.55404</td><td style=\"text-align: right;\">                8.44</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           87.5877</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2768892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-36-58\n",
      "  done: false\n",
      "  episode_len_mean: 85.33050847457628\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.770000000000012\n",
      "  episode_reward_mean: 1.9456779661016985\n",
      "  episode_reward_min: -1.4700000000000009\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 29429\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6398288619823944\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008381875246006027\n",
      "          policy_loss: -0.020965325336855575\n",
      "          total_loss: 0.21575999138478794\n",
      "          vf_explained_var: 0.7334344983100891\n",
      "          vf_loss: 0.2416417761443135\n",
      "    num_agent_steps_sampled: 2768892\n",
      "    num_agent_steps_trained: 2768892\n",
      "    num_steps_sampled: 2768892\n",
      "    num_steps_trained: 2768892\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.01860940695298\n",
      "    ram_util_percent: 45.580368098159504\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050037989649866395\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.44467509021309\n",
      "    mean_inference_ms: 8.78748441104035\n",
      "    mean_raw_obs_processing_ms: 2.5118300167574215\n",
      "  time_since_restore: 86274.34957242012\n",
      "  time_this_iter_s: 342.7345201969147\n",
      "  time_total_s: 86274.34957242012\n",
      "  timers:\n",
      "    learn_throughput: 65.233\n",
      "    learn_time_ms: 153235.6\n",
      "    load_throughput: 86030.844\n",
      "    load_time_ms: 116.191\n",
      "    sample_throughput: 57.879\n",
      "    sample_time_ms: 172703.978\n",
      "    update_time_ms: 11.869\n",
      "  timestamp: 1636987018\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2768892\n",
      "  training_iteration: 277\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   277</td><td style=\"text-align: right;\">         86274.3</td><td style=\"text-align: right;\">2768892</td><td style=\"text-align: right;\"> 1.94568</td><td style=\"text-align: right;\">               10.77</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           85.3305</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2778888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-42-25\n",
      "  done: false\n",
      "  episode_len_mean: 85.79310344827586\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.220000000000011\n",
      "  episode_reward_mean: 1.0504310344827603\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 29545\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6498177244113044\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006917673886159153\n",
      "          policy_loss: -0.02148973451067622\n",
      "          total_loss: 0.16244791381033216\n",
      "          vf_explained_var: 0.7078914642333984\n",
      "          vf_loss: 0.19270658424466403\n",
      "    num_agent_steps_sampled: 2778888\n",
      "    num_agent_steps_trained: 2778888\n",
      "    num_steps_sampled: 2778888\n",
      "    num_steps_trained: 2778888\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.56702355460386\n",
      "    ram_util_percent: 45.72740899357601\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050025098196564435\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.45692772473074\n",
      "    mean_inference_ms: 8.78750888815893\n",
      "    mean_raw_obs_processing_ms: 2.514498421215034\n",
      "  time_since_restore: 86601.58596253395\n",
      "  time_this_iter_s: 327.23639011383057\n",
      "  time_total_s: 86601.58596253395\n",
      "  timers:\n",
      "    learn_throughput: 65.202\n",
      "    learn_time_ms: 153307.285\n",
      "    load_throughput: 86454.958\n",
      "    load_time_ms: 115.621\n",
      "    sample_throughput: 57.985\n",
      "    sample_time_ms: 172390.409\n",
      "    update_time_ms: 11.864\n",
      "  timestamp: 1636987345\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2778888\n",
      "  training_iteration: 278\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   278</td><td style=\"text-align: right;\">         86601.6</td><td style=\"text-align: right;\">2778888</td><td style=\"text-align: right;\"> 1.05043</td><td style=\"text-align: right;\">                7.22</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           85.7931</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2788884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-47-37\n",
      "  done: false\n",
      "  episode_len_mean: 87.26086956521739\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.020000000000007\n",
      "  episode_reward_mean: 1.435652173913046\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 29660\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.643436344974061\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007859228957653947\n",
      "          policy_loss: -0.025901701068107644\n",
      "          total_loss: 0.1560419932879412\n",
      "          vf_explained_var: 0.7217201590538025\n",
      "          vf_loss: 0.1882357137858804\n",
      "    num_agent_steps_sampled: 2788884\n",
      "    num_agent_steps_trained: 2788884\n",
      "    num_steps_sampled: 2788884\n",
      "    num_steps_trained: 2788884\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.86089887640449\n",
      "    ram_util_percent: 45.62898876404495\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05001811788639081\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.47254310419182\n",
      "    mean_inference_ms: 8.788366742803454\n",
      "    mean_raw_obs_processing_ms: 2.5076636169903255\n",
      "  time_since_restore: 86913.50254058838\n",
      "  time_this_iter_s: 311.9165780544281\n",
      "  time_total_s: 86913.50254058838\n",
      "  timers:\n",
      "    learn_throughput: 65.233\n",
      "    learn_time_ms: 153235.912\n",
      "    load_throughput: 86227.773\n",
      "    load_time_ms: 115.926\n",
      "    sample_throughput: 58.523\n",
      "    sample_time_ms: 170804.481\n",
      "    update_time_ms: 12.517\n",
      "  timestamp: 1636987657\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2788884\n",
      "  training_iteration: 279\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   279</td><td style=\"text-align: right;\">         86913.5</td><td style=\"text-align: right;\">2788884</td><td style=\"text-align: right;\"> 1.43565</td><td style=\"text-align: right;\">                7.02</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           87.2609</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2798880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-53-17\n",
      "  done: false\n",
      "  episode_len_mean: 86.6842105263158\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.87000000000001\n",
      "  episode_reward_mean: 1.451140350877196\n",
      "  episode_reward_min: -1.6200000000000006\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 29774\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.645667767422831\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0071636246250246\n",
      "          policy_loss: -0.024658493431778544\n",
      "          total_loss: 0.1756259506721543\n",
      "          vf_explained_var: 0.7298607230186462\n",
      "          vf_loss: 0.20838153661332195\n",
      "    num_agent_steps_sampled: 2798880\n",
      "    num_agent_steps_trained: 2798880\n",
      "    num_steps_sampled: 2798880\n",
      "    num_steps_trained: 2798880\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.94515463917524\n",
      "    ram_util_percent: 45.90886597938144\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003203346393725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.47826997783443\n",
      "    mean_inference_ms: 8.78959668178564\n",
      "    mean_raw_obs_processing_ms: 2.511279645937342\n",
      "  time_since_restore: 87253.92627596855\n",
      "  time_this_iter_s: 340.42373538017273\n",
      "  time_total_s: 87253.92627596855\n",
      "  timers:\n",
      "    learn_throughput: 65.236\n",
      "    learn_time_ms: 153228.268\n",
      "    load_throughput: 86047.229\n",
      "    load_time_ms: 116.169\n",
      "    sample_throughput: 57.642\n",
      "    sample_time_ms: 173414.852\n",
      "    update_time_ms: 11.512\n",
      "  timestamp: 1636987997\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2798880\n",
      "  training_iteration: 280\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   280</td><td style=\"text-align: right;\">         87253.9</td><td style=\"text-align: right;\">2798880</td><td style=\"text-align: right;\"> 1.45114</td><td style=\"text-align: right;\">                6.87</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">           86.6842</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2808876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_14-58-47\n",
      "  done: false\n",
      "  episode_len_mean: 87.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.730000000000013\n",
      "  episode_reward_mean: 1.1377391304347848\n",
      "  episode_reward_min: -2.1599999999999997\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 29889\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.655634123749203\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00776028272930397\n",
      "          policy_loss: -0.026181193640153123\n",
      "          total_loss: 0.14625270032745777\n",
      "          vf_explained_var: 0.7214721441268921\n",
      "          vf_loss: 0.17910147990720968\n",
      "    num_agent_steps_sampled: 2808876\n",
      "    num_agent_steps_trained: 2808876\n",
      "    num_steps_sampled: 2808876\n",
      "    num_steps_trained: 2808876\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.6859872611465\n",
      "    ram_util_percent: 45.56411889596602\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003969284971094\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.49143079819695\n",
      "    mean_inference_ms: 8.790146094830215\n",
      "    mean_raw_obs_processing_ms: 2.514273878419986\n",
      "  time_since_restore: 87583.95129728317\n",
      "  time_this_iter_s: 330.025021314621\n",
      "  time_total_s: 87583.95129728317\n",
      "  timers:\n",
      "    learn_throughput: 65.225\n",
      "    learn_time_ms: 153254.046\n",
      "    load_throughput: 86692.807\n",
      "    load_time_ms: 115.304\n",
      "    sample_throughput: 57.535\n",
      "    sample_time_ms: 173738.779\n",
      "    update_time_ms: 11.144\n",
      "  timestamp: 1636988327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2808876\n",
      "  training_iteration: 281\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   281</td><td style=\"text-align: right;\">           87584</td><td style=\"text-align: right;\">2808876</td><td style=\"text-align: right;\"> 1.13774</td><td style=\"text-align: right;\">                8.73</td><td style=\"text-align: right;\">               -2.16</td><td style=\"text-align: right;\">              87.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2818872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-04-14\n",
      "  done: false\n",
      "  episode_len_mean: 88.0701754385965\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.63000000000001\n",
      "  episode_reward_mean: 1.6028947368421083\n",
      "  episode_reward_min: -2.14\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 30003\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6523046091071563\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00842571506655952\n",
      "          policy_loss: -0.021125656276400017\n",
      "          total_loss: 0.20809812110880566\n",
      "          vf_explained_var: 0.7357605695724487\n",
      "          vf_loss: 0.23415263838206346\n",
      "    num_agent_steps_sampled: 2818872\n",
      "    num_agent_steps_trained: 2818872\n",
      "    num_steps_sampled: 2818872\n",
      "    num_steps_trained: 2818872\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.98583690987127\n",
      "    ram_util_percent: 45.43218884120172\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05001728518044146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.506236172966844\n",
      "    mean_inference_ms: 8.79059670397473\n",
      "    mean_raw_obs_processing_ms: 2.513110910988487\n",
      "  time_since_restore: 87910.58024191856\n",
      "  time_this_iter_s: 326.62894463539124\n",
      "  time_total_s: 87910.58024191856\n",
      "  timers:\n",
      "    learn_throughput: 65.263\n",
      "    learn_time_ms: 153164.566\n",
      "    load_throughput: 86591.036\n",
      "    load_time_ms: 115.439\n",
      "    sample_throughput: 57.502\n",
      "    sample_time_ms: 173837.064\n",
      "    update_time_ms: 10.808\n",
      "  timestamp: 1636988654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2818872\n",
      "  training_iteration: 282\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   282</td><td style=\"text-align: right;\">         87910.6</td><td style=\"text-align: right;\">2818872</td><td style=\"text-align: right;\"> 1.60289</td><td style=\"text-align: right;\">                8.63</td><td style=\"text-align: right;\">               -2.14</td><td style=\"text-align: right;\">           88.0702</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2828868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-09-41\n",
      "  done: false\n",
      "  episode_len_mean: 87.07826086956521\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.870000000000009\n",
      "  episode_reward_mean: 1.3946086956521768\n",
      "  episode_reward_min: -1.7500000000000007\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 30118\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.646668238925119\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007541064797632011\n",
      "          policy_loss: -0.02410719100939126\n",
      "          total_loss: 0.1543666907478697\n",
      "          vf_explained_var: 0.7655453085899353\n",
      "          vf_loss: 0.18561364005789416\n",
      "    num_agent_steps_sampled: 2828868\n",
      "    num_agent_steps_trained: 2828868\n",
      "    num_steps_sampled: 2828868\n",
      "    num_steps_trained: 2828868\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.0813704496788\n",
      "    ram_util_percent: 45.75267665952891\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003233717800078\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.514409632818165\n",
      "    mean_inference_ms: 8.791940850219536\n",
      "    mean_raw_obs_processing_ms: 2.5122034899932015\n",
      "  time_since_restore: 88237.45428776741\n",
      "  time_this_iter_s: 326.87404584884644\n",
      "  time_total_s: 88237.45428776741\n",
      "  timers:\n",
      "    learn_throughput: 65.249\n",
      "    learn_time_ms: 153198.671\n",
      "    load_throughput: 87431.517\n",
      "    load_time_ms: 114.329\n",
      "    sample_throughput: 57.074\n",
      "    sample_time_ms: 175141.189\n",
      "    update_time_ms: 11.944\n",
      "  timestamp: 1636988981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2828868\n",
      "  training_iteration: 283\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   283</td><td style=\"text-align: right;\">         88237.5</td><td style=\"text-align: right;\">2828868</td><td style=\"text-align: right;\"> 1.39461</td><td style=\"text-align: right;\">                6.87</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           87.0783</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2838864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 87.54385964912281\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.950000000000014\n",
      "  episode_reward_mean: 1.5263157894736867\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 30232\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.65285975871942\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007053676853333646\n",
      "          policy_loss: -0.026556307744855682\n",
      "          total_loss: 0.16008791165450253\n",
      "          vf_explained_var: 0.7392191290855408\n",
      "          vf_loss: 0.19509501499362672\n",
      "    num_agent_steps_sampled: 2838864\n",
      "    num_agent_steps_trained: 2838864\n",
      "    num_steps_sampled: 2838864\n",
      "    num_steps_trained: 2838864\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.36077586206895\n",
      "    ram_util_percent: 45.56702586206898\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002740710253149\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.52373266090405\n",
      "    mean_inference_ms: 8.79197722675165\n",
      "    mean_raw_obs_processing_ms: 2.5199314925411356\n",
      "  time_since_restore: 88562.73600435257\n",
      "  time_this_iter_s: 325.2817165851593\n",
      "  time_total_s: 88562.73600435257\n",
      "  timers:\n",
      "    learn_throughput: 65.229\n",
      "    learn_time_ms: 153244.155\n",
      "    load_throughput: 87857.381\n",
      "    load_time_ms: 113.775\n",
      "    sample_throughput: 57.611\n",
      "    sample_time_ms: 173509.018\n",
      "    update_time_ms: 11.892\n",
      "  timestamp: 1636989306\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2838864\n",
      "  training_iteration: 284\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   284</td><td style=\"text-align: right;\">         88562.7</td><td style=\"text-align: right;\">2838864</td><td style=\"text-align: right;\"> 1.52632</td><td style=\"text-align: right;\">                8.95</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           87.5439</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2848860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-20-19\n",
      "  done: false\n",
      "  episode_len_mean: 88.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.940000000000012\n",
      "  episode_reward_mean: 1.4977192982456167\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 30346\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6523593219936403\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007756680421724107\n",
      "          policy_loss: -0.023837638208563\n",
      "          total_loss: 0.18665327505511034\n",
      "          vf_explained_var: 0.7182493805885315\n",
      "          vf_loss: 0.21713498306190038\n",
      "    num_agent_steps_sampled: 2848860\n",
      "    num_agent_steps_trained: 2848860\n",
      "    num_steps_sampled: 2848860\n",
      "    num_steps_trained: 2848860\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.83744394618834\n",
      "    ram_util_percent: 45.46905829596411\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05002551002148952\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.53650548542429\n",
      "    mean_inference_ms: 8.792869349745345\n",
      "    mean_raw_obs_processing_ms: 2.5138711960102116\n",
      "  time_since_restore: 88875.7301337719\n",
      "  time_this_iter_s: 312.9941294193268\n",
      "  time_total_s: 88875.7301337719\n",
      "  timers:\n",
      "    learn_throughput: 65.227\n",
      "    learn_time_ms: 153248.574\n",
      "    load_throughput: 87682.79\n",
      "    load_time_ms: 114.002\n",
      "    sample_throughput: 58.091\n",
      "    sample_time_ms: 172075.263\n",
      "    update_time_ms: 11.124\n",
      "  timestamp: 1636989619\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2848860\n",
      "  training_iteration: 285\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   285</td><td style=\"text-align: right;\">         88875.7</td><td style=\"text-align: right;\">2848860</td><td style=\"text-align: right;\"> 1.49772</td><td style=\"text-align: right;\">                6.94</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">                88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2858856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-25-43\n",
      "  done: false\n",
      "  episode_len_mean: 87.34210526315789\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.010000000000012\n",
      "  episode_reward_mean: 1.4463157894736869\n",
      "  episode_reward_min: -1.7600000000000007\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 30460\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.654790788022881\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006676000288664849\n",
      "          policy_loss: -0.02543826985817689\n",
      "          total_loss: 0.1457627041086268\n",
      "          vf_explained_var: 0.7216504812240601\n",
      "          vf_loss: 0.18063902244425545\n",
      "    num_agent_steps_sampled: 2858856\n",
      "    num_agent_steps_trained: 2858856\n",
      "    num_steps_sampled: 2858856\n",
      "    num_steps_trained: 2858856\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.32878787878788\n",
      "    ram_util_percent: 45.73571428571427\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050029935228595314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.54586278512882\n",
      "    mean_inference_ms: 8.793443142571228\n",
      "    mean_raw_obs_processing_ms: 2.513650699038788\n",
      "  time_since_restore: 89199.3770198822\n",
      "  time_this_iter_s: 323.6468861103058\n",
      "  time_total_s: 89199.3770198822\n",
      "  timers:\n",
      "    learn_throughput: 65.197\n",
      "    learn_time_ms: 153320.782\n",
      "    load_throughput: 87430.715\n",
      "    load_time_ms: 114.331\n",
      "    sample_throughput: 57.676\n",
      "    sample_time_ms: 173312.858\n",
      "    update_time_ms: 11.812\n",
      "  timestamp: 1636989943\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2858856\n",
      "  training_iteration: 286\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   286</td><td style=\"text-align: right;\">         89199.4</td><td style=\"text-align: right;\">2858856</td><td style=\"text-align: right;\"> 1.44632</td><td style=\"text-align: right;\">                9.01</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           87.3421</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2868852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-31-08\n",
      "  done: false\n",
      "  episode_len_mean: 88.33333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.120000000000013\n",
      "  episode_reward_mean: 1.4328947368421079\n",
      "  episode_reward_min: -1.9100000000000008\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 30574\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6468829965998983\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008086170210617255\n",
      "          policy_loss: -0.026807709507898896\n",
      "          total_loss: 0.1796597899065122\n",
      "          vf_explained_var: 0.7438666224479675\n",
      "          vf_loss: 0.21221235998404714\n",
      "    num_agent_steps_sampled: 2868852\n",
      "    num_agent_steps_trained: 2868852\n",
      "    num_steps_sampled: 2868852\n",
      "    num_steps_trained: 2868852\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.48491379310346\n",
      "    ram_util_percent: 45.76487068965517\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003289903177245\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.55383106221262\n",
      "    mean_inference_ms: 8.794021214107056\n",
      "    mean_raw_obs_processing_ms: 2.5176483623324835\n",
      "  time_since_restore: 89524.66731476784\n",
      "  time_this_iter_s: 325.2902948856354\n",
      "  time_total_s: 89524.66731476784\n",
      "  timers:\n",
      "    learn_throughput: 65.215\n",
      "    learn_time_ms: 153276.525\n",
      "    load_throughput: 87922.899\n",
      "    load_time_ms: 113.691\n",
      "    sample_throughput: 58.247\n",
      "    sample_time_ms: 171613.452\n",
      "    update_time_ms: 11.391\n",
      "  timestamp: 1636990268\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2868852\n",
      "  training_iteration: 287\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   287</td><td style=\"text-align: right;\">         89524.7</td><td style=\"text-align: right;\">2868852</td><td style=\"text-align: right;\"> 1.43289</td><td style=\"text-align: right;\">                7.12</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           88.3333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2878848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-36-22\n",
      "  done: false\n",
      "  episode_len_mean: 88.47321428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.170000000000013\n",
      "  episode_reward_mean: 1.3807142857142882\n",
      "  episode_reward_min: -1.6000000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 30686\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6423077253194958\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006953012103921516\n",
      "          policy_loss: -0.027424035769783788\n",
      "          total_loss: 0.138258271652441\n",
      "          vf_explained_var: 0.7820891737937927\n",
      "          vf_loss: 0.1742855753351608\n",
      "    num_agent_steps_sampled: 2878848\n",
      "    num_agent_steps_trained: 2878848\n",
      "    num_steps_sampled: 2878848\n",
      "    num_steps_trained: 2878848\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.70984340044744\n",
      "    ram_util_percent: 45.876286353467556\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05004297512240712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.56404698172471\n",
      "    mean_inference_ms: 8.794580836840014\n",
      "    mean_raw_obs_processing_ms: 2.51426231853157\n",
      "  time_since_restore: 89837.74473834038\n",
      "  time_this_iter_s: 313.0774235725403\n",
      "  time_total_s: 89837.74473834038\n",
      "  timers:\n",
      "    learn_throughput: 65.227\n",
      "    learn_time_ms: 153249.187\n",
      "    load_throughput: 88027.216\n",
      "    load_time_ms: 113.556\n",
      "    sample_throughput: 58.722\n",
      "    sample_time_ms: 170224.414\n",
      "    update_time_ms: 11.482\n",
      "  timestamp: 1636990582\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2878848\n",
      "  training_iteration: 288\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   288</td><td style=\"text-align: right;\">         89837.7</td><td style=\"text-align: right;\">2878848</td><td style=\"text-align: right;\"> 1.38071</td><td style=\"text-align: right;\">                6.17</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           88.4732</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2888844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-41-46\n",
      "  done: false\n",
      "  episode_len_mean: 87.20869565217392\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.740000000000013\n",
      "  episode_reward_mean: 1.35626086956522\n",
      "  episode_reward_min: -1.880000000000001\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 30801\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6408994195807693\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007981928905210404\n",
      "          policy_loss: -0.027000903058001118\n",
      "          total_loss: 0.140952922252572\n",
      "          vf_explained_var: 0.7743754386901855\n",
      "          vf_loss: 0.17390600918139468\n",
      "    num_agent_steps_sampled: 2888844\n",
      "    num_agent_steps_trained: 2888844\n",
      "    num_steps_sampled: 2888844\n",
      "    num_steps_trained: 2888844\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.41922246220304\n",
      "    ram_util_percent: 45.86544276457883\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050043360717989094\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.57342741245732\n",
      "    mean_inference_ms: 8.795123503040575\n",
      "    mean_raw_obs_processing_ms: 2.5143517973445135\n",
      "  time_since_restore: 90162.09180116653\n",
      "  time_this_iter_s: 324.3470628261566\n",
      "  time_total_s: 90162.09180116653\n",
      "  timers:\n",
      "    learn_throughput: 65.199\n",
      "    learn_time_ms: 153315.068\n",
      "    load_throughput: 87678.353\n",
      "    load_time_ms: 114.008\n",
      "    sample_throughput: 58.319\n",
      "    sample_time_ms: 171401.985\n",
      "    update_time_ms: 10.912\n",
      "  timestamp: 1636990906\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2888844\n",
      "  training_iteration: 289\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   289</td><td style=\"text-align: right;\">         90162.1</td><td style=\"text-align: right;\">2888844</td><td style=\"text-align: right;\"> 1.35626</td><td style=\"text-align: right;\">                8.74</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           87.2087</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2898840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-47-15\n",
      "  done: false\n",
      "  episode_len_mean: 86.14782608695653\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.110000000000011\n",
      "  episode_reward_mean: 1.4619130434782635\n",
      "  episode_reward_min: -1.6600000000000006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 30916\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6464540785194464\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0074345126179868335\n",
      "          policy_loss: -0.025178764407865258\n",
      "          total_loss: 0.16816043231087044\n",
      "          vf_explained_var: 0.7629613876342773\n",
      "          vf_loss: 0.20074989437364424\n",
      "    num_agent_steps_sampled: 2898840\n",
      "    num_agent_steps_trained: 2898840\n",
      "    num_steps_sampled: 2898840\n",
      "    num_steps_trained: 2898840\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.27121535181237\n",
      "    ram_util_percent: 45.81407249466951\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050030888608218964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.58603725465817\n",
      "    mean_inference_ms: 8.79524650761135\n",
      "    mean_raw_obs_processing_ms: 2.520357251243427\n",
      "  time_since_restore: 90491.13219046593\n",
      "  time_this_iter_s: 329.0403892993927\n",
      "  time_total_s: 90491.13219046593\n",
      "  timers:\n",
      "    learn_throughput: 65.214\n",
      "    learn_time_ms: 153279.17\n",
      "    load_throughput: 88332.373\n",
      "    load_time_ms: 113.163\n",
      "    sample_throughput: 58.696\n",
      "    sample_time_ms: 170300.331\n",
      "    update_time_ms: 10.977\n",
      "  timestamp: 1636991235\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2898840\n",
      "  training_iteration: 290\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   290</td><td style=\"text-align: right;\">         90491.1</td><td style=\"text-align: right;\">2898840</td><td style=\"text-align: right;\"> 1.46191</td><td style=\"text-align: right;\">                7.11</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           86.1478</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2908836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-52-40\n",
      "  done: false\n",
      "  episode_len_mean: 87.54385964912281\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.27000000000001\n",
      "  episode_reward_mean: 1.478070175438599\n",
      "  episode_reward_min: -1.7900000000000005\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 31030\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6347017905650993\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0074218083191151495\n",
      "          policy_loss: -0.025112134432340533\n",
      "          total_loss: 0.16571967169546928\n",
      "          vf_explained_var: 0.7644220590591431\n",
      "          vf_loss: 0.198157540965093\n",
      "    num_agent_steps_sampled: 2908836\n",
      "    num_agent_steps_trained: 2908836\n",
      "    num_steps_sampled: 2908836\n",
      "    num_steps_trained: 2908836\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.32241379310345\n",
      "    ram_util_percent: 45.963577586206895\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003363915374466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.594239715867346\n",
      "    mean_inference_ms: 8.796294044189287\n",
      "    mean_raw_obs_processing_ms: 2.51975307298004\n",
      "  time_since_restore: 90816.28272461891\n",
      "  time_this_iter_s: 325.1505341529846\n",
      "  time_total_s: 90816.28272461891\n",
      "  timers:\n",
      "    learn_throughput: 65.198\n",
      "    learn_time_ms: 153318.698\n",
      "    load_throughput: 87880.401\n",
      "    load_time_ms: 113.745\n",
      "    sample_throughput: 58.878\n",
      "    sample_time_ms: 169773.886\n",
      "    update_time_ms: 10.656\n",
      "  timestamp: 1636991560\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2908836\n",
      "  training_iteration: 291\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   291</td><td style=\"text-align: right;\">         90816.3</td><td style=\"text-align: right;\">2908836</td><td style=\"text-align: right;\"> 1.47807</td><td style=\"text-align: right;\">               11.27</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           87.5439</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2918832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_15-58-05\n",
      "  done: false\n",
      "  episode_len_mean: 87.00869565217391\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.680000000000012\n",
      "  episode_reward_mean: 1.5225217391304375\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 31145\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6388682750555184\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008840300490093426\n",
      "          policy_loss: -0.021394311408233693\n",
      "          total_loss: 0.2008171129315041\n",
      "          vf_explained_var: 0.6972230672836304\n",
      "          vf_loss: 0.2259433837265222\n",
      "    num_agent_steps_sampled: 2918832\n",
      "    num_agent_steps_trained: 2918832\n",
      "    num_steps_sampled: 2918832\n",
      "    num_steps_trained: 2918832\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.29913793103448\n",
      "    ram_util_percent: 45.95043103448276\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050028440361200154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.60491224474973\n",
      "    mean_inference_ms: 8.79630456627367\n",
      "    mean_raw_obs_processing_ms: 2.522125844585824\n",
      "  time_since_restore: 91141.0715584755\n",
      "  time_this_iter_s: 324.78883385658264\n",
      "  time_total_s: 91141.0715584755\n",
      "  timers:\n",
      "    learn_throughput: 65.179\n",
      "    learn_time_ms: 153362.533\n",
      "    load_throughput: 87534.818\n",
      "    load_time_ms: 114.195\n",
      "    sample_throughput: 58.957\n",
      "    sample_time_ms: 169546.262\n",
      "    update_time_ms: 10.497\n",
      "  timestamp: 1636991885\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2918832\n",
      "  training_iteration: 292\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   292</td><td style=\"text-align: right;\">         91141.1</td><td style=\"text-align: right;\">2918832</td><td style=\"text-align: right;\"> 1.52252</td><td style=\"text-align: right;\">               10.68</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           87.0087</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2928828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-03-22\n",
      "  done: false\n",
      "  episode_len_mean: 85.13559322033899\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.010000000000012\n",
      "  episode_reward_mean: 1.408305084745765\n",
      "  episode_reward_min: -1.6500000000000008\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 31263\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.640412743274982\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006827094695670493\n",
      "          policy_loss: -0.024582035464640613\n",
      "          total_loss: 0.18323576962097715\n",
      "          vf_explained_var: 0.7163925170898438\n",
      "          vf_loss: 0.21672483581341168\n",
      "    num_agent_steps_sampled: 2928828\n",
      "    num_agent_steps_trained: 2928828\n",
      "    num_steps_sampled: 2928828\n",
      "    num_steps_trained: 2928828\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.87234513274336\n",
      "    ram_util_percent: 45.447566371681404\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050041879711202095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.621078939647404\n",
      "    mean_inference_ms: 8.797697046976294\n",
      "    mean_raw_obs_processing_ms: 2.5144217243192926\n",
      "  time_since_restore: 91457.83186221123\n",
      "  time_this_iter_s: 316.76030373573303\n",
      "  time_total_s: 91457.83186221123\n",
      "  timers:\n",
      "    learn_throughput: 65.217\n",
      "    learn_time_ms: 153274.05\n",
      "    load_throughput: 86745.236\n",
      "    load_time_ms: 115.234\n",
      "    sample_throughput: 59.28\n",
      "    sample_time_ms: 168623.4\n",
      "    update_time_ms: 9.745\n",
      "  timestamp: 1636992202\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2928828\n",
      "  training_iteration: 293\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   293</td><td style=\"text-align: right;\">         91457.8</td><td style=\"text-align: right;\">2928828</td><td style=\"text-align: right;\"> 1.40831</td><td style=\"text-align: right;\">                7.01</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">           85.1356</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2938824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-09-08\n",
      "  done: false\n",
      "  episode_len_mean: 86.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.880000000000011\n",
      "  episode_reward_mean: 1.3591379310344849\n",
      "  episode_reward_min: -1.7700000000000007\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 31379\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.634008427257212\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007869304079555557\n",
      "          policy_loss: -0.02420018339712714\n",
      "          total_loss: 0.18012585181336946\n",
      "          vf_explained_var: 0.726006805896759\n",
      "          vf_loss: 0.21049795388443093\n",
      "    num_agent_steps_sampled: 2938824\n",
      "    num_agent_steps_trained: 2938824\n",
      "    num_steps_sampled: 2938824\n",
      "    num_steps_trained: 2938824\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.98198380566801\n",
      "    ram_util_percent: 45.44838056680162\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050034435951395576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.635555193864\n",
      "    mean_inference_ms: 8.797849587201252\n",
      "    mean_raw_obs_processing_ms: 2.5189813426655827\n",
      "  time_since_restore: 91804.40391635895\n",
      "  time_this_iter_s: 346.57205414772034\n",
      "  time_total_s: 91804.40391635895\n",
      "  timers:\n",
      "    learn_throughput: 65.203\n",
      "    learn_time_ms: 153305.058\n",
      "    load_throughput: 86775.955\n",
      "    load_time_ms: 115.193\n",
      "    sample_throughput: 58.551\n",
      "    sample_time_ms: 170722.4\n",
      "    update_time_ms: 9.334\n",
      "  timestamp: 1636992548\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2938824\n",
      "  training_iteration: 294\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   294</td><td style=\"text-align: right;\">         91804.4</td><td style=\"text-align: right;\">2938824</td><td style=\"text-align: right;\"> 1.35914</td><td style=\"text-align: right;\">                8.88</td><td style=\"text-align: right;\">               -1.77</td><td style=\"text-align: right;\">                86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2948820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-14-43\n",
      "  done: false\n",
      "  episode_len_mean: 86.34482758620689\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.080000000000014\n",
      "  episode_reward_mean: 1.6817241379310373\n",
      "  episode_reward_min: -1.820000000000001\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 31495\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.640677185751434\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0065630192162371955\n",
      "          policy_loss: -0.023040344760331333\n",
      "          total_loss: 0.17393529638011232\n",
      "          vf_explained_var: 0.7327281832695007\n",
      "          vf_loss: 0.20656211246203027\n",
      "    num_agent_steps_sampled: 2948820\n",
      "    num_agent_steps_trained: 2948820\n",
      "    num_steps_sampled: 2948820\n",
      "    num_steps_trained: 2948820\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.46924686192469\n",
      "    ram_util_percent: 45.79539748953975\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003352731192949\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.652952521139966\n",
      "    mean_inference_ms: 8.798122221564755\n",
      "    mean_raw_obs_processing_ms: 2.5209546592384786\n",
      "  time_since_restore: 92139.31436538696\n",
      "  time_this_iter_s: 334.91044902801514\n",
      "  time_total_s: 92139.31436538696\n",
      "  timers:\n",
      "    learn_throughput: 65.219\n",
      "    learn_time_ms: 153268.355\n",
      "    load_throughput: 86241.643\n",
      "    load_time_ms: 115.907\n",
      "    sample_throughput: 57.797\n",
      "    sample_time_ms: 172949.076\n",
      "    update_time_ms: 10.106\n",
      "  timestamp: 1636992883\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2948820\n",
      "  training_iteration: 295\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   295</td><td style=\"text-align: right;\">         92139.3</td><td style=\"text-align: right;\">2948820</td><td style=\"text-align: right;\"> 1.68172</td><td style=\"text-align: right;\">                7.08</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">           86.3448</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2958816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-20-06\n",
      "  done: false\n",
      "  episode_len_mean: 86.86086956521739\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.730000000000011\n",
      "  episode_reward_mean: 0.9758260869565235\n",
      "  episode_reward_min: -1.7100000000000006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 31610\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.636964913107391\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006556558885997486\n",
      "          policy_loss: -0.024948935095682485\n",
      "          total_loss: 0.15696529176535928\n",
      "          vf_explained_var: 0.6780102849006653\n",
      "          vf_loss: 0.19148013264728853\n",
      "    num_agent_steps_sampled: 2958816\n",
      "    num_agent_steps_trained: 2958816\n",
      "    num_steps_sampled: 2958816\n",
      "    num_steps_trained: 2958816\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.86413043478261\n",
      "    ram_util_percent: 45.65239130434784\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050046846840105845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.67239902873848\n",
      "    mean_inference_ms: 8.799428753962339\n",
      "    mean_raw_obs_processing_ms: 2.51272692672132\n",
      "  time_since_restore: 92461.47027492523\n",
      "  time_this_iter_s: 322.15590953826904\n",
      "  time_total_s: 92461.47027492523\n",
      "  timers:\n",
      "    learn_throughput: 65.244\n",
      "    learn_time_ms: 153210.017\n",
      "    load_throughput: 86655.824\n",
      "    load_time_ms: 115.353\n",
      "    sample_throughput: 57.828\n",
      "    sample_time_ms: 172858.17\n",
      "    update_time_ms: 10.334\n",
      "  timestamp: 1636993206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2958816\n",
      "  training_iteration: 296\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   296</td><td style=\"text-align: right;\">         92461.5</td><td style=\"text-align: right;\">2958816</td><td style=\"text-align: right;\">0.975826</td><td style=\"text-align: right;\">                8.73</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           86.8609</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2968812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-25-46\n",
      "  done: false\n",
      "  episode_len_mean: 86.04273504273505\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.880000000000008\n",
      "  episode_reward_mean: 1.1480341880341904\n",
      "  episode_reward_min: -1.8800000000000008\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 31727\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.644962383233584\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007961031032814177\n",
      "          policy_loss: -0.022487113951968077\n",
      "          total_loss: 0.1724280895259327\n",
      "          vf_explained_var: 0.6805382370948792\n",
      "          vf_loss: 0.20096157648019555\n",
      "    num_agent_steps_sampled: 2968812\n",
      "    num_agent_steps_trained: 2968812\n",
      "    num_steps_sampled: 2968812\n",
      "    num_steps_trained: 2968812\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.83628865979381\n",
      "    ram_util_percent: 45.57216494845362\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050037578082202834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.68374566389414\n",
      "    mean_inference_ms: 8.79968318501404\n",
      "    mean_raw_obs_processing_ms: 2.5203081895513564\n",
      "  time_since_restore: 92801.86261415482\n",
      "  time_this_iter_s: 340.39233922958374\n",
      "  time_total_s: 92801.86261415482\n",
      "  timers:\n",
      "    learn_throughput: 65.227\n",
      "    learn_time_ms: 153249.961\n",
      "    load_throughput: 86036.546\n",
      "    load_time_ms: 116.183\n",
      "    sample_throughput: 57.34\n",
      "    sample_time_ms: 174328.432\n",
      "    update_time_ms: 9.824\n",
      "  timestamp: 1636993546\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2968812\n",
      "  training_iteration: 297\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   297</td><td style=\"text-align: right;\">         92801.9</td><td style=\"text-align: right;\">2968812</td><td style=\"text-align: right;\"> 1.14803</td><td style=\"text-align: right;\">                6.88</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           86.0427</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2978808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-31-19\n",
      "  done: false\n",
      "  episode_len_mean: 87.44736842105263\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.240000000000006\n",
      "  episode_reward_mean: 1.3224561403508797\n",
      "  episode_reward_min: -1.940000000000001\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 31841\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.641324911871527\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0069298912651530415\n",
      "          policy_loss: -0.024680102509884245\n",
      "          total_loss: 0.16195575748411062\n",
      "          vf_explained_var: 0.7301974892616272\n",
      "          vf_loss: 0.19528855585023505\n",
      "    num_agent_steps_sampled: 2978808\n",
      "    num_agent_steps_trained: 2978808\n",
      "    num_steps_sampled: 2978808\n",
      "    num_steps_trained: 2978808\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.74821052631579\n",
      "    ram_util_percent: 45.76063157894737\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05005258434038051\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.69544145206184\n",
      "    mean_inference_ms: 8.800932349656996\n",
      "    mean_raw_obs_processing_ms: 2.5203554107481456\n",
      "  time_since_restore: 93134.79848480225\n",
      "  time_this_iter_s: 332.9358706474304\n",
      "  time_total_s: 93134.79848480225\n",
      "  timers:\n",
      "    learn_throughput: 65.224\n",
      "    learn_time_ms: 153256.58\n",
      "    load_throughput: 86062.931\n",
      "    load_time_ms: 116.148\n",
      "    sample_throughput: 56.696\n",
      "    sample_time_ms: 176307.897\n",
      "    update_time_ms: 9.765\n",
      "  timestamp: 1636993879\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2978808\n",
      "  training_iteration: 298\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   298</td><td style=\"text-align: right;\">         93134.8</td><td style=\"text-align: right;\">2978808</td><td style=\"text-align: right;\"> 1.32246</td><td style=\"text-align: right;\">                7.24</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           87.4474</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2988804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-36-46\n",
      "  done: false\n",
      "  episode_len_mean: 86.65217391304348\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.210000000000008\n",
      "  episode_reward_mean: 1.750695652173916\n",
      "  episode_reward_min: -1.840000000000001\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 31956\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6318466040823196\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006186887919006856\n",
      "          policy_loss: -0.021832756924196187\n",
      "          total_loss: 0.18076333335927156\n",
      "          vf_explained_var: 0.7421691417694092\n",
      "          vf_loss: 0.2130582393059491\n",
      "    num_agent_steps_sampled: 2988804\n",
      "    num_agent_steps_trained: 2988804\n",
      "    num_steps_sampled: 2988804\n",
      "    num_steps_trained: 2988804\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.22398286937903\n",
      "    ram_util_percent: 45.669379014989296\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050046593236570486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.70698682861498\n",
      "    mean_inference_ms: 8.801414098681049\n",
      "    mean_raw_obs_processing_ms: 2.5190555549113682\n",
      "  time_since_restore: 93461.71451830864\n",
      "  time_this_iter_s: 326.91603350639343\n",
      "  time_total_s: 93461.71451830864\n",
      "  timers:\n",
      "    learn_throughput: 65.213\n",
      "    learn_time_ms: 153283.174\n",
      "    load_throughput: 86490.949\n",
      "    load_time_ms: 115.573\n",
      "    sample_throughput: 56.622\n",
      "    sample_time_ms: 176538.791\n",
      "    update_time_ms: 9.99\n",
      "  timestamp: 1636994206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2988804\n",
      "  training_iteration: 299\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   299</td><td style=\"text-align: right;\">         93461.7</td><td style=\"text-align: right;\">2988804</td><td style=\"text-align: right;\">  1.7507</td><td style=\"text-align: right;\">                7.21</td><td style=\"text-align: right;\">               -1.84</td><td style=\"text-align: right;\">           86.6522</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 2998800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-42-01\n",
      "  done: false\n",
      "  episode_len_mean: 86.80172413793103\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.640000000000008\n",
      "  episode_reward_mean: 1.684655172413796\n",
      "  episode_reward_min: -1.720000000000001\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 32072\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6306792794129787\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007129886990517685\n",
      "          policy_loss: -0.023112370002951122\n",
      "          total_loss: 0.2188606854343118\n",
      "          vf_explained_var: 0.7224344611167908\n",
      "          vf_loss: 0.25000672838212845\n",
      "    num_agent_steps_sampled: 2998800\n",
      "    num_agent_steps_trained: 2998800\n",
      "    num_steps_sampled: 2998800\n",
      "    num_steps_trained: 2998800\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.89311111111111\n",
      "    ram_util_percent: 45.48066666666666\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05005149383950425\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.720257567186096\n",
      "    mean_inference_ms: 8.802407704524807\n",
      "    mean_raw_obs_processing_ms: 2.514050063860877\n",
      "  time_since_restore: 93776.88273000717\n",
      "  time_this_iter_s: 315.1682116985321\n",
      "  time_total_s: 93776.88273000717\n",
      "  timers:\n",
      "    learn_throughput: 65.179\n",
      "    learn_time_ms: 153362.862\n",
      "    load_throughput: 86073.904\n",
      "    load_time_ms: 116.133\n",
      "    sample_throughput: 57.097\n",
      "    sample_time_ms: 175071.554\n",
      "    update_time_ms: 10.032\n",
      "  timestamp: 1636994521\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2998800\n",
      "  training_iteration: 300\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   300</td><td style=\"text-align: right;\">         93776.9</td><td style=\"text-align: right;\">2998800</td><td style=\"text-align: right;\"> 1.68466</td><td style=\"text-align: right;\">                8.64</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           86.8017</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3008796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-47-45\n",
      "  done: false\n",
      "  episode_len_mean: 86.13913043478261\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.140000000000011\n",
      "  episode_reward_mean: 1.467478260869568\n",
      "  episode_reward_min: -2.3000000000000003\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 32187\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6328452088893988\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006320053456304075\n",
      "          policy_loss: -0.02129911013886842\n",
      "          total_loss: 0.1700288786377726\n",
      "          vf_explained_var: 0.7579931020736694\n",
      "          vf_loss: 0.20145883539285606\n",
      "    num_agent_steps_sampled: 3008796\n",
      "    num_agent_steps_trained: 3008796\n",
      "    num_steps_sampled: 3008796\n",
      "    num_steps_trained: 3008796\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.16191446028513\n",
      "    ram_util_percent: 45.55885947046843\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050035375171603745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.733427221032166\n",
      "    mean_inference_ms: 8.80194012665493\n",
      "    mean_raw_obs_processing_ms: 2.5228876155302813\n",
      "  time_since_restore: 94120.96410703659\n",
      "  time_this_iter_s: 344.08137702941895\n",
      "  time_total_s: 94120.96410703659\n",
      "  timers:\n",
      "    learn_throughput: 65.214\n",
      "    learn_time_ms: 153278.949\n",
      "    load_throughput: 86679.222\n",
      "    load_time_ms: 115.322\n",
      "    sample_throughput: 56.459\n",
      "    sample_time_ms: 177048.974\n",
      "    update_time_ms: 10.443\n",
      "  timestamp: 1636994865\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3008796\n",
      "  training_iteration: 301\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   301</td><td style=\"text-align: right;\">           94121</td><td style=\"text-align: right;\">3008796</td><td style=\"text-align: right;\"> 1.46748</td><td style=\"text-align: right;\">                7.14</td><td style=\"text-align: right;\">                -2.3</td><td style=\"text-align: right;\">           86.1391</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3018792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-53-15\n",
      "  done: false\n",
      "  episode_len_mean: 87.38260869565218\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.350000000000017\n",
      "  episode_reward_mean: 1.251304347826089\n",
      "  episode_reward_min: -1.760000000000001\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 32302\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6382649627506223\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006063233875182315\n",
      "          policy_loss: -0.024256679170534142\n",
      "          total_loss: 0.1579634363966015\n",
      "          vf_explained_var: 0.7372511625289917\n",
      "          vf_loss: 0.19306336021783133\n",
      "    num_agent_steps_sampled: 3018792\n",
      "    num_agent_steps_trained: 3018792\n",
      "    num_steps_sampled: 3018792\n",
      "    num_steps_trained: 3018792\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.48638297872341\n",
      "    ram_util_percent: 45.457446808510646\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050050775859992014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.745418349342124\n",
      "    mean_inference_ms: 8.803462193473274\n",
      "    mean_raw_obs_processing_ms: 2.5195008516714683\n",
      "  time_since_restore: 94450.73602175713\n",
      "  time_this_iter_s: 329.7719147205353\n",
      "  time_total_s: 94450.73602175713\n",
      "  timers:\n",
      "    learn_throughput: 65.211\n",
      "    learn_time_ms: 153286.399\n",
      "    load_throughput: 87146.271\n",
      "    load_time_ms: 114.704\n",
      "    sample_throughput: 56.303\n",
      "    sample_time_ms: 177540.025\n",
      "    update_time_ms: 10.604\n",
      "  timestamp: 1636995195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3018792\n",
      "  training_iteration: 302\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   302</td><td style=\"text-align: right;\">         94450.7</td><td style=\"text-align: right;\">3018792</td><td style=\"text-align: right;\">  1.2513</td><td style=\"text-align: right;\">               10.35</td><td style=\"text-align: right;\">               -1.76</td><td style=\"text-align: right;\">           87.3826</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3028788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_16-58-36\n",
      "  done: false\n",
      "  episode_len_mean: 87.85964912280701\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.950000000000014\n",
      "  episode_reward_mean: 1.478333333333336\n",
      "  episode_reward_min: -2.2100000000000004\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 32416\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.636877772033724\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007191338335693134\n",
      "          policy_loss: -0.02416983887147254\n",
      "          total_loss: 0.183209233575214\n",
      "          vf_explained_var: 0.7068713903427124\n",
      "          vf_loss: 0.21531723643868014\n",
      "    num_agent_steps_sampled: 3028788\n",
      "    num_agent_steps_trained: 3028788\n",
      "    num_steps_sampled: 3028788\n",
      "    num_steps_trained: 3028788\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.79190371991247\n",
      "    ram_util_percent: 45.413566739606125\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050055241647917054\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.760964091288294\n",
      "    mean_inference_ms: 8.803969273627011\n",
      "    mean_raw_obs_processing_ms: 2.5151958516477997\n",
      "  time_since_restore: 94771.28508234024\n",
      "  time_this_iter_s: 320.5490605831146\n",
      "  time_total_s: 94771.28508234024\n",
      "  timers:\n",
      "    learn_throughput: 65.177\n",
      "    learn_time_ms: 153365.875\n",
      "    load_throughput: 87629.149\n",
      "    load_time_ms: 114.072\n",
      "    sample_throughput: 56.208\n",
      "    sample_time_ms: 177839.239\n",
      "    update_time_ms: 10.983\n",
      "  timestamp: 1636995516\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3028788\n",
      "  training_iteration: 303\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   303</td><td style=\"text-align: right;\">         94771.3</td><td style=\"text-align: right;\">3028788</td><td style=\"text-align: right;\"> 1.47833</td><td style=\"text-align: right;\">               14.95</td><td style=\"text-align: right;\">               -2.21</td><td style=\"text-align: right;\">           87.8596</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3038784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-04-19\n",
      "  done: false\n",
      "  episode_len_mean: 87.64601769911505\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.690000000000015\n",
      "  episode_reward_mean: 1.3160176991150467\n",
      "  episode_reward_min: -1.8000000000000007\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 32529\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6297602735014043\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007034053847091862\n",
      "          policy_loss: -0.0226226187358873\n",
      "          total_loss: 0.18313409512520282\n",
      "          vf_explained_var: 0.6777095794677734\n",
      "          vf_loss: 0.21402680639289\n",
      "    num_agent_steps_sampled: 3038784\n",
      "    num_agent_steps_trained: 3038784\n",
      "    num_steps_sampled: 3038784\n",
      "    num_steps_trained: 3038784\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.03727087576375\n",
      "    ram_util_percent: 45.28757637474542\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05004752017542209\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.77204949315332\n",
      "    mean_inference_ms: 8.804175241219879\n",
      "    mean_raw_obs_processing_ms: 2.5215306456419513\n",
      "  time_since_restore: 95114.92189574242\n",
      "  time_this_iter_s: 343.6368134021759\n",
      "  time_total_s: 95114.92189574242\n",
      "  timers:\n",
      "    learn_throughput: 65.197\n",
      "    learn_time_ms: 153320.781\n",
      "    load_throughput: 87870.786\n",
      "    load_time_ms: 113.758\n",
      "    sample_throughput: 56.287\n",
      "    sample_time_ms: 177590.0\n",
      "    update_time_ms: 12.553\n",
      "  timestamp: 1636995859\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3038784\n",
      "  training_iteration: 304\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   304</td><td style=\"text-align: right;\">         95114.9</td><td style=\"text-align: right;\">3038784</td><td style=\"text-align: right;\"> 1.31602</td><td style=\"text-align: right;\">               12.69</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">            87.646</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3048780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-09-52\n",
      "  done: false\n",
      "  episode_len_mean: 87.61739130434782\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.900000000000011\n",
      "  episode_reward_mean: 1.7033913043478295\n",
      "  episode_reward_min: -1.8500000000000012\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 32644\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.62935480072967\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00690073295901203\n",
      "          policy_loss: -0.020592159174510048\n",
      "          total_loss: 0.19374156031880974\n",
      "          vf_explained_var: 0.7308907508850098\n",
      "          vf_loss: 0.22294144393422474\n",
      "    num_agent_steps_sampled: 3048780\n",
      "    num_agent_steps_trained: 3048780\n",
      "    num_steps_sampled: 3048780\n",
      "    num_steps_trained: 3048780\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.17278481012659\n",
      "    ram_util_percent: 45.290506329113924\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006540837796862\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.78526983747782\n",
      "    mean_inference_ms: 8.805332293292546\n",
      "    mean_raw_obs_processing_ms: 2.5189215790170896\n",
      "  time_since_restore: 95447.6332962513\n",
      "  time_this_iter_s: 332.7114005088806\n",
      "  time_total_s: 95447.6332962513\n",
      "  timers:\n",
      "    learn_throughput: 65.166\n",
      "    learn_time_ms: 153392.995\n",
      "    load_throughput: 88046.627\n",
      "    load_time_ms: 113.531\n",
      "    sample_throughput: 56.38\n",
      "    sample_time_ms: 177298.33\n",
      "    update_time_ms: 12.23\n",
      "  timestamp: 1636996192\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3048780\n",
      "  training_iteration: 305\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   305</td><td style=\"text-align: right;\">         95447.6</td><td style=\"text-align: right;\">3048780</td><td style=\"text-align: right;\"> 1.70339</td><td style=\"text-align: right;\">                 8.9</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           87.6174</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3058776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-15-14\n",
      "  done: false\n",
      "  episode_len_mean: 88.70535714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.710000000000012\n",
      "  episode_reward_mean: 1.4899107142857166\n",
      "  episode_reward_min: -1.860000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 32756\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.632505291343754\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007406455243958613\n",
      "          policy_loss: -0.01939932514483539\n",
      "          total_loss: 0.18852940380541433\n",
      "          vf_explained_var: 0.6917382478713989\n",
      "          vf_loss: 0.2152718473954174\n",
      "    num_agent_steps_sampled: 3058776\n",
      "    num_agent_steps_trained: 3058776\n",
      "    num_steps_sampled: 3058776\n",
      "    num_steps_trained: 3058776\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.80544662309367\n",
      "    ram_util_percent: 45.27298474945533\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050048986128417475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.80248979334018\n",
      "    mean_inference_ms: 8.805799198129963\n",
      "    mean_raw_obs_processing_ms: 2.5150511165695386\n",
      "  time_since_restore: 95769.15394425392\n",
      "  time_this_iter_s: 321.5206480026245\n",
      "  time_total_s: 95769.15394425392\n",
      "  timers:\n",
      "    learn_throughput: 65.149\n",
      "    learn_time_ms: 153432.598\n",
      "    load_throughput: 88018.032\n",
      "    load_time_ms: 113.568\n",
      "    sample_throughput: 56.412\n",
      "    sample_time_ms: 177195.566\n",
      "    update_time_ms: 12.02\n",
      "  timestamp: 1636996514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3058776\n",
      "  training_iteration: 306\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   306</td><td style=\"text-align: right;\">         95769.2</td><td style=\"text-align: right;\">3058776</td><td style=\"text-align: right;\"> 1.48991</td><td style=\"text-align: right;\">               10.71</td><td style=\"text-align: right;\">               -1.86</td><td style=\"text-align: right;\">           88.7054</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3068772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-20-56\n",
      "  done: false\n",
      "  episode_len_mean: 87.4695652173913\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.870000000000013\n",
      "  episode_reward_mean: 1.372521739130437\n",
      "  episode_reward_min: -1.7500000000000009\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 32871\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.631755698644198\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0076226899702534125\n",
      "          policy_loss: -0.025529614417280397\n",
      "          total_loss: 0.1721180203784671\n",
      "          vf_explained_var: 0.6931282877922058\n",
      "          vf_loss: 0.2044290723088078\n",
      "    num_agent_steps_sampled: 3068772\n",
      "    num_agent_steps_trained: 3068772\n",
      "    num_steps_sampled: 3068772\n",
      "    num_steps_trained: 3068772\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.0\n",
      "    ram_util_percent: 45.4961145194274\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05005719796133777\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.80845881986576\n",
      "    mean_inference_ms: 8.80684878130358\n",
      "    mean_raw_obs_processing_ms: 2.521269367836307\n",
      "  time_since_restore: 96111.62226343155\n",
      "  time_this_iter_s: 342.46831917762756\n",
      "  time_total_s: 96111.62226343155\n",
      "  timers:\n",
      "    learn_throughput: 65.175\n",
      "    learn_time_ms: 153372.245\n",
      "    load_throughput: 88326.232\n",
      "    load_time_ms: 113.171\n",
      "    sample_throughput: 56.327\n",
      "    sample_time_ms: 177463.668\n",
      "    update_time_ms: 12.168\n",
      "  timestamp: 1636996856\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3068772\n",
      "  training_iteration: 307\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   307</td><td style=\"text-align: right;\">         96111.6</td><td style=\"text-align: right;\">3068772</td><td style=\"text-align: right;\"> 1.37252</td><td style=\"text-align: right;\">                8.87</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           87.4696</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3078768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-26-10\n",
      "  done: false\n",
      "  episode_len_mean: 87.92035398230088\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.220000000000006\n",
      "  episode_reward_mean: 1.580707964601773\n",
      "  episode_reward_min: -2.149999999999999\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 32984\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6228952583084757\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008327088054782146\n",
      "          policy_loss: -0.018481114307720946\n",
      "          total_loss: 0.21842568449031274\n",
      "          vf_explained_var: 0.6822929978370667\n",
      "          vf_loss: 0.24179433587238064\n",
      "    num_agent_steps_sampled: 3078768\n",
      "    num_agent_steps_trained: 3078768\n",
      "    num_steps_sampled: 3078768\n",
      "    num_steps_trained: 3078768\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.95491071428572\n",
      "    ram_util_percent: 45.62589285714286\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05005109471825485\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.82204082398387\n",
      "    mean_inference_ms: 8.807637485163307\n",
      "    mean_raw_obs_processing_ms: 2.516317230857452\n",
      "  time_since_restore: 96426.01367521286\n",
      "  time_this_iter_s: 314.39141178131104\n",
      "  time_total_s: 96426.01367521286\n",
      "  timers:\n",
      "    learn_throughput: 65.166\n",
      "    learn_time_ms: 153393.184\n",
      "    load_throughput: 88424.441\n",
      "    load_time_ms: 113.046\n",
      "    sample_throughput: 56.929\n",
      "    sample_time_ms: 175588.332\n",
      "    update_time_ms: 12.236\n",
      "  timestamp: 1636997170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3078768\n",
      "  training_iteration: 308\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   308</td><td style=\"text-align: right;\">           96426</td><td style=\"text-align: right;\">3078768</td><td style=\"text-align: right;\"> 1.58071</td><td style=\"text-align: right;\">               11.22</td><td style=\"text-align: right;\">               -2.15</td><td style=\"text-align: right;\">           87.9204</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3088764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-31-36\n",
      "  done: false\n",
      "  episode_len_mean: 87.15652173913044\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.640000000000013\n",
      "  episode_reward_mean: 1.5274782608695685\n",
      "  episode_reward_min: -2.089999999999999\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 33099\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.630467592039679\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0067474622097759675\n",
      "          policy_loss: -0.022002451448168002\n",
      "          total_loss: 0.17720547838725595\n",
      "          vf_explained_var: 0.6748864650726318\n",
      "          vf_loss: 0.20821959802196321\n",
      "    num_agent_steps_sampled: 3088764\n",
      "    num_agent_steps_trained: 3088764\n",
      "    num_steps_sampled: 3088764\n",
      "    num_steps_trained: 3088764\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.23548387096774\n",
      "    ram_util_percent: 45.77892473118279\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050057336642120365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.830539763821186\n",
      "    mean_inference_ms: 8.808888056128596\n",
      "    mean_raw_obs_processing_ms: 2.5142025104072796\n",
      "  time_since_restore: 96751.84097099304\n",
      "  time_this_iter_s: 325.8272957801819\n",
      "  time_total_s: 96751.84097099304\n",
      "  timers:\n",
      "    learn_throughput: 65.184\n",
      "    learn_time_ms: 153349.377\n",
      "    load_throughput: 88476.073\n",
      "    load_time_ms: 112.98\n",
      "    sample_throughput: 56.95\n",
      "    sample_time_ms: 175522.617\n",
      "    update_time_ms: 12.336\n",
      "  timestamp: 1636997496\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3088764\n",
      "  training_iteration: 309\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   309</td><td style=\"text-align: right;\">         96751.8</td><td style=\"text-align: right;\">3088764</td><td style=\"text-align: right;\"> 1.52748</td><td style=\"text-align: right;\">                6.64</td><td style=\"text-align: right;\">               -2.09</td><td style=\"text-align: right;\">           87.1565</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3098760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-37-14\n",
      "  done: false\n",
      "  episode_len_mean: 87.87719298245614\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.940000000000014\n",
      "  episode_reward_mean: 1.1973684210526336\n",
      "  episode_reward_min: -1.8300000000000007\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 33213\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.640706805082468\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006716355285847178\n",
      "          policy_loss: -0.021190916856305083\n",
      "          total_loss: 0.1679837241012635\n",
      "          vf_explained_var: 0.661496102809906\n",
      "          vf_loss: 0.19836842520321663\n",
      "    num_agent_steps_sampled: 3098760\n",
      "    num_agent_steps_trained: 3098760\n",
      "    num_steps_sampled: 3098760\n",
      "    num_steps_trained: 3098760\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.72095435684648\n",
      "    ram_util_percent: 45.67427385892116\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05004292756912346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.841202121132184\n",
      "    mean_inference_ms: 8.809185071477168\n",
      "    mean_raw_obs_processing_ms: 2.520427098333444\n",
      "  time_since_restore: 97089.76266622543\n",
      "  time_this_iter_s: 337.92169523239136\n",
      "  time_total_s: 97089.76266622543\n",
      "  timers:\n",
      "    learn_throughput: 65.203\n",
      "    learn_time_ms: 153306.292\n",
      "    load_throughput: 88751.258\n",
      "    load_time_ms: 112.629\n",
      "    sample_throughput: 56.207\n",
      "    sample_time_ms: 177841.245\n",
      "    update_time_ms: 12.078\n",
      "  timestamp: 1636997834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3098760\n",
      "  training_iteration: 310\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   310</td><td style=\"text-align: right;\">         97089.8</td><td style=\"text-align: right;\">3098760</td><td style=\"text-align: right;\"> 1.19737</td><td style=\"text-align: right;\">                8.94</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           87.8772</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3108756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-42-29\n",
      "  done: false\n",
      "  episode_len_mean: 88.99107142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.69000000000001\n",
      "  episode_reward_mean: 1.5929464285714314\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 33325\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.63660413424174\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007640272621378186\n",
      "          policy_loss: -0.02157511968070116\n",
      "          total_loss: 0.17803599323886327\n",
      "          vf_explained_var: 0.7321943044662476\n",
      "          vf_loss: 0.20639597202340762\n",
      "    num_agent_steps_sampled: 3108756\n",
      "    num_agent_steps_trained: 3108756\n",
      "    num_steps_sampled: 3108756\n",
      "    num_steps_trained: 3108756\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.81403118040089\n",
      "    ram_util_percent: 45.88708240534522\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006373566443728\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.848768549839114\n",
      "    mean_inference_ms: 8.81109397499135\n",
      "    mean_raw_obs_processing_ms: 2.513703706918977\n",
      "  time_since_restore: 97404.36646962166\n",
      "  time_this_iter_s: 314.603803396225\n",
      "  time_total_s: 97404.36646962166\n",
      "  timers:\n",
      "    learn_throughput: 65.167\n",
      "    learn_time_ms: 153389.78\n",
      "    load_throughput: 88355.679\n",
      "    load_time_ms: 113.134\n",
      "    sample_throughput: 57.182\n",
      "    sample_time_ms: 174808.849\n",
      "    update_time_ms: 11.91\n",
      "  timestamp: 1636998149\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3108756\n",
      "  training_iteration: 311\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   311</td><td style=\"text-align: right;\">         97404.4</td><td style=\"text-align: right;\">3108756</td><td style=\"text-align: right;\"> 1.59295</td><td style=\"text-align: right;\">                8.69</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           88.9911</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3118752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-47-55\n",
      "  done: false\n",
      "  episode_len_mean: 87.78260869565217\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.120000000000008\n",
      "  episode_reward_mean: 1.2889565217391323\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 33440\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6374089564013685\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006505134573942877\n",
      "          policy_loss: -0.0238355853037638\n",
      "          total_loss: 0.1878474609934303\n",
      "          vf_explained_var: 0.6593149900436401\n",
      "          vf_loss: 0.22138518831636916\n",
      "    num_agent_steps_sampled: 3118752\n",
      "    num_agent_steps_trained: 3118752\n",
      "    num_steps_sampled: 3118752\n",
      "    num_steps_trained: 3118752\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.44699570815452\n",
      "    ram_util_percent: 45.75772532188841\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006217222574721\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.85737043488197\n",
      "    mean_inference_ms: 8.811880637843315\n",
      "    mean_raw_obs_processing_ms: 2.5137846245790394\n",
      "  time_since_restore: 97730.83030176163\n",
      "  time_this_iter_s: 326.4638321399689\n",
      "  time_total_s: 97730.83030176163\n",
      "  timers:\n",
      "    learn_throughput: 65.185\n",
      "    learn_time_ms: 153347.958\n",
      "    load_throughput: 88398.358\n",
      "    load_time_ms: 113.079\n",
      "    sample_throughput: 57.277\n",
      "    sample_time_ms: 174519.33\n",
      "    update_time_ms: 12.537\n",
      "  timestamp: 1636998475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3118752\n",
      "  training_iteration: 312\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   312</td><td style=\"text-align: right;\">         97730.8</td><td style=\"text-align: right;\">3118752</td><td style=\"text-align: right;\"> 1.28896</td><td style=\"text-align: right;\">                7.12</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           87.7826</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3128748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-53-23\n",
      "  done: false\n",
      "  episode_len_mean: 87.65486725663717\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.10000000000001\n",
      "  episode_reward_mean: 1.2330973451327456\n",
      "  episode_reward_min: -2.1999999999999997\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 33553\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.650347957651839\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006409397958732688\n",
      "          policy_loss: -0.01929246527899025\n",
      "          total_loss: 0.18087586713954806\n",
      "          vf_explained_var: 0.7195335626602173\n",
      "          vf_loss: 0.21024522597734363\n",
      "    num_agent_steps_sampled: 3128748\n",
      "    num_agent_steps_trained: 3128748\n",
      "    num_steps_sampled: 3128748\n",
      "    num_steps_trained: 3128748\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.38886509635974\n",
      "    ram_util_percent: 45.26381156316916\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05003494950663496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.86907562737465\n",
      "    mean_inference_ms: 8.811730515442031\n",
      "    mean_raw_obs_processing_ms: 2.5162518054256107\n",
      "  time_since_restore: 98058.40661740303\n",
      "  time_this_iter_s: 327.5763156414032\n",
      "  time_total_s: 98058.40661740303\n",
      "  timers:\n",
      "    learn_throughput: 65.191\n",
      "    learn_time_ms: 153334.578\n",
      "    load_throughput: 88506.068\n",
      "    load_time_ms: 112.941\n",
      "    sample_throughput: 57.043\n",
      "    sample_time_ms: 175236.28\n",
      "    update_time_ms: 12.172\n",
      "  timestamp: 1636998803\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3128748\n",
      "  training_iteration: 313\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   313</td><td style=\"text-align: right;\">         98058.4</td><td style=\"text-align: right;\">3128748</td><td style=\"text-align: right;\">  1.2331</td><td style=\"text-align: right;\">                 7.1</td><td style=\"text-align: right;\">                -2.2</td><td style=\"text-align: right;\">           87.6549</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3138744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_17-58-49\n",
      "  done: false\n",
      "  episode_len_mean: 88.13274336283186\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.660000000000005\n",
      "  episode_reward_mean: 1.4382300884955777\n",
      "  episode_reward_min: -2.1300000000000003\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 33666\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.645185822401291\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007489873169090222\n",
      "          policy_loss: -0.020508208261946072\n",
      "          total_loss: 0.18351972552183538\n",
      "          vf_explained_var: 0.7409586906433105\n",
      "          vf_loss: 0.21128406626267884\n",
      "    num_agent_steps_sampled: 3138744\n",
      "    num_agent_steps_trained: 3138744\n",
      "    num_steps_sampled: 3138744\n",
      "    num_steps_trained: 3138744\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.28967741935483\n",
      "    ram_util_percent: 45.85741935483872\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050062912192184665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.87194687056943\n",
      "    mean_inference_ms: 8.813427729131872\n",
      "    mean_raw_obs_processing_ms: 2.516588300319659\n",
      "  time_since_restore: 98384.0513651371\n",
      "  time_this_iter_s: 325.6447477340698\n",
      "  time_total_s: 98384.0513651371\n",
      "  timers:\n",
      "    learn_throughput: 65.17\n",
      "    learn_time_ms: 153382.642\n",
      "    load_throughput: 87931.399\n",
      "    load_time_ms: 113.68\n",
      "    sample_throughput: 57.651\n",
      "    sample_time_ms: 173387.648\n",
      "    update_time_ms: 11.744\n",
      "  timestamp: 1636999129\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3138744\n",
      "  training_iteration: 314\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   314</td><td style=\"text-align: right;\">         98384.1</td><td style=\"text-align: right;\">3138744</td><td style=\"text-align: right;\"> 1.43823</td><td style=\"text-align: right;\">                6.66</td><td style=\"text-align: right;\">               -2.13</td><td style=\"text-align: right;\">           88.1327</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3148740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-04-16\n",
      "  done: false\n",
      "  episode_len_mean: 87.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.17\n",
      "  episode_reward_mean: 1.33921739130435\n",
      "  episode_reward_min: -1.6500000000000006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 33781\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6484634945535253\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007958798063409926\n",
      "          policy_loss: -0.01933224654923647\n",
      "          total_loss: 0.18683275603052452\n",
      "          vf_explained_var: 0.7321537733078003\n",
      "          vf_loss: 0.21225211006055913\n",
      "    num_agent_steps_sampled: 3148740\n",
      "    num_agent_steps_trained: 3148740\n",
      "    num_steps_sampled: 3148740\n",
      "    num_steps_trained: 3148740\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.44141630901287\n",
      "    ram_util_percent: 46.197424892703864\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050067008837050384\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.88229756848114\n",
      "    mean_inference_ms: 8.814389547611826\n",
      "    mean_raw_obs_processing_ms: 2.514197979858681\n",
      "  time_since_restore: 98710.92505788803\n",
      "  time_this_iter_s: 326.8736927509308\n",
      "  time_total_s: 98710.92505788803\n",
      "  timers:\n",
      "    learn_throughput: 65.213\n",
      "    learn_time_ms: 153282.732\n",
      "    load_throughput: 88248.501\n",
      "    load_time_ms: 113.271\n",
      "    sample_throughput: 57.812\n",
      "    sample_time_ms: 172904.849\n",
      "    update_time_ms: 10.926\n",
      "  timestamp: 1636999456\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3148740\n",
      "  training_iteration: 315\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   315</td><td style=\"text-align: right;\">         98710.9</td><td style=\"text-align: right;\">3148740</td><td style=\"text-align: right;\"> 1.33922</td><td style=\"text-align: right;\">                9.17</td><td style=\"text-align: right;\">               -1.65</td><td style=\"text-align: right;\">              87.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3158736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-09-45\n",
      "  done: false\n",
      "  episode_len_mean: 87.03508771929825\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.010000000000008\n",
      "  episode_reward_mean: 1.065877192982458\n",
      "  episode_reward_min: -1.850000000000001\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 33895\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.646444957378583\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006108540304997093\n",
      "          policy_loss: -0.01963062054103511\n",
      "          total_loss: 0.17895846297232132\n",
      "          vf_explained_var: 0.6999107003211975\n",
      "          vf_loss: 0.2093980132602155\n",
      "    num_agent_steps_sampled: 3158736\n",
      "    num_agent_steps_trained: 3158736\n",
      "    num_steps_sampled: 3158736\n",
      "    num_steps_trained: 3158736\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.40405117270791\n",
      "    ram_util_percent: 45.87931769722813\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006415853038466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.891997580288695\n",
      "    mean_inference_ms: 8.814912193974346\n",
      "    mean_raw_obs_processing_ms: 2.5154814850833684\n",
      "  time_since_restore: 99039.82195329666\n",
      "  time_this_iter_s: 328.89689540863037\n",
      "  time_total_s: 99039.82195329666\n",
      "  timers:\n",
      "    learn_throughput: 65.209\n",
      "    learn_time_ms: 153291.609\n",
      "    load_throughput: 87999.003\n",
      "    load_time_ms: 113.592\n",
      "    sample_throughput: 57.57\n",
      "    sample_time_ms: 173633.142\n",
      "    update_time_ms: 10.902\n",
      "  timestamp: 1636999785\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3158736\n",
      "  training_iteration: 316\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   316</td><td style=\"text-align: right;\">         99039.8</td><td style=\"text-align: right;\">3158736</td><td style=\"text-align: right;\"> 1.06588</td><td style=\"text-align: right;\">                7.01</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           87.0351</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3168732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-15-09\n",
      "  done: false\n",
      "  episode_len_mean: 88.33333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.010000000000007\n",
      "  episode_reward_mean: 1.5626315789473713\n",
      "  episode_reward_min: -1.8000000000000007\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 34009\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6449522303719806\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00820863992944504\n",
      "          policy_loss: -0.017384516942895886\n",
      "          total_loss: 0.20951372945848376\n",
      "          vf_explained_var: 0.6964545249938965\n",
      "          vf_loss: 0.2323099222870018\n",
      "    num_agent_steps_sampled: 3168732\n",
      "    num_agent_steps_trained: 3168732\n",
      "    num_steps_sampled: 3168732\n",
      "    num_steps_trained: 3168732\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.49157667386609\n",
      "    ram_util_percent: 45.82699784017277\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05007208681300764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.897948905789846\n",
      "    mean_inference_ms: 8.815767595952453\n",
      "    mean_raw_obs_processing_ms: 2.51582535429924\n",
      "  time_since_restore: 99364.34051275253\n",
      "  time_this_iter_s: 324.5185594558716\n",
      "  time_total_s: 99364.34051275253\n",
      "  timers:\n",
      "    learn_throughput: 65.18\n",
      "    learn_time_ms: 153360.006\n",
      "    load_throughput: 87813.99\n",
      "    load_time_ms: 113.832\n",
      "    sample_throughput: 58.194\n",
      "    sample_time_ms: 171769.977\n",
      "    update_time_ms: 11.021\n",
      "  timestamp: 1637000109\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3168732\n",
      "  training_iteration: 317\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   317</td><td style=\"text-align: right;\">         99364.3</td><td style=\"text-align: right;\">3168732</td><td style=\"text-align: right;\"> 1.56263</td><td style=\"text-align: right;\">                9.01</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           88.3333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3178728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-20-33\n",
      "  done: false\n",
      "  episode_len_mean: 88.04424778761062\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.080000000000009\n",
      "  episode_reward_mean: 1.101592920353984\n",
      "  episode_reward_min: -1.950000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 34122\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.649913974195464\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0072656063491340584\n",
      "          policy_loss: -0.016378117814405353\n",
      "          total_loss: 0.1817804524436211\n",
      "          vf_explained_var: 0.6414932608604431\n",
      "          vf_loss: 0.2060367551154624\n",
      "    num_agent_steps_sampled: 3178728\n",
      "    num_agent_steps_trained: 3178728\n",
      "    num_steps_sampled: 3178728\n",
      "    num_steps_trained: 3178728\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.56609071274298\n",
      "    ram_util_percent: 45.84017278617709\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05008211082860837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.903464177211106\n",
      "    mean_inference_ms: 8.8167419598604\n",
      "    mean_raw_obs_processing_ms: 2.5150841526295467\n",
      "  time_since_restore: 99688.57310724258\n",
      "  time_this_iter_s: 324.23259449005127\n",
      "  time_total_s: 99688.57310724258\n",
      "  timers:\n",
      "    learn_throughput: 65.179\n",
      "    learn_time_ms: 153362.96\n",
      "    load_throughput: 87493.589\n",
      "    load_time_ms: 114.248\n",
      "    sample_throughput: 57.864\n",
      "    sample_time_ms: 172750.921\n",
      "    update_time_ms: 10.693\n",
      "  timestamp: 1637000433\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3178728\n",
      "  training_iteration: 318\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   318</td><td style=\"text-align: right;\">         99688.6</td><td style=\"text-align: right;\">3178728</td><td style=\"text-align: right;\"> 1.10159</td><td style=\"text-align: right;\">                7.08</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           88.0442</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3188724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-25-59\n",
      "  done: false\n",
      "  episode_len_mean: 88.19469026548673\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.710000000000015\n",
      "  episode_reward_mean: 1.480442477876109\n",
      "  episode_reward_min: -1.8500000000000008\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 34235\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.648565818509485\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006753509424836154\n",
      "          policy_loss: -0.016464191063060466\n",
      "          total_loss: 0.19118319213127669\n",
      "          vf_explained_var: 0.7128424644470215\n",
      "          vf_loss: 0.21682453549299865\n",
      "    num_agent_steps_sampled: 3188724\n",
      "    num_agent_steps_trained: 3188724\n",
      "    num_steps_sampled: 3188724\n",
      "    num_steps_trained: 3188724\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.20409482758622\n",
      "    ram_util_percent: 45.92952586206897\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05007416838487082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.91305760106111\n",
      "    mean_inference_ms: 8.817111948763548\n",
      "    mean_raw_obs_processing_ms: 2.515458293455131\n",
      "  time_since_restore: 100013.99579286575\n",
      "  time_this_iter_s: 325.42268562316895\n",
      "  time_total_s: 100013.99579286575\n",
      "  timers:\n",
      "    learn_throughput: 65.15\n",
      "    learn_time_ms: 153430.375\n",
      "    load_throughput: 87230.909\n",
      "    load_time_ms: 114.592\n",
      "    sample_throughput: 57.9\n",
      "    sample_time_ms: 172643.559\n",
      "    update_time_ms: 10.254\n",
      "  timestamp: 1637000759\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3188724\n",
      "  training_iteration: 319\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   319</td><td style=\"text-align: right;\">          100014</td><td style=\"text-align: right;\">3188724</td><td style=\"text-align: right;\"> 1.48044</td><td style=\"text-align: right;\">                6.71</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           88.1947</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3198720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-31-45\n",
      "  done: false\n",
      "  episode_len_mean: 89.63963963963964\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.580000000000009\n",
      "  episode_reward_mean: 1.6767567567567596\n",
      "  episode_reward_min: -1.6800000000000008\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 34346\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.647530179349785\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006678835233178604\n",
      "          policy_loss: -0.018535937525284214\n",
      "          total_loss: 0.1801770318992054\n",
      "          vf_explained_var: 0.7419973015785217\n",
      "          vf_loss: 0.20807114669607363\n",
      "    num_agent_steps_sampled: 3198720\n",
      "    num_agent_steps_trained: 3198720\n",
      "    num_steps_sampled: 3198720\n",
      "    num_steps_trained: 3198720\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.95101214574899\n",
      "    ram_util_percent: 45.96396761133604\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05007934281830108\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.916043999577894\n",
      "    mean_inference_ms: 8.817913723423626\n",
      "    mean_raw_obs_processing_ms: 2.5244039973176737\n",
      "  time_since_restore: 100360.1059384346\n",
      "  time_this_iter_s: 346.11014556884766\n",
      "  time_total_s: 100360.1059384346\n",
      "  timers:\n",
      "    learn_throughput: 65.153\n",
      "    learn_time_ms: 153424.363\n",
      "    load_throughput: 86515.222\n",
      "    load_time_ms: 115.54\n",
      "    sample_throughput: 57.625\n",
      "    sample_time_ms: 173467.751\n",
      "    update_time_ms: 10.341\n",
      "  timestamp: 1637001105\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3198720\n",
      "  training_iteration: 320\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   320</td><td style=\"text-align: right;\">          100360</td><td style=\"text-align: right;\">3198720</td><td style=\"text-align: right;\"> 1.67676</td><td style=\"text-align: right;\">                8.58</td><td style=\"text-align: right;\">               -1.68</td><td style=\"text-align: right;\">           89.6396</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3208716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-37-07\n",
      "  done: false\n",
      "  episode_len_mean: 90.29729729729729\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.960000000000014\n",
      "  episode_reward_mean: 1.316306306306309\n",
      "  episode_reward_min: -1.970000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 34457\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6440976814327075\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006312677629358491\n",
      "          policy_loss: -0.019996570912786782\n",
      "          total_loss: 0.151094340490432\n",
      "          vf_explained_var: 0.7425070405006409\n",
      "          vf_loss: 0.18135318557182567\n",
      "    num_agent_steps_sampled: 3208716\n",
      "    num_agent_steps_trained: 3208716\n",
      "    num_steps_sampled: 3208716\n",
      "    num_steps_trained: 3208716\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.68695652173913\n",
      "    ram_util_percent: 45.94652173913043\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05008189872827539\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.92198622107256\n",
      "    mean_inference_ms: 8.81895129558915\n",
      "    mean_raw_obs_processing_ms: 2.524394236430679\n",
      "  time_since_restore: 100682.10386705399\n",
      "  time_this_iter_s: 321.99792861938477\n",
      "  time_total_s: 100682.10386705399\n",
      "  timers:\n",
      "    learn_throughput: 65.174\n",
      "    learn_time_ms: 153373.814\n",
      "    load_throughput: 86261.25\n",
      "    load_time_ms: 115.881\n",
      "    sample_throughput: 57.363\n",
      "    sample_time_ms: 174258.086\n",
      "    update_time_ms: 10.124\n",
      "  timestamp: 1637001427\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3208716\n",
      "  training_iteration: 321\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   321</td><td style=\"text-align: right;\">          100682</td><td style=\"text-align: right;\">3208716</td><td style=\"text-align: right;\"> 1.31631</td><td style=\"text-align: right;\">                6.96</td><td style=\"text-align: right;\">               -1.97</td><td style=\"text-align: right;\">           90.2973</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3218712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-42-32\n",
      "  done: false\n",
      "  episode_len_mean: 88.98214285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.580000000000011\n",
      "  episode_reward_mean: 1.2319642857142878\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 34569\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6453843257366083\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.005976540643417426\n",
      "          policy_loss: -0.017910961110670216\n",
      "          total_loss: 0.12259675189972115\n",
      "          vf_explained_var: 0.788560152053833\n",
      "          vf_loss: 0.15164433647241665\n",
      "    num_agent_steps_sampled: 3218712\n",
      "    num_agent_steps_trained: 3218712\n",
      "    num_steps_sampled: 3218712\n",
      "    num_steps_trained: 3218712\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.49288793103449\n",
      "    ram_util_percent: 45.529741379310344\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050070111829159596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.92959561898368\n",
      "    mean_inference_ms: 8.81927220626616\n",
      "    mean_raw_obs_processing_ms: 2.524815472601557\n",
      "  time_since_restore: 101007.52555537224\n",
      "  time_this_iter_s: 325.42168831825256\n",
      "  time_total_s: 101007.52555537224\n",
      "  timers:\n",
      "    learn_throughput: 65.142\n",
      "    learn_time_ms: 153449.65\n",
      "    load_throughput: 86436.457\n",
      "    load_time_ms: 115.646\n",
      "    sample_throughput: 57.422\n",
      "    sample_time_ms: 174079.213\n",
      "    update_time_ms: 9.378\n",
      "  timestamp: 1637001752\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3218712\n",
      "  training_iteration: 322\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   322</td><td style=\"text-align: right;\">          101008</td><td style=\"text-align: right;\">3218712</td><td style=\"text-align: right;\"> 1.23196</td><td style=\"text-align: right;\">                6.58</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           88.9821</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3228708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-47-56\n",
      "  done: false\n",
      "  episode_len_mean: 89.07964601769912\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.350000000000009\n",
      "  episode_reward_mean: 1.2239823008849577\n",
      "  episode_reward_min: -2.2799999999999976\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 34682\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.645501290427314\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006273125309182201\n",
      "          policy_loss: -0.02043188033490163\n",
      "          total_loss: 0.1596437335300904\n",
      "          vf_explained_var: 0.7418593764305115\n",
      "          vf_loss: 0.1904532930125188\n",
      "    num_agent_steps_sampled: 3228708\n",
      "    num_agent_steps_trained: 3228708\n",
      "    num_steps_sampled: 3228708\n",
      "    num_steps_trained: 3228708\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.37922077922077\n",
      "    ram_util_percent: 45.5612554112554\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006790741227247\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.935123169637905\n",
      "    mean_inference_ms: 8.819912032599019\n",
      "    mean_raw_obs_processing_ms: 2.5256550957555306\n",
      "  time_since_restore: 101331.13067245483\n",
      "  time_this_iter_s: 323.6051170825958\n",
      "  time_total_s: 101331.13067245483\n",
      "  timers:\n",
      "    learn_throughput: 65.155\n",
      "    learn_time_ms: 153418.318\n",
      "    load_throughput: 86489.54\n",
      "    load_time_ms: 115.575\n",
      "    sample_throughput: 57.543\n",
      "    sample_time_ms: 173713.376\n",
      "    update_time_ms: 9.429\n",
      "  timestamp: 1637002076\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3228708\n",
      "  training_iteration: 323\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   323</td><td style=\"text-align: right;\">          101331</td><td style=\"text-align: right;\">3228708</td><td style=\"text-align: right;\"> 1.22398</td><td style=\"text-align: right;\">                9.35</td><td style=\"text-align: right;\">               -2.28</td><td style=\"text-align: right;\">           89.0796</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3238704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-53-19\n",
      "  done: false\n",
      "  episode_len_mean: 90.32432432432432\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.610000000000005\n",
      "  episode_reward_mean: 1.3630630630630651\n",
      "  episode_reward_min: -1.9900000000000009\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 34793\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6487839337088106\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006351520931809331\n",
      "          policy_loss: -0.016128978823335506\n",
      "          total_loss: 0.17073756572511842\n",
      "          vf_explained_var: 0.7274264097213745\n",
      "          vf_loss: 0.19707613093619292\n",
      "    num_agent_steps_sampled: 3238704\n",
      "    num_agent_steps_trained: 3238704\n",
      "    num_steps_sampled: 3238704\n",
      "    num_steps_trained: 3238704\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.29499999999999\n",
      "    ram_util_percent: 45.33608695652173\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05007473865571889\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.939898908438\n",
      "    mean_inference_ms: 8.821067112025506\n",
      "    mean_raw_obs_processing_ms: 2.5218762708717777\n",
      "  time_since_restore: 101653.66435050964\n",
      "  time_this_iter_s: 322.53367805480957\n",
      "  time_total_s: 101653.66435050964\n",
      "  timers:\n",
      "    learn_throughput: 65.155\n",
      "    learn_time_ms: 153418.744\n",
      "    load_throughput: 86989.145\n",
      "    load_time_ms: 114.911\n",
      "    sample_throughput: 57.646\n",
      "    sample_time_ms: 173404.64\n",
      "    update_time_ms: 8.133\n",
      "  timestamp: 1637002399\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3238704\n",
      "  training_iteration: 324\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   324</td><td style=\"text-align: right;\">          101654</td><td style=\"text-align: right;\">3238704</td><td style=\"text-align: right;\"> 1.36306</td><td style=\"text-align: right;\">                6.61</td><td style=\"text-align: right;\">               -1.99</td><td style=\"text-align: right;\">           90.3243</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3248700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_18-58-42\n",
      "  done: false\n",
      "  episode_len_mean: 89.94594594594595\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.740000000000014\n",
      "  episode_reward_mean: 1.629549549549553\n",
      "  episode_reward_min: -2.569999999999998\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 34904\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6429239236391506\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00669555658217569\n",
      "          policy_loss: -0.018022162437789205\n",
      "          total_loss: 0.19700789575536665\n",
      "          vf_explained_var: 0.7240305542945862\n",
      "          vf_loss: 0.22429931873702405\n",
      "    num_agent_steps_sampled: 3248700\n",
      "    num_agent_steps_trained: 3248700\n",
      "    num_steps_sampled: 3248700\n",
      "    num_steps_trained: 3248700\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.35206073752713\n",
      "    ram_util_percent: 45.27266811279826\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050060464964385515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.94668897369385\n",
      "    mean_inference_ms: 8.821326440524896\n",
      "    mean_raw_obs_processing_ms: 2.5258274450371903\n",
      "  time_since_restore: 101976.64558768272\n",
      "  time_this_iter_s: 322.98123717308044\n",
      "  time_total_s: 101976.64558768272\n",
      "  timers:\n",
      "    learn_throughput: 65.129\n",
      "    learn_time_ms: 153480.076\n",
      "    load_throughput: 87289.424\n",
      "    load_time_ms: 114.516\n",
      "    sample_throughput: 57.795\n",
      "    sample_time_ms: 172954.695\n",
      "    update_time_ms: 8.114\n",
      "  timestamp: 1637002722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3248700\n",
      "  training_iteration: 325\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   325</td><td style=\"text-align: right;\">          101977</td><td style=\"text-align: right;\">3248700</td><td style=\"text-align: right;\"> 1.62955</td><td style=\"text-align: right;\">                8.74</td><td style=\"text-align: right;\">               -2.57</td><td style=\"text-align: right;\">           89.9459</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3258696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-04-07\n",
      "  done: false\n",
      "  episode_len_mean: 89.8018018018018\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.8400000000000105\n",
      "  episode_reward_mean: 1.3940540540540565\n",
      "  episode_reward_min: -1.780000000000001\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 35015\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6394898204721957\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006782380673826925\n",
      "          policy_loss: -0.017992510043211982\n",
      "          total_loss: 0.18546617986578653\n",
      "          vf_explained_var: 0.7377334237098694\n",
      "          vf_loss: 0.21247108806975376\n",
      "    num_agent_steps_sampled: 3258696\n",
      "    num_agent_steps_trained: 3258696\n",
      "    num_steps_sampled: 3258696\n",
      "    num_steps_trained: 3258696\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.1647948164147\n",
      "    ram_util_percent: 45.231317494600425\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050091075129821014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.94907694580956\n",
      "    mean_inference_ms: 8.823232365692824\n",
      "    mean_raw_obs_processing_ms: 2.5242209196567953\n",
      "  time_since_restore: 102301.60735702515\n",
      "  time_this_iter_s: 324.9617693424225\n",
      "  time_total_s: 102301.60735702515\n",
      "  timers:\n",
      "    learn_throughput: 65.158\n",
      "    learn_time_ms: 153410.807\n",
      "    load_throughput: 87571.147\n",
      "    load_time_ms: 114.147\n",
      "    sample_throughput: 57.904\n",
      "    sample_time_ms: 172631.054\n",
      "    update_time_ms: 8.179\n",
      "  timestamp: 1637003047\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3258696\n",
      "  training_iteration: 326\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   326</td><td style=\"text-align: right;\">          102302</td><td style=\"text-align: right;\">3258696</td><td style=\"text-align: right;\"> 1.39405</td><td style=\"text-align: right;\">                6.84</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           89.8018</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3268692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-09-32\n",
      "  done: false\n",
      "  episode_len_mean: 89.63392857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.640000000000013\n",
      "  episode_reward_mean: 1.6320535714285747\n",
      "  episode_reward_min: -1.8000000000000007\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 35127\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.639966289202372\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006118114430202502\n",
      "          policy_loss: -0.018349105158709307\n",
      "          total_loss: 0.1418723732742489\n",
      "          vf_explained_var: 0.7860665321350098\n",
      "          vf_loss: 0.17094108301541236\n",
      "    num_agent_steps_sampled: 3268692\n",
      "    num_agent_steps_trained: 3268692\n",
      "    num_steps_sampled: 3268692\n",
      "    num_steps_trained: 3268692\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.60537634408603\n",
      "    ram_util_percent: 45.33376344086022\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006775560370408\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.96109268323987\n",
      "    mean_inference_ms: 8.823279272612417\n",
      "    mean_raw_obs_processing_ms: 2.5244884645778805\n",
      "  time_since_restore: 102627.20966959\n",
      "  time_this_iter_s: 325.60231256484985\n",
      "  time_total_s: 102627.20966959\n",
      "  timers:\n",
      "    learn_throughput: 65.153\n",
      "    learn_time_ms: 153422.407\n",
      "    load_throughput: 88024.148\n",
      "    load_time_ms: 113.56\n",
      "    sample_throughput: 57.871\n",
      "    sample_time_ms: 172728.236\n",
      "    update_time_ms: 8.388\n",
      "  timestamp: 1637003372\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3268692\n",
      "  training_iteration: 327\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   327</td><td style=\"text-align: right;\">          102627</td><td style=\"text-align: right;\">3268692</td><td style=\"text-align: right;\"> 1.63205</td><td style=\"text-align: right;\">                8.64</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           89.6339</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3278688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-14-57\n",
      "  done: false\n",
      "  episode_len_mean: 89.08035714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.960000000000015\n",
      "  episode_reward_mean: 1.5278571428571455\n",
      "  episode_reward_min: -1.9100000000000008\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 35239\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6447768616880105\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006353590668192172\n",
      "          policy_loss: -0.0169320164140887\n",
      "          total_loss: 0.16891240685318526\n",
      "          vf_explained_var: 0.7207942008972168\n",
      "          vf_loss: 0.1960086337951386\n",
      "    num_agent_steps_sampled: 3278688\n",
      "    num_agent_steps_trained: 3278688\n",
      "    num_steps_sampled: 3278688\n",
      "    num_steps_trained: 3278688\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.47300215982722\n",
      "    ram_util_percent: 45.55269978401728\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05007735794655153\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.96456800087533\n",
      "    mean_inference_ms: 8.8248289703369\n",
      "    mean_raw_obs_processing_ms: 2.5226646531243815\n",
      "  time_since_restore: 102951.72493362427\n",
      "  time_this_iter_s: 324.51526403427124\n",
      "  time_total_s: 102951.72493362427\n",
      "  timers:\n",
      "    learn_throughput: 65.173\n",
      "    learn_time_ms: 153375.597\n",
      "    load_throughput: 87892.965\n",
      "    load_time_ms: 113.729\n",
      "    sample_throughput: 57.846\n",
      "    sample_time_ms: 172802.808\n",
      "    update_time_ms: 8.994\n",
      "  timestamp: 1637003697\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3278688\n",
      "  training_iteration: 328\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   328</td><td style=\"text-align: right;\">          102952</td><td style=\"text-align: right;\">3278688</td><td style=\"text-align: right;\"> 1.52786</td><td style=\"text-align: right;\">                8.96</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           89.0804</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3288684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-20-07\n",
      "  done: false\n",
      "  episode_len_mean: 89.79464285714286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.110000000000003\n",
      "  episode_reward_mean: 1.0688392857142879\n",
      "  episode_reward_min: -2.039999999999999\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 35351\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6475559297789877\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006181603830322382\n",
      "          policy_loss: -0.016850113423748148\n",
      "          total_loss: 0.1593586779334861\n",
      "          vf_explained_var: 0.685256838798523\n",
      "          vf_loss: 0.1868415772043264\n",
      "    num_agent_steps_sampled: 3288684\n",
      "    num_agent_steps_trained: 3288684\n",
      "    num_steps_sampled: 3288684\n",
      "    num_steps_trained: 3288684\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.84401805869074\n",
      "    ram_util_percent: 45.641083521444706\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05008488606806921\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.97176464203687\n",
      "    mean_inference_ms: 8.826071422749674\n",
      "    mean_raw_obs_processing_ms: 2.5174609242803534\n",
      "  time_since_restore: 103262.10079836845\n",
      "  time_this_iter_s: 310.3758647441864\n",
      "  time_total_s: 103262.10079836845\n",
      "  timers:\n",
      "    learn_throughput: 65.188\n",
      "    learn_time_ms: 153341.573\n",
      "    load_throughput: 87739.013\n",
      "    load_time_ms: 113.929\n",
      "    sample_throughput: 58.343\n",
      "    sample_time_ms: 171331.389\n",
      "    update_time_ms: 9.675\n",
      "  timestamp: 1637004007\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3288684\n",
      "  training_iteration: 329\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   329</td><td style=\"text-align: right;\">          103262</td><td style=\"text-align: right;\">3288684</td><td style=\"text-align: right;\"> 1.06884</td><td style=\"text-align: right;\">                7.11</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           89.7946</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3298680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-25-47\n",
      "  done: false\n",
      "  episode_len_mean: 88.42477876106194\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.70000000000001\n",
      "  episode_reward_mean: 1.2122123893805334\n",
      "  episode_reward_min: -1.850000000000001\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 35464\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.650546080740089\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006077226623361979\n",
      "          policy_loss: -0.01735160544068895\n",
      "          total_loss: 0.14837007937817556\n",
      "          vf_explained_var: 0.7161027193069458\n",
      "          vf_loss: 0.17665187824262768\n",
      "    num_agent_steps_sampled: 3298680\n",
      "    num_agent_steps_trained: 3298680\n",
      "    num_steps_sampled: 3298680\n",
      "    num_steps_trained: 3298680\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.88577319587628\n",
      "    ram_util_percent: 45.8220618556701\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050069034411648596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.975758607230254\n",
      "    mean_inference_ms: 8.826162028511412\n",
      "    mean_raw_obs_processing_ms: 2.525449706417222\n",
      "  time_since_restore: 103602.27140903473\n",
      "  time_this_iter_s: 340.170610666275\n",
      "  time_total_s: 103602.27140903473\n",
      "  timers:\n",
      "    learn_throughput: 65.175\n",
      "    learn_time_ms: 153371.61\n",
      "    load_throughput: 88130.003\n",
      "    load_time_ms: 113.423\n",
      "    sample_throughput: 58.556\n",
      "    sample_time_ms: 170707.583\n",
      "    update_time_ms: 10.073\n",
      "  timestamp: 1637004347\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3298680\n",
      "  training_iteration: 330\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   330</td><td style=\"text-align: right;\">          103602</td><td style=\"text-align: right;\">3298680</td><td style=\"text-align: right;\"> 1.21221</td><td style=\"text-align: right;\">                 6.7</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">           88.4248</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3308676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-31-10\n",
      "  done: false\n",
      "  episode_len_mean: 89.375\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.860000000000008\n",
      "  episode_reward_mean: 1.7215178571428602\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 35576\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6478334107969563\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006308201846465656\n",
      "          policy_loss: -0.017073790296816674\n",
      "          total_loss: 0.17112467443196375\n",
      "          vf_explained_var: 0.6973744630813599\n",
      "          vf_loss: 0.19850956693522503\n",
      "    num_agent_steps_sampled: 3308676\n",
      "    num_agent_steps_trained: 3308676\n",
      "    num_steps_sampled: 3308676\n",
      "    num_steps_trained: 3308676\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.21434782608695\n",
      "    ram_util_percent: 46.07260869565218\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050079256006131216\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.979319118291656\n",
      "    mean_inference_ms: 8.827424283346245\n",
      "    mean_raw_obs_processing_ms: 2.5229312356689917\n",
      "  time_since_restore: 103924.80220651627\n",
      "  time_this_iter_s: 322.53079748153687\n",
      "  time_total_s: 103924.80220651627\n",
      "  timers:\n",
      "    learn_throughput: 65.177\n",
      "    learn_time_ms: 153367.476\n",
      "    load_throughput: 88632.512\n",
      "    load_time_ms: 112.78\n",
      "    sample_throughput: 58.536\n",
      "    sample_time_ms: 170765.593\n",
      "    update_time_ms: 10.049\n",
      "  timestamp: 1637004670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3308676\n",
      "  training_iteration: 331\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   331</td><td style=\"text-align: right;\">          103925</td><td style=\"text-align: right;\">3308676</td><td style=\"text-align: right;\"> 1.72152</td><td style=\"text-align: right;\">                8.86</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">            89.375</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3318672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-36-18\n",
      "  done: false\n",
      "  episode_len_mean: 90.43636363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.490000000000009\n",
      "  episode_reward_mean: 1.2916363636363664\n",
      "  episode_reward_min: -1.9400000000000008\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 35686\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6494303674779385\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0065695369720589316\n",
      "          policy_loss: -0.016799657251168457\n",
      "          total_loss: 0.19662359758025497\n",
      "          vf_explained_var: 0.7127186059951782\n",
      "          vf_loss: 0.22308055345191916\n",
      "    num_agent_steps_sampled: 3318672\n",
      "    num_agent_steps_trained: 3318672\n",
      "    num_steps_sampled: 3318672\n",
      "    num_steps_trained: 3318672\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.70227272727273\n",
      "    ram_util_percent: 46.02704545454545\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050084371271837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.983662841608236\n",
      "    mean_inference_ms: 8.82847973336691\n",
      "    mean_raw_obs_processing_ms: 2.5183556848351363\n",
      "  time_since_restore: 104232.7377398014\n",
      "  time_this_iter_s: 307.935533285141\n",
      "  time_total_s: 104232.7377398014\n",
      "  timers:\n",
      "    learn_throughput: 65.174\n",
      "    learn_time_ms: 153373.915\n",
      "    load_throughput: 88526.233\n",
      "    load_time_ms: 112.916\n",
      "    sample_throughput: 59.144\n",
      "    sample_time_ms: 169010.094\n",
      "    update_time_ms: 10.399\n",
      "  timestamp: 1637004978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3318672\n",
      "  training_iteration: 332\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   332</td><td style=\"text-align: right;\">          104233</td><td style=\"text-align: right;\">3318672</td><td style=\"text-align: right;\"> 1.29164</td><td style=\"text-align: right;\">                6.49</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           90.4364</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3328668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-41-42\n",
      "  done: false\n",
      "  episode_len_mean: 89.17857142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.710000000000015\n",
      "  episode_reward_mean: 1.0715178571428594\n",
      "  episode_reward_min: -2.080000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 35798\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6542856387602978\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006708941318245684\n",
      "          policy_loss: -0.017173312060359835\n",
      "          total_loss: 0.1807936511018401\n",
      "          vf_explained_var: 0.6658445596694946\n",
      "          vf_loss: 0.2073155367233528\n",
      "    num_agent_steps_sampled: 3328668\n",
      "    num_agent_steps_trained: 3328668\n",
      "    num_steps_sampled: 3328668\n",
      "    num_steps_trained: 3328668\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.24848484848485\n",
      "    ram_util_percent: 45.93874458874459\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05007800219559515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.98952783867462\n",
      "    mean_inference_ms: 8.828837273412393\n",
      "    mean_raw_obs_processing_ms: 2.521946994949733\n",
      "  time_since_restore: 104556.53657579422\n",
      "  time_this_iter_s: 323.7988359928131\n",
      "  time_total_s: 104556.53657579422\n",
      "  timers:\n",
      "    learn_throughput: 65.166\n",
      "    learn_time_ms: 153392.513\n",
      "    load_throughput: 88571.042\n",
      "    load_time_ms: 112.859\n",
      "    sample_throughput: 59.144\n",
      "    sample_time_ms: 169010.586\n",
      "    update_time_ms: 10.363\n",
      "  timestamp: 1637005302\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3328668\n",
      "  training_iteration: 333\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   333</td><td style=\"text-align: right;\">          104557</td><td style=\"text-align: right;\">3328668</td><td style=\"text-align: right;\"> 1.07152</td><td style=\"text-align: right;\">                6.71</td><td style=\"text-align: right;\">               -2.08</td><td style=\"text-align: right;\">           89.1786</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3338664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-47-06\n",
      "  done: false\n",
      "  episode_len_mean: 89.49107142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.840000000000014\n",
      "  episode_reward_mean: 1.5141071428571455\n",
      "  episode_reward_min: -2.2499999999999996\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 35910\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.646608543599773\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.00598990960428905\n",
      "          policy_loss: -0.021287733532934106\n",
      "          total_loss: 0.15322112657933726\n",
      "          vf_explained_var: 0.7181001901626587\n",
      "          vf_loss: 0.18562346249480502\n",
      "    num_agent_steps_sampled: 3338664\n",
      "    num_agent_steps_trained: 3338664\n",
      "    num_steps_sampled: 3338664\n",
      "    num_steps_trained: 3338664\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.31991341991342\n",
      "    ram_util_percent: 45.95822510822511\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006879347863675\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.99736155876788\n",
      "    mean_inference_ms: 8.829662641725365\n",
      "    mean_raw_obs_processing_ms: 2.5230311034646298\n",
      "  time_since_restore: 104880.449832201\n",
      "  time_this_iter_s: 323.91325640678406\n",
      "  time_total_s: 104880.449832201\n",
      "  timers:\n",
      "    learn_throughput: 65.189\n",
      "    learn_time_ms: 153338.173\n",
      "    load_throughput: 88455.502\n",
      "    load_time_ms: 113.006\n",
      "    sample_throughput: 59.077\n",
      "    sample_time_ms: 169202.379\n",
      "    update_time_ms: 10.559\n",
      "  timestamp: 1637005626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3338664\n",
      "  training_iteration: 334\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   334</td><td style=\"text-align: right;\">          104880</td><td style=\"text-align: right;\">3338664</td><td style=\"text-align: right;\"> 1.51411</td><td style=\"text-align: right;\">               10.84</td><td style=\"text-align: right;\">               -2.25</td><td style=\"text-align: right;\">           89.4911</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3348660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-52-19\n",
      "  done: false\n",
      "  episode_len_mean: 89.14414414414415\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.050000000000011\n",
      "  episode_reward_mean: 1.9452252252252282\n",
      "  episode_reward_min: -2.1900000000000004\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 36021\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6489329445056424\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007465982682097902\n",
      "          policy_loss: -0.01694079822876578\n",
      "          total_loss: 0.2047109103685993\n",
      "          vf_explained_var: 0.7151663303375244\n",
      "          vf_loss: 0.22900654138185275\n",
      "    num_agent_steps_sampled: 3348660\n",
      "    num_agent_steps_trained: 3348660\n",
      "    num_steps_sampled: 3348660\n",
      "    num_steps_trained: 3348660\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.82107623318385\n",
      "    ram_util_percent: 45.766367713004485\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05007078848233512\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.00372454569813\n",
      "    mean_inference_ms: 8.83085682524262\n",
      "    mean_raw_obs_processing_ms: 2.5192921942089317\n",
      "  time_since_restore: 105193.21816968918\n",
      "  time_this_iter_s: 312.76833748817444\n",
      "  time_total_s: 105193.21816968918\n",
      "  timers:\n",
      "    learn_throughput: 65.186\n",
      "    learn_time_ms: 153346.202\n",
      "    load_throughput: 88414.129\n",
      "    load_time_ms: 113.059\n",
      "    sample_throughput: 59.439\n",
      "    sample_time_ms: 168172.766\n",
      "    update_time_ms: 10.654\n",
      "  timestamp: 1637005939\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3348660\n",
      "  training_iteration: 335\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   335</td><td style=\"text-align: right;\">          105193</td><td style=\"text-align: right;\">3348660</td><td style=\"text-align: right;\"> 1.94523</td><td style=\"text-align: right;\">               13.05</td><td style=\"text-align: right;\">               -2.19</td><td style=\"text-align: right;\">           89.1441</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3358656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_19-57-45\n",
      "  done: false\n",
      "  episode_len_mean: 89.76785714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.990000000000013\n",
      "  episode_reward_mean: 1.5841964285714312\n",
      "  episode_reward_min: -2.04\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 36133\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.634156326045338\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006356464240534895\n",
      "          policy_loss: -0.014120614958497195\n",
      "          total_loss: 0.1609269052783712\n",
      "          vf_explained_var: 0.7245543003082275\n",
      "          vf_loss: 0.18509816160091222\n",
      "    num_agent_steps_sampled: 3358656\n",
      "    num_agent_steps_trained: 3358656\n",
      "    num_steps_sampled: 3358656\n",
      "    num_steps_trained: 3358656\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.43562231759657\n",
      "    ram_util_percent: 45.761158798283255\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0500590722285175\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.011655319776544\n",
      "    mean_inference_ms: 8.83136587839191\n",
      "    mean_raw_obs_processing_ms: 2.5197421211027082\n",
      "  time_since_restore: 105519.50775527954\n",
      "  time_this_iter_s: 326.28958559036255\n",
      "  time_total_s: 105519.50775527954\n",
      "  timers:\n",
      "    learn_throughput: 65.18\n",
      "    learn_time_ms: 153360.12\n",
      "    load_throughput: 88503.92\n",
      "    load_time_ms: 112.944\n",
      "    sample_throughput: 59.397\n",
      "    sample_time_ms: 168291.241\n",
      "    update_time_ms: 10.473\n",
      "  timestamp: 1637006265\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3358656\n",
      "  training_iteration: 336\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   336</td><td style=\"text-align: right;\">          105520</td><td style=\"text-align: right;\">3358656</td><td style=\"text-align: right;\">  1.5842</td><td style=\"text-align: right;\">                8.99</td><td style=\"text-align: right;\">               -2.04</td><td style=\"text-align: right;\">           89.7679</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3368652\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_20-03-24\n",
      "  done: false\n",
      "  episode_len_mean: 89.36607142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.720000000000015\n",
      "  episode_reward_mean: 1.5663392857142893\n",
      "  episode_reward_min: -2.199999999999998\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 36245\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6324684735037325\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006001925502865731\n",
      "          policy_loss: -0.015315829193553863\n",
      "          total_loss: 0.18716712766844365\n",
      "          vf_explained_var: 0.7009267807006836\n",
      "          vf_loss: 0.21342536316882085\n",
      "    num_agent_steps_sampled: 3368652\n",
      "    num_agent_steps_trained: 3368652\n",
      "    num_steps_sampled: 3368652\n",
      "    num_steps_trained: 3368652\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.76376811594203\n",
      "    ram_util_percent: 45.555900621118006\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050074095802114145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.016192044181004\n",
      "    mean_inference_ms: 8.83256061659459\n",
      "    mean_raw_obs_processing_ms: 2.5233002374125375\n",
      "  time_since_restore: 105858.60135316849\n",
      "  time_this_iter_s: 339.09359788894653\n",
      "  time_total_s: 105858.60135316849\n",
      "  timers:\n",
      "    learn_throughput: 65.186\n",
      "    learn_time_ms: 153344.954\n",
      "    load_throughput: 88477.697\n",
      "    load_time_ms: 112.978\n",
      "    sample_throughput: 58.919\n",
      "    sample_time_ms: 169655.286\n",
      "    update_time_ms: 9.843\n",
      "  timestamp: 1637006604\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3368652\n",
      "  training_iteration: 337\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   337</td><td style=\"text-align: right;\">          105859</td><td style=\"text-align: right;\">3368652</td><td style=\"text-align: right;\"> 1.56634</td><td style=\"text-align: right;\">               10.72</td><td style=\"text-align: right;\">                -2.2</td><td style=\"text-align: right;\">           89.3661</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3378648\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_20-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 90.39090909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.59000000000001\n",
      "  episode_reward_mean: 1.5659090909090938\n",
      "  episode_reward_min: -2.2199999999999984\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 36355\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6242952497596415\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.005861431537005077\n",
      "          policy_loss: -0.018968686911985916\n",
      "          total_loss: 0.175969879491191\n",
      "          vf_explained_var: 0.7340930104255676\n",
      "          vf_loss: 0.2061593117311788\n",
      "    num_agent_steps_sampled: 3378648\n",
      "    num_agent_steps_trained: 3378648\n",
      "    num_steps_sampled: 3378648\n",
      "    num_steps_trained: 3378648\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.10176991150442\n",
      "    ram_util_percent: 45.47057522123893\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05008659292661449\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.02749005239578\n",
      "    mean_inference_ms: 8.833790671506438\n",
      "    mean_raw_obs_processing_ms: 2.5190122619893702\n",
      "  time_since_restore: 106175.45824766159\n",
      "  time_this_iter_s: 316.856894493103\n",
      "  time_total_s: 106175.45824766159\n",
      "  timers:\n",
      "    learn_throughput: 65.16\n",
      "    learn_time_ms: 153407.634\n",
      "    load_throughput: 88604.884\n",
      "    load_time_ms: 112.815\n",
      "    sample_throughput: 59.208\n",
      "    sample_time_ms: 168827.491\n",
      "    update_time_ms: 9.461\n",
      "  timestamp: 1637006921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3378648\n",
      "  training_iteration: 338\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   338</td><td style=\"text-align: right;\">          106175</td><td style=\"text-align: right;\">3378648</td><td style=\"text-align: right;\"> 1.56591</td><td style=\"text-align: right;\">                8.59</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           90.3909</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3388644\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_20-14-23\n",
      "  done: false\n",
      "  episode_len_mean: 88.73451327433628\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.930000000000007\n",
      "  episode_reward_mean: 1.7956637168141625\n",
      "  episode_reward_min: -1.7100000000000009\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 36468\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.631966711822738\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006275082498913332\n",
      "          policy_loss: -0.016976267428129403\n",
      "          total_loss: 0.19439547418529152\n",
      "          vf_explained_var: 0.7576988935470581\n",
      "          vf_loss: 0.22160906036997324\n",
      "    num_agent_steps_sampled: 3388644\n",
      "    num_agent_steps_trained: 3388644\n",
      "    num_steps_sampled: 3388644\n",
      "    num_steps_trained: 3388644\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.0437627811861\n",
      "    ram_util_percent: 45.587525562372186\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050072752448006005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.035708049275875\n",
      "    mean_inference_ms: 8.833969654216448\n",
      "    mean_raw_obs_processing_ms: 2.52628679167221\n",
      "  time_since_restore: 106517.69282865524\n",
      "  time_this_iter_s: 342.23458099365234\n",
      "  time_total_s: 106517.69282865524\n",
      "  timers:\n",
      "    learn_throughput: 65.179\n",
      "    learn_time_ms: 153363.128\n",
      "    load_throughput: 88892.141\n",
      "    load_time_ms: 112.451\n",
      "    sample_throughput: 58.097\n",
      "    sample_time_ms: 172057.552\n",
      "    update_time_ms: 9.874\n",
      "  timestamp: 1637007263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3388644\n",
      "  training_iteration: 339\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   339</td><td style=\"text-align: right;\">          106518</td><td style=\"text-align: right;\">3388644</td><td style=\"text-align: right;\"> 1.79566</td><td style=\"text-align: right;\">                6.93</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">           88.7345</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3398640\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_20-19-49\n",
      "  done: false\n",
      "  episode_len_mean: 89.08035714285714\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.030000000000009\n",
      "  episode_reward_mean: 1.701785714285718\n",
      "  episode_reward_min: -1.900000000000001\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 36580\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.620554609380217\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006928409089168105\n",
      "          policy_loss: -0.016079090319128117\n",
      "          total_loss: 0.1870346361090644\n",
      "          vf_explained_var: 0.7325940132141113\n",
      "          vf_loss: 0.2115625177701123\n",
      "    num_agent_steps_sampled: 3398640\n",
      "    num_agent_steps_trained: 3398640\n",
      "    num_steps_sampled: 3398640\n",
      "    num_steps_trained: 3398640\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.24525862068964\n",
      "    ram_util_percent: 45.63125\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0500804654759584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.04106135216185\n",
      "    mean_inference_ms: 8.835394925157477\n",
      "    mean_raw_obs_processing_ms: 2.5236619786860266\n",
      "  time_since_restore: 106843.25281262398\n",
      "  time_this_iter_s: 325.55998396873474\n",
      "  time_total_s: 106843.25281262398\n",
      "  timers:\n",
      "    learn_throughput: 65.199\n",
      "    learn_time_ms: 153315.459\n",
      "    load_throughput: 88780.613\n",
      "    load_time_ms: 112.592\n",
      "    sample_throughput: 58.578\n",
      "    sample_time_ms: 170643.736\n",
      "    update_time_ms: 9.585\n",
      "  timestamp: 1637007589\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3398640\n",
      "  training_iteration: 340\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   340</td><td style=\"text-align: right;\">          106843</td><td style=\"text-align: right;\">3398640</td><td style=\"text-align: right;\"> 1.70179</td><td style=\"text-align: right;\">                7.03</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           89.0804</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3408636\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_20-25-00\n",
      "  done: false\n",
      "  episode_len_mean: 90.4054054054054\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.960000000000013\n",
      "  episode_reward_mean: 1.450810810810814\n",
      "  episode_reward_min: -2.12\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 36691\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.624558960678231\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006474534010909022\n",
      "          policy_loss: -0.01674258307629448\n",
      "          total_loss: 0.17391189967986578\n",
      "          vf_explained_var: 0.7322045564651489\n",
      "          vf_loss: 0.20030655038829606\n",
      "    num_agent_steps_sampled: 3408636\n",
      "    num_agent_steps_trained: 3408636\n",
      "    num_steps_sampled: 3408636\n",
      "    num_steps_trained: 3408636\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.73378378378378\n",
      "    ram_util_percent: 45.71261261261262\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05006414016762297\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.049538594069176\n",
      "    mean_inference_ms: 8.835579075027194\n",
      "    mean_raw_obs_processing_ms: 2.521581601633196\n",
      "  time_since_restore: 107154.09630918503\n",
      "  time_this_iter_s: 310.8434965610504\n",
      "  time_total_s: 107154.09630918503\n",
      "  timers:\n",
      "    learn_throughput: 65.172\n",
      "    learn_time_ms: 153377.73\n",
      "    load_throughput: 88434.811\n",
      "    load_time_ms: 113.032\n",
      "    sample_throughput: 59.004\n",
      "    sample_time_ms: 169410.865\n",
      "    update_time_ms: 11.108\n",
      "  timestamp: 1637007900\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3408636\n",
      "  training_iteration: 341\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   341</td><td style=\"text-align: right;\">          107154</td><td style=\"text-align: right;\">3408636</td><td style=\"text-align: right;\"> 1.45081</td><td style=\"text-align: right;\">                8.96</td><td style=\"text-align: right;\">               -2.12</td><td style=\"text-align: right;\">           90.4054</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3418632\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_20-30-25\n",
      "  done: false\n",
      "  episode_len_mean: 89.34821428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.020000000000012\n",
      "  episode_reward_mean: 1.6614285714285748\n",
      "  episode_reward_min: -2.2299999999999995\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 36803\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6244756638494313\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006516584023926566\n",
      "          policy_loss: -0.019584866031670034\n",
      "          total_loss: 0.1573931059979189\n",
      "          vf_explained_var: 0.7383706569671631\n",
      "          vf_loss: 0.18652143673613095\n",
      "    num_agent_steps_sampled: 3418632\n",
      "    num_agent_steps_trained: 3418632\n",
      "    num_steps_sampled: 3418632\n",
      "    num_steps_trained: 3418632\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.31443965517242\n",
      "    ram_util_percent: 45.59375\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.050081259096348474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.05210596630381\n",
      "    mean_inference_ms: 8.837107638094178\n",
      "    mean_raw_obs_processing_ms: 2.525553546091138\n",
      "  time_since_restore: 107479.42223262787\n",
      "  time_this_iter_s: 325.3259234428406\n",
      "  time_total_s: 107479.42223262787\n",
      "  timers:\n",
      "    learn_throughput: 65.196\n",
      "    learn_time_ms: 153321.603\n",
      "    load_throughput: 88655.377\n",
      "    load_time_ms: 112.751\n",
      "    sample_throughput: 58.385\n",
      "    sample_time_ms: 171207.116\n",
      "    update_time_ms: 10.801\n",
      "  timestamp: 1637008225\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3418632\n",
      "  training_iteration: 342\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   342</td><td style=\"text-align: right;\">          107479</td><td style=\"text-align: right;\">3418632</td><td style=\"text-align: right;\"> 1.66143</td><td style=\"text-align: right;\">                9.02</td><td style=\"text-align: right;\">               -2.23</td><td style=\"text-align: right;\">           89.3482</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3428628\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_20-35-35\n",
      "  done: false\n",
      "  episode_len_mean: 89.90090090090091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.410000000000013\n",
      "  episode_reward_mean: 1.5821621621621653\n",
      "  episode_reward_min: -2.059999999999999\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 36914\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6209645968217115\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007183009546968386\n",
      "          policy_loss: -0.013262492161180474\n",
      "          total_loss: 0.20350292747100004\n",
      "          vf_explained_var: 0.7028731107711792\n",
      "          vf_loss: 0.22456579819783315\n",
      "    num_agent_steps_sampled: 3428628\n",
      "    num_agent_steps_trained: 3428628\n",
      "    num_steps_sampled: 3428628\n",
      "    num_steps_trained: 3428628\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.68939051918736\n",
      "    ram_util_percent: 45.80609480812641\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05007643991774609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.060380759005184\n",
      "    mean_inference_ms: 8.838337919285612\n",
      "    mean_raw_obs_processing_ms: 2.5198143319817645\n",
      "  time_since_restore: 107789.73557257652\n",
      "  time_this_iter_s: 310.3133399486542\n",
      "  time_total_s: 107789.73557257652\n",
      "  timers:\n",
      "    learn_throughput: 65.198\n",
      "    learn_time_ms: 153317.508\n",
      "    load_throughput: 88174.208\n",
      "    load_time_ms: 113.366\n",
      "    sample_throughput: 58.848\n",
      "    sample_time_ms: 169862.386\n",
      "    update_time_ms: 10.383\n",
      "  timestamp: 1637008535\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3428628\n",
      "  training_iteration: 343\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   343</td><td style=\"text-align: right;\">          107790</td><td style=\"text-align: right;\">3428628</td><td style=\"text-align: right;\"> 1.58216</td><td style=\"text-align: right;\">               10.41</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           89.9009</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3438624\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_20-41-02\n",
      "  done: false\n",
      "  episode_len_mean: 88.75221238938053\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.440000000000014\n",
      "  episode_reward_mean: 1.8920353982300921\n",
      "  episode_reward_min: -2.1899999999999995\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 37027\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.625249999608749\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.006519722472342376\n",
      "          policy_loss: -0.014883389908016428\n",
      "          total_loss: 0.1912943413013465\n",
      "          vf_explained_var: 0.7307884097099304\n",
      "          vf_loss: 0.21572089516040352\n",
      "    num_agent_steps_sampled: 3438624\n",
      "    num_agent_steps_trained: 3438624\n",
      "    num_steps_sampled: 3438624\n",
      "    num_steps_trained: 3438624\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.43648068669528\n",
      "    ram_util_percent: 45.96351931330472\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05008152791712998\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.06421175859821\n",
      "    mean_inference_ms: 8.839614636684926\n",
      "    mean_raw_obs_processing_ms: 2.5196978749692067\n",
      "  time_since_restore: 108116.77729582787\n",
      "  time_this_iter_s: 327.0417232513428\n",
      "  time_total_s: 108116.77729582787\n",
      "  timers:\n",
      "    learn_throughput: 65.178\n",
      "    learn_time_ms: 153365.689\n",
      "    load_throughput: 88249.894\n",
      "    load_time_ms: 113.269\n",
      "    sample_throughput: 58.756\n",
      "    sample_time_ms: 170126.956\n",
      "    update_time_ms: 10.707\n",
      "  timestamp: 1637008862\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3438624\n",
      "  training_iteration: 344\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   344</td><td style=\"text-align: right;\">          108117</td><td style=\"text-align: right;\">3438624</td><td style=\"text-align: right;\"> 1.89204</td><td style=\"text-align: right;\">               10.44</td><td style=\"text-align: right;\">               -2.19</td><td style=\"text-align: right;\">           88.7522</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 3448620\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_20-46-28\n",
      "  done: false\n",
      "  episode_len_mean: 88.30088495575221\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.110000000000012\n",
      "  episode_reward_mean: 1.26699115044248\n",
      "  episode_reward_min: -1.9500000000000006\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 37140\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6276405351793666\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.005606977914184025\n",
      "          policy_loss: -0.018584450957580254\n",
      "          total_loss: 0.1477483398318848\n",
      "          vf_explained_var: 0.7441065907478333\n",
      "          vf_loss: 0.17823912616835064\n",
      "    num_agent_steps_sampled: 3448620\n",
      "    num_agent_steps_trained: 3448620\n",
      "    num_steps_sampled: 3448620\n",
      "    num_steps_trained: 3448620\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.4694623655914\n",
      "    ram_util_percent: 45.8068817204301\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0500725061808251\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.07228383972998\n",
      "    mean_inference_ms: 8.839877617405543\n",
      "    mean_raw_obs_processing_ms: 2.5214841944068462\n",
      "  time_since_restore: 108442.24078464508\n",
      "  time_this_iter_s: 325.46348881721497\n",
      "  time_total_s: 108442.24078464508\n",
      "  timers:\n",
      "    learn_throughput: 65.188\n",
      "    learn_time_ms: 153341.359\n",
      "    load_throughput: 87911.874\n",
      "    load_time_ms: 113.705\n",
      "    sample_throughput: 58.313\n",
      "    sample_time_ms: 171419.641\n",
      "    update_time_ms: 11.303\n",
      "  timestamp: 1637009188\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3448620\n",
      "  training_iteration: 345\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">   345</td><td style=\"text-align: right;\">          108442</td><td style=\"text-align: right;\">3448620</td><td style=\"text-align: right;\"> 1.26699</td><td style=\"text-align: right;\">                9.11</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           88.3009</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 128,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 5_000,\n",
    "             #\"lr\": 1e-4,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO All Tasks pretrained (visual pretrained AngelaCNN + CrossAttn) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/all_tasks_cross_attn\",\n",
    "        keep_checkpoints_num=50,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
